{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Execution (PsExec)\n\nThis notebook demonstrates how to execute HEC-RAS plans on remote Windows machines using PsExec.\n\n**Features:**\n- Distributed execution across multiple remote machines\n- Automatic project deployment via network shares\n- Parallel execution with configurable workers\n- Result collection and consolidation\n- **Automatic PsExec.exe download** (no manual setup required)\n\n**Requirements:**\n- Remote machine(s) configured per REMOTE_WORKER_SETUP_GUIDE.md (see feature_dev_notes/RasRemote/)\n- Network share accessible from control machine\n- HEC-RAS installed on remote machine(s)\n\n**Note:** PsExec.exe will be automatically downloaded to `C:\\Users\\{username}\\psexec\\` if not found.\n\n**Author:** William (Bill) Katzenmeyer, P.E., C.F.M.\n\n**Date:** 2025-11-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:44:48.741897Z",
     "iopub.status.busy": "2025-12-04T13:44:48.741749Z",
     "iopub.status.idle": "2025-12-04T13:44:50.617989Z",
     "shell.execute_reply": "2025-12-04T13:44:50.617420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramiko and docker already installed; skipping pip install.\n",
      "Loading ras-commander from local dev copy\n"
     ]
    }
   ],
   "source": [
    "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
    "##### Uncomment and run this cell instead of the pip cell above\n",
    "\n",
    "# Optional dependency install for remote workers (only if missing)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "need_paramiko = False\n",
    "need_docker = False\n",
    "\n",
    "try:\n",
    "    import paramiko\n",
    "except ImportError:\n",
    "    need_paramiko = True\n",
    "\n",
    "try:\n",
    "    import docker\n",
    "except ImportError:\n",
    "    need_docker = True\n",
    "\n",
    "to_install = []\n",
    "if need_paramiko:\n",
    "    to_install.append(\"paramiko\")\n",
    "if need_docker:\n",
    "    to_install.append(\"docker\")\n",
    "\n",
    "if to_install:\n",
    "    print(f\"Installing missing packages: {', '.join(to_install)}\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *to_install])\n",
    "else:\n",
    "    print(\"paramiko and docker already installed; skipping pip install.\")\n",
    "\n",
    "# For Development Mode, add the parent directory to the Python path\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "current_file = Path(os.getcwd()).resolve()\n",
    "rascmdr_directory = current_file.parent\n",
    "\n",
    "# Use insert(0) instead of append() to give highest priority to local version\n",
    "if str(rascmdr_directory) not in sys.path:\n",
    "    sys.path.insert(0, str(rascmdr_directory))\n",
    "\n",
    "print(\"Loading ras-commander from local dev copy\")\n",
    "from ras_commander import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Remote Workers\n",
    "\n",
    "Load worker configurations from `RemoteWorkers.json` file using `load_workers_from_json()`.\n",
    "\n",
    "**First time setup:**\n",
    "1. Copy `RemoteWorkers.json.template` to `RemoteWorkers.json`\n",
    "2. Edit `RemoteWorkers.json` with your remote machine details\n",
    "3. The JSON file is in `.gitignore` for security (credentials won't be committed)\n",
    "\n",
    "**JSON Format:**\n",
    "```json\n",
    "{\n",
    "  \"workers\": [\n",
    "    {\n",
    "      \"name\": \"Local Compute\",\n",
    "      \"worker_type\": \"local\",\n",
    "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
    "      \"process_priority\": \"low\",\n",
    "      \"queue_priority\": 0,\n",
    "      \"cores_total\": 4,\n",
    "      \"cores_per_plan\": 2,\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Remote Workstation\",\n",
    "      \"worker_type\": \"psexec\",\n",
    "      \"hostname\": \"192.168.1.100\",\n",
    "      \"share_path\": \"\\\\\\\\192.168.1.100\\\\RasRemote\",\n",
    "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
    "      \"username\": \"your_username\",\n",
    "      \"password\": \"your_password\",\n",
    "      \"session_id\": 2,\n",
    "      \"process_priority\": \"low\",\n",
    "      \"queue_priority\": 1,\n",
    "      \"cores_total\": 16,\n",
    "      \"cores_per_plan\": 4,\n",
    "      \"enabled\": true\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Changes (v0.85.0):**\n",
    "- `ras_exe_path` is no longer required - automatically obtained from the initialized RAS project\n",
    "- Use `load_workers_from_json()` to load all workers from a JSON file\n",
    "- `worker_type` field is now required in each worker configuration\n",
    "- `worker_folder` replaces `local_path` - specifies where temp folders are created\n",
    "\n",
    "**Configuration Fields:**\n",
    "- `worker_type`: Required - \"psexec\", \"local\", \"docker\", \"ssh\", etc.\n",
    "- `worker_folder`: Local path where temporary worker folders are created during execution\n",
    "- `share_path`: (psexec/docker) UNC path to network share that maps to worker_folder\n",
    "- `process_priority`: OS process priority for HEC-RAS execution\n",
    "  - Valid values: `\"low\"` (default, recommended), `\"below normal\"`, `\"normal\"`\n",
    "- `queue_priority`: Execution queue priority (0-9)\n",
    "  - Lower values execute first (0 = highest priority)\n",
    "- `cores_total`: Total CPU cores on the remote machine (enables parallel execution)\n",
    "- `cores_per_plan`: Cores allocated to each HEC-RAS plan\n",
    "- **Parallel plans**: cores_total / cores_per_plan (e.g., 16/4 = 4 plans in parallel)\n",
    "\n",
    "**Session ID:** Use `query user` on remote machine to find (typically 2)\n",
    "\n",
    "### Docker Worker Configuration\n",
    "\n",
    "For Docker workers using SSH remote hosts (`docker_host: \"ssh://user@host\"`):\n",
    "\n",
    "**Required Setup:**\n",
    "1. **SSH key-based authentication** (password auth NOT supported by Docker SDK)\n",
    "   ```bash\n",
    "   # Generate SSH key (if you don't have one)\n",
    "   ssh-keygen -t ed25519\n",
    "   \n",
    "   # Copy key to remote host\n",
    "   ssh-copy-id user@192.168.3.8\n",
    "   \n",
    "   # Test connection (must work without password prompt)\n",
    "   ssh user@192.168.3.8 \"docker info\"\n",
    "   ```\n",
    "\n",
    "2. **Docker configuration on remote host:**\n",
    "   - Docker Desktop or Docker Engine must be running\n",
    "   - User must be in the `docker` group (Linux) or have Docker Desktop access (Windows)\n",
    "\n",
    "3. **JSON configuration example:**\n",
    "   ```json\n",
    "   {\n",
    "     \"name\": \"Remote Docker\",\n",
    "     \"worker_type\": \"docker\",\n",
    "     \"docker_image\": \"hecras:6.6\",\n",
    "     \"docker_host\": \"ssh://user@192.168.3.8\",\n",
    "     \"share_path\": \"\\\\\\\\192.168.3.8\\\\RasRemote\",\n",
    "     \"remote_staging_path\": \"/mnt/c/RasRemote\",\n",
    "     \"use_ssh_client\": true,\n",
    "     \"cores_total\": 8,\n",
    "     \"cores_per_plan\": 4,\n",
    "     \"preprocess_on_host\": true,\n",
    "     \"enabled\": true\n",
    "   }\n",
    "   ```\n",
    "\n",
    "**Key Docker Fields:**\n",
    "- `docker_image`: Docker image with HEC-RAS Linux (e.g., \"hecras:6.6\")\n",
    "- `docker_host`: Docker daemon URL - `ssh://user@host` for remote SSH\n",
    "- `remote_staging_path`: Path on Docker host for volume mounts (use WSL paths like `/mnt/c/...`)\n",
    "- `use_ssh_client`: Set `true` to use system ssh command (recommended for SSH agent support)\n",
    "- `preprocess_on_host`: Set `true` to run Windows preprocessing locally before Docker execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:44:50.620145Z",
     "iopub.status.busy": "2025-12-04T13:44:50.619899Z",
     "iopub.status.idle": "2025-12-04T13:44:50.625070Z",
     "shell.execute_reply": "2025-12-04T13:44:50.624571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 enabled worker(s) in RemoteWorkers.json:\n",
      "  - CLB-04 Docker 6.6 (localhost)\n",
      "    Type: docker\n",
      "    Cores: 4 total, 4 per plan \u2192 1 plans in parallel\n",
      "    Process Priority: low, Queue Priority: 4\n",
      "\n",
      "NOTE: Workers will be loaded after init_ras_project() to get ras_exe_path automatically\n"
     ]
    }
   ],
   "source": [
    "# Load remote worker configurations using the new load_workers_from_json() function\n",
    "# Note: Workers are loaded AFTER init_ras_project() so ras_exe_path is obtained automatically\n",
    "\n",
    "config_file = Path(\"RemoteWorkers.json\")\n",
    "\n",
    "if not config_file.exists():\n",
    "    print(\"ERROR: RemoteWorkers.json not found!\")\n",
    "    print()\n",
    "    print(\"First time setup:\")\n",
    "    print(\"1. Copy RemoteWorkers.json.template to RemoteWorkers.json\")\n",
    "    print(\"2. Edit RemoteWorkers.json with your remote machine details\")\n",
    "    print(\"3. Run this cell again\")\n",
    "    print()\n",
    "    print(\"The RemoteWorkers.json file should be in the same folder as this notebook.\")\n",
    "    raise FileNotFoundError(\"RemoteWorkers.json not found. See instructions above.\")\n",
    "\n",
    "# Preview the JSON configuration (without loading workers yet)\n",
    "import json\n",
    "with open(config_file, 'r') as f:\n",
    "    worker_configs = json.load(f)\n",
    "\n",
    "# Get enabled workers for display\n",
    "enabled_configs = [w for w in worker_configs[\"workers\"] if w.get(\"enabled\", True)]\n",
    "\n",
    "print(f\"Found {len(enabled_configs)} enabled worker(s) in RemoteWorkers.json:\")\n",
    "for w in enabled_configs:\n",
    "    cores_total = w.get('cores_total', 'Not set')\n",
    "    cores_per_plan = w.get('cores_per_plan', 4)\n",
    "    process_priority = w.get('process_priority', 'low')\n",
    "    queue_priority = w.get('queue_priority', 0)\n",
    "    \n",
    "    if w.get('cores_total'):\n",
    "        max_parallel = w['cores_total'] // cores_per_plan\n",
    "        parallel_info = f\"{max_parallel} plans in parallel\"\n",
    "    else:\n",
    "        parallel_info = \"Sequential execution\"\n",
    "\n",
    "    print(f\"  - {w.get('name', 'unnamed')} ({w.get('hostname', 'localhost')})\")\n",
    "    print(f\"    Type: {w.get('worker_type', 'unknown')}\")\n",
    "    print(f\"    Cores: {cores_total} total, {cores_per_plan} per plan \u2192 {parallel_info}\")\n",
    "    print(f\"    Process Priority: {process_priority}, Queue Priority: {queue_priority}\")\n",
    "\n",
    "print()\n",
    "print(\"NOTE: Workers will be loaded after init_ras_project() to get ras_exe_path automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example 1: Execute Single Plan (Muncie)\n",
    "\n",
    "Simple example executing one plan from the Muncie example project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:44:50.626654Z",
     "iopub.status.busy": "2025-12-04T13:44:50.626520Z",
     "iopub.status.idle": "2025-12-04T13:44:50.924896Z",
     "shell.execute_reply": "2025-12-04T13:44:50.924317Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:01 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
      "2025-12-04 10:51:01 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
      "2025-12-04 10:51:01 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
      "2025-12-04 10:51:01 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
      "2025-12-04 10:51:01 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n",
      "2025-12-04 10:51:02 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
      "2025-12-04 10:51:02 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project extracted to: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
      "Project initialized: Muncie\n",
      "Available plans: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Extract Muncie example project\n",
    "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
    "print(f\"Project extracted to: {muncie_path}\")\n",
    "\n",
    "# Initialize project (updates global ras object)\n",
    "init_ras_project(muncie_path, \"6.6\")\n",
    "print(f\"Project initialized: {ras.project_name}\")\n",
    "print(f\"Available plans: {list(ras.plan_df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:44:50.926883Z",
     "iopub.status.busy": "2025-12-04T13:44:50.926736Z",
     "iopub.status.idle": "2025-12-04T13:44:52.170233Z",
     "shell.execute_reply": "2025-12-04T13:44:52.169643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:02 - ras_commander.remote.RasWorker - INFO - Initializing docker worker\n",
      "2025-12-04 10:51:02 - ras_commander.remote.DockerWorker - INFO - Using system ssh client for Docker connection\n",
      "2025-12-04 10:51:02 - ras_commander.remote.DockerWorker - INFO - Docker daemon connected: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Docker image found: hecras:6.6\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - DockerWorker initialized:\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Image: hecras:6.6\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Host: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Preprocess on host: True\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Max parallel plans: 1\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Timeout: 60 minutes\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   SSH client: system\n",
      "2025-12-04 10:51:03 - ras_commander.remote.RasWorker - INFO - Loaded worker: CLB-04 Docker 6.6 (docker)\n",
      "2025-12-04 10:51:03 - ras_commander.remote.RasWorker - INFO - Loaded 1 workers from RemoteWorkers.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 worker(s):\n",
      "  - CLB-04 Docker 6.6 (docker)\n",
      "    Hostname: None\n",
      "    RAS Exe: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n",
      "    Session ID: N/A\n",
      "    Process Priority: low\n",
      "    Queue Priority: 4\n",
      "\n",
      "Using worker for examples: CLB-04 Docker 6.6\n"
     ]
    }
   ],
   "source": [
    "# Load workers from JSON - ras_exe_path is automatically obtained from the ras object\n",
    "# This must be called AFTER init_ras_project() so the RAS executable path is known\n",
    "\n",
    "workers = load_workers_from_json(\"RemoteWorkers.json\")\n",
    "\n",
    "print(f\"Loaded {len(workers)} worker(s):\")\n",
    "for w in workers:\n",
    "    print(f\"  - {w.worker_id} ({w.worker_type})\")\n",
    "    print(f\"    Hostname: {w.hostname}\")\n",
    "    print(f\"    RAS Exe: {w.ras_exe_path}\")\n",
    "    print(f\"    Session ID: {getattr(w, 'session_id', 'N/A')}\")\n",
    "    print(f\"    Process Priority: {getattr(w, 'process_priority', 'N/A')}\")\n",
    "    print(f\"    Queue Priority: {getattr(w, 'queue_priority', 'N/A')}\")\n",
    "    if hasattr(w, 'max_parallel_plans') and w.max_parallel_plans > 1:\n",
    "        print(f\"    Parallel Capacity: {w.max_parallel_plans} plans simultaneously\")\n",
    "    print()\n",
    "\n",
    "# Use first worker for single-plan examples\n",
    "if workers:\n",
    "    worker = workers[0]\n",
    "    print(f\"Using worker for examples: {worker.worker_id}\")\n",
    "else:\n",
    "    raise ValueError(\"No workers loaded from RemoteWorkers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:44:52.172155Z",
     "iopub.status.busy": "2025-12-04T13:44:52.171916Z",
     "iopub.status.idle": "2025-12-04T13:45:10.486743Z",
     "shell.execute_reply": "2025-12-04T13:45:10.486276Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:03 - ras_commander.remote.Execution - INFO - Starting distributed execution of 1 plans across 1 workers\n",
      "2025-12-04 10:51:03 - ras_commander.remote.Execution - INFO - Total worker slots available: 1\n",
      "2025-12-04 10:51:03 - ras_commander.remote.Execution - INFO - Submitting plan 01 to worker CLB-04 Docker 6.6 (sub-worker #1)\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Starting Docker execution: plan 01, sub-worker 1\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Remote Docker host: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Local preprocessing: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Remote share (UNC): \\\\192.168.3.8\\RasRemote\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO -   Docker mounts: /mnt/c/RasRemote\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Copying project to local staging for preprocessing...\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Running preprocessing locally (not on network share)...\n",
      "2025-12-04 10:51:03 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\Users\\billk_clb\\AppData\\Local\\Temp\\ras_docker_Muncie_p01_sw1_b5d7969b\\input\\Muncie.rasmap\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Preprocessing plan 01 for Linux execution...\n",
      "2025-12-04 10:51:03 - ras_commander.geom.GeomPreprocessor - INFO - Clearing geometry preprocessor file for single plan: 01\n",
      "2025-12-04 10:51:03 - ras_commander.geom.GeomPreprocessor - WARNING - No geometry preprocessor file found for: 01\n",
      "2025-12-04 10:51:03 - ras_commander.geom.GeomPreprocessor - INFO - Geometry dataframe updated successfully.\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Plan 01 uses geometry 01\n",
      "2025-12-04 10:51:03 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\\ras_docker_Muncie_p01_sw1_b5d7969b\\input\\Muncie.p01 (flags modified: 3)\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Starting HEC-RAS preprocessing with early termination...\n",
      "2025-12-04 10:51:03 - ras_commander.remote.DockerWorker - INFO - Monitoring Muncie.bco01 for 'Starting Unsteady Flow Computations' signal...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Plan 01 on remote machine...\n",
      "This will take ~30-60 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - Detected 'Starting Unsteady Flow Computations' in Muncie.bco01\n",
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete - terminating HEC-RAS before computation starts\n",
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - Terminating HEC-RAS process...\n",
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - HEC-RAS terminated successfully\n",
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete: Muncie.p01.tmp.hdf (1.9 MB)\n",
      "2025-12-04 10:51:07 - ras_commander.remote.DockerWorker - INFO - Copying preprocessed files to remote share...\n",
      "2025-12-04 10:51:08 - ras_commander.remote.DockerWorker - INFO - Files copied to: \\\\192.168.3.8\\RasRemote\\ras_docker_Muncie_p01_sw1_b5d7969b\n",
      "2025-12-04 10:51:08 - ras_commander.remote.DockerWorker - INFO - Plan 01 uses geometry 01\n",
      "2025-12-04 10:51:08 - ras_commander.remote.DockerWorker - INFO - Starting container: hecras:6.6\n",
      "2025-12-04 10:51:09 - ras_commander.remote.DockerWorker - INFO - Container started: 0c322b3a82ac\n",
      "2025-12-04 10:51:50 - ras_commander.remote.DockerWorker - INFO - Container finished in 40.5s, exit code 0\n",
      "2025-12-04 10:51:51 - ras_commander.remote.DockerWorker - INFO - Copying result: Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.remote.DockerWorker - INFO - Copying result: Muncie.p01.tmp.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.remote.DockerWorker - INFO - Copying result: Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.remote.DockerWorker - INFO - Copying result: Muncie.p01.tmp.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.remote.DockerWorker - INFO - Docker execution completed for plan 01\n",
      "2025-12-04 10:51:51 - ras_commander.remote.Execution - INFO - Plan 01 completed successfully (48.3s)\n",
      "2025-12-04 10:51:51 - ras_commander.remote.Execution - INFO - Distributed execution complete: 1 succeeded, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete in 48.3 seconds (0.8 minutes)\n",
      "\n",
      "Results:\n",
      "  Plan 01: SUCCESS\n",
      "    HDF Path: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "    Execution Time: 48.3s\n"
     ]
    }
   ],
   "source": [
    "# Execute Plan 01 remotely\n",
    "# autoclean=True (default) deletes worker folders after execution\n",
    "# Set autoclean=False for debugging to preserve worker folders on the remote machine\n",
    "\n",
    "print(\"Executing Plan 01 on remote machine...\")\n",
    "print(\"This will take ~30-60 seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = compute_parallel_remote(\n",
    "    plan_numbers=\"01\",\n",
    "    workers=[worker],\n",
    "    num_cores=4,\n",
    "    autoclean=True  # Default is True - deletes temp folders after execution\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"\\nResults:\")\n",
    "for plan_num, result in results.items():\n",
    "    if result.success:\n",
    "        print(f\"  Plan {plan_num}: SUCCESS\")\n",
    "        print(f\"    HDF Path: {result.hdf_path}\")\n",
    "        print(f\"    Execution Time: {result.execution_time:.1f}s\")\n",
    "    else:\n",
    "        print(f\"  Plan {plan_num}: FAILED - {result.error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:45:10.488401Z",
     "iopub.status.busy": "2025-12-04T13:45:10.488251Z",
     "iopub.status.idle": "2025-12-04T13:45:10.509097Z",
     "shell.execute_reply": "2025-12-04T13:45:10.508579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - WARNING - Compute Messages not found in HDF at 'Results/Summary/Compute Messages (text)', falling back to .txt file extraction\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n",
      "2025-12-04 10:51:51 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MUNCIE PLAN 01 - RESULT VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "HDF File: Muncie.p01.hdf\n",
      "Size: 3.25 MB\n",
      "\n",
      "Compute Status: \u26a0\ufe0f Check messages\n",
      "\n",
      "Compute Messages (last 250 chars):\n",
      "\n",
      "\n",
      "\n",
      "Volume Accounting: Available (1 entries)\n",
      "      Error  Error Percent  Total Boundary Flux of Water In  \\\n",
      "0 -0.277472        0.00075                     36674.503906   \n",
      "\n",
      "   Total Boundary Flux of Water Out Vol Accounting in  Volume Ending  \\\n",
      "0                      33463.007812         Acre Feet    3533.462646   \n",
      "\n",
      "   Volume Starting  \n",
      "0       322.244659  \n",
      "\n",
      "\u2705 Remote execution verified - HDF results successfully collected!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Muncie results using HDF analysis\n",
    "from ras_commander import HdfResultsPlan\n",
    "\n",
    "hdf_path = Path(muncie_path) / \"Muncie.p01.hdf\"\n",
    "\n",
    "if hdf_path.exists():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"MUNCIE PLAN 01 - RESULT VERIFICATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Get basic info\n",
    "    size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"HDF File: {hdf_path.name}\")\n",
    "    print(f\"Size: {size_mb:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    # Get compute messages (static method)\n",
    "    msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
    "    \n",
    "    if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
    "        print(\"Compute Status: \u2705 Successful\")\n",
    "    else:\n",
    "        print(\"Compute Status: \u26a0\ufe0f Check messages\")\n",
    "    \n",
    "    # Show last part of compute messages\n",
    "    print(\"\\nCompute Messages (last 250 chars):\")\n",
    "    print(msgs[-250:])\n",
    "    print()\n",
    "    \n",
    "    # Get steady flow results\n",
    "    is_steady = HdfResultsPlan.is_steady_plan(hdf_path)\n",
    "    if is_steady:\n",
    "        profiles = HdfResultsPlan.get_steady_profile_names(hdf_path)\n",
    "        print(f\"Steady Flow Profiles: {profiles}\")\n",
    "        \n",
    "        # Get WSE for first profile\n",
    "        if profiles:\n",
    "            wse_df = HdfResultsPlan.get_steady_wse(hdf_path, profiles[0])\n",
    "            if wse_df is not None and len(wse_df) > 0:\n",
    "                print(f\"Cross Sections: {len(wse_df)}\")\n",
    "                print(f\"WSE Range: {wse_df['W.S. Elev'].min():.2f} to {wse_df['W.S. Elev'].max():.2f} ft\")\n",
    "    \n",
    "    # Get volume accounting\n",
    "    try:\n",
    "        vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
    "        if vol is not None:\n",
    "            print(f\"\\nVolume Accounting: Available ({len(vol)} entries)\")\n",
    "            print(vol)\n",
    "    except:\n",
    "        print(\"\\nVolume Accounting: Not available\")\n",
    "    \n",
    "    print()\n",
    "    print(\"\u2705 Remote execution verified - HDF results successfully collected!\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"\u274c HDF file not found - execution may have failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:45:10.510901Z",
     "iopub.status.busy": "2025-12-04T13:45:10.510734Z",
     "iopub.status.idle": "2025-12-04T13:45:11.938158Z",
     "shell.execute_reply": "2025-12-04T13:45:11.937489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:51 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
      "2025-12-04 10:51:51 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
      "2025-12-04 10:51:52 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
      "2025-12-04 10:51:53 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project extracted to: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
      "Project initialized: BaldEagleDamBrk\n",
      "Available plans: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# Extract BaldEagleCrkMulti2D project\n",
    "baldeagle_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
    "print(f\"Project extracted to: {baldeagle_path}\")\n",
    "\n",
    "# Initialize project (updates global ras object)\n",
    "init_ras_project(baldeagle_path, \"6.6\")\n",
    "print(f\"Project initialized: {ras.project_name}\")\n",
    "print(f\"Available plans: {list(ras.plan_df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:45:11.940096Z",
     "iopub.status.busy": "2025-12-04T13:45:11.939949Z",
     "iopub.status.idle": "2025-12-04T13:54:41.603556Z",
     "shell.execute_reply": "2025-12-04T13:54:41.603081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:53 - ras_commander.remote.Execution - INFO - Starting distributed execution of 3 plans across 1 workers\n",
      "2025-12-04 10:51:53 - ras_commander.remote.Execution - INFO - Total worker slots available: 1\n",
      "2025-12-04 10:51:53 - ras_commander.remote.Execution - INFO - Submitting plan 03 to worker CLB-04 Docker 6.6 (sub-worker #1)\n",
      "2025-12-04 10:51:53 - ras_commander.remote.Execution - INFO - Submitting plan 04 to worker CLB-04 Docker 6.6 (sub-worker #1)\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Starting Docker execution: plan 03, sub-worker 1\n",
      "2025-12-04 10:51:53 - ras_commander.remote.Execution - INFO - Submitting plan 06 to worker CLB-04 Docker 6.6 (sub-worker #1)\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Remote Docker host: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO -   Local preprocessing: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO -   Remote share (UNC): \\\\192.168.3.8\\RasRemote\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO -   Docker mounts: /mnt/c/RasRemote\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Copying project to local staging for preprocessing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 3 plans on remote machine: ['03', '04', '06']\n",
      "These are 2D unsteady models - may take 5-10 minutes total\n",
      "Watch the logs to observe queue priority and wave scheduling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Running preprocessing locally (not on network share)...\n",
      "2025-12-04 10:51:53 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\Users\\billk_clb\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p03_sw1_87b65e71\\input\\BaldEagleDamBrk.rasmap\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Preprocessing plan 03 for Linux execution...\n",
      "2025-12-04 10:51:53 - ras_commander.geom.GeomPreprocessor - INFO - Clearing geometry preprocessor file for single plan: 03\n",
      "2025-12-04 10:51:53 - ras_commander.geom.GeomPreprocessor - WARNING - No geometry preprocessor file found for: 03\n",
      "2025-12-04 10:51:53 - ras_commander.geom.GeomPreprocessor - INFO - Geometry dataframe updated successfully.\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Plan 03 uses geometry 09\n",
      "2025-12-04 10:51:53 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p03_sw1_87b65e71\\input\\BaldEagleDamBrk.p03 (flags modified: 3)\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Starting HEC-RAS preprocessing with early termination...\n",
      "2025-12-04 10:51:53 - ras_commander.remote.DockerWorker - INFO - Monitoring BaldEagleDamBrk.bco03 for 'Starting Unsteady Flow Computations' signal...\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - Detected 'Starting Unsteady Flow Computations' in BaldEagleDamBrk.bco03\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete - terminating HEC-RAS before computation starts\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - Terminating HEC-RAS process...\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - HEC-RAS terminated successfully\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - WARNING - Full simulation completed. Renaming BaldEagleDamBrk.p03.hdf to BaldEagleDamBrk.p03.tmp.hdf...\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - Created BaldEagleDamBrk.p03.tmp.hdf (59.1 MB)\n",
      "2025-12-04 10:54:29 - ras_commander.remote.DockerWorker - INFO - Copying preprocessed files to remote share...\n",
      "2025-12-04 10:54:33 - ras_commander.remote.DockerWorker - INFO - Files copied to: \\\\192.168.3.8\\RasRemote\\ras_docker_BaldEagleDamBrk_p03_sw1_87b65e71\n",
      "2025-12-04 10:54:33 - ras_commander.remote.DockerWorker - INFO - Plan 03 uses geometry 09\n",
      "2025-12-04 10:54:33 - ras_commander.remote.DockerWorker - INFO - Starting container: hecras:6.6\n",
      "2025-12-04 10:54:34 - ras_commander.remote.DockerWorker - INFO - Container started: c185dede5de4\n",
      "2025-12-04 10:54:36 - ras_commander.remote.DockerWorker - INFO - Container finished in 1.8s, exit code 0\n",
      "2025-12-04 10:54:37 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p03.tmp.hdf\n",
      "2025-12-04 10:54:37 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p03.tmp.hdf\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Docker execution completed for plan 03\n",
      "2025-12-04 10:54:38 - ras_commander.remote.Execution - INFO - Plan 03 completed successfully (165.6s)\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Starting Docker execution: plan 04, sub-worker 1\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Remote Docker host: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO -   Local preprocessing: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO -   Remote share (UNC): \\\\192.168.3.8\\RasRemote\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO -   Docker mounts: /mnt/c/RasRemote\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Copying project to local staging for preprocessing...\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Running preprocessing locally (not on network share)...\n",
      "2025-12-04 10:54:38 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\Users\\billk_clb\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p04_sw1_96236c8b\\input\\BaldEagleDamBrk.rasmap\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Preprocessing plan 04 for Linux execution...\n",
      "2025-12-04 10:54:38 - ras_commander.geom.GeomPreprocessor - INFO - Clearing geometry preprocessor file for single plan: 04\n",
      "2025-12-04 10:54:38 - ras_commander.geom.GeomPreprocessor - WARNING - No geometry preprocessor file found for: 04\n",
      "2025-12-04 10:54:38 - ras_commander.geom.GeomPreprocessor - INFO - Geometry dataframe updated successfully.\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Plan 04 uses geometry 13\n",
      "2025-12-04 10:54:38 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p04_sw1_96236c8b\\input\\BaldEagleDamBrk.p04 (flags modified: 3)\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Starting HEC-RAS preprocessing with early termination...\n",
      "2025-12-04 10:54:38 - ras_commander.remote.DockerWorker - INFO - Monitoring BaldEagleDamBrk.bco04 for 'Starting Unsteady Flow Computations' signal...\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - Detected 'Starting Unsteady Flow Computations' in BaldEagleDamBrk.bco04\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete - terminating HEC-RAS before computation starts\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - Terminating HEC-RAS process...\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - HEC-RAS terminated successfully\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete: BaldEagleDamBrk.p04.tmp.hdf (8.8 MB)\n",
      "2025-12-04 10:54:50 - ras_commander.remote.DockerWorker - INFO - Copying preprocessed files to remote share...\n",
      "2025-12-04 10:54:54 - ras_commander.remote.DockerWorker - INFO - Files copied to: \\\\192.168.3.8\\RasRemote\\ras_docker_BaldEagleDamBrk_p04_sw1_96236c8b\n",
      "2025-12-04 10:54:54 - ras_commander.remote.DockerWorker - INFO - Plan 04 uses geometry 13\n",
      "2025-12-04 10:54:55 - ras_commander.remote.DockerWorker - INFO - Starting container: hecras:6.6\n",
      "2025-12-04 10:54:56 - ras_commander.remote.DockerWorker - INFO - Container started: ef914a2a32bd\n",
      "2025-12-04 10:57:00 - ras_commander.remote.DockerWorker - INFO - Container finished in 124.4s, exit code 0\n",
      "2025-12-04 10:57:01 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 10:57:02 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 10:57:02 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p04.tmp.hdf\n",
      "2025-12-04 10:57:02 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p04.tmp.hdf\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Docker execution completed for plan 04\n",
      "2025-12-04 10:57:03 - ras_commander.remote.Execution - INFO - Plan 04 completed successfully (144.8s)\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Starting Docker execution: plan 06, sub-worker 1\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Remote Docker host: ssh://bill@192.168.3.8\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO -   Local preprocessing: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO -   Remote share (UNC): \\\\192.168.3.8\\RasRemote\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO -   Docker mounts: /mnt/c/RasRemote\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Copying project to local staging for preprocessing...\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Running preprocessing locally (not on network share)...\n",
      "2025-12-04 10:57:03 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\Users\\billk_clb\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p06_sw1_614375e3\\input\\BaldEagleDamBrk.rasmap\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Preprocessing plan 06 for Linux execution...\n",
      "2025-12-04 10:57:03 - ras_commander.geom.GeomPreprocessor - INFO - Clearing geometry preprocessor file for single plan: 06\n",
      "2025-12-04 10:57:03 - ras_commander.geom.GeomPreprocessor - WARNING - No geometry preprocessor file found for: 06\n",
      "2025-12-04 10:57:03 - ras_commander.geom.GeomPreprocessor - INFO - Geometry dataframe updated successfully.\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Plan 06 uses geometry 09\n",
      "2025-12-04 10:57:03 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\Users\\BILLK_~1\\AppData\\Local\\Temp\\ras_docker_BaldEagleDamBrk_p06_sw1_614375e3\\input\\BaldEagleDamBrk.p06 (flags modified: 3)\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Starting HEC-RAS preprocessing with early termination...\n",
      "2025-12-04 10:57:03 - ras_commander.remote.DockerWorker - INFO - Monitoring BaldEagleDamBrk.bco06 for 'Starting Unsteady Flow Computations' signal...\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - Detected 'Starting Unsteady Flow Computations' in BaldEagleDamBrk.bco06\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete - terminating HEC-RAS before computation starts\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - Terminating HEC-RAS process...\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - HEC-RAS terminated successfully\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - Preprocessing complete: BaldEagleDamBrk.p06.tmp.hdf (572.7 MB)\n",
      "2025-12-04 11:00:50 - ras_commander.remote.DockerWorker - INFO - Copying preprocessed files to remote share...\n",
      "2025-12-04 11:00:59 - ras_commander.remote.DockerWorker - INFO - Files copied to: \\\\192.168.3.8\\RasRemote\\ras_docker_BaldEagleDamBrk_p06_sw1_614375e3\n",
      "2025-12-04 11:00:59 - ras_commander.remote.DockerWorker - INFO - Plan 06 uses geometry 09\n",
      "2025-12-04 11:01:00 - ras_commander.remote.DockerWorker - INFO - Starting container: hecras:6.6\n",
      "2025-12-04 11:01:01 - ras_commander.remote.DockerWorker - INFO - Container started: 2f3bd958ed94\n",
      "2025-12-04 11:03:42 - ras_commander.remote.DockerWorker - INFO - Container finished in 160.8s, exit code 0\n",
      "2025-12-04 11:03:43 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:45 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p06.tmp.hdf\n",
      "2025-12-04 11:03:47 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:49 - ras_commander.remote.DockerWorker - INFO - Copying result: BaldEagleDamBrk.p06.tmp.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.remote.DockerWorker - INFO - Docker execution completed for plan 06\n",
      "2025-12-04 11:03:52 - ras_commander.remote.Execution - INFO - Plan 06 completed successfully (409.1s)\n",
      "2025-12-04 11:03:52 - ras_commander.remote.Execution - INFO - Distributed execution complete: 3 succeeded, 0 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution complete in 719.5 seconds (12.0 minutes)\n",
      "\n",
      "Results:\n",
      "  Plan 03: SUCCESS (165.6s)\n",
      "  Plan 04: SUCCESS (144.8s)\n",
      "  Plan 06: SUCCESS (409.1s)\n",
      "\n",
      "Summary: 3/3 plans succeeded\n"
     ]
    }
   ],
   "source": [
    "# Execute a few plans to test parallel execution with thread-safe implementation\n",
    "# Testing with 3 plans to verify thread-safety fix works\n",
    "# (Reduced from 8 plans to avoid timeout during testing)\n",
    "\n",
    "test_plans = [\"03\", \"04\", \"06\"]\n",
    "print(f\"Executing {len(test_plans)} plans on remote machine: {test_plans}\")\n",
    "print(\"These are 2D unsteady models - may take 5-10 minutes total\")\n",
    "print(\"Watch the logs to observe queue priority and wave scheduling\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = compute_parallel_remote(\n",
    "    plan_numbers=test_plans,\n",
    "    workers=[worker],\n",
    "    num_cores=4,\n",
    "    autoclean=True  # Default is True - deletes temp folders after execution\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"\\nResults:\")\n",
    "success_count = 0\n",
    "for plan_num, result in results.items():\n",
    "    if result.success:\n",
    "        print(f\"  Plan {plan_num}: SUCCESS ({result.execution_time:.1f}s)\")\n",
    "        success_count += 1\n",
    "    else:\n",
    "        print(f\"  Plan {plan_num}: FAILED - {result.error_message}\")\n",
    "\n",
    "print(f\"\\nSummary: {success_count}/{len(results)} plans succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.605762Z",
     "iopub.status.busy": "2025-12-04T13:54:41.605521Z",
     "iopub.status.idle": "2025-12-04T13:54:41.665868Z",
     "shell.execute_reply": "2025-12-04T13:54:41.665434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Reading computation messages from HDF: BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Successfully extracted 2014 characters from HDF\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - WARNING - Compute Messages not found in HDF at 'Results/Summary/Compute Messages (text)', falling back to .txt file extraction\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p04.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - WARNING - Compute Messages not found in HDF at 'Results/Summary/Compute Messages (text)', falling back to .txt file extraction\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Using existing Path object HDF file: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
      "2025-12-04 11:03:52 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BALDEAGLE PLANS - RESULT VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Plan 03:\n",
      "  HDF Size: 59.07 MB\n",
      "  Status: \u2705 Computation successful\n",
      "  Unsteady Summary: Available\n",
      "  Volume Accounting: 1 entries\n",
      "\n",
      "Plan 04:\n",
      "  HDF Size: 81.72 MB\n",
      "  Status: \u26a0\ufe0f Check compute messages\n",
      "  Unsteady Summary: Available\n",
      "  Volume Accounting: 1 entries\n",
      "\n",
      "Plan 06:\n",
      "  HDF Size: 564.36 MB\n",
      "  Status: \u26a0\ufe0f Check compute messages\n",
      "  Unsteady Summary: Available\n",
      "  Volume Accounting: 1 entries\n",
      "\n",
      "\u2705 Remote execution verified - 2D model results successfully collected!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify BaldEagle results using HDF analysis\n",
    "from ras_commander import HdfResultsPlan, HdfResultsMesh\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BALDEAGLE PLANS - RESULT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for plan_num in [\"03\", \"04\", \"06\"]:\n",
    "    hdf_path = Path(baldeagle_path) / f\"BaldEagleDamBrk.p{plan_num}.hdf\"\n",
    "    \n",
    "    if hdf_path.exists():\n",
    "        print(f\"Plan {plan_num}:\")\n",
    "        size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  HDF Size: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Get compute messages (static method)\n",
    "        msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
    "        if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
    "            print(f\"  Status: \u2705 Computation successful\")\n",
    "        else:\n",
    "            print(f\"  Status: \u26a0\ufe0f Check compute messages\")\n",
    "        \n",
    "        # Get unsteady summary\n",
    "        try:\n",
    "            summary = HdfResultsPlan.get_unsteady_summary(hdf_path)\n",
    "            if summary is not None:\n",
    "                print(f\"  Unsteady Summary: Available\")\n",
    "        except:\n",
    "            print(f\"  Unsteady Summary: Not available\")\n",
    "        \n",
    "        # Get volume accounting\n",
    "        try:\n",
    "            vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
    "            if vol is not None and len(vol) > 0:\n",
    "                print(f\"  Volume Accounting: {len(vol)} entries\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Get mesh timesteps for 2D\n",
    "        try:\n",
    "            mesh_times = HdfResultsMesh.get_output_times(hdf_path)\n",
    "            if mesh_times is not None:\n",
    "                print(f\"  Output Timesteps: {len(mesh_times)}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Plan {plan_num}: \u274c HDF file not found\")\n",
    "        print()\n",
    "\n",
    "print(\"\u2705 Remote execution verified - 2D model results successfully collected!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example 3: Multiple Remote Workers (Parallel)\n",
    "\n",
    "Execute plans across multiple remote machines simultaneously.\n",
    "\n",
    "**Note:** This example uses ALL enabled workers from `RemoteWorkers.json`.\n",
    "To use multiple machines, add additional workers to the JSON file and set `enabled: true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.667975Z",
     "iopub.status.busy": "2025-12-04T13:54:41.667820Z",
     "iopub.status.idle": "2025-12-04T13:54:41.672272Z",
     "shell.execute_reply": "2025-12-04T13:54:41.671893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 1 worker loaded - skipping multi-worker example\n",
      "To test parallel execution:\n",
      "  1. Add more workers to RemoteWorkers.json\n",
      "  2. Set enabled=true for each\n",
      "  3. Re-run the notebook from the beginning\n"
     ]
    }
   ],
   "source": [
    "# Execute multiple plans across all loaded workers\n",
    "# Plans will be distributed based on queue_priority (0 first, then 1, etc.)\n",
    "\n",
    "# Workers were already loaded in cell-7 using load_workers_from_json()\n",
    "if len(workers) > 1:\n",
    "    print(f\"Executing plans across {len(workers)} worker(s)...\")\n",
    "    for w in workers:\n",
    "        print(f\"  - {w.worker_id} ({w.hostname}) - Queue {getattr(w, 'queue_priority', 0)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = compute_parallel_remote(\n",
    "        plan_numbers=[\"06\", \"19\"],\n",
    "        workers=workers,\n",
    "        num_cores=4,\n",
    "        clear_geompre=False,\n",
    "        autoclean=True  # Default is True - deletes temp folders after execution\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nTotal execution time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"\\nResults:\")\n",
    "    for plan_num, result in results.items():\n",
    "        status = \"SUCCESS\" if result.success else f\"FAILED: {result.error_message}\"\n",
    "        print(f\"  Plan {plan_num}: {status}\")\n",
    "    \n",
    "    # Calculate speedup\n",
    "    successful = sum(1 for r in results.values() if r.success)\n",
    "    print(f\"\\nSummary: {successful}/{len(results)} plans succeeded\")\n",
    "else:\n",
    "    print(f\"Only 1 worker loaded - skipping multi-worker example\")\n",
    "    print(f\"To test parallel execution:\")\n",
    "    print(f\"  1. Add more workers to RemoteWorkers.json\")\n",
    "    print(f\"  2. Set enabled=true for each\")\n",
    "    print(f\"  3. Re-run the notebook from the beginning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.673915Z",
     "iopub.status.busy": "2025-12-04T13:54:41.673778Z",
     "iopub.status.idle": "2025-12-04T13:54:41.692004Z",
     "shell.execute_reply": "2025-12-04T13:54:41.691495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 11:03:52 - ras_commander.remote.RasWorker - INFO - Initializing psexec worker\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO - Initializing PsExec worker for 192.168.3.8\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO - PsExec worker configured:\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Hostname: 192.168.3.8\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Share path: \\\\192.168.3.8\\RasRemote\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Worker folder: C:\\RasRemote\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   User: .\\bill\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   System account: False\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Session ID: 2\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Process Priority: low\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - INFO -   Queue Priority: 0\n",
      "2025-12-04 11:03:52 - ras_commander.remote.PsexecWorker - WARNING - Validation deferred - share access and remote execution will be tested during actual plan execution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual worker initialized:\n",
      "  Worker ID: psexec_62a78450\n",
      "  Hostname: 192.168.3.8\n",
      "  Worker Folder: C:\\RasRemote\n",
      "  RAS Exe: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n",
      "  Parallel Capacity: 4 plans\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Manually initialize a worker without JSON file\n",
    "# This demonstrates the init_ras_worker() function directly\n",
    "# Note: ras_exe_path is automatically obtained from the ras object\n",
    "\n",
    "manual_worker = init_ras_worker(\n",
    "    \"psexec\",\n",
    "    hostname=\"192.168.3.8\",  # Replace with your hostname\n",
    "    share_path=r\"\\\\192.168.3.8\\RasRemote\",  # Replace with your share path\n",
    "    worker_folder=r\"C:\\RasRemote\",  # Local path on remote machine corresponding to share_path\n",
    "    credentials={\n",
    "        \"username\": \".\\\\bill\",  # Replace with your username\n",
    "        \"password\": \"YourPassword\"  # Replace with your password\n",
    "    },\n",
    "    # ras_exe_path is NOT required - obtained from ras object automatically\n",
    "    session_id=2,\n",
    "    process_priority=\"low\",\n",
    "    queue_priority=0,\n",
    "    cores_total=8,\n",
    "    cores_per_plan=2\n",
    ")\n",
    "\n",
    "print(f\"Manual worker initialized:\")\n",
    "print(f\"  Worker ID: {manual_worker.worker_id}\")\n",
    "print(f\"  Hostname: {manual_worker.hostname}\")\n",
    "print(f\"  Worker Folder: {manual_worker.worker_folder}\")\n",
    "print(f\"  RAS Exe: {manual_worker.ras_exe_path}\")  # Automatically set from ras object\n",
    "print(f\"  Parallel Capacity: {manual_worker.max_parallel_plans} plans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Results\n",
    "\n",
    "Check that HDF files were created and results collected properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.693756Z",
     "iopub.status.busy": "2025-12-04T13:54:41.693621Z",
     "iopub.status.idle": "2025-12-04T13:54:41.697302Z",
     "shell.execute_reply": "2025-12-04T13:54:41.696791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder not found: c:\\GH\\ras-commander\\examples\\example_projects\\multi_worker_results\\BaldEagleDamBrk\n"
     ]
    }
   ],
   "source": [
    "# List only .pXX.hdf files in results folder (plan result HDFs)\n",
    "import re\n",
    "\n",
    "results_path = Path(baldeagle_path).parent / \"multi_worker_results\" / \"BaldEagleDamBrk\"\n",
    "\n",
    "pattern = re.compile(r\"\\.p\\d{2}\\.hdf$\", re.IGNORECASE)\n",
    "\n",
    "if results_path.exists():\n",
    "    hdf_files = [hdf for hdf in results_path.glob(\"*.hdf\") if pattern.search(hdf.name)]\n",
    "    print(f\"Plan HDF files (.pXX.hdf) in results folder: {len(hdf_files)}\")\n",
    "    for hdf in hdf_files:\n",
    "        size_mb = hdf.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {hdf.name}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"Results folder not found: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Configuration\n",
    "\n",
    "### Session ID Determination\n",
    "\n",
    "Find the active session ID on a remote machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.699070Z",
     "iopub.status.busy": "2025-12-04T13:54:41.698923Z",
     "iopub.status.idle": "2025-12-04T13:54:41.702889Z",
     "shell.execute_reply": "2025-12-04T13:54:41.702376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker doesn't have psexec_path or credentials set\n",
      "Try session_id=2 (most common for single-user workstations)\n"
     ]
    }
   ],
   "source": [
    "# Query active sessions on remote machine\n",
    "# Uses the first loaded worker to get psexec_path and credentials\n",
    "import subprocess\n",
    "\n",
    "if workers:\n",
    "    w = workers[0]\n",
    "    psexec = getattr(w, 'psexec_path', None)\n",
    "    \n",
    "    if psexec and hasattr(w, 'credentials') and w.credentials:\n",
    "        cmd = [\n",
    "            psexec,\n",
    "            f\"\\\\\\\\{w.hostname}\",\n",
    "            \"-u\", w.credentials.get(\"username\", \"\"),\n",
    "            \"-p\", w.credentials.get(\"password\", \"\"),\n",
    "            \"-accepteula\",\n",
    "            \"cmd\", \"/c\", \"query\", \"user\"\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)\n",
    "            print(\"Active sessions on remote machine:\")\n",
    "            print(result.stdout)\n",
    "            print(\"\\nLook for the ID column - typically 2 for workstations\")\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"Timeout querying sessions\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not query sessions: {e}\")\n",
    "    else:\n",
    "        print(\"Worker doesn't have psexec_path or credentials set\")\n",
    "        print(\"Try session_id=2 (most common for single-user workstations)\")\n",
    "else:\n",
    "    print(\"No workers loaded - run previous cells first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Priority Levels\n",
    "\n",
    "Control OS process priority for remote HEC-RAS execution:\n",
    "\n",
    "- `\"low\"` - Low priority (recommended for background work, minimal impact on remote user)\n",
    "- `\"below normal\"` - Below normal priority\n",
    "- `\"normal\"` - Normal priority (default Windows priority)\n",
    "\n",
    "**Note:** Higher priorities (above normal, high, realtime) are NOT supported to avoid impacting remote user operations.\n",
    "\n",
    "### Queue Priority\n",
    "\n",
    "Control execution order across workers:\n",
    "\n",
    "- `queue_priority` is an integer from 0-9 (lower = higher priority)\n",
    "- Workers at queue level 0 are filled before queue level 1, etc.\n",
    "- Within each queue level, wave scheduling applies (one plan per machine first, then additional)\n",
    "- Use for tiered bursting: local workers (queue 0) execute first, then remote (queue 1), then cloud (queue 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.704569Z",
     "iopub.status.busy": "2025-12-04T13:54:41.704429Z",
     "iopub.status.idle": "2025-12-04T13:54:41.708225Z",
     "shell.execute_reply": "2025-12-04T13:54:41.707715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker: CLB-04 Docker 6.6\n",
      "  Process Priority: low\n",
      "  Queue Priority: 4\n",
      "  RAS Exe Path: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n",
      "\n",
      "To change settings, edit RemoteWorkers.json and reload workers:\n",
      "  workers = load_workers_from_json('RemoteWorkers.json')\n"
     ]
    }
   ],
   "source": [
    "# Example: Viewing worker configuration with low process priority\n",
    "# Workers loaded from JSON already have these settings applied\n",
    "\n",
    "if workers:\n",
    "    w = workers[0]\n",
    "    print(f\"Worker: {w.worker_id}\")\n",
    "    print(f\"  Process Priority: {getattr(w, 'process_priority', 'N/A')}\")\n",
    "    print(f\"  Queue Priority: {getattr(w, 'queue_priority', 'N/A')}\")\n",
    "    print(f\"  RAS Exe Path: {w.ras_exe_path}\")\n",
    "    print()\n",
    "    print(\"To change settings, edit RemoteWorkers.json and reload workers:\")\n",
    "    print(\"  workers = load_workers_from_json('RemoteWorkers.json')\")\n",
    "else:\n",
    "    print(\"No workers loaded - run previous cells first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Troubleshooting (Optional)\n",
    "\n",
    "### Test Remote Connections using psexec\n",
    "\n",
    "Change the cell below to a code cell, enter your username and password for use in testing. \n",
    "\n",
    "Don't leave your passwords here, it can get synced back to git.  Use RemoteWorkers.json, it is already in the .gitignore for this repo.  \n",
    "Use the code cell below for testing only, not as a design pattern for production usage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.709936Z",
     "iopub.status.busy": "2025-12-04T13:54:41.709793Z",
     "iopub.status.idle": "2025-12-04T13:54:41.713540Z",
     "shell.execute_reply": "2025-12-04T13:54:41.713047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No psexec workers found in workers list.\n",
      "Define REMOTE_CONFIG manually or add psexec workers to RemoteWorkers.json\n"
     ]
    }
   ],
   "source": [
    "# Build REMOTE_CONFIG from the first psexec worker in workers list\n",
    "# This uses the credentials already loaded from RemoteWorkers.json\n",
    "\n",
    "REMOTE_CONFIG = None\n",
    "\n",
    "if workers:\n",
    "    # Find first psexec worker\n",
    "    for w in workers:\n",
    "        if w.worker_type == \"psexec\":\n",
    "            REMOTE_CONFIG = {\n",
    "                \"hostname\": w.hostname,\n",
    "                \"share_path\": w.share_path,\n",
    "                \"username\": w.credentials.get(\"username\", \"\") if hasattr(w, 'credentials') and w.credentials else \"\",\n",
    "                \"password\": w.credentials.get(\"password\", \"\") if hasattr(w, 'credentials') and w.credentials else \"\",\n",
    "                \"ras_exe_path\": w.ras_exe_path,\n",
    "                \"session_id\": getattr(w, 'session_id', 2)\n",
    "            }\n",
    "            print(f\"REMOTE_CONFIG built from worker: {w.worker_id}\")\n",
    "            print(f\"  Hostname: {REMOTE_CONFIG['hostname']}\")\n",
    "            print(f\"  Share Path: {REMOTE_CONFIG['share_path']}\")\n",
    "            print(f\"  Session ID: {REMOTE_CONFIG['session_id']}\")\n",
    "            break\n",
    "\n",
    "if REMOTE_CONFIG is None:\n",
    "    print(\"WARNING: No psexec workers found in workers list.\")\n",
    "    print(\"Define REMOTE_CONFIG manually or add psexec workers to RemoteWorkers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.715161Z",
     "iopub.status.busy": "2025-12-04T13:54:41.715028Z",
     "iopub.status.idle": "2025-12-04T13:54:41.718881Z",
     "shell.execute_reply": "2025-12-04T13:54:41.718384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_CONFIG not set - run the cell above first\n"
     ]
    }
   ],
   "source": [
    "# Test basic PsExec connectivity\n",
    "import subprocess\n",
    "\n",
    "if REMOTE_CONFIG is None:\n",
    "    print(\"REMOTE_CONFIG not set - run the cell above first\")\n",
    "else:\n",
    "    # Get psexec path from the initialized worker\n",
    "    try:\n",
    "        temp_worker = init_ras_worker(\n",
    "            \"psexec\",\n",
    "            hostname=REMOTE_CONFIG[\"hostname\"],\n",
    "            share_path=REMOTE_CONFIG[\"share_path\"],\n",
    "            credentials={\n",
    "                \"username\": REMOTE_CONFIG[\"username\"],\n",
    "                \"password\": REMOTE_CONFIG[\"password\"]\n",
    "            },\n",
    "            session_id=REMOTE_CONFIG[\"session_id\"]\n",
    "        )\n",
    "        psexec_path = temp_worker.psexec_path\n",
    "\n",
    "        test_cmd = [\n",
    "            psexec_path,\n",
    "            f\"\\\\\\\\{REMOTE_CONFIG['hostname']}\",\n",
    "            \"-u\", REMOTE_CONFIG[\"username\"],\n",
    "            \"-p\", REMOTE_CONFIG[\"password\"],\n",
    "            \"-i\", str(REMOTE_CONFIG[\"session_id\"]),\n",
    "            \"-accepteula\",\n",
    "            \"cmd\", \"/c\", \"echo\", \"SUCCESS\"\n",
    "        ]\n",
    "\n",
    "        result = subprocess.run(test_cmd, capture_output=True, text=True, timeout=30)\n",
    "        if \"SUCCESS\" in result.stdout:\n",
    "            print(\"[OK] PsExec connection successful!\")\n",
    "        else:\n",
    "            print(\"[WARNING] Unexpected output:\")\n",
    "            print(result.stdout)\n",
    "            print(result.stderr)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"[FAIL] Connection timeout - check firewall and services\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] Connection error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Share Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.720434Z",
     "iopub.status.busy": "2025-12-04T13:54:41.720304Z",
     "iopub.status.idle": "2025-12-04T13:54:41.723608Z",
     "shell.execute_reply": "2025-12-04T13:54:41.723119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_CONFIG not set - run the 'Build REMOTE_CONFIG' cell first\n"
     ]
    }
   ],
   "source": [
    "# Test if share is accessible\n",
    "from pathlib import WindowsPath\n",
    "\n",
    "if REMOTE_CONFIG is None:\n",
    "    print(\"REMOTE_CONFIG not set - run the 'Build REMOTE_CONFIG' cell first\")\n",
    "else:\n",
    "    share_path = Path(REMOTE_CONFIG[\"share_path\"])\n",
    "\n",
    "    try:\n",
    "        # This may fail without authenticated session - that's OK\n",
    "        if share_path.exists():\n",
    "            print(f\"[OK] Share accessible: {share_path}\")\n",
    "            files = list(share_path.iterdir())[:5]\n",
    "            print(f\"     Contents: {len(list(share_path.iterdir()))} items\")\n",
    "        else:\n",
    "            print(f\"[INFO] Share not accessible via Path.exists() (authentication may be required)\")\n",
    "            print(f\"      This is normal - share will be accessed during execution with credentials\")\n",
    "    except Exception as e:\n",
    "        print(f\"[INFO] Cannot test share access: {e}\")\n",
    "        print(f\"      This is normal - share will be accessed during execution with credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Notes and Best Practices\n",
    "\n",
    "### Remote Worker Configuration:\n",
    "- Credentials stored in `RemoteWorkers.json` (not committed to git)\n",
    "- See **REMOTE_WORKERS_README.md** for JSON format and setup\n",
    "- Template provided: `RemoteWorkers.json.template`\n",
    "\n",
    "### Remote Worker Requirements:\n",
    "1. \u2705 Network share created and accessible\n",
    "2. \u2705 User in local Administrators group\n",
    "3. \u2705 Group Policy: User added to network access, local logon, batch job policies\n",
    "4. \u2705 Registry: LocalAccountTokenFilterPolicy = 1\n",
    "5. \u2705 Remote Registry service running\n",
    "6. \u2705 Windows Firewall configured\n",
    "7. \u2705 Machine rebooted after changes\n",
    "\n",
    "### Session ID:\n",
    "- Session ID 2 is typical for single-user workstations\n",
    "- Use `query user` on remote machine to verify\n",
    "- User must be logged in for session to be active\n",
    "- Session ID can change if user logs off/on\n",
    "\n",
    "### HEC-RAS Considerations:\n",
    "- HEC-RAS is a GUI application\n",
    "- MUST use session-based execution (`system_account=False`)\n",
    "- NEVER use SYSTEM account (`system_account=True`) for HEC-RAS\n",
    "- HEC-RAS window will start on the desktop of the remote desktop\n",
    "- Ensure HEC-RAS version matches on all workers, and TOS has been accepted.\n",
    "\n",
    "### Performance:\n",
    "- Network share speed affects file transfer\n",
    "- Use Gigabit Ethernet for best performance\n",
    "- 2-4 workers per machine optimal (depends on cores/RAM)\n",
    "- Plans execute sequentially on each worker\n",
    "- Multiple workers enable true parallel execution\n",
    "\n",
    "### Security:\n",
    "- Credentials in `RemoteWorkers.json` (in .gitignore)\n",
    "- Never commit credentials to git\n",
    "- See setup instructions for required group policy and registry changes\n",
    "\n",
    "### Debugging:\n",
    "- Check logs in ras_commander.log\n",
    "- Inspect compute messages: `project.p##.computeMsgs.txt`\n",
    "- Verify temp folders on remote share\n",
    "- Test PsExec manually with provided batch files\n",
    "\n",
    "---\n",
    "\n",
    "**For complete setup instructions, see:**\n",
    "- `feature_dev_notes/RasRemote/REMOTE_WORKER_SETUP_GUIDE.md` - Remote machine setup\n",
    "- `REMOTE_WORKERS_README.md` - JSON credential file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup Remote Worker Folders\n",
    "\n",
    "The `autoclean=True` parameter (default) automatically deletes worker folders after execution.\n",
    "However, if you used `autoclean=False` for debugging or if executions were interrupted,\n",
    "you may have leftover folders on the remote shares.\n",
    "\n",
    "**All files in the RasRemote share are considered temporary** and can be safely deleted\n",
    "to preserve disk space on the remote machines.\n",
    "\n",
    "Run the cells below to manually clean up any remaining worker folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:41.725260Z",
     "iopub.status.busy": "2025-12-04T13:54:41.725128Z",
     "iopub.status.idle": "2025-12-04T13:54:43.146336Z",
     "shell.execute_reply": "2025-12-04T13:54:43.145916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLEANUP PREVIEW (dry_run=True)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "Share: \\\\192.168.3.8\\RasRemote\\ (None)\n",
      "============================================================\n",
      "  [WOULD DELETE] BaldEagleDamBrk_04_SW2_1eb53001 (0.0 MB)\n",
      "  [WOULD DELETE] docker (0.0 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_5a90bd88 (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_5b00f282 (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_87b65e71 (574.3 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_a81a8524 (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_b8ad058f (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_e9545117 (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p03_sw1_f6147736 (574.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p04_sw1_838f712b (791.0 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p04_sw1_96236c8b (794.3 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p04_sw1_aaf7134c (790.9 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p04_sw1_f9a505f9 (790.9 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p06_sw1_614375e3 (2877.4 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p06_sw1_65d667e2 (2929.6 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p06_sw1_690c1887 (2929.6 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p06_sw1_f15855af (2929.5 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p13_sw1_e283fe6e (1789.3 MB)\n",
      "  [WOULD DELETE] ras_docker_BaldEagleDamBrk_p15_sw1_e0423956 (247.6 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_3eed65fe (68.3 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_64e1d6b4 (68.3 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_6e207aef (65.1 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_8e32baee (60.8 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_a2ee2508 (65.1 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_a3e45f57 (65.1 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_a70d3004 (49.4 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_b5d7969b (81.7 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_ded0a52f (68.3 MB)\n",
      "  [WOULD DELETE] ras_docker_Muncie_p01_sw1_fa628206 (68.3 MB)\n",
      "\n",
      "  Summary: 29 folders, 21551.0 MB total\n",
      "  Set dry_run=False to delete these folders\n"
     ]
    }
   ],
   "source": [
    "# List and optionally clean up worker folders on remote machines\n",
    "# This cleans ALL files in the RasRemote share - all contents are temporary\n",
    "\n",
    "def cleanup_remote_shares(workers, dry_run=True):\n",
    "    \"\"\"\n",
    "    Clean up worker folders from remote shares.\n",
    "    \n",
    "    Args:\n",
    "        workers: List of worker objects with share_path attribute\n",
    "        dry_run: If True, only list folders without deleting (default True for safety)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {hostname: {\"folders\": count, \"size_mb\": total_size}}\n",
    "    \"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    results = {}\n",
    "    seen_shares = set()\n",
    "    \n",
    "    for w in workers:\n",
    "        if not hasattr(w, 'share_path') or not w.share_path:\n",
    "            continue\n",
    "            \n",
    "        share_path = Path(w.share_path)\n",
    "        share_key = str(share_path)\n",
    "        \n",
    "        # Skip if we've already processed this share\n",
    "        if share_key in seen_shares:\n",
    "            continue\n",
    "        seen_shares.add(share_key)\n",
    "        \n",
    "        hostname = getattr(w, 'hostname', 'unknown')\n",
    "        \n",
    "        try:\n",
    "            if not share_path.exists():\n",
    "                print(f\"Share not accessible: {share_path}\")\n",
    "                continue\n",
    "                \n",
    "            folders = [f for f in share_path.iterdir() if f.is_dir()]\n",
    "            total_size = 0\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Share: {share_path} ({hostname})\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if not folders:\n",
    "                print(\"  No folders found - share is clean\")\n",
    "                results[hostname] = {\"folders\": 0, \"size_mb\": 0}\n",
    "                continue\n",
    "                \n",
    "            for folder in folders:\n",
    "                # Calculate folder size\n",
    "                folder_size = sum(f.stat().st_size for f in folder.rglob('*') if f.is_file())\n",
    "                folder_size_mb = folder_size / (1024 * 1024)\n",
    "                total_size += folder_size_mb\n",
    "                \n",
    "                if dry_run:\n",
    "                    print(f\"  [WOULD DELETE] {folder.name} ({folder_size_mb:.1f} MB)\")\n",
    "                else:\n",
    "                    print(f\"  [DELETING] {folder.name} ({folder_size_mb:.1f} MB)\")\n",
    "                    shutil.rmtree(folder, ignore_errors=True)\n",
    "            \n",
    "            results[hostname] = {\"folders\": len(folders), \"size_mb\": total_size}\n",
    "            \n",
    "            if dry_run:\n",
    "                print(f\"\\n  Summary: {len(folders)} folders, {total_size:.1f} MB total\")\n",
    "                print(f\"  Set dry_run=False to delete these folders\")\n",
    "            else:\n",
    "                print(f\"\\n  Deleted: {len(folders)} folders, {total_size:.1f} MB freed\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing {share_path}: {e}\")\n",
    "            \n",
    "    return results\n",
    "\n",
    "# DRY RUN - List folders without deleting\n",
    "print(\"=\" * 70)\n",
    "print(\"CLEANUP PREVIEW (dry_run=True)\")\n",
    "print(\"=\" * 70)\n",
    "cleanup_results = cleanup_remote_shares(workers, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T13:54:43.148033Z",
     "iopub.status.busy": "2025-12-04T13:54:43.147859Z",
     "iopub.status.idle": "2025-12-04T13:54:43.150176Z",
     "shell.execute_reply": "2025-12-04T13:54:43.149732Z"
    }
   },
   "outputs": [],
   "source": [
    "# ACTUALLY DELETE - Uncomment and run to delete all worker folders\n",
    "# WARNING: This permanently deletes all folders in the RasRemote shares!\n",
    "\n",
    "# print(\"=\" * 70)\n",
    "# print(\"CLEANUP EXECUTION (dry_run=False)\")\n",
    "# print(\"=\" * 70)\n",
    "# cleanup_results = cleanup_remote_shares(workers, dry_run=False)\n",
    "# print(\"\\nCleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rascmdr_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}