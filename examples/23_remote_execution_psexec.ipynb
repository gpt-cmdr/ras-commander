{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Remote Execution with ras-commander\n",
    "\n",
    "This notebook demonstrates how to execute HEC-RAS plans using:\n",
    "1. **Local parallel execution** - `RasCmdr.compute_parallel()` on your local machine\n",
    "2. **Remote execution** - `compute_parallel_remote()` on remote machines via PsExec/Docker\n",
    "\n",
    "## Features\n",
    "- Distributed execution across multiple remote machines\n",
    "- Automatic project deployment via network shares\n",
    "- Parallel execution with configurable workers\n",
    "- Result collection and consolidation\n",
    "- **Automatic PsExec.exe download** (no manual setup required)\n",
    "\n",
    "## Requirements for Remote Execution\n",
    "- Remote machine(s) configured per `REMOTE_WORKER_SETUP_GUIDE.md`\n",
    "- Network share accessible from control machine\n",
    "- HEC-RAS installed on remote machine(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ras-commander...\n",
      "Loaded from: C:\\GH\\ras-commander\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# For Development Mode: add parent directory to path\n",
    "current_file = Path(os.getcwd()).resolve()\n",
    "rascmdr_directory = current_file.parent\n",
    "if str(rascmdr_directory) not in sys.path:\n",
    "    sys.path.insert(0, str(rascmdr_directory))\n",
    "\n",
    "print(\"Loading ras-commander...\")\n",
    "from ras_commander import *\n",
    "print(f\"Loaded from: {rascmdr_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n",
      "2025-12-10 21:10:18 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n",
      "2025-12-10 21:10:19 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
      "2025-12-10 21:10:19 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project extracted to: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
      "\n",
      "Project: BaldEagleDamBrk\n",
      "Available plans: ['13', '15', '17', '18', '19', '03', '04', '02', '01', '05', '06']\n"
     ]
    }
   ],
   "source": [
    "# Extract example project for testing\n",
    "project_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\", output_path=\"example_projects_23_remote_execution_psexec\")\n",
    "print(f\"Project extracted to: {project_path}\")\n",
    "\n",
    "# Initialize project\n",
    "ras = init_ras_project(project_path, \"6.6\")\n",
    "print(f\"\\nProject: {ras.project_name}\")\n",
    "print(f\"Available plans: {list(ras.plan_df['plan_number'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Local Parallel Execution\n",
    "\n",
    "Use `RasCmdr.compute_parallel()` to run multiple plans on your **local machine**.\n",
    "This is the simplest way to parallelize HEC-RAS execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "#### Configuration for local parallel execution\n",
    "LOCAL_PLANS = [\"03\", \"04\", \"06\"]  # Plans to execute\n",
    "LOCAL_MAX_WORKERS = 3              # Number of parallel processes\n",
    "LOCAL_NUM_CORES = 2                # Cores per HEC-RAS instance\n",
    "\n",
    "print(f\"Plans to execute: {LOCAL_PLANS}\")\n",
    "print(f\"Configuration: {LOCAL_NUM_CORES} cores x {LOCAL_MAX_WORKERS} workers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "#### Execute plans in parallel on LOCAL machine\n",
    "print(f\"Starting LOCAL parallel execution of {len(LOCAL_PLANS)} plans...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "local_results = RasCmdr.compute_parallel(\n",
    "    plan_number=LOCAL_PLANS,\n",
    "    max_workers=LOCAL_MAX_WORKERS,\n",
    "    num_cores=LOCAL_NUM_CORES,\n",
    "    ras_object=ras,\n",
    "    overwrite_dest=True\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "#### Display local execution results\n",
    "print(\"LOCAL Execution Results:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "success_count = sum(1 for success in local_results.values() if success)\n",
    "fail_count = len(local_results) - success_count\n",
    "\n",
    "for plan_num, success in local_results.items():\n",
    "    status = \"SUCCESS\" if success else \"FAILED\"\n",
    "    print(f\"  Plan {plan_num}: {status}\")\n",
    "\n",
    "print(f\"\\nSummary: {success_count}/{len(local_results)} plans succeeded\")\n",
    "print(f\"Results folder: {ras.project_folder.parent / (ras.project_folder.name + ' [Computed]')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Remote Execution Setup\n",
    "\n",
    "To use **remote execution**, you need to configure remote workers.\n",
    "\n",
    "## First Time Setup\n",
    "1. Copy `RemoteWorkers.json.template` to `RemoteWorkers.json`\n",
    "2. Edit `RemoteWorkers.json` with your remote machine details\n",
    "3. The JSON file is in `.gitignore` for security\n",
    "\n",
    "## Worker Types\n",
    "- **local** - Execute on local machine (useful for mixed local+remote)\n",
    "- **psexec** - Execute on remote Windows via PsExec\n",
    "- **docker** - Execute in Docker container (local or remote via SSH)\n",
    "\n",
    "## JSON Configuration Example\n",
    "```json\n",
    "{\n",
    "  \"workers\": [\n",
    "    {\n",
    "      \"name\": \"Local Worker\",\n",
    "      \"worker_type\": \"local\",\n",
    "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
    "      \"cores_total\": 8,\n",
    "      \"cores_per_plan\": 2,\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Remote Workstation\",\n",
    "      \"worker_type\": \"psexec\",\n",
    "      \"hostname\": \"192.168.1.100\",\n",
    "      \"share_path\": \"\\\\\\\\192.168.1.100\\\\RasRemote\",\n",
    "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
    "      \"username\": \"your_username\",\n",
    "      \"password\": \"your_password\",\n",
    "      \"session_id\": 2,\n",
    "      \"cores_total\": 16,\n",
    "      \"cores_per_plan\": 4,\n",
    "      \"enabled\": true\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 enabled worker(s) in RemoteWorkers.json:\n",
      "  - CLB-04 (psexec)\n",
      "    Cores: 8 total, 2 per plan\n",
      "  - Local Compute (local)\n",
      "    Cores: 8 total, 2 per plan\n",
      "  - CLB-02 Docker 6.6 (docker)\n",
      "    Cores: 6 total, 2 per plan\n",
      "  - CLB-03 Docker 6.6 (docker)\n",
      "    Cores: 6 total, 2 per plan\n"
     ]
    }
   ],
   "source": [
    "# Check if RemoteWorkers.json exists\n",
    "config_file = Path(\"RemoteWorkers.json\")\n",
    "\n",
    "if not config_file.exists():\n",
    "    print(\"WARNING: RemoteWorkers.json not found!\")\n",
    "    print()\n",
    "    print(\"To use remote execution:\")\n",
    "    print(\"1. Copy RemoteWorkers.json.template to RemoteWorkers.json\")\n",
    "    print(\"2. Edit RemoteWorkers.json with your remote machine details\")\n",
    "    print(\"3. Re-run this cell\")\n",
    "    print()\n",
    "    print(\"For now, you can still use LOCAL parallel execution (Part 2 above).\")\n",
    "    REMOTE_AVAILABLE = False\n",
    "else:\n",
    "    import json\n",
    "    with open(config_file, 'r') as f:\n",
    "        worker_configs = json.load(f)\n",
    "    \n",
    "    enabled_configs = [w for w in worker_configs[\"workers\"] if w.get(\"enabled\", True)]\n",
    "    \n",
    "    print(f\"Found {len(enabled_configs)} enabled worker(s) in RemoteWorkers.json:\")\n",
    "    for w in enabled_configs:\n",
    "        cores_total = w.get('cores_total', 'Not set')\n",
    "        cores_per_plan = w.get('cores_per_plan', 4)\n",
    "        print(f\"  - {w.get('name', 'unnamed')} ({w.get('worker_type', 'unknown')})\")\n",
    "        print(f\"    Cores: {cores_total} total, {cores_per_plan} per plan\")\n",
    "    \n",
    "    REMOTE_AVAILABLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: Remote Parallel Execution\n",
    "\n",
    "Use `compute_parallel_remote()` to run plans on **remote machines**.\n",
    "\n",
    "**Key differences from local execution:**\n",
    "- Plans are copied to remote shares\n",
    "- Execution happens on remote machines\n",
    "- Results are collected back to local project\n",
    "- Supports multiple remote workers simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 21:10:19 - ras_commander.remote.RasWorker - INFO - Initializing psexec worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO - Initializing PsExec worker for 192.168.3.8\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO - PsExec worker configured:\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Hostname: 192.168.3.8\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Share path: \\\\192.168.3.8\\RasRemote\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Worker folder: C:\\RasRemote\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   User: .\\bill\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   System account: False\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Session ID: 2\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Process Priority: low\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - INFO -   Queue Priority: 1\n",
      "2025-12-10 21:10:19 - ras_commander.remote.PsexecWorker - WARNING - Validation deferred - share access and remote execution will be tested during actual plan execution\n",
      "2025-12-10 21:10:19 - ras_commander.remote.RasWorker - INFO - Loaded worker: CLB-04 (psexec)\n",
      "2025-12-10 21:10:19 - ras_commander.remote.RasWorker - INFO - Initializing local worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO - Initializing local worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO - Local worker configured:\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO -   Worker folder: C:\\RasRemote\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO -   RAS Exe: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO -   Process Priority: low\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO -   Queue Priority: 0\n",
      "2025-12-10 21:10:19 - ras_commander.remote.LocalWorker - INFO -   Parallel Capacity: 4 plans simultaneously\n",
      "2025-12-10 21:10:19 - ras_commander.remote.RasWorker - INFO - Loaded worker: Local Compute (local)\n",
      "2025-12-10 21:10:19 - ras_commander.remote.RasWorker - INFO - Initializing docker worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.DockerWorker - INFO - SSH key path specified: ~/.ssh/docker_worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.DockerWorker - INFO - Note: When use_ssh_client=True, configure the key in ~/.ssh/config:\n",
      "2025-12-10 21:10:19 - ras_commander.remote.DockerWorker - INFO -   Host 192.168.3.160\n",
      "2025-12-10 21:10:19 - ras_commander.remote.DockerWorker - INFO -     IdentityFile C:\\Users\\billk_clb/.ssh/docker_worker\n",
      "2025-12-10 21:10:19 - ras_commander.remote.DockerWorker - INFO - Using system ssh client for Docker connection\n"
     ]
    }
   ],
   "source": [
    "# Load remote workers from JSON\n",
    "# NOTE: This must be called AFTER init_ras_project() so ras_exe_path is available\n",
    "\n",
    "if REMOTE_AVAILABLE:\n",
    "    workers = load_workers_from_json(\"RemoteWorkers.json\")\n",
    "    \n",
    "    print(f\"Loaded {len(workers)} worker(s):\")\n",
    "    for w in workers:\n",
    "        print(f\"  - {w.worker_id} ({w.worker_type})\")\n",
    "        if hasattr(w, 'max_parallel_plans') and w.max_parallel_plans > 1:\n",
    "            print(f\"    Parallel Capacity: {w.max_parallel_plans} plans\")\n",
    "else:\n",
    "    print(\"Remote workers not available - configure RemoteWorkers.json first\")\n",
    "    workers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for remote execution\n",
    "REMOTE_PLANS = [\"03\", \"04\", \"06\"]  # Plans to execute remotely\n",
    "REMOTE_NUM_CORES = 4               # Cores per HEC-RAS instance\n",
    "\n",
    "print(f\"Plans to execute: {REMOTE_PLANS}\")\n",
    "print(f\"Workers available: {len(workers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute plans on REMOTE workers\n",
    "if workers:\n",
    "    print(f\"Starting REMOTE execution of {len(REMOTE_PLANS)} plans...\")\n",
    "    print(f\"Using {len(workers)} worker(s)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    remote_results = compute_parallel_remote(\n",
    "        plan_numbers=REMOTE_PLANS,\n",
    "        workers=workers,\n",
    "        num_cores=REMOTE_NUM_CORES,\n",
    "        autoclean=True  # Delete temp folders after execution (default)\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "else:\n",
    "    print(\"No remote workers available.\")\n",
    "    print(\"Configure RemoteWorkers.json to enable remote execution.\")\n",
    "    remote_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display remote execution results\n",
    "if remote_results:\n",
    "    print(\"REMOTE Execution Results:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for plan_num, result in remote_results.items():\n",
    "        if result.success:\n",
    "            print(f\"  Plan {plan_num}: SUCCESS ({result.execution_time:.1f}s)\")\n",
    "            print(f\"    HDF Path: {result.hdf_path}\")\n",
    "        else:\n",
    "            print(f\"  Plan {plan_num}: FAILED - {result.error_message}\")\n",
    "    \n",
    "    success_count = sum(1 for r in remote_results.values() if r.success)\n",
    "    print(f\"\\nSummary: {success_count}/{len(remote_results)} plans succeeded\")\n",
    "else:\n",
    "    print(\"No remote results - run the remote execution cell above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Verify Results\n",
    "\n",
    "Check that HDF files were created and contain valid results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify HDF results\n",
    "from ras_commander import HdfResultsPlan\n",
    "\n",
    "print(\"Result Verification:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check plans that were executed (either local or remote)\n",
    "plans_to_check = LOCAL_PLANS if local_results else (REMOTE_PLANS if remote_results else [])\n",
    "\n",
    "for plan_num in plans_to_check:\n",
    "    hdf_path = project_path / f\"{ras.project_name}.p{plan_num}.hdf\"\n",
    "    \n",
    "    if hdf_path.exists():\n",
    "        size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\nPlan {plan_num}:\")\n",
    "        print(f\"  HDF Size: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Get compute messages\n",
    "        msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
    "        if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
    "            print(f\"  Status: SUCCESS\")\n",
    "        else:\n",
    "            print(f\"  Status: Check messages\")\n",
    "        \n",
    "        # Get volume accounting\n",
    "        vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
    "        if vol is not None and len(vol) > 0:\n",
    "            error_pct = vol['Error Percent'].iloc[0]\n",
    "            print(f\"  Volume Error: {error_pct:.4f}%\")\n",
    "    else:\n",
    "        print(f\"\\nPlan {plan_num}: HDF not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 6: Manual Worker Configuration (Optional)\n",
    "\n",
    "You can also create workers programmatically without a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a PsExec worker manually\n",
    "# Uncomment and modify with your settings to test\n",
    "\n",
    "# manual_worker = init_ras_worker(\n",
    "#     \"psexec\",\n",
    "#     hostname=\"192.168.1.100\",\n",
    "#     share_path=r\"\\\\192.168.1.100\\RasRemote\",\n",
    "#     worker_folder=r\"C:\\RasRemote\",\n",
    "#     credentials={\n",
    "#         \"username\": \"your_username\",\n",
    "#         \"password\": \"your_password\"\n",
    "#     },\n",
    "#     session_id=2,\n",
    "#     cores_total=8,\n",
    "#     cores_per_plan=2\n",
    "# )\n",
    "# \n",
    "# print(f\"Manual worker created: {manual_worker.worker_id}\")\n",
    "# print(f\"  Parallel Capacity: {manual_worker.max_parallel_plans} plans\")\n",
    "\n",
    "print(\"Uncomment the code above to create a manual worker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 7: Cleanup (Optional)\n",
    "\n",
    "Clean up temporary worker folders on remote shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup function for remote shares\n",
    "def cleanup_remote_shares(workers, dry_run=True):\n",
    "    \"\"\"Clean up worker folders from remote shares.\"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    seen_shares = set()\n",
    "    \n",
    "    for w in workers:\n",
    "        if not hasattr(w, 'share_path') or not w.share_path:\n",
    "            continue\n",
    "            \n",
    "        share_path = Path(w.share_path)\n",
    "        if str(share_path) in seen_shares:\n",
    "            continue\n",
    "        seen_shares.add(str(share_path))\n",
    "        \n",
    "        # Check if share exists before accessing\n",
    "        if not share_path.exists():\n",
    "            continue\n",
    "                \n",
    "            folders = [f for f in share_path.iterdir() if f.is_dir()]\n",
    "            \n",
    "            print(f\"\\nShare: {share_path}\")\n",
    "            print(f\"  Folders: {len(folders)}\")\n",
    "            \n",
    "            for folder in folders:\n",
    "                folder_size = sum(f.stat().st_size for f in folder.rglob('*') if f.is_file())\n",
    "                folder_size_mb = folder_size / (1024 * 1024)\n",
    "                \n",
    "                if dry_run:\n",
    "                    print(f\"  [WOULD DELETE] {folder.name} ({folder_size_mb:.1f} MB)\")\n",
    "                else:\n",
    "                    print(f\"  [DELETING] {folder.name}\")\n",
    "                    shutil.rmtree(folder, ignore_errors=True)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Preview cleanup (dry run)\n",
    "if workers:\n",
    "    print(\"CLEANUP PREVIEW (dry_run=True):\")\n",
    "    cleanup_remote_shares(workers, dry_run=True)\n",
    "    print(\"\\nSet dry_run=False to actually delete folders.\")\n",
    "else:\n",
    "    print(\"No workers loaded - nothing to clean up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: Local vs Remote Execution\n",
    "\n",
    "| Feature | Local (`compute_parallel`) | Remote (`compute_parallel_remote`) |\n",
    "|---------|---------------------------|------------------------------------|\n",
    "| Setup | None | Configure RemoteWorkers.json |\n",
    "| Execution | Local machine only | Remote machines via PsExec/Docker |\n",
    "| File Transfer | Direct | Via network shares |\n",
    "| Scaling | Limited by local cores | Unlimited remote machines |\n",
    "| Best For | Small jobs, testing | Large batches, distributed work |\n",
    "\n",
    "## Quick Reference\n",
    "\n",
    "**Local Parallel:**\n",
    "```python\n",
    "results = RasCmdr.compute_parallel(\n",
    "    plan_number=[\"01\", \"02\", \"03\"],\n",
    "    max_workers=3,\n",
    "    num_cores=2,\n",
    "    ras_object=ras\n",
    ")\n",
    "```\n",
    "\n",
    "**Remote Parallel:**\n",
    "```python\n",
    "workers = load_workers_from_json(\"RemoteWorkers.json\")\n",
    "results = compute_parallel_remote(\n",
    "    plan_numbers=[\"01\", \"02\", \"03\"],\n",
    "    workers=workers,\n",
    "    num_cores=4\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**For complete setup instructions, see:**\n",
    "- `feature_dev_notes/RasRemote/REMOTE_WORKER_SETUP_GUIDE.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rascmdr_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}