{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Execution with PsExec\n",
    "\n",
    "This notebook demonstrates how to execute HEC-RAS plans on remote Windows machines using PsExec.\n",
    "\n",
    "**Features:**\n",
    "- Distributed execution across multiple remote machines\n",
    "- Automatic project deployment via network shares\n",
    "- Parallel execution with configurable workers\n",
    "- Result collection and consolidation\n",
    "- **Automatic PsExec.exe download** (no manual setup required)\n",
    "\n",
    "**Requirements:**\n",
    "- Remote machine(s) configured per REMOTE_WORKER_SETUP_GUIDE.md (see feature_dev_notes/RasRemote/)\n",
    "- Network share accessible from control machine\n",
    "- HEC-RAS installed on remote machine(s)\n",
    "\n",
    "**Note:** PsExec.exe will be automatically downloaded to `C:\\Users\\{username}\\psexec\\` if not found.\n",
    "\n",
    "**Author:** William (Bill) Katzenmeyer, P.E., C.F.M.\n",
    "\n",
    "**Date:** 2025-11-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
    "##### Uncomment and run this cell instead of the pip cell above\n",
    "\n",
    "# For Development Mode, add the parent directory to the Python path\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "current_file = Path(os.getcwd()).resolve()\n",
    "rascmdr_directory = current_file.parent\n",
    "\n",
    "# Use insert(0) instead of append() to give highest priority to local version\n",
    "if str(rascmdr_directory) not in sys.path:\n",
    "    sys.path.insert(0, str(rascmdr_directory))\n",
    "\n",
    "print(\"Loading ras-commander from local dev copy\")\n",
    "from ras_commander import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Remote Workers\n",
    "\n",
    "Load worker configurations from `RemoteWorkers.json` file.\n",
    "\n",
    "**First time setup:**\n",
    "1. Copy `RemoteWorkers.json.template` to `RemoteWorkers.json`\n",
    "2. Edit `RemoteWorkers.json` with your remote machine details\n",
    "3. The JSON file is in `.gitignore` for security (credentials won't be committed)\n",
    "\n",
    "**JSON Format:**\n",
    "```json\n",
    "{\n",
    "  \"workers\": [\n",
    "    {\n",
    "      \"name\": \"Local Compute\",\n",
    "      \"hostname\": \"localhost\",\n",
    "      \"share_path\": \"C:\\\\Temp\\\\RasRemote\",\n",
    "      \"username\": \"local_user\",\n",
    "      \"password\": \"local_password\",\n",
    "      \"ras_exe_path\": \"C:\\\\Program Files (x86)\\\\HEC\\\\HEC-RAS\\\\6.6\\\\RAS.exe\",\n",
    "      \"session_id\": 2,\n",
    "      \"process_priority\": \"low\",\n",
    "      \"queue_priority\": 0,\n",
    "      \"cores_total\": 4,\n",
    "      \"cores_per_plan\": 2,\n",
    "      \"enabled\": true\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Remote Workstation\",\n",
    "      \"hostname\": \"192.168.1.100\",\n",
    "      \"share_path\": \"\\\\\\\\192.168.1.100\\\\RasRemote\",\n",
    "      \"username\": \"your_username\",\n",
    "      \"password\": \"your_password\",\n",
    "      \"ras_exe_path\": \"C:\\\\Program Files (x86)\\\\HEC\\\\HEC-RAS\\\\6.6\\\\RAS.exe\",\n",
    "      \"session_id\": 2,\n",
    "      \"process_priority\": \"low\",\n",
    "      \"queue_priority\": 1,\n",
    "      \"cores_total\": 16,\n",
    "      \"cores_per_plan\": 4,\n",
    "      \"enabled\": true\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Configuration Fields:**\n",
    "- `process_priority`: OS process priority for HEC-RAS execution\n",
    "  - Valid values: `\"low\"` (default, recommended), `\"below normal\"`, `\"normal\"`\n",
    "  - Recommended: `\"low\"` to minimize impact on remote user operations\n",
    "- `queue_priority`: Execution queue priority (0-9)\n",
    "  - Lower values execute first (0 = highest priority)\n",
    "  - Workers at queue level 0 are filled before queue level 1, etc.\n",
    "  - Use for tiered bursting: local=0, remote=1, cloud=2\n",
    "- `cores_total`: Total CPU cores on the remote machine (enables parallel execution)\n",
    "- `cores_per_plan`: Cores allocated to each HEC-RAS plan\n",
    "- **Parallel plans**: cores_total / cores_per_plan (e.g., 16/4 = 4 plans in parallel)\n",
    "\n",
    "**Session ID:** Use `query user` on remote machine to find (typically 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load remote worker configurations from JSON file\n",
    "import json\n",
    "\n",
    "config_file = Path(\"RemoteWorkers.json\")\n",
    "\n",
    "if not config_file.exists():\n",
    "    print(\"ERROR: RemoteWorkers.json not found!\")\n",
    "    print()\n",
    "    print(\"First time setup:\")\n",
    "    print(\"1. Copy RemoteWorkers.json.template to RemoteWorkers.json\")\n",
    "    print(\"2. Edit RemoteWorkers.json with your remote machine details\")\n",
    "    print(\"3. Run this cell again\")\n",
    "    print()\n",
    "    print(\"The RemoteWorkers.json file should be in the same folder as this notebook.\")\n",
    "    raise FileNotFoundError(\"RemoteWorkers.json not found. See instructions above.\")\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "    worker_configs = json.load(f)\n",
    "\n",
    "# Get enabled workers\n",
    "enabled_workers = [w for w in worker_configs[\"workers\"] if w.get(\"enabled\", True)]\n",
    "\n",
    "# Create obfuscated display versions\n",
    "enabled_workers_display = []\n",
    "for w in enabled_workers:\n",
    "    w_display = w.copy()\n",
    "    w_display[\"username\"] = \"<user>\"\n",
    "    w_display[\"password\"] = \"<password>\"\n",
    "    enabled_workers_display.append(w_display)\n",
    "\n",
    "print(f\"Loaded {len(enabled_workers)} enabled worker(s) from RemoteWorkers.json:\")\n",
    "for w in enabled_workers_display:\n",
    "    cores_total = w.get('cores_total', 'Not set')\n",
    "    cores_per_plan = w.get('cores_per_plan', 4)\n",
    "    process_priority = w.get('process_priority', 'low')\n",
    "    queue_priority = w.get('queue_priority', 0)\n",
    "    \n",
    "    if w.get('cores_total'):\n",
    "        max_parallel = w['cores_total'] // cores_per_plan\n",
    "        parallel_info = f\"{max_parallel} plans in parallel\"\n",
    "    else:\n",
    "        parallel_info = \"Sequential execution\"\n",
    "\n",
    "    print(f\"  - {w['name']} ({w['hostname']})\")\n",
    "    print(f\"    User: {w['username']}, Password: {w['password']}\")\n",
    "    print(f\"    Cores: {cores_total} total, {cores_per_plan} per plan → {parallel_info}\")\n",
    "    print(f\"    Process Priority: {process_priority}, Queue Priority: {queue_priority}\")\n",
    "\n",
    "# For single-worker examples, use the first worker\n",
    "if enabled_workers:\n",
    "    REMOTE_CONFIG = enabled_workers[0]\n",
    "    REMOTE_CONFIG_DISPLAY = enabled_workers_display[0]\n",
    "    \n",
    "    print(f\"\\nUsing worker for examples: {REMOTE_CONFIG_DISPLAY['name']}\")\n",
    "    print(f\"  Hostname: {REMOTE_CONFIG_DISPLAY['hostname']}\")\n",
    "    print(f\"  Username: {REMOTE_CONFIG_DISPLAY['username']}\")\n",
    "    print(f\"  Session ID: {REMOTE_CONFIG_DISPLAY['session_id']}\")\n",
    "    print(f\"  Queue Priority: {REMOTE_CONFIG.get('queue_priority', 0)}\")\n",
    "    if REMOTE_CONFIG.get('cores_total'):\n",
    "        max_p = REMOTE_CONFIG['cores_total'] // REMOTE_CONFIG.get('cores_per_plan', 4)\n",
    "        print(f\"  Parallel Capacity: {max_p} plans simultaneously\")\n",
    "else:\n",
    "    raise ValueError(\"No enabled workers found in RemoteWorkers.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example 1: Execute Single Plan (Muncie)\n",
    "\n",
    "Simple example executing one plan from the Muncie example project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Muncie example project\n",
    "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
    "print(f\"Project extracted to: {muncie_path}\")\n",
    "\n",
    "# Initialize project (updates global ras object)\n",
    "init_ras_project(muncie_path, \"6.6\")\n",
    "print(f\"Project initialized: {ras.project_name}\")\n",
    "print(f\"Available plans: {list(ras.plan_df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize remote worker\n",
    "worker = init_ras_worker(\n",
    "    \"psexec\",\n",
    "    hostname=REMOTE_CONFIG[\"hostname\"],\n",
    "    share_path=REMOTE_CONFIG[\"share_path\"],\n",
    "    credentials={\n",
    "        \"username\": REMOTE_CONFIG[\"username\"],\n",
    "        \"password\": REMOTE_CONFIG[\"password\"]\n",
    "    },\n",
    "    ras_exe_path=REMOTE_CONFIG[\"ras_exe_path\"],\n",
    "    session_id=REMOTE_CONFIG[\"session_id\"],\n",
    "    system_account=False,  # Required for HEC-RAS GUI\n",
    "    process_priority=REMOTE_CONFIG.get(\"process_priority\", \"low\"),  # Valid: \"low\", \"below normal\", \"normal\"\n",
    "    queue_priority=REMOTE_CONFIG.get(\"queue_priority\", 0),  # 0-9, lower executes first\n",
    "    cores_total=REMOTE_CONFIG.get(\"cores_total\"),\n",
    "    cores_per_plan=REMOTE_CONFIG.get(\"cores_per_plan\", 4)\n",
    "    # psexec_path omitted - will auto-detect or download to user profile\n",
    ")\n",
    "\n",
    "print(f\"Worker initialized: {worker.worker_id}\")\n",
    "print(f\"Hostname: {worker.hostname}\")\n",
    "print(f\"Session ID: {worker.session_id}\")\n",
    "print(f\"Process Priority: {worker.process_priority}\")\n",
    "print(f\"Queue Priority: {worker.queue_priority}\")\n",
    "print(f\"PsExec location: {worker.psexec_path}\")\n",
    "if worker.max_parallel_plans > 1:\n",
    "    print(f\"Parallel Capacity: {worker.max_parallel_plans} plans simultaneously\")\n",
    "else:\n",
    "    print(f\"Execution Mode: Sequential (set cores_total for parallel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Plan 01 remotely\n",
    "print(\"Executing Plan 01 on remote machine...\")\n",
    "print(\"This will take ~30-60 seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = compute_parallel_remote(\n",
    "    plan_number=\"01\",\n",
    "    workers=[worker],\n",
    "    dest_folder=\"muncie_remote_results\",\n",
    "    num_cores=4,\n",
    "    overwrite_dest=True  # Overwrite if running multiple times\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"\\nResults: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Muncie results using HDF analysis\n",
    "from ras_commander import HdfResultsPlan\n",
    "\n",
    "hdf_path = Path(muncie_path) / \"Muncie.p01.hdf\"\n",
    "\n",
    "if hdf_path.exists():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"MUNCIE PLAN 01 - RESULT VERIFICATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Get basic info\n",
    "    size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"HDF File: {hdf_path.name}\")\n",
    "    print(f\"Size: {size_mb:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    # Get compute messages (static method)\n",
    "    msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
    "    \n",
    "    if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
    "        print(\"Compute Status: ✅ Successful\")\n",
    "    else:\n",
    "        print(\"Compute Status: ⚠️ Check messages\")\n",
    "    \n",
    "    # Show last part of compute messages\n",
    "    print(\"\\nCompute Messages (last 250 chars):\")\n",
    "    print(msgs[-250:])\n",
    "    print()\n",
    "    \n",
    "    # Get steady flow results\n",
    "    is_steady = HdfResultsPlan.is_steady_plan(hdf_path)\n",
    "    if is_steady:\n",
    "        profiles = HdfResultsPlan.get_steady_profile_names(hdf_path)\n",
    "        print(f\"Steady Flow Profiles: {profiles}\")\n",
    "        \n",
    "        # Get WSE for first profile\n",
    "        if profiles:\n",
    "            wse_df = HdfResultsPlan.get_steady_wse(hdf_path, profiles[0])\n",
    "            if wse_df is not None and len(wse_df) > 0:\n",
    "                print(f\"Cross Sections: {len(wse_df)}\")\n",
    "                print(f\"WSE Range: {wse_df['W.S. Elev'].min():.2f} to {wse_df['W.S. Elev'].max():.2f} ft\")\n",
    "    \n",
    "    # Get volume accounting\n",
    "    try:\n",
    "        vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
    "        if vol is not None:\n",
    "            print(f\"\\nVolume Accounting: Available ({len(vol)} entries)\")\n",
    "            print(vol)\n",
    "    except:\n",
    "        print(\"\\nVolume Accounting: Not available\")\n",
    "    \n",
    "    print()\n",
    "    print(\"✅ Remote execution verified - HDF results successfully collected!\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"❌ HDF file not found - execution may have failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BaldEagleCrkMulti2D project\n",
    "baldeagle_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
    "print(f\"Project extracted to: {baldeagle_path}\")\n",
    "\n",
    "# Initialize project (updates global ras object)\n",
    "init_ras_project(baldeagle_path, \"6.6\")\n",
    "print(f\"Project initialized: {ras.project_name}\")\n",
    "print(f\"Available plans: {list(ras.plan_df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute expanded set of plans to test queue priority and parallel execution\n",
    "# Plans 03, 04, 06, 13, 15, 17, 18, 19 - 8 plans total\n",
    "# This tests the queue-aware scheduling with multiple sub-workers\n",
    "\n",
    "test_plans = [\"03\", \"04\", \"06\", \"13\", \"15\", \"17\", \"18\", \"19\"]\n",
    "print(f\"Executing {len(test_plans)} plans on remote machine: {test_plans}\")\n",
    "print(\"These are 2D unsteady models - may take 10-20 minutes total\")\n",
    "print(\"Watch the logs to observe queue priority and wave scheduling\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = compute_parallel_remote(\n",
    "    plan_number=test_plans,\n",
    "    workers=[worker],\n",
    "    dest_folder=\"baldeagle_remote_results\",\n",
    "    num_cores=4,\n",
    "    overwrite_dest=True  # Important: overwrite to avoid conflicts\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"\\nResults:\")\n",
    "success_count = 0\n",
    "for plan, success in results.items():\n",
    "    status = \"SUCCESS\" if success else \"FAILED\"\n",
    "    print(f\"  Plan {plan}: {status}\")\n",
    "    if success:\n",
    "        success_count += 1\n",
    "\n",
    "print(f\"\\nSummary: {success_count}/{len(results)} plans succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify BaldEagle results using HDF analysis\n",
    "from ras_commander import HdfResultsPlan, HdfResultsMesh\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BALDEAGLE PLANS 06 & 19 - RESULT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for plan_num in [\"06\", \"19\"]:\n",
    "    hdf_path = Path(baldeagle_path) / f\"BaldEagleDamBrk.p{plan_num}.hdf\"\n",
    "    \n",
    "    if hdf_path.exists():\n",
    "        print(f\"Plan {plan_num}:\")\n",
    "        size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  HDF Size: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Get compute messages (static method)\n",
    "        msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
    "        if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
    "            print(f\"  Status: ✅ Computation successful\")\n",
    "        else:\n",
    "            print(f\"  Status: ⚠️ Check compute messages\")\n",
    "        \n",
    "        # Get unsteady summary\n",
    "        try:\n",
    "            summary = HdfResultsPlan.get_unsteady_summary(hdf_path)\n",
    "            if summary is not None:\n",
    "                print(f\"  Unsteady Summary: Available\")\n",
    "        except:\n",
    "            print(f\"  Unsteady Summary: Not available\")\n",
    "        \n",
    "        # Get volume accounting\n",
    "        try:\n",
    "            vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
    "            if vol is not None and len(vol) > 0:\n",
    "                print(f\"  Volume Accounting: {len(vol)} entries\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Get mesh timesteps for 2D\n",
    "        try:\n",
    "            mesh_times = HdfResultsMesh.get_output_times(hdf_path)\n",
    "            if mesh_times is not None:\n",
    "                print(f\"  Output Timesteps: {len(mesh_times)}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Plan {plan_num}: ❌ HDF file not found\")\n",
    "        print()\n",
    "\n",
    "print(\"✅ Remote execution verified - 2D model results successfully collected!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example 3: Multiple Remote Workers (Parallel)\n",
    "\n",
    "Execute plans across multiple remote machines simultaneously.\n",
    "\n",
    "**Note:** This example uses ALL enabled workers from `RemoteWorkers.json`.\n",
    "To use multiple machines, add additional workers to the JSON file and set `enabled: true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute multiple plans across all enabled workers\n",
    "# Plans will be distributed based on queue_priority (0 first, then 1, etc.)\n",
    "\n",
    "# Skip if only one worker (already tested in Example 2)\n",
    "if len(enabled_workers) > 1:\n",
    "    # Initialize worker instances from all enabled configs\n",
    "    workers = []\n",
    "    for w_config in enabled_workers:\n",
    "        w = init_ras_worker(\n",
    "            \"psexec\",\n",
    "            hostname=w_config[\"hostname\"],\n",
    "            share_path=w_config[\"share_path\"],\n",
    "            credentials={\n",
    "                \"username\": w_config[\"username\"],\n",
    "                \"password\": w_config[\"password\"]\n",
    "            },\n",
    "            ras_exe_path=w_config[\"ras_exe_path\"],\n",
    "            session_id=w_config[\"session_id\"],\n",
    "            system_account=False,\n",
    "            process_priority=w_config.get(\"process_priority\", \"low\"),  # Valid: \"low\", \"below normal\", \"normal\"\n",
    "            queue_priority=w_config.get(\"queue_priority\", 0),  # 0-9, lower executes first\n",
    "            cores_total=w_config.get(\"cores_total\"),\n",
    "            cores_per_plan=w_config.get(\"cores_per_plan\", 4)\n",
    "        )\n",
    "        workers.append(w)\n",
    "        print(f\"Initialized worker: {w_config['name']} ({w_config['hostname']}) - Queue {w.queue_priority}\")\n",
    "    \n",
    "    print(f\"\\nExecuting plans across {len(workers)} worker(s)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = compute_parallel_remote(\n",
    "        plan_number=[\"06\", \"19\"],  # Or use None for all plans\n",
    "        workers=workers,\n",
    "        dest_folder=\"multi_worker_results\",\n",
    "        num_cores=4,\n",
    "        clear_geompre=False,\n",
    "        overwrite_dest=True\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nTotal execution time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"\\nResults:\")\n",
    "    for plan, success in results.items():\n",
    "        print(f\"  Plan {plan}: {'SUCCESS' if success else 'FAILED'}\")\n",
    "    \n",
    "    # Calculate speedup\n",
    "    estimated_sequential = elapsed * len(workers)\n",
    "    speedup = estimated_sequential / elapsed\n",
    "    print(f\"\\nEstimated speedup: {speedup:.1f}x (with {len(workers)} workers)\")\n",
    "else:\n",
    "    print(f\"Only 1 worker configured - skipping multi-worker example\")\n",
    "    print(f\"To test parallel execution:\")\n",
    "    print(f\"  1. Add more workers to RemoteWorkers.json\")\n",
    "    print(f\"  2. Set enabled=true for each\")\n",
    "    print(f\"  3. Re-run this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute multiple plans across all enabled workers\n",
    "# Plans will be distributed based on queue_priority (0 first, then 1, etc.)\n",
    "\n",
    "# Skip if only one worker (already tested in Example 2)\n",
    "if len(enabled_workers) > 1:\n",
    "    # Initialize worker instances from all enabled configs\n",
    "    workers = []\n",
    "    for w_config in enabled_workers:\n",
    "        w = init_ras_worker(\n",
    "            \"psexec\",\n",
    "            hostname=w_config[\"hostname\"],\n",
    "            share_path=w_config[\"share_path\"],\n",
    "            credentials={\n",
    "                \"username\": w_config[\"username\"],\n",
    "                \"password\": w_config[\"password\"]\n",
    "            },\n",
    "            ras_exe_path=w_config[\"ras_exe_path\"],\n",
    "            session_id=w_config[\"session_id\"],\n",
    "            system_account=False,\n",
    "            process_priority=w_config.get(\"process_priority\", \"low\"),  # Valid: \"low\", \"below normal\", \"normal\"\n",
    "            queue_priority=w_config.get(\"queue_priority\", 0),  # 0-9, lower executes first\n",
    "            cores_total=w_config.get(\"cores_total\"),\n",
    "            cores_per_plan=w_config.get(\"cores_per_plan\", 4)\n",
    "        )\n",
    "        workers.append(w)\n",
    "        print(f\"Initialized worker: {w_config['name']} ({w_config['hostname']}) - Queue {w.queue_priority}\")\n",
    "    \n",
    "    print(f\"\\nExecuting plans across {len(workers)} worker(s)...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    results = compute_parallel_remote(\n",
    "        plan_number=[\"06\", \"19\"],  # Or use None for all plans\n",
    "        workers=workers,\n",
    "        dest_folder=\"multi_worker_results\",\n",
    "        num_cores=4,\n",
    "        clear_geompre=False,\n",
    "        overwrite_dest=True\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nTotal execution time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"\\nResults:\")\n",
    "    for plan, success in results.items():\n",
    "        print(f\"  Plan {plan}: {'SUCCESS' if success else 'FAILED'}\")\n",
    "    \n",
    "    # Calculate speedup\n",
    "    estimated_sequential = elapsed * len(workers)\n",
    "    speedup = estimated_sequential / elapsed\n",
    "    print(f\"\\nEstimated speedup: {speedup:.1f}x (with {len(workers)} workers)\")\n",
    "else:\n",
    "    print(f\"Only 1 worker configured - skipping multi-worker example\")\n",
    "    print(f\"To test parallel execution:\")\n",
    "    print(f\"  1. Add more workers to RemoteWorkers.json\")\n",
    "    print(f\"  2. Set enabled=true for each\")\n",
    "    print(f\"  3. Re-run this cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Results\n",
    "\n",
    "Check that HDF files were created and results collected properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List HDF files in results folder\n",
    "results_path = Path(baldeagle_path).parent / \"multi_worker_results\" / \"BaldEagleDamBrk\"\n",
    "\n",
    "if results_path.exists():\n",
    "    hdf_files = list(results_path.glob(\"*.hdf\"))\n",
    "    print(f\"HDF files in results folder: {len(hdf_files)}\")\n",
    "    for hdf in hdf_files:\n",
    "        size_mb = hdf.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {hdf.name}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"Results folder not found: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Configuration\n",
    "\n",
    "### Session ID Determination\n",
    "\n",
    "Find the active session ID on a remote machine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires PsExec to query remote sessions\n",
    "# First initialize a worker to get the psexec_path (will auto-detect/download)\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    temp_worker = init_ras_worker(\n",
    "        \"psexec\",\n",
    "        hostname=REMOTE_CONFIG[\"hostname\"],\n",
    "        share_path=REMOTE_CONFIG[\"share_path\"],\n",
    "        credentials={\n",
    "            \"username\": REMOTE_CONFIG[\"username\"],\n",
    "            \"password\": REMOTE_CONFIG[\"password\"]\n",
    "        },\n",
    "        ras_exe_path=REMOTE_CONFIG[\"ras_exe_path\"],\n",
    "        session_id=REMOTE_CONFIG[\"session_id\"]\n",
    "    )\n",
    "    psexec = temp_worker.psexec_path\n",
    "\n",
    "    cmd = [\n",
    "        psexec,\n",
    "        f\"\\\\\\\\{REMOTE_CONFIG['hostname']}\",\n",
    "        \"-u\", REMOTE_CONFIG[\"username\"],\n",
    "        \"-p\", REMOTE_CONFIG[\"password\"],\n",
    "        \"-accepteula\",\n",
    "        \"cmd\", \"/c\", \"query\", \"user\"\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)\n",
    "    print(\"Active sessions on remote machine:\")\n",
    "    print(result.stdout)\n",
    "    print(\"\\nLook for the ID column - typically 2 for workstations\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not query sessions: {e}\")\n",
    "    print(\"Try session_id=2 (most common for single-user workstations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Priority Levels\n",
    "\n",
    "Control OS process priority for remote HEC-RAS execution:\n",
    "\n",
    "- `\"low\"` - Low priority (recommended for background work, minimal impact on remote user)\n",
    "- `\"below normal\"` - Below normal priority\n",
    "- `\"normal\"` - Normal priority (default Windows priority)\n",
    "\n",
    "**Note:** Higher priorities (above normal, high, realtime) are NOT supported to avoid impacting remote user operations.\n",
    "\n",
    "### Queue Priority\n",
    "\n",
    "Control execution order across workers:\n",
    "\n",
    "- `queue_priority` is an integer from 0-9 (lower = higher priority)\n",
    "- Workers at queue level 0 are filled before queue level 1, etc.\n",
    "- Within each queue level, wave scheduling applies (one plan per machine first, then additional)\n",
    "- Use for tiered bursting: local workers (queue 0) execute first, then remote (queue 1), then cloud (queue 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with low process priority for background execution\n",
    "worker_low_priority = init_ras_worker(\n",
    "    \"psexec\",\n",
    "    hostname=REMOTE_CONFIG[\"hostname\"],\n",
    "    share_path=REMOTE_CONFIG[\"share_path\"],\n",
    "    credentials={\n",
    "        \"username\": REMOTE_CONFIG[\"username\"],\n",
    "        \"password\": REMOTE_CONFIG[\"password\"]\n",
    "    },\n",
    "    ras_exe_path=REMOTE_CONFIG[\"ras_exe_path\"],\n",
    "    session_id=REMOTE_CONFIG[\"session_id\"],\n",
    "    system_account=False,\n",
    "    process_priority=\"low\",  # Valid: \"low\", \"below normal\", \"normal\". Recommended: \"low\"\n",
    "    queue_priority=0  # 0-9, lower executes first\n",
    ")\n",
    "\n",
    "print(f\"Worker configured with process_priority='{worker_low_priority.process_priority}'\")\n",
    "print(f\"Worker configured with queue_priority={worker_low_priority.queue_priority}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Troubleshooting (Optional)\n",
    "\n",
    "### Test Remote Connections using psexec\n",
    "\n",
    "Change the cell below to a code cell, enter your username and password for use in testing. \n",
    "\n",
    "Don't leave your passwords here, it can get synced back to git.  Use RemoteWorkers.json, it is already in the .gitignore for this repo.  \n",
    "Use the code cell below for testing only, not as a design pattern for production usage: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test basic PsExec connectivity\n",
    "import subprocess\n",
    "\n",
    "### Get psexec path from the initialized worker\n",
    "try:\n",
    "    temp_worker = init_ras_worker(\n",
    "        \"psexec\",\n",
    "        hostname=REMOTE_CONFIG[\"hostname\"],\n",
    "        share_path=REMOTE_CONFIG[\"share_path\"],\n",
    "        credentials={\n",
    "            \"username\": REMOTE_CONFIG[\"username\"],\n",
    "            \"password\": REMOTE_CONFIG[\"password\"]\n",
    "        },\n",
    "        ras_exe_path=REMOTE_CONFIG[\"ras_exe_path\"],\n",
    "        session_id=REMOTE_CONFIG[\"session_id\"]\n",
    "    )\n",
    "    psexec_path = temp_worker.psexec_path\n",
    "\n",
    "    test_cmd = [\n",
    "        psexec_path,\n",
    "        f\"\\\\\\\\{REMOTE_CONFIG['hostname']}\",\n",
    "        \"-u\", REMOTE_CONFIG[\"username\"],\n",
    "        \"-p\", REMOTE_CONFIG[\"password\"],\n",
    "        \"-i\", str(REMOTE_CONFIG[\"session_id\"]),\n",
    "        \"-accepteula\",\n",
    "        \"cmd\", \"/c\", \"echo\", \"SUCCESS\"\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(test_cmd, capture_output=True, text=True, timeout=30)\n",
    "    if \"SUCCESS\" in result.stdout:\n",
    "        print(\"[OK] PsExec connection successful!\")\n",
    "    else:\n",
    "        print(\"[WARNING] Unexpected output:\")\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"[FAIL] Connection timeout - check firewall and services\")\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] Connection error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Share Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if share is accessible\n",
    "from pathlib import WindowsPath\n",
    "\n",
    "share_path = Path(REMOTE_CONFIG[\"share_path\"])\n",
    "\n",
    "try:\n",
    "    # This may fail without authenticated session - that's OK\n",
    "    if share_path.exists():\n",
    "        print(f\"[OK] Share accessible: {share_path}\")\n",
    "        files = list(share_path.iterdir())[:5]\n",
    "        print(f\"     Contents: {len(list(share_path.iterdir()))} items\")\n",
    "    else:\n",
    "        print(f\"[INFO] Share not accessible via Path.exists() (authentication may be required)\")\n",
    "        print(f\"      This is normal - share will be accessed during execution with credentials\")\n",
    "except Exception as e:\n",
    "    print(f\"[INFO] Cannot test share access: {e}\")\n",
    "    print(f\"      This is normal - share will be accessed during execution with credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Notes and Best Practices\n",
    "\n",
    "### Remote Worker Configuration:\n",
    "- Credentials stored in `RemoteWorkers.json` (not committed to git)\n",
    "- See **REMOTE_WORKERS_README.md** for JSON format and setup\n",
    "- Template provided: `RemoteWorkers.json.template`\n",
    "\n",
    "### Remote Worker Requirements:\n",
    "1. ✅ Network share created and accessible\n",
    "2. ✅ User in local Administrators group\n",
    "3. ✅ Group Policy: User added to network access, local logon, batch job policies\n",
    "4. ✅ Registry: LocalAccountTokenFilterPolicy = 1\n",
    "5. ✅ Remote Registry service running\n",
    "6. ✅ Windows Firewall configured\n",
    "7. ✅ Machine rebooted after changes\n",
    "\n",
    "### Session ID:\n",
    "- Session ID 2 is typical for single-user workstations\n",
    "- Use `query user` on remote machine to verify\n",
    "- User must be logged in for session to be active\n",
    "- Session ID can change if user logs off/on\n",
    "\n",
    "### HEC-RAS Considerations:\n",
    "- HEC-RAS is a GUI application\n",
    "- MUST use session-based execution (`system_account=False`)\n",
    "- NEVER use SYSTEM account (`system_account=True`) for HEC-RAS\n",
    "- HEC-RAS window will start on the desktop of the remote desktop\n",
    "- Ensure HEC-RAS version matches on all workers, and TOS has been accepted.\n",
    "\n",
    "### Performance:\n",
    "- Network share speed affects file transfer\n",
    "- Use Gigabit Ethernet for best performance\n",
    "- 2-4 workers per machine optimal (depends on cores/RAM)\n",
    "- Plans execute sequentially on each worker\n",
    "- Multiple workers enable true parallel execution\n",
    "\n",
    "### Security:\n",
    "- Credentials in `RemoteWorkers.json` (in .gitignore)\n",
    "- Never commit credentials to git\n",
    "- See setup instructions for required group policy and registry changes\n",
    "\n",
    "### Debugging:\n",
    "- Check logs in ras_commander.log\n",
    "- Inspect compute messages: `project.p##.computeMsgs.txt`\n",
    "- Verify temp folders on remote share\n",
    "- Test PsExec manually with provided batch files\n",
    "\n",
    "---\n",
    "\n",
    "**For complete setup instructions, see:**\n",
    "- `feature_dev_notes/RasRemote/REMOTE_WORKER_SETUP_GUIDE.md` - Remote machine setup\n",
    "- `REMOTE_WORKERS_README.md` - JSON credential file format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rascmdr_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
