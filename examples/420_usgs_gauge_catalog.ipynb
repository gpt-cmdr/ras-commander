{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 33: USGS Gauge Catalog Generation\n",
        "\n",
        "This notebook demonstrates how to generate and use a standardized USGS gauge data catalog for your HEC-RAS project.\n",
        "\n",
        "## Purpose\n",
        "\n",
        "The gauge catalog generation function creates a standardized \"USGS Gauge Data\" folder (similar to the precipitation module's storm catalog) that:\n",
        "- Discovers all active USGS gauges within project extent\n",
        "- Downloads historical data for each gauge\n",
        "- Creates master catalog for easy gauge discovery\n",
        "- Provides standard location for engineering review and downstream functions\n",
        "\n",
        "## Key Functions\n",
        "\n",
        "- `generate_gauge_catalog()`: Create complete gauge catalog with metadata and data\n",
        "- `load_gauge_catalog()`: Load gauge catalog from standard location\n",
        "- `load_gauge_data()`: Load historical data for specific gauge\n",
        "- `get_gauge_folder()`: Get path to gauge folder\n",
        "- `update_gauge_catalog()`: Refresh catalog with latest data\n",
        "\n",
        "## Example Project\n",
        "\n",
        "We'll use the **Bald Eagle Creek** example project which has 2 active USGS gauges:\n",
        "- USGS-01547200: Upstream gauge (265 sq mi drainage)\n",
        "- USGS-01548005: Downstream gauge (562 sq mi drainage)\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "Requires: `pip install dataretrieval geopandas tqdm`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Add parent directory to path for development\n",
        "try:\n",
        "    from ras_commander import init_ras_project, ras, RasExamples\n",
        "    from ras_commander.usgs import (\n",
        "        generate_gauge_catalog,\n",
        "        load_gauge_catalog,\n",
        "        load_gauge_data,\n",
        "        get_gauge_folder,\n",
        "        update_gauge_catalog\n",
        "    )\n",
        "except ImportError:\n",
        "    current_file = Path().resolve()\n",
        "    parent_directory = current_file.parent\n",
        "    sys.path.append(str(parent_directory))\n",
        "    from ras_commander import init_ras_project, ras, RasExamples\n",
        "    from ras_commander.usgs import (\n",
        "        generate_gauge_catalog,\n",
        "        load_gauge_catalog,\n",
        "        load_gauge_data,\n",
        "        get_gauge_folder,\n",
        "        update_gauge_catalog\n",
        "    )\n",
        "\n",
        "print(\"✓ Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extract Example Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Found zip file: C:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n",
            "2025-12-13 23:14:33 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to c:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\n",
            "2025-12-13 23:14:33 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project extracted to: c:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\n",
            "\n",
            "Project: BaldEagle\n",
            "Path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\n",
            "\n",
            "Project initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Extract Bald Eagle Creek project\n",
        "project_path = RasExamples.extract_project(\"Balde Eagle Creek\", output_path=\"example_projects_420_usgs_gauge_catalog\")\n",
        "\n",
        "print(f\"Project extracted to: {project_path}\")\n",
        "\n",
        "# Initialize project\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "print(f\"\\nProject: {ras.project_name}\")\n",
        "print(f\"Path: {ras.project_folder}\")\n",
        "print(f\"\\nProject initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Gauge Catalog\n",
        "\n",
        "This will:\n",
        "1. Find all USGS gauges within 50% buffer of project extent\n",
        "2. Download 10 years of historical data (flow and stage)\n",
        "3. Create standardized folder structure\n",
        "4. Generate master catalog and documentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-13 23:14:33 - ras_commander.usgs.catalog - INFO - Generating USGS gauge catalog for project: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\n",
            "2025-12-13 23:14:33 - ras_commander.usgs.catalog - INFO - Output folder: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\USGS Gauge Data\n",
            "2025-12-13 23:14:33 - ras_commander.usgs.catalog - INFO - Buffer: 50.0%, Historical years: 10\n",
            "2025-12-13 23:14:33 - ras_commander.usgs.catalog - INFO - Step 1/7: Finding gauges in project extent...\n",
            "2025-12-13 23:14:33 - ras_commander.usgs.spatial - INFO - Retrieving project bounds from: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Found 178 cross sections\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfXsec - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfXsec - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - CRITICAL - No valid projection found. Checked:\n",
            "1. HDF file projection attribute: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            " was checked and no projection attribute found2. No RASMapper projection file found\n",
            "To fix this:\n",
            "1. Open RASMapper\n",
            "2. Click Map > Set Projection\n",
            "3. Select an appropriate projection file or coordinate system\n",
            "4. Save the RASMapper project\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfXsec - INFO - Extracted 1 river centerlines\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Found 1 river centerlines\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfBase - CRITICAL - No valid projection found. Checked:\n",
            "1. HDF file projection attribute: C:\\GH\\ras-commander\\examples\\example_projects_420_usgs_gauge_catalog\\Balde Eagle Creek\\BaldEagle.g01.hdf\n",
            " was checked and no projection attribute found2. No RASMapper projection file found\n",
            "To fix this:\n",
            "1. Open RASMapper\n",
            "2. Click Map > Set Projection\n",
            "3. Select an appropriate projection file or coordinate system\n",
            "4. Save the RASMapper project\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Original extent: (1967609.38, 288126.34, 2065322.25, 353446.47)\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - Buffered extent (50.0% x, 50.0% y): (1943181.16, 271796.31, 2089750.47, 369776.50)\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - No CRS in HDF file, using provided project_crs: EPSG:2271\n",
            "2025-12-13 23:14:33 - ras_commander.hdf.HdfProject - INFO - WGS84 bounds: W=-77.841980, S=40.911801, E=-77.309518, N=41.181529\n",
            "2025-12-13 23:14:33 - ras_commander.usgs.spatial - INFO - Querying USGS gauges in bounds: W=-77.841980, S=40.911801, E=-77.309518, N=41.181529\n",
            "2025-12-13 23:14:33 - dataretrieval.waterdata.utils - INFO - Requesting: https://api.waterdata.usgs.gov/ogcapi/v0/collections/monitoring-locations/items?skipGeometry=False&limit=10000&bbox=-77.84197980123724%2C40.911800921758946%2C-77.30951761463129%2C41.18152865157271\n",
            "2025-12-13 23:14:34 - ras_commander.usgs.spatial - INFO - Found 446 USGS gauges\n",
            "2025-12-13 23:14:34 - ras_commander.usgs.spatial - ERROR - Failed to create GeoDataFrame: 'dec_long_va'\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "No USGS gauges found within 50.0% buffer of project extent. Try increasing buffer_percent parameter.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Note: Bald Eagle Creek project doesn't have embedded CRS, so we specify it manually\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# The project uses PA State Plane North (US feet) - EPSG:2271\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m summary = \u001b[43mgenerate_gauge_catalog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer_percent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Search within 50% buffer of project extent\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_historical\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Download historical data\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistorical_years\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Last 10 years of data\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mflow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Retrieve flow and stage data\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_crs\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEPSG:2271\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# PA State Plane North (US feet) - required for Bald Eagle\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Display summary\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\GH\\ras-commander\\ras_commander\\usgs\\catalog.py:187\u001b[39m, in \u001b[36mgenerate_gauge_catalog\u001b[39m\u001b[34m(ras_object, buffer_percent, include_historical, historical_years, output_folder, parameters, rate_limit_rps, project_crs)\u001b[39m\n\u001b[32m    180\u001b[39m gauges_df = UsgsGaugeSpatial.find_gauges_in_project(\n\u001b[32m    181\u001b[39m     hdf_path=geom_hdf_path,\n\u001b[32m    182\u001b[39m     buffer_percent=buffer_percent,\n\u001b[32m    183\u001b[39m     project_crs=project_crs\n\u001b[32m    184\u001b[39m )\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gauges_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(gauges_df) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    188\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo USGS gauges found within \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuffer_percent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% buffer of project extent. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTry increasing buffer_percent parameter.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m     )\n\u001b[32m    192\u001b[39m gauge_count = \u001b[38;5;28mlen\u001b[39m(gauges_df)\n\u001b[32m    193\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgauge_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m gauges in project extent\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mValueError\u001b[39m: No USGS gauges found within 50.0% buffer of project extent. Try increasing buffer_percent parameter."
          ]
        }
      ],
      "source": [
        "# Note: Bald Eagle Creek project doesn't have embedded CRS, so we specify it manually\n",
        "# The project uses PA State Plane North (US feet) - EPSG:2271\n",
        "summary = generate_gauge_catalog(\n",
        "    buffer_percent=50.0,         # Search within 50% buffer of project extent\n",
        "    include_historical=True,     # Download historical data\n",
        "    historical_years=10,         # Last 10 years of data\n",
        "    parameters=['flow', 'stage'], # Retrieve flow and stage data\n",
        "    project_crs=\"EPSG:2271\"      # PA State Plane North (US feet) - required for Bald Eagle\n",
        ")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GAUGE CATALOG GENERATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Gauges found: {summary['gauge_count']}\")\n",
        "print(f\"Successfully processed: {summary['gauges_processed']}\")\n",
        "print(f\"Failed: {summary['gauges_failed']}\")\n",
        "print(f\"Output folder: {summary['output_folder']}\")\n",
        "print(f\"Data size: {summary['data_size_mb']:.2f} MB\")\n",
        "print(f\"Processing time: {summary['processing_time_sec']:.1f} seconds\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Explore Catalog Structure\n",
        "\n",
        "The catalog creates a standardized folder structure:\n",
        "\n",
        "```\n",
        "project_folder/\n",
        "├── USGS Gauge Data/\n",
        "│   ├── gauge_catalog.csv          # Master catalog\n",
        "│   ├── gauge_locations.geojson    # Spatial data\n",
        "│   ├── README.md                  # Documentation\n",
        "│   ├── USGS-01547200/             # Individual gauge folders\n",
        "│   │   ├── metadata.json\n",
        "│   │   ├── historical_flow.csv\n",
        "│   │   ├── historical_stage.csv\n",
        "│   │   └── data_availability.json\n",
        "│   └── USGS-01548005/\n",
        "│       └── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List files in catalog folder\n",
        "catalog_folder = Path(ras.project_path) / \"USGS Gauge Data\"\n",
        "\n",
        "print(\"Catalog folder contents:\")\n",
        "print(\"\\nTop-level files:\")\n",
        "for file in sorted(catalog_folder.glob('*')):\n",
        "    if file.is_file():\n",
        "        size_kb = file.stat().st_size / 1024\n",
        "        print(f\"  {file.name:30s} ({size_kb:8.1f} KB)\")\n",
        "\n",
        "print(\"\\nGauge folders:\")\n",
        "for folder in sorted(catalog_folder.glob('USGS-*')):\n",
        "    if folder.is_dir():\n",
        "        file_count = len(list(folder.glob('*')))\n",
        "        print(f\"  {folder.name:30s} ({file_count} files)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Load and Explore Master Catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load catalog using helper function\n",
        "catalog = load_gauge_catalog()\n",
        "\n",
        "print(f\"Loaded catalog with {len(catalog)} gauges\\n\")\n",
        "\n",
        "# Display key information\n",
        "print(\"Gauge Catalog:\")\n",
        "print(\"-\" * 120)\n",
        "display_cols = ['site_id', 'station_name', 'drainage_area_sqmi', 'upstream_downstream', \n",
        "                'distance_to_project_km', 'parameters_available']\n",
        "print(catalog[display_cols].to_string(index=False))\n",
        "print(\"-\" * 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Gauge Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metadata for first gauge\n",
        "site_id = catalog.iloc[0]['site_id']\n",
        "gauge_folder = get_gauge_folder(site_id)\n",
        "metadata_file = gauge_folder / \"metadata.json\"\n",
        "\n",
        "with open(metadata_file, 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "print(f\"Metadata for USGS-{site_id}:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Station: {metadata['station_name']}\")\n",
        "print(f\"Location: {metadata['location']['latitude']:.4f}, {metadata['location']['longitude']:.4f}\")\n",
        "print(f\"State: {metadata['location']['state']}\")\n",
        "print(f\"County: {metadata['location']['county']}\")\n",
        "print(f\"Drainage Area: {metadata['drainage_area_sqmi']} sq mi\")\n",
        "print(f\"Gage Datum: {metadata['gage_datum_ft']} ft\")\n",
        "print(f\"Active: {metadata['active']}\")\n",
        "print(f\"\\nAvailable Parameters: {', '.join(metadata['available_parameters'])}\")\n",
        "print(f\"\\nPeriod of Record:\")\n",
        "print(f\"  Start: {metadata['period_of_record']['start']}\")\n",
        "print(f\"  End: {metadata['period_of_record']['end']}\")\n",
        "print(f\"  Years: {metadata['period_of_record']['years']}\")\n",
        "print(f\"\\nLast Updated: {metadata['last_updated']}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Load Data Availability Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data availability for first gauge\n",
        "availability_file = gauge_folder / \"data_availability.json\"\n",
        "\n",
        "with open(availability_file, 'r') as f:\n",
        "    availability = json.load(f)\n",
        "\n",
        "print(f\"Data Availability for USGS-{site_id}:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for param, info in availability.items():\n",
        "    print(f\"\\n{param.upper()}:\")\n",
        "    print(f\"  Available: {info['available']}\")\n",
        "    if info['available']:\n",
        "        print(f\"  Date Range: {info['start_date']} to {info['end_date']}\")\n",
        "        print(f\"  Record Count: {info['record_count']:,}\")\n",
        "        print(f\"  Completeness: {info['completeness']*100:.1f}%\")\n",
        "        if info['gaps']:\n",
        "            print(f\"  Gaps Found: {len(info['gaps'])}\")\n",
        "            for gap in info['gaps'][:3]:  # Show first 3 gaps\n",
        "                print(f\"    - {gap['start']} to {gap['end']} ({gap['days']} days)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Load Historical Data Using Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load flow data for first gauge\n",
        "flow_data = load_gauge_data(site_id, parameter='flow')\n",
        "\n",
        "print(f\"Flow Data for USGS-{site_id}:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Records: {len(flow_data):,}\")\n",
        "print(f\"Date Range: {flow_data['datetime'].min()} to {flow_data['datetime'].max()}\")\n",
        "print(f\"\\nFlow Statistics:\")\n",
        "print(f\"  Mean: {flow_data['value'].mean():.1f} cfs\")\n",
        "print(f\"  Median: {flow_data['value'].median():.1f} cfs\")\n",
        "print(f\"  Min: {flow_data['value'].min():.1f} cfs\")\n",
        "print(f\"  Max: {flow_data['value'].max():.1f} cfs\")\n",
        "print(f\"\\nFirst 5 records:\")\n",
        "print(flow_data.head())\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load stage data\n",
        "stage_data = load_gauge_data(site_id, parameter='stage')\n",
        "\n",
        "print(f\"Stage Data for USGS-{site_id}:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Records: {len(stage_data):,}\")\n",
        "print(f\"Date Range: {stage_data['datetime'].min()} to {stage_data['datetime'].max()}\")\n",
        "print(f\"\\nStage Statistics:\")\n",
        "print(f\"  Mean: {stage_data['value'].mean():.2f} ft\")\n",
        "print(f\"  Median: {stage_data['value'].median():.2f} ft\")\n",
        "print(f\"  Min: {stage_data['value'].min():.2f} ft\")\n",
        "print(f\"  Max: {stage_data['value'].max():.2f} ft\")\n",
        "print(f\"\\nFirst 5 records:\")\n",
        "print(stage_data.head())\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Plot Historical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Create figure with 2 subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
        "\n",
        "# Plot flow\n",
        "ax1.plot(flow_data['datetime'], flow_data['value'], 'b-', linewidth=0.8, alpha=0.7)\n",
        "ax1.set_ylabel('Flow (cfs)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title(f\"USGS-{site_id}: {metadata['station_name']}\", fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(bottom=0)\n",
        "\n",
        "# Plot stage\n",
        "ax2.plot(stage_data['datetime'], stage_data['value'], 'g-', linewidth=0.8, alpha=0.7)\n",
        "ax2.set_ylabel('Stage (ft)', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim(bottom=0)\n",
        "\n",
        "# Format x-axis\n",
        "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "ax2.xaxis.set_major_locator(mdates.YearLocator())\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nPlot shows 10 years of flow and stage data for USGS-{site_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Process All Gauges in Catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for all gauges\n",
        "print(\"Summary for all gauges:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx, gauge in catalog.iterrows():\n",
        "    site_id = gauge['site_id']\n",
        "    name = gauge['station_name']\n",
        "    drainage = gauge['drainage_area_sqmi']\n",
        "    position = gauge['upstream_downstream']\n",
        "    distance = gauge['distance_to_project_km']\n",
        "    \n",
        "    print(f\"\\nUSGS-{site_id}: {name}\")\n",
        "    print(f\"  Position: {position.title()} ({distance:.1f} km from project)\")\n",
        "    print(f\"  Drainage: {drainage} sq mi\")\n",
        "    \n",
        "    # Check if flow data file exists before loading\n",
        "    gauge_folder = get_gauge_folder(site_id)\n",
        "    flow_file = gauge_folder / \"historical_flow.csv\"\n",
        "    \n",
        "    if flow_file.exists():\n",
        "        flow = load_gauge_data(site_id, parameter='flow')\n",
        "        print(f\"  Flow: {len(flow):,} records, mean={flow['value'].mean():.0f} cfs, max={flow['value'].max():.0f} cfs\")\n",
        "    else:\n",
        "        print(f\"  Flow: No data available\")\n",
        "    \n",
        "    # Check if stage data file exists before loading\n",
        "    stage_file = gauge_folder / \"historical_stage.csv\"\n",
        "    \n",
        "    if stage_file.exists():\n",
        "        stage = load_gauge_data(site_id, parameter='stage')\n",
        "        print(f\"  Stage: {len(stage):,} records, mean={stage['value'].mean():.2f} ft, max={stage['value'].max():.2f} ft\")\n",
        "    else:\n",
        "        print(f\"  Stage: No data available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Use Catalog Data for Boundary Conditions\n",
        "\n",
        "The catalog data can be easily used with other USGS functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ras_commander.usgs import generate_flow_hydrograph_table\n",
        "\n",
        "# Select upstream gauge for BC generation\n",
        "upstream_gauge = catalog[catalog['upstream_downstream'] == 'upstream'].iloc[0]\n",
        "site_id = upstream_gauge['site_id']\n",
        "\n",
        "print(f\"Using USGS-{site_id} for boundary condition:\")\n",
        "print(f\"  Station: {upstream_gauge['station_name']}\")\n",
        "print(f\"  Drainage: {upstream_gauge['drainage_area_sqmi']} sq mi\\n\")\n",
        "\n",
        "# Load flow data\n",
        "flow = load_gauge_data(site_id, parameter='flow')\n",
        "\n",
        "# Get last 7 days (168 hours)\n",
        "recent_flow = flow.tail(168).copy()\n",
        "\n",
        "print(f\"Using last {len(recent_flow)} hourly values for BC\")\n",
        "print(f\"Date range: {recent_flow['datetime'].min()} to {recent_flow['datetime'].max()}\")\n",
        "print(f\"Flow range: {recent_flow['value'].min():.0f} to {recent_flow['value'].max():.0f} cfs\\n\")\n",
        "\n",
        "# Generate HEC-RAS format hydrograph table\n",
        "bc_table = generate_flow_hydrograph_table(\n",
        "    flow_values=recent_flow['value'],\n",
        "    interval='1HOUR'\n",
        ")\n",
        "\n",
        "print(\"Generated boundary condition table:\")\n",
        "print(bc_table[:500])  # Show first 500 characters\n",
        "print(f\"\\n... ({len(bc_table)} characters total)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Update Catalog (Add New Data)\n",
        "\n",
        "The `update_gauge_catalog()` function refreshes existing gauges with new data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update catalog with latest data (last 30 days)\n",
        "update_summary = update_gauge_catalog()\n",
        "\n",
        "print(\"\\nCatalog Update Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Gauges updated: {update_summary['gauges_updated']}\")\n",
        "print(f\"Gauges failed: {update_summary['gauges_failed']}\")\n",
        "print(f\"Processing time: {update_summary['processing_time_sec']:.1f} seconds\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Custom Catalog Configuration\n",
        "\n",
        "You can customize the catalog generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Generate catalog with custom settings\n",
        "# (Don't run this cell if you want to keep existing catalog)\n",
        "\n",
        "if False:  # Set to True to run\n",
        "    custom_summary = generate_gauge_catalog(\n",
        "        buffer_percent=100.0,        # Wider search area (2x project extent)\n",
        "        include_historical=True,\n",
        "        historical_years=20,         # More historical data\n",
        "        parameters=['flow', 'stage', 'temperature'],  # Additional parameters\n",
        "        output_folder=None           # Use default location\n",
        "    )\n",
        "    \n",
        "    print(\"Custom catalog generated:\")\n",
        "    print(f\"  Gauges: {custom_summary['gauge_count']}\")\n",
        "    print(f\"  Data size: {custom_summary['data_size_mb']:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. ✅ **Catalog Generation**: One-command gauge discovery and data download\n",
        "2. ✅ **Standard Structure**: Consistent folder organization across projects\n",
        "3. ✅ **Metadata Management**: Complete gauge information in JSON format\n",
        "4. ✅ **Data Loading**: Easy access to historical gauge data\n",
        "5. ✅ **Integration**: Seamless use with boundary condition generation\n",
        "6. ✅ **Updates**: Refresh catalog with latest data\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "- **Standard Location**: `project_folder/USGS Gauge Data/` (like precipitation module)\n",
        "- **One Command**: `generate_gauge_catalog()` does everything\n",
        "- **Engineering Review**: Master catalog CSV for easy gauge assessment\n",
        "- **Downstream Functions**: Standard location for automated workflows\n",
        "- **Documentation**: Auto-generated README with usage instructions\n",
        "\n",
        "## Related Examples\n",
        "\n",
        "- Example 29: USGS Gauge Data Integration (basic retrieval)\n",
        "- Example 30: Real-Time Monitoring (live gauge data)\n",
        "- Example 31: BC Generation from Live Gauge (boundary conditions)\n",
        "- Example 32: Model Validation with USGS (calibration metrics)\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "With the catalog generated, you can:\n",
        "- Review all available gauges in one location\n",
        "- Use gauge data for boundary condition generation\n",
        "- Perform model validation with observed data\n",
        "- Include catalog in project deliverables for documentation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
