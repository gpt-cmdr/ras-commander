{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 32: Model Validation with USGS Gauge Data\n",
    "\n",
    "This example demonstrates how to validate HEC-RAS model results against observed USGS gauge data. We'll compare modeled flows from the Bald Eagle Creek model to observed data from a downstream gauge and calculate comprehensive validation metrics.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Run HEC-RAS model** (or use existing results)\n",
    "2. **Extract modeled timeseries** at location near gauge\n",
    "3. **Query observed USGS data** from downstream gauge\n",
    "4. **Align timeseries** for direct comparison\n",
    "5. **Calculate validation metrics** (NSE, KGE, peak error, RMSE, bias)\n",
    "6. **Create comparison plots** (timeseries, scatter, residuals)\n",
    "7. **Assess model performance** and identify calibration needs\n",
    "\n",
    "## Use Case: Model Performance Assessment\n",
    "\n",
    "This workflow enables:\n",
    "- Quantitative model performance evaluation\n",
    "- Identification of systematic biases\n",
    "- Guidance for calibration efforts\n",
    "- Reporting model accuracy for stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEVELOPMENT MODE TOGGLE\n# =============================================================================\nUSE_LOCAL_SOURCE = False  # <-- TOGGLE THIS\n\nif USE_LOCAL_SOURCE:\n    import sys\n    from pathlib import Path\n    local_path = str(Path.cwd().parent)\n    if local_path not in sys.path:\n        sys.path.insert(0, local_path)\n    print(f\"ðŸ“ LOCAL SOURCE MODE: Loading from {local_path}/ras_commander\")\nelse:\n    print(\"ðŸ“¦ PIP PACKAGE MODE: Loading installed ras-commander\")\n\n# Import ras-commander\nfrom ras_commander import init_ras_project, RasExamples, ras, RasCmdr\nfrom ras_commander.hdf import HdfResultsPlan\nfrom ras_commander.usgs import (\n    get_gauge_metadata,\n    retrieve_flow_data,\n    align_timeseries\n)\nfrom ras_commander.usgs.metrics import (\n    nash_sutcliffe_efficiency,\n    kling_gupta_efficiency,\n    calculate_peak_error,\n    calculate_all_metrics\n)\nfrom ras_commander.usgs.visualization import (\n    plot_timeseries_comparison,\n    plot_scatter_comparison,\n    plot_residuals\n)\n\n# Additional imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\n# Verify which version loaded\nimport ras_commander\nprint(f\"âœ“ Loaded: {ras_commander.__file__}\")\nprint(\"âœ“ Imports successful\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Configure these values to customize the notebook for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETERS - Edit these to customize the notebook\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Project Configuration\n",
    "PROJECT_NAME = \"Muncie\"           # Example project to extract\n",
    "RAS_VERSION = \"6.6\"               # HEC-RAS version (6.3, 6.5, 6.6, etc.)\n",
    "\n",
    "# Output Configuration\n",
    "OUTPUTS_DIR = Path(\"_outputs\") / \"914_model_validation_with_usgs\"  # Artifacts saved here\n",
    "\n",
    "# USGS Configuration\n",
    "USGS_SITE = \"01547200\"            # USGS gauge site number\n",
    "START_DATE = \"2020-01-01\"         # Data start date\n",
    "END_DATE = \"2020-12-31\"           # Data end date\n",
    "ONLINE = True                     # Enable network requests\n",
    "\n",
    "# Create output directory\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Outputs will be saved to: {OUTPUTS_DIR.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Project and Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and initialize Bald Eagle Creek project\n",
    "print(\"Extracting Bald Eagle Creek project...\")\n",
    "project_paths = RasExamples.extract_project([\"Balde Eagle Creek\", \"BaldEagleCrkMulti2D\"], output_path=OUTPUTS_DIR.parent / \"example_projects\")\n",
    "project_path = project_paths[0]  # Use 1D model\n",
    "print(f\"Using: {project_path}\\n\")\n",
    "\n",
    "init_ras_project(project_path, RAS_VERSION)\n",
    "print(f\"Project initialized: {ras.project_folder}\")\n",
    "print(f\"Plans: {len(ras.plan_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if results exist\n",
    "plan_df = ras.plan_df\n",
    "plan_01 = plan_df[plan_df['plan_number'] == '01'].iloc[0]\n",
    "\n",
    "results_path = plan_01.get('results_path') or plan_01.get('hdf_path')\n",
    "has_results = Path(results_path).exists() if results_path else False\n",
    "\n",
    "print(f\"\\nPlan 01 Results:\")\n",
    "print(f\"  Results file: {Path(results_path).name if results_path else 'Not found'}\")\n",
    "print(f\"  Exists: {has_results}\")\n",
    "\n",
    "if not has_results:\n",
    "    print(f\"\\nâš  No results found - will run model first\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ Results exist - can proceed with validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model if results don't exist\n",
    "if not has_results:\n",
    "    print(\"Running HEC-RAS Plan 01...\")\n",
    "    print(\"This may take several minutes...\\n\")\n",
    "    \n",
    "    try:\n",
    "        RasCmdr.compute_plan(\n",
    "            plan_number='01',\n",
    "            ras_object=ras,\n",
    "            num_cores=8\n",
    "        )\n",
    "        print(\"\\nâœ“ Model execution complete\")\n",
    "        \n",
    "        # Reinitialize to load new results\n",
    "        init_ras_project(project_path, RAS_VERSION)\n",
    "        plan_01 = ras.plan_df[ras.plan_df['plan_number'] == '01'].iloc[0]\n",
    "        results_path = plan_01.get('results_path') or plan_01.get('hdf_path')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâœ— Error running model: {e}\")\n",
    "        print(\"This example requires HEC-RAS to be installed.\")\n",
    "        results_path = None\n",
    "else:\n",
    "    print(\"Using existing model results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Modeled Timeseries\n",
    "\n",
    "We'll extract modeled flow at a cross section near the downstream gauge location.\n",
    "\n",
    "**Validation Gauge:** USGS-01548005 (Bald Eagle Creek near Beech Creek Station)\n",
    "- Location: ~10 miles downstream of Lock Haven\n",
    "- Drainage: 562 sq mi\n",
    "- Model XS: We'll use a cross section in the downstream reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open results HDF\n",
    "if results_path and Path(results_path).exists():\n",
    "    print(f\"Opening results: {Path(results_path).name}\")\n",
    "    hdf = HdfResultsPlan(results_path)\n",
    "    \n",
    "    # Get available cross sections\n",
    "    xs_list = hdf.get_cross_section_list()\n",
    "    print(f\"\\nAvailable cross sections: {len(xs_list)}\")\n",
    "    print(f\"River stations range: {xs_list[0]} to {xs_list[-1]}\")\n",
    "    \n",
    "    # Select a downstream cross section near the gauge\n",
    "    # USGS-01548005 is ~10 miles downstream, likely around river station 80000-90000\n",
    "    target_station = 81500  # Near the gate structure, downstream location\n",
    "    \n",
    "    # Find closest cross section\n",
    "    closest_xs = min(xs_list, key=lambda x: abs(float(x) - target_station))\n",
    "    \n",
    "    print(f\"\\nValidation location:\")\n",
    "    print(f\"  Target station: {target_station}\")\n",
    "    print(f\"  Closest XS: {closest_xs}\")\n",
    "    print(f\"  This is downstream of Lock Haven, near USGS-01548005\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot extract modeled data - no results available\")\n",
    "    closest_xs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract modeled flow timeseries\n",
    "if closest_xs:\n",
    "    print(f\"Extracting modeled flow at XS {closest_xs}...\")\n",
    "    \n",
    "    # Get flow timeseries\n",
    "    flow_ts = hdf.get_timeseries(\n",
    "        river='Bald Eagle',\n",
    "        reach='Loc Hav',\n",
    "        rs=closest_xs,\n",
    "        variable='Flow'\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    modeled_df = pd.DataFrame({\n",
    "        'datetime': flow_ts['datetime'],\n",
    "        'value': flow_ts['values']\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nModeled flow statistics:\")\n",
    "    print(f\"  Records: {len(modeled_df)}\")\n",
    "    print(f\"  Time range: {modeled_df['datetime'].min()} to {modeled_df['datetime'].max()}\")\n",
    "    print(f\"  Mean flow: {modeled_df['value'].mean():.1f} cfs\")\n",
    "    print(f\"  Peak flow: {modeled_df['value'].max():.1f} cfs\")\n",
    "    print(f\"  Min flow: {modeled_df['value'].min():.1f} cfs\")\n",
    "else:\n",
    "    print(\"Cannot extract modeled timeseries - no results\")\n",
    "    modeled_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Observed USGS Data\n",
    "\n",
    "Retrieve observed flow data from the downstream gauge for the same time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauge configuration\n",
    "downstream_gauge = \"01548005\"  # Bald Eagle Creek near Beech Creek Station\n",
    "\n",
    "print(f\"Querying USGS-{downstream_gauge}...\")\n",
    "try:\n",
    "    metadata = get_gauge_metadata(downstream_gauge)\n",
    "    print(f\"\\nGauge: USGS-{downstream_gauge}\")\n",
    "    print(f\"Name: {metadata['station_name']}\")\n",
    "    print(f\"Location: ({metadata['latitude']:.4f}, {metadata['longitude']:.4f})\")\n",
    "    print(f\"Drainage Area: {metadata['drainage_area_sqmi']} sq mi\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Metadata query had issues: {e}\")\n",
    "    print(f\"Using known values: USGS-{downstream_gauge}, Beech Creek Station, PA, 562 sq mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get simulation period from model\n",
    "if modeled_df is not None:\n",
    "    start_date = modeled_df['datetime'].min()\n",
    "    end_date = modeled_df['datetime'].max()\n",
    "    \n",
    "    print(f\"\\nQuerying observed data for model period:\")\n",
    "    print(f\"  Start: {start_date}\")\n",
    "    print(f\"  End: {end_date}\")\n",
    "    \n",
    "    # Retrieve observed data\n",
    "    observed_df = retrieve_flow_data(\n",
    "        site_id=downstream_gauge,\n",
    "        start_date=start_date.strftime('%Y-%m-%d'),\n",
    "        end_date=end_date.strftime('%Y-%m-%d'),\n",
    "        interval='instantaneous'  # Hourly data\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nObserved flow statistics:\")\n",
    "    print(f\"  Records: {len(observed_df)}\")\n",
    "    print(f\"  Time range: {observed_df['datetime'].min()} to {observed_df['datetime'].max()}\")\n",
    "    print(f\"  Mean flow: {observed_df['value'].mean():.1f} cfs\")\n",
    "    print(f\"  Peak flow: {observed_df['value'].max():.1f} cfs\")\n",
    "    print(f\"  Min flow: {observed_df['value'].min():.1f} cfs\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot query observed data - no model results\")\n",
    "    observed_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Align Timeseries for Comparison\n",
    "\n",
    "Synchronize modeled and observed data to matching timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align timeseries\n",
    "if modeled_df is not None and observed_df is not None:\n",
    "    print(\"Aligning modeled and observed timeseries...\")\n",
    "    \n",
    "    aligned_df = align_timeseries(\n",
    "        modeled=modeled_df,\n",
    "        observed=observed_df,\n",
    "        tolerance_minutes=30  # Allow 30-minute tolerance for timestamp matching\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAligned timeseries:\")\n",
    "    print(f\"  Matched records: {len(aligned_df)}\")\n",
    "    print(f\"  Time range: {aligned_df['datetime'].min()} to {aligned_df['datetime'].max()}\")\n",
    "    print(f\"  Data completeness: {len(aligned_df) / len(modeled_df) * 100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nAligned statistics:\")\n",
    "    print(f\"  Modeled mean: {aligned_df['modeled'].mean():.1f} cfs\")\n",
    "    print(f\"  Observed mean: {aligned_df['observed'].mean():.1f} cfs\")\n",
    "    print(f\"  Difference: {aligned_df['modeled'].mean() - aligned_df['observed'].mean():.1f} cfs\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot align timeseries - missing data\")\n",
    "    aligned_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Validation Metrics\n",
    "\n",
    "Compute comprehensive performance metrics for model assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all validation metrics\n",
    "if aligned_df is not None and len(aligned_df) > 0:\n",
    "    print(\"Calculating validation metrics...\\n\")\n",
    "    \n",
    "    metrics = calculate_all_metrics(\n",
    "        observed=aligned_df['observed'].values,\n",
    "        modeled=aligned_df['modeled'].values\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"MODEL PERFORMANCE METRICS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"  Nash-Sutcliffe Efficiency (NSE): {metrics['nse']:.3f}\")\n",
    "    print(f\"    Interpretation: {_interpret_nse(metrics['nse'])}\")\n",
    "    print(f\"  Kling-Gupta Efficiency (KGE): {metrics['kge']:.3f}\")\n",
    "    print(f\"    Components: r={metrics['kge_components']['correlation']:.3f}, \"\n",
    "          f\"Î²={metrics['kge_components']['bias_ratio']:.3f}, \"\n",
    "          f\"Î³={metrics['kge_components']['variability_ratio']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nError Metrics:\")\n",
    "    print(f\"  Root Mean Square Error (RMSE): {metrics['rmse']:.1f} cfs\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {metrics['mae']:.1f} cfs\")\n",
    "    print(f\"  Mean Bias: {metrics['bias']:.1f} cfs\")\n",
    "    print(f\"    Model {'overestimates' if metrics['bias'] > 0 else 'underestimates'} by {abs(metrics['bias']):.1f} cfs on average\")\n",
    "    \n",
    "    print(f\"\\nPeak Flow Analysis:\")\n",
    "    peak_metrics = calculate_peak_error(\n",
    "        observed=aligned_df['observed'].values,\n",
    "        modeled=aligned_df['modeled'].values,\n",
    "        timestamps=aligned_df['datetime'].values\n",
    "    )\n",
    "    print(f\"  Observed peak: {peak_metrics['observed_peak']:.1f} cfs at {peak_metrics['observed_peak_time']}\")\n",
    "    print(f\"  Modeled peak: {peak_metrics['modeled_peak']:.1f} cfs at {peak_metrics['modeled_peak_time']}\")\n",
    "    print(f\"  Peak error: {peak_metrics['peak_error_percent']:.1f}%\")\n",
    "    print(f\"  Timing error: {peak_metrics['timing_error_hours']:.1f} hours\")\n",
    "    \n",
    "    print(f\"\\nCorrelation:\")\n",
    "    print(f\"  Pearson RÂ²: {metrics['r_squared']:.3f}\")\n",
    "    print(f\"  Percent Bias (PBIAS): {metrics['pbias']:.1f}%\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot calculate metrics - no aligned data\")\n",
    "    metrics = None\n",
    "\n",
    "# Helper function for NSE interpretation\n",
    "def _interpret_nse(nse):\n",
    "    if nse > 0.75:\n",
    "        return \"Excellent (> 0.75)\"\n",
    "    elif nse > 0.65:\n",
    "        return \"Very Good (0.65-0.75)\"\n",
    "    elif nse > 0.50:\n",
    "        return \"Good (0.50-0.65)\"\n",
    "    elif nse > 0.40:\n",
    "        return \"Satisfactory (0.40-0.50)\"\n",
    "    else:\n",
    "        return \"Unsatisfactory (< 0.40)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Comparison Plots\n",
    "\n",
    "Generate publication-quality visualizations of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries comparison plot\n",
    "if aligned_df is not None and metrics is not None:\n",
    "    print(\"Creating timeseries comparison plot...\")\n",
    "    \n",
    "    plot_timeseries_comparison(\n",
    "        observed=aligned_df['observed'].values,\n",
    "        modeled=aligned_df['modeled'].values,\n",
    "        timestamps=aligned_df['datetime'].values,\n",
    "        title=f\"Model Validation: USGS-{downstream_gauge} vs HEC-RAS\",\n",
    "        observed_label=\"USGS Observed\",\n",
    "        modeled_label=\"HEC-RAS Modeled\",\n",
    "        show_metrics=True,\n",
    "        metrics_dict=metrics\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with 1:1 line\n",
    "if aligned_df is not None:\n",
    "    print(\"Creating scatter comparison plot...\")\n",
    "    \n",
    "    plot_scatter_comparison(\n",
    "        observed=aligned_df['observed'].values,\n",
    "        modeled=aligned_df['modeled'].values,\n",
    "        title=\"Modeled vs Observed Flow\",\n",
    "        xlabel=\"Observed Flow (cfs)\",\n",
    "        ylabel=\"Modeled Flow (cfs)\",\n",
    "        show_metrics=True,\n",
    "        metrics_dict=metrics\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis (4-panel diagnostic plot)\n",
    "if aligned_df is not None:\n",
    "    print(\"Creating residual diagnostic plots...\")\n",
    "    \n",
    "    plot_residuals(\n",
    "        observed=aligned_df['observed'].values,\n",
    "        modeled=aligned_df['modeled'].values,\n",
    "        timestamps=aligned_df['datetime'].values\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Assessment and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate performance assessment\n",
    "if metrics is not None:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"PERFORMANCE ASSESSMENT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    nse = metrics['nse']\n",
    "    kge = metrics['kge']\n",
    "    pbias = metrics['pbias']\n",
    "    \n",
    "    print(f\"\\nOverall Model Rating:\")\n",
    "    if nse > 0.75 and abs(pbias) < 10:\n",
    "        rating = \"EXCELLENT\"\n",
    "        color = \"green\"\n",
    "    elif nse > 0.65 and abs(pbias) < 15:\n",
    "        rating = \"VERY GOOD\"\n",
    "        color = \"lightgreen\"\n",
    "    elif nse > 0.50 and abs(pbias) < 25:\n",
    "        rating = \"GOOD\"\n",
    "        color = \"yellow\"\n",
    "    elif nse > 0.40:\n",
    "        rating = \"SATISFACTORY\"\n",
    "        color = \"orange\"\n",
    "    else:\n",
    "        rating = \"UNSATISFACTORY\"\n",
    "        color = \"red\"\n",
    "    \n",
    "    print(f\"  {rating}\")\n",
    "    print(f\"  NSE: {nse:.3f}, KGE: {kge:.3f}, PBIAS: {pbias:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nKey Findings:\")\n",
    "    \n",
    "    # Bias assessment\n",
    "    if abs(pbias) < 10:\n",
    "        print(f\"  âœ“ Low bias ({pbias:.1f}%) - Model captures flow magnitude well\")\n",
    "    elif abs(pbias) < 25:\n",
    "        print(f\"  âš  Moderate bias ({pbias:.1f}%) - Consider adjusting Manning's n or BC scaling\")\n",
    "    else:\n",
    "        print(f\"  âœ— High bias ({pbias:.1f}%) - Significant systematic error present\")\n",
    "    \n",
    "    # Timing assessment\n",
    "    if 'timing_error_hours' in peak_metrics:\n",
    "        timing_error = abs(peak_metrics['timing_error_hours'])\n",
    "        if timing_error < 3:\n",
    "            print(f\"  âœ“ Good timing ({timing_error:.1f}h error) - Peak timing well captured\")\n",
    "        elif timing_error < 6:\n",
    "            print(f\"  âš  Moderate timing error ({timing_error:.1f}h) - Check wave travel time\")\n",
    "        else:\n",
    "            print(f\"  âœ— Poor timing ({timing_error:.1f}h) - Review time step and boundary timing\")\n",
    "    \n",
    "    # Peak magnitude assessment\n",
    "    if 'peak_error_percent' in peak_metrics:\n",
    "        peak_error = abs(peak_metrics['peak_error_percent'])\n",
    "        if peak_error < 15:\n",
    "            print(f\"  âœ“ Good peak match ({peak_error:.1f}% error) - Peak flows accurate\")\n",
    "        elif peak_error < 25:\n",
    "            print(f\"  âš  Moderate peak error ({peak_error:.1f}%) - Review roughness calibration\")\n",
    "        else:\n",
    "            print(f\"  âœ— Large peak error ({peak_error:.1f}%) - Significant peak flow mismatch\")\n",
    "    \n",
    "    print(f\"\\nCalibration Recommendations:\")\n",
    "    \n",
    "    if pbias > 15:\n",
    "        print(f\"  1. Model overestimates - Increase Manning's n or reduce BC flows\")\n",
    "    elif pbias < -15:\n",
    "        print(f\"  1. Model underestimates - Decrease Manning's n or increase BC flows\")\n",
    "    else:\n",
    "        print(f\"  1. Flow magnitude is well calibrated\")\n",
    "    \n",
    "    if nse < 0.65:\n",
    "        print(f\"  2. Improve NSE by reducing systematic errors (check geometry, roughness)\")\n",
    "    \n",
    "    if metrics['kge_components']['correlation'] < 0.85:\n",
    "        print(f\"  3. Low correlation - Check boundary condition timing and shape\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Model Validation Workflow\n",
    "\n",
    "This example demonstrated the complete workflow for validating HEC-RAS results against USGS gauge observations:\n",
    "\n",
    "### Workflow Steps Completed\n",
    "\n",
    "1. âœ“ **Ran HEC-RAS model** (or used existing results)\n",
    "2. âœ“ **Extracted modeled flow** at cross section near downstream gauge\n",
    "3. âœ“ **Queried USGS observations** from gauge 01548005 (Beech Creek Station)\n",
    "4. âœ“ **Aligned timeseries** for direct comparison\n",
    "5. âœ“ **Calculated validation metrics** (NSE, KGE, RMSE, peak error, etc.)\n",
    "6. âœ“ **Created comparison plots** (timeseries, scatter, residuals)\n",
    "7. âœ“ **Assessed performance** and provided calibration guidance\n",
    "\n",
    "### Key Functions Used\n",
    "\n",
    "- `retrieve_flow_data()` - Query USGS observations\n",
    "- `align_timeseries()` - Synchronize modeled and observed data\n",
    "- `calculate_all_metrics()` - Comprehensive validation suite\n",
    "- `nash_sutcliffe_efficiency()` - NSE metric\n",
    "- `kling_gupta_efficiency()` - KGE metric with components\n",
    "- `calculate_peak_error()` - Peak flow and timing analysis\n",
    "- `plot_timeseries_comparison()` - Publication-quality timeseries plots\n",
    "- `plot_scatter_comparison()` - 1:1 scatter plots with statistics\n",
    "- `plot_residuals()` - 4-panel diagnostic plots\n",
    "\n",
    "### Validation Metrics Guide\n",
    "\n",
    "**Nash-Sutcliffe Efficiency (NSE):**\n",
    "- > 0.75: Excellent\n",
    "- 0.65-0.75: Very Good\n",
    "- 0.50-0.65: Good\n",
    "- 0.40-0.50: Satisfactory\n",
    "- < 0.40: Unsatisfactory\n",
    "\n",
    "**Percent Bias (PBIAS):**\n",
    "- < Â±10%: Very Good\n",
    "- Â±10-15%: Good\n",
    "- Â±15-25%: Satisfactory\n",
    "- > Â±25%: Unsatisfactory\n",
    "\n",
    "**Kling-Gupta Efficiency (KGE):**\n",
    "- Balances correlation, bias, and variability\n",
    "- Values near 1.0 indicate excellent performance\n",
    "- Components help identify specific deficiencies\n",
    "\n",
    "### Applications\n",
    "\n",
    "This workflow enables:\n",
    "- Quantitative model performance reporting\n",
    "- Systematic calibration guidance\n",
    "- Identification of bias and timing errors\n",
    "- Stakeholder communication of model accuracy\n",
    "\n",
    "### Related Examples\n",
    "\n",
    "- **Example 29:** Complete USGS integration workflow\n",
    "- **Example 30:** Real-time monitoring functions\n",
    "- **Example 31:** BC generation from live gauge data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}