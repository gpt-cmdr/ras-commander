{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAS Commander: Parallel Plan Execution\n",
    "\n",
    "This notebook demonstrates how to execute multiple HEC-RAS plans in parallel using the RAS Commander library. Parallel execution allows you to make better use of your computer's processing power by running multiple plans simultaneously.\n",
    "\n",
    "## Operations Covered\n",
    "\n",
    "1. **Project Initialization**: Initialize a HEC-RAS project and prepare it for parallel execution\n",
    "2. **Parallel Execution of All Plans**: Run all plans in a project simultaneously\n",
    "3. **Selective Parallel Execution**: Run only specific plans in parallel\n",
    "4. **Dynamic Worker Allocation**: Automatically determine the optimal number of parallel workers\n",
    "5. **Resource Management**: Optimize CPU core utilization for parallel runs\n",
    "6. **Results Comparison**: Analyze and visualize execution performance\n",
    "\n",
    "Let's begin by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ras-commander from pip (uncomment to install if needed)\n",
    "#!pip install ras-commander\n",
    "# This installs ras-commander and all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required modules\n",
    "\n",
    "# Import all ras-commander modules\n",
    "from ras_commander import *\n",
    "\n",
    "# Import the required libraries for this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil  # For getting system CPU info\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import math  # Import math to avoid NameError in get_optimal_worker_count function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Working Environment\n",
    "\n",
    "Let's set up our working directory and check the system resources available for parallel execution. This will help us make informed decisions about how many workers to use.\n",
    "\n",
    "For this notebook we will be using the \"Muncie\" HEC Example Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Muncie example project\n",
    "# The extract_project method downloads the project from GitHub if not already present,\n",
    "# and extracts it to the example_projects folder\n",
    "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
    "print(f\"Extracted project to: {muncie_path}\")  \n",
    "\n",
    "# Verify the path exists\n",
    "print(f\"Bald Eagle Creek project exists: {muncie_path.exists()}\")\n",
    "\n",
    "\n",
    "# Create compute folders\n",
    "compute_folder = muncie_path.parent / \"compute_test_parallel\"\n",
    "specific_compute_folder = muncie_path.parent / \"compute_test_parallel_specific\"\n",
    "dynamic_compute_folder = muncie_path.parent / \"compute_test_parallel_dynamic\"\n",
    "\n",
    "# Check system resources for parallel execution\n",
    "cpu_count = psutil.cpu_count(logical=True)  # Logical cores (including hyper-threading)\n",
    "physical_cores = psutil.cpu_count(logical=False)  # Physical cores only\n",
    "memory_gb = psutil.virtual_memory().total / (1024**3)  # Total RAM in GB\n",
    "available_memory_gb = psutil.virtual_memory().available / (1024**3)  # Available RAM in GB\n",
    "\n",
    "print(f\"System Resources:\")\n",
    "print(f\"- {physical_cores} physical CPU cores ({cpu_count} logical cores with hyper-threading)\")\n",
    "print(f\"- {memory_gb:.1f} GB total memory ({available_memory_gb:.1f} GB available)\")\n",
    "\n",
    "# Functions to help with resource management\n",
    "def get_optimal_worker_count(cores_per_worker=2):\n",
    "    \"\"\"Calculate the optimal number of workers based on available physical cores.\"\"\"\n",
    "    optimal_workers = math.floor(physical_cores / cores_per_worker)\n",
    "    return max(1, optimal_workers)  # Ensure at least 1 worker\n",
    "\n",
    "print(f\"\\nFor parallel HEC-RAS execution:\")\n",
    "print(f\"- With 2 cores per worker: Can use up to {get_optimal_worker_count(2)} parallel workers\")\n",
    "print(f\"- With 4 cores per worker: Can use up to {get_optimal_worker_count(4)} parallel workers\")\n",
    "print(f\"\\nEach HEC-RAS instance typically requires 2-4 GB of RAM. Based on your available memory,\")\n",
    "print(f\"you could reasonably run {math.floor(available_memory_gb / 3)} instances simultaneously.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Parallel Execution in HEC-RAS\n",
    "\n",
    "HEC-RAS simulations can be computationally intensive, especially for large models or long simulation periods. Parallel execution allows you to run multiple plans simultaneously, making better use of your computer's processing power.\n",
    "\n",
    "### Key Concepts in Parallel Execution\n",
    "\n",
    "1. **Workers**: Each worker is a separate process that can execute a HEC-RAS plan. The `max_workers` parameter determines how many plans can be executed simultaneously.\n",
    "\n",
    "2. **Cores per Worker**: Each worker (HEC-RAS instance) can utilize multiple CPU cores. The `num_cores` parameter sets how many cores each worker uses.\n",
    "\n",
    "3. **Resource Balancing**: Effective parallel execution requires balancing the number of workers with the cores per worker. Too many workers or too many cores per worker can lead to resource contention and slower overall performance.\n",
    "\n",
    "4. **Worker Folders**: Each worker gets its own folder with a copy of the project, allowing for isolated execution.\n",
    "\n",
    "### Parallel vs. Sequential Execution\n",
    "\n",
    "- **Parallel**: Multiple plans run simultaneously (good for independent plans, faster overall completion)\n",
    "- **Sequential**: Plans run one after another (good for dependent plans, consistent resource usage)\n",
    "\n",
    "### Optimal Configuration\n",
    "\n",
    "The optimal configuration depends on your hardware and the specific plans you're running:\n",
    "\n",
    "- For most models, 2-4 cores per worker provides good performance\n",
    "- Set `max_workers` based on available physical cores: `max_workers = floor(physical_cores / cores_per_worker)`\n",
    "- Ensure you have enough memory: each worker typically needs 2-4 GB of RAM\n",
    "\n",
    "Now, let's download and extract our example project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Extracting Example HEC-RAS Project\n",
    "\n",
    "Let's use the `RasExamples` class to download and extract the \"Balde Eagle Creek\" example project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Project Initialization\n",
    "\n",
    "Let's initialize the HEC-RAS project using the `init_ras_project()` function. We'll store the initialized object in a variable to use later, rather than relying on the global `ras` object. This approach is more suitable for working with multiple projects or compute folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the source project\n",
    "source_project = init_ras_project(muncie_path, \"6.6\")\n",
    "print(f\"Initialized source project: {source_project.project_name}\")\n",
    "\n",
    "# Display the current plan files in the project\n",
    "print(\"\\nAvailable plans in the project:\")\n",
    "display.display(source_project.plan_df)\n",
    "\n",
    "# Check how many plans we have\n",
    "plan_count = len(source_project.plan_df)\n",
    "print(f\"Found {plan_count} plans in the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the RasCmdr.compute_parallel Method\n",
    "\n",
    "Before we start executing plans in parallel, let's understand the `compute_parallel()` method from the `RasCmdr` class.\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "- `plan_number` (Union[str, List[str], None]): Plan number(s) to compute. If None, all plans are computed.\n",
    "- `max_workers` (int): Maximum number of parallel workers (default: 2).\n",
    "- `num_cores` (int): Number of cores to use per plan computation (default: 2).\n",
    "- `clear_geompre` (bool): Whether to clear geometry preprocessor files (default: False).\n",
    "- `ras_object` (Optional[RasPrj]): Specific RAS object to use. If None, uses global ras instance.\n",
    "- `dest_folder` (Union[str, Path, None]): Destination folder for computed results.\n",
    "- `overwrite_dest` (bool): Whether to overwrite existing destination folder (default: False).\n",
    "\n",
    "### Return Value\n",
    "- `Dict[str, bool]`: Dictionary of plan numbers and their execution success status.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Worker Assignment**: Plans are assigned to workers in a round-robin fashion. For example, with 3 workers and 5 plans, workers would be assigned as follows: Worker 1: Plans 1 & 4, Worker 2: Plans 2 & 5, Worker 3: Plan 3.\n",
    "\n",
    "2. **Worker Folders**: Each worker gets its own folder (a subdirectory of the destination folder) for isolated execution.\n",
    "\n",
    "3. **Result Consolidation**: After all plans are executed, results are consolidated into the destination folder.\n",
    "\n",
    "4. **Resource Management**: Each worker can use multiple cores as specified by `num_cores`.\n",
    "\n",
    "Now, let's see how this works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parallel Execution of All Plans\n",
    "\n",
    "Let's execute all plans in the project in parallel. We'll use 3 workers, with 2 cores per worker. This approach is good when you have multiple plans that are independent of each other and you want to complete them as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Executing all plans in parallel...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Create compute folder if it doesn't exist\n",
    "compute_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the parameters for parallel execution\n",
    "max_workers = 4\n",
    "cores_per_worker = 1\n",
    "\n",
    "print(f\"Using {max_workers} parallel workers, each with {cores_per_worker} cores\")\n",
    "print(f\"Destination folder: {compute_folder}\")\n",
    "\n",
    "# Record start time for performance measurement\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute all plans in parallel\n",
    "results_all = RasCmdr.compute_parallel(\n",
    "    max_workers=max_workers,\n",
    "    num_cores=cores_per_worker,\n",
    "    dest_folder=compute_folder,\n",
    "    overwrite_dest=True,\n",
    "    ras_object=source_project\n",
    ")\n",
    "\n",
    "# Record end time and calculate duration\n",
    "end_time = time.time()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "print(f\"Parallel execution of all plans completed in {total_duration:.2f} seconds\")\n",
    "\n",
    "# Create a DataFrame from the execution results for better visualization\n",
    "results_df = pd.DataFrame([\n",
    "    {\"Plan\": plan, \"Success\": success}\n",
    "    for plan, success in results_all.items()\n",
    "])\n",
    "\n",
    "# Sort by plan number\n",
    "results_df = results_df.sort_values(\"Plan\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nExecution Results:\")\n",
    "display.display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Examining the Parallel Execution Results\n",
    "\n",
    "Let's initialize a RAS project in the compute folder and examine the results of the parallel execution. This will help us understand what happened during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a RAS project in the compute folder\n",
    "compute_project = RasPrj()\n",
    "init_ras_project(compute_folder, \"6.6\", ras_object=compute_project)\n",
    "print(f\"Initialized compute project: {compute_project.project_name}\")\n",
    "\n",
    "# Display the plan files in the compute folder\n",
    "print(\"\\nPlans in the compute folder:\")\n",
    "display.display(compute_project.plan_df)\n",
    "\n",
    "# Check which plans have results\n",
    "plans_with_results = compute_project.plan_df[compute_project.plan_df['HDF_Results_Path'].notna()]\n",
    "print(f\"\\nFound {len(plans_with_results)} plans with results:\")\n",
    "display.display(plans_with_results[['plan_number', 'HDF_Results_Path']])\n",
    "\n",
    "# List the worker folders (they should have been removed during results consolidation)\n",
    "worker_folders = list(compute_folder.glob(\"*Worker*\"))\n",
    "if worker_folders:\n",
    "    print(f\"\\nFound {len(worker_folders)} worker folders:\")\n",
    "    for folder in worker_folders:\n",
    "        print(f\"  {folder.name}\")\n",
    "else:\n",
    "    print(\"\\nNo worker folders remain in the compute folder (they were removed during results consolidation)\")\n",
    "\n",
    "# Check for HDF result files\n",
    "hdf_files = list(compute_folder.glob(\"*.hdf\"))\n",
    "hdf_files.sort()\n",
    "\n",
    "print(f\"\\nFound {len(hdf_files)} HDF files in the compute folder:\")\n",
    "for file in hdf_files:\n",
    "    file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
    "    print(f\"  {file.name}: {file_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Examples: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution of Specific Plans\n",
    "\n",
    "Now, let's execute only specific plans in the project in parallel. This approach is useful when you only want to run a subset of the available plans, perhaps for testing or comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Executing specific plans in parallel...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Create specific compute folder if it doesn't exist\n",
    "specific_compute_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the plans to execute\n",
    "specific_plans = [\"01\", \"03\"]\n",
    "print(f\"Selected plans: {', '.join(specific_plans)}\")\n",
    "\n",
    "# Define the parameters for parallel execution\n",
    "max_workers = 2  # One for each plan\n",
    "cores_per_worker = 2\n",
    "\n",
    "print(f\"Using {max_workers} parallel workers, each with {cores_per_worker} cores\")\n",
    "print(f\"Destination folder: {specific_compute_folder}\")\n",
    "\n",
    "# Record start time for performance measurement\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute specific plans in parallel\n",
    "results_specific = RasCmdr.compute_parallel(\n",
    "    plan_number=specific_plans,\n",
    "    max_workers=max_workers,\n",
    "    num_cores=cores_per_worker,\n",
    "    dest_folder=specific_compute_folder,\n",
    "    overwrite_dest=True,\n",
    "    ras_object=source_project\n",
    ")\n",
    "\n",
    "# Record end time and calculate duration\n",
    "end_time = time.time()\n",
    "specific_duration = end_time - start_time\n",
    "\n",
    "print(f\"Parallel execution of specific plans completed in {specific_duration:.2f} seconds\")\n",
    "\n",
    "# Create a DataFrame from the execution results for better visualization\n",
    "specific_results_df = pd.DataFrame([\n",
    "    {\"Plan\": plan, \"Success\": success}\n",
    "    for plan, success in results_specific.items()\n",
    "])\n",
    "\n",
    "# Sort by plan number\n",
    "specific_results_df = specific_results_df.sort_values(\"Plan\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nExecution Results:\")\n",
    "display.display(specific_results_df)\n",
    "\n",
    "# Initialize a RAS project in the specific compute folder\n",
    "specific_compute_project = RasPrj()\n",
    "init_ras_project(specific_compute_folder, \"6.6\", ras_object=specific_compute_project)\n",
    "print(f\"\\nInitialized specific compute project: {specific_compute_project.project_name}\")\n",
    "\n",
    "# Check which plans have results\n",
    "specific_plans_with_results = specific_compute_project.plan_df[specific_compute_project.plan_df['HDF_Results_Path'].notna()]\n",
    "print(f\"Found {len(specific_plans_with_results)} plans with results:\")\n",
    "display.display(specific_plans_with_results[['plan_number', 'HDF_Results_Path']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution with Max Workers Defined by Physical Cores (\"Dynamic Worker Allocation\") \n",
    "\n",
    "In this step, we'll determine the optimal number of workers based on the physical cores available on the system. This approach ensures that we make efficient use of the available hardware without overcommitting resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Executing plans with dynamic worker allocation...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Create dynamic compute folder if it doesn't exist\n",
    "dynamic_compute_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the cores per worker\n",
    "cores_per_worker = 4\n",
    "# 2 cores per worker is the efficiency point for most CPU's, due to L2/L3 cache being shared by 2 cores in most x86 CPU's\n",
    "# 4-8 cores per worker is the maximum performance point for most CPU's, using more compute power to marginally lower runtime \n",
    "# when using parallel compute, 2 cores per worker is typically optimal as it is assumed you are maximizing throughput (efficency) over single-plan runtime (performance)\n",
    "\n",
    "# Calculate the optimal number of workers based on physical cores\n",
    "max_workers = get_optimal_worker_count(cores_per_worker)\n",
    "print(f\"System has {physical_cores} physical cores\")\n",
    "print(f\"With {cores_per_worker} cores per worker, optimal worker count is {max_workers}\")\n",
    "print(f\"Destination folder: {dynamic_compute_folder}\")\n",
    "\n",
    "# Record start time for performance measurement\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute all plans with dynamic worker allocation\n",
    "results_dynamic = RasCmdr.compute_parallel(\n",
    "    plan_number=specific_plans,\n",
    "    max_workers=max_workers,\n",
    "    num_cores=cores_per_worker,\n",
    "    dest_folder=dynamic_compute_folder,\n",
    "    overwrite_dest=True,\n",
    "    ras_object=source_project\n",
    ")\n",
    "\n",
    "# Record end time and calculate duration\n",
    "end_time = time.time()\n",
    "dynamic_duration = end_time - start_time\n",
    "\n",
    "print(f\"Parallel execution with dynamic worker allocation completed in {dynamic_duration:.2f} seconds\")\n",
    "\n",
    "# Create a DataFrame from the execution results for better visualization\n",
    "dynamic_results_df = pd.DataFrame([\n",
    "    {\"Plan\": plan, \"Success\": success}\n",
    "    for plan, success in results_dynamic.items()\n",
    "])\n",
    "\n",
    "# Sort by plan number\n",
    "dynamic_results_df = dynamic_results_df.sort_values(\"Plan\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nExecution Results:\")\n",
    "display.display(dynamic_results_df)\n",
    "\n",
    "# Initialize a RAS project in the dynamic compute folder\n",
    "dynamic_compute_project = RasPrj()\n",
    "init_ras_project(dynamic_compute_folder, \"6.6\", ras_object=dynamic_compute_project)\n",
    "print(f\"\\nInitialized dynamic compute project: {dynamic_compute_project.project_name}\")\n",
    "\n",
    "# Check which plans have results\n",
    "dynamic_plans_with_results = dynamic_compute_project.plan_df[dynamic_compute_project.plan_df['HDF_Results_Path'].notna()]\n",
    "print(f\"Found {len(dynamic_plans_with_results)} plans with results:\")\n",
    "display.display(dynamic_plans_with_results[['plan_number', 'HDF_Results_Path']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's compare the performance of the different parallel execution approaches we've tried. This will help us understand the impact of worker count and plan selection on execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for individual plan runtimes\n",
    "plan_data = []\n",
    "\n",
    "# Define the approaches with more descriptive labels including worker and core counts\n",
    "approach_labels = {\n",
    "    \"all_plans\": \"All Plans (2 workers × 2 cores = 4 cores total)\",\n",
    "    \"specific_plans\": \"Specific Plans (1 worker × 2 cores = 2 cores total)\",\n",
    "    \"dynamic_workers\": f\"Dynamic Workers (1 worker × 4 cores = 4 cores total)\"\n",
    "}\n",
    "\n",
    "# Extract runtimes from the log messages\n",
    "# For all plans approach\n",
    "plan_data.append({\"Approach\": approach_labels[\"all_plans\"], \"Plan\": \"01\", \"Runtime\": 35.72})\n",
    "plan_data.append({\"Approach\": approach_labels[\"all_plans\"], \"Plan\": \"03\", \"Runtime\": 82.70})\n",
    "# Omitting plan 04 as it's a 1D model\n",
    "\n",
    "# For specific plans approach (plans 01 and 03 were run)\n",
    "plan_data.append({\"Approach\": approach_labels[\"specific_plans\"], \"Plan\": \"01\", \"Runtime\": 29.10})\n",
    "plan_data.append({\"Approach\": approach_labels[\"specific_plans\"], \"Plan\": \"03\", \"Runtime\": 36.09})\n",
    "\n",
    "# For dynamic worker approach (plans 01 and 03 were run)\n",
    "plan_data.append({\"Approach\": approach_labels[\"dynamic_workers\"], \"Plan\": \"01\", \"Runtime\": 28.48})\n",
    "plan_data.append({\"Approach\": approach_labels[\"dynamic_workers\"], \"Plan\": \"03\", \"Runtime\": 49.43})\n",
    "\n",
    "# Create a DataFrame\n",
    "plan_runtime_df = pd.DataFrame(plan_data)\n",
    "\n",
    "# Create a grouped bar chart for plan runtimes\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get all unique plan numbers and ensure they're sorted\n",
    "plans = sorted(plan_runtime_df[\"Plan\"].unique())\n",
    "\n",
    "# Create x positions for the bars\n",
    "x = np.arange(len(plans))\n",
    "width = 0.25  # Width of the bars\n",
    "\n",
    "# Plot bars for each approach\n",
    "approaches = plan_runtime_df[\"Approach\"].unique()\n",
    "for i, approach in enumerate(approaches):\n",
    "    # Filter data for this approach\n",
    "    approach_data = plan_runtime_df[plan_runtime_df[\"Approach\"] == approach]\n",
    "    \n",
    "    # Initialize runtimes array with NaN values\n",
    "    runtimes = [np.nan] * len(plans)\n",
    "    \n",
    "    # Fill in runtimes where data exists\n",
    "    for j, plan in enumerate(plans):\n",
    "        plan_runtime = approach_data[approach_data[\"Plan\"] == plan][\"Runtime\"]\n",
    "        if not plan_runtime.empty:\n",
    "            runtimes[j] = plan_runtime.values[0]\n",
    "    \n",
    "    # Create bars for this approach (only where we have data)\n",
    "    valid_indices = [idx for idx, val in enumerate(runtimes) if not np.isnan(val)]\n",
    "    valid_plans = [plans[idx] for idx in valid_indices]\n",
    "    valid_runtimes = [runtimes[idx] for idx in valid_indices]\n",
    "    valid_positions = [x[idx] + (i - len(approaches)/2 + 0.5) * width for idx in valid_indices]\n",
    "    \n",
    "    # Plot the bars\n",
    "    bars = plt.bar(valid_positions, valid_runtimes, width, label=approach)\n",
    "    \n",
    "    # Add runtime labels on top of bars\n",
    "    for pos, runtime in zip(valid_positions, valid_runtimes):\n",
    "        plt.text(pos, runtime + 2, f\"{runtime:.1f}s\", ha='center', va='bottom')\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels\n",
    "plt.xlabel('Plan Number', fontsize=12)\n",
    "plt.ylabel('Runtime (seconds)', fontsize=12)\n",
    "plt.title('Runtime Comparison by Plan Number and Parallelization Approach', fontsize=14)\n",
    "plt.xticks(x, plans, fontsize=11)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add note about omitting Plan 04\n",
    "plt.figtext(0.5, 0.01, \"\\nNote: Plan 04 (1D model) is omitted from this comparison\", \n",
    "            ha='center', fontsize=10, style='italic')\n",
    "\n",
    "# Ensure all plan numbers show on x-axis regardless of data availability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Parallel Plan Execution\n",
    "\n",
    "In this notebook, we've explored how to execute HEC-RAS plans in parallel using the RAS Commander library. Here's a summary of the key techniques we've covered:\n",
    "\n",
    "1. **Basic Parallel Execution**: Using `RasCmdr.compute_parallel()` to run all plans in a project simultaneously\n",
    "2. **Selective Parallel Execution**: Running only specific plans in parallel\n",
    "3. **Dynamic Worker Allocation**: Determining the optimal number of workers based on available system resources\n",
    "4. **Performance Analysis**: Comparing execution times for different parallel configurations\n",
    "5. **Advanced Parallel Workflows**: Building complex workflows with parallel execution for sensitivity analysis\n",
    "\n",
    "### Key Functions Used\n",
    "\n",
    "- `RasCmdr.compute_parallel()`: Execute multiple plans in parallel\n",
    "- `RasPlan.clone_plan()`: Create a new plan based on an existing one\n",
    "- `RasPlan.update_plan_description()`: Update the description of a plan\n",
    "- `RasPlan.set_num_cores()`: Set the number of cores for a plan to use\n",
    "- `RasPlan.get_results_path()`: Get the path to the results file for a plan\n",
    "\n",
    "### Best Practices for Parallel Execution\n",
    "\n",
    "1. **Use Separate RAS Objects**: Create and use separate RAS objects for different projects or folders\n",
    "2. **Balance Workers and Cores**: Find the right balance between the number of workers and cores per worker\n",
    "3. **Consider Hardware Limits**: Be mindful of your system's physical cores and memory\n",
    "4. **Use Clean Compute Folders**: Use the `dest_folder` parameter to keep your project organized\n",
    "5. **Handle Overwrite Carefully**: Use `overwrite_dest=True` for repeatable workflows, but be cautious about losing results\n",
    "6. **Monitor Performance**: Track execution times and adjust your configuration for optimal performance\n",
    "7. **Match Workers to Plans**: For best results, use one worker per plan when running a small number of plans\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdrpip4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
