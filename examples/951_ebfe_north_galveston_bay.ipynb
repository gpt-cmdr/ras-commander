{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Using eBFE Models: North Galveston Bay HMS + RAS Integration\n\nThis notebook demonstrates working with compound eBFE/BLE models that include both HEC-HMS hydrologic and HEC-RAS hydraulic models.\n\n## The Problem: eBFE Models Are Broken\n\n**FEMA's eBFE models are fundamentally broken and unusable without significant manual effort:**\n\n1. **HMS and RAS Mixed**: Hydrologic and hydraulic models in same archive with no clear separation\n2. **Nested 6.1 GB Zip**: RAS model buried in nested zip requiring manual extraction (command-line tools fail)\n3. **Absolute DSS Paths**: HMS DSS outputs use absolute paths → HEC-RAS can't find them\n4. **Terrain Separated**: Terrain outside project folder → Model won't run\n5. **Output/ Separated**: Pre-run results inaccessible\n\n**Manual Fix Time**: 45-90 minutes per model (HMS extraction, RAS extraction, path corrections, folder moves)\n\n**With RasEbfeModels**: Automatic HMS/RAS separation, path corrections, folder integration ✓\n\n## Our Solution: Automated Organization + Path Fixing\n\n**RasEbfeModels.organize_north_galveston_bay() automatically**:\n1. Separates HMS Model/ from RAS Model/\n2. Organizes 7 storm frequencies + sensitivity analysis\n3. Corrects DSS paths to relative references  \n4. Moves Terrain/ and Output/ when RAS extracted\n5. Creates runnable models (or clear extraction instructions)\n\n## Model Characteristics\n\n- **Pattern 4**: Compound HMS + RAS archive (most complex)\n- **Size**: 8.2 GB\n- **HMS**: NorthGalvestonBay.hms with 7 storm frequencies + sensitivity\n- **RAS**: 2D coastal hydraulic model (nested in RAS_Submittal.zip)\n- **Type**: Coastal flood analysis (hurricane surge)\n\n## What You'll Learn\n\n1. Organize compound HMS + RAS model (most complex pattern)\n2. Understand the critical fixes applied automatically\n3. Work with HMS hydrologic model (multiple storm frequencies)\n4. Handle large nested RAS extraction (6.1 GB, manual required)\n5. Understand HMS → RAS workflow\n6. Validate DSS time series data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Downloads Required**:\n",
    "1. North Galveston Bay Models.zip (8.2 GB) - HMS + nested RAS\n",
    "2. North Galveston Bay Documents.zip (20 MB) - BLE reports\n",
    "\n",
    "**Note**: This is Pattern 4 - most complex pattern with both hydrologic and hydraulic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path for development\n",
    "try:\n",
    "    from ras_commander import init_ras_project, RasCmdr\n",
    "except ImportError:\n",
    "    sys.path.insert(0, str(Path.cwd().parent))\n",
    "    from ras_commander import init_ras_project, RasCmdr\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Organize Downloaded Model\n",
    "\n",
    "Use `RasEbfeModels.organize_north_galveston_bay()` to organize HMS and RAS content into separate folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import eBFE model organization function\n",
    "from ras_commander.ebfe_models import RasEbfeModels\n",
    "\n",
    "# Set paths\n",
    "downloaded_folder = Path(r\"D:\\Ras-Commander_BulkData\\eBFE\\Harris_County\\12040203_NorthGalvestonBay_Models_extracted\")\n",
    "organized_folder = Path(r\"D:\\Ras-Commander_BulkData\\eBFE\\Organized\\NorthGalvestonBay_12040203\")\n",
    "\n",
    "# Organize (HMS will be ready, RAS requires manual extraction)\n",
    "if not organized_folder.exists() or not (organized_folder / \"agent\" / \"model_log.md\").exists():\n",
    "    print(\"Organizing North Galveston Bay model...\")\n",
    "    print(\"Note: RAS model (6.1 GB nested zip) requires manual extraction\\n\")\n",
    "    \n",
    "    organized_folder = RasEbfeModels.organize_north_galveston_bay(\n",
    "        downloaded_folder,\n",
    "        organized_folder,\n",
    "        extract_ras_nested=False,  # Manual extraction recommended\n",
    "        validate_dss=True\n",
    "    )\n",
    "else:\n",
    "    print(f\"Model already organized at: {organized_folder}\")\n",
    "\n",
    "print(f\"\\n✓ Organized model location: {organized_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore HMS Model\n",
    "\n",
    "Pattern 4 includes HEC-HMS hydrologic model with multiple storm frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMS model location\n",
    "hms_folder = organized_folder / \"HMS Model\" / \"NorthGalvestonBay\"\n",
    "hms_project = hms_folder / \"NorthGalvestonBay.hms\"\n",
    "\n",
    "if hms_project.exists():\n",
    "    print(f\"HMS Project: {hms_project.name}\")\n",
    "    print(f\"Location: {hms_folder}\\n\")\n",
    "    \n",
    "    # List storm frequencies\n",
    "    dss_files = list(hms_folder.glob('*.dss'))\n",
    "    print(f\"Storm Frequencies ({len(dss_files)} DSS files):\")\n",
    "    for dss in sorted(dss_files):\n",
    "        size_mb = dss.stat().st_size / 1e6\n",
    "        print(f\"  - {dss.stem}: {size_mb:.1f} MB\")\n",
    "    \n",
    "    # List basin models\n",
    "    basin_files = list(hms_folder.glob('*.basin'))\n",
    "    print(f\"\\nBasin Models ({len(basin_files)}):\")\n",
    "    for basin in sorted(basin_files):\n",
    "        print(f\"  - {basin.name}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ HMS project not found - check organization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore HMS DSS Time Series\n",
    "\n",
    "HMS models generate streamflow hydrographs in DSS format that feed into HEC-RAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ras_commander.dss import RasDss\n",
    "\n",
    "# Pick one storm frequency to explore\n",
    "dss_file = hms_folder / \"100yr.dss\"\n",
    "\n",
    "if dss_file.exists():\n",
    "    print(f\"Exploring: {dss_file.name}\\n\")\n",
    "    \n",
    "    # Get catalog of all pathnames\n",
    "    catalog = RasDss.get_catalog(dss_file)\n",
    "    print(f\"Total pathnames: {len(catalog)}\")\n",
    "    \n",
    "    # Show first 10 pathnames\n",
    "    print(f\"\\nFirst 10 pathnames:\")\n",
    "    for i, pathname in enumerate(catalog['pathname'][:10]):\n",
    "        print(f\"  {i+1}. {pathname}\")\n",
    "    \n",
    "    if len(catalog) > 10:\n",
    "        print(f\"  ... and {len(catalog) - 10} more\")\n",
    "    \n",
    "    # Validate DSS pathnames\n",
    "    print(f\"\\nValidating DSS pathnames...\")\n",
    "    invalid_count = 0\n",
    "    for pathname in catalog['pathname']:\n",
    "        result = RasDss.check_pathname(dss_file, pathname)\n",
    "        if not result.is_valid:\n",
    "            invalid_count += 1\n",
    "    \n",
    "    if invalid_count == 0:\n",
    "        print(f\"  ✓ All {len(catalog)} pathnames valid\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ {invalid_count} invalid pathname(s) found\")\n",
    "else:\n",
    "    print(f\"⚠️ {dss_file.name} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check RAS Model Status\n",
    "\n",
    "Pattern 4 RAS model is in a nested 6.1 GB zip. Check extraction status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ras_folder = organized_folder / \"RAS Model\"\n",
    "extraction_readme = ras_folder / \"README_EXTRACTION_NEEDED.txt\"\n",
    "\n",
    "# Check if RAS has been extracted\n",
    "ras_prj_files = list(ras_folder.glob('**/*.prj'))\n",
    "# Filter out shapefile .prj\n",
    "ras_prj_files = [p for p in ras_prj_files if 'Shp' not in str(p) and 'Features' not in str(p)]\n",
    "\n",
    "if ras_prj_files:\n",
    "    print(\"✓ RAS model extracted successfully\")\n",
    "    print(f\"  Found: {ras_prj_files[0]}\")\n",
    "    ras_extracted = True\n",
    "elif extraction_readme.exists():\n",
    "    print(\"⚠️ RAS model requires manual extraction\")\n",
    "    print(f\"\\nInstructions: {extraction_readme}\")\n",
    "    print(\"\\nExtraction Steps:\")\n",
    "    print(extraction_readme.read_text())\n",
    "    ras_extracted = False\n",
    "else:\n",
    "    print(\"⚠️ RAS model status unknown\")\n",
    "    ras_extracted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize RAS Model (If Extracted)\n",
    "\n",
    "If RAS_Submittal.zip has been manually extracted, initialize with ras-commander."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ras_extracted:\n",
    "    print(\"Initializing RAS model...\")\n",
    "    \n",
    "    # Initialize project\n",
    "    ras_project = ras_prj_files[0].parent\n",
    "    ras = init_ras_project(ras_project, \"6.5\")  # Version TBD from files\n",
    "    \n",
    "    print(f\"✓ Project initialized: {ras.prj_file}\")\n",
    "    print(f\"\\nPlans found: {len(ras.plan_df)}\")\n",
    "    print(ras.plan_df[['plan_number', 'plan_title']].to_string())\n",
    "    \n",
    "    # Validate DSS files in RAS model\n",
    "    print(\"\\nValidating RAS DSS files...\")\n",
    "    ras_dss_files = list(ras_project.glob('**/*.dss'))\n",
    "    print(f\"  Found {len(ras_dss_files)} DSS file(s)\")\n",
    "    \n",
    "    for dss in ras_dss_files:\n",
    "        catalog = RasDss.get_catalog(dss)\n",
    "        print(f\"  {dss.name}: {len(catalog)} pathname(s)\")\n",
    "else:\n",
    "    print(\"⚠️ RAS model not extracted - complete manual extraction first\")\n",
    "    print(\"\\nAfter extraction, re-run this cell to initialize RAS model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Understanding HMS → RAS Workflow\n",
    "\n",
    "Pattern 4 models show the typical HMS → RAS workflow:\n",
    "\n",
    "1. **HEC-HMS**: Generates streamflow hydrographs from precipitation\n",
    "2. **DSS Transfer**: HMS results saved to DSS files\n",
    "3. **HEC-RAS**: Uses DSS hydrographs as boundary conditions\n",
    "4. **2D Routing**: Computes inundation depths and extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HMS → RAS Workflow for North Galveston Bay:\\n\")\n",
    "print(\"Step 1: HEC-HMS Hydrologic Modeling\")\n",
    "print(\"  - Input: Design storm precipitation (10yr, 25yr, 50yr, 100yr, 500yr)\")\n",
    "print(\"  - Process: Basin rainfall-runoff transformation\")\n",
    "print(\"  - Output: Streamflow hydrographs → DSS files\")\n",
    "print(f\"  - Location: {hms_folder}\")\n",
    "print()\n",
    "print(\"Step 2: DSS Time Series\")\n",
    "print(\"  - HMS results stored in .dss files\")\n",
    "print(\"  - Multiple storm frequencies (7 total)\")\n",
    "print(\"  - Sensitivity variants: 100yr_Min, 100yr_Plus\")\n",
    "print()\n",
    "print(\"Step 3: HEC-RAS Hydraulic Modeling\")\n",
    "print(\"  - Input: HMS hydrographs from DSS + coastal boundary conditions\")\n",
    "print(\"  - Process: 2D shallow water equations\")\n",
    "print(\"  - Output: Inundation maps, depths, velocities\")\n",
    "if ras_extracted:\n",
    "    print(f\"  - Location: {ras_project}\")\n",
    "else:\n",
    "    print(f\"  - Status: Pending manual extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Review Documentation\n",
    "\n",
    "Pattern 4 models include comprehensive BLE reports and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_folder = organized_folder / \"Documentation\"\n",
    "doc_files = list(docs_folder.glob('*'))\n",
    "\n",
    "print(f\"Documentation Files ({len(doc_files)}):\")\n",
    "print(\"=\" * 80)\n",
    "for doc in sorted(doc_files):\n",
    "    size_mb = doc.stat().st_size / 1e6\n",
    "    print(f\"  - {doc.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "# Read model inventory if available\n",
    "inventory = docs_folder / \"2D_Model_Inventory.xlsx\"\n",
    "if inventory.exists():\n",
    "    print(f\"\\nReading model inventory...\")\n",
    "    df = pd.read_excel(inventory, sheet_name=0, nrows=10)\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Check Agent Work Log\n",
    "\n",
    "Every organized model has agent/model_log.md documenting the organization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = organized_folder / \"agent\" / \"model_log.md\"\n",
    "\n",
    "if model_log.exists():\n",
    "    print(f\"Agent Work Log: {model_log}\\n\")\n",
    "    print(\"Preview (first 30 lines):\")\n",
    "    print(\"=\" * 80)\n",
    "    log_content = model_log.read_text()\n",
    "    print('\\n'.join(log_content.split('\\n')[:30]))\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"⚠️ Agent work log not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Extract Results from RAS Model\n",
    "\n",
    "**Requires**: Manual extraction of RAS_Submittal.zip first\n",
    "\n",
    "After extracting the RAS model, you can initialize and extract results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ras_extracted:\n",
    "    print(\"Extracting RAS results...\\n\")\n",
    "    \n",
    "    # Check for HDF result files\n",
    "    hdf_files = list(ras_project.glob('**/*.p*.hdf'))\n",
    "    print(f\"HDF result files: {len(hdf_files)}\")\n",
    "    \n",
    "    if hdf_files:\n",
    "        # Extract from first HDF file\n",
    "        from ras_commander.hdf import HdfResultsPlan\n",
    "        \n",
    "        hdf = HdfResultsPlan(hdf_files[0])\n",
    "        wse = hdf.get_wse(time_index=-1)\n",
    "        \n",
    "        print(f\"\\nResults from {hdf_files[0].name}:\")\n",
    "        print(f\"  WSE count: {len(wse)}\")\n",
    "        print(f\"  WSE range: {wse.min():.2f} to {wse.max():.2f} ft\")\n",
    "    else:\n",
    "        print(\"  No HDF files found - may need to run compute test\")\n",
    "else:\n",
    "    print(\"⚠️ RAS model not extracted\")\n",
    "    print(\"\\nTo extract:\")\n",
    "    print(\"  1. See RAS Model/README_EXTRACTION_NEEDED.txt\")\n",
    "    print(\"  2. Extract RAS_Submittal.zip (6.1 GB) via Windows Explorer\")\n",
    "    print(\"  3. Re-run this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ **Pattern 4 Organization**: Compound HMS + RAS model organization\n",
    "2. ✓ **HMS Content**: 7 storm frequencies + sensitivity analysis\n",
    "3. ✓ **DSS Exploration**: HMS-generated streamflow hydrographs\n",
    "4. ✓ **Documentation**: BLE reports and metadata\n",
    "5. ✓ **Agent Log**: Complete organization documentation\n",
    "6. ⚠️ **RAS Integration**: Requires manual extraction (large nested zip)\n",
    "\n",
    "**Pattern 4 Characteristics**:\n",
    "- Most complex pattern (HMS + RAS)\n",
    "- Multiple storm frequencies (10yr through 500yr)\n",
    "- Sensitivity analysis (100yr_Min, 100yr_Plus)\n",
    "- Large nested RAS zip may require manual extraction\n",
    "- Coastal flood analysis (hurricane surge)\n",
    "\n",
    "**HMS → RAS Workflow**:\n",
    "```\n",
    "HEC-HMS (precipitation → streamflow)\n",
    "   ↓ DSS files\n",
    "HEC-RAS (streamflow → inundation)\n",
    "```\n",
    "\n",
    "**Next Steps**:\n",
    "- Extract RAS_Submittal.zip manually (6.1 GB)\n",
    "- Initialize RAS model with ras-commander\n",
    "- Run compute test to validate HMS → RAS workflow\n",
    "- Extract and visualize coastal inundation results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}