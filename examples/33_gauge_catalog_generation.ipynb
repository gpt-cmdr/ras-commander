{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 33: USGS Gauge Catalog Generation\n",
    "\n",
    "This notebook demonstrates how to generate and use a standardized USGS gauge data catalog for your HEC-RAS project.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The gauge catalog generation function creates a standardized \"USGS Gauge Data\" folder (similar to the precipitation module's storm catalog) that:\n",
    "- Discovers all active USGS gauges within project extent\n",
    "- Downloads historical data for each gauge\n",
    "- Creates master catalog for easy gauge discovery\n",
    "- Provides standard location for engineering review and downstream functions\n",
    "\n",
    "## Key Functions\n",
    "\n",
    "- `generate_gauge_catalog()`: Create complete gauge catalog with metadata and data\n",
    "- `load_gauge_catalog()`: Load gauge catalog from standard location\n",
    "- `load_gauge_data()`: Load historical data for specific gauge\n",
    "- `get_gauge_folder()`: Get path to gauge folder\n",
    "- `update_gauge_catalog()`: Refresh catalog with latest data\n",
    "\n",
    "## Example Project\n",
    "\n",
    "We'll use the **Bald Eagle Creek** example project which has 2 active USGS gauges:\n",
    "- USGS-01547200: Upstream gauge (265 sq mi drainage)\n",
    "- USGS-01548005: Downstream gauge (562 sq mi drainage)\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "Requires: `pip install dataretrieval geopandas tqdm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DEVELOPMENT MODE TOGGLE\n# =============================================================================\nUSE_LOCAL_SOURCE = False  # <-- TOGGLE THIS\n\nif USE_LOCAL_SOURCE:\n    import sys\n    from pathlib import Path\n    local_path = str(Path.cwd().parent)\n    if local_path not in sys.path:\n        sys.path.insert(0, local_path)\n    print(f\"\ud83d\udcc1 LOCAL SOURCE MODE: Loading from {local_path}/ras_commander\")\nelse:\n    print(\"\ud83d\udce6 PIP PACKAGE MODE: Loading installed ras-commander\")\n\n# Import ras-commander\nfrom ras_commander import init_ras_project, ras, RasExamples\nfrom ras_commander.usgs import (\n    generate_gauge_catalog,\n    load_gauge_catalog,\n    load_gauge_data,\n    get_gauge_folder,\n    update_gauge_catalog\n)\n\n# Additional imports\nimport pandas as pd\nimport json\n\n# Verify which version loaded\nimport ras_commander\nprint(f\"\u2713 Loaded: {ras_commander.__file__}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 2. USGS API Key (Optional but Recommended)\n\n### Rate Limits\n\nUSGS API has different rate limits depending on whether you have an API key:\n\n| Tier | Rate Limit | Use Case |\n|------|------------|----------|\n| **Without API key** | ~5 requests/sec | Most users (default) |\n| **With free API key** | ~10 requests/sec | Faster processing |\n\n### Getting a Free API Key\n\nSign up for instant approval (no review process):\n\n**https://api.waterdata.usgs.gov/signup/**\n\n### Using an API Key\n\n```python\nfrom ras_commander.usgs import test_api_key\n\n# Test your API key (replace with your actual key)\napi_key = \"YOUR_API_KEY_HERE\"\n\nif test_api_key(api_key):\n    print(\"API key is valid!\")\n    # Use with generate_gauge_catalog\n    summary = generate_gauge_catalog(\n        api_key=api_key,\n        rate_limit_rps=10.0  # Faster rate with API key\n    )\nelse:\n    print(\"API key is invalid - will use slower rate (5 req/sec)\")\n```\n\n### Note\n\n**This notebook runs without an API key** using the default 5 req/sec rate limit.  \nIf you have an API key, you can add it to the cells below for faster processing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIONAL: Test USGS API Key\n",
    "# =============================================================================\n",
    "# Uncomment and add your API key to test it before use\n",
    "\n",
    "USE_API_KEY = False  # Set to True to use API key\n",
    "\n",
    "if USE_API_KEY:\n",
    "    from ras_commander.usgs import test_api_key\n",
    "    \n",
    "    # Replace with your actual API key from https://api.waterdata.usgs.gov/signup/\n",
    "    api_key = \"YOUR_API_KEY_HERE\"\n",
    "    \n",
    "    print(\"Testing USGS API key...\")\n",
    "    if test_api_key(api_key):\n",
    "        print(\"SUCCESS: API key is valid and functional!\")\n",
    "        print(f\"You can now use rate_limit_rps=10.0 for faster processing\")\n",
    "    else:\n",
    "        print(\"FAILED: API key validation failed\")\n",
    "        print(\"Will use default rate (5 req/sec) without API key\")\n",
    "        api_key = None\n",
    "else:\n",
    "    api_key = None\n",
    "    print(\"Running without API key (5 req/sec rate limit)\")\n",
    "    print(\"Get a free API key at: https://api.waterdata.usgs.gov/signup/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Example Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract Bald Eagle Creek project\nproject_path = RasExamples.extract_project(\"Balde Eagle Creek\", output_path=\"example_projects_33_gauge_catalog_generation\")\n\nprint(f\"Project extracted to: {project_path}\")\n\n# Initialize project\ninit_ras_project(project_path, \"6.6\")\n\nprint(f\"\\nProject: {ras.project_name}\")\nprint(f\"Path: {ras.project_path}\")\nprint(f\"\\nProject initialized successfully\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Gauge Catalog\n",
    "\n",
    "This will:\n",
    "1. Find all USGS gauges within 50% buffer of project extent\n",
    "2. Download 10 years of historical data (flow and stage)\n",
    "3. Create standardized folder structure\n",
    "4. Generate master catalog and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate catalog with default settings\n",
    "# Note: If USE_API_KEY=True above, this will use the validated API key\n",
    "summary = generate_gauge_catalog(\n",
    "    buffer_percent=50.0,         # Search within 50% buffer of project extent\n",
    "    include_historical=True,     # Download historical data\n",
    "    historical_years=10,         # Last 10 years of data\n",
    "    parameters=['flow', 'stage'],  # Retrieve flow and stage data\n",
    "    api_key=api_key,             # Use API key if provided (None otherwise)\n",
    "    rate_limit_rps=10.0 if api_key else 5.0  # 10 req/sec with key, 5 without\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "print(\"\n\" + \"=\"*60)\n",
    "print(\"GAUGE CATALOG GENERATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Gauges found: {summary['gauge_count']}\")\n",
    "print(f\"Successfully processed: {summary['gauges_processed']}\")\n",
    "print(f\"Failed: {summary['gauges_failed']}\")\n",
    "print(f\"Output folder: {summary['output_folder']}\")\n",
    "print(f\"Data size: {summary['data_size_mb']:.2f} MB\")\n",
    "print(f\"Processing time: {summary['processing_time_sec']:.1f} seconds\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Catalog Structure\n",
    "\n",
    "The catalog creates a standardized folder structure:\n",
    "\n",
    "```\n",
    "project_folder/\n",
    "\u251c\u2500\u2500 USGS Gauge Data/\n",
    "\u2502   \u251c\u2500\u2500 gauge_catalog.csv          # Master catalog\n",
    "\u2502   \u251c\u2500\u2500 gauge_locations.geojson    # Spatial data\n",
    "\u2502   \u251c\u2500\u2500 README.md                  # Documentation\n",
    "\u2502   \u251c\u2500\u2500 USGS-01547200/             # Individual gauge folders\n",
    "\u2502   \u2502   \u251c\u2500\u2500 metadata.json\n",
    "\u2502   \u2502   \u251c\u2500\u2500 historical_flow.csv\n",
    "\u2502   \u2502   \u251c\u2500\u2500 historical_stage.csv\n",
    "\u2502   \u2502   \u2514\u2500\u2500 data_availability.json\n",
    "\u2502   \u2514\u2500\u2500 USGS-01548005/\n",
    "\u2502       \u2514\u2500\u2500 ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in catalog folder\n",
    "catalog_folder = Path(ras.project_path) / \"USGS Gauge Data\"\n",
    "\n",
    "print(\"Catalog folder contents:\")\n",
    "print(\"\\nTop-level files:\")\n",
    "for file in sorted(catalog_folder.glob('*')):\n",
    "    if file.is_file():\n",
    "        size_kb = file.stat().st_size / 1024\n",
    "        print(f\"  {file.name:30s} ({size_kb:8.1f} KB)\")\n",
    "\n",
    "print(\"\\nGauge folders:\")\n",
    "for folder in sorted(catalog_folder.glob('USGS-*')):\n",
    "    if folder.is_dir():\n",
    "        file_count = len(list(folder.glob('*')))\n",
    "        print(f\"  {folder.name:30s} ({file_count} files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Explore Master Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog using helper function\n",
    "catalog = load_gauge_catalog()\n",
    "\n",
    "print(f\"Loaded catalog with {len(catalog)} gauges\\n\")\n",
    "\n",
    "# Display key information\n",
    "print(\"Gauge Catalog:\")\n",
    "print(\"-\" * 120)\n",
    "display_cols = ['site_id', 'station_name', 'drainage_area_sqmi', 'upstream_downstream', \n",
    "                'distance_to_project_km', 'parameters_available']\n",
    "print(catalog[display_cols].to_string(index=False))\n",
    "print(\"-\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Gauge Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata for first gauge\n",
    "site_id = catalog.iloc[0]['site_id']\n",
    "gauge_folder = get_gauge_folder(site_id)\n",
    "metadata_file = gauge_folder / \"metadata.json\"\n",
    "\n",
    "with open(metadata_file, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Metadata for USGS-{site_id}:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Station: {metadata['station_name']}\")\n",
    "print(f\"Location: {metadata['location']['latitude']:.4f}, {metadata['location']['longitude']:.4f}\")\n",
    "print(f\"State: {metadata['location']['state']}\")\n",
    "print(f\"County: {metadata['location']['county']}\")\n",
    "print(f\"Drainage Area: {metadata['drainage_area_sqmi']} sq mi\")\n",
    "print(f\"Gage Datum: {metadata['gage_datum_ft']} ft\")\n",
    "print(f\"Active: {metadata['active']}\")\n",
    "print(f\"\\nAvailable Parameters: {', '.join(metadata['available_parameters'])}\")\n",
    "print(f\"\\nPeriod of Record:\")\n",
    "print(f\"  Start: {metadata['period_of_record']['start']}\")\n",
    "print(f\"  End: {metadata['period_of_record']['end']}\")\n",
    "print(f\"  Years: {metadata['period_of_record']['years']}\")\n",
    "print(f\"\\nLast Updated: {metadata['last_updated']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Load Data Availability Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data availability for first gauge\n",
    "availability_file = gauge_folder / \"data_availability.json\"\n",
    "\n",
    "with open(availability_file, 'r') as f:\n",
    "    availability = json.load(f)\n",
    "\n",
    "print(f\"Data Availability for USGS-{site_id}:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for param, info in availability.items():\n",
    "    print(f\"\\n{param.upper()}:\")\n",
    "    print(f\"  Available: {info['available']}\")\n",
    "    if info['available']:\n",
    "        print(f\"  Date Range: {info['start_date']} to {info['end_date']}\")\n",
    "        print(f\"  Record Count: {info['record_count']:,}\")\n",
    "        print(f\"  Completeness: {info['completeness']*100:.1f}%\")\n",
    "        if info['gaps']:\n",
    "            print(f\"  Gaps Found: {len(info['gaps'])}\")\n",
    "            for gap in info['gaps'][:3]:  # Show first 3 gaps\n",
    "                print(f\"    - {gap['start']} to {gap['end']} ({gap['days']} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Historical Data Using Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flow data for first gauge\n",
    "flow_data = load_gauge_data(site_id, parameter='flow')\n",
    "\n",
    "print(f\"Flow Data for USGS-{site_id}:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Records: {len(flow_data):,}\")\n",
    "print(f\"Date Range: {flow_data['datetime'].min()} to {flow_data['datetime'].max()}\")\n",
    "print(f\"\\nFlow Statistics:\")\n",
    "print(f\"  Mean: {flow_data['value'].mean():.1f} cfs\")\n",
    "print(f\"  Median: {flow_data['value'].median():.1f} cfs\")\n",
    "print(f\"  Min: {flow_data['value'].min():.1f} cfs\")\n",
    "print(f\"  Max: {flow_data['value'].max():.1f} cfs\")\n",
    "print(f\"\\nFirst 5 records:\")\n",
    "print(flow_data.head())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stage data\n",
    "stage_data = load_gauge_data(site_id, parameter='stage')\n",
    "\n",
    "print(f\"Stage Data for USGS-{site_id}:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Records: {len(stage_data):,}\")\n",
    "print(f\"Date Range: {stage_data['datetime'].min()} to {stage_data['datetime'].max()}\")\n",
    "print(f\"\\nStage Statistics:\")\n",
    "print(f\"  Mean: {stage_data['value'].mean():.2f} ft\")\n",
    "print(f\"  Median: {stage_data['value'].median():.2f} ft\")\n",
    "print(f\"  Min: {stage_data['value'].min():.2f} ft\")\n",
    "print(f\"  Max: {stage_data['value'].max():.2f} ft\")\n",
    "print(f\"\\nFirst 5 records:\")\n",
    "print(stage_data.head())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n# Create figure with 2 subplots\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n\n# Plot flow\nax1.plot(flow_data['datetime'], flow_data['value'], 'b-', linewidth=0.8, alpha=0.7)\nax1.set_ylabel('Flow (cfs)', fontsize=12, fontweight='bold')\nax1.set_title(f\"USGS-{site_id}: {metadata['station_name']}\", fontsize=14, fontweight='bold')\nax1.grid(True, alpha=0.3)\nax1.set_ylim(bottom=0)\n\n# Plot stage\nax2.plot(stage_data['datetime'], stage_data['value'], 'g-', linewidth=0.8, alpha=0.7)\nax2.set_ylabel('Stage (ft)', fontsize=12, fontweight='bold')\nax2.set_xlabel('Date', fontsize=12, fontweight='bold')\nax2.grid(True, alpha=0.3)\nax2.set_ylim(bottom=0)\n\n# Format x-axis\nax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\nax2.xaxis.set_major_locator(mdates.YearLocator())\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nPlot shows 10 years of flow and stage data for USGS-{site_id}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Process All Gauges in Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics for all gauges\nprint(\"Summary for all gauges:\")\nprint(\"=\"*80)\n\nfor idx, gauge in catalog.iterrows():\n    site_id = gauge['site_id']\n    name = gauge['station_name']\n    drainage = gauge['drainage_area_sqmi']\n    position = gauge['upstream_downstream']\n    distance = gauge['distance_to_project_km']\n    \n    print(f\"\\nUSGS-{site_id}: {name}\")\n    print(f\"  Position: {position.title()} ({distance:.1f} km from project)\")\n    print(f\"  Drainage: {drainage} sq mi\")\n    \n    # Check if flow data file exists before loading\n    gauge_folder = get_gauge_folder(site_id)\n    flow_file = gauge_folder / \"historical_flow.csv\"\n    \n    if flow_file.exists():\n        flow = load_gauge_data(site_id, parameter='flow')\n        print(f\"  Flow: {len(flow):,} records, mean={flow['value'].mean():.0f} cfs, max={flow['value'].max():.0f} cfs\")\n    else:\n        print(f\"  Flow: No data available\")\n    \n    # Check if stage data file exists before loading\n    stage_file = gauge_folder / \"historical_stage.csv\"\n    \n    if stage_file.exists():\n        stage = load_gauge_data(site_id, parameter='stage')\n        print(f\"  Stage: {len(stage):,} records, mean={stage['value'].mean():.2f} ft, max={stage['value'].max():.2f} ft\")\n    else:\n        print(f\"  Stage: No data available\")\n\nprint(\"\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Use Catalog Data for Boundary Conditions\n",
    "\n",
    "The catalog data can be easily used with other USGS functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ras_commander.usgs import generate_flow_hydrograph_table\n",
    "\n",
    "# Select upstream gauge for BC generation\n",
    "upstream_gauge = catalog[catalog['upstream_downstream'] == 'upstream'].iloc[0]\n",
    "site_id = upstream_gauge['site_id']\n",
    "\n",
    "print(f\"Using USGS-{site_id} for boundary condition:\")\n",
    "print(f\"  Station: {upstream_gauge['station_name']}\")\n",
    "print(f\"  Drainage: {upstream_gauge['drainage_area_sqmi']} sq mi\\n\")\n",
    "\n",
    "# Load flow data\n",
    "flow = load_gauge_data(site_id, parameter='flow')\n",
    "\n",
    "# Get last 7 days (168 hours)\n",
    "recent_flow = flow.tail(168).copy()\n",
    "\n",
    "print(f\"Using last {len(recent_flow)} hourly values for BC\")\n",
    "print(f\"Date range: {recent_flow['datetime'].min()} to {recent_flow['datetime'].max()}\")\n",
    "print(f\"Flow range: {recent_flow['value'].min():.0f} to {recent_flow['value'].max():.0f} cfs\\n\")\n",
    "\n",
    "# Generate HEC-RAS format hydrograph table\n",
    "bc_table = generate_flow_hydrograph_table(\n",
    "    flow_values=recent_flow['value'],\n",
    "    interval='1HOUR'\n",
    ")\n",
    "\n",
    "print(\"Generated boundary condition table:\")\n",
    "print(bc_table[:500])  # Show first 500 characters\n",
    "print(f\"\\n... ({len(bc_table)} characters total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Update Catalog (Add New Data)\n",
    "\n",
    "The `update_gauge_catalog()` function refreshes existing gauges with new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update catalog with latest data (last 30 days)\n",
    "update_summary = update_gauge_catalog()\n",
    "\n",
    "print(\"\\nCatalog Update Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Gauges updated: {update_summary['gauges_updated']}\")\n",
    "print(f\"Gauges failed: {update_summary['gauges_failed']}\")\n",
    "print(f\"Processing time: {update_summary['processing_time_sec']:.1f} seconds\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Custom Catalog Configuration\n",
    "\n",
    "You can customize the catalog generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate catalog with custom settings\n",
    "# (Don't run this cell if you want to keep existing catalog)\n",
    "\n",
    "if False:  # Set to True to run\n",
    "    custom_summary = generate_gauge_catalog(\n",
    "        buffer_percent=100.0,        # Wider search area (2x project extent)\n",
    "        include_historical=True,\n",
    "        historical_years=20,         # More historical data\n",
    "        parameters=['flow', 'stage', 'temperature'],  # Additional parameters\n",
    "        output_folder=None           # Use default location\n",
    "    )\n",
    "    \n",
    "    print(\"Custom catalog generated:\")\n",
    "    print(f\"  Gauges: {custom_summary['gauge_count']}\")\n",
    "    print(f\"  Data size: {custom_summary['data_size_mb']:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. \u2705 **Catalog Generation**: One-command gauge discovery and data download\n",
    "2. \u2705 **Standard Structure**: Consistent folder organization across projects\n",
    "3. \u2705 **Metadata Management**: Complete gauge information in JSON format\n",
    "4. \u2705 **Data Loading**: Easy access to historical gauge data\n",
    "5. \u2705 **Integration**: Seamless use with boundary condition generation\n",
    "6. \u2705 **Updates**: Refresh catalog with latest data\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Standard Location**: `project_folder/USGS Gauge Data/` (like precipitation module)\n",
    "- **One Command**: `generate_gauge_catalog()` does everything\n",
    "- **Engineering Review**: Master catalog CSV for easy gauge assessment\n",
    "- **Downstream Functions**: Standard location for automated workflows\n",
    "- **Documentation**: Auto-generated README with usage instructions\n",
    "\n",
    "## Related Examples\n",
    "\n",
    "- Example 29: USGS Gauge Data Integration (basic retrieval)\n",
    "- Example 30: Real-Time Monitoring (live gauge data)\n",
    "- Example 31: BC Generation from Live Gauge (boundary conditions)\n",
    "- Example 32: Model Validation with USGS (calibration metrics)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "With the catalog generated, you can:\n",
    "- Review all available gauges in one location\n",
    "- Use gauge data for boundary condition generation\n",
    "- Perform model validation with observed data\n",
    "- Include catalog in project deliverables for documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}