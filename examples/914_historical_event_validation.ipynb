{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Event Validation with AORC Precipitation and USGS Gauges\n",
    "\n",
    "This notebook demonstrates a comprehensive historical flood event validation workflow using:\n",
    "- AORC gridded precipitation (rain-on-grid on 2D mesh)\n",
    "- USGS gauge data for boundary conditions\n",
    "- Multiple validation points\n",
    "- HUC12 watershed coverage analysis\n",
    "\n",
    "**Event**: December 24-25, 2020 storm (2.72 inches, largest 2020 event)\n",
    "**Model**: Bald Eagle Creek Multi-2D  \n",
    "**Template**: Plan 06 (gridded precipitation enabled)\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. Extract and initialize HEC-RAS project (BaldEagleCrkMulti2D)\n",
    "2. Get project bounds and HUC12 watershed coverage analysis\n",
    "3. Download AORC precipitation data for storm event\n",
    "4. Retrieve USGS gauge data for boundary conditions\n",
    "5. Clone plan and configure for storm simulation\n",
    "6. Run HEC-RAS model\n",
    "7. Extract modeled results and compare with observed USGS data\n",
    "8. Calculate validation metrics and generate comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Flexible imports for development vs installed package\n",
    "try:\n",
    "    from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, ras\n",
    "    from ras_commander.hdf import HdfProject, HdfMesh, HdfResultsXsec, HdfResultsMesh\n",
    "    from ras_commander.precip import PrecipAorc\n",
    "    from ras_commander.usgs import (\n",
    "        get_gauge_metadata,\n",
    "        retrieve_flow_data,\n",
    "        retrieve_stage_data,\n",
    "        align_timeseries,\n",
    "        calculate_all_metrics,\n",
    "        plot_timeseries_comparison,\n",
    "        plot_scatter_comparison,\n",
    "        configure_rate_limit\n",
    "    )\n",
    "except ImportError:\n",
    "    current_file = Path.cwd()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.insert(0, str(parent_directory))\n",
    "    from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, ras\n",
    "    from ras_commander.hdf import HdfProject, HdfMesh, HdfResultsXsec, HdfResultsMesh\n",
    "    from ras_commander.precip import PrecipAorc\n",
    "    from ras_commander.usgs import (\n",
    "        get_gauge_metadata,\n",
    "        retrieve_flow_data,\n",
    "        retrieve_stage_data,\n",
    "        align_timeseries,\n",
    "        calculate_all_metrics,\n",
    "        plot_timeseries_comparison,\n",
    "        plot_scatter_comparison,\n",
    "        configure_rate_limit\n",
    "    )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# API KEY SETUP\n",
    "# =============================================================================\n",
    "# USGS API key provides higher rate limits (5 req/sec vs 0.2 req/sec)\n",
    "api_key_file = Path(\"usgs_api_key.txt\")\n",
    "\n",
    "if api_key_file.exists():\n",
    "    usgs_api_key = api_key_file.read_text().strip()\n",
    "    configure_rate_limit(requests_per_second=5.0)\n",
    "    print(f\"USGS API key loaded - configured rate limit: 5.0 req/sec\")\n",
    "else:\n",
    "    usgs_api_key = None\n",
    "    print(\"No API key file found - using public access (0.2 req/sec)\")\n",
    "    print(\"To get higher rate limits, create usgs_api_key.txt with your USGS API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PARAMETERS\n",
    "# =============================================================================\n",
    "PROJECT_NAME = \"BaldEagleCrkMulti2D\"\n",
    "TEMPLATE_PLAN = \"06\"  # Plan with gridded precipitation enabled\n",
    "STORM_DATE = \"20201224\"  # December 24-25, 2020 storm\n",
    "\n",
    "# Simulation period (48h warmup + event + 48h recession)\n",
    "SIM_START = \"2020-12-22\"\n",
    "SIM_END = \"2020-12-27\"\n",
    "\n",
    "# USGS Gauges in Bald Eagle Creek watershed\n",
    "# 01547500 - Bald Eagle Creek at Blanchard, PA (upstream BC)\n",
    "# 01548005 - Beech Creek Station (validation point + downstream BC)\n",
    "UPSTREAM_GAUGE = \"01547500\"\n",
    "VALIDATION_GAUGE = \"01548005\"\n",
    "\n",
    "# HEC-RAS version\n",
    "RAS_VERSION = \"6.6\"\n",
    "\n",
    "print(f\"Project: {PROJECT_NAME}\")\n",
    "print(f\"Template Plan: {TEMPLATE_PLAN}\")\n",
    "print(f\"Storm Date: {STORM_DATE}\")\n",
    "print(f\"Simulation Period: {SIM_START} to {SIM_END}\")\n",
    "print(f\"Upstream BC Gauge: {UPSTREAM_GAUGE}\")\n",
    "print(f\"Validation Gauge: {VALIDATION_GAUGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT AND INITIALIZE PROJECT\n",
    "# =============================================================================\n",
    "# Check if project with suffix already exists\n",
    "suffix = \"914_historical\"\n",
    "expected_folder = Path.cwd() / \"example_projects\" / f\"{PROJECT_NAME}_{suffix}\"\n",
    "\n",
    "if expected_folder.exists():\n",
    "    print(f\"Project folder already exists: {expected_folder}\")\n",
    "    project_folder = expected_folder\n",
    "else:\n",
    "    # Extract project with unique suffix for this analysis\n",
    "    project_folder = RasExamples.extract_project(PROJECT_NAME, suffix=suffix)\n",
    "    print(f\"Project extracted to: {project_folder}\")\n",
    "\n",
    "# Initialize project\n",
    "ras = init_ras_project(project_folder, RAS_VERSION)\n",
    "print(f\"Project initialized\")\n",
    "\n",
    "# Display available plans\n",
    "print(f\"\\nAvailable plans:\")\n",
    "print(ras.plan_df[['plan_number', 'Plan Title']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GET PROJECT BOUNDS FOR AORC DOWNLOAD\n",
    "# =============================================================================\n",
    "# Find geometry HDF file\n",
    "geom_hdf_files = list(project_folder.glob(\"*.g*.hdf\"))\n",
    "print(f\"Found geometry HDF files: {[f.name for f in geom_hdf_files]}\")\n",
    "\n",
    "# Use the most appropriate geometry file (typically highest number with 2D areas)\n",
    "geom_hdf = None\n",
    "for f in sorted(geom_hdf_files, reverse=True):\n",
    "    if f.suffix == '.hdf' and '.g' in f.name:\n",
    "        geom_hdf = f\n",
    "        break\n",
    "\n",
    "if geom_hdf is None:\n",
    "    raise FileNotFoundError(\"No geometry HDF file found\")\n",
    "\n",
    "print(f\"\\nUsing geometry HDF: {geom_hdf.name}\")\n",
    "\n",
    "# Get project bounds in WGS84 for AORC download\n",
    "# Use 50% buffer to capture upstream precipitation areas\n",
    "bounds = HdfProject.get_project_bounds_latlon(\n",
    "    geom_hdf, \n",
    "    buffer_percent=50.0,\n",
    "    project_crs=\"EPSG:26918\"  # UTM Zone 18N for Pennsylvania\n",
    ")\n",
    "\n",
    "print(f\"\\nProject bounds (WGS84 with 50% buffer):\")\n",
    "print(f\"  West:  {bounds[0]:.4f}\")\n",
    "print(f\"  South: {bounds[1]:.4f}\")\n",
    "print(f\"  East:  {bounds[2]:.4f}\")\n",
    "print(f\"  North: {bounds[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD HUC12 WATERSHED FOR COVERAGE ANALYSIS\n",
    "# =============================================================================\n",
    "try:\n",
    "    from pygeohydro import WBD\n",
    "    \n",
    "    # Get mesh areas for centroid calculation\n",
    "    mesh_areas = HdfMesh.get_mesh_areas(geom_hdf)\n",
    "    print(f\"Found {len(mesh_areas)} 2D flow areas\")\n",
    "    \n",
    "    # Calculate centroid of 2D mesh in WGS84\n",
    "    mesh_wgs84 = mesh_areas.to_crs(\"EPSG:4326\")\n",
    "    centroid = mesh_wgs84.geometry.unary_union.centroid\n",
    "    print(f\"\\nModel centroid: {centroid.y:.4f}N, {centroid.x:.4f}W\")\n",
    "    \n",
    "    # Download HUC12 watershed containing centroid\n",
    "    wbd = WBD(\"huc12\")\n",
    "    huc12 = wbd.bygeom(Point(centroid.x, centroid.y), geo_crs=\"EPSG:4326\")\n",
    "    \n",
    "    print(f\"\\nHUC12 Watershed:\")\n",
    "    print(f\"  HUC ID: {huc12.iloc[0]['huc12']}\")\n",
    "    print(f\"  Name: {huc12.iloc[0]['name']}\")\n",
    "    print(f\"  Area: {huc12.iloc[0]['areasqkm']:.1f} sq km ({huc12.iloc[0]['areasqkm'] * 0.386102:.1f} sq mi)\")\n",
    "    \n",
    "    HUC12_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"pygeohydro not available - skipping HUC12 analysis\")\n",
    "    print(\"Install with: pip install pygeohydro\")\n",
    "    HUC12_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading HUC12: {e}\")\n",
    "    HUC12_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE DRAINAGE COVERAGE\n",
    "# =============================================================================\n",
    "if HUC12_AVAILABLE and 'huc12' in dir():\n",
    "    # Use equal-area projection for accurate area calculations\n",
    "    # EPSG:5070 (Albers Equal Area Conic) is standard for US applications\n",
    "    equal_area_crs = \"EPSG:5070\"\n",
    "    \n",
    "    # Project mesh areas to equal-area CRS for accurate area calculation\n",
    "    mesh_areas_proj = mesh_areas.to_crs(equal_area_crs)\n",
    "    mesh_total_area_sqkm = mesh_areas_proj.geometry.area.sum() / 1e6  # m^2 to km^2\n",
    "    \n",
    "    # Use reported area from WBD (already accurate from USGS)\n",
    "    huc12_area_sqkm = huc12.iloc[0]['areasqkm']\n",
    "    \n",
    "    # Calculate coverage percentage\n",
    "    coverage_pct = (mesh_total_area_sqkm / huc12_area_sqkm) * 100\n",
    "    unmodeled_area_sqkm = huc12_area_sqkm - mesh_total_area_sqkm\n",
    "    \n",
    "    print(\"Drainage Coverage Analysis:\")\n",
    "    print(f\"  2D Mesh Area: {mesh_total_area_sqkm:.2f} sq km ({mesh_total_area_sqkm * 0.386102:.2f} sq mi)\")\n",
    "    print(f\"  HUC12 Area: {huc12_area_sqkm:.2f} sq km ({huc12_area_sqkm * 0.386102:.2f} sq mi)\")\n",
    "    print(f\"  Coverage: {coverage_pct:.1f}%\")\n",
    "    print(f\"  Unmodeled Area: {unmodeled_area_sqkm:.2f} sq km ({unmodeled_area_sqkm * 0.386102:.2f} sq mi)\")\n",
    "    \n",
    "    if coverage_pct < 80:\n",
    "        print(f\"\\nWARNING: Model covers only {coverage_pct:.1f}% of HUC12 drainage area\")\n",
    "        print(\"  Expect validation discrepancies due to unmodeled runoff contributions\")\n",
    "else:\n",
    "    print(\"HUC12 not available - skipping coverage analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE COVERAGE FIGURE\n",
    "# =============================================================================\n",
    "if HUC12_AVAILABLE and 'huc12' in dir():\n",
    "    # Use projected CRS for proper visualization\n",
    "    vis_crs = \"EPSG:5070\"  # Albers Equal Area Conic\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Project all data to visualization CRS\n",
    "    huc12_proj = huc12.to_crs(vis_crs)\n",
    "    mesh_areas_vis = mesh_areas.to_crs(vis_crs)\n",
    "    \n",
    "    # Plot HUC12 boundary\n",
    "    huc12_proj.plot(ax=ax, facecolor='lightblue', edgecolor='blue', linewidth=2, alpha=0.3, label='HUC12 Watershed')\n",
    "    \n",
    "    # Plot 2D mesh areas\n",
    "    mesh_areas_vis.plot(ax=ax, facecolor='green', edgecolor='darkgreen', linewidth=1, alpha=0.5, label='2D Flow Areas')\n",
    "    \n",
    "    # Add USGS gauge locations if we can retrieve them\n",
    "    try:\n",
    "        upstream_meta = get_gauge_metadata(UPSTREAM_GAUGE)\n",
    "        validation_meta = get_gauge_metadata(VALIDATION_GAUGE)\n",
    "        \n",
    "        # Create gauge points in WGS84\n",
    "        gauge_points = gpd.GeoDataFrame([\n",
    "            {'site_id': UPSTREAM_GAUGE, 'name': upstream_meta['station_name'], \n",
    "             'geometry': Point(upstream_meta['longitude'], upstream_meta['latitude']), 'role': 'Upstream BC'},\n",
    "            {'site_id': VALIDATION_GAUGE, 'name': validation_meta['station_name'],\n",
    "             'geometry': Point(validation_meta['longitude'], validation_meta['latitude']), 'role': 'Validation'}\n",
    "        ], crs=\"EPSG:4326\")\n",
    "        \n",
    "        # Transform to visualization CRS\n",
    "        gauge_points_proj = gauge_points.to_crs(vis_crs)\n",
    "        \n",
    "        # Plot gauges with different colors\n",
    "        for idx, row in gauge_points_proj.iterrows():\n",
    "            color = 'red' if row['role'] == 'Upstream BC' else 'orange'\n",
    "            ax.scatter(row.geometry.x, row.geometry.y, c=color, s=150, marker='^', \n",
    "                      edgecolors='black', linewidths=1.5, zorder=5)\n",
    "            ax.annotate(f\"{row['site_id']}\\n({row['role']})\", \n",
    "                       (row.geometry.x, row.geometry.y), \n",
    "                       xytext=(10, 10), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not add gauge locations: {e}\")\n",
    "    \n",
    "    ax.set_title(f\"Drainage Coverage Analysis\\n{PROJECT_NAME} - HUC12: {huc12.iloc[0]['huc12']}\", fontsize=14)\n",
    "    ax.set_xlabel('Easting (m)')\n",
    "    ax.set_ylabel('Northing (m)')\n",
    "    \n",
    "    # Add coverage annotation\n",
    "    ax.annotate(f\"Coverage: {coverage_pct:.1f}%\\nUnmodeled: {unmodeled_area_sqkm:.1f} sq km\",\n",
    "               xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10,\n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(project_folder / \"coverage_analysis.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nCoverage figure saved to: {project_folder / 'coverage_analysis.png'}\")\n",
    "else:\n",
    "    print(\"Skipping coverage figure (HUC12 not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD AORC PRECIPITATION DATA\n",
    "# =============================================================================\n",
    "# Create precipitation folder\n",
    "precip_folder = project_folder / \"Precipitation\"\n",
    "precip_folder.mkdir(exist_ok=True)\n",
    "\n",
    "aorc_file = precip_folder / f\"storm_{STORM_DATE}.nc\"\n",
    "\n",
    "print(f\"Downloading AORC precipitation data...\")\n",
    "print(f\"  Start: {SIM_START} 00:00\")\n",
    "print(f\"  End: {SIM_END} 00:00\")\n",
    "print(f\"  Output: {aorc_file}\")\n",
    "\n",
    "try:\n",
    "    output_path = PrecipAorc.download(\n",
    "        bounds=bounds,\n",
    "        start_time=f\"{SIM_START} 00:00\",\n",
    "        end_time=f\"{SIM_END} 00:00\",\n",
    "        output_path=aorc_file,\n",
    "        target_crs=\"EPSG:5070\",  # SHG (Standard Hydrologic Grid) for HEC-RAS\n",
    "        resolution=2000.0  # 2km resolution (standard SHG)\n",
    "    )\n",
    "    print(f\"\\nAORC data downloaded successfully: {output_path}\")\n",
    "    \n",
    "    # Get file size\n",
    "    file_size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError downloading AORC data: {e}\")\n",
    "    print(\"Continuing with workflow - manual precipitation setup may be needed\")\n",
    "    aorc_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RETRIEVE USGS UPSTREAM BOUNDARY CONDITION DATA\n",
    "# =============================================================================\n",
    "print(f\"Retrieving upstream BC flow data from gauge {UPSTREAM_GAUGE}...\")\n",
    "\n",
    "# Get gauge metadata\n",
    "upstream_meta = get_gauge_metadata(UPSTREAM_GAUGE)\n",
    "print(f\"  Station: {upstream_meta['station_name']}\")\n",
    "print(f\"  Drainage area: {upstream_meta.get('drainage_area_sqmi', 'N/A')} sq mi\")\n",
    "\n",
    "# Retrieve flow data for simulation period\n",
    "upstream_flow = retrieve_flow_data(\n",
    "    site_id=UPSTREAM_GAUGE,\n",
    "    start_datetime=SIM_START,\n",
    "    end_datetime=SIM_END,\n",
    "    data_type='iv'  # Instantaneous values\n",
    ")\n",
    "\n",
    "# Remove timezone to match HEC-RAS (timezone-naive)\n",
    "upstream_flow['datetime'] = pd.to_datetime(upstream_flow['datetime']).dt.tz_localize(None)\n",
    "\n",
    "print(f\"\\nRetrieved {len(upstream_flow)} records\")\n",
    "print(f\"  Period: {upstream_flow['datetime'].min()} to {upstream_flow['datetime'].max()}\")\n",
    "print(f\"  Flow range: {upstream_flow['value'].min():.0f} to {upstream_flow['value'].max():.0f} cfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RETRIEVE USGS VALIDATION DATA\n",
    "# =============================================================================\n",
    "print(f\"Retrieving validation data from gauge {VALIDATION_GAUGE}...\")\n",
    "\n",
    "# Get gauge metadata\n",
    "try:\n",
    "    validation_meta = get_gauge_metadata(VALIDATION_GAUGE)\n",
    "    print(f\"  Station: {validation_meta['station_name']}\")\n",
    "    print(f\"  Drainage area: {validation_meta.get('drainage_area_sqmi', 'N/A')} sq mi\")\n",
    "except Exception as e:\n",
    "    print(f\"  Could not retrieve metadata: {e}\")\n",
    "    validation_meta = {'station_name': f'USGS {VALIDATION_GAUGE}'}\n",
    "\n",
    "# Retrieve flow data for validation\n",
    "try:\n",
    "    validation_flow = retrieve_flow_data(\n",
    "        site_id=VALIDATION_GAUGE,\n",
    "        start_datetime=SIM_START,\n",
    "        end_datetime=SIM_END,\n",
    "        data_type='iv'\n",
    "    )\n",
    "    \n",
    "    # Remove timezone\n",
    "    validation_flow['datetime'] = pd.to_datetime(validation_flow['datetime']).dt.tz_localize(None)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(validation_flow)} flow records\")\n",
    "    print(f\"  Period: {validation_flow['datetime'].min()} to {validation_flow['datetime'].max()}\")\n",
    "    print(f\"  Flow range: {validation_flow['value'].min():.0f} to {validation_flow['value'].max():.0f} cfs\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving validation flow data: {e}\")\n",
    "    validation_flow = None\n",
    "\n",
    "# Retrieve stage data for validation\n",
    "try:\n",
    "    validation_stage = retrieve_stage_data(\n",
    "        site_id=VALIDATION_GAUGE,\n",
    "        start_datetime=SIM_START,\n",
    "        end_datetime=SIM_END,\n",
    "        data_type='iv'\n",
    "    )\n",
    "    \n",
    "    # Remove timezone\n",
    "    validation_stage['datetime'] = pd.to_datetime(validation_stage['datetime']).dt.tz_localize(None)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(validation_stage)} stage records\")\n",
    "    print(f\"  Stage range: {validation_stage['value'].min():.2f} to {validation_stage['value'].max():.2f} ft\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Stage data not available for gauge {VALIDATION_GAUGE}: {e}\")\n",
    "    validation_stage = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT UPSTREAM BC HYDROGRAPH\n",
    "# =============================================================================\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.plot(upstream_flow['datetime'], upstream_flow['value'], 'b-', linewidth=1, label='USGS Flow')\n",
    "ax.fill_between(upstream_flow['datetime'], 0, upstream_flow['value'], alpha=0.2)\n",
    "\n",
    "# Highlight storm period\n",
    "storm_start = pd.Timestamp('2020-12-24')\n",
    "storm_end = pd.Timestamp('2020-12-26')\n",
    "ax.axvspan(storm_start, storm_end, alpha=0.1, color='red', label='Storm Period')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Flow (cfs)')\n",
    "ax.set_title(f'Upstream Boundary Condition: USGS {UPSTREAM_GAUGE}\\n{upstream_meta[\"station_name\"]}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate peak flow during storm\n",
    "storm_data = upstream_flow[(upstream_flow['datetime'] >= storm_start) & (upstream_flow['datetime'] <= storm_end)]\n",
    "print(f\"\\nStorm Period Statistics ({storm_start.strftime('%Y-%m-%d')} to {storm_end.strftime('%Y-%m-%d')})\")\n",
    "print(f\"  Peak flow: {storm_data['value'].max():.0f} cfs\")\n",
    "print(f\"  Peak time: {storm_data.loc[storm_data['value'].idxmax(), 'datetime']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLONE PLAN FOR STORM SIMULATION\n",
    "# =============================================================================\n",
    "print(f\"Cloning plan {TEMPLATE_PLAN} for storm simulation...\")\n",
    "\n",
    "# Clone the template plan\n",
    "new_plan = RasPlan.clone_plan(\n",
    "    TEMPLATE_PLAN,\n",
    "    new_plan_shortid=\"storm12\",\n",
    "    ras_object=ras\n",
    ")\n",
    "\n",
    "print(f\"Created new plan: {new_plan}\")\n",
    "\n",
    "# Re-initialize to pick up new plan\n",
    "ras = init_ras_project(project_folder, RAS_VERSION)\n",
    "\n",
    "# Display updated plans\n",
    "print(f\"\\nUpdated plan list:\")\n",
    "print(ras.plan_df[['plan_number', 'Plan Title']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UPDATE SIMULATION DATES IN PLAN FILE\n",
    "# =============================================================================\n",
    "import re\n",
    "\n",
    "# Find the new plan file\n",
    "plan_files = list(project_folder.glob(\"*.p*\"))\n",
    "plan_file = None\n",
    "for f in plan_files:\n",
    "    if f.suffix.startswith('.p') and f.suffix != '.prj' and 'storm12' in str(f).lower() or new_plan in f.name:\n",
    "        if not f.name.endswith('.hdf'):\n",
    "            plan_file = f\n",
    "            break\n",
    "\n",
    "# If not found by name, use the last plan number\n",
    "if plan_file is None:\n",
    "    plan_file = project_folder / f\"{project_folder.name.split('_')[0]}.p{new_plan}\"\n",
    "\n",
    "print(f\"Plan file: {plan_file}\")\n",
    "\n",
    "if plan_file.exists():\n",
    "    content = plan_file.read_text()\n",
    "    \n",
    "    # Update simulation dates\n",
    "    # Format: Simulation Date=22DEC2020,0000,27DEC2020,0000\n",
    "    new_date_line = \"Simulation Date=22DEC2020,0000,27DEC2020,0000\"\n",
    "    \n",
    "    # Replace existing simulation date line\n",
    "    content = re.sub(r'Simulation Date=.*', new_date_line, content)\n",
    "    \n",
    "    plan_file.write_text(content)\n",
    "    print(f\"Updated simulation dates: Dec 22-27, 2020\")\n",
    "else:\n",
    "    print(f\"Warning: Plan file not found at {plan_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTE: MANUAL CONFIGURATION STEPS\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"MANUAL CONFIGURATION REQUIRED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"The following steps require manual configuration in HEC-RAS GUI:\")\n",
    "print(\"\")\n",
    "print(\"1. PRECIPITATION DATA:\")\n",
    "if aorc_file and aorc_file.exists():\n",
    "    print(f\"   - AORC NetCDF file saved to: {aorc_file}\")\n",
    "print(\"   - In HEC-RAS: Edit > Plan Data > Meteorology Data\")\n",
    "print(\"   - Set Precipitation Type to 'GDAL Raster'\")\n",
    "print(f\"   - Browse to: {aorc_file if aorc_file else 'Precipitation/storm_20201224.nc'}\")\n",
    "print(\"\")\n",
    "print(\"2. UPSTREAM BOUNDARY CONDITION:\")\n",
    "print(f\"   - USGS gauge {UPSTREAM_GAUGE} data available above\")\n",
    "print(\"   - In HEC-RAS: Edit > Unsteady Flow Data\")\n",
    "print(\"   - Update upstream flow hydrograph with USGS data\")\n",
    "print(\"\")\n",
    "print(\"3. DOWNSTREAM BOUNDARY CONDITION:\")\n",
    "print(\"   - Use normal depth or stage hydrograph from downstream gauge\")\n",
    "print(\"\")\n",
    "print(\"For automated boundary condition updates, see notebook 913.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RUN MODEL (Skip if manual configuration needed)\n",
    "# =============================================================================\n",
    "RUN_MODEL = True  # Set to True after manual configuration\n",
    "\n",
    "if RUN_MODEL:\n",
    "    print(f\"Running plan {new_plan}...\")\n",
    "    \n",
    "    try:\n",
    "        RasCmdr.compute_plan(\n",
    "            plan_number=new_plan,\n",
    "            num_cores=4,\n",
    "            ras_object=ras\n",
    "        )\n",
    "        print(\"Model execution complete\")\n",
    "        \n",
    "        # Re-initialize to pick up results\n",
    "        ras = init_ras_project(project_folder, RAS_VERSION)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Model execution failed: {e}\")\n",
    "        print(\"\\nCheck that:\")\n",
    "        print(\"  1. Precipitation data is properly configured\")\n",
    "        print(\"  2. Boundary conditions are set\")\n",
    "        print(\"  3. Simulation dates match precipitation data\")\n",
    "else:\n",
    "    print(\"Model execution skipped - set RUN_MODEL = True after configuration\")\n",
    "    print(\"\\nAlternatively, use existing results from pre-run plan...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# USE EXISTING PLAN RESULTS (If available)\n",
    "# =============================================================================\n",
    "# Check if any plan has HDF results we can use for demonstration\n",
    "hdf_path = None\n",
    "\n",
    "for idx, row in ras.plan_df.iterrows():\n",
    "    hdf_path_str = row.get('HDF_Results_Path')\n",
    "    if hdf_path_str and Path(hdf_path_str).exists():\n",
    "        hdf_path = Path(hdf_path_str)\n",
    "        plan_number = row['plan_number']\n",
    "        print(f\"Found existing results: Plan {plan_number}\")\n",
    "        print(f\"  HDF: {hdf_path.name}\")\n",
    "        break\n",
    "\n",
    "if hdf_path is None:\n",
    "    print(\"No existing HDF results found.\")\n",
    "    print(\"Run the model first or use an existing plan with results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# VALIDATION: EXTRACT AND COMPARE MODELED VS OBSERVED DATA\n",
    "# =============================================================================\n",
    "# The cells below extract modeled results from the HDF file and compare them \n",
    "# against observed USGS data. This section requires:\n",
    "# 1. A completed HEC-RAS run with HDF results (check cell above)\n",
    "# 2. validation_meta defined (from cell 11)  \n",
    "# 3. validation_flow/validation_stage defined (from cell 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT MODELED RESULTS\n",
    "# =============================================================================\n",
    "if hdf_path and hdf_path.exists():\n",
    "    print(f\"Extracting modeled results from {hdf_path.name}...\")\n",
    "    \n",
    "    modeled_df = None\n",
    "    \n",
    "    # Try 1D cross-section data first (for 1D or 1D/2D combined models)\n",
    "    try:\n",
    "        print(\"Attempting to extract 1D cross-section results...\")\n",
    "        xs_data = HdfResultsXsec.get_xsec_timeseries(hdf_path)\n",
    "        \n",
    "        # Get list of cross sections\n",
    "        xs_names = xs_data.coords['cross_section'].values.tolist()\n",
    "        station_values = xs_data.coords['Station'].values.tolist()\n",
    "        time_values = xs_data.coords['time'].values\n",
    "        \n",
    "        print(f\"\\nExtracted 1D cross-section data:\")\n",
    "        print(f\"  Cross sections: {len(xs_names)}\")\n",
    "        print(f\"  Time steps: {len(time_values)}\")\n",
    "        print(f\"  Station range: {station_values[0]} to {station_values[-1]}\")\n",
    "        \n",
    "        # Select a downstream cross section for validation comparison\n",
    "        # Use a station in the middle-lower portion of the model\n",
    "        target_station = float(station_values[-1]) + (float(station_values[0]) - float(station_values[-1])) * 0.3\n",
    "        closest_idx = min(range(len(station_values)), key=lambda i: abs(float(station_values[i]) - target_station))\n",
    "        validation_xs = xs_names[closest_idx]\n",
    "        \n",
    "        print(f\"\\nUsing cross section for validation: {validation_xs}\")\n",
    "        print(f\"  Station: {station_values[closest_idx]}\")\n",
    "        \n",
    "        # Extract flow timeseries\n",
    "        modeled_flow_ts = xs_data['Flow'].sel(cross_section=validation_xs)\n",
    "        \n",
    "        # Create modeled dataframe\n",
    "        modeled_df = pd.DataFrame({\n",
    "            'datetime': pd.to_datetime(time_values),\n",
    "            'value': modeled_flow_ts.values\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nModeled results (1D cross-section):\")\n",
    "        print(f\"  Period: {modeled_df['datetime'].min()} to {modeled_df['datetime'].max()}\")\n",
    "        print(f\"  Flow range: {modeled_df['value'].min():.1f} to {modeled_df['value'].max():.1f} cfs\")\n",
    "        \n",
    "    except (KeyError, Exception) as e:\n",
    "        print(f\"  1D cross-section data not available: {e}\")\n",
    "        print(\"\\nFalling back to 2D mesh results...\")\n",
    "        \n",
    "        # Try 2D reference lines (like cross-sections for 2D models)\n",
    "        try:\n",
    "            print(\"Attempting to extract 2D reference line results...\")\n",
    "            ref_lines_data = HdfResultsXsec.get_ref_lines_timeseries(hdf_path)\n",
    "            \n",
    "            if ref_lines_data and len(ref_lines_data.data_vars) > 0:\n",
    "                # Get reference line names\n",
    "                if 'ref_line' in ref_lines_data.coords:\n",
    "                    ref_line_names = ref_lines_data.coords['ref_line'].values.tolist()\n",
    "                    time_values = ref_lines_data.coords['time'].values\n",
    "                    \n",
    "                    print(f\"\\nExtracted 2D reference line data:\")\n",
    "                    print(f\"  Reference lines: {len(ref_line_names)}\")\n",
    "                    print(f\"  Time steps: {len(time_values)}\")\n",
    "                    \n",
    "                    # Use the first (or most downstream) reference line\n",
    "                    validation_ref_line = ref_line_names[0] if ref_line_names else None\n",
    "                    \n",
    "                    if validation_ref_line and 'Flow' in ref_lines_data.data_vars:\n",
    "                        print(f\"\\nUsing reference line for validation: {validation_ref_line}\")\n",
    "                        \n",
    "                        # Extract flow timeseries\n",
    "                        modeled_flow_ts = ref_lines_data['Flow'].sel(ref_line=validation_ref_line)\n",
    "                        \n",
    "                        # Create modeled dataframe\n",
    "                        modeled_df = pd.DataFrame({\n",
    "                            'datetime': pd.to_datetime(time_values),\n",
    "                            'value': modeled_flow_ts.values\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"\\nModeled results (2D reference line):\")\n",
    "                        print(f\"  Period: {modeled_df['datetime'].min()} to {modeled_df['datetime'].max()}\")\n",
    "                        print(f\"  Flow range: {modeled_df['value'].min():.1f} to {modeled_df['value'].max():.1f} cfs\")\n",
    "                    else:\n",
    "                        print(\"  No flow data available in reference lines\")\n",
    "                else:\n",
    "                    print(\"  No reference lines found in HDF file\")\n",
    "            else:\n",
    "                print(\"  Reference line data is empty\")\n",
    "                \n",
    "        except Exception as e2:\n",
    "            print(f\"  2D reference line data not available: {e2}\")\n",
    "            print(\"\\nFalling back to 2D mesh cell results near gauge location...\")\n",
    "            \n",
    "            # Try 2D mesh cell data near validation gauge\n",
    "            try:\n",
    "                # Get validation gauge location\n",
    "                if validation_meta and 'latitude' in validation_meta and 'longitude' in validation_meta:\n",
    "                    gauge_lat = validation_meta['latitude']\n",
    "                    gauge_lon = validation_meta['longitude']\n",
    "                    gauge_point = Point(gauge_lon, gauge_lat)\n",
    "                    \n",
    "                    print(f\"\\nValidation gauge location: {gauge_lat:.4f}N, {gauge_lon:.4f}W\")\n",
    "                    \n",
    "                    # Get mesh cell points and find nearest to gauge\n",
    "                    cell_points = HdfMesh.get_mesh_cell_points(geom_hdf)\n",
    "                    \n",
    "                    # Transform gauge point to mesh CRS\n",
    "                    mesh_crs = cell_points.crs\n",
    "                    gauge_gdf = gpd.GeoDataFrame([1], geometry=[gauge_point], crs=\"EPSG:4326\")\n",
    "                    gauge_proj = gauge_gdf.to_crs(mesh_crs)\n",
    "                    gauge_point_proj = gauge_proj.geometry.iloc[0]\n",
    "                    \n",
    "                    # Find nearest cell\n",
    "                    cell_id, distance = HdfMesh.find_nearest_cell(gauge_point_proj, cell_points)\n",
    "                    \n",
    "                    if cell_id is not None:\n",
    "                        print(f\"  Nearest mesh cell: {cell_id} (distance: {distance:.1f} m)\")\n",
    "                        \n",
    "                        # Get mesh area names\n",
    "                        mesh_names = HdfMesh.get_mesh_area_names(hdf_path)\n",
    "                        if mesh_names:\n",
    "                            mesh_name = mesh_names[0]  # Use first mesh area\n",
    "                            \n",
    "                            # Get cell timeseries for water surface (we'll use this as proxy)\n",
    "                            # Note: For 2D models, flow is typically calculated from face velocities\n",
    "                            # Here we extract water surface as a proxy metric\n",
    "                            print(f\"  Extracting water surface timeseries from mesh: {mesh_name}\")\n",
    "                            \n",
    "                            # Get all mesh cell timeseries\n",
    "                            mesh_cells_data = HdfResultsMesh.get_mesh_cells_timeseries(\n",
    "                                hdf_path, \n",
    "                                mesh_names=[mesh_name],\n",
    "                                var=\"Water Surface\"\n",
    "                            )\n",
    "                            \n",
    "                            if mesh_name in mesh_cells_data:\n",
    "                                wse_data = mesh_cells_data[mesh_name]['Water Surface']\n",
    "                                \n",
    "                                # Extract timeseries for the specific cell\n",
    "                                if cell_id < wse_data.sizes.get('cell_id', 0):\n",
    "                                    cell_wse = wse_data.sel(cell_id=cell_id)\n",
    "                                    time_values = cell_wse.coords['time'].values\n",
    "                                    \n",
    "                                    # Create dataframe with water surface (as proxy)\n",
    "                                    # Note: This is WSE, not flow - validation will need adjustment\n",
    "                                    modeled_df = pd.DataFrame({\n",
    "                                        'datetime': pd.to_datetime(time_values),\n",
    "                                        'value': cell_wse.values  # WSE in feet\n",
    "                                    })\n",
    "                                    \n",
    "                                    print(f\"\\nModeled results (2D mesh cell - Water Surface):\")\n",
    "                                    print(f\"  Period: {modeled_df['datetime'].min()} to {modeled_df['datetime'].max()}\")\n",
    "                                    print(f\"  WSE range: {modeled_df['value'].min():.2f} to {modeled_df['value'].max():.2f} ft\")\n",
    "                                    print(f\"\\nNOTE: Extracted water surface elevation, not flow.\")\n",
    "                                    print(f\"      For flow validation, use reference lines or calculate from face velocities.\")\n",
    "                                else:\n",
    "                                    print(f\"  Cell ID {cell_id} not found in mesh data\")\n",
    "                            else:\n",
    "                                print(f\"  No data available for mesh: {mesh_name}\")\n",
    "                        else:\n",
    "                            print(\"  No mesh areas found in HDF file\")\n",
    "                    else:\n",
    "                        print(\"  Could not find nearest cell to gauge location\")\n",
    "                else:\n",
    "                    print(\"  Validation gauge location not available\")\n",
    "                    \n",
    "            except Exception as e3:\n",
    "                print(f\"  2D mesh cell extraction failed: {e3}\")\n",
    "                print(f\"\\nUnable to extract modeled results from HDF file.\")\n",
    "                print(f\"  This may be a 2D-only model without 1D cross-sections or reference lines.\")\n",
    "                print(f\"  Consider using HEC-RAS to add a reference line at the validation gauge location.\")\n",
    "                modeled_df = None\n",
    "    \n",
    "    if modeled_df is None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"WARNING: Could not extract flow timeseries from model results.\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Options:\")\n",
    "        print(\"  1. Add a reference line in HEC-RAS at the validation gauge location\")\n",
    "        print(\"  2. Use stage validation instead of flow (extract WSE from mesh cells)\")\n",
    "        print(\"  3. Calculate flow from face velocities if reference lines are not available\")\n",
    "        print(\"=\"*70)\n",
    "else:\n",
    "    print(\"No HDF results available for extraction\")\n",
    "    modeled_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ALIGN AND CALCULATE FLOW METRICS\n",
    "# =============================================================================\n",
    "if modeled_df is not None and validation_flow is not None:\n",
    "    print(\"Aligning modeled and observed flow timeseries...\")\n",
    "    \n",
    "    # Align timeseries\n",
    "    aligned_flow = align_timeseries(\n",
    "        modeled_df=modeled_df,\n",
    "        observed_df=validation_flow\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAligned {len(aligned_flow)} timesteps\")\n",
    "    print(f\"  Period: {aligned_flow['datetime'].min()} to {aligned_flow['datetime'].max()}\")\n",
    "    print(f\"  Modeled range: {aligned_flow['modeled'].min():.1f} to {aligned_flow['modeled'].max():.1f} cfs\")\n",
    "    print(f\"  Observed range: {aligned_flow['observed'].min():.1f} to {aligned_flow['observed'].max():.1f} cfs\")\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    # Note: calculate_all_metrics expects (observed, modeled) order\n",
    "    print(\"\\nCalculating flow validation metrics...\")\n",
    "    flow_metrics = calculate_all_metrics(\n",
    "        observed=aligned_flow['observed'],\n",
    "        modeled=aligned_flow['modeled'],\n",
    "        time_index=aligned_flow['datetime']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FLOW VALIDATION METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Nash-Sutcliffe Efficiency (NSE): {flow_metrics['nse']:.3f}\")\n",
    "    print(f\"  Interpretation: {'Good' if flow_metrics['nse'] > 0.5 else 'Poor'} (>0.5 = satisfactory)\")\n",
    "    print(f\"\\nKling-Gupta Efficiency (KGE): {flow_metrics['kge']:.3f}\")\n",
    "    print(f\"  Interpretation: {'Good' if flow_metrics['kge'] > 0.5 else 'Poor'} (>0.5 = satisfactory)\")\n",
    "    print(f\"\\nPeak Flow Error: {flow_metrics['peak_error_pct']:.1f}%\")\n",
    "    print(f\"Volume Error: {flow_metrics['vol_error_pct']:.1f}%\")\n",
    "    print(f\"RMSE: {flow_metrics['rmse']:.1f} cfs\")\n",
    "else:\n",
    "    print(\"Cannot calculate metrics - missing modeled or observed data\")\n",
    "    aligned_flow = None\n",
    "    flow_metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT FLOW COMPARISON\n",
    "# =============================================================================\n",
    "if aligned_flow is not None:\n",
    "    # plot_timeseries_comparison expects aligned_data DataFrame, not separate arrays\n",
    "    fig = plot_timeseries_comparison(\n",
    "        aligned_data=aligned_flow,\n",
    "        metrics=flow_metrics,\n",
    "        title=f\"Flow Validation: {validation_meta.get('station_name', VALIDATION_GAUGE)}\"\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(project_folder / \"flow_validation.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFigure saved to: {project_folder / 'flow_validation.png'}\")\n",
    "else:\n",
    "    print(\"Cannot plot comparison - missing aligned data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT SCATTER COMPARISON\n",
    "# =============================================================================\n",
    "if aligned_flow is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Flow scatter plot\n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(aligned_flow['observed'], aligned_flow['modeled'], alpha=0.5, s=10)\n",
    "    \n",
    "    # Add 1:1 line\n",
    "    max_val = max(aligned_flow['observed'].max(), aligned_flow['modeled'].max())\n",
    "    ax1.plot([0, max_val], [0, max_val], 'r--', label='1:1 Line')\n",
    "    \n",
    "    ax1.set_xlabel('Observed Flow (cfs)')\n",
    "    ax1.set_ylabel('Modeled Flow (cfs)')\n",
    "    ax1.set_title(f'Flow Scatter Plot\\nNSE={flow_metrics[\"nse\"]:.3f}, KGE={flow_metrics[\"kge\"]:.3f}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_aspect('equal')\n",
    "    \n",
    "    # Residuals histogram\n",
    "    ax2 = axes[1]\n",
    "    residuals = aligned_flow['modeled'] - aligned_flow['observed']\n",
    "    ax2.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax2.axvline(x=0, color='r', linestyle='--', label='Zero Error')\n",
    "    ax2.axvline(x=residuals.mean(), color='g', linestyle='-', label=f'Mean: {residuals.mean():.0f} cfs')\n",
    "    \n",
    "    ax2.set_xlabel('Residual (Modeled - Observed) [cfs]')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Residuals Distribution')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(project_folder / \"flow_scatter.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFigure saved to: {project_folder / 'flow_scatter.png'}\")\n",
    "else:\n",
    "    print(\"Cannot plot scatter - missing aligned data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "### Validation Interpretation\n",
    "\n",
    "**NSE (Nash-Sutcliffe Efficiency)**:\n",
    "- NSE > 0.75: Very good\n",
    "- 0.65 < NSE < 0.75: Good\n",
    "- 0.50 < NSE < 0.65: Satisfactory\n",
    "- NSE < 0.50: Unsatisfactory\n",
    "\n",
    "**KGE (Kling-Gupta Efficiency)**:\n",
    "- KGE > 0.75: Very good\n",
    "- 0.50 < KGE < 0.75: Good/Satisfactory\n",
    "- KGE < 0.50: Unsatisfactory\n",
    "\n",
    "### Expected Limitations\n",
    "\n",
    "1. **Drainage Area Mismatch**: The 2D model may not cover the entire HUC12 watershed, leading to missing runoff contributions from unmodeled areas.\n",
    "\n",
    "2. **USGS Gauge Location**: The validation gauge may be downstream of significant unmodeled tributaries.\n",
    "\n",
    "3. **Precipitation Spatial Variability**: AORC data at 4km resolution may not capture localized intense precipitation.\n",
    "\n",
    "4. **Boundary Condition Uncertainty**: Upstream BC from USGS gauge represents only one flow path into the model.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Expand Model Domain**: Consider extending 2D mesh to cover more of the HUC12 watershed.\n",
    "\n",
    "2. **Additional Validation Points**: Add more USGS gauges if available within the model domain.\n",
    "\n",
    "3. **Sensitivity Analysis**: Test sensitivity to Manning's n, precipitation, and initial conditions.\n",
    "\n",
    "4. **Multiple Events**: Validate against multiple storm events to assess model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY REPORT\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"HISTORICAL EVENT VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nProject: {PROJECT_NAME}\")\n",
    "print(f\"Storm Event: December 24-25, 2020\")\n",
    "print(f\"Simulation Period: {SIM_START} to {SIM_END}\")\n",
    "\n",
    "print(f\"\\nData Sources:\")\n",
    "print(f\"  Precipitation: AORC gridded data (4km, hourly)\")\n",
    "print(f\"  Upstream BC: USGS {UPSTREAM_GAUGE}\")\n",
    "print(f\"  Validation: USGS {VALIDATION_GAUGE}\")\n",
    "\n",
    "if HUC12_AVAILABLE and 'coverage_pct' in dir():\n",
    "    print(f\"\\nDrainage Coverage:\")\n",
    "    print(f\"  Model covers {coverage_pct:.1f}% of HUC12 watershed\")\n",
    "    print(f\"  Unmodeled area: {unmodeled_area_sqkm:.1f} sq km\")\n",
    "\n",
    "if flow_metrics is not None:\n",
    "    print(f\"\\nFlow Validation Metrics:\")\n",
    "    print(f\"  NSE: {flow_metrics['nse']:.3f}\")\n",
    "    print(f\"  KGE: {flow_metrics['kge']:.3f}\")\n",
    "    print(f\"  Peak Error: {flow_metrics['peak_error_pct']:.1f}%\")\n",
    "    print(f\"  Volume Error: {flow_metrics['vol_error_pct']:.1f}%\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "if (project_folder / \"coverage_analysis.png\").exists():\n",
    "    print(f\"  - {project_folder / 'coverage_analysis.png'}\")\n",
    "if (project_folder / \"flow_validation.png\").exists():\n",
    "    print(f\"  - {project_folder / 'flow_validation.png'}\")\n",
    "if (project_folder / \"flow_scatter.png\").exists():\n",
    "    print(f\"  - {project_folder / 'flow_scatter.png'}\")\n",
    "if aorc_file and aorc_file.exists():\n",
    "    print(f\"  - {aorc_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Modeler\n",
    "\n",
    "### Current State of Analysis\n",
    "\n",
    "This notebook has completed the **data preparation phase** for historical event validation:\n",
    "\n",
    " **Completed**:\n",
    "- HUC12 drainage coverage analysis (84.6% modeled, 15.4% ungauged)\n",
    "- AORC precipitation downloaded for Storm 12 (Dec 24-25, 2020)\n",
    "- USGS boundary condition data retrieved and validated\n",
    "- Template plan cloned and ready for configuration\n",
    "- Upstream BC hydrograph visualized and validated\n",
    "\n",
    " **Pending Manual Configuration**:\n",
    "\n",
    "The model currently has:\n",
    "1. **Existing upstream BC** at \"Upstream Inflow\" - needs USGS data update\n",
    "2. **Existing downstream BC** as \"Normal Depth\" - needs conversion to Stage Hydrograph\n",
    "\n",
    "**Additional BCs NOT in current model** (would require geometry file edits):\n",
    "3. **Spring Creek** (USGS 01547100, 142 sq mi) - lateral inflow boundary\n",
    "4. **Marsh Creek** (USGS 01547700, 44 sq mi) - lateral inflow boundary\n",
    "5. **Beech Creek** (USGS 01547980, 170 sq mi) - potential lateral inflow\n",
    "6. **Fishing Creek** (USGS 01548079, 180 sq mi) - potential lateral inflow\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 1: Minimum Viable Validation (Recommended to Start)\n",
    "\n",
    "**Use existing boundary condition locations only:**\n",
    "\n",
    "#### 1.1 Update Existing Upstream BC with USGS Data\n",
    "\n",
    "The \"Upstream Inflow\" BC already exists. Update it with USGS 01547500 flow data.\n",
    "\n",
    "**Steps**:\n",
    "1. Locate cloned unsteady file: `BaldEagleDamBrk.u07` (or whatever was created)\n",
    "2. Find \"Boundary Location=...Upstream Inflow\" (around line 6)\n",
    "3. Replace the flow hydrograph table with USGS data\n",
    "\n",
    "**Use notebook cell outputs**:\n",
    "- Cell 11 shows the upstream BC hydrograph plot\n",
    "- The hydrograph data has been retrieved (576 hourly values)\n",
    "\n",
    "**Automation**:\n",
    "```python\n",
    "from ras_commander.usgs.boundary_generation import BoundaryGenerator\n",
    "\n",
    "# Generate flow table from USGS data\n",
    "flow_table = BoundaryGenerator.generate_flow_hydrograph_table(\n",
    "    flow_values=upstream_flow['value'].values,\n",
    "    interval='1HOUR'\n",
    ")\n",
    "\n",
    "# Update in unsteady file\n",
    "BoundaryGenerator.update_boundary_hydrograph(\n",
    "    unsteady_file=unsteady_file,\n",
    "    boundary_location=\"BaldEagleCr,Upstream Inflow\",\n",
    "    hydrograph_table=flow_table\n",
    ")\n",
    "```\n",
    "\n",
    "#### 1.2 Convert Downstream BC to Stage Hydrograph\n",
    "\n",
    "The \"DSNormalDepth\" BC needs to be converted from Normal Depth to Stage Hydrograph.\n",
    "\n",
    "**Manual Steps**:\n",
    "1. Open unsteady file: `BaldEagleDamBrk.u07`\n",
    "2. Find \"Boundary Location=...DSNormalDepth\" (around line 4)\n",
    "3. Find \"Friction Slope=0.0003,0\" (next line after boundary location)\n",
    "4. Replace \"Friction Slope=\" line with stage hydrograph table\n",
    "\n",
    "**Generate stage table**:\n",
    "```python\n",
    "from ras_commander.usgs.boundary_generation import BoundaryGenerator\n",
    "\n",
    "stage_table = BoundaryGenerator.generate_stage_hydrograph_table(\n",
    "    stage_values=validation_stage['value'].values,\n",
    "    interval='1HOUR'\n",
    ")\n",
    "\n",
    "# Save to helper file for copy-paste\n",
    "with open('stage_hydrograph_insert.txt', 'w') as f:\n",
    "    f.write(stage_table)\n",
    "\n",
    "print(\"Stage table saved to stage_hydrograph_insert.txt\")\n",
    "print(\"Copy contents and replace 'Friction Slope=' line in unsteady file\")\n",
    "```\n",
    "\n",
    "#### 1.3 Update Precipitation Source\n",
    "\n",
    "Change from DSS to AORC NetCDF:\n",
    "\n",
    "**Manual Steps**:\n",
    "1. Open unsteady file\n",
    "2. Find section starting with `Met BC=Precipitation|Mode=Gridded` (around line 141)\n",
    "3. Change:\n",
    "   - `Met BC=Precipitation|Gridded Source=DSS`  `Met BC=Precipitation|Gridded Source=GDAL`\n",
    "   - Update file path to point to downloaded AORC NetCDF\n",
    "\n",
    "**Automation** (if available):\n",
    "```python\n",
    "from ras_commander import RasUnsteady\n",
    "\n",
    "RasUnsteady.set_gridded_precipitation(\n",
    "    unsteady_file=unsteady_file,\n",
    "    netcdf_path=\"Precipitation/storm_20201224.nc\",\n",
    "    interpolation=\"Nearest\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### 1.4 Run Simulation and Validate\n",
    "\n",
    "After BC configuration:\n",
    "1. Open project in HEC-RAS GUI to verify BCs\n",
    "2. Run simulation (set `RUN_MODEL=True` in cell 17, or run in GUI)\n",
    "3. Execute cells 18-22 to extract results and calculate metrics\n",
    "4. Review validation findings\n",
    "\n",
    "**Expected Metrics** (with 15% ungauged drainage):\n",
    "- NSE: 0.40-0.65 (satisfactory to good, accounting for ungauged area)\n",
    "- PBIAS: -30% to 0% (negative bias expected from ungauged inflow)\n",
    "- Peak Error: 10-30%\n",
    "- Correlation: > 0.70\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 2: Enhanced Validation with Lateral Inflows (Future)\n",
    "\n",
    "**Add new boundary conditions** for lateral tributaries to improve validation.\n",
    "\n",
    "#### 2.1 Required New BCs\n",
    "\n",
    "| Tributary | Gauge | DA (sq mi) | Data Available | Priority |\n",
    "|-----------|-------|------------|----------------|----------|\n",
    "| **Spring Creek** | 01547100 | 142 | Flow (IV)  | **HIGH** |\n",
    "| **Marsh Creek** | 01547700 | 44 | Flow (IV)  | **HIGH** |\n",
    "| Beech Creek | 01547980 | 170 | No data | Low |\n",
    "| Fishing Creek | 01548079 | 180 | No data | Low |\n",
    "\n",
    "**Combined gaged inflow**: 339 + 142 + 44 = **525 sq mi** (vs 562 sq mi at downstream gauge)\n",
    "**Ungauged gap**: 37 sq mi (6.6% of downstream drainage)\n",
    "\n",
    "#### 2.2 Geometry File Edits Required\n",
    "\n",
    "**For each new BC**, you need to:\n",
    "\n",
    "1. **Create SA/2D Area Conn** in geometry file:\n",
    "   - Add connection line between external boundary and 2D mesh\n",
    "   - Define as \"SA/2D Area Conn\" type\n",
    "   - Specify connection cells\n",
    "\n",
    "2. **Define External SA** (storage area):\n",
    "   - Create storage area for lateral inflow\n",
    "   - Connect to 2D mesh via SA/2D Area Conn\n",
    "\n",
    "3. **Add BC Reference** in unsteady file:\n",
    "   - Reference the new SA connection\n",
    "   - Add flow hydrograph table\n",
    "\n",
    "**Current Limitation**: This requires **manual geometry editing** or HEC-RAS GUI operations.\n",
    "\n",
    "#### 2.3 Future Automation Feature (Development Roadmap)\n",
    "\n",
    "**Proposed Function**: `create_bc_from_gauge_location()`\n",
    "\n",
    "**Concept**:\n",
    "```python\n",
    "from ras_commander.geom import RasGeometry2D\n",
    "\n",
    "RasGeometry2D.create_lateral_bc_from_gauge(\n",
    "    geom_file=\"BaldEagleDamBrk.g09\",\n",
    "    gauge_id=\"01547100\",  # Spring Creek\n",
    "    gauge_lat=40.9158,\n",
    "    gauge_lon=-77.7897,\n",
    "    num_faces=20,        # Number of mesh cell faces to use\n",
    "    offset_distance=50,  # Offset from mesh (ft)\n",
    "    trim_percent=7.5,    # Trim 7.5% from each end\n",
    "    bc_name=\"Spring Creek Inflow\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Algorithm**:\n",
    "1. Find nearest 20 mesh cell faces to gauge location\n",
    "2. Extract face linestrings and combine\n",
    "3. Offset linestring away from mesh interior by 50 ft\n",
    "4. Trim 5-10% from each end (avoid corners)\n",
    "5. Add SA/2D Area Conn to geometry file\n",
    "6. Add BC reference to unsteady file\n",
    "7. Validate geometry integrity\n",
    "\n",
    "**Benefits**:\n",
    "- Automate BC creation from gauge coordinates\n",
    "- Ensure valid HEC-RAS geometry\n",
    "- Accelerate validation model setup\n",
    "- Enable batch processing of multiple lateral inflows\n",
    "\n",
    "**Roadmap Priority**: Medium-High (enables comprehensive multi-gauge validation)\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 3: Multi-Gauge Validation Network\n",
    "\n",
    "**Once lateral BCs are added**, validate at multiple points:\n",
    "\n",
    "| Validation Point | Gauge | DA at Gauge | DA Upstream BCs | Coverage |\n",
    "|------------------|-------|-------------|-----------------|----------|\n",
    "| Downstream | 01548005 | 562 sq mi | 525 sq mi | 93.4% |\n",
    "| Midstream | 01548000 | 559 sq mi | 525 sq mi | 93.9% |\n",
    "| Spring Creek | 01547100 | 142 sq mi | 142 sq mi | 100% (at BC) |\n",
    "\n",
    "**Validation Approach**:\n",
    "- Extract results at cross sections near each gauge\n",
    "- Compare modeled vs observed at each location\n",
    "- Calculate metrics for each validation point\n",
    "- Assess spatial performance (upstream vs downstream)\n",
    "\n",
    "---\n",
    "\n",
    "### Phase 4: Multi-Event Calibration (Future)\n",
    "\n",
    "**Use AORC catalog to test multiple storms**:\n",
    "\n",
    "From 2020 AORC catalog (cell 9 reference):\n",
    "1. Storm 12 (Dec 24-25): 2.72\" - largest event\n",
    "2. Storm 5 (Apr 30-May 1): 2.12\" - spring conditions\n",
    "3. Storm 10 (Nov 11): 1.99\" - high intensity\n",
    "4. Storm 9 (Oct 29-30): 1.74\" - fall conditions\n",
    "\n",
    "**Multi-event validation benefits**:\n",
    "- Test across different magnitudes\n",
    "- Assess parameter transferability\n",
    "- Identify seasonal biases\n",
    "- Build confidence in calibration\n",
    "\n",
    "---\n",
    "\n",
    "### Tools and References\n",
    "\n",
    "**Automation Functions Available**:\n",
    "- `BoundaryGenerator.generate_flow_hydrograph_table()` - Create BC tables\n",
    "- `BoundaryGenerator.update_boundary_hydrograph()` - Update existing BCs\n",
    "- `RasUnsteady.set_gridded_precipitation()` - Configure AORC NetCDF\n",
    "- `calculate_all_metrics()` - Comprehensive validation metrics\n",
    "- `plot_timeseries_comparison()` - Publication-quality plots\n",
    "\n",
    "**Documentation**:\n",
    "- BC Configuration: `.claude/outputs/general-purpose/2025-12-30-bc-configuration-workflow.md`\n",
    "- Gauge Analysis: `.claude/outputs/general-purpose/2025-12-29-gauge-data-availability.md`\n",
    "- AORC Workflow: `.claude/outputs/general-purpose/2025-12-29-aorc-workflow-research.md`\n",
    "- Complete Summary: `.claude/outputs/general-purpose/2025-12-30-validation-workflow-summary.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated Time to Complete**:\n",
    "- Phase 1 (Minimum viable): 2-3 hours\n",
    "- Phase 2 (Add lateral BCs): +3-5 hours (pending automation feature)\n",
    "- Phase 3 (Multi-gauge validation): +2-3 hours\n",
    "- Phase 4 (Multi-event): +4-6 hours per additional storm\n",
    "\n",
    "**Recommended Approach**: Start with Phase 1, validate the workflow works, then expand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rascmdr_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
