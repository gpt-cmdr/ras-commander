{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:26.598182Z",
          "iopub.status.busy": "2025-11-17T19:05:26.597941Z",
          "iopub.status.idle": "2025-11-17T19:05:28.305562Z",
          "shell.execute_reply": "2025-11-17T19:05:28.305031Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with Legacy HEC-RAS Using RasControl\n",
        "\n",
        "This notebook demonstrates **RasControl**, which provides a ras-commander style API for legacy HEC-RAS versions (3.x-4.x) using the HECRASController COM interface.\n",
        "\n",
        "## What is RasControl?\n",
        "\n",
        "**RasControl** wraps the HECRASController COM API with ras-commander conventions:\n",
        "\n",
        "- \u2705 **Use plan numbers** - `RasControl.run_plan(\"02\")` not file paths\n",
        "- \u2705 **Integrated with ras object** - Works with `init_ras_project()`\n",
        "- \u2705 **Steady AND unsteady** - Extract profiles and time series\n",
        "- \u2705 **Auto-sets current plan** - Just pass the plan number!\n",
        "- \u2705 **No COM complexity** - Clean public API\n",
        "\n",
        "## When to Use RasControl\n",
        "\n",
        "| Use RasControl | Use HDF Methods |\n",
        "|----------------|----------------|\n",
        "| HEC-RAS 3.1, 4.1 | HEC-RAS 6.0+ |\n",
        "| No HDF support | Modern versions |\n",
        "| Legacy models | 2D mesh data |\n",
        "| Version migration | Better performance |\n",
        "\n",
        "## Supported Versions\n",
        "\n",
        "3.0, 3.1, 4.0, 4.1, 5.0-5.0.7, 6.0-6.7 Beta\n",
        "\n",
        "Accepts: `\"4.1\"`, `\"41\"`, `\"5.0.6\"`, `\"506\"`, `\"6.6\"`, `\"66\"`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.307996Z",
          "iopub.status.busy": "2025-11-17T19:05:28.307624Z",
          "iopub.status.idle": "2025-11-17T19:05:28.310145Z",
          "shell.execute_reply": "2025-11-17T19:05:28.309754Z"
        }
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade ras-commander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.312286Z",
          "iopub.status.busy": "2025-11-17T19:05:28.311987Z",
          "iopub.status.idle": "2025-11-17T19:05:28.315882Z",
          "shell.execute_reply": "2025-11-17T19:05:28.315329Z"
        }
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.318508Z",
          "iopub.status.busy": "2025-11-17T19:05:28.318153Z",
          "iopub.status.idle": "2025-11-17T19:05:28.321877Z",
          "shell.execute_reply": "2025-11-17T19:05:28.321380Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PLOTTING CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Set better default plotting parameters\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 9\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "\n",
        "import numpy as np  # Add if not already imported\n",
        "\n",
        "print(\"\u2713 Plotting configuration loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.323634Z",
          "iopub.status.busy": "2025-11-17T19:05:28.323423Z",
          "iopub.status.idle": "2025-11-17T19:05:28.327130Z",
          "shell.execute_reply": "2025-11-17T19:05:28.326476Z"
        }
      },
      "outputs": [],
      "source": [
        "# Enable this cell for local development version of ras-commander\n",
        "import os\n",
        "import sys      \n",
        "from pathlib import Path\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.329457Z",
          "iopub.status.busy": "2025-11-17T19:05:28.329226Z",
          "iopub.status.idle": "2025-11-17T19:05:28.333188Z",
          "shell.execute_reply": "2025-11-17T19:05:28.332632Z"
        }
      },
      "outputs": [],
      "source": [
        "# 2. Import all required modules\n",
        "\n",
        "# Import all ras-commander modules\n",
        "from ras_commander import *\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.336035Z",
          "iopub.status.busy": "2025-11-17T19:05:28.335610Z",
          "iopub.status.idle": "2025-11-17T19:05:28.345204Z",
          "shell.execute_reply": "2025-11-17T19:05:28.344712Z"
        }
      },
      "outputs": [],
      "source": [
        "# Helper Plotting Functions\n",
        "\n",
        "def plot_steady_profiles_by_reach(df, title_prefix=\"Steady Flow Profiles\"):\n",
        "    \"\"\"\n",
        "    Plot steady flow profiles separated by River/Reach.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Steady results from RasControl.get_steady_results()\n",
        "    title_prefix : str\n",
        "        Prefix for plot titles\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # Group by River/Reach\n",
        "    for (river, reach), group_df in df.groupby(['river', 'reach']):\n",
        "        fig, ax = plt.subplots(figsize=(14, 6))\n",
        "        \n",
        "        # Sort by station (descending - upstream to downstream)\n",
        "        group_df_sorted = group_df.sort_values('node_id', ascending=False)\n",
        "        \n",
        "        # Plot each profile\n",
        "        profiles = group_df['profile'].unique()\n",
        "        for profile in profiles:\n",
        "            prof_data = group_df_sorted[group_df_sorted['profile'] == profile]\n",
        "            ax.plot(prof_data['node_id'], prof_data['wsel'], \n",
        "                    marker='o', label=f'{profile}', linewidth=2, markersize=4)\n",
        "        \n",
        "        # Add channel invert\n",
        "        invert = group_df_sorted.drop_duplicates('node_id')[['node_id', 'min_ch_el']]\n",
        "        ax.plot(invert['node_id'], invert['min_ch_el'], \n",
        "                'k--', label='Channel Invert', linewidth=2, alpha=0.7)\n",
        "        \n",
        "        ax.set_xlabel('River Station', fontsize=12)\n",
        "        ax.set_ylabel('Elevation (ft)', fontsize=12)\n",
        "        ax.set_title(f'{title_prefix}\\n{river} - {reach}', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "        ax.legend(loc='best', fontsize=9, ncol=2)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.invert_xaxis()  # Upstream on left\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_unsteady_timeseries_multi_xs(df_timeseries, df_maxws, selected_xs=None, n_xs=5):\n",
        "    \"\"\"\n",
        "    Plot unsteady time series at multiple cross sections with Max WS annotations.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df_timeseries : DataFrame\n",
        "        Unsteady results WITHOUT 'Max WS' rows, with 'datetime' column\n",
        "    df_maxws : DataFrame\n",
        "        Unsteady results for ONLY 'Max WS' rows\n",
        "    selected_xs : list, optional\n",
        "        List of specific cross sections to plot. If None, selects evenly spaced XS\n",
        "    n_xs : int\n",
        "        Number of cross sections to plot (used if selected_xs is None)\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.dates as mdates\n",
        "    \n",
        "    # Select cross sections if not provided\n",
        "    if selected_xs is None:\n",
        "        all_xs = sorted(df_timeseries['node_id'].unique(), reverse=True)\n",
        "        step = max(1, len(all_xs) // n_xs)\n",
        "        selected_xs = all_xs[::step][:n_xs]\n",
        "    \n",
        "    # Create subplots\n",
        "    n_xs_plot = len(selected_xs)\n",
        "    fig, axes = plt.subplots(n_xs_plot, 1, figsize=(14, 4*n_xs_plot))\n",
        "    if n_xs_plot == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, xs in enumerate(selected_xs):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Get data for this XS\n",
        "        xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "        maxws_data = df_maxws[df_maxws['node_id'] == xs]\n",
        "        \n",
        "        # Plot time series\n",
        "        ax.plot(xs_data['datetime'], xs_data['wsel'], \n",
        "                'b-o', linewidth=2, markersize=4, label='WSE at Output Timesteps')\n",
        "        \n",
        "        # Get values for annotation\n",
        "        max_ws_value = maxws_data['wsel'].iloc[0] if len(maxws_data) > 0 else None\n",
        "        max_output_value = xs_data['wsel'].max()\n",
        "        \n",
        "        # Add horizontal reference for Max WS\n",
        "        if max_ws_value:\n",
        "            ax.axhline(max_ws_value, color='r', linestyle='--', \n",
        "                       linewidth=2, alpha=0.7, label='Max WS (computational)')\n",
        "        \n",
        "        # Add annotations\n",
        "        annotation_text = f\"Max WS (computational): {max_ws_value:.2f} ft\\n\"\n",
        "        annotation_text += f\"Max (output interval): {max_output_value:.2f} ft\"\n",
        "        \n",
        "        ax.text(0.02, 0.98, annotation_text, \n",
        "                transform=ax.transAxes, fontsize=10,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "        \n",
        "        ax.set_ylabel('WSE (ft)', fontsize=11)\n",
        "        ax.set_title(f'Station {xs}', fontsize=12, fontweight='bold')\n",
        "        ax.legend(loc='upper right', fontsize=9)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Format x-axis for dates\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))\n",
        "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "    axes[-1].set_xlabel('Date/Time', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\u2713 Helper plotting functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.347374Z",
          "iopub.status.busy": "2025-11-17T19:05:28.347110Z",
          "iopub.status.idle": "2025-11-17T19:05:28.350335Z",
          "shell.execute_reply": "2025-11-17T19:05:28.349925Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import ras-commander\n",
        "sys.path.append(str(Path(os.getcwd()).parent))\n",
        "from ras_commander import RasExamples, init_ras_project, RasControl, ras, RasCmdr\n",
        "\n",
        "print(f\"RasControl supports: {list(RasControl.SUPPORTED_VERSIONS.keys())[:5]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract and Initialize Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.352379Z",
          "iopub.status.busy": "2025-11-17T19:05:28.352111Z",
          "iopub.status.idle": "2025-11-17T19:05:28.490274Z",
          "shell.execute_reply": "2025-11-17T19:05:28.489921Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract Bald Eagle Creek (has steady Plan 02 and unsteady Plan 01)\n",
        "project_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "\n",
        "# Initialize with version (required for RasControl)\n",
        "init_ras_project(project_path, \"6.6\")  # or \"66\", \"6.5\", \"4.1\", \"41\", etc.\n",
        "\n",
        "print(f\"Project: {ras.project_name}\")\n",
        "print(f\"Version: {ras.ras_version}\")\n",
        "print(f\"\\nPlans:\")\n",
        "print(ras.plan_df[['plan_number', 'Plan Title', 'flow_type',\"full_path\"]])\n",
        "\n",
        "# Use the full_path from plan_df to do the following for each plain text plan file: \n",
        "# Find the following values and change them\n",
        "# Change \"Output Interval=10MIN\" \n",
        "# Change \"Mapping Interval=10MIN\" \n",
        "\n",
        "\n",
        "import re, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ...existing code...\n",
        "def update_plan_intervals_from_plan_df(plan_df, plan_numbers=None,\n",
        "                                       output_interval=None, mapping_interval=None,\n",
        "                                       make_backup=True, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    Replace Output Interval and Mapping Interval in plain-text plan files referenced by plan_df['full_path'].\n",
        "    - plan_numbers: list of plan_number strings to limit changes (e.g. ['01','02']) or None for all.\n",
        "    - output_interval / mapping_interval: strings like '6MIN', '10MIN' (include unit).\n",
        "    \"\"\"\n",
        "    for _, row in plan_df.iterrows():\n",
        "        plan_no = str(row.get('plan_number', '')).zfill(2)\n",
        "        if plan_numbers and plan_no not in [str(p).zfill(2) for p in plan_numbers]:\n",
        "            continue\n",
        "\n",
        "        fp = Path(row.get('full_path', ''))\n",
        "        if not fp.exists():\n",
        "            print(f\"Missing file: {fp}\")\n",
        "            continue\n",
        "\n",
        "        text = fp.read_text(encoding=encoding, errors='ignore')\n",
        "        new_text = text\n",
        "\n",
        "        if output_interval:\n",
        "            # Use a callable replacement to avoid accidental numeric backreference parsing (e.g. \"\\16MIN\")\n",
        "            new_text = re.sub(\n",
        "                r'(?i)(Output\\s*Interval\\s*=\\s*)(\\S+)',\n",
        "                lambda m, out=output_interval: m.group(1) + out,\n",
        "                new_text\n",
        "            )\n",
        "\n",
        "        if mapping_interval:\n",
        "            new_text = re.sub(\n",
        "                r'(?i)(Mapping\\s*Interval\\s*=\\s*)(\\S+)',\n",
        "                lambda m, mp=mapping_interval: m.group(1) + mp,\n",
        "                new_text\n",
        "            )\n",
        "\n",
        "        if new_text != text:\n",
        "            if make_backup:\n",
        "                bak = fp.with_suffix(fp.suffix + '.bak')\n",
        "                shutil.copy(fp, bak)\n",
        "            fp.write_text(new_text, encoding=encoding)\n",
        "            print(f\"Updated {fp} (Plan {plan_no})\")\n",
        "        else:\n",
        "            print(f\"No change needed: {fp} (Plan {plan_no})\")\n",
        "# ...existing code...\n",
        "\n",
        "# Example usage: update Plan 01 (unsteady) to 6MIN intervals\n",
        "update_plan_intervals_from_plan_df(ras.plan_df, plan_numbers=['01'],\n",
        "                                   output_interval='10MIN', mapping_interval='10MIN',\n",
        "                                   make_backup=True)\n",
        "update_plan_intervals_from_plan_df(ras.plan_df, plan_numbers=['02'],\n",
        "                                   output_interval='10MIN', mapping_interval='10MIN',\n",
        "                                   make_backup=True)\n",
        "init_ras_project(project_path, \"6.6\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.492030Z",
          "iopub.status.busy": "2025-11-17T19:05:28.491822Z",
          "iopub.status.idle": "2025-11-17T19:05:28.505453Z",
          "shell.execute_reply": "2025-11-17T19:05:28.505039Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Steady State (Plan 02)\n",
        "\n",
        "Extract steady profiles. **Note:** `run_plan()` automatically sets Plan 02 as current!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.507423Z",
          "iopub.status.busy": "2025-11-17T19:05:28.507171Z",
          "iopub.status.idle": "2025-11-17T19:05:51.438318Z",
          "shell.execute_reply": "2025-11-17T19:05:51.437852Z"
        }
      },
      "outputs": [],
      "source": [
        "# Run Plan 02 (auto-sets as current, then runs)\n",
        "print(\"Running Plan 02 (Steady)...\")\n",
        "\n",
        "# NEW BEHAVIOR: run_plan() now checks if plan is current before running\n",
        "# - If plan is already current (results are up-to-date), it skips the computation\n",
        "# - To force recomputation regardless: RasControl.run_plan(\"02\", force_recompute=True)\n",
        "success, msgs = RasControl.run_plan(\"02\", force_recompute=True)\n",
        "print(f\"Success: {success}, Messages: {len(msgs)}\")\n",
        "print(msgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Computation Messages (Steady Flow)\n",
        "\n",
        "After running the plan, we can extract detailed computation messages using `RasControl.get_comp_msgs()`. This method:\n",
        "- Reads from `.comp_msgs.txt` or `.computeMsgs.txt` files (version-dependent)\n",
        "- Falls back to HDF extraction if .txt files not available\n",
        "- Returns detailed information about the computation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:51.440440Z",
          "iopub.status.busy": "2025-11-17T19:05:51.440210Z",
          "iopub.status.idle": "2025-11-17T19:05:51.449904Z",
          "shell.execute_reply": "2025-11-17T19:05:51.448693Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract computation messages for steady flow Plan 02\n",
        "print(\"=\"*80)\n",
        "print(\"COMPUTATION MESSAGES - Plan 02 (Steady Flow)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "msgs_steady = RasControl.get_comp_msgs(\"02\")\n",
        "\n",
        "if msgs_steady:\n",
        "    print(f\"\\nExtracted {len(msgs_steady)} characters of computation messages\\n\")\n",
        "    \n",
        "    # Display first 800 characters\n",
        "    print(\"Computation messages (first 800 characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(msgs_steady[:800])\n",
        "    \n",
        "    if len(msgs_steady) > 800:\n",
        "        print(\"\\n... (truncated) ...\")\n",
        "else:\n",
        "    print(\"No computation messages available for Plan 02\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:51.452979Z",
          "iopub.status.busy": "2025-11-17T19:05:51.452668Z",
          "iopub.status.idle": "2025-11-17T19:05:54.930528Z",
          "shell.execute_reply": "2025-11-17T19:05:54.929999Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract steady results (auto-sets Plan 02 as current)\n",
        "df_steady = RasControl.get_steady_results(\"02\")\n",
        "\n",
        "print(f\"Rows: {len(df_steady)}\")\n",
        "print(f\"Profiles: {df_steady['profile'].nunique()}\")\n",
        "print(f\"XS: {df_steady['node_id'].nunique()}\")\n",
        "df_steady.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:54.932440Z",
          "iopub.status.busy": "2025-11-17T19:05:54.932282Z",
          "iopub.status.idle": "2025-11-17T19:05:55.133019Z",
          "shell.execute_reply": "2025-11-17T19:05:55.132476Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEADY FLOW: Longitudinal Profiles by River/Reach\n",
        "# ============================================================================\n",
        "\n",
        "# Convert node_id to float for proper sorting\n",
        "df_steady['node_id'] = df_steady['node_id'].astype(float)\n",
        "\n",
        "# Group by River/Reach and create separate plots\n",
        "for (river, reach), group_df in df_steady.groupby(['river', 'reach']):\n",
        "    \n",
        "    # Sort by station (descending - upstream to downstream per HEC-RAS convention)\n",
        "    group_df_sorted = group_df.sort_values('node_id', ascending=False)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 7))\n",
        "    \n",
        "    # Get unique profiles and plot each one\n",
        "    profiles = sorted(group_df['profile'].unique())\n",
        "    colors = plt.cm.viridis(np.linspace(0, 0.9, len(profiles)))\n",
        "    \n",
        "    for idx, profile in enumerate(profiles):\n",
        "        prof_data = group_df_sorted[group_df_sorted['profile'] == profile]\n",
        "        ax.plot(prof_data['node_id'], prof_data['wsel'], \n",
        "                marker='o', markersize=3, linewidth=2, \n",
        "                color=colors[idx], label=f'WSE: {profile}', alpha=0.8)\n",
        "    \n",
        "    # Add channel invert (plot once, not for each profile)\n",
        "    invert = group_df_sorted.drop_duplicates('node_id')[['node_id', 'min_ch_el']].sort_values('node_id', ascending=False)\n",
        "    ax.plot(invert['node_id'], invert['min_ch_el'], \n",
        "            'k--', linewidth=2.5, alpha=0.7, label='Channel Invert')\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_xlabel('River Station', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Elevation (ft)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title(f'{river} - {reach}\\nSteady Flow Water Surface Profiles', \n",
        "                 fontsize=15, fontweight='bold', pad=15)\n",
        "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    ax.invert_xaxis()  # Upstream (larger stations) on left\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\u2713 Plotted {len(profiles)} profiles for {river} - {reach}\")\n",
        "    print(f\"  Station range: {group_df['node_id'].min():.1f} to {group_df['node_id'].max():.1f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:55.135745Z",
          "iopub.status.busy": "2025-11-17T19:05:55.135457Z",
          "iopub.status.idle": "2025-11-17T19:05:55.149829Z",
          "shell.execute_reply": "2025-11-17T19:05:55.149281Z"
        }
      },
      "outputs": [],
      "source": [
        "# Export\n",
        "Path(\"working\").mkdir(exist_ok=True)\n",
        "df_steady.to_csv(\"working/steady_plan02.csv\", index=False)\n",
        "print(f\"Exported {len(df_steady)} rows to working/steady_plan02.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Unsteady Time Series (Plan 01)\n",
        "\n",
        "Extract unsteady results. **Note:** Methods automatically set Plan 01 as current!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:55.151959Z",
          "iopub.status.busy": "2025-11-17T19:05:55.151619Z",
          "iopub.status.idle": "2025-11-17T19:07:31.696996Z",
          "shell.execute_reply": "2025-11-17T19:07:31.696555Z"
        }
      },
      "outputs": [],
      "source": [
        "# Run Plan 01 (auto-sets as current, waits for completion)\n",
        "# This may take 5-10 minutes!\n",
        "print(\"Running Plan 01 (Unsteady)...\")\n",
        "# success, msgs = RasControl.run_plan(new_plan)  >> Don't use this, it always sets cores to max\n",
        "RasCmdr.compute_plan(\"01\", clear_geompre=True, num_cores=2)  ## Use this instead, it's ras-commander's direct command line wrapper with extra arguments\n",
        "   \n",
        "print(f\"Success: {success}\")\n",
        "print(f\"Messages: {msgs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:31.699394Z",
          "iopub.status.busy": "2025-11-17T19:07:31.699111Z",
          "iopub.status.idle": "2025-11-17T19:07:32.773695Z",
          "shell.execute_reply": "2025-11-17T19:07:32.773223Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get output times (auto-sets Plan 01 as current)\n",
        "times = RasControl.get_output_times(\"01\")\n",
        "print(f\"Found {len(times)} timesteps\")\n",
        "print(f\"First: {times[0]}\")\n",
        "print(f\"Last: {times[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Computation Messages (Unsteady Flow)\n",
        "\n",
        "Similarly, we can extract computation messages for the unsteady flow plan to review:\n",
        "- Simulation timing and performance\n",
        "- Convergence information\n",
        "- Any warnings or errors encountered during computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:32.775767Z",
          "iopub.status.busy": "2025-11-17T19:07:32.775512Z",
          "iopub.status.idle": "2025-11-17T19:07:32.789775Z",
          "shell.execute_reply": "2025-11-17T19:07:32.789282Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract computation messages for unsteady flow Plan 01\n",
        "print(\"=\"*80)\n",
        "print(\"COMPUTATION MESSAGES - Plan 01 (Unsteady Flow)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "msgs_unsteady = RasControl.get_comp_msgs(\"01\")\n",
        "\n",
        "if msgs_unsteady:\n",
        "    print(f\"\\nExtracted {len(msgs_unsteady)} characters of computation messages\\n\")\n",
        "    \n",
        "    # Display first 800 characters\n",
        "    print(\"Computation messages (first 800 characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(msgs_unsteady[:800])\n",
        "    \n",
        "    if len(msgs_unsteady) > 800:\n",
        "        print(\"\\n... (truncated) ...\")\n",
        "    \n",
        "    # Check for errors/warnings\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Checking for warnings/errors...\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    lines = msgs_unsteady.split('\\n')\n",
        "    issues = [l for l in lines if 'error' in l.lower() or 'warning' in l.lower()]\n",
        "    \n",
        "    if issues:\n",
        "        print(f\"Found {len(issues)} warning/error lines:\")\n",
        "        for issue in issues[:5]:  # Show first 5\n",
        "            print(f\"  - {issue.strip()}\")\n",
        "    else:\n",
        "        print(\"\u2713 No warnings or errors found\")\n",
        "else:\n",
        "    print(\"No computation messages available for Plan 01\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:32.791418Z",
          "iopub.status.busy": "2025-11-17T19:07:32.791276Z",
          "iopub.status.idle": "2025-11-17T19:08:04.208694Z",
          "shell.execute_reply": "2025-11-17T19:08:04.208082Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract unsteady (limit to 10 timesteps for demo)\n",
        "df_unsteady = RasControl.get_unsteady_results(\"01\")\n",
        "\n",
        "print(f\"Rows: {len(df_unsteady)}\")\n",
        "print(f\"Timesteps: {df_unsteady['time_index'].nunique()}\")\n",
        "print(f\"XS: {df_unsteady['node_id'].nunique()}\")\n",
        "df_unsteady.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding \"Max WS\" in Unsteady Output\n",
        "\n",
        "**Important:** HEC-RAS unsteady results include a special row with `time_string=\"Max WS\"` (time_index=1). This contains the **maximum values that occurred at ANY computational timestep** during the entire simulation, not just at output intervals.\n",
        "\n",
        "**Why this matters:**\n",
        "- Output intervals (e.g., every 1 hour) may miss the peak flow/WSE\n",
        "- Computational timesteps (e.g., every 30 seconds) capture the true maximum\n",
        "- \"Max WS\" shows the absolute peak, even if it wasn't saved to an output interval\n",
        "\n",
        "**How to use it:**\n",
        "- Include in DataFrame for reference (critical data!)\n",
        "- Filter out when plotting time series (it's not a timestep)\n",
        "- Show as horizontal reference line on plots to indicate peak\n",
        "\n",
        "The next cell demonstrates this pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:04.211178Z",
          "iopub.status.busy": "2025-11-17T19:08:04.210883Z",
          "iopub.status.idle": "2025-11-17T19:08:05.861386Z",
          "shell.execute_reply": "2025-11-17T19:08:05.860496Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Time Series at Multiple Cross Sections\n",
        "# ============================================================================\n",
        "# NOTE: This cell shows LEGACY manual datetime parsing for reference.\n",
        "# For v0.81.0+, see the cell below for automatic datetime usage!\n",
        "# ============================================================================\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "\n",
        "# Convert node_id to float\n",
        "df_unsteady['node_id'] = df_unsteady['node_id'].astype(float)\n",
        "\n",
        "# Separate Max WS from timeseries data\n",
        "df_maxws = df_unsteady[df_unsteady['time_string'] == 'Max WS'].copy()\n",
        "df_timeseries = df_unsteady[df_unsteady['time_string'] != 'Max WS'].copy()\n",
        "\n",
        "# LEGACY: Parse datetime for timeseries (NOT NEEDED in v0.81.0+ - datetime column auto-included!)\n",
        "df_timeseries['datetime'] = pd.to_datetime(df_timeseries['time_string'], \n",
        "                                           format='%d%b%Y %H%M', errors='coerce')\n",
        "\n",
        "# Select cross sections to plot (every 20th station for manageable plot count)\n",
        "all_xs = sorted(df_timeseries['node_id'].unique(), reverse=True)  # Upstream to downstream\n",
        "selected_xs = all_xs[::20]  # Adjust step size as needed (20, 30, etc.)\n",
        "\n",
        "if len(selected_xs) == 0:\n",
        "    selected_xs = [all_xs[0]]  # At least plot one\n",
        "\n",
        "print(f\"Creating time series plots for {len(selected_xs)} cross sections:\")\n",
        "print(f\"  Stations: {[f'{xs:.1f}' for xs in selected_xs]}\\n\")\n",
        "\n",
        "# Create subplots - one per cross section\n",
        "n_xs = len(selected_xs)\n",
        "fig, axes = plt.subplots(n_xs, 1, figsize=(16, 4*n_xs))\n",
        "if n_xs == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, xs in enumerate(selected_xs):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Get data for this cross section\n",
        "    xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "    maxws_data = df_maxws[df_maxws['node_id'] == xs]\n",
        "    \n",
        "    if len(xs_data) == 0:\n",
        "        ax.text(0.5, 0.5, f'No data for station {xs:.1f}', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        continue\n",
        "    \n",
        "    # Plot WSE time series\n",
        "    ax.plot(xs_data['datetime'], xs_data['wsel'], \n",
        "            'b-o', linewidth=2, markersize=5, label='WSE (output intervals)', \n",
        "            alpha=0.8)\n",
        "    \n",
        "    # Get max values\n",
        "    max_ws_value = maxws_data['wsel'].iloc[0] if len(maxws_data) > 0 else None\n",
        "    max_output_value = xs_data['wsel'].max()\n",
        "    max_output_time = xs_data.loc[xs_data['wsel'].idxmax(), 'datetime']\n",
        "    \n",
        "    # Add horizontal line for computational Max WS\n",
        "    #if max_ws_value:\n",
        "    #    ax.axhline(max_ws_value, color='r', linestyle='--', \n",
        "    #               linewidth=2, alpha=0.7, label='Max WS (computational)')\n",
        "    \n",
        "    # Create annotation text box\n",
        "    annotation_lines = [\n",
        "        f\"Max WS (computational): {max_ws_value:.2f} ft\" if max_ws_value else \"Max WS: N/A\",\n",
        "        f\"Max (output interval): {max_output_value:.2f} ft\",\n",
        "        f\"  at {max_output_time.strftime('%m/%d %H:%M')}\" if pd.notna(max_output_time) else \"\"\n",
        "    ]\n",
        "    annotation_text = '\\n'.join(annotation_lines)\n",
        "    \n",
        "    ax.text(0.02, 0.98, annotation_text, \n",
        "            transform=ax.transAxes, fontsize=10,\n",
        "            verticalalignment='top', horizontalalignment='left',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.9, pad=0.5))\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_ylabel('WSE (ft)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'Station {xs:.1f}', fontsize=12, fontweight='bold', loc='left')\n",
        "    ax.legend(loc='upper right', fontsize=9, framealpha=0.9)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Format x-axis for dates\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M'))\n",
        "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))  # Adjust interval as needed\n",
        "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center', fontsize=9)\n",
        "\n",
        "# Add common x-label to bottom subplot\n",
        "axes[-1].set_xlabel('Date / Time', fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Unsteady Flow: Water Surface Time Series at Selected Cross Sections',\n",
        "             fontsize=16, fontweight='bold', y=1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u2713 Created time series plots for {len(selected_xs)} stations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NEW in v0.81.0: Automatic Datetime Parsing\n",
        "\n",
        "Starting in version 0.81.0, `get_unsteady_results()` automatically includes a `datetime` column with proper datetime64[ns] objects. **Manual parsing is no longer needed!**\n",
        "\n",
        "**Key Improvements:**\n",
        "- \u2705 `datetime` column added automatically\n",
        "- \u2705 Already in datetime64[ns] format (not strings)\n",
        "- \u2705 \"Max WS\" rows have `pd.NaT` for clean filtering\n",
        "- \u2705 Immediate compatibility with pandas datetime operations\n",
        "- \u2705 Backward compatible - `time_string` still included\n",
        "\n",
        "The cell above shows the old manual parsing method (kept for reference). The next cell demonstrates the modern approach using the automatic `datetime` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:05.867596Z",
          "iopub.status.busy": "2025-11-17T19:08:05.867396Z",
          "iopub.status.idle": "2025-11-17T19:08:05.884233Z",
          "shell.execute_reply": "2025-11-17T19:08:05.883715Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MODERN APPROACH: Using Automatic datetime Column (v0.81.0+)\n",
        "# ============================================================================\n",
        "\n",
        "# Check that datetime column exists and is already parsed\n",
        "print(\"DataFrame columns:\")\n",
        "print(df_unsteady.columns.tolist())\n",
        "print(f\"\\ndatetime column type: {df_unsteady['datetime'].dtype}\")\n",
        "print(f\"Sample datetime values:\")\n",
        "print(df_unsteady[['time_string', 'datetime']].head(10))\n",
        "\n",
        "# Separate using datetime column (NaT for Max WS rows)\n",
        "df_maxws_modern = df_unsteady[df_unsteady['datetime'].isna()].copy()\n",
        "df_timeseries_modern = df_unsteady[df_unsteady['datetime'].notna()].copy()\n",
        "\n",
        "print(f\"\\nMax WS rows: {len(df_maxws_modern)}\")\n",
        "print(f\"Timeseries rows: {len(df_timeseries_modern)}\")\n",
        "\n",
        "# Use pandas datetime accessors directly - no manual parsing needed!\n",
        "print(\"\\nDatetime operations (no parsing required!):\")\n",
        "print(f\"  Simulation start: {df_timeseries_modern['datetime'].min()}\")\n",
        "print(f\"  Simulation end: {df_timeseries_modern['datetime'].max()}\")\n",
        "print(f\"  Duration: {df_timeseries_modern['datetime'].max() - df_timeseries_modern['datetime'].min()}\")\n",
        "print(f\"  Unique hours: {df_timeseries_modern['datetime'].dt.hour.unique()[:10]}\")\n",
        "\n",
        "# Time-based filtering (modern approach)\n",
        "# Example: Get data for a specific date\n",
        "specific_date = pd.Timestamp('1999-02-19')\n",
        "feb_19_data = df_timeseries_modern[df_timeseries_modern['datetime'].dt.date == specific_date.date()]\n",
        "print(f\"\\nData points on {specific_date.date()}: {len(feb_19_data)}\")\n",
        "\n",
        "# Example: Get data for specific time range\n",
        "start_time = pd.Timestamp('1999-02-18 12:00:00')\n",
        "end_time = pd.Timestamp('1999-02-20 12:00:00')\n",
        "time_range_data = df_timeseries_modern[\n",
        "    (df_timeseries_modern['datetime'] >= start_time) & \n",
        "    (df_timeseries_modern['datetime'] <= end_time)\n",
        "]\n",
        "print(f\"Data points between {start_time} and {end_time}: {len(time_range_data)}\")\n",
        "\n",
        "print(\"\\n\u2713 Modern datetime functionality demonstrated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:05.886246Z",
          "iopub.status.busy": "2025-11-17T19:08:05.885985Z",
          "iopub.status.idle": "2025-11-17T19:08:06.063285Z",
          "shell.execute_reply": "2025-11-17T19:08:06.062819Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Maximum Water Surface Envelope\n",
        "# ============================================================================\n",
        "\n",
        "# Sort by station for profile view\n",
        "max_wse_sorted = df_maxws.sort_values('node_id', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 7))\n",
        "\n",
        "# Plot maximum WSE envelope\n",
        "ax.plot(max_wse_sorted['node_id'], max_wse_sorted['wsel'],\n",
        "        'r-o', linewidth=2.5, markersize=5, \n",
        "        label='Max WS Envelope (peak at any computational timestep)', \n",
        "        alpha=0.8)\n",
        "\n",
        "# Add channel invert\n",
        "invert = max_wse_sorted[['node_id', 'min_ch_el']].drop_duplicates('node_id').sort_values('node_id', ascending=False)\n",
        "ax.plot(invert['node_id'], invert['min_ch_el'],\n",
        "        'k--', linewidth=2.5, alpha=0.7, label='Channel Invert')\n",
        "\n",
        "# Fill between for visual clarity\n",
        "ax.fill_between(max_wse_sorted['node_id'], \n",
        "                max_wse_sorted['min_ch_el'], \n",
        "                max_wse_sorted['wsel'],\n",
        "                alpha=0.2, color='blue', label='Maximum Flow Depth')\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('River Station', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Elevation (ft)', fontsize=13, fontweight='bold')\n",
        "ax.set_title('Maximum Water Surface Envelope\\n(Peak elevation reached at any computational timestep during simulation)',\n",
        "             fontsize=15, fontweight='bold', pad=15)\n",
        "ax.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.invert_xaxis()  # Upstream on left\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "max_depth = (max_wse_sorted['wsel'] - max_wse_sorted['min_ch_el']).max()\n",
        "max_depth_station = max_wse_sorted.loc[(max_wse_sorted['wsel'] - max_wse_sorted['min_ch_el']).idxmax(), 'node_id']\n",
        "\n",
        "print(f\"\\n\u2713 Maximum Water Surface Envelope\")\n",
        "print(f\"  Max depth: {max_depth:.2f} ft at station {max_depth_station:.1f}\")\n",
        "print(f\"  Highest WSE: {max_wse_sorted['wsel'].max():.2f} ft at station {max_wse_sorted.loc[max_wse_sorted['wsel'].idxmax(), 'node_id']:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:06.065813Z",
          "iopub.status.busy": "2025-11-17T19:08:06.065276Z",
          "iopub.status.idle": "2025-11-17T19:08:06.214514Z",
          "shell.execute_reply": "2025-11-17T19:08:06.213873Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Velocity Hydrographs at Key Locations\n",
        "# ============================================================================\n",
        "\n",
        "# Select critical stations (upstream, middle, downstream)\n",
        "all_stations = sorted(df_timeseries['node_id'].unique(), reverse=True)\n",
        "n_stations = len(all_stations)\n",
        "\n",
        "if n_stations >= 3:\n",
        "    critical_xs = [\n",
        "        all_stations[0],                    # Upstream\n",
        "        all_stations[n_stations // 2],      # Middle\n",
        "        all_stations[-1]                    # Downstream\n",
        "    ]\n",
        "    labels = ['Upstream', 'Midstream', 'Downstream']\n",
        "else:\n",
        "    critical_xs = all_stations\n",
        "    labels = [f'Station {i+1}' for i in range(len(critical_xs))]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "# Plot velocity hydrographs\n",
        "for idx, (xs, label) in enumerate(zip(critical_xs, labels)):\n",
        "    xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "    ax.plot(xs_data['datetime'], xs_data['velocity'],\n",
        "            marker='o', linewidth=2, markersize=5,\n",
        "            color=colors[idx % len(colors)],\n",
        "            label=f'{label} (Sta {xs:.1f})', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Date / Time', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Velocity (ft/s)', fontsize=13, fontweight='bold')\n",
        "ax.set_title('Velocity Hydrographs at Key Cross Sections', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u2713 Created velocity hydrographs for {len(critical_xs)} key locations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "## Complete RasControl API\n",
        "\n",
        "```python\n",
        "# Initialize with version (flexible formats)\n",
        "init_ras_project(path, \"4.1\")  # or \"41\", \"66\", \"5.0.6\", \"506\", etc.\n",
        "\n",
        "# Run plans (auto-sets as current, waits for completion)\n",
        "# NOTE: run_plan() now checks if plan is current before running\n",
        "# If results are up-to-date, it skips computation (faster workflow)\n",
        "success, msgs = RasControl.run_plan(\"02\")\n",
        "\n",
        "# To force recomputation regardless of current status:\n",
        "success, msgs = RasControl.run_plan(\"02\", force_recompute=True)\n",
        "\n",
        "# Extract steady (auto-sets as current)\n",
        "df_steady = RasControl.get_steady_results(\"02\")\n",
        "\n",
        "# Extract unsteady (auto-sets as current, includes Max WS)\n",
        "df_unsteady = RasControl.get_unsteady_results(\"01\")\n",
        "\n",
        "# Filter for time series plotting\n",
        "df_timeseries = df_unsteady[df_unsteady['time_string'] != 'Max WS']\n",
        "max_wse = df_unsteady[df_unsteady['time_string'] == 'Max WS']['wsel'].iloc[0]\n",
        "```\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- \u2705 Plan numbers (not file paths)\n",
        "- \u2705 Auto-sets current plan\n",
        "- \u2705 Blocks until completion\n",
        "- \u2705 Steady AND unsteady\n",
        "- \u2705 All versions 3.0-6.7\n",
        "- \u2705 Flexible version formats\n",
        "- \u2705 Includes Max WS data\n",
        "- \u2705 Multi-version comparison (optional)\n",
        "\n",
        "## What Was Demonstrated\n",
        "\n",
        "1. **Steady workflow** - Plan 02 extraction and plotting\n",
        "2. **Unsteady workflow** - Plan 01 time series with Max WS reference\n",
        "3. **Max WS handling** - Understanding and visualizing peak values\n",
        "4. **Multi-version comparison** - Optional cells for version validation\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Apply to your legacy HEC-RAS models\n",
        "- Run multi-version comparison for migration validation\n",
        "- For HEC-RAS 6.0+: Use HDF methods for better performance\n",
        "  - `19_steady_flow_analysis.ipynb`\n",
        "  - `10_1d_hdf_data_extraction.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What This Creates\n",
        "\n",
        "Running the multi-version comparison cells will:\n",
        "\n",
        "**New Plans in Project:**\n",
        "- `02_41`, `02_506`, `02_63`, `02_66` (steady)\n",
        "- `01_41`, `01_506`, `01_63`, `01_66` (unsteady)\n",
        "\n",
        "**CSV Files in working/:**\n",
        "- `steady_v41.csv`, `steady_v506.csv`, `steady_v63.csv`, `steady_v66.csv`\n",
        "- `unsteady_v41.csv`, `unsteady_v506.csv`, `unsteady_v63.csv`, `unsteady_v66.csv`\n",
        "\n",
        "**Results:**\n",
        "- All plans remain in project for further analysis\n",
        "- CSV files for external comparison\n",
        "- Plots showing version differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:06.216949Z",
          "iopub.status.busy": "2025-11-17T19:08:06.216484Z",
          "iopub.status.idle": "2025-11-17T19:17:53.446182Z",
          "shell.execute_reply": "2025-11-17T19:17:53.445593Z"
        }
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Multi-version unsteady comparison\n",
        "# Uncomment to run (may take 1-2 Hr)\n",
        "\n",
        "from ras_commander import RasPlan\n",
        "\n",
        "# Step 1: Update Plan 01 output intervals for more detail\n",
        "print(\"Step 1: Updating Plan 01 intervals...\")\n",
        "init_ras_project(project_path, \"6.6\")  # Use latest for modification\n",
        "\n",
        "# Update intervals: Output=15MIN, Mapping=15MIN\n",
        "RasPlan.update_plan_intervals(\"01\", \n",
        "                              output_interval=\"10MIN\",\n",
        "                              mapping_interval=\"10MIN\")\n",
        "print(\"  \u2713 Output Interval: 1HOUR \u2192 6MIN\")\n",
        "print(\"  \u2713 Mapping Interval: 1HOUR \u2192 6MIN\\n\")\n",
        "\n",
        "# Step 2: Run across versions\n",
        "# All versions with actual COM interfaces\n",
        "test_versions = [\n",
        "    (\"4.1\", \"41\"),       # HEC-RAS 4.1     \u2192 RAS41.HECRASController\n",
        "#    (\"5.0.1\", \"501\"),    # HEC-RAS 5.0.1   \u2192 RAS501.HECRASController  >> FREEZES, SKIP, LIKELY ISSUE WITH HECRASCONTROLLER\n",
        "#    (\"5.0.3\", \"503\"),    # HEC-RAS 5.0.3   \u2192 RAS503.HECRASController\n",
        "    (\"5.0.4\", \"504\"),    # HEC-RAS 5.0.4   \u2192 RAS504.HECRASController\n",
        "    (\"5.0.6\", \"506\"),    # HEC-RAS 5.0.6   \u2192 RAS506.HECRASController\n",
        "    (\"6.3.1\", \"631\"),    # HEC-RAS 6.3.1   \u2192 RAS631.HECRASController\n",
        "    (\"6.6\", \"66\"),       # HEC-RAS 6.6     \u2192 RAS66.HECRASController\n",
        "]\n",
        "\n",
        "unsteady_results = {}\n",
        "max_ws_data = {}  # Store Max WS separately\n",
        "\n",
        "print(\"=== MULTI-VERSION UNSTEADY COMPARISON ===\\n\")\n",
        "\n",
        "for version_name, version_code in test_versions:\n",
        "    print(f\"Processing HEC-RAS {version_name}...\")\n",
        "    \n",
        "    # Clone Plan 01 for this version\n",
        "    new_plan = RasPlan.clone_plan(\"01\",\n",
        "                      new_shortid=f\"Unsteady_{version_code}\",\n",
        "                      new_title=f\"Unsteady - v{version_name}\")\n",
        "    print(f\"  Cloned to Plan {new_plan}\")\n",
        "    \n",
        "    # Re-initialize with this version\n",
        "    init_ras_project(project_path, version_name)\n",
        "    \n",
        "    # Run the plan (this will take several minutes!)\n",
        "    print(f\"  Running Plan {new_plan} (may take 5-10 min)...\")\n",
        "    # NOTE: Using force_recompute=True for fresh cloned plans to ensure computation\n",
        "    # (Default behavior now checks if plan is current and skips if already computed)\n",
        "    #success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "    success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "    print(success, msgs)\n",
        "    if success:\n",
        "        # Extract results (limit to 20 timesteps for comparison)\n",
        "        df = RasControl.get_unsteady_results(new_plan)\n",
        "        \n",
        "        # Separate Max WS from timeseries\n",
        "        max_ws_data[version_name] = df[df['time_string'] == 'Max WS'].copy()\n",
        "        unsteady_results[version_name] = df[df['time_string'] != 'Max WS'].copy()\n",
        "        \n",
        "        # Save CSV\n",
        "        csv_path = Path(f\"working/unsteady_v{version_code}.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"  \u2713 Extracted {len(df)} rows -> {csv_path}\")\n",
        "    else:\n",
        "        print(f\"  \u2717 Failed\")\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:17:53.448669Z",
          "iopub.status.busy": "2025-11-17T19:17:53.448393Z",
          "iopub.status.idle": "2025-11-17T19:18:03.889215Z",
          "shell.execute_reply": "2025-11-17T19:18:03.888522Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot comparison at multiple cross sections (every 5th station)\n",
        "if unsteady_results:\n",
        "    # Gather all station IDs across versions\n",
        "    xs_set = set()\n",
        "    for df in unsteady_results.values():\n",
        "        try:\n",
        "            xs_set.update(df['node_id'].astype(float).unique().tolist())\n",
        "        except Exception:\n",
        "            xs_set.update(df['node_id'].unique().tolist())\n",
        "\n",
        "    all_xs = sorted(xs_set, reverse=True)  # upstream -> downstream\n",
        "    if not all_xs:\n",
        "        print(\"No cross section data found in unsteady_results\")\n",
        "    else:\n",
        "        # Select every 5th cross section for plotting (adjust step as needed)\n",
        "        step = 5\n",
        "        selected_xs = all_xs[::step] if len(all_xs) > step else all_xs\n",
        "        print(f\"Plotting {len(selected_xs)} stations (every {step}th of {len(all_xs)} total)\")\n",
        "\n",
        "        for xs_id in selected_xs:\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 6))\n",
        "\n",
        "            # Plot WSE time series for each version at this station\n",
        "            for version, df in unsteady_results.items():\n",
        "                # FIX: Convert node_id to float for comparison\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id].sort_values('time_index')\n",
        "                if len(xs_data):\n",
        "                    ax1.plot(xs_data['time_index'], xs_data['wsel'],\n",
        "                             marker='o', label=f'v{version}', alpha=0.8)\n",
        "\n",
        "            # Add Max WS reference lines (if available) for this station\n",
        "            for version, df in max_ws_data.items():\n",
        "                try:\n",
        "                    df_float = df.copy()\n",
        "                    df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                    max_row = df_float[df_float['node_id'] == xs_id]\n",
        "                    if len(max_row):\n",
        "                        max_wse = float(max_row['wsel'].iloc[0])\n",
        "                        ax1.axhline(max_wse, linestyle='--', alpha=0.5, label=f'MaxWS v{version}')\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            ax1.set_xlabel('Time Index', fontsize=11)\n",
        "            ax1.set_ylabel('Water Surface Elevation (ft)', fontsize=11)\n",
        "            ax1.set_title(f'WSE Time Series at {xs_id} - Version Comparison',\n",
        "                          fontsize=13, fontweight='bold')\n",
        "            ax1.legend(fontsize=8)\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot Flow time series for each version at this station\n",
        "            for version, df in unsteady_results.items():\n",
        "                # FIX: Convert node_id to float for comparison\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id].sort_values('time_index')\n",
        "                if len(xs_data):\n",
        "                    ax2.plot(xs_data['time_index'], xs_data['flow'],\n",
        "                             marker='o', label=f'v{version}', alpha=0.8)\n",
        "\n",
        "            ax2.set_xlabel('Time Index', fontsize=11)\n",
        "            ax2.set_ylabel('Flow (cfs)', fontsize=11)\n",
        "            ax2.set_title(f'Flow Time Series at {xs_id} - Version Comparison',\n",
        "                          fontsize=13, fontweight='bold')\n",
        "            ax2.legend(fontsize=8)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Basic per-station stats\n",
        "            print(f\"\\nStation {xs_id}:\")\n",
        "            for version, df in unsteady_results.items():\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id]\n",
        "                if len(xs_data):\n",
        "                    print(f\"  v{version}: timesteps={len(xs_data)}, max_wse={xs_data['wsel'].max():.2f} ft\")\n",
        "                else:\n",
        "                    print(f\"  v{version}: no data\")\n",
        "\n",
        "        # Summary of Max WS across versions for the first selected station (if any)\n",
        "        if selected_xs:\n",
        "            summary_xs = selected_xs[0]\n",
        "            print(f\"\\nMax WSE by version at station {summary_xs}:\")\n",
        "            for version, df in max_ws_data.items():\n",
        "                try:\n",
        "                    df_float = df.copy()\n",
        "                    df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                    max_row = df_float[df_float['node_id'] == summary_xs]\n",
        "                    if len(max_row):\n",
        "                        max_wse = float(max_row['wsel'].iloc[0])\n",
        "                        print(f\"  v{version}: {max_wse:.2f} ft\")\n",
        "                    else:\n",
        "                        print(f\"  v{version}: N/A\")\n",
        "                except Exception:\n",
        "                    print(f\"  v{version}: N/A\")\n",
        "\n",
        "else:\n",
        "    print(\"Uncomment code above to run multi-version comparison\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:18:03.891945Z",
          "iopub.status.busy": "2025-11-17T19:18:03.891491Z",
          "iopub.status.idle": "2025-11-17T19:18:33.587488Z",
          "shell.execute_reply": "2025-11-17T19:18:33.586876Z"
        }
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Multi-version steady state comparison\n",
        "\n",
        "from ras_commander import RasPlan\n",
        "\n",
        "# Versions to test - all versions with actual COM interfaces\n",
        "test_versions = [\n",
        "  #  (\"4.1\", \"41\"),       # HEC-RAS 4.1     \u2192 RAS41.HECRASController\n",
        "  #  (\"5.0.1\", \"501\"),    # HEC-RAS 5.0.1   \u2192 RAS501.HECRASController\n",
        "  #  (\"5.0.3\", \"503\"),    # HEC-RAS 5.0.3   \u2192 RAS503.HECRASController\n",
        "    (\"5.0.4\", \"504\"),    # HEC-RAS 5.0.4   \u2192 RAS504.HECRASController\n",
        "    (\"5.0.6\", \"506\"),    # HEC-RAS 5.0.6   \u2192 RAS506.HECRASController\n",
        "    (\"6.3.1\", \"631\"),    # HEC-RAS 6.3.1   \u2192 RAS631.HECRASController\n",
        "    (\"6.6\", \"66\"),       # HEC-RAS 6.6     \u2192 RAS66.HECRASController\n",
        "]\n",
        "\n",
        "steady_results = {}\n",
        "\n",
        "print(\"=== MULTI-VERSION STEADY STATE COMPARISON ===\\n\")\n",
        "\n",
        "for version_name, version_code in test_versions:\n",
        "    print(f\"Processing HEC-RAS {version_name}...\")\n",
        "    \n",
        "    # Clone Plan 02 for this version\n",
        "    new_plan = RasPlan.clone_plan(\"02\",\n",
        "                      new_shortid=f\"Steady_{version_code}\",\n",
        "                      new_title=f\"Steady - v{version_name}\")\n",
        "    print(f\"  Cloned to Plan {new_plan}\")\n",
        "    \n",
        "    # Re-initialize with this version\n",
        "    init_ras_project(project_path, version_name)\n",
        "    \n",
        "    # Run the plan using ras-commander's compute_plan() instead of RasControl.run_plan\n",
        "    print(f\"  Running Plan {new_plan} with 2 cores...\")\n",
        "    try:\n",
        "        # Use direct command line execution, preferred over RasControl.run_plan\n",
        "        #RasCmdr.compute_plan(new_plan, clear_geompre=True, num_cores=2)\n",
        "        success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "        print(success, msgs)\n",
        "        # Extract results\n",
        "        df = RasControl.get_steady_results(new_plan)\n",
        "        steady_results[version_name] = df\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = Path(f\"working/steady_v{version_code}.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"  \u2713 Extracted {len(df)} rows -> {csv_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  \u2717 Failed: {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# Plot comparison - first profile from each version\n",
        "if steady_results:\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    \n",
        "    for version, df in steady_results.items():\n",
        "        first_prof = df[df['profile'] == df['profile'].iloc[0]]\n",
        "        ax.plot(range(len(first_prof)), first_prof['wsel'], \n",
        "                marker='o', label=f'v{version}', alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Cross Section Index', fontsize=12)\n",
        "    ax.set_ylabel('Water Surface Elevation (ft)', fontsize=12)\n",
        "    ax.set_title('Steady State Profile - Multi-Version Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n\u2713 Compared {len(steady_results)} versions\")\n",
        "\n",
        "else:\n",
        "    print(\"Uncomment code above to run multi-version comparison\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}