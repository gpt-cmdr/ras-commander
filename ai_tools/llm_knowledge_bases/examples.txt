Project Structure (files included):
├── 00_Using_RasExamples.ipynb
├── 01_project_initialization.ipynb
├── 02_plan_and_geometry_operations.ipynb
├── 03_unsteady_flow_operations.ipynb
├── 04_multiple_project_operations.ipynb
├── 05_single_plan_execution.ipynb
├── 06_executing_plan_sets.ipynb
├── 07_sequential_plan_execution.ipynb
├── 08_parallel_execution.ipynb
├── 09_plan_parameter_operations.ipynb
├── 101_Core_Sensitivity.ipynb
├── 102_benchmarking_versions_6.1_to_6.6.ipynb
├── 103_Running_AEP_Events_from_Atlas_14.ipynb
├── 104_Atlas14_AEP_Multi_Project.ipynb
├── 105_mannings_sensitivity_bulk_analysis.ipynb
├── 106_mannings_sensitivity_multi-interval.ipynb
├── 10_1d_hdf_data_extraction.ipynb
├── 11_2d_hdf_data_extraction.ipynb
├── 12_2d_hdf_data_extraction pipes and pumps.ipynb
├── 13_2d_detail_face_data_extraction.ipynb
├── 14_fluvial_pluvial_delineation.ipynb
├── 15_stored_map_generation.ipynb
├── 16_automating_ras_with_win32com.ipynb
├── 17_extracting_profiles_with_hecrascontroller and RasControl.ipynb
├── 18_breach_results_extraction.ipynb
├── 19_steady_flow_analysis.ipynb
├── 20_plaintext_geometry_operations.ipynb
├── 21_rasmap_raster_exports.ipynb
├── 22_dss_boundary_extraction.ipynb
├── 23_remote_execution_psexec.ipynb
├── AGENTS.md
├── README.md
├── REMOTE_WORKERS_README.md
├── RemoteWorkers.json
├── RemoteWorkers.json.template
├── flood_polygons.geojson
└── hyetographs
    ├── hyetograph_ARI_100_years_pos50pct_24hr.csv
    ├── hyetograph_ARI_10_years_pos50pct_24hr.csv
    ├── hyetograph_ARI_25_years_pos50pct_24hr.csv
    ├── hyetograph_ARI_2_years_pos50pct_24hr.csv
    ├── hyetograph_ARI_50_years_pos50pct_24hr.csv
    └── hyetograph_ARI_5_years_pos50pct_24hr.csv

File: C:\GH\ras-commander\examples\00_Using_RasExamples.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:36:37.154554Z",
          "iopub.status.busy": "2025-11-17T17:36:37.154336Z",
          "iopub.status.idle": "2025-11-17T17:36:39.149660Z",
          "shell.execute_reply": "2025-11-17T17:36:39.149051Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:37 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using RASExamples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Method for Calling HEC-RAS Example Projects by Folder Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:36:39.152344Z",
          "iopub.status.busy": "2025-11-17T17:36:39.152025Z",
          "iopub.status.idle": "2025-11-17T17:37:05.377294Z",
          "shell.execute_reply": "2025-11-17T17:37:05.376750Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Found zip file: C:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:39 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Project 'Muncie' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Existing folder for project 'Muncie' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Extracting project 'Davis'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Project 'Davis' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Existing folder for project 'Davis' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Successfully extracted project 'Davis' to C:\\GH\\ras-commander\\examples\\example_projects\\Davis\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Special Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Extracting special project 'NewOrleansMetro'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - Downloading special project from: https://www.hec.usace.army.mil/confluence/rasdocs/hgt/files/latest/299502039/299502111/1/1747692522764/NewOrleansMetroPipesExample.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:36:40 - ras_commander.RasExamples - INFO - This may take a few moments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:03 - ras_commander.RasExamples - INFO - Downloaded special project zip file to C:\\GH\\ras-commander\\examples\\example_projects\\NewOrleansMetro_temp.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:04 - ras_commander.RasExamples - INFO - Successfully extracted special project 'NewOrleansMetro' to C:\\GH\\ras-commander\\examples\\example_projects\\NewOrleansMetro\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:04 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Special Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:04 - ras_commander.RasExamples - INFO - Extracting special project 'BeaverLake'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:04 - ras_commander.RasExamples - INFO - Downloading special project from: https://www.hec.usace.army.mil/confluence/rasdocs/hgt/files/latest/299501780/299502090/1/1747692179014/BeaverLake-SWMM-Import-Solution.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:04 - ras_commander.RasExamples - INFO - This may take a few moments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Downloaded special project zip file to C:\\GH\\ras-commander\\examples\\example_projects\\BeaverLake_temp.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Successfully extracted special project 'BeaverLake' to C:\\GH\\ras-commander\\examples\\example_projects\\BeaverLake\n"
          ]
        },
        {
          "data": {
            "text/plain": "[\"[WindowsPath('C:/GH/ras-commander/examples/example_projects/Balde Eagle Creek'),\\n\", \" WindowsPath('C:/GH/ras-commander/examples/example_projects/BaldEagleCrkMulti2D'),\\n\", \" WindowsPath('C:/GH/ras-commander/examples/example_projects/Muncie'),\\n\", \" WindowsPath('C:/GH/ras-commander/examples/example_projects/Davis'),\\n\", \" WindowsPath('C:/GH/ras-commander/examples/example_projects/NewOrleansMetro'),\\n\", \" WindowsPath('C:/GH/ras-commander/examples/example_projects/BeaverLake')]\"]"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This Code Cell is All You Need\n",
        "# This is what this Class was intended to do: Help me make repeatable workflows around HEC-RAS Example Projects for testing and demonstration purposes. \n",
        "\n",
        "# Extract specific projects\n",
        "RasExamples.extract_project([\"Balde Eagle Creek\", \"BaldEagleCrkMulti2D\", \"Muncie\", \"Davis\", \"NewOrleansMetro\", \"BeaverLake\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RasExamples will not download a new .zip file if one already exists, this allows you to replace the Example_Projects_6_x.zip with your own zip file (with the same folder format as the HEC-RAS examples) and you will be able to load them by folder name for repeatable Test Driven Development\n",
        "\n",
        "Just make sure all project folders have unique folder names. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.379849Z",
          "iopub.status.busy": "2025-11-17T17:37:05.379645Z",
          "iopub.status.idle": "2025-11-17T17:37:05.384262Z",
          "shell.execute_reply": "2025-11-17T17:37:05.383590Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example projects are already downloaded.\n",
            "RasExamples.folder_df:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<property at 0x22070ad3f10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check if example projects are already downloaded\n",
        "if RasExamples.projects_dir.exists():\n",
        "    print(\"Example projects are already downloaded.\")\n",
        "    print(\"RasExamples.folder_df:\")\n",
        "    display(RasExamples.folder_df)\n",
        "else:\n",
        "    print(\"Downloading example projects...\")\n",
        "    RasExamples.get_example_projects()\n",
        "    print(\"RasExamples.folder_df:\")\n",
        "    display(RasExamples.folder_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.386668Z",
          "iopub.status.busy": "2025-11-17T17:37:05.386326Z",
          "iopub.status.idle": "2025-11-17T17:37:05.390346Z",
          "shell.execute_reply": "2025-11-17T17:37:05.389909Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Available categories: 1D Sediment Transport, 1D Steady Flow Hydraulics, 1D Unsteady Flow Hydraulics, 2D Sediment Transport, 2D Unsteady Flow Hydraulics, Applications Guide, Pipes (beta), Water Quality\n"
          ]
        }
      ],
      "source": [
        "# List all categories\n",
        "categories = RasExamples.list_categories()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.392502Z",
          "iopub.status.busy": "2025-11-17T17:37:05.392312Z",
          "iopub.status.idle": "2025-11-17T17:37:05.396489Z",
          "shell.execute_reply": "2025-11-17T17:37:05.395948Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available categories:\n"
          ]
        },
        {
          "data": {
            "text/plain": "[\"['1D Sediment Transport',\\n\", \" '1D Steady Flow Hydraulics',\\n\", \" '1D Unsteady Flow Hydraulics',\\n\", \" '2D Sediment Transport',\\n\", \" '2D Unsteady Flow Hydraulics',\\n\", \" 'Applications Guide',\\n\", \" 'Pipes (beta)',\\n\", \" 'Water Quality']\"]"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nAvailable categories:\")\n",
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.398659Z",
          "iopub.status.busy": "2025-11-17T17:37:05.398387Z",
          "iopub.status.idle": "2025-11-17T17:37:05.404171Z",
          "shell.execute_reply": "2025-11-17T17:37:05.403544Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Projects in category '1D Sediment Transport': BSTEM - Simple Example, Dredging Example, Reservoir Video Tutorial, SIAM Example, Simple Sediment Transport Example, Unsteady Sediment with Concentration Rules, Video Tutorial (Sediment Intro)\n"
          ]
        },
        {
          "data": {
            "text/plain": "[\"['BSTEM - Simple Example',\\n\", \" 'Dredging Example',\\n\", \" 'Reservoir Video Tutorial',\\n\", \" 'SIAM Example',\\n\", \" 'Simple Sediment Transport Example',\\n\", \" 'Unsteady Sediment with Concentration Rules',\\n\", \" 'Video Tutorial (Sediment Intro)']\"]"
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List projects in a specific category\n",
        "projects = RasExamples.list_projects(\"1D Sediment Transport\")\n",
        "projects\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.406270Z",
          "iopub.status.busy": "2025-11-17T17:37:05.406089Z",
          "iopub.status.idle": "2025-11-17T17:37:05.410665Z",
          "shell.execute_reply": "2025-11-17T17:37:05.410113Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - All available projects: BSTEM - Simple Example, Dredging Example, Reservoir Video Tutorial, SIAM Example, Simple Sediment Transport Example, Unsteady Sediment with Concentration Rules, Video Tutorial (Sediment Intro), Baxter RAS Mapper, Chapter 4 Example Data, ConSpan Culvert, Mixed Flow Regime Channel, Wailupe GeoRAS, Balde Eagle Creek, Bridge Hydraulics, ContractionExpansionMinorLosses, Culvert Hydraulics, Culverts with Flap Gates, Dam Breaching, Elevation Controled Gates, Inline Structure with Gated Spillways, Internal Stage and Flow Boundary Condition, JunctionHydraulics, Lateral Strcuture with Gates, Lateral Structure connected to a River Reach, Lateral Structure Overflow Weir, Lateral Structure with Culverts and Gates, Lateral Structure with Culverts, Levee Breaching, Mixed Flow Regime, Multiple Reaches with Hydraulic Structures, NavigationDam, Pumping Station with Rules, Pumping Station, Rule Operations, Simplified Physical Breaching, Storage Area Hydraulic Connection, UngagedAreaInflows, Unsteady Flow Encroachment Analysis, Chippewa_2D, Weise_2D, BaldEagleCrkMulti2D, Muncie, Example 1 - Critical Creek, Example 10 - Stream Junction, Example 11 - Bridge Scour, Example 12 - Inline Structure, Example 13 - Singler Bridge (WSPRO), Example 14 - Ice Covered River, Example 15 - Split Flow Junction with Lateral Weir, Example 16 - Channel Modification, Example 17 - Unsteady Flow Application, Example 18 - Advanced Inline Structure, Example 19 - Hydrologic Routing - ModPuls, Example 2 - Beaver Creek, Example 20 - HagerLatWeir, Example 21 - Overflow Gates, Example 22 - Groundwater Interflow, Example 23 - Urban Modeling, Example 24 - Mannings-n-Calibration, Example 3 - Single Culvert, Example 4 - Multiple Culverts, Example 5 - Multiple Openings, Example 6 - Floodway Determination, Example 7 - Multiple Plans, Example 8 - Looped Network, Example 9 - Mixed Flow Analysis, Davis, Nutrient Example, NewOrleansMetro, BeaverLake\n"
          ]
        },
        {
          "data": {
            "text/plain": "[\"['BSTEM - Simple Example',\\n\", \" 'Dredging Example',\\n\", \" 'Reservoir Video Tutorial',\\n\", \" 'SIAM Example',\\n\", \" 'Simple Sediment Transport Example',\\n\", \" 'Unsteady Sediment with Concentration Rules',\\n\", \" 'Video Tutorial (Sediment Intro)',\\n\", \" 'Baxter RAS Mapper',\\n\", \" 'Chapter 4 Example Data',\\n\", \" 'ConSpan Culvert',\\n\", \" 'Mixed Flow Regime Channel',\\n\", \" 'Wailupe GeoRAS',\\n\", \" 'Balde Eagle Creek',\\n\", \" 'Bridge Hydraulics',\\n\", \" 'ContractionExpansionMinorLosses',\\n\", \" 'Culvert Hydraulics',\\n\", \" 'Culverts with Flap Gates',\\n\", \" 'Dam Breaching',\\n\", \" 'Elevation Controled Gates',\\n\", \" 'Inline Structure with Gated Spillways',\\n\", \" 'Internal Stage and Flow Boundary Condition',\\n\", \" 'JunctionHydraulics',\\n\", \" 'Lateral Strcuture with Gates',\\n\", \" 'Lateral Structure connected to a River Reach',\\n\", \" 'Lateral Structure Overflow Weir',\\n\", \" 'Lateral Structure with Culverts and Gates',\\n\", \" 'Lateral Structure with Culverts',\\n\", \" 'Levee Breaching',\\n\", \" 'Mixed Flow \n...\n[Output truncated, 2482 characters total]"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List all projects\n",
        "all_projects = RasExamples.list_projects()\n",
        "all_projects\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:05.412579Z",
          "iopub.status.busy": "2025-11-17T17:37:05.412309Z",
          "iopub.status.idle": "2025-11-17T17:37:06.967896Z",
          "shell.execute_reply": "2025-11-17T17:37:06.967474Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:05 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Project 'Muncie' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Existing folder for project 'Muncie' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        }
      ],
      "source": [
        "# Extract specific projects\n",
        "projects_to_extract = [\"Balde Eagle Creek\", \"BaldEagleCrkMulti2D\", \"Muncie\"]\n",
        "extracted_paths = RasExamples.extract_project(projects_to_extract)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note about New Pipes and Conduits Version 6.6 Example Project\n",
        "\n",
        "Use project name \"Davis\" to explore pipes and conduits (introduced in version 6.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NEW Example Projects:\n",
        "#### The \"BeaverLake\" and \"NewOrleansMetro\" were published to the HEC-RAS Sample Datasets page.  These sample datasets are specifically for Pipe Systems introduced in HEC-RAS 6.6\n",
        "\n",
        "https://www.hec.usace.army.mil/confluence/rasdocs/hgt/latest/sample-datasets/small-city-urban-drainage-davis-ca\n",
        "\n",
        "https://www.hec.usace.army.mil/confluence/rasdocs/hgt/latest/sample-datasets/small-neighborhood-drainage-beaver-lake\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:06.969867Z",
          "iopub.status.busy": "2025-11-17T17:37:06.969691Z",
          "iopub.status.idle": "2025-11-17T17:37:08.359092Z",
          "shell.execute_reply": "2025-11-17T17:37:08.358479Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Special Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Extracting special project 'BeaverLake'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Special project 'BeaverLake' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Existing folder for project 'BeaverLake' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - Downloading special project from: https://www.hec.usace.army.mil/confluence/rasdocs/hgt/files/latest/299501780/299502090/1/1747692179014/BeaverLake-SWMM-Import-Solution.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:06 - ras_commander.RasExamples - INFO - This may take a few moments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Downloaded special project zip file to C:\\GH\\ras-commander\\examples\\example_projects\\BeaverLake_temp.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Successfully extracted special project 'BeaverLake' to C:\\GH\\ras-commander\\examples\\example_projects\\BeaverLake\n"
          ]
        }
      ],
      "source": [
        "extracted_paths = RasExamples.extract_project(\"BeaverLake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:08.361532Z",
          "iopub.status.busy": "2025-11-17T17:37:08.361271Z",
          "iopub.status.idle": "2025-11-17T17:37:29.155193Z",
          "shell.execute_reply": "2025-11-17T17:37:29.154530Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Special Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Extracting special project 'NewOrleansMetro'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Special project 'NewOrleansMetro' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Existing folder for project 'NewOrleansMetro' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - Downloading special project from: https://www.hec.usace.army.mil/confluence/rasdocs/hgt/files/latest/299502039/299502111/1/1747692522764/NewOrleansMetroPipesExample.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:08 - ras_commander.RasExamples - INFO - This may take a few moments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:28 - ras_commander.RasExamples - INFO - Downloaded special project zip file to C:\\GH\\ras-commander\\examples\\example_projects\\NewOrleansMetro_temp.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:29 - ras_commander.RasExamples - INFO - Successfully extracted special project 'NewOrleansMetro' to C:\\GH\\ras-commander\\examples\\example_projects\\NewOrleansMetro\n"
          ]
        }
      ],
      "source": [
        "extracted_paths = RasExamples.extract_project(\"NewOrleansMetro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:29.157603Z",
          "iopub.status.busy": "2025-11-17T17:37:29.157426Z",
          "iopub.status.idle": "2025-11-17T17:37:30.557762Z",
          "shell.execute_reply": "2025-11-17T17:37:30.557186Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:29 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Special Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:29 - ras_commander.RasExamples - INFO - Extracting special project 'BeaverLake'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:29 - ras_commander.RasExamples - INFO - Downloading special project from: https://www.hec.usace.army.mil/confluence/rasdocs/hgt/files/latest/299501780/299502090/1/1747692179014/BeaverLake-SWMM-Import-Solution.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:29 - ras_commander.RasExamples - INFO - This may take a few moments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Downloaded special project zip file to C:\\GH\\ras-commander\\examples\\special_projects\\BeaverLake_temp.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Successfully extracted special project 'BeaverLake' to C:\\GH\\ras-commander\\examples\\special_projects\\BeaverLake\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special project extracted to: C:\\GH\\ras-commander\\examples\\special_projects\\BeaverLake\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Special projects also work with custom output paths\n",
        "beaverlake_path = RasExamples.extract_project(\"BeaverLake\", output_path=\"special_projects\")\n",
        "print(f\"Special project extracted to: {beaverlake_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:30.559758Z",
          "iopub.status.busy": "2025-11-17T17:37:30.559596Z",
          "iopub.status.idle": "2025-11-17T17:37:30.619583Z",
          "shell.execute_reply": "2025-11-17T17:37:30.618869Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\unsteady_examples\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Extracting project 'Pumping Station'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Project 'Pumping Station' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Existing folder for project 'Pumping Station' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Successfully extracted project 'Pumping Station' to C:\\GH\\ras-commander\\examples\\unsteady_examples\\Pumping Station\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted 2 projects:\n",
            "  - C:\\GH\\ras-commander\\examples\\unsteady_examples\\Balde Eagle Creek\n",
            "  - C:\\GH\\ras-commander\\examples\\unsteady_examples\\Pumping Station\n"
          ]
        }
      ],
      "source": [
        "# Example 3: Extract multiple projects to a custom location\n",
        "projects = [\"Balde Eagle Creek\", \"Pumping Station\"]\n",
        "extracted_paths = RasExamples.extract_project(projects, output_path=\"unsteady_examples\")\n",
        "print(f\"Extracted {len(extracted_paths)} projects:\")\n",
        "for path in extracted_paths:\n",
        "    print(f\"  - {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:30.621749Z",
          "iopub.status.busy": "2025-11-17T17:37:30.621562Z",
          "iopub.status.idle": "2025-11-17T17:37:30.722815Z",
          "shell.execute_reply": "2025-11-17T17:37:30.722091Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Extracting project 'Dam Breaching'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Project 'Dam Breaching' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Existing folder for project 'Dam Breaching' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Successfully extracted project 'Dam Breaching' to C:\\HEC_RAS_Projects\\testing\\Dam Breaching\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted to: C:\\HEC_RAS_Projects\\testing\\Dam Breaching\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Extract to an absolute path\n",
        "from pathlib import Path\n",
        "custom_path = Path(\"C:/HEC_RAS_Projects/testing\")\n",
        "dam_breach_path = RasExamples.extract_project(\"Dam Breaching\", output_path=custom_path)\n",
        "print(f\"Extracted to: {dam_breach_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:30.724773Z",
          "iopub.status.busy": "2025-11-17T17:37:30.724567Z",
          "iopub.status.idle": "2025-11-17T17:37:30.961765Z",
          "shell.execute_reply": "2025-11-17T17:37:30.961384Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:37:30 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to C:\\GH\\ras-commander\\examples\\my_projects\\Muncie\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted to: C:\\GH\\ras-commander\\examples\\my_projects\\Muncie\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Extract to a relative path (creates subfolder in current directory)\n",
        "muncie_path = RasExamples.extract_project(\"Muncie\", output_path=\"my_projects\")\n",
        "print(f\"Extracted to: {muncie_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting Projects to Custom Locations\n",
        "\n",
        "By default, projects are extracted to the `example_projects` subfolder. However, you can specify a custom output location using the `output_path` parameter. This is useful when organizing projects for different workflows or when you need to extract projects to a specific directory."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\01_project_initialization.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:52.089029Z",
          "iopub.status.busy": "2025-11-17T17:37:52.088811Z",
          "iopub.status.idle": "2025-11-17T17:37:53.423339Z",
          "shell.execute_reply": "2025-11-17T17:37:53.422758Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:53.425824Z",
          "iopub.status.busy": "2025-11-17T17:37:53.425360Z",
          "iopub.status.idle": "2025-11-17T17:37:53.428349Z",
          "shell.execute_reply": "2025-11-17T17:37:53.427847Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAS Commander: Core Concepts\n",
        "\n",
        "RAS Commander is a Python library that provides tools for automating HEC-RAS tasks. It's built with several key design principles:\n",
        "\n",
        "1. **Project-Centric Architecture**: Everything revolves around HEC-RAS projects\n",
        "2. **Two RAS Object Approaches**:\n",
        "   - **Global `ras` Object**: A singleton for simple scripts\n",
        "   - **Custom RAS Objects**: Multiple ras project instances for complex workflows\n",
        "3. **Comprehensive Project Representation**: Each RAS object includes DataFrames for plans, geometries, flows, and boundaries\n",
        "4. **Logging**: Built-in logging to track operations and debug issues\n",
        "5. **HDF Support**: Specialized functions for HDF file access (plan results, geometry, etc.)\n",
        "\n",
        "Let's explore these concepts in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading Example HEC-RAS Projects\n",
        "\n",
        "RAS Commander includes a utility to download and extract example HEC-RAS projects. These are useful for learning and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:53.430973Z",
          "iopub.status.busy": "2025-11-17T17:37:53.430686Z",
          "iopub.status.idle": "2025-11-17T17:37:55.089155Z",
          "shell.execute_reply": "2025-11-17T17:37:55.088504Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract specific projects we'll use in this tutorial\n",
        "# This will download them if not present and extract them to the example_projects folder\n",
        "extracted_paths = RasExamples.extract_project([\"Balde Eagle Creek\", \"BaldEagleCrkMulti2D\", \"Muncie\"])\n",
        "print(extracted_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get Paths for Extracted Example Projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.091718Z",
          "iopub.status.busy": "2025-11-17T17:37:55.091523Z",
          "iopub.status.idle": "2025-11-17T17:37:55.095907Z",
          "shell.execute_reply": "2025-11-17T17:37:55.095460Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get the parent directory of the first extracted path as our examples directory\n",
        "examples_dir = extracted_paths[0].parent\n",
        "print(f\"Examples directory: {examples_dir}\")\n",
        "\n",
        "\n",
        "# Define paths to the extracted projects\n",
        "bald_eagle_path = examples_dir / \"Balde Eagle Creek\"\n",
        "multi_2d_path = examples_dir / \"BaldEagleCrkMulti2D\"\n",
        "muncie_path = examples_dir / \"Muncie\"\n",
        "\n",
        "# Verify the paths exist\n",
        "for path in [bald_eagle_path, multi_2d_path, muncie_path]:\n",
        "    print(f\"Path {path} exists: {path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility Function to Print RAS Object Data\n",
        "\n",
        "Let's create a utility function to help us explore the contents of RAS objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.097891Z",
          "iopub.status.busy": "2025-11-17T17:37:55.097719Z",
          "iopub.status.idle": "2025-11-17T17:37:55.101682Z",
          "shell.execute_reply": "2025-11-17T17:37:55.101226Z"
        }
      },
      "outputs": [],
      "source": [
        "def print_ras_object_data(ras_obj, project_name):\n",
        "    \"\"\"Prints comprehensive information about a RAS object\"\"\"\n",
        "    print(f\"\\n{project_name} Data:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Project Name: {ras_obj.get_project_name()}\")\n",
        "    print(f\"Project Folder: {ras_obj.project_folder}\")\n",
        "    print(f\"PRJ File: {ras_obj.prj_file}\")\n",
        "    print(f\"HEC-RAS Executable Path: {ras_obj.ras_exe_path}\")\n",
        "    \n",
        "    print(\"\\nPlan Files DataFrame (ras.plan_df):\")\n",
        "    with pd.option_context('display.max_columns', None):\n",
        "        display.display(ras_obj.plan_df)\n",
        "    \n",
        "    print(\"\\nSteady Flow Files DataFrame:\")\n",
        "    display.display(ras_obj.flow_df)\n",
        "    \n",
        "    print(\"\\nUnsteady Flow Files DataFrame (ras.unsteady_df):\")\n",
        "    display.display(ras_obj.unsteady_df)\n",
        "    \n",
        "    print(\"\\nGeometry Files DataFrame (ras.geom_df):\")\n",
        "    display.display(ras_obj.geom_df)\n",
        "    \n",
        "    print(\"\\nHDF Entries DataFrame (ras.get_hdf_entries()):\")\n",
        "    display.display(ras_obj.get_hdf_entries())\n",
        "    \n",
        "    print(\"\\nBoundary Conditions DataFrame (ras.boundaries_df):\")\n",
        "    display.display(ras_obj.boundaries_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 1: Using the Global `ras` Object\n",
        "\n",
        "The global `ras` object is a singleton instance that persists throughout your script. It's ideal for simple scripts working with a single project.\n",
        "\n",
        "Key characteristics:\n",
        "- It's available as `ras` immediately after import\n",
        "- It's initialized via `init_ras_project()` without saving the return value\n",
        "- It provides access to all project data through the global `ras` variable\n",
        "- It's simple to use but can be problematic in complex scenarios\n",
        "\n",
        "Let's initialize it with the Bald Eagle Creek project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.103990Z",
          "iopub.status.busy": "2025-11-17T17:37:55.103789Z",
          "iopub.status.idle": "2025-11-17T17:37:55.150534Z",
          "shell.execute_reply": "2025-11-17T17:37:55.149949Z"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize the global ras object with Bald Eagle Creek project\n",
        "# Note: This updates the global 'ras' object visible throughout the script\n",
        "# Parameters:\n",
        "#   - project_folder: Path to the HEC-RAS project folder (required)\n",
        "#   - ras_version: HEC-RAS version (e.g. \"6.5\") or path to Ras.exe (required first time)\n",
        "\n",
        "init_ras_project(bald_eagle_path, \"6.5\")\n",
        "print(f\"The global 'ras' object is now initialized with the {ras.project_name} project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.152677Z",
          "iopub.status.busy": "2025-11-17T17:37:55.152486Z",
          "iopub.status.idle": "2025-11-17T17:37:55.172621Z",
          "shell.execute_reply": "2025-11-17T17:37:55.171953Z"
        }
      },
      "outputs": [],
      "source": [
        "# Find the .prj file in the Bald Eagle Creek folder\n",
        "prj_file = list(bald_eagle_path.glob(\"*.prj\"))[0]\n",
        "print(f\"Found .prj file: {prj_file}\")\n",
        "print(f\"File name: {prj_file.name}\\n\")\n",
        "\n",
        "# Initialize using the .prj file path directly (NEW FEATURE!)\n",
        "# This works exactly the same as passing the folder path\n",
        "init_ras_project(prj_file, \"6.5\")\n",
        "print(f\"Successfully initialized project using .prj file path!\")\n",
        "print(f\"Project name: {ras.project_name}\")\n",
        "print(f\"Project folder: {ras.project_folder}\")\n",
        "print(f\"PRJ file: {ras.prj_file}\")\n",
        "\n",
        "# Verify both methods produce identical results\n",
        "print(f\"\\n\u2713 Both folder path and .prj file path initialization methods produce the same result!\")\n",
        "print(f\"\u2713 The project folder is automatically extracted from the .prj file's parent directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative: Initialize Using .prj File Path\n",
        "\n",
        "**New Feature**: You can now initialize a project by providing the direct path to a `.prj` file instead of the project folder. This is especially useful when:\n",
        "- Working with file selection dialogs (which return file paths)\n",
        "- Using configuration files that store specific .prj file paths\n",
        "- Working with folders that contain multiple projects\n",
        "- Building command-line tools that accept file paths\n",
        "\n",
        "The function automatically:\n",
        "1. Validates that the file has a `.prj` extension\n",
        "2. Verifies the file contains \"**Proj Title=**\" to confirm it's a HEC-RAS project file (not a plan file)\n",
        "3. Extracts the parent folder and uses it as the project folder\n",
        "4. Optimizes initialization by passing the .prj file directly (avoids re-searching)\n",
        "\n",
        "Let's see this in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.174860Z",
          "iopub.status.busy": "2025-11-17T17:37:55.174677Z",
          "iopub.status.idle": "2025-11-17T17:37:55.230667Z",
          "shell.execute_reply": "2025-11-17T17:37:55.230040Z"
        }
      },
      "outputs": [],
      "source": [
        "# Explore the global ras object with our utility function\n",
        "print_ras_object_data(ras, \"Global RAS Object (Bald Eagle Creek)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the RAS Object Structure\n",
        "\n",
        "Each RAS object contains several important components:\n",
        "\n",
        "1. **Project Metadata**:\n",
        "   - `project_name`: Name of the HEC-RAS project\n",
        "   - `project_folder`: Directory containing project files\n",
        "   - `prj_file`: Path to the main .prj file\n",
        "   - `ras_exe_path`: Path to the HEC-RAS executable\n",
        "\n",
        "2. **Project DataFrames**:\n",
        "   - `plan_df`: Information about all plan files (.p*)\n",
        "   - `flow_df`: Information about all steady flow files (.f*)\n",
        "   - `unsteady_df`: Information about all unsteady flow files (.u*)\n",
        "   - `geom_df`: Information about all geometry files (.g*)\n",
        "   - `boundaries_df`: Information about all boundary conditions\n",
        "\n",
        "3. **Methods for Data Access**:\n",
        "   - `get_plan_entries()`: Get plan file information\n",
        "   - `get_flow_entries()`: Get flow file information\n",
        "   - `get_unsteady_entries()`: Get unsteady flow file information \n",
        "   - `get_geom_entries()`: Get geometry file information\n",
        "   - `get_hdf_entries()`: Get HDF file paths for result files\n",
        "   - `get_boundary_conditions()`: Get boundary condition details\n",
        "\n",
        "Let's see how to access specific information from these components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.232994Z",
          "iopub.status.busy": "2025-11-17T17:37:55.232815Z",
          "iopub.status.idle": "2025-11-17T17:37:55.237432Z",
          "shell.execute_reply": "2025-11-17T17:37:55.236861Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get the first plan's details\n",
        "if not ras.plan_df.empty:\n",
        "    first_plan = ras.plan_df.iloc[0]\n",
        "    print(f\"First plan number: {first_plan['plan_number']}\")\n",
        "    print(f\"Plan path: {first_plan['full_path']}\")\n",
        "    \n",
        "    # Get the geometry file for this plan\n",
        "    geom_id = first_plan.get('Geom File', '').replace('g', '')\n",
        "    if geom_id:\n",
        "        geom_info = ras.geom_df[ras.geom_df['geom_number'] == geom_id]\n",
        "        if not geom_info.empty:\n",
        "            print(f\"Geometry file: {geom_info.iloc[0]['full_path']}\")\n",
        "    \n",
        "    # Get the HDF results file for this plan (if exists)\n",
        "    if 'HDF_Results_Path' in first_plan and first_plan['HDF_Results_Path']:\n",
        "        print(f\"Results file: {first_plan['HDF_Results_Path']}\")\n",
        "else:\n",
        "    print(\"No plans found in the project.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with Boundary Conditions\n",
        "\n",
        "Boundary conditions define the inputs and outputs of your model. Let's see how to access boundary condition information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.239531Z",
          "iopub.status.busy": "2025-11-17T17:37:55.239357Z",
          "iopub.status.idle": "2025-11-17T17:37:55.249584Z",
          "shell.execute_reply": "2025-11-17T17:37:55.249056Z"
        }
      },
      "outputs": [],
      "source": [
        "# View the boundary conditions DataFrame\n",
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Approach 2: Using Custom RAS Objects\n",
        "\n",
        "For more complex scripts or when working with multiple projects, it's better to create and use separate RAS objects. This approach:\n",
        "\n",
        "- Creates independent RAS objects for each project\n",
        "- Avoids overwriting the global `ras` object\n",
        "- Provides clearer separation between projects\n",
        "- Allows working with multiple projects simultaneously\n",
        "- Requires saving the return value from `init_ras_project()`\n",
        "\n",
        "Let's initialize multiple projects with custom RAS objects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.251874Z",
          "iopub.status.busy": "2025-11-17T17:37:55.251679Z",
          "iopub.status.idle": "2025-11-17T17:37:55.531033Z",
          "shell.execute_reply": "2025-11-17T17:37:55.530361Z"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize multiple project instances with custom RAS objects\n",
        "# Note: This also updates the global 'ras' object each time, but we'll use the custom instances\n",
        "# Parameters remain the same as before\n",
        "multi_2d_project = RasPrj()\n",
        "init_ras_project(multi_2d_path, \"6.5\", ras_object=multi_2d_project)\n",
        "print(f\"\\nMulti2D project initialized with its own RAS object\")\n",
        "\n",
        "muncie_project = RasPrj()\n",
        "init_ras_project(muncie_path, \"6.5\", ras_object=muncie_project)\n",
        "print(f\"\\nMuncie project initialized with its own RAS object\")\n",
        "\n",
        "# Note that the global 'ras' object now points to the Muncie project\n",
        "# The global 'ras' object gets overwritten every time a project is initialized ,\n",
        "print(f\"\\nGlobal 'ras' object now points to: {ras.project_name} since it was the last one initialized.  Avoid the global object when using multiple projects.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring Multiple Projects\n",
        "\n",
        "Now we have three RAS objects:\n",
        "- `multi_2d_project`: Our custom object for the Multi2D project\n",
        "- `muncie_project`: Our custom object for the Muncie project\n",
        "- `ras`: The global object (which now points to Muncie)\n",
        "\n",
        "Let's examine the Multi2D project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.533405Z",
          "iopub.status.busy": "2025-11-17T17:37:55.533215Z",
          "iopub.status.idle": "2025-11-17T17:37:55.545021Z",
          "shell.execute_reply": "2025-11-17T17:37:55.544380Z"
        }
      },
      "outputs": [],
      "source": [
        "display.display(multi_2d_project.plan_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.547113Z",
          "iopub.status.busy": "2025-11-17T17:37:55.546936Z",
          "iopub.status.idle": "2025-11-17T17:37:55.592643Z",
          "shell.execute_reply": "2025-11-17T17:37:55.591864Z"
        }
      },
      "outputs": [],
      "source": [
        "# Examine the Multi2D project\n",
        "print_ras_object_data(multi_2d_project, \"Multi2D Project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.594929Z",
          "iopub.status.busy": "2025-11-17T17:37:55.594734Z",
          "iopub.status.idle": "2025-11-17T17:37:55.630064Z",
          "shell.execute_reply": "2025-11-17T17:37:55.629395Z"
        }
      },
      "outputs": [],
      "source": [
        "# Examine the Muncie project\n",
        "print_ras_object_data(muncie_project, \"Muncie Project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing Projects\n",
        "\n",
        "Let's compare some key metrics of the two projects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:37:55.632467Z",
          "iopub.status.busy": "2025-11-17T17:37:55.632177Z",
          "iopub.status.idle": "2025-11-17T17:37:55.642660Z",
          "shell.execute_reply": "2025-11-17T17:37:55.642046Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create a comparison table of the two projects\n",
        "comparison_data = {\n",
        "    'Project Name': [multi_2d_project.project_name, muncie_project.project_name],\n",
        "    'Number of Plans': [len(multi_2d_project.plan_df), len(muncie_project.plan_df)],\n",
        "    'Number of Geometries': [len(multi_2d_project.geom_df), len(muncie_project.geom_df)],\n",
        "    'Number of Flow Files': [len(multi_2d_project.flow_df), len(muncie_project.flow_df)],\n",
        "    'Number of Unsteady Files': [len(multi_2d_project.unsteady_df), len(muncie_project.unsteady_df)],\n",
        "    'Number of Boundary Conditions': [len(multi_2d_project.boundaries_df) if hasattr(multi_2d_project, 'boundaries_df') else 0, \n",
        "                                     len(muncie_project.boundaries_df) if hasattr(muncie_project, 'boundaries_df') else 0],\n",
        "    'HDF Results Available': [len(multi_2d_project.get_hdf_entries()) > 0, len(muncie_project.get_hdf_entries()) > 0]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "display.display(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAS Commander: Best Practices\n",
        "\n",
        "After exploring both approaches, here are some best practices for using RAS Commander:\n",
        "\n",
        "1. **Choose Your Approach Based on Complexity**:\n",
        "   - **Simple Scripts** (one project): Use the global `ras` object\n",
        "   - **Complex Scripts** (multiple projects): Use custom RAS objects\n",
        "\n",
        "2. **Be Consistent**:\n",
        "   - Don't mix global and custom approaches in the same script\n",
        "   - Use descriptive names for custom RAS objects\n",
        "\n",
        "3. **Working with Project Files**:\n",
        "   - Access project files through the RAS object's DataFrames\n",
        "   - Use helper functions like `get_plan_path()` to resolve paths\n",
        "\n",
        "4. **Error Handling**:\n",
        "   - Always check for empty DataFrames before accessing their contents\n",
        "   - Use the built-in logging to track operations\n",
        "\n",
        "5. **Performance Considerations**:\n",
        "   - For large projects, consider using the HDF classes directly\n",
        "   - Cache results of expensive operations when possible\n",
        "\n",
        "## Summary of Key Functions\n",
        "\n",
        "- `init_ras_project(project_folder, ras_version)`: Initialize a RAS project\n",
        "- `RasExamples().extract_project(project_name)`: Extract example projects\n",
        "- `RasPrj.get_project_name()`: Get the name of the project\n",
        "- `RasPrj.get_plan_entries()`: Get plan file information\n",
        "- `RasPrj.get_flow_entries()`: Get flow file information\n",
        "- `RasPrj.get_unsteady_entries()`: Get unsteady flow file information\n",
        "- `RasPrj.get_geom_entries()`: Get geometry file information\n",
        "- `RasPrj.get_hdf_entries()`: Get HDF result file information\n",
        "- `RasPrj.get_boundary_conditions()`: Get boundary condition details\n",
        "- `RasPlan.get_plan_path(plan_number)`: Get the path to a plan file\n",
        "- `RasPlan.get_geom_path(geom_number)`: Get the path to a geometry file\n",
        "- `RasPlan.get_flow_path(flow_number)`: Get the path to a flow file\n",
        "- `RasPlan.get_unsteady_path(unsteady_number)`: Get the path to an unsteady flow file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you understand the basics of project initialization in RAS Commander, you can explore more advanced topics:\n",
        "\n",
        "1. Working with HDF files for result analysis\n",
        "2. Modifying plan, geometry, and flow files\n",
        "3. Running HEC-RAS simulations\n",
        "4. Extracting and visualizing results\n",
        "5. Automating model calibration\n",
        "\n",
        "These topics are covered in other examples and notebooks in the RAS Commander documentation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\02_plan_and_geometry_operations.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:12.543843Z",
          "iopub.status.busy": "2025-11-17T17:38:12.543647Z",
          "iopub.status.idle": "2025-11-17T17:38:13.834447Z",
          "shell.execute_reply": "2025-11-17T17:38:13.833893Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:12 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAS Commander: Plan and Geometry Operations\n",
        "\n",
        "This notebook demonstrates how to perform operations on HEC-RAS plan and geometry files using the RAS Commander library. We'll explore how to initialize projects, clone plans and geometries, configure parameters, execute plans, and analyze results.\n",
        "\n",
        "## Operations Covered\n",
        "\n",
        "1. **Project Initialization**: Initialize a HEC-RAS project by specifying the project path and version\n",
        "2. **Plan Operations**:\n",
        "   - Clone an existing plan to create a new one\n",
        "   - Configure simulation parameters and intervals\n",
        "   - Set run flags and update descriptions\n",
        "3. **Geometry Operations**:\n",
        "   - Clone a geometry file to create a modified version\n",
        "   - Set the geometry for a plan\n",
        "   - Clear geometry preprocessor files to ensure clean results\n",
        "4. **Flow Operations**:\n",
        "   - Clone unsteady flow files\n",
        "   - Configure flow parameters\n",
        "5. **Plan Computation**: Run the plan with specified settings\n",
        "6. **Results Verification**: Check HDF entries to confirm results were written"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup\n",
        "Uncomment and run package installation commands if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.836723Z",
          "iopub.status.busy": "2025-11-17T17:38:13.836462Z",
          "iopub.status.idle": "2025-11-17T17:38:13.839185Z",
          "shell.execute_reply": "2025-11-17T17:38:13.838692Z"
        }
      },
      "outputs": [],
      "source": [
        "# 1. Install ras-commander from pip (uncomment to install if needed)\n",
        "#!pip install ras-commander\n",
        "# This installs ras-commander and all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.841102Z",
          "iopub.status.busy": "2025-11-17T17:38:13.840814Z",
          "iopub.status.idle": "2025-11-17T17:38:13.844322Z",
          "shell.execute_reply": "2025-11-17T17:38:13.843798Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n"
          ]
        }
      ],
      "source": [
        "# Enable this cell for local development version of ras-commander\n",
        "import os\n",
        "import sys      \n",
        "from pathlib import Path\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.846011Z",
          "iopub.status.busy": "2025-11-17T17:38:13.845875Z",
          "iopub.status.idle": "2025-11-17T17:38:13.848522Z",
          "shell.execute_reply": "2025-11-17T17:38:13.848045Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import the required libraries for this notebook\n",
        "#from ras_commander import *  # Import all ras-commander modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "from datetime import datetime  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading and Extracting Example HEC-RAS Projects\n",
        "\n",
        "We'll use the `RasExamples` class to download and extract an example HEC-RAS project. For this notebook, we'll use the \"Balde Eagle Creek\" project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.850431Z",
          "iopub.status.busy": "2025-11-17T17:38:13.850124Z",
          "iopub.status.idle": "2025-11-17T17:38:13.893104Z",
          "shell.execute_reply": "2025-11-17T17:38:13.892530Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Found zip file: C:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        }
      ],
      "source": [
        "# Extract specific projects we'll use in this tutorial\n",
        "# This will download them if not present and extract them to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(bald_eagle_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Initialization\n",
        "\n",
        "The first step is to initialize the HEC-RAS project. This is done using the `init_ras_project()` function, which takes the project folder path and HEC-RAS version as parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.895273Z",
          "iopub.status.busy": "2025-11-17T17:38:13.895101Z",
          "iopub.status.idle": "2025-11-17T17:38:13.938980Z",
          "shell.execute_reply": "2025-11-17T17:38:13.938465Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized HEC-RAS project: BaldEagle\n",
            "\n",
            "HEC-RAS Project Plan Data (plan_df):\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "0                 2MIN            1HOUR        1  ...     None      dss   \n",
              "1                 2MIN              NaN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method HDF_Results_Path Geom File  \\\n",
              "0                     2             None        01   \n",
              "1                     1             None        01   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...    Steady  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "\n",
        "# Display the current plan files in the project\n",
        "print(\"\\nHEC-RAS Project Plan Data (plan_df):\")\n",
        "display.display(ras.plan_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Plan and Geometry Operations in HEC-RAS\n",
        "\n",
        "Before diving into the operations, let's understand what plan and geometry files are in HEC-RAS:\n",
        "\n",
        "- **Plan Files** (`.p*`): Define the simulation parameters including the reference to geometry and flow files, as well as computational settings.\n",
        "- **Geometry Files** (`.g*`): Define the physical characteristics of the river/channel system including cross-sections, 2D areas, and structures.\n",
        "\n",
        "The `RasPlan` and `RasGeo` classes provide methods for working with these files, including:\n",
        "\n",
        "1. Creating new plans and geometries by cloning existing ones\n",
        "2. Modifying simulation parameters and settings\n",
        "3. Associating geometries with plans\n",
        "4. Managing preprocessor files\n",
        "5. Retrieving information from plans and geometries\n",
        "\n",
        "In the following sections, we'll explore these operations in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cloning Plans and Geometries\n",
        "\n",
        "Let's start by cloning a plan to create a new simulation scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.940960Z",
          "iopub.status.busy": "2025-11-17T17:38:13.940777Z",
          "iopub.status.idle": "2025-11-17T17:38:13.995513Z",
          "shell.execute_reply": "2025-11-17T17:38:13.995104Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p01 to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasUtils - INFO - Project file updated with new Plan entry: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New plan created: 03\n",
            "\n",
            "Updated plan files:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>UNET D2 Cores</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>0.0</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>03</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>Combined Test Plan</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>0.0</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "2          03              02              01  Unsteady with Bridges and Dam   \n",
              "\n",
              "  Program Version    Short Identifier                  Simulation Date  \\\n",
              "0            5.00        UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN           SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "2            5.00  Combined Test Plan    18FEB1999,0000,24FEB1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... UNET D2 Cores PS Cores  \\\n",
              "0                 2MIN            1HOUR        1  ...           0.0     None   \n",
              "1                 2MIN              NaN        1  ...           NaN     None   \n",
              "2                 2MIN            1HOUR        1  ...           0.0     None   \n",
              "\n",
              "  DSS File Friction Slope Method HDF_Results_Path  Geom File  Geom Path  \\\n",
              "0      dss                     2             None         01       None   \n",
              "1      dss                     1             None         01       None   \n",
              "2      dss                     2             None         01       None   \n",
              "\n",
              "  Flow File Flow Path                                          full_path  \n",
              "0        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "1        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "2        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "\n",
              "[3 rows x 26 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n",
            "\n",
            "New plan details:\n",
            "Plan number: 03\n",
            "Description: No description\n",
            "Short Identifier: Combined Test Plan\n",
            "Geometry file: 01\n",
            "File path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        }
      ],
      "source": [
        "# Clone plan \"01\" to create a new plan\n",
        "new_plan_number = RasPlan.clone_plan(\"1\", new_shortid=\"Combined Test Plan\")\n",
        "print(f\"New plan created: {new_plan_number}\")\n",
        "\n",
        "# Display updated plan files\n",
        "print(\"\\nUpdated plan files:\")\n",
        "display.display(ras.plan_df)\n",
        "\n",
        "# Get the path to the new plan file\n",
        "plan_path = RasPlan.get_plan_path(new_plan_number)\n",
        "print(f\"\\nNew plan file path: {plan_path}\")\n",
        "\n",
        "# Let's examine the new plan's details\n",
        "new_plan = ras.plan_df[ras.plan_df['plan_number'] == new_plan_number].iloc[0]\n",
        "print(f\"\\nNew plan details:\")\n",
        "print(f\"Plan number: {new_plan_number}\")\n",
        "print(f\"Description: {new_plan.get('description', 'No description')}\")\n",
        "print(f\"Short Identifier: {new_plan.get('Short Identifier', 'Not available')}\")\n",
        "print(f\"Geometry file: {new_plan.get('Geom File', 'None')}\")\n",
        "print(f\"File path: {new_plan['full_path']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:13.997296Z",
          "iopub.status.busy": "2025-11-17T17:38:13.997051Z",
          "iopub.status.idle": "2025-11-17T17:38:14.016769Z",
          "shell.execute_reply": "2025-11-17T17:38:14.016110Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Plan Title: Unsteady with Bridges and Dam\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Short Identifier: Combined Test Plan\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current plan title: Unsteady with Bridges and Dam\n",
            "Current plan shortid: Combined Test Plan\n"
          ]
        }
      ],
      "source": [
        "# Get the current plan title and shortid\n",
        "current_title = RasPlan.get_plan_title(new_plan_number)\n",
        "current_shortid = RasPlan.get_shortid(new_plan_number)\n",
        "\n",
        "print(f\"Current plan title: {current_title}\")\n",
        "print(f\"Current plan shortid: {current_shortid}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.019022Z",
          "iopub.status.busy": "2025-11-17T17:38:14.018728Z",
          "iopub.status.idle": "2025-11-17T17:38:14.046053Z",
          "shell.execute_reply": "2025-11-17T17:38:14.045645Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Constructed plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Updated Plan Title in plan file to: Unsteady with Bridges and Dam clonedplan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - WARNING - Short Identifier too long (24 char max). Truncating: Combined Test Plan clonedplan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Constructed plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Updated Short Identifier in plan file to: Combined Test Plan clone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Plan Title: Unsteady with Bridges and Dam clonedplan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Short Identifier: Combined Test Plan clone\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated plan title: Unsteady with Bridges and Dam clonedplan\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated plan shortid: Combined Test Plan clone\n"
          ]
        }
      ],
      "source": [
        "# Update the title and shortid to append \" clonedplan\"\n",
        "new_title = f\"{current_title} clonedplan\"\n",
        "new_shortid = f\"{current_shortid} clonedplan\"\n",
        "\n",
        "RasPlan.set_plan_title(new_plan_number, new_title)\n",
        "RasPlan.set_shortid(new_plan_number, new_shortid)\n",
        "\n",
        "print(f\"\\nUpdated plan title: {RasPlan.get_plan_title(new_plan_number)}\")\n",
        "print(f\"Updated plan shortid: {RasPlan.get_shortid(new_plan_number)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.047993Z",
          "iopub.status.busy": "2025-11-17T17:38:14.047799Z",
          "iopub.status.idle": "2025-11-17T17:38:14.059437Z",
          "shell.execute_reply": "2025-11-17T17:38:14.058938Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Plan Title: Unsteady with Bridges and Dam clonedplan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Retrieved Short Identifier: Combined Test Plan clone\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current plan title: Unsteady with Bridges and Dam clonedplan\n",
            "Current plan shortid: Combined Test Plan clone\n"
          ]
        }
      ],
      "source": [
        "# Get the current plan title and shortid again to confirm the changes\n",
        "current_title = RasPlan.get_plan_title(new_plan_number)\n",
        "current_shortid = RasPlan.get_shortid(new_plan_number)\n",
        "\n",
        "print(f\"Current plan title: {current_title}\")\n",
        "print(f\"Current plan shortid: {current_shortid}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's clone a geometry file. This allows us to make modifications to a geometry without affecting the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.061401Z",
          "iopub.status.busy": "2025-11-17T17:38:14.061202Z",
          "iopub.status.idle": "2025-11-17T17:38:14.100076Z",
          "shell.execute_reply": "2025-11-17T17:38:14.099339Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g01 to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g01.hdf to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g02.hdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Project file updated with new Geom entry: 02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New geometry created: 02\n",
            "\n",
            "Updated geometry files:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>geom_file</th>\\n', '      <th>geom_number</th>\\n', '      <th>full_path</th>\\n', '      <th>hdf_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>g01</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>g02</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  geom_file geom_number                                          full_path  \\\n",
              "0       g01          01  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1       g02          02  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                            hdf_path  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Found geometry path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New geometry file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g02\n",
            "\n",
            "New geometry details:\n",
            "Geometry number: 02\n",
            "Geometry file: Not available\n",
            "File path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.g02\n",
            "HDF path: None\n"
          ]
        }
      ],
      "source": [
        "# Clone geometry \"01\" to create a new geometry file\n",
        "new_geom_number = RasPlan.clone_geom(\"01\")\n",
        "print(f\"New geometry created: {new_geom_number}\")\n",
        "\n",
        "# Display updated geometry files\n",
        "print(\"\\nUpdated geometry files:\")\n",
        "display.display(ras.geom_df)\n",
        "\n",
        "# Get the path to the new geometry file\n",
        "geom_path = RasPlan.get_geom_path(new_geom_number)\n",
        "print(f\"\\nNew geometry file path: {geom_path}\")\n",
        "\n",
        "# Examine the new geometry's details\n",
        "new_geom = ras.geom_df.loc[ras.geom_df['geom_number'] == new_geom_number].squeeze()\n",
        "print(f\"\\nNew geometry details:\")\n",
        "print(f\"Geometry number: {new_geom_number}\")\n",
        "print(f\"Geometry file: {new_geom.get('geom_file', 'Not available')}\")\n",
        "print(f\"File path: {new_geom.get('full_path', 'Not available')}\")\n",
        "print(f\"HDF path: {new_geom.get('hdf_path', 'None')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also clone an unsteady flow file to complete our new simulation setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.102839Z",
          "iopub.status.busy": "2025-11-17T17:38:14.102340Z",
          "iopub.status.idle": "2025-11-17T17:38:14.141224Z",
          "shell.execute_reply": "2025-11-17T17:38:14.140700Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.u02 to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.u01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.u01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Project file updated with new Unsteady entry: 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New unsteady flow created: 01\n",
            "\n",
            "Updated unsteady flow files:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>unsteady_number</th>\\n', '      <th>full_path</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Flow Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Use Restart</th>\\n', '      <th>Precipitation Mode</th>\\n', '      <th>Wind Mode</th>\\n', '      <th>Met BC=Precipitation|Mode</th>\\n', '      <th>Met BC=Evapotranspiration|Mode</th>\\n', '      <th>Met BC=Precipitation|Expanded View</th>\\n', '      <th>Met BC=Precipitation|Constant Units</th>\\n', '      <th>Met BC=Precipitation|Gridded Source</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>None</td>\\n', '      <td>Flow Hydrograph 2</td>\\n', '      <td>6.30</td>\\n', '      <td>0</td>\\n', '      <td>Disable</td>\\n', '      <td>No Wind Forces</td>\\n', '      <td>None</td>\\n', '      <td>None</td>\\n', '      <td>0</td>\\n', '      <td>mm/hr</td>\\n', '      <td>DSS</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>None</td>\\n', '      <td>Flow Hydrograph 2</td>\\n', '      <td>6.30</td>\\n', '      <td>0</td>\\n', '      <td>Disable</td>\\n', '      <td>No Wind Forces</td>\\n', '      <td>None</td>\\n', '      <td>None</td>\\n', '      <td>0</td>\\n', '      <td>mm/hr</td>\\n', '      <td>DSS</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  unsteady_number                                          full_path  \\\n",
              "0              02  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1              01  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "  geometry_number         Flow Title Program Version Use Restart  \\\n",
              "0            None  Flow Hydrograph 2            6.30           0   \n",
              "1            None  Flow Hydrograph 2            6.30           0   \n",
              "\n",
              "  Precipitation Mode       Wind Mode Met BC=Precipitation|Mode  \\\n",
              "0            Disable  No Wind Forces                      None   \n",
              "1            Disable  No Wind Forces                      None   \n",
              "\n",
              "  Met BC=Evapotranspiration|Mode Met BC=Precipitation|Expanded View  \\\n",
              "0                           None                                  0   \n",
              "1                           None                                  0   \n",
              "\n",
              "  Met BC=Precipitation|Constant Units Met BC=Precipitation|Gridded Source  \n",
              "0                               mm/hr                                 DSS  \n",
              "1                               mm/hr                                 DSS  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New unsteady flow details:\n",
            "Unsteady number: 01\n",
            "File path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.u01\n",
            "Flow Title: Flow Hydrograph 2\n"
          ]
        }
      ],
      "source": [
        "# Clone unsteady flow \"02\" to create a new unsteady flow file\n",
        "new_unsteady_number = RasPlan.clone_unsteady(\"02\")\n",
        "print(f\"New unsteady flow created: {new_unsteady_number}\")\n",
        "\n",
        "# Display updated unsteady flow files\n",
        "print(\"\\nUpdated unsteady flow files:\")\n",
        "display.display(ras.unsteady_df)\n",
        "\n",
        "# Examine the new unsteady flow's details\n",
        "new_unsteady = ras.unsteady_df[ras.unsteady_df['unsteady_number'] == new_unsteady_number].iloc[0]\n",
        "print(f\"\\nNew unsteady flow details:\")\n",
        "print(f\"Unsteady number: {new_unsteady_number}\")\n",
        "print(f\"File path: {new_unsteady['full_path']}\")\n",
        "print(f\"Flow Title: {new_unsteady.get('Flow Title', 'Not available')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Associating Files and Setting Parameters\n",
        "\n",
        "Now that we have cloned our plan, geometry, and unsteady flow files, we need to associate them with each other and set various parameters.\n",
        "\n",
        "### Setting Geometry for a Plan\n",
        "\n",
        "Let's associate our new geometry with our new plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.143203Z",
          "iopub.status.busy": "2025-11-17T17:38:14.143006Z",
          "iopub.status.idle": "2025-11-17T17:38:14.164685Z",
          "shell.execute_reply": "2025-11-17T17:38:14.164150Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Updated Geom File in plan file to g02 for plan 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Geometry for plan 03 set to 02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated geometry for plan 03 to geometry 02\n",
            "Plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n",
            "\n",
            "Verified that plan 03 now uses geometry file: g02\n"
          ]
        }
      ],
      "source": [
        "# Set the new geometry for the cloned plan\n",
        "updated_geom_df = RasPlan.set_geom(new_plan_number, new_geom_number)\n",
        "plan_path = RasPlan.get_plan_path(new_plan_number, ras_object=ras)\n",
        "print(f\"Updated geometry for plan {new_plan_number} to geometry {new_geom_number}\")\n",
        "print(f\"Plan file path: {plan_path}\")\n",
        "\n",
        "# Let's verify the change\n",
        "updated_plan = ras.plan_df[ras.plan_df['plan_number'] == new_plan_number].iloc[0]\n",
        "print(f\"\\nVerified that plan {new_plan_number} now uses geometry file: {updated_plan.get('Geom File', 'None')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting Unsteady Flow for a Plan\n",
        "\n",
        "Similarly, let's associate our new unsteady flow file with our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.166671Z",
          "iopub.status.busy": "2025-11-17T17:38:14.166508Z",
          "iopub.status.idle": "2025-11-17T17:38:14.188564Z",
          "shell.execute_reply": "2025-11-17T17:38:14.187981Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated unsteady flow for plan 03 to unsteady flow 01\n"
          ]
        }
      ],
      "source": [
        "# Set unsteady flow for the cloned plan\n",
        "RasPlan.set_unsteady(new_plan_number, new_unsteady_number)\n",
        "print(f\"Updated unsteady flow for plan {new_plan_number} to unsteady flow {new_unsteady_number}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Clearing Geometry Preprocessor Files\n",
        "\n",
        "When working with geometry files, it's important to clear the preprocessor files to ensure clean results. These files (with `.c*` extension) contain computed hydraulic properties that should be recomputed when the geometry changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.190556Z",
          "iopub.status.busy": "2025-11-17T17:38:14.190360Z",
          "iopub.status.idle": "2025-11-17T17:38:14.196595Z",
          "shell.execute_reply": "2025-11-17T17:38:14.196211Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleared geometry preprocessor files for plan 03\n",
            "Preprocessor file exists after clearing: False\n"
          ]
        }
      ],
      "source": [
        "# Clear geometry preprocessor files for the cloned plan\n",
        "RasGeo.clear_geompre_files(plan_path)\n",
        "print(f\"Cleared geometry preprocessor files for plan {new_plan_number}\")\n",
        "\n",
        "# Check if preprocessor file exists after clearing\n",
        "geom_preprocessor_suffix = '.c' + ''.join(Path(plan_path).suffixes[1:])\n",
        "geom_preprocessor_file = Path(plan_path).with_suffix(geom_preprocessor_suffix)\n",
        "print(f\"Preprocessor file exists after clearing: {geom_preprocessor_file.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting Computation Parameters\n",
        "\n",
        "Let's set the computation parameters for our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.198310Z",
          "iopub.status.busy": "2025-11-17T17:38:14.198136Z",
          "iopub.status.idle": "2025-11-17T17:38:14.237891Z",
          "shell.execute_reply": "2025-11-17T17:38:14.237372Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Constructed plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated number of cores for plan 03 to 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Verified that UNET D1 Cores is set to: 2\n",
            "Updated geometry preprocessor options for plan 03\n",
            "- Run HTab: -1 (Force recomputation of geometry tables)\n",
            "- Use Existing IB Tables: -1 (Force recomputation of interpolation/boundary tables)\n",
            "\n",
            "Verified setting values:\n",
            "- Run HTab: -1\n",
            "- UNET Use Existing IB Tables: -1\n"
          ]
        }
      ],
      "source": [
        "# Set the number of cores to use for the computation\n",
        "RasPlan.set_num_cores(new_plan_number, 2)\n",
        "print(f\"Updated number of cores for plan {new_plan_number} to 2\")\n",
        "\n",
        "# Verify by extracting the value from the plan file\n",
        "cores_value = RasPlan.get_plan_value(new_plan_number, \"UNET D1 Cores\")\n",
        "print(f\"\\nVerified that UNET D1 Cores is set to: {cores_value}\")\n",
        "\n",
        "# Set geometry preprocessor options\n",
        "RasPlan.set_geom_preprocessor(plan_path, run_htab=-1, use_ib_tables=-1)\n",
        "print(f\"Updated geometry preprocessor options for plan {new_plan_number}\")\n",
        "print(f\"- Run HTab: -1 (Force recomputation of geometry tables)\")\n",
        "print(f\"- Use Existing IB Tables: -1 (Force recomputation of interpolation/boundary tables)\")\n",
        "\n",
        "# Verify by extracting the values from the plan file\n",
        "run_htab_value = RasPlan.get_plan_value(new_plan_number, \"Run HTab\")\n",
        "ib_tables_value = RasPlan.get_plan_value(new_plan_number, \"UNET Use Existing IB Tables\")\n",
        "print(f\"\\nVerified setting values:\")\n",
        "print(f\"- Run HTab: {run_htab_value}\")\n",
        "print(f\"- UNET Use Existing IB Tables: {ib_tables_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Updating Simulation Parameters\n",
        "\n",
        "Now, let's update various simulation parameters for our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.240002Z",
          "iopub.status.busy": "2025-11-17T17:38:14.239813Z",
          "iopub.status.idle": "2025-11-17T17:38:14.248111Z",
          "shell.execute_reply": "2025-11-17T17:38:14.247535Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Updated simulation date in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated simulation date for plan 03:\n",
            "- Start Date: 2023-01-01 00:00:00\n",
            "- End Date: 2023-01-05 23:59:00\n"
          ]
        }
      ],
      "source": [
        "# 1. Update simulation date\n",
        "start_date = datetime(2023, 1, 1, 0, 0)  # January 1, 2023, 00:00\n",
        "end_date = datetime(2023, 1, 5, 23, 59)  # January 5, 2023, 23:59\n",
        "\n",
        "RasPlan.update_simulation_date(new_plan_number, start_date, end_date)\n",
        "print(f\"Updated simulation date for plan {new_plan_number}:\")\n",
        "print(f\"- Start Date: {start_date}\")\n",
        "print(f\"- End Date: {end_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.250325Z",
          "iopub.status.busy": "2025-11-17T17:38:14.250012Z",
          "iopub.status.idle": "2025-11-17T17:38:14.264698Z",
          "shell.execute_reply": "2025-11-17T17:38:14.264037Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verified Simulation Date value: 01JAN2023,0000,05JAN2023,2359\n"
          ]
        }
      ],
      "source": [
        "# Verify the update\n",
        "sim_date = RasPlan.get_plan_value(new_plan_number, \"Simulation Date\")\n",
        "print(f\"Verified Simulation Date value: {sim_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.266757Z",
          "iopub.status.busy": "2025-11-17T17:38:14.266551Z",
          "iopub.status.idle": "2025-11-17T17:38:14.288751Z",
          "shell.execute_reply": "2025-11-17T17:38:14.288363Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Successfully updated intervals in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated plan intervals for plan 03:\n",
            "- Computation Interval: 1MIN\n",
            "- Output Interval: 15MIN\n",
            "- Mapping Interval: 30MIN\n",
            "Verified interval values:\n",
            "- Computation Interval: 1MIN\n",
            "- Mapping Interval: 30MIN\n"
          ]
        }
      ],
      "source": [
        "# 2. Update plan intervals\n",
        "RasPlan.update_plan_intervals(\n",
        "    new_plan_number,\n",
        "    computation_interval=\"1MIN\",  # Computational time step\n",
        "    output_interval=\"15MIN\",      # How often results are written\n",
        "    mapping_interval=\"30MIN\"      # How often mapping outputs are created\n",
        ")\n",
        "print(f\"\\nUpdated plan intervals for plan {new_plan_number}:\")\n",
        "print(f\"- Computation Interval: 1MIN\")\n",
        "print(f\"- Output Interval: 15MIN\")\n",
        "print(f\"- Mapping Interval: 30MIN\")\n",
        "\n",
        "# Verify the updates\n",
        "comp_interval = RasPlan.get_plan_value(new_plan_number, \"Computation Interval\")\n",
        "mapping_interval = RasPlan.get_plan_value(new_plan_number, \"Mapping Interval\")\n",
        "print(f\"Verified interval values:\")\n",
        "print(f\"- Computation Interval: {comp_interval}\")\n",
        "print(f\"- Mapping Interval: {mapping_interval}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.290574Z",
          "iopub.status.busy": "2025-11-17T17:38:14.290388Z",
          "iopub.status.idle": "2025-11-17T17:38:14.298445Z",
          "shell.execute_reply": "2025-11-17T17:38:14.297821Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated run flags for plan 03:\n",
            "- Geometry Preprocessor: True\n",
            "- Unsteady Flow Simulation: True\n",
            "- Post Processor: True\n",
            "- Floodplain Mapping: True\n"
          ]
        }
      ],
      "source": [
        "# 3. Update run flags\n",
        "RasPlan.update_run_flags(\n",
        "    new_plan_number,\n",
        "    geometry_preprocessor=True,   # Run the geometry preprocessor\n",
        "    unsteady_flow_simulation=True, # Run unsteady flow simulation\n",
        "    post_processor=True,          # Run post-processing\n",
        "    floodplain_mapping=True       # Generate floodplain mapping outputs\n",
        ")\n",
        "print(f\"\\nUpdated run flags for plan {new_plan_number}:\")\n",
        "print(f\"- Geometry Preprocessor: True\")\n",
        "print(f\"- Unsteady Flow Simulation: True\")\n",
        "print(f\"- Post Processor: True\")\n",
        "print(f\"- Floodplain Mapping: True\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.300563Z",
          "iopub.status.busy": "2025-11-17T17:38:14.300125Z",
          "iopub.status.idle": "2025-11-17T17:38:14.331529Z",
          "shell.execute_reply": "2025-11-17T17:38:14.331102Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - WARNING - Unknown key: Run UNet. Valid keys are: Friction Slope Method, Geom File, Run WQNET, Plan Title, Run HTab, UNET D1 Cores, Run UNET, Short Identifier, Description, Simulation Date, Flow File, PS Cores, Mapping Interval, Run RASMapper, Run Post Process, UNET 1D Methodology, DSS File, UNET D2 Solver Type, Computation Interval, Plan File, UNET D2 Cores, Program Version, Run Sediment, UNET Use Existing IB Tables, UNET D2 Name\n",
            " Add more keys and explanations in get_plan_value() as needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasPlan - WARNING - No description found in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verified run flag values:\n",
            "- Run HTab (Geometry Preprocessor): 1\n",
            "- Run UNet (Unsteady Flow): 1\n",
            "\n",
            "Updated description for plan 03\n",
            "Current plan description:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Verify the updates\n",
        "run_htab = RasPlan.get_plan_value(new_plan_number, \"Run HTab\")\n",
        "run_unet = RasPlan.get_plan_value(new_plan_number, \"Run UNet\")\n",
        "print(f\"Verified run flag values:\")\n",
        "print(f\"- Run HTab (Geometry Preprocessor): {run_htab}\")\n",
        "print(f\"- Run UNet (Unsteady Flow): {run_unet}\")\n",
        "\n",
        "# 4. Update plan description\n",
        "new_description = \"Combined plan with modified geometry and unsteady flow\\nJanuary 2023 simulation\\n1-minute computation interval\\nGeometry and unsteady flow from cloned files\"\n",
        "RasPlan.update_plan_description(new_plan_number, new_description)\n",
        "print(f\"\\nUpdated description for plan {new_plan_number}\")\n",
        "\n",
        "# Read back the description\n",
        "current_description = RasPlan.read_plan_description(new_plan_number)\n",
        "print(f\"Current plan description:\\n{current_description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the Plan\n",
        "\n",
        "Now that we have set up all the parameters, let's compute the plan using RasCmdr.compute_plan():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:38:14.333277Z",
          "iopub.status.busy": "2025-11-17T17:38:14.333079Z",
          "iopub.status.idle": "2025-11-17T17:39:47.743201Z",
          "shell.execute_reply": "2025-11-17T17:39:47.742574Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing plan 03...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:38:14 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 93.39 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan 03 computed successfully\n"
          ]
        }
      ],
      "source": [
        "# Compute the plan with our configured settings\n",
        "# Note: This may take several minutes depending on the complexity of the model\n",
        "print(f\"Computing plan {new_plan_number}...\")\n",
        "success = RasCmdr.compute_plan(new_plan_number, clear_geompre=True)\n",
        "\n",
        "if success:\n",
        "    print(f\"Plan {new_plan_number} computed successfully\")\n",
        "else:\n",
        "    print(f\"Failed to compute plan {new_plan_number}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verifying Results\n",
        "\n",
        "After computation, we should check if results were written correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:39:47.745308Z",
          "iopub.status.busy": "2025-11-17T17:39:47.745064Z",
          "iopub.status.idle": "2025-11-17T17:39:47.762928Z",
          "shell.execute_reply": "2025-11-17T17:39:47.762521Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HDF entries for the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>description</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>2</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady with Bridges and Dam clonedplan</td>\\n', '      <td>5.00</td>\\n', '      <td>Combined Test Plan clone</td>\\n', '      <td>01JAN2023,0000,05JAN2023,2359</td>\\n', '      <td>1MIN</td>\\n', '      <td>30MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>Combined plan with modified geometry and unste...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number  \\\n",
              "2          03              01              02   \n",
              "\n",
              "                                 Plan Title Program Version  \\\n",
              "2  Unsteady with Bridges and Dam clonedplan            5.00   \n",
              "\n",
              "           Short Identifier                Simulation Date  \\\n",
              "2  Combined Test Plan clone  01JAN2023,0000,05JAN2023,2359   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "2                 1MIN            30MIN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method                                        description  \\\n",
              "2                     2  Combined plan with modified geometry and unste...   \n",
              "\n",
              "                                    HDF_Results_Path  Geom File  Geom Path  \\\n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...         02       None   \n",
              "\n",
              "  Flow File Flow Path                                          full_path  \n",
              "2        01      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "\n",
              "[1 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Plan 03 has a valid HDF results file:\n",
            "HDF Path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03.hdf\n",
            "\n",
            "All plan entries with their HDF paths:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>03</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number                                   HDF_Results_Path\n",
              "0          01                                               None\n",
              "1          02                                               None\n",
              "2          03  C:\\GH\\ras-commander\\examples\\example_projects\\..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Refresh the plan entries to ensure we have the latest data\n",
        "ras.plan_df = ras.get_plan_entries()\n",
        "hdf_entries = ras.get_hdf_entries()\n",
        "\n",
        "if not hdf_entries.empty:\n",
        "    print(\"HDF entries for the project:\")\n",
        "    display.display(hdf_entries)\n",
        "    \n",
        "    # Check if our new plan has an HDF file\n",
        "    new_plan_hdf = hdf_entries[hdf_entries['plan_number'] == new_plan_number]\n",
        "    if not new_plan_hdf.empty:\n",
        "        print(f\"\\nPlan {new_plan_number} has a valid HDF results file:\")\n",
        "        print(f\"HDF Path: {new_plan_hdf.iloc[0]['HDF_Results_Path']}\")\n",
        "    else:\n",
        "        print(f\"\\nNo HDF entry found for plan {new_plan_number}\")\n",
        "else:\n",
        "    print(\"No HDF entries found. This could mean the plan hasn't been computed successfully or the results haven't been written yet.\")\n",
        "\n",
        "# Display all plan entries to see their HDF paths\n",
        "print(\"\\nAll plan entries with their HDF paths:\")\n",
        "plan_hdf_info = ras.plan_df[['plan_number', 'HDF_Results_Path']]\n",
        "display.display(plan_hdf_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the plan was computed successfully, we can examine the runtime data and volume accounting from the HDF results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:39:47.765018Z",
          "iopub.status.busy": "2025-11-17T17:39:47.764791Z",
          "iopub.status.idle": "2025-11-17T17:39:47.794810Z",
          "shell.execute_reply": "2025-11-17T17:39:47.794312Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.HdfResultsPlan - INFO - Final validated HDF file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03.hdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.HdfResultsPlan - INFO - Extracting Plan Information from: BaldEagle.p03.hdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.HdfResultsPlan - INFO - Plan Name: Unsteady with Bridges and Dam clonedplan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.HdfResultsPlan - INFO - Simulation Duration (hours): 119.98333333333333\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking computation runtime data...\n",
            "\n",
            "Simulation Runtime Statistics:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan Name</th>\\n', '      <th>File Name</th>\\n', '      <th>Simulation Start Time</th>\\n', '      <th>Simulation End Time</th>\\n', '      <th>Simulation Duration (s)</th>\\n', '      <th>Simulation Time (hr)</th>\\n', '      <th>Completing Geometry (hr)</th>\\n', '      <th>Preprocessing Geometry (hr)</th>\\n', '      <th>Completing Event Conditions (hr)</th>\\n', '      <th>Unsteady Flow Computations (hr)</th>\\n', '      <th>Complete Process (hr)</th>\\n', '      <th>Unsteady Flow Speed (hr/hr)</th>\\n', '      <th>Complete Process Speed (hr/hr)</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>Unsteady with Bridges and Dam clonedplan</td>\\n', '      <td>BaldEagle.p03.hdf</td>\\n', '      <td>2023-01-01</td>\\n', '      <td>2023-01-05 23:59:00</td>\\n', '      <td>431940.0</td>\\n', '      <td>119.983333</td>\\n', '      <td>N/A</td>\\n', '      <td>0.021285</td>\\n', '      <td>N/A</td>\\n', '      <td>0.001267</td>\\n', '      <td>0.025117</td>\\n', '      <td>94661.406969</td>\\n', '      <td>4776.934817</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "                                  Plan Name          File Name  \\\n",
              "0  Unsteady with Bridges and Dam clonedplan  BaldEagle.p03.hdf   \n",
              "\n",
              "  Simulation Start Time Simulation End Time  Simulation Duration (s)  \\\n",
              "0            2023-01-01 2023-01-05 23:59:00                 431940.0   \n",
              "\n",
              "   Simulation Time (hr) Completing Geometry (hr)  Preprocessing Geometry (hr)  \\\n",
              "0            119.983333                      N/A                     0.021285   \n",
              "\n",
              "  Completing Event Conditions (hr)  Unsteady Flow Computations (hr)  \\\n",
              "0                              N/A                         0.001267   \n",
              "\n",
              "   Complete Process (hr)  Unsteady Flow Speed (hr/hr)  \\\n",
              "0               0.025117                 94661.406969   \n",
              "\n",
              "   Complete Process Speed (hr/hr)  \n",
              "0                     4776.934817  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 12:39:47 - ras_commander.HdfResultsPlan - INFO - Final validated HDF file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Simulation Duration: 431940.00 seconds\n",
            "Computation Time: 0.02512 hours\n",
            "Computation Speed: 4776.93 (simulation hours/compute hours)\n",
            "\n",
            "Checking volume accounting...\n"
          ]
        }
      ],
      "source": [
        "# Get computation runtime data from HDF\n",
        "print(\"Checking computation runtime data...\")\n",
        "runtime_df = HdfResultsPlan.get_runtime_data(new_plan_number)\n",
        "\n",
        "if runtime_df is not None and not runtime_df.empty:\n",
        "    print(\"\\nSimulation Runtime Statistics:\")\n",
        "    display.display(runtime_df)\n",
        "    \n",
        "    # Extract key metrics\n",
        "    sim_duration = runtime_df['Simulation Duration (s)'].iloc[0]\n",
        "    compute_time = runtime_df['Complete Process (hr)'].iloc[0]\n",
        "    compute_speed = runtime_df['Complete Process Speed (hr/hr)'].iloc[0]\n",
        "    \n",
        "    print(f\"\\nSimulation Duration: {sim_duration:.2f} seconds\")\n",
        "    print(f\"Computation Time: {compute_time:.5f} hours\")\n",
        "    print(f\"Computation Speed: {compute_speed:.2f} (simulation hours/compute hours)\")\n",
        "else:\n",
        "    print(\"No runtime data found. This may indicate the simulation didn't complete successfully.\")\n",
        "\n",
        "# Get volume accounting data\n",
        "print(\"\\nChecking volume accounting...\")\n",
        "volume_df = HdfResultsPlan.get_volume_accounting(new_plan_number)\n",
        "\n",
        "if volume_df is not None and not isinstance(volume_df, bool):\n",
        "    # Handle volume_df as a dictionary\n",
        "    if isinstance(volume_df, dict):\n",
        "        error_percent = volume_df.get('Error Percent')\n",
        "        if error_percent is not None:\n",
        "            print(f\"\\nFinal Volume Balance Error: {float(error_percent):.8f}%\")\n",
        "            \n",
        "        # Print other key statistics\n",
        "        print(\"\\nDetailed Volume Statistics:\")\n",
        "        print(f\"Volume Starting: {float(volume_df['Volume Starting']):.2f} {volume_df['Vol Accounting in'].decode()}\")\n",
        "        print(f\"Volume Ending: {float(volume_df['Volume Ending']):.2f} {volume_df['Vol Accounting in'].decode()}\")\n",
        "        print(f\"Total Inflow: {float(volume_df['Total Boundary Flux of Water In']):.2f} {volume_df['Vol Accounting in'].decode()}\")\n",
        "        print(f\"Total Outflow: {float(volume_df['Total Boundary Flux of Water Out']):.2f} {volume_df['Vol Accounting in'].decode()}\")\n",
        "else:\n",
        "    print(\"No volume accounting data found. This may indicate the simulation didn't complete successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Plan and Geometry Operations\n",
        "\n",
        "In this notebook, we've covered a comprehensive range of operations on HEC-RAS plan and geometry files using the RAS Commander library:\n",
        "\n",
        "1. **Project Initialization**: We initialized a HEC-RAS project to work with\n",
        "2. **Plan Operations**:\n",
        "   - Created a new plan by cloning an existing one\n",
        "   - Updated simulation parameters (dates, intervals, etc.)\n",
        "   - Set run flags for different components\n",
        "   - Updated the plan description\n",
        "3. **Geometry Operations**:\n",
        "   - Created a new geometry by cloning an existing one\n",
        "   - Associated the new geometry with our plan\n",
        "   - Cleared geometry preprocessor files\n",
        "4. **Unsteady Flow Operations**:\n",
        "   - Created a new unsteady flow file by cloning an existing one\n",
        "   - Associated it with our plan\n",
        "5. **Computation and Verification**:\n",
        "   - Computed our plan with the specified settings\n",
        "   - Verified the results using HDF entries\n",
        "   - Analyzed runtime statistics and volume accounting\n",
        "\n",
        "\n",
        "### Key Classes and Functions Used\n",
        "\n",
        "- `RasPlan`: For plan operations (cloning, setting components, and modifying parameters)\n",
        "- `RasGeo`: For geometry operations (cloning, clearing preprocessor files)\n",
        "- `RasCmdr`: For executing HEC-RAS simulations\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "To further enhance your HEC-RAS automation, consider exploring:\n",
        "\n",
        "1. **Parameter Sweeps**: Create and run multiple plans with varying parameters\n",
        "2. **Parallel Computations**: Run multiple plans simultaneously using `RasCmdr.compute_parallel()`\n",
        "3. **Advanced Results Analysis**: Use the HDF classes to extract and analyze specific model results\n",
        "4. **Spatial Visualization**: Create maps and plots of simulation results\n",
        "5. **Model Calibration**: Automate comparison between model results and observations\n",
        "\n",
        "The RAS Commander library provides a powerful framework for automating and streamlining your HEC-RAS workflows, enabling more efficient hydraulic modeling and analyses."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\03_unsteady_flow_operations.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set to True to generate plots, False to skip plotting\n",
        "generate_plots = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Unsteady Flow Files in HEC-RAS\n",
        "\n",
        "Unsteady flow files (`.u*` files) in HEC-RAS define the time-varying boundary conditions that drive dynamic simulations. These include:\n",
        "\n",
        "- **Flow Hydrographs**: Time-series of flow values at model boundaries\n",
        "- **Stage Hydrographs**: Time-series of water surface elevations\n",
        "- **Lateral Inflows**: Distributed inflows along a reach\n",
        "- **Gate Operations**: Time-series of gate settings\n",
        "- **Meteorological Data**: Rainfall, evaporation, and other meteorological inputs\n",
        "\n",
        "The `RasUnsteady` class in RAS Commander provides methods for working with these files, including extracting boundaries, reading tables, and modifying parameters.\n",
        "\n",
        "Let's set up our working directory and define paths to example projects:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading and Extracting Example HEC-RAS Projects\n",
        "\n",
        "We'll use the `RasExamples` class to download and extract an example HEC-RAS project with unsteady flow files. For this notebook, we'll use the \"Balde Eagle Creek\" project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the Bald Eagle Creek example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(f\"Extracted project to: {bald_eagle_path}\")  \n",
        "\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "The first step is to initialize the HEC-RAS project. This is done using the `init_ras_project()` function, which takes the following parameters:\n",
        "\n",
        "- `ras_project_folder`: Path to the HEC-RAS project folder (required)\n",
        "- `ras_version`: HEC-RAS version (e.g., \"6.6\") or path to Ras.exe (required first time)\n",
        "\n",
        "This function initializes the global `ras` object that we'll use for the rest of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the HEC-RAS project\n",
        "# This function returns a RAS object, but also updates the global 'ras' object\n",
        "# Parameters:\n",
        "#   - ras_project_folder: Path to the HEC-RAS project folder\n",
        "#   - ras_version: HEC-RAS version or path to Ras.exe\n",
        "\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "\n",
        "# Display the unsteady flow files in the project\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nHEC-RAS Project Plan Data (plan_df):\")\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nHEC-RAS Project Geometry Data (geom_df):\")\n",
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nHEC-RAS Project Unsteady Flow Data (unsteady_df):\")\n",
        "\n",
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nHEC-RAS Project Boundary Data (boundaries_df):\")\n",
        "print(\"Columns:\", list(ras.boundaries_df.columns))\n",
        "ras.boundaries_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the RasUnsteady Class\n",
        "\n",
        "The `RasUnsteady` class provides functionality for working with HEC-RAS unsteady flow files (`.u*` files). Key operations include:\n",
        "\n",
        "1. **Extracting Boundary Conditions**: Read and parse boundary conditions from unsteady flow files\n",
        "2. **Modifying Flow Titles**: Update descriptive titles for unsteady flow scenarios\n",
        "3. **Managing Restart Settings**: Configure restart file options for continuing simulations\n",
        "4. **Working with Tables**: Extract, modify, and update flow tables\n",
        "\n",
        "Most methods in this class are static and work with the global `ras` object by default, though you can also pass in a custom RAS object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Extract Boundary Conditions and Tables\n",
        "\n",
        "The `extract_boundary_and_tables()` method from the `RasUnsteady` class allows us to extract boundary conditions and their associated tables from an unsteady flow file.\n",
        "\n",
        "Parameters for `RasUnsteady.extract_boundary_and_tables()`:\n",
        "- `unsteady_file` (str): Path to the unsteady flow file\n",
        "- `ras_object` (optional): Custom RAS object to use instead of the global one\n",
        "\n",
        "Returns:\n",
        "- `pd.DataFrame`: DataFrame containing boundary conditions and their associated tables\n",
        "\n",
        "Let's see how this works with our example project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to unsteady flow file \"02\"\n",
        "unsteady_file = RasPlan.get_unsteady_path(\"02\")\n",
        "print(f\"Unsteady flow file path: {unsteady_file}\")\n",
        "\n",
        "# Extract boundary conditions and tables\n",
        "boundaries_df = RasUnsteady.extract_boundary_and_tables(unsteady_file)\n",
        "print(f\"Extracted {len(boundaries_df)} boundary conditions from the unsteady flow file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Print Boundaries and Tables\n",
        "\n",
        "The `print_boundaries_and_tables()` method provides a formatted display of the boundary conditions and their associated tables. This method doesn't return anything; it just prints the information in a readable format.\n",
        "\n",
        "Parameters for `RasUnsteady.print_boundaries_and_tables()`:\n",
        "- `boundaries_df` (pd.DataFrame): DataFrame containing boundary conditions from `extract_boundary_and_tables()`\n",
        "\n",
        "Let's use this method to get a better understanding of our boundary conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the boundaries and tables in a formatted way\n",
        "print(\"Detailed boundary conditions and tables:\")\n",
        "RasUnsteady.print_boundaries_and_tables(boundaries_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Boundary Condition Types\n",
        "\n",
        "The output above shows the different types of boundary conditions in our unsteady flow file. Let's understand what each type means:\n",
        "\n",
        "1. **Flow Hydrograph**: A time series of flow values (typically in cfs or cms) entering the model at a specific location. These are used at upstream boundaries or internal points where flow enters the system.\n",
        "\n",
        "2. **Stage Hydrograph**: A time series of water surface elevations (typically in ft or m) that define the downstream boundary condition.\n",
        "\n",
        "3. **Gate Openings**: Time series of gate settings (typically height in ft or m) for hydraulic structures such as spillways, sluice gates, or other control structures.\n",
        "\n",
        "4. **Lateral Inflow Hydrograph**: Flow entering the system along a reach, not at a specific point. This can represent tributary inflows, overland flow, or other distributed inputs.\n",
        "\n",
        "5. **Normal Depth**: A boundary condition where the water surface slope is assumed to equal the bed slope. This is represented by a friction slope value.\n",
        "\n",
        "Let's look at a specific boundary condition in more detail:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's examine the first boundary condition in more detail\n",
        "if not boundaries_df.empty:\n",
        "    first_boundary = boundaries_df.iloc[0]\n",
        "    print(f\"Detailed look at boundary condition {1}:\")\n",
        "    \n",
        "    # Print boundary location components\n",
        "    print(f\"\\nBoundary Location:\")\n",
        "    print(f\"  River Name: {first_boundary.get('River Name', 'N/A')}\")\n",
        "    print(f\"  Reach Name: {first_boundary.get('Reach Name', 'N/A')}\")\n",
        "    print(f\"  River Station: {first_boundary.get('River Station', 'N/A')}\")\n",
        "    print(f\"  Storage Area Name: {first_boundary.get('Storage Area Name', 'N/A')}\")\n",
        "    \n",
        "    # Print boundary condition type and other properties\n",
        "    print(f\"\\nBoundary Properties:\")\n",
        "    print(f\"  Boundary Type: {first_boundary.get('bc_type', 'N/A')}\")\n",
        "    print(f\"  DSS File: {first_boundary.get('DSS File', 'N/A')}\")\n",
        "    print(f\"  Use DSS: {first_boundary.get('Use DSS', 'N/A')}\")\n",
        "    \n",
        "    # Print table statistics if available\n",
        "    if 'Tables' in first_boundary and isinstance(first_boundary['Tables'], dict):\n",
        "        print(f\"\\nTable Information:\")\n",
        "        for table_name, table_df in first_boundary['Tables'].items():\n",
        "            print(f\"  {table_name}: {len(table_df)} values\")\n",
        "            if not table_df.empty:\n",
        "                print(f\"    Min Value: {table_df['Value'].min()}\")\n",
        "                print(f\"    Max Value: {table_df['Value'].max()}\")\n",
        "                print(f\"    First 5 Values: {table_df['Value'].head(5).tolist()}\")\n",
        "else:\n",
        "    print(\"No boundary conditions found in the unsteady flow file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Update Flow Title\n",
        "\n",
        "The flow title in an unsteady flow file provides a description of the simulation scenario. The `update_flow_title()` method allows us to modify this title.\n",
        "\n",
        "Parameters for `RasUnsteady.update_flow_title()`:\n",
        "- `unsteady_file` (str): Full path to the unsteady flow file\n",
        "- `new_title` (str): New flow title (max 24 characters)\n",
        "- `ras_object` (optional): Custom RAS object to use instead of the global one\n",
        "\n",
        "Let's clone an unsteady flow file and update its title:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone unsteady flow \"02\" to create a new unsteady flow file\n",
        "new_unsteady_number = RasPlan.clone_unsteady(\"02\")\n",
        "print(f\"New unsteady flow created: {new_unsteady_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_unsteady_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to the new unsteady flow file\n",
        "new_unsteady_file = RasPlan.get_unsteady_path(new_unsteady_number)\n",
        "print(f\"New unsteady flow file path: {new_unsteady_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_unsteady_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current flow title\n",
        "current_title = None\n",
        "for _, row in ras.unsteady_df.iterrows():\n",
        "    if row['unsteady_number'] == new_unsteady_number and 'Flow Title' in row:\n",
        "        current_title = row['Flow Title']\n",
        "        break\n",
        "print(f\"Current flow title: {current_title}\")\n",
        "\n",
        "# Update the flow title\n",
        "new_title = \"Modified Flow Scenario\"\n",
        "RasUnsteady.update_flow_title(new_unsteady_file, new_title)\n",
        "print(f\"Updated flow title to: {new_title}\")\n",
        "\n",
        "# Refresh unsteady flow information to see the change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Review unsteady flow information to see the change\n",
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Working with Flow Tables\n",
        "\n",
        "Flow tables in unsteady flow files contain the time-series data for boundary conditions. Let's explore how to extract and work with these tables using some of the advanced methods from the `RasUnsteady` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract specific tables from the unsteady flow file\n",
        "all_tables = RasUnsteady.extract_tables(new_unsteady_file)\n",
        "print(f\"Extracted {len(all_tables)} tables from the unsteady flow file.\")\n",
        "\n",
        "# Let's look at the available table names\n",
        "print(\"\\nAvailable tables:\")\n",
        "for table_name in all_tables.keys():\n",
        "    print(f\"  {table_name}\")\n",
        "\n",
        "# Select the first table for detailed analysis\n",
        "if all_tables and len(all_tables) > 0:\n",
        "    first_table_name = list(all_tables.keys())[0]\n",
        "    first_table = all_tables[first_table_name]\n",
        "    \n",
        "    print(f\"\\nDetailed look at table '{first_table_name}':\")\n",
        "    print(f\"  Number of values: {len(first_table)}\")\n",
        "    print(f\"  Min value: {first_table['Value'].min()}\")\n",
        "    print(f\"  Max value: {first_table['Value'].max()}\")\n",
        "    print(f\"  Mean value: {first_table['Value'].mean():.2f}\")\n",
        "    print(f\"  First 10 values: {first_table['Value'].head(10).tolist()}\")\n",
        "    \n",
        "    # Create a visualization of the table values\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        \n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(first_table['Value'].values)\n",
        "        plt.title(f\"{first_table_name} Values\")\n",
        "        plt.xlabel('Time Step')\n",
        "        plt.ylabel('Value')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create visualization: {e}\")\n",
        "else:\n",
        "    print(\"No tables found in the unsteady flow file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Modifying Flow Tables\n",
        "\n",
        "Now let's demonstrate how to modify a flow table and write it back to the unsteady flow file. For this example, we'll scale all the values in a table by a factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scaling existing values down by a 0.75 scale factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, identify tables in the unsteady flow file\n",
        "tables = RasUnsteady.identify_tables(open(new_unsteady_file, 'r').readlines())\n",
        "print(f\"Identified {len(tables)} tables in the unsteady flow file.\")\n",
        "\n",
        "# Let's look at the first flow hydrograph table\n",
        "flow_hydrograph_tables = [t for t in tables if t[0] == 'Flow Hydrograph=']\n",
        "if flow_hydrograph_tables:\n",
        "    table_name, start_line, end_line = flow_hydrograph_tables[0]\n",
        "    print(f\"\\nSelected table: {table_name}\")\n",
        "    print(f\"  Start line: {start_line}\")\n",
        "    print(f\"  End line: {end_line}\")\n",
        "    \n",
        "    # Parse the table\n",
        "    lines = open(new_unsteady_file, 'r').readlines()\n",
        "    table_df = RasUnsteady.parse_fixed_width_table(lines, start_line, end_line)\n",
        "    print(f\"\\nOriginal table statistics:\")\n",
        "    print(f\"  Number of values: {len(table_df)}\")\n",
        "    print(f\"  Min value: {table_df['Value'].min()}\")\n",
        "    print(f\"  Max value: {table_df['Value'].max()}\")\n",
        "    print(f\"  First 5 values: {table_df['Value'].head(5).tolist()}\")\n",
        "    \n",
        "    # Modify the table - let's scale all values by 75%\n",
        "    scale_factor = 0.75\n",
        "    table_df['Value'] = table_df['Value'] * scale_factor\n",
        "    print(f\"\\nModified table statistics (scaled by {scale_factor}):\")\n",
        "    print(f\"  Number of values: {len(table_df)}\")\n",
        "    print(f\"  Min value: {table_df['Value'].min()}\")\n",
        "    print(f\"  Max value: {table_df['Value'].max()}\")\n",
        "    print(f\"  First 5 values: {table_df['Value'].head(5).tolist()}\")\n",
        "    \n",
        "    # Write the modified table back to the file\n",
        "    RasUnsteady.write_table_to_file(new_unsteady_file, table_name, table_df, start_line)\n",
        "    print(f\"\\nUpdated table written back to the unsteady flow file.\")\n",
        "    \n",
        "    # Re-read the table to verify changes\n",
        "    lines = open(new_unsteady_file, 'r').readlines()\n",
        "    updated_table_df = RasUnsteady.parse_fixed_width_table(lines, start_line, end_line)\n",
        "    print(f\"\\nVerified updated table statistics:\")\n",
        "    print(f\"  Number of values: {len(updated_table_df)}\")\n",
        "    print(f\"  Min value: {updated_table_df['Value'].min()}\")\n",
        "    print(f\"  Max value: {updated_table_df['Value'].max()}\")\n",
        "    print(f\"  First 5 values: {updated_table_df['Value'].head(5).tolist()}\")\n",
        "else:\n",
        "    print(\"No flow hydrograph tables found in the unsteady flow file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract specific tables from the unsteady flow file\n",
        "all_tables = RasUnsteady.extract_tables(new_unsteady_file)\n",
        "\n",
        "# Get the updated flow hydrograph table\n",
        "flow_hydrograph_tables = [t for t in all_tables.keys() if 'Flow Hydrograph=' in t]\n",
        "if flow_hydrograph_tables:\n",
        "    table_name = flow_hydrograph_tables[0]\n",
        "    table_df = all_tables[table_name]\n",
        "    \n",
        "    # Create visualization of the updated flow values\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(table_df['Value'].values, 'b-', label='Updated Flow')\n",
        "    plt.title('Updated Flow Hydrograph')\n",
        "    plt.xlabel('Time Step') \n",
        "    plt.ylabel('Flow (cfs)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"\\nUpdated flow hydrograph statistics:\")\n",
        "    print(f\"  Number of values: {len(table_df)}\")\n",
        "    print(f\"  Min flow: {table_df['Value'].min():.1f} cfs\")\n",
        "    print(f\"  Max flow: {table_df['Value'].max():.1f} cfs\")\n",
        "    print(f\"  Mean flow: {table_df['Value'].mean():.1f} cfs\")\n",
        "else:\n",
        "    print(\"No flow hydrograph tables found in the unsteady flow file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute Plan 01 to generate model results\n",
        "\n",
        "RasCmdr.compute_plan(\"01\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cross section results timeseries as xarray dataset\n",
        "xsec_results_xr_plan1 = HdfResultsXsec.get_xsec_timeseries(\"01\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xsec_results_xr_plan1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print time series for specific cross section\n",
        "target_xs = \"Bald Eagle       Loc Hav          136202.3\"\n",
        "\n",
        "print(\"\\nTime Series Data for Cross Section:\", target_xs)\n",
        "for var in ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']:\n",
        "    print(f\"\\n{var}:\")\n",
        "    print(f\"Plan 1:\")\n",
        "    print(xsec_results_xr_plan1[var].sel(cross_section=target_xs).values[:5])  # Show first 5 values\n",
        "\n",
        "\n",
        "# Create time series plots\n",
        "if generate_plots:\n",
        "\n",
        "    # Create a figure for each variable\n",
        "    variables = ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']\n",
        "\n",
        "    for var in variables:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        \n",
        "        # Convert time values to datetime if needed\n",
        "        time_values1 = pd.to_datetime(xsec_results_xr_plan1.time.values)\n",
        "        values1 = xsec_results_xr_plan1[var].sel(cross_section=target_xs).values\n",
        "\n",
        "        \n",
        "        # Plot both plans\n",
        "        plt.plot(time_values1, values1, '-', linewidth=2, label='Plan 1')\n",
        "        \n",
        "        plt.title(f'{var} at {target_xs}')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel(var.replace('_', ' '))\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Force display\n",
        "        plt.draw()\n",
        "        plt.pause(0.1)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Applying the Updated Unsteady Flow to a New Plan\n",
        "\n",
        "Now that we've modified an unsteady flow file, let's create a plan that uses it, and compute the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone an existing plan\n",
        "new_plan_number = RasPlan.clone_plan(\"01\", new_plan_shortid=\"Modified Flow Test\")\n",
        "print(f\"New plan created: {new_plan_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_plan_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current plan title and shortid\n",
        "current_title = RasPlan.get_plan_title(new_plan_number)\n",
        "current_shortid = RasPlan.get_shortid(new_plan_number)\n",
        "\n",
        "print(f\"Current plan title: {current_title}\")\n",
        "print(f\"Current plan shortid: {current_shortid}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the title and shortid to append \" clonedplan\"\n",
        "new_title = f\"{current_title} 0.75 Flow Scale Factor\"\n",
        "new_shortid = f\"{current_shortid} 0.75 FSF\"\n",
        "\n",
        "RasPlan.set_plan_title(new_plan_number, new_title)\n",
        "RasPlan.set_shortid(new_plan_number, new_shortid)\n",
        "\n",
        "print(f\"\\nUpdated plan title: {RasPlan.get_plan_title(new_plan_number)}\")\n",
        "print(f\"Updated plan shortid: {RasPlan.get_shortid(new_plan_number)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print new_unsteady_number again as a reminder of it's current value\n",
        "new_unsteady_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the modified unsteady flow for the new plan\n",
        "RasPlan.set_unsteady(new_plan_number, new_unsteady_number)\n",
        "print(f\"Set unsteady flow {new_unsteady_number} for plan {new_plan_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the modified unsteady flow for the new plan\n",
        "RasPlan.set_unsteady(new_plan_number, new_unsteady_number)\n",
        "print(f\"Set unsteady flow {new_unsteady_number} for plan {new_plan_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to the new plan file\n",
        "new_plan_path = RasPlan.get_plan_path(new_plan_number)\n",
        "\n",
        "# Print contents of new plan file to confirm changes\n",
        "# Read and display the contents of the plan file\n",
        "with open(new_plan_path, 'r') as f:\n",
        "    plan_contents = f.read()\n",
        "print(f\"Contents of plan file {new_plan_number}:\")\n",
        "print(plan_contents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the plan description\n",
        "new_description = \"Test plan using modified unsteady flow\\nFlow scaled to 75% of original\\nWith restart file enabled\"\n",
        "RasPlan.update_plan_description(new_plan_number, new_description)\n",
        "print(f\"Updated plan description for plan {new_plan_number}\")\n",
        "\n",
        "# Set computation options\n",
        "RasPlan.set_num_cores(new_plan_number, 2)\n",
        "\n",
        "# Consider any other changes you want to make at this step, such as computation intervals etc: \n",
        "# RasPlan.update_plan_intervals(\n",
        "#    new_plan_number,\n",
        "#    computation_interval=\"1MIN\",\n",
        "#    output_interval=\"15MIN\",\n",
        "#    mapping_interval=\"1HOUR\"\n",
        "#)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the plan\n",
        "print(f\"\\nComputing plan {new_plan_number} with modified unsteady flow...\")\n",
        "success = RasCmdr.compute_plan(new_plan_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if success:\n",
        "    print(f\"Plan {new_plan_number} computed successfully\")\n",
        "    \n",
        "    # Check the results path\n",
        "    results_path = RasPlan.get_results_path(new_plan_number)\n",
        "    if results_path:\n",
        "        print(f\"Results available at: {results_path}\")\n",
        "        \n",
        "        # If it exists, get its size\n",
        "        results_file = Path(results_path)\n",
        "        if results_file.exists():\n",
        "            size_mb = results_file.stat().st_size / (1024 * 1024)\n",
        "            print(f\"Results file size: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(\"No results found.\")\n",
        "else:\n",
        "    print(f\"Failed to compute plan {new_plan_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show updated plan_df dataframe, which should show the HDF results files\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get results for Plan 03 and Compare with Plan 01's results for the specified Cross Section\n",
        "target_xs = \"Bald Eagle       Loc Hav          136202.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cross section results timeseries as xarray dataset\n",
        "xsec_results_xr_plan2 = HdfResultsXsec.get_xsec_timeseries(\"03\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xsec_results_xr_plan2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print time series for specific cross section\n",
        "target_xs = \"Bald Eagle       Loc Hav          136202.3\"\n",
        "\n",
        "print(\"\\nTime Series Data for Cross Section:\", target_xs)\n",
        "for var in ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']:\n",
        "    print(f\"\\n{var}:\")\n",
        "    print(f\"Plan 1:\")\n",
        "    print(xsec_results_xr_plan1[var].sel(cross_section=target_xs).values[:5])  # Show first 5 values\n",
        "    print(f\"Plan 2:\")\n",
        "    print(xsec_results_xr_plan2[var].sel(cross_section=target_xs).values[:5])  # Show first 5 values\n",
        "\n",
        "# Create time series plots\n",
        "if generate_plots:\n",
        "\n",
        "    # Create a figure for each variable\n",
        "    variables = ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']\n",
        "\n",
        "    for var in variables:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        \n",
        "        # Convert time values to datetime if needed\n",
        "        time_values1 = pd.to_datetime(xsec_results_xr_plan1.time.values)\n",
        "        time_values2 = pd.to_datetime(xsec_results_xr_plan2.time.values)\n",
        "        values1 = xsec_results_xr_plan1[var].sel(cross_section=target_xs).values\n",
        "        values2 = xsec_results_xr_plan2[var].sel(cross_section=target_xs).values\n",
        "        \n",
        "        # Get plan titles from plan_df\n",
        "        plan1_title = ras.plan_df.loc[ras.plan_df['plan_number'] == '01', 'Plan Title'].iloc[0]\n",
        "        plan2_title = ras.plan_df.loc[ras.plan_df['plan_number'] == '03', 'Plan Title'].iloc[0]\n",
        "        \n",
        "        # Plot both plans with titles\n",
        "        plt.plot(time_values1, values1, '-', linewidth=2, label=f'{plan1_title} (Plan 01)')\n",
        "        plt.plot(time_values2, values2, '--', linewidth=2, label=f'{plan2_title} (Plan 03)')\n",
        "        \n",
        "        plt.title(f'{var} at {target_xs}')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel(var.replace('_', ' '))\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Force display\n",
        "        plt.draw()\n",
        "        plt.pause(0.1)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Unsteady Flow Operations\n",
        "\n",
        "In this notebook, we've covered the following unsteady flow operations using RAS Commander:\n",
        "\n",
        "1. **Project Initialization**: We initialized a HEC-RAS project to work with\n",
        "2. **Boundary Extraction**: We extracted boundary conditions and tables from unsteady flow files\n",
        "3. **Boundary Analysis**: We inspected and understood boundary condition structures\n",
        "4. **Flow Title Updates**: We modified the title of an unsteady flow file\n",
        "5. **Restart Settings**: We configured restart file settings for continuing simulations\n",
        "6. **Table Extraction**: We extracted flow tables for analysis\n",
        "7. **Table Modification**: We modified a flow table and wrote it back to the file\n",
        "8. **Application**: We created a plan using our modified unsteady flow and computed results\n",
        "\n",
        "### Key Classes and Functions Used\n",
        "\n",
        "- `RasUnsteady.extract_boundary_and_tables()`: Extract boundary conditions and tables\n",
        "- `RasUnsteady.print_boundaries_and_tables()`: Display formatted boundary information\n",
        "- `RasUnsteady.update_flow_title()`: Modify the flow title\n",
        "- `RasUnsteady.update_restart_settings()`: Configure restart options\n",
        "- `RasUnsteady.extract_tables()`: Extract tables from unsteady flow files\n",
        "- `RasUnsteady.identify_tables()`: Identify table locations in file\n",
        "- `RasUnsteady.parse_fixed_width_table()`: Parse fixed-width tables\n",
        "- `RasUnsteady.write_table_to_file()`: Write modified tables back to file\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "To further explore unsteady flow operations with RAS Commander, consider:\n",
        "\n",
        "1. **Advanced Flow Modifications**: Create scripts that systematically modify flow hydrographs\n",
        "2. **Sensitivity Analysis**: Create variations of unsteady flows to assess model sensitivity\n",
        "3. **Batch Processing**: Process multiple unsteady flow files for scenario analysis\n",
        "4. **Custom Boundary Conditions**: Create unsteady flows from external data sources\n",
        "5. **Results Analysis**: Compare results from different unsteady flow scenarios\n",
        "\n",
        "These advanced topics can be explored by building on the foundation established in this notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\04_multiple_project_operations.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:39.070533Z",
          "iopub.status.busy": "2025-11-17T18:31:39.070278Z",
          "iopub.status.idle": "2025-11-17T18:31:40.525003Z",
          "shell.execute_reply": "2025-11-17T18:31:40.524432Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:39 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:40.527284Z",
          "iopub.status.busy": "2025-11-17T18:31:40.526994Z",
          "iopub.status.idle": "2025-11-17T18:31:40.530698Z",
          "shell.execute_reply": "2025-11-17T18:31:40.530173Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:40.532837Z",
          "iopub.status.busy": "2025-11-17T18:31:40.532651Z",
          "iopub.status.idle": "2025-11-17T18:31:42.422954Z",
          "shell.execute_reply": "2025-11-17T18:31:42.422314Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Found zip file: C:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:40 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Project 'Muncie' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Existing folder for project 'Muncie' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WindowsPath('C:/GH/ras-commander/examples/example_projects/Balde Eagle Creek'), WindowsPath('C:/GH/ras-commander/examples/example_projects/BaldEagleCrkMulti2D'), WindowsPath('C:/GH/ras-commander/examples/example_projects/Muncie')]\n",
            "Examples directory: C:\\GH\\ras-commander\\examples\\example_projects\n",
            "Path C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek exists: True\n",
            "Path C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D exists: True\n",
            "Path C:\\GH\\ras-commander\\examples\\example_projects\\Muncie exists: True\n"
          ]
        }
      ],
      "source": [
        "# Extract specific projects we'll use in this tutorial\n",
        "# This will download them if not present and extract them to the example_projects folder\n",
        "extracted_paths = RasExamples.extract_project([\"Balde Eagle Creek\", \"BaldEagleCrkMulti2D\", \"Muncie\"])\n",
        "print(extracted_paths)\n",
        "\n",
        "# Get the parent directory of the first extracted path as our examples directory\n",
        "examples_dir = extracted_paths[0].parent\n",
        "print(f\"Examples directory: {examples_dir}\")\n",
        "\n",
        "\n",
        "# Define paths to the extracted projects\n",
        "bald_eagle_path = examples_dir / \"Balde Eagle Creek\"\n",
        "multi_2d_path = examples_dir / \"BaldEagleCrkMulti2D\"\n",
        "muncie_path = examples_dir / \"Muncie\"\n",
        "\n",
        "# Verify the paths exist\n",
        "for path in [bald_eagle_path, multi_2d_path, muncie_path]:\n",
        "    print(f\"Path {path} exists: {path.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:42.425057Z",
          "iopub.status.busy": "2025-11-17T18:31:42.424802Z",
          "iopub.status.idle": "2025-11-17T18:31:42.429421Z",
          "shell.execute_reply": "2025-11-17T18:31:42.428823Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System Resources:\n",
            "- 8 physical CPU cores (8 logical cores)\n",
            "- 13.4 GB available memory\n",
            "For multiple HEC-RAS projects, a good rule of thumb is:\n",
            "- Assign 2-4 cores per project\n",
            "- Allocate at least 2-4 GB of RAM per project\n",
            "Based on your system, you could reasonably run 4 projects simultaneously.\n"
          ]
        }
      ],
      "source": [
        "# Define computation output paths\n",
        "bald_eagle_compute_folder = examples_dir / \"compute_bald_eagle\"\n",
        "muncie_compute_folder = examples_dir / \"compute_muncie\"\n",
        "\n",
        "# Check system resources\n",
        "cpu_count = psutil.cpu_count(logical=True)\n",
        "physical_cpu_count = psutil.cpu_count(logical=False)\n",
        "available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
        "\n",
        "print(f\"System Resources:\")\n",
        "print(f\"- {physical_cpu_count} physical CPU cores ({cpu_count} logical cores)\")\n",
        "print(f\"- {available_memory_gb:.1f} GB available memory\")\n",
        "print(f\"For multiple HEC-RAS projects, a good rule of thumb is:\")\n",
        "print(f\"- Assign 2-4 cores per project\")\n",
        "print(f\"- Allocate at least 2-4 GB of RAM per project\")\n",
        "print(f\"Based on your system, you could reasonably run {min(physical_cpu_count//2, int(available_memory_gb//3))} projects simultaneously.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Multiple RAS Project Management\n",
        "\n",
        "When working with multiple HEC-RAS projects in RAS Commander, there are two important concepts to understand:\n",
        "\n",
        "1. **The Global 'ras' Object**: By default, RAS Commander maintains a global `ras` object that represents the currently active project. This is convenient for simple scripts.\n",
        "\n",
        "2. **Custom RAS Objects**: For multiple projects, you'll create separate RAS objects for each project. These custom objects store project-specific data and are passed to RAS Commander functions using the `ras_object` parameter.\n",
        "\n",
        "### Best Practices for Multiple Project Management\n",
        "\n",
        "- **Name Your Objects Clearly**: Use descriptive variable names for your RAS objects (e.g., `bald_eagle_ras`, `muncie_ras`)\n",
        "- **Be Consistent**: Always pass the appropriate RAS object to functions when working with multiple projects\n",
        "- **Avoid Using Global 'ras'**: When working with multiple projects, avoid using the global `ras` object to prevent confusion\n",
        "- **Separate Compute Folders**: Use separate computation folders for each project\n",
        "- **Manage Resources**: Be mindful of CPU and memory usage when running multiple projects in parallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading and Extracting Example HEC-RAS Projects\n",
        "\n",
        "We'll use the `RasExamples` class to download and extract two example HEC-RAS projects: \"Balde Eagle Creek\" and \"Muncie\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:42.431798Z",
          "iopub.status.busy": "2025-11-17T18:31:42.431536Z",
          "iopub.status.idle": "2025-11-17T18:31:43.092073Z",
          "shell.execute_reply": "2025-11-17T18:31:43.091458Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:42 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed existing example projects directory: C:\\GH\\ras-commander\\examples\\example_projects\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted projects to:\n",
            "- C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "- C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
            "\n",
            "Bald Eagle Creek project exists: True\n",
            "Muncie project exists: True\n"
          ]
        }
      ],
      "source": [
        "# Delete existing project if it exists to ensure a clean start\n",
        "if examples_dir.exists():\n",
        "    shutil.rmtree(examples_dir)\n",
        "    print(f\"Removed existing example projects directory: {examples_dir}\")\n",
        "\n",
        "# Create a RasExamples instance\n",
        "ras_examples = RasExamples()\n",
        "\n",
        "# Extract the example projects\n",
        "extracted_paths = ras_examples.extract_project([\"Balde Eagle Creek\", \"Muncie\"])\n",
        "print(f\"Extracted projects to:\")\n",
        "for path in extracted_paths:\n",
        "    print(f\"- {path}\")\n",
        "\n",
        "# Verify the paths exist\n",
        "print(f\"\\nBald Eagle Creek project exists: {bald_eagle_path.exists()}\")\n",
        "print(f\"Muncie project exists: {muncie_path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize Multiple Projects\n",
        "\n",
        "Let's initialize both HEC-RAS projects. Instead of using the global `ras` object, we'll create separate RAS objects for each project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.094547Z",
          "iopub.status.busy": "2025-11-17T18:31:43.094337Z",
          "iopub.status.idle": "2025-11-17T18:31:43.232786Z",
          "shell.execute_reply": "2025-11-17T18:31:43.232115Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized Bald Eagle Creek project: BaldEagle\n",
            "Initialized Muncie project: Muncie\n",
            "\n",
            "Available plans in Bald Eagle Creek project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "0                 2MIN            1HOUR        1  ...     None      dss   \n",
              "1                 2MIN              NaN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method HDF_Results_Path Geom File  \\\n",
              "0                     2             None        01   \n",
              "1                     1             None        01   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...    Steady  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available plans in Muncie project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>9-SAs</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady Run with 2D 50ft Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>-1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>01</td>\\n', '      <td>04</td>\\n', '      <td>Unsteady Run with 2D 50ft User n Value R</td>\\n', '      <td>5.10</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number  \\\n",
              "0          01              01              01   \n",
              "1          03              01              02   \n",
              "2          04              01              04   \n",
              "\n",
              "                                 Plan Title Program Version  \\\n",
              "0                  Unsteady Multi  9-SA run            5.00   \n",
              "1            Unsteady Run with 2D 50ft Grid            5.10   \n",
              "2  Unsteady Run with 2D 50ft User n Value R            5.10   \n",
              "\n",
              "      Short Identifier                Simulation Date Computation Interval  \\\n",
              "0                9-SAs  02JAN1900,0000,02JAN1900,2400                15SEC   \n",
              "1         2D 50ft Grid  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "2  50ft User n Regions  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "\n",
              "  Mapping Interval Run HTab  ... Friction Slope Method UNET D2 SolverType  \\\n",
              "0             5MIN        1  ...                     1                NaN   \n",
              "1             5MIN       -1  ...                     1   Pardiso (Direct)   \n",
              "2             5MIN        1  ...                     1   Pardiso (Direct)   \n",
              "\n",
              "       UNET D2 Name HDF_Results_Path Geom File  \\\n",
              "0               NaN             None        01   \n",
              "1  2D Interior Area             None        02   \n",
              "2  2D Interior Area             None        04   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize both projects with their own RAS objects\n",
        "bald_eagle_ras = RasPrj()\n",
        "init_ras_project(bald_eagle_path, \"6.6\", ras_object=bald_eagle_ras)\n",
        "print(f\"Initialized Bald Eagle Creek project: {bald_eagle_ras.project_name}\")\n",
        "\n",
        "muncie_ras = RasPrj()\n",
        "init_ras_project(muncie_path, \"6.6\", ras_object=muncie_ras)\n",
        "print(f\"Initialized Muncie project: {muncie_ras.project_name}\")\n",
        "\n",
        "# Display available plans in each project\n",
        "print(\"\\nAvailable plans in Bald Eagle Creek project:\")\n",
        "display.display(bald_eagle_ras.plan_df)\n",
        "\n",
        "print(\"\\nAvailable plans in Muncie project:\")\n",
        "display.display(muncie_ras.plan_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Plans in Each Project\n",
        "\n",
        "Now, let's clone a plan in each project, giving them custom short identifiers. This demonstrates how to perform operations on multiple projects independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.234840Z",
          "iopub.status.busy": "2025-11-17T18:31:43.234602Z",
          "iopub.status.idle": "2025-11-17T18:31:43.382563Z",
          "shell.execute_reply": "2025-11-17T18:31:43.381320Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p01 to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Project file updated with new Plan entry: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01 to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created new plan 03 in Bald Eagle Creek project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Project file updated with new Plan entry: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created new plan 02 in Muncie project\n",
            "\n",
            "Updated plans in Bald Eagle Creek project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>UNET D2 Cores</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>0.0</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>03</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>MultiProjDemo</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>0.0</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "2          03              02              01  Unsteady with Bridges and Dam   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "2            5.00    MultiProjDemo    18FEB1999,0000,24FEB1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... UNET D2 Cores PS Cores  \\\n",
              "0                 2MIN            1HOUR        1  ...           0.0     None   \n",
              "1                 2MIN              NaN        1  ...           NaN     None   \n",
              "2                 2MIN            1HOUR        1  ...           0.0     None   \n",
              "\n",
              "  DSS File Friction Slope Method HDF_Results_Path  Geom File  Geom Path  \\\n",
              "0      dss                     2             None         01       None   \n",
              "1      dss                     1             None         01       None   \n",
              "2      dss                     2             None         01       None   \n",
              "\n",
              "  Flow File Flow Path                                          full_path  \n",
              "0        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "1        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "2        02      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "\n",
              "[3 rows x 26 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updated plans in Muncie project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>9-SAs</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady Run with 2D 50ft Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>-1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>01</td>\\n', '      <td>04</td>\\n', '      <td>Unsteady Run with 2D 50ft User n Value R</td>\\n', '      <td>5.10</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>04</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>MultiProjDemo</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number  \\\n",
              "0          01              01              01   \n",
              "1          03              01              02   \n",
              "2          04              01              04   \n",
              "3          02              01              01   \n",
              "\n",
              "                                 Plan Title Program Version  \\\n",
              "0                  Unsteady Multi  9-SA run            5.00   \n",
              "1            Unsteady Run with 2D 50ft Grid            5.10   \n",
              "2  Unsteady Run with 2D 50ft User n Value R            5.10   \n",
              "3                  Unsteady Multi  9-SA run            5.00   \n",
              "\n",
              "      Short Identifier                Simulation Date Computation Interval  \\\n",
              "0                9-SAs  02JAN1900,0000,02JAN1900,2400                15SEC   \n",
              "1         2D 50ft Grid  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "2  50ft User n Regions  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "3        MultiProjDemo  02JAN1900,0000,02JAN1900,2400                15SEC   \n",
              "\n",
              "  Mapping Interval Run HTab  ... DSS File Friction Slope Method  \\\n",
              "0             5MIN        1  ...      dss                     1   \n",
              "1             5MIN       -1  ...      dss                     1   \n",
              "2             5MIN        1  ...      dss                     1   \n",
              "3             5MIN        1  ...      dss                     1   \n",
              "\n",
              "  UNET D2 SolverType      UNET D2 Name HDF_Results_Path Geom File  Geom Path  \\\n",
              "0                NaN               NaN             None        01       None   \n",
              "1   Pardiso (Direct)  2D Interior Area             None        02       None   \n",
              "2   Pardiso (Direct)  2D Interior Area             None        04       None   \n",
              "3                NaN               NaN             None        01       None   \n",
              "\n",
              "   Flow File Flow Path                                          full_path  \n",
              "0         01      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "1         01      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "2         01      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "3         01      None  C:\\GH\\ras-commander\\examples\\example_projects\\...  \n",
              "\n",
              "[4 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Clone plans with custom short identifiers\n",
        "new_bald_eagle_plan = RasPlan.clone_plan(\"01\", new_plan_shortid=\"MultiProjDemo\", ras_object=bald_eagle_ras)\n",
        "print(f\"Created new plan {new_bald_eagle_plan} in Bald Eagle Creek project\")\n",
        "\n",
        "new_muncie_plan = RasPlan.clone_plan(\"01\", new_plan_shortid=\"MultiProjDemo\", ras_object=muncie_ras)\n",
        "print(f\"Created new plan {new_muncie_plan} in Muncie project\")\n",
        "\n",
        "# Display the updated plan dataframes\n",
        "print(\"\\nUpdated plans in Bald Eagle Creek project:\")\n",
        "bald_eagle_ras.plan_df = bald_eagle_ras.get_plan_entries()  # Refresh the plan dataframe\n",
        "display.display(bald_eagle_ras.plan_df)\n",
        "\n",
        "print(\"\\nUpdated plans in Muncie project:\")\n",
        "muncie_ras.plan_df = muncie_ras.get_plan_entries()  # Refresh the plan dataframe\n",
        "display.display(muncie_ras.plan_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Configure Plans for Both Projects\n",
        "\n",
        "Let's configure the plans for both projects, setting geometry, number of cores, and other parameters. This demonstrates how to customize plans for different projects using the same code structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.385327Z",
          "iopub.status.busy": "2025-11-17T18:31:43.385074Z",
          "iopub.status.idle": "2025-11-17T18:31:43.523213Z",
          "shell.execute_reply": "2025-11-17T18:31:43.522757Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Updated Geom File in plan file to g01 for plan 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Geometry for plan 03 set to 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Constructed plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring Bald Eagle Creek plan:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Successfully updated intervals in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Updated Geom File in plan file to g01 for plan 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Geometry for plan 02 set to 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Constructed plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully configured Bald Eagle Creek plan\n",
            "\n",
            "Configuring Muncie plan:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasPlan - INFO - Successfully updated intervals in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully configured Muncie plan\n"
          ]
        }
      ],
      "source": [
        "# Configure the Bald Eagle Creek plan\n",
        "print(\"Configuring Bald Eagle Creek plan:\")\n",
        "RasPlan.set_geom(new_bald_eagle_plan, \"01\", ras_object=bald_eagle_ras)\n",
        "RasPlan.set_num_cores(new_bald_eagle_plan, 2, ras_object=bald_eagle_ras)\n",
        "\n",
        "# Update description and intervals\n",
        "description = \"Multi-project demonstration plan\\nBald Eagle Creek project\\nConfigured for parallel execution\"\n",
        "RasPlan.update_plan_description(new_bald_eagle_plan, description, ras_object=bald_eagle_ras)\n",
        "RasPlan.update_plan_intervals(\n",
        "    new_bald_eagle_plan, \n",
        "    computation_interval=\"10SEC\", \n",
        "    output_interval=\"5MIN\", \n",
        "    ras_object=bald_eagle_ras\n",
        ")\n",
        "print(\"Successfully configured Bald Eagle Creek plan\")\n",
        "\n",
        "# Configure the Muncie plan\n",
        "print(\"\\nConfiguring Muncie plan:\")\n",
        "RasPlan.set_geom(new_muncie_plan, \"01\", ras_object=muncie_ras)\n",
        "RasPlan.set_num_cores(new_muncie_plan, 2, ras_object=muncie_ras)\n",
        "\n",
        "# Update description and intervals\n",
        "description = \"Multi-project demonstration plan\\nMuncie project\\nConfigured for parallel execution\"\n",
        "RasPlan.update_plan_description(new_muncie_plan, description, ras_object=muncie_ras)\n",
        "RasPlan.update_plan_intervals(\n",
        "    new_muncie_plan, \n",
        "    computation_interval=\"10SEC\", \n",
        "    output_interval=\"5MIN\", \n",
        "    ras_object=muncie_ras\n",
        ")\n",
        "print(\"Successfully configured Muncie plan\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Compute Folders for Both Projects\n",
        "\n",
        "Now, let's create separate compute folders for each project. This allows us to run the computations separately and in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.525285Z",
          "iopub.status.busy": "2025-11-17T18:31:43.524871Z",
          "iopub.status.idle": "2025-11-17T18:31:43.528757Z",
          "shell.execute_reply": "2025-11-17T18:31:43.528352Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\n",
            "Created compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\n"
          ]
        }
      ],
      "source": [
        "# Create compute folders or clean them if they already exist\n",
        "for folder in [bald_eagle_compute_folder, muncie_compute_folder]:\n",
        "    if folder.exists():\n",
        "        shutil.rmtree(folder)\n",
        "        print(f\"Removed existing compute folder: {folder}\")\n",
        "    folder.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created compute folder: {folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Define Project Execution Function\n",
        "\n",
        "Let's define a function to execute plans for each project, which we can run in parallel. This function will handle plan execution, timing, and provide detailed status updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.530767Z",
          "iopub.status.busy": "2025-11-17T18:31:43.530390Z",
          "iopub.status.idle": "2025-11-17T18:31:43.535269Z",
          "shell.execute_reply": "2025-11-17T18:31:43.534857Z"
        }
      },
      "outputs": [],
      "source": [
        "def execute_plan(plan_number, ras_object, compute_folder, project_name):\n",
        "    \"\"\"\n",
        "    Execute a HEC-RAS plan and return detailed information about the execution.\n",
        "    \n",
        "    Args:\n",
        "        plan_number (str): The plan number to execute\n",
        "        ras_object: The RAS project object\n",
        "        compute_folder (Path): Folder where computation will be performed\n",
        "        project_name (str): A descriptive name for the project\n",
        "        \n",
        "    Returns:\n",
        "        dict: Detailed information about the execution\n",
        "    \"\"\"\n",
        "    print(f\"Starting execution of plan {plan_number} for {project_name}...\")\n",
        "    \n",
        "    # Record start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Execute the plan in the compute folder\n",
        "    success = RasCmdr.compute_plan(\n",
        "        plan_number=plan_number, \n",
        "        ras_object=ras_object, \n",
        "        dest_folder=compute_folder,\n",
        "        clear_geompre=True\n",
        "    )\n",
        "    \n",
        "    # Record end time and calculate duration\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    \n",
        "    # Determine if results were created\n",
        "    result_path = None\n",
        "    result_size = None\n",
        "    \n",
        "    try:\n",
        "        # Initialize a temporary RAS object in the compute folder to check results\n",
        "        compute_ras = init_ras_project(compute_folder, ras_object.ras_exe_path)\n",
        "        result_path = RasPlan.get_results_path(plan_number, ras_object=compute_ras)\n",
        "        \n",
        "        if result_path:\n",
        "            result_file = Path(result_path)\n",
        "            if result_file.exists():\n",
        "                result_size = result_file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking results for {project_name}: {e}\")\n",
        "    \n",
        "    # Build result information\n",
        "    result_info = {\n",
        "        \"project_name\": project_name,\n",
        "        \"plan_number\": plan_number,\n",
        "        \"success\": success,\n",
        "        \"duration\": duration,\n",
        "        \"compute_folder\": str(compute_folder),\n",
        "        \"result_path\": str(result_path) if result_path else None,\n",
        "        \"result_size_mb\": result_size,\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "    \n",
        "    print(f\"Completed execution of plan {plan_number} for {project_name} in {duration:.2f} seconds\")\n",
        "    return result_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Execute Plans for Both Projects in Parallel\n",
        "\n",
        "Now, let's run both projects in parallel using a `ThreadPoolExecutor`. This allows us to utilize our system resources efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:31:43.537541Z",
          "iopub.status.busy": "2025-11-17T18:31:43.537226Z",
          "iopub.status.idle": "2025-11-17T18:33:41.527608Z",
          "shell.execute_reply": "2025-11-17T18:33:41.526984Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing plans for both projects in parallel...\n",
            "This may take several minutes...\n",
            "Starting execution of plan 03 for Bald Eagle Creek...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Copied project folder to destination: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting execution of plan 02 for Muncie...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.p03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.p03\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Copied project folder to destination: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:31:43 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.p02\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:32:03 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:32:03 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 20.20 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:32:03 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed execution of plan 02 for Muncie in 20.37 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:33:41 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:33:41 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 117.87 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:33:41 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_bald_eagle\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed execution of plan 03 for Bald Eagle Creek in 117.97 seconds\n",
            "\n",
            "All executions complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"Executing plans for both projects in parallel...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Define the execution tasks\n",
        "execution_tasks = [\n",
        "    (new_bald_eagle_plan, bald_eagle_ras, bald_eagle_compute_folder, \"Bald Eagle Creek\"),\n",
        "    (new_muncie_plan, muncie_ras, muncie_compute_folder, \"Muncie\")\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Execute the plans in parallel using ThreadPoolExecutor\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    futures = [\n",
        "        executor.submit(execute_plan, *task)\n",
        "        for task in execution_tasks\n",
        "    ]\n",
        "    \n",
        "    # Collect results as they complete\n",
        "    for future in as_completed(futures):\n",
        "        try:\n",
        "            result = future.result()\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Execution error: {e}\")\n",
        "\n",
        "print(\"\\nAll executions complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Analyze Results\n",
        "\n",
        "Let's analyze the results from both project executions, comparing execution times, result sizes, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:33:41.530062Z",
          "iopub.status.busy": "2025-11-17T18:33:41.529784Z",
          "iopub.status.idle": "2025-11-17T18:33:41.733112Z",
          "shell.execute_reply": "2025-11-17T18:33:41.732512Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution Results Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>project_name</th>\\n', '      <th>plan_number</th>\\n', '      <th>success</th>\\n', '      <th>duration</th>\\n', '      <th>result_size_mb</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>Muncie</td>\\n', '      <td>02</td>\\n', '      <td>True</td>\\n', '      <td>20.365752</td>\\n', '      <td>3.857758</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>Bald Eagle Creek</td>\\n', '      <td>03</td>\\n', '      <td>True</td>\\n', '      <td>117.969050</td>\\n', '      <td>11.529761</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "       project_name plan_number  success    duration  result_size_mb\n",
              "0            Muncie          02     True   20.365752        3.857758\n",
              "1  Bald Eagle Creek          03     True  117.969050       11.529761"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a DataFrame from the results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the results table\n",
        "print(\"Execution Results Summary:\")\n",
        "display.display(results_df[['project_name', 'plan_number', 'success', 'duration', 'result_size_mb']])\n",
        "\n",
        "# Create a bar chart for execution times\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['project_name'], results_df['duration'], color=['blue', 'green'])\n",
        "plt.title('Execution Time by Project')\n",
        "plt.xlabel('Muncie Plan 02 vs Bald Eagle Creek Plan 02\\n (2 separate projects, for demonstration purposes only)')\n",
        "plt.ylabel('Execution Time (seconds)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add duration values on top of the bars\n",
        "for i, duration in enumerate(results_df['duration']):\n",
        "    plt.text(i, duration + 5, f\"{duration:.1f}s\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# If we have result sizes, create a chart for those as well\n",
        "if results_df['result_size_mb'].notna().any():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(results_df['project_name'], results_df['result_size_mb'], color=['orange', 'purple'])\n",
        "    plt.title('Result File Size by Project')\n",
        "    plt.xlabel('Project')\n",
        "    plt.ylabel('Result Size (MB)')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    \n",
        "    # Add size values on top of the bars\n",
        "    for i, size in enumerate(results_df['result_size_mb']):\n",
        "        if pd.notna(size):\n",
        "            plt.text(i, size + 2, f\"{size:.1f} MB\", ha='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Compare Two HEC-RAS Projects\n",
        "\n",
        "Let's create a utility function to compare the structures of the two HEC-RAS projects. This helps us understand the differences between the projects we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:33:41.735705Z",
          "iopub.status.busy": "2025-11-17T18:33:41.735396Z",
          "iopub.status.idle": "2025-11-17T18:33:41.861620Z",
          "shell.execute_reply": "2025-11-17T18:33:41.861013Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Structure Comparison:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Project Name</th>\\n', '      <th>Plan Count</th>\\n', '      <th>Geometry Count</th>\\n', '      <th>Flow Count</th>\\n', '      <th>Unsteady Count</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>Bald Eagle Creek</th>\\n', '      <td>BaldEagle</td>\\n', '      <td>3</td>\\n', '      <td>1</td>\\n', '      <td>2</td>\\n', '      <td>1</td>\\n', '    </tr><tr>\\n', '      <th>Muncie</th>\\n', '      <td>Muncie</td>\\n', '      <td>4</td>\\n', '      <td>3</td>\\n', '      <td>1</td>\\n', '      <td>1</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "                 Project Name  Plan Count  Geometry Count  Flow Count  \\\n",
              "Bald Eagle Creek    BaldEagle           3               1           2   \n",
              "Muncie                 Muncie           4               3           1   \n",
              "\n",
              "                  Unsteady Count  \n",
              "Bald Eagle Creek               1  \n",
              "Muncie                         1  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def compare_project_structures(ras_object1, name1, ras_object2, name2):\n",
        "    \"\"\"\n",
        "    Compare the structures of two HEC-RAS projects and display differences.\n",
        "    \"\"\"\n",
        "    # Refresh all dataframes to ensure we have the latest data\n",
        "    ras_object1.plan_df = ras_object1.get_plan_entries()\n",
        "    ras_object1.geom_df = ras_object1.get_geom_entries()\n",
        "    ras_object1.flow_df = ras_object1.get_flow_entries()\n",
        "    ras_object1.unsteady_df = ras_object1.get_unsteady_entries()\n",
        "    \n",
        "    ras_object2.plan_df = ras_object2.get_plan_entries()\n",
        "    ras_object2.geom_df = ras_object2.get_geom_entries()\n",
        "    ras_object2.flow_df = ras_object2.get_flow_entries()\n",
        "    ras_object2.unsteady_df = ras_object2.get_unsteady_entries()\n",
        "    \n",
        "    # Create a comparison dictionary\n",
        "    comparison = {\n",
        "        'Project Name': [ras_object1.project_name, ras_object2.project_name],\n",
        "        'Plan Count': [len(ras_object1.plan_df), len(ras_object2.plan_df)],\n",
        "        'Geometry Count': [len(ras_object1.geom_df), len(ras_object2.geom_df)],\n",
        "        'Flow Count': [len(ras_object1.flow_df), len(ras_object2.flow_df)],\n",
        "        'Unsteady Count': [len(ras_object1.unsteady_df), len(ras_object2.unsteady_df)]\n",
        "    }\n",
        "    \n",
        "    # Create a DataFrame for the comparison\n",
        "    comparison_df = pd.DataFrame(comparison, index=[name1, name2])\n",
        "    \n",
        "\n",
        "    # Display the comparison\n",
        "    print(\"Project Structure Comparison:\")\n",
        "    display.display(comparison_df)\n",
        "    \n",
        "    # Create a bar chart to visualize the comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    comparison_df.iloc[:, 1:].plot(kind='bar', ax=plt.gca())\n",
        "    plt.title('Project Structure Comparison')\n",
        "    plt.xlabel('Project')\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend(title='Component')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    \n",
        "    # Set y-axis to only show whole numbers (integers)\n",
        "    ax = plt.gca()\n",
        "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return comparison_df\n",
        "\n",
        "# Compare the structures of the two projects\n",
        "comparison_df = compare_project_structures(\n",
        "    bald_eagle_ras, \"Bald Eagle Creek\", \n",
        "    muncie_ras, \"Muncie\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## This approach can also be used to programmatically compare 2 copies of the same project to ensure all of the plan parameters, boundary condition definitions, etc remained the same, and for other QAQC processes.\n",
        "\n",
        "This will be shown in further examples in more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Multiple Project Operations\n",
        "\n",
        "In this notebook, we've demonstrated how to work with multiple HEC-RAS projects simultaneously using the RAS Commander library. We've covered the following key operations:\n",
        "\n",
        "1. **Initializing Multiple Projects**: Creating separate RAS objects for different projects\n",
        "2. **Independent Configuration**: Configuring plans with project-specific parameters\n",
        "3. **Parallel Execution**: Running computations from different projects simultaneously\n",
        "4. **Resource Management**: Organizing compute folders and tracking execution statistics\n",
        "5. **Results Comparison**: Analyzing and comparing results from different projects\n",
        "6. **Advanced Workflows**: Creating sensitivity plans and batch processing pipelines\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "When working with multiple HEC-RAS projects in RAS Commander, remember these key concepts:\n",
        "\n",
        "- **Custom RAS Objects**: Create and use separate RAS objects for each project\n",
        "- **Always Specify ras_object**: Use the `ras_object` parameter in all function calls\n",
        "- **Separate Compute Folders**: Use separate folders for each project's computations\n",
        "- **Resource Management**: Be mindful of CPU and memory usage when running in parallel\n",
        "- **Project Tracking**: Keep track of which results belong to which project\n",
        "\n",
        "### Multiple Project Applications\n",
        "\n",
        "Working with multiple projects unlocks advanced applications such as:\n",
        "\n",
        "1. **Model Comparison**: Compare results from different river systems\n",
        "2. **Basin-wide Analysis**: Analyze connected river systems in parallel\n",
        "3. **Parameter Sweep**: Test a range of parameters across multiple models\n",
        "4. **Model Development**: Develop and test models simultaneously\n",
        "5. **Batch Processing**: Process large sets of models in an automated pipeline\n",
        "\n",
        "These capabilities make RAS Commander a powerful tool for large-scale hydraulic modeling and water resources management."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\05_single_plan_execution.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up Our Working Environment\n",
        "\n",
        "Let's set up our working directory and paths to example projects. We'll also check the number of available CPU cores on this system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n",
            "2025-12-02 16:52:37 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to c:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted project to: c:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "Bald Eagle Creek project exists: True\n"
          ]
        }
      ],
      "source": [
        "# Extract the Bald Eagle Creek example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(f\"Extracted project to: {bald_eagle_path}\")  \n",
        "\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System has 8 physical CPU cores (8 logical cores)\n",
            "For HEC-RAS computation, it's often most efficient to use 2-8 cores\n"
          ]
        }
      ],
      "source": [
        "# Define paths to example projects\n",
        "examples_dir = bald_eagle_path.parent\n",
        "\n",
        "# Define computation output paths\n",
        "compute_dest_folder = examples_dir / \"compute_test\"\n",
        "\n",
        "# Check system resources\n",
        "cpu_count = psutil.cpu_count(logical=True)\n",
        "physical_cpu_count = psutil.cpu_count(logical=False)\n",
        "print(f\"System has {physical_cpu_count} physical CPU cores ({cpu_count} logical cores)\")\n",
        "print(f\"For HEC-RAS computation, it's often most efficient to use 2-8 cores\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the RasCmdr.compute_plan Method\n",
        "\n",
        "Before we dive into execution, let's understand the `compute_plan` method from the `RasCmdr` class, which is the core function for running HEC-RAS simulations.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number` (str, Path): The plan number to execute or the full path to the plan file\n",
        "- `dest_folder` (str, Path, optional): Destination folder for computation\n",
        "- `ras_object` (RasPrj, optional): Specific RAS object to use (defaults to global `ras`)\n",
        "- `clear_geompre` (bool, optional): Whether to clear geometry preprocessor files (default: False)\n",
        "- `num_cores` (int, optional): Number of processor cores to use (default: None, uses plan settings)\n",
        "- `overwrite_dest` (bool, optional): Whether to overwrite the destination folder if it exists (default: False)\n",
        "\n",
        "### Returns\n",
        "- `bool`: True if the execution was successful, False otherwise\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Destination Folder**: By default, the simulation runs in the original project folder. Specifying a destination folder creates a copy of the project in that location for execution, leaving the original project untouched.\n",
        "\n",
        "2. **Number of Cores**: HEC-RAS can use multiple processor cores to speed up computation. The optimal number depends on the model complexity and your computer's specifications. Generally:\n",
        "   - 1-2 cores: Good for small models, highest efficiency per core\n",
        "   - 3-8 cores: Good balance for most models\n",
        "   - >8 cores: Diminishing returns, may actually be slower due to overhead\n",
        "\n",
        "3. **Geometry Preprocessor Files**: These files store precomputed hydraulic properties. Clearing them forces HEC-RAS to recompute these properties, which is useful after making geometry changes.\n",
        "\n",
        "4. **Overwrite Destination**: Controls whether an existing destination folder should be overwritten. This is a safety feature to prevent accidental deletion of important results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "Let's initialize the HEC-RAS project using the `init_ras_project()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:52:37 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized HEC-RAS project: BaldEagle\n"
          ]
        }
      ],
      "source": [
        "# Initialize the HEC-RAS project\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Explore Available Plans\n",
        "\n",
        "Let's examine the available plans in the project to understand what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available plans in the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "0                 2MIN            1HOUR        1  ...     None      dss   \n",
              "1                 2MIN              NaN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method HDF_Results_Path Geom File  \\\n",
              "0                     2             None        01   \n",
              "1                     1             None        01   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...    Steady  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:52:37 - ras_commander.RasPlan - ERROR - Key 'PS Cores' not found in the plan file.\n",
            "2025-12-02 16:52:37 - ras_commander.RasPlan - ERROR - Key 'UNET D1 Cores' not found in the plan file.\n",
            "2025-12-02 16:52:37 - ras_commander.RasPlan - ERROR - Key 'UNET D2 Cores' not found in the plan file.\n",
            "2025-12-02 16:52:37 - ras_commander.RasPlan - ERROR - Key 'PS Cores' not found in the plan file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current core settings for plans:\n",
            "Plan 01's Existing Settings:\n",
            "  1D Cores: 0\n",
            "  2D Cores: 0\n",
            "  Pump Station Cores: None\n",
            "Plan 02's Existing Settings:\n",
            "  1D Cores: None\n",
            "  2D Cores: None\n",
            "  Pump Station Cores: None\n"
          ]
        }
      ],
      "source": [
        "# Display the available plans in the project\n",
        "print(\"Available plans in the project:\")\n",
        "display.display(ras.plan_df)\n",
        "\n",
        "# Let's check the current setting for number of cores in the plans\n",
        "print(\"\\nCurrent core settings for plans:\")\n",
        "for plan_num in ras.plan_df['plan_number']:\n",
        "    # Check all three core parameters\n",
        "    d1_cores = RasPlan.get_plan_value(plan_num, \"UNET D1 Cores\")\n",
        "    d2_cores = RasPlan.get_plan_value(plan_num, \"UNET D2 Cores\") \n",
        "    ps_cores = RasPlan.get_plan_value(plan_num, \"PS Cores\")\n",
        "    \n",
        "    print(f\"Plan {plan_num}'s Existing Settings:\")\n",
        "    print(f\"  1D Cores: {d1_cores}\")\n",
        "    print(f\"  2D Cores: {d2_cores}\")\n",
        "    print(f\"  Pump Station Cores: {ps_cores}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create a Destination Folder Structure\n",
        "\n",
        "Now, let's prepare a destination folder for our computation. This allows us to run simulations without modifying the original project files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Destination folder will be created: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\n"
          ]
        }
      ],
      "source": [
        "# Create a destination folder path\n",
        "dest_folder = examples_dir / \"compute_test_cores\"\n",
        "\n",
        "# Check if the destination folder already exists\n",
        "if dest_folder.exists():\n",
        "    print(f\"Destination folder already exists: {dest_folder}\")\n",
        "    print(\"We'll use overwrite_dest=True to replace it\")\n",
        "else:\n",
        "    print(f\"Destination folder will be created: {dest_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Execute a Plan with a Specified Number of Cores\n",
        "\n",
        "Now we're ready to execute a plan with a specified number of cores, overwriting the destination folder if it exists. This is the core functionality demonstrated in Example 5 of the original script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:52:37 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "2025-12-02 16:52:37 - ras_commander.RasCmdr - INFO - Copied project folder to destination: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\n",
            "2025-12-02 16:52:37 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.rasmap\n",
            "2025-12-02 16:52:37 - ras_commander.RasUtils - INFO - Using provided plan file path: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.p01\n",
            "2025-12-02 16:52:37 - ras_commander.RasUtils - INFO - Successfully updated file: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.p01\n",
            "2025-12-02 16:52:37 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 01\n",
            "2025-12-02 16:52:37 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 16:52:37 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.prj\" \"c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.p01\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing plan 01 with 2 cores...\n",
            "Destination folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:54:09 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 16:54:09 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 91.70 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Plan 01 executed successfully using 2 cores\n",
            "Execution time: 91.79 seconds\n"
          ]
        }
      ],
      "source": [
        "# Select a plan and number of cores\n",
        "plan_number = \"01\"\n",
        "num_cores = 2  # Specify the number of cores to use\n",
        "\n",
        "print(f\"Executing plan {plan_number} with {num_cores} cores...\")\n",
        "print(f\"Destination folder: {dest_folder}\")\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute the plan with specified parameters\n",
        "success = RasCmdr.compute_plan(\n",
        "    plan_number,              # The plan to execute\n",
        "    dest_folder=dest_folder,  # Where to run the simulation\n",
        "    num_cores=num_cores,      # Number of processor cores to use\n",
        "    overwrite_dest=True       # Overwrite destination folder if it exists\n",
        ")\n",
        "\n",
        "# Record the end time and calculate duration\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "# Report results\n",
        "if success:\n",
        "    print(f\"\u2705 Plan {plan_number} executed successfully using {num_cores} cores\")\n",
        "    print(f\"Execution time: {duration:.2f} seconds\")\n",
        "else:\n",
        "    print(f\"\u274c Plan {plan_number} execution failed\")\n",
        "    print(f\"Time elapsed: {duration:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify Results\n",
        "\n",
        "After execution, let's verify the results by checking the results paths and examining the destination folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Destination folder exists: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\n",
            "\n",
            "Key files in destination folder:\n",
            "  BaldEagle.b01: 9.3 KB\n",
            "  BaldEagle.bco01: 2.2 KB\n",
            "  BaldEagle.c01: 522.1 KB\n",
            "  BaldEagle.dss: 3601.5 KB\n",
            "  BaldEagle.f01: 1209.0 KB\n",
            "  BaldEagle.f02: 1.5 KB\n",
            "  BaldEagle.g01: 513.6 KB\n",
            "  BaldEagle.g01.gmz: 372.6 KB\n",
            "  BaldEagle.g01.hdf: 3920.5 KB\n",
            "  BaldEagle.gis: 127.8 KB\n",
            "  ... and 13 more files\n",
            "\n",
            "HDF result files:\n",
            "  BaldEagle.g01.hdf: 3.8 MB\n",
            "  BaldEagle.p01.hdf: 7.4 MB\n",
            "  BaldEagle.u02.hdf: 0.0 MB\n"
          ]
        }
      ],
      "source": [
        "# Verify that the destination folder exists and contains the expected files\n",
        "if dest_folder.exists():\n",
        "    print(f\"Destination folder exists: {dest_folder}\")\n",
        "    \n",
        "    # List the key files in the destination folder\n",
        "    print(\"\\nKey files in destination folder:\")\n",
        "    project_files = list(dest_folder.glob(f\"{ras.project_name}.*\"))\n",
        "    for file in project_files[:10]:  # Show first 10 files\n",
        "        file_size = file.stat().st_size / 1024  # Size in KB\n",
        "        print(f\"  {file.name}: {file_size:.1f} KB\")\n",
        "    \n",
        "    if len(project_files) > 10:\n",
        "        print(f\"  ... and {len(project_files) - 10} more files\")\n",
        "    \n",
        "    # Check for HDF result files\n",
        "    print(\"\\nHDF result files:\")\n",
        "    hdf_files = list(dest_folder.glob(f\"*.hdf\"))\n",
        "    for file in hdf_files:\n",
        "        file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "        print(f\"  {file.name}: {file_size:.1f} MB\")\n",
        "else:\n",
        "    print(f\"Destination folder does not exist: {dest_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - No HEC-RAS Version Specified.Attempting to detect HEC-RAS version from plan files.\n",
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - Searching for plan files in C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\n",
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - Found plan file: BaldEagle.p01\n",
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - Successfully read plan file with utf-8 encoding\n",
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - Found Program Version=5.00 in BaldEagle.p01\n",
            "2025-12-02 16:54:09 - ras_commander.RasPrj - INFO - Checking RAS executable path: C:\\Program Files (x86)\\HEC\\HEC-RAS\\5.0\\Ras.exe\n",
            "2025-12-02 16:54:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.rasmap\n"
          ]
        },
        {
          "data": {
            "text/plain": "['<ras_commander.RasPrj.RasPrj at 0x240d845de80>']"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Since we are now working in the dest_folder, init_ras_project in that folder \n",
        "\n",
        "init_ras_project(dest_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Extract Computation Messages\n",
        "\n",
        "After successful plan execution, we can extract detailed computation messages that provide insights into:\n",
        "- Computation time and performance metrics\n",
        "- Warning messages and errors (if any)\n",
        "- Convergence information\n",
        "- Process timing breakdown\n",
        "\n",
        "The `HdfResultsPlan.get_compute_messages()` function automatically extracts messages from the HDF file, with fallback to .txt files for older HEC-RAS versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:57:29 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.p01.hdf\n",
            "2025-12-02 16:57:29 - ras_commander.hdf.HdfResultsPlan - INFO - Reading computation messages from HDF: BaldEagle.p01.hdf\n",
            "2025-12-02 16:57:29 - ras_commander.hdf.HdfResultsPlan - INFO - Successfully extracted 1693 characters from HDF\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXTRACTING COMPUTATION MESSAGES\n",
            "================================================================================\n",
            "\n",
            "Successfully extracted computation messages (1693 characters)\n",
            "\n",
            "First 1000 characters of computation messages:\n",
            "--------------------------------------------------------------------------------\n",
            "Plan: 'Unsteady with Bridges and Dam' (BaldEagle.p01)\n",
            "Simulation started at: 02Dec2025 04:52:39 PM\n",
            "\n",
            "Writing Plan GIS Data...\n",
            "Completed Writing Plan GIS Data\n",
            "Writing Geometry...\n",
            "Computing Bank Lines\n",
            "Bank lines generated in 108 ms\n",
            "Computing Edge Lines\n",
            "Edge Lines generated in 48 ms\n",
            "Computing XS Interpolation Surface\n",
            "XS Interpolation Surface generated in 115 ms\n",
            "Completed Writing Geometry\n",
            "Writing Event Conditions ...\n",
            "Completed Writing Event Condition Data\n",
            "\n",
            "\t\n",
            "Geometric Preprocessor HEC-RAS 6.6 September 2024\n",
            " \n",
            "\n",
            "Finished Processing Geometry\n",
            "\n",
            "\n",
            "Performing Unsteady Flow Simulation  HEC-RAS 6.6 September 2024\n",
            " \n",
            "\t\n",
            "Unsteady Input Summary:\n",
            "     1D Unsteady Finite Difference Numerical Solution\n",
            "\n",
            "Overall Volume Accounting Error in Acre Feet:    -29.5468461514\n",
            "Overall Volume Accounting Error as percentage:           0.01407\n",
            "Please review \"Computational Log File\" output for volume accounting details\n",
            "\n",
            "Writing Results to DSS\n",
            "\n",
            "Finished Unsteady Flow Simulation\n",
            "\n",
            "Reading U\n",
            "\n",
            "... (message truncated for display) ...\n",
            "\n",
            "Total message length: 1693 characters\n",
            "\n",
            "================================================================================\n",
            "CHECKING FOR WARNINGS/ERRORS\n",
            "================================================================================\n",
            "Found 2 warning/error messages:\n",
            "  - Overall Volume Accounting Error in Acre Feet:    -29.5468461514\n",
            "  - Overall Volume Accounting Error as percentage:           0.01407\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Extract and display computation messages\n",
        "from ras_commander import HdfResultsPlan\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXTRACTING COMPUTATION MESSAGES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Extract messages using plan number\n",
        "compute_msgs = HdfResultsPlan.get_compute_messages(plan_number)\n",
        "\n",
        "if compute_msgs:\n",
        "    print(f\"\\nSuccessfully extracted computation messages ({len(compute_msgs)} characters)\\n\")\n",
        "    \n",
        "    # Display first 1000 characters\n",
        "    print(\"First 1000 characters of computation messages:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(compute_msgs[:1000])\n",
        "    \n",
        "    if len(compute_msgs) > 1000:\n",
        "        print(\"\\n... (message truncated for display) ...\")\n",
        "        print(f\"\\nTotal message length: {len(compute_msgs)} characters\")\n",
        "    \n",
        "    # Check for warnings or errors\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CHECKING FOR WARNINGS/ERRORS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    lines = compute_msgs.split('\\n')\n",
        "    warnings_errors = [line for line in lines if 'warning' in line.lower() or 'error' in line.lower()]\n",
        "    \n",
        "    if warnings_errors:\n",
        "        print(f\"Found {len(warnings_errors)} warning/error messages:\")\n",
        "        for msg in warnings_errors[:10]:  # Show first 10\n",
        "            print(f\"  - {msg.strip()}\")\n",
        "    else:\n",
        "        print(\"\u2713 No warnings or errors found in computation messages\")\n",
        "else:\n",
        "    print(\"\u26a0 No computation messages available\")\n",
        "    print(\"This may indicate the plan was not computed or messages are not available.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:57:29 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.rasmap\n",
            "2025-12-02 16:57:29 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for plan 01 are located at: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_cores\\BaldEagle.p01.hdf\n",
            "Results file size: 7.41 MB\n"
          ]
        }
      ],
      "source": [
        "# Check the results path using the RasPlan.get_results_path method\n",
        "# First, initialize a RAS object using the destination folder\n",
        "try:\n",
        "    dest_ras = RasPrj()\n",
        "    init_ras_project(dest_folder, \"6.6\", ras_object=dest_ras)\n",
        "    \n",
        "    # Get the results path for the plan we just executed\n",
        "    results_path = RasPlan.get_results_path(plan_number, ras_object=dest_ras)\n",
        "    \n",
        "    if results_path:\n",
        "        print(f\"Results for plan {plan_number} are located at: {results_path}\")\n",
        "        \n",
        "        # Check if the file exists and get its size\n",
        "        results_file = Path(results_path)\n",
        "        if results_file.exists():\n",
        "            size_mb = results_file.stat().st_size / (1024 * 1024)\n",
        "            print(f\"Results file size: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"No results found for plan {plan_number} in the destination folder\")\n",
        "except Exception as e:\n",
        "    print(f\"Error checking results: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Single Plan Execution Options\n",
        "\n",
        "The `RasCmdr.compute_plan()` method provides a flexible way to execute HEC-RAS plans with various options. Here's a summary of the key parameters we've explored:\n",
        "\n",
        "1. **Basic Execution**: Simply provide a plan number\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\"01\")\n",
        "   ```\n",
        "\n",
        "2. **Destination Folder**: Run in a separate folder to preserve the original project\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\"01\", dest_folder=\"path/to/folder\")\n",
        "   ```\n",
        "\n",
        "3. **Number of Cores**: Control the CPU resources used\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\"01\", num_cores=2)\n",
        "   ```\n",
        "\n",
        "4. **Overwrite Destination**: Replace existing computation folders\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\"01\", dest_folder=\"path/to/folder\", overwrite_dest=True)\n",
        "   ```\n",
        "\n",
        "5. **Clear Geometry Preprocessor**: Force recalculation of geometric properties\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\"01\", clear_geompre=True)\n",
        "   ```\n",
        "\n",
        "6. **Combined Options**: Use multiple options together\n",
        "   ```python\n",
        "   RasCmdr.compute_plan(\n",
        "       \"01\",\n",
        "       dest_folder=\"path/to/folder\",\n",
        "       num_cores=2,\n",
        "       clear_geompre=True,\n",
        "       overwrite_dest=True\n",
        "   )\n",
        "   ```\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "To further enhance your HEC-RAS automation, consider exploring:\n",
        "\n",
        "1. **Parallel Execution**: Use `RasCmdr.compute_parallel()` to run multiple plans simultaneously\n",
        "2. **Test Mode**: Use `RasCmdr.compute_test_mode()` for testing purposes\n",
        "3. **Pre-Processing**: Modify plans, geometries, and unsteady flows before execution\n",
        "4. **Post-Processing**: Analyze results after computation\n",
        "5. **Batch Processing**: Create scripts for parameter sweeps or scenario analysis\n",
        "\n",
        "These advanced topics are covered in other examples and documentation for the RAS Commander library."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\06_executing_plan_sets.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:35:59.294958Z",
          "iopub.status.busy": "2025-11-17T18:35:59.294779Z",
          "iopub.status.idle": "2025-11-17T18:36:01.297343Z",
          "shell.execute_reply": "2025-11-17T18:36:01.296746Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:36:01.300789Z",
          "iopub.status.busy": "2025-11-17T18:36:01.300420Z",
          "iopub.status.idle": "2025-11-17T18:36:01.304106Z",
          "shell.execute_reply": "2025-11-17T18:36:01.303566Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:36:01.306444Z",
          "iopub.status.busy": "2025-11-17T18:36:01.306179Z",
          "iopub.status.idle": "2025-11-17T18:36:01.368873Z",
          "shell.execute_reply": "2025-11-17T18:36:01.368280Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n",
            "2025-12-02 16:58:18 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to c:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted project to: c:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "Bald Eagle Creek project exists: True\n"
          ]
        }
      ],
      "source": [
        "# Extract the Bald Eagle Creek example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(f\"Extracted project to: {bald_eagle_path}\")  \n",
        "\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Plan Specification in HEC-RAS\n",
        "\n",
        "In HEC-RAS, each plan (`.p*` file) represents a specific hydraulic model simulation scenario. When working with RAS Commander, you can specify plans for execution in several ways:\n",
        "\n",
        "1. **Single Plan**: Specify one plan by its number (e.g., \"01\")\n",
        "2. **List of Plans**: Specify multiple plans as a list (e.g., [\"01\", \"03\", \"05\"])\n",
        "3. **All Plans**: Execute all plans in a project by not specifying any plan or passing `None`\n",
        "4. **Filtered Plans**: Select plans based on criteria (e.g., plans with specific flow conditions)\n",
        "5. **Plan Path**: Specify the full path to a plan file instead of just the number\n",
        "\n",
        "### Why Plan Specification Matters\n",
        "\n",
        "- **Efficiency**: Run only the plans you need rather than recomputing everything\n",
        "- **Organization**: Group related plans for batch processing\n",
        "- **Automation**: Create workflows that process plans in a specific order\n",
        "- **Resource Management**: Optimize hardware utilization for specific plans\n",
        "\n",
        "### Best Practices for Plan Specification\n",
        "\n",
        "- Use consistent formatting for plan numbers (e.g., always use two-digit strings like \"01\" instead of 1)\n",
        "- Check available plans before attempting to execute them\n",
        "- Organize plans by purpose to make selection easier\n",
        "- Use descriptive short identifiers and plan titles to aid in selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "Let's initialize the HEC-RAS project using the `init_ras_project()` function and explore the available plans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:36:01.371640Z",
          "iopub.status.busy": "2025-11-17T18:36:01.371351Z",
          "iopub.status.idle": "2025-11-17T18:36:01.442763Z",
          "shell.execute_reply": "2025-11-17T18:36:01.442231Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:58:18 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized HEC-RAS project: BaldEagle\n",
            "\n",
            "Available plans in the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "0                 2MIN            1HOUR        1  ...     None      dss   \n",
              "1                 2MIN              NaN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method HDF_Results_Path Geom File  \\\n",
              "0                     2             None        01   \n",
              "1                     1             None        01   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...    Steady  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:58:18 - ras_commander.RasPlan - WARNING - No description found in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p01\n",
            "2025-12-02 16:58:18 - ras_commander.RasPlan - WARNING - No description found in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Plan details:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan Number</th>\\n', '      <th>Short ID</th>\\n', '      <th>Description</th>\\n', '      <th>Geometry</th>\\n', '      <th>Has Results</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td></td>\\n', '      <td>01</td>\\n', '      <td>False</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>SteadyRun</td>\\n', '      <td></td>\\n', '      <td>01</td>\\n', '      <td>False</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan Number      Short ID Description Geometry  Has Results\n",
              "0          01  UnsteadyFlow                   01        False\n",
              "1          02     SteadyRun                   01        False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize the HEC-RAS project\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "\n",
        "# Display the current plan files in the project\n",
        "print(\"\\nAvailable plans in the project:\")\n",
        "display.display(ras.plan_df)\n",
        "\n",
        "# Check plan details to understand what each plan represents\n",
        "plan_details = []\n",
        "for index, row in ras.plan_df.iterrows():\n",
        "    plan_number = row['plan_number']\n",
        "    \n",
        "    # Get plan description if available\n",
        "    description = None\n",
        "    if 'description' in row:\n",
        "        description = row['description']\n",
        "    else:\n",
        "        try:\n",
        "            description = RasPlan.read_plan_description(plan_number)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    # Get short identifier if available\n",
        "    short_id = None\n",
        "    if 'Short Identifier' in row:\n",
        "        short_id = row['Short Identifier']\n",
        "    \n",
        "    # Get geometry file\n",
        "    geom_file = None\n",
        "    if 'Geom File' in row:\n",
        "        geom_file = row['Geom File']\n",
        "    \n",
        "    # Check if the plan has results\n",
        "    has_results = False\n",
        "    if 'HDF_Results_Path' in row and row['HDF_Results_Path']:\n",
        "        has_results = True\n",
        "    \n",
        "    plan_details.append({\n",
        "        'Plan Number': plan_number,\n",
        "        'Short ID': short_id,\n",
        "        'Description': description[:50] + '...' if description and len(description) > 50 else description,\n",
        "        'Geometry': geom_file,\n",
        "        'Has Results': has_results\n",
        "    })\n",
        "\n",
        "# Create a DataFrame with the plan details\n",
        "plan_details_df = pd.DataFrame(plan_details)\n",
        "print(\"\\nPlan details:\")\n",
        "display.display(plan_details_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Sequential Execution of Specific Plans\n",
        "\n",
        "Let's execute specific plans in sequence using `RasCmdr.compute_test_mode()` with a list of plan numbers. This approach allows us to run only the plans we need, in the order we specify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:36:01.444992Z",
          "iopub.status.busy": "2025-11-17T18:36:01.444744Z",
          "iopub.status.idle": "2025-11-17T18:37:36.316125Z",
          "shell.execute_reply": "2025-11-17T18:37:36.315673Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Starting the compute_test_mode...\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Creating the test folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]...\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Copied project folder to compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\n",
            "2025-12-02 16:58:18 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.rasmap\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Initialized RAS project in compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.prj\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Getting plan entries...\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Retrieved plan entries successfully.\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['01', '03']\n",
            "2025-12-02 16:58:18 - ras_commander.RasCmdr - INFO - Running selected plans sequentially...\n",
            "2025-12-02 16:58:19 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\n",
            "2025-12-02 16:58:19 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.p01\n",
            "2025-12-02 16:58:19 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.p01\n",
            "2025-12-02 16:58:19 - ras_commander.RasCmdr - INFO - Set number of cores to 6 for plan: 01\n",
            "2025-12-02 16:58:19 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 16:58:19 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\\BaldEagle.p01\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing specific plans sequentially...\n",
            "This may take several minutes...\n",
            "Selected plans: 01, 03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 89.69 seconds\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Successfully computed plan 01\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 89.71 seconds\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - All selected plans have been executed.\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - compute_test_mode completed.\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential execution of specific plans completed in 89.77 seconds\n",
            "\n",
            "Sequential Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '      <th>Execution Type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '      <td>Sequential</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success Execution Type\n",
              "0   01     True     Sequential"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing specific plans sequentially...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Define the plans to execute\n",
        "specific_plans = [\"01\", \"03\"]\n",
        "print(f\"Selected plans: {', '.join(specific_plans)}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute specific plans sequentially\n",
        "execution_results = RasCmdr.compute_test_mode(\n",
        "    plan_number=specific_plans,\n",
        "    dest_folder_suffix=\"[SpecificSequential]\",\n",
        "    num_cores=6, \n",
        "    overwrite_dest=True\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "sequential_duration = end_time - start_time\n",
        "\n",
        "print(f\"Sequential execution of specific plans completed in {sequential_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "sequential_results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success, \"Execution Type\": \"Sequential\"}\n",
        "    for plan, success in execution_results.items()\n",
        "])\n",
        "\n",
        "sequential_results_df \n",
        "\n",
        "# Ensure the 'Plan' column exists before sorting\n",
        "if 'Plan' in sequential_results_df.columns:\n",
        "    sequential_results_df = sequential_results_df.sort_values(\"Plan\")\n",
        "else:\n",
        "    print(\"Warning: 'Plan' column not found in execution results.\")\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nSequential Execution Results:\")\n",
        "display.display(sequential_results_df)\n",
        "\n",
        "# Check the test folder\n",
        "test_folder = bald_eagle_path.parent / f\"{ras.project_name} [SpecificSequential]\"\n",
        "if test_folder.exists():\n",
        "    print(f\"\\nTest folder exists: {test_folder}\")\n",
        "    \n",
        "    # Check for results\n",
        "    hdf_files = list(test_folder.glob(\"*.p*.hdf\"))\n",
        "    if hdf_files:\n",
        "        print(f\"Found {len(hdf_files)} HDF result files:\")\n",
        "        for file in hdf_files:\n",
        "            file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "            print(f\"  {file.name}: {file_size:.1f} MB\")\n",
        "    else:\n",
        "        print(\"No HDF result files found in the test folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Running Only Plans Without HDF Results\n",
        "An important use case is to identify and execute only those plans that have no existing HDF results. This approach can save time by avoiding redundant computations, especially useful when adding new plans to an existing project or after making limited changes.\n",
        "\n",
        "Let's demonstrate how to:\n",
        "\n",
        "- Use the `ras` object to identify plans without results\n",
        "- Create a filtered list of these plans\n",
        "- Execute only the missing plans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:37:36.317995Z",
          "iopub.status.busy": "2025-11-17T18:37:36.317784Z",
          "iopub.status.idle": "2025-11-17T18:39:14.693164Z",
          "shell.execute_reply": "2025-11-17T18:39:14.692565Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Starting the compute_test_mode...\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Creating the test folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]...\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Copied project folder to compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\n",
            "2025-12-02 16:59:48 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.rasmap\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Initialized RAS project in compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.prj\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Getting plan entries...\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Retrieved plan entries successfully.\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['01', '02']\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Running selected plans sequentially...\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\n",
            "2025-12-02 16:59:48 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p01\n",
            "2025-12-02 16:59:48 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p01\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Set number of cores to 6 for plan: 01\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 16:59:48 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p01\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identifying and executing plans without HDF results...\n",
            "Found 2 plans without HDF results: 01, 02\n",
            "\n",
            "Executing 2 plans without results...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 89.20 seconds\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Successfully computed plan 01\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 89.24 seconds\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\n",
            "2025-12-02 17:01:18 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p02\n",
            "2025-12-02 17:01:18 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p02\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Set number of cores to 6 for plan: 02\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:01:18 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [MissingPlans]\\BaldEagle.p02\"\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 02\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.00 seconds\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - Successfully computed plan 02\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.03 seconds\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - All selected plans have been executed.\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - compute_test_mode completed.\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n",
            "2025-12-02 17:01:22 - ras_commander.RasCmdr - INFO - Plan 02: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution completed in 93.34 seconds\n",
            "\n",
            "Execution Results for Plans Without HDF Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '      <th>Execution Type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '      <td>Missing Plans</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>True</td>\\n', '      <td>Missing Plans</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success Execution Type\n",
              "0   01     True  Missing Plans\n",
              "1   02     True  Missing Plans"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Identifying and executing plans without HDF results...\")\n",
        "\n",
        "# Use the ras object to determine which plans don't have results\n",
        "plans_no_results = ras.plan_df[ras.plan_df['HDF_Results_Path'].isna()]['plan_number'].tolist()\n",
        "\n",
        "if not plans_no_results:\n",
        "    print(\"All plans already have HDF results. Creating a test scenario...\")\n",
        "    # For demonstration purposes, pretend some plans don't have results\n",
        "    plans_no_results = [\"04\", \"05\"]\n",
        "    print(f\"Simulating no results for plans: {', '.join(plans_no_results)}\")\n",
        "else:\n",
        "    print(f\"Found {len(plans_no_results)} plans without HDF results: {', '.join(plans_no_results)}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute only the plans without results\n",
        "if plans_no_results:\n",
        "    print(f\"\\nExecuting {len(plans_no_results)} plans without results...\")\n",
        "    execution_results = RasCmdr.compute_test_mode(\n",
        "        plan_number=plans_no_results,\n",
        "        dest_folder_suffix=\"[MissingPlans]\",\n",
        "        num_cores=6, \n",
        "        overwrite_dest=True\n",
        "    )\n",
        "    \n",
        "    # Record end time and calculate duration\n",
        "    end_time = time.time()\n",
        "    duration = end_time - start_time\n",
        "    \n",
        "    print(f\"Execution completed in {duration:.2f} seconds\")\n",
        "    \n",
        "    # Create a DataFrame from the execution results\n",
        "    missing_results_df = pd.DataFrame([\n",
        "        {\"Plan\": plan, \"Success\": success, \"Execution Type\": \"Missing Plans\"}\n",
        "        for plan, success in execution_results.items()\n",
        "    ])\n",
        "    \n",
        "    # Sort by plan number\n",
        "    missing_results_df = missing_results_df.sort_values(\"Plan\")\n",
        "    \n",
        "    # Display the results\n",
        "    print(\"\\nExecution Results for Plans Without HDF Results:\")\n",
        "    display.display(missing_results_df)\n",
        "    \n",
        "    # Check the test folder\n",
        "    test_folder = bald_eagle_path.parent / f\"{ras.project_name} [MissingPlans]\"\n",
        "    if test_folder.exists():\n",
        "        print(f\"\\nTest folder exists: {test_folder}\")\n",
        "        \n",
        "        # Check for results\n",
        "        hdf_files = list(test_folder.glob(\"*.p*.hdf\"))\n",
        "        if hdf_files:\n",
        "            print(f\"Found {len(hdf_files)} HDF result files:\")\n",
        "            for file in hdf_files:\n",
        "                file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "                print(f\"  {file.name}: {file_size:.1f} MB\")\n",
        "        else:\n",
        "            print(\"No HDF result files found in the test folder\")\n",
        "else:\n",
        "    print(\"No plans without results to execute.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verification of Results\n",
        "After executing the plans that were missing HDF results, it's important to verify that the results were properly generated. Let's check if the execution actually created the expected output files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:14.695684Z",
          "iopub.status.busy": "2025-11-17T18:39:14.695405Z",
          "iopub.status.idle": "2025-11-17T18:39:14.700048Z",
          "shell.execute_reply": "2025-11-17T18:39:14.699421Z"
        }
      },
      "outputs": [],
      "source": [
        "# Re-initialize the project with the test folder to see updated results\n",
        "missing_plans_folder = bald_eagle_path.parent / f\"{ras.project_name} [MissingPlans]\"\n",
        "\n",
        "if missing_plans_folder.exists():\n",
        "    # Initialize the project from the test folder\n",
        "    test_ras = RasPrj()\n",
        "    init_ras_project(missing_plans_folder, \"6.6\", ras_object=test_ras)\n",
        "    \n",
        "    # Check which plans now have results\n",
        "    plans_with_results = test_ras.plan_df[test_ras.plan_df['HDF_Results_Path'].notna()]['plan_number'].tolist()\n",
        "    \n",
        "    print(f\"Plans with results after execution: {', '.join(plans_with_results)}\")\n",
        "    \n",
        "    # Verify if all previously missing plans now have results\n",
        "    all_generated = all(plan in plans_with_results for plan in plans_no_results)\n",
        "    \n",
        "    if all_generated:\n",
        "        print(\"\u2705 Successfully generated results for all missing plans\")\n",
        "    else:\n",
        "        print(\"\u26a0\ufe0f Some plans still don't have results after execution\")\n",
        "        missing_after = [plan for plan in plans_no_results if plan not in plans_with_results]\n",
        "        print(f\"Plans still missing results: {', '.join(missing_after)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Plan Specification Techniques\n",
        "\n",
        "In this notebook, we've explored different ways to specify and execute HEC-RAS plans using the RAS Commander library. Here's a summary of the key techniques we've covered:\n",
        "\n",
        "1. **Basic Plan Specification**\n",
        "   - Single plan by number: `\"01\"`\n",
        "   - List of specific plans: `[\"01\", \"03\"]`\n",
        "   - All plans: `ras.plan_df['plan_number'].tolist()`\n",
        "\n",
        "2. **Advanced Selection**\n",
        "   - Categorization: Grouping plans by purpose or type\n",
        "   - Dependencies: Ensuring prerequisite plans are run first\n",
        "   - Ordered execution: Running plans in a specific sequence\n",
        "\n",
        "3. **Run Plans with Missing Results (HDF)**\n",
        "   - Using ras object to determine which plans have results\n",
        "   - Creating a list of plans with no results\n",
        "   - Running those plans sequentially\n",
        "\n",
        "4. NOTE: run_parallel can also run a list of plans, but compute_plan is only made for single plan execution.  \n",
        "\n",
        "\n",
        "### Best Practices for Plan Specification\n",
        "\n",
        "1. **Consistent Formatting**: Use two-digit strings for plan numbers (\"01\" instead of 1)\n",
        "2. **Descriptive Naming**: Use meaningful short identifiers that describe the plan's purpose\n",
        "3. **Verify Availability**: Check that specified plans exist before trying to execute them\n",
        "4. **Document Dependencies**: Keep track of which plans depend on others\n",
        "5. **Use Appropriate Execution Method**: Choose sequential or parallel based on dependencies and resources\n",
        "6. **Monitor Performance**: Track execution times to identify optimization opportunities\n",
        "\n",
        "By applying these techniques, you can create efficient and organized workflows for executing HEC-RAS plans, from simple batch processing to complex dependency-based execution sequences."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\07_sequential_plan_execution.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:33.176440Z",
          "iopub.status.busy": "2025-11-17T18:39:33.175954Z",
          "iopub.status.idle": "2025-11-17T18:39:34.600184Z",
          "shell.execute_reply": "2025-11-17T18:39:34.599725Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:33 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:34.602404Z",
          "iopub.status.busy": "2025-11-17T18:39:34.602070Z",
          "iopub.status.idle": "2025-11-17T18:39:34.605282Z",
          "shell.execute_reply": "2025-11-17T18:39:34.604752Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:34.607552Z",
          "iopub.status.busy": "2025-11-17T18:39:34.607279Z",
          "iopub.status.idle": "2025-11-17T18:39:34.656894Z",
          "shell.execute_reply": "2025-11-17T18:39:34.656291Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Found zip file: C:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted project to: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "Bald Eagle Creek project exists: True\n"
          ]
        }
      ],
      "source": [
        "# Extract the Bald Eagle Creek example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(f\"Extracted project to: {bald_eagle_path}\")  \n",
        "\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:34.659440Z",
          "iopub.status.busy": "2025-11-17T18:39:34.659042Z",
          "iopub.status.idle": "2025-11-17T18:39:34.671672Z",
          "shell.execute_reply": "2025-11-17T18:39:34.671102Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples directory set to: C:\\GH\\ras-commander\\examples\\example_projects\n",
            "Removing existing test folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [SpecificSequential]\n"
          ]
        }
      ],
      "source": [
        "# define examples_dir as parent of bald_eagle_path\n",
        "examples_dir = bald_eagle_path.parent\n",
        "print(f\"Examples directory set to: {examples_dir}\")\n",
        "\n",
        "    \n",
        "# Remove any compute test folders from previous runs\n",
        "for folder in examples_dir.glob(\"*[[]AllSequential[]]*\"):\n",
        "    if folder.is_dir():\n",
        "        print(f\"Removing existing test folder: {folder}\")\n",
        "        shutil.rmtree(folder)\n",
        "        \n",
        "for folder in examples_dir.glob(\"*[[]SpecificSequential*[]]*\"):\n",
        "    if folder.is_dir():\n",
        "        print(f\"Removing existing test folder: {folder}\")\n",
        "        shutil.rmtree(folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Sequential Execution in HEC-RAS\n",
        "\n",
        "HEC-RAS simulations can be executed in several ways:\n",
        "\n",
        "1. **Single Plan Execution**: Run one plan at a time using `RasCmdr.compute_plan()`\n",
        "2. **Sequential Execution**: Run multiple plans one after another using `RasCmdr.compute_test_mode()`\n",
        "3. **Parallel Execution**: Run multiple plans simultaneously using `RasCmdr.compute_parallel()`\n",
        "\n",
        "This notebook focuses on the second approach: **Sequential Execution**. Here are the key benefits of sequential execution:\n",
        "\n",
        "- **Controlled Resource Usage**: By running plans one at a time, you ensure consistent resource usage\n",
        "- **Dependency Management**: When later plans depend on results from earlier plans\n",
        "- **Simplified Debugging**: Easier to identify which plan is causing an issue when they run sequentially\n",
        "- **Consistent Test Environment**: All plans run in the same isolated folder\n",
        "\n",
        "The `compute_test_mode()` function from `RasCmdr` is specifically designed for this purpose. It creates a separate test folder, copies the project there, and executes the specified plans in sequential order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading and Extracting Example HEC-RAS Project\n",
        "\n",
        "Let's use the `RasExamples` class to download and extract the \"Balde Eagle Creek\" example project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "Let's initialize the HEC-RAS project using the `init_ras_project()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:34.674301Z",
          "iopub.status.busy": "2025-11-17T18:39:34.673970Z",
          "iopub.status.idle": "2025-11-17T18:39:34.725955Z",
          "shell.execute_reply": "2025-11-17T18:39:34.725300Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized HEC-RAS project: BaldEagle\n",
            "\n",
            "HEC-RAS Project Plan Data:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number                     Plan Title  \\\n",
              "0          01              02              01  Unsteady with Bridges and Dam   \n",
              "1          02            None              01                Steady Flow Run   \n",
              "\n",
              "  Program Version Short Identifier                  Simulation Date  \\\n",
              "0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \n",
              "1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \n",
              "\n",
              "  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\n",
              "0                 2MIN            1HOUR        1  ...     None      dss   \n",
              "1                 2MIN              NaN        1  ...     None      dss   \n",
              "\n",
              "  Friction Slope Method HDF_Results_Path Geom File  \\\n",
              "0                     2             None        01   \n",
              "1                     1             None        01   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         02   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...    Steady  \n",
              "\n",
              "[2 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 plans in the project\n"
          ]
        }
      ],
      "source": [
        "# Initialize the HEC-RAS project\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "\n",
        "# Display the current plan files in the project\n",
        "print(\"\\nHEC-RAS Project Plan Data:\")\n",
        "display.display(ras.plan_df)\n",
        "\n",
        "# Check how many plans we have\n",
        "plan_count = len(ras.plan_df)\n",
        "print(f\"Found {plan_count} plans in the project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the RasCmdr.compute_test_mode Method\n",
        "\n",
        "Before we start executing plans, let's understand the `compute_test_mode()` method from the `RasCmdr` class, which we'll use for sequential execution.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number` (str, list[str], optional): Plan number or list of plan numbers to execute. If None, all plans will be executed.\n",
        "- `dest_folder_suffix` (str, optional): Suffix to append to the test folder name. Defaults to \"[Test]\".\n",
        "- `clear_geompre` (bool, optional): Whether to clear geometry preprocessor files. Defaults to False.\n",
        "- `num_cores` (int, optional): Maximum number of cores to use for each plan. If None, the current setting is not changed.\n",
        "- `ras_object` (RasPrj, optional): Specific RAS object to use. If None, uses the global ras object.\n",
        "- `overwrite_dest` (bool, optional): Whether to overwrite the destination folder if it exists. Defaults to False.\n",
        "\n",
        "### Return Value\n",
        "- `Dict[str, bool]`: Dictionary of plan numbers and their execution success status.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Test Folder**: The function creates a separate folder with the specified suffix, copying the project there for execution.\n",
        "2. **Sequential Execution**: Plans are executed one after another in the specified order.\n",
        "3. **Geometry Preprocessor Files**: These files store precomputed hydraulic properties. Clearing them forces HEC-RAS to recompute these properties.\n",
        "4. **Destination Folder Option**: The suffix determines the name of the test folder. Unlike `compute_plan()`, you can't specify an arbitrary destination folder.\n",
        "5. **Overwrite Option**: Controls whether an existing test folder should be overwritten.\n",
        "\n",
        "Now, let's see how this works in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Sequential Execution of All Plans\n",
        "\n",
        "Let's execute all plans in the project sequentially. This will create a test folder with the suffix \"[AllSequential]\" and run all plans one after another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:39:34.728602Z",
          "iopub.status.busy": "2025-11-17T18:39:34.728260Z",
          "iopub.status.idle": "2025-11-17T18:41:12.830417Z",
          "shell.execute_reply": "2025-11-17T18:41:12.829932Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Starting the compute_test_mode...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Creating the test folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Copied project folder to compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Initialized RAS project in compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.prj\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Getting plan entries...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Retrieved plan entries successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Running selected plans sequentially...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:39:34 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.p01\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing all plans sequentially...\n",
            "This may take several minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 93.85 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Successfully computed plan 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 93.86 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:08 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.p02\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.17 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Successfully computed plan 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.18 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - All selected plans have been executed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - compute_test_mode completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Plan 02: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential execution of all plans completed in 98.09 seconds\n",
            "\n",
            "Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>True</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success\n",
              "0   01     True\n",
              "1   02     True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing all plans sequentially...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute all plans sequentially\n",
        "# - dest_folder_suffix: Suffix to append to the test folder name\n",
        "# - overwrite_dest: Overwrite the destination folder if it exists\n",
        "# - no ras object is specified, it will use the default \"ras\" object\n",
        "execution_results = RasCmdr.compute_test_mode(\n",
        "    dest_folder_suffix=\"[AllSequential]\",\n",
        "    overwrite_dest=True\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "print(f\"Sequential execution of all plans completed in {total_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success}\n",
        "    for plan, success in execution_results.items()\n",
        "])\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nExecution Results:\")\n",
        "display.display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Examining the Test Folder\n",
        "\n",
        "Let's examine the test folder created by `compute_test_mode()` to better understand what happened during sequential execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:12.832608Z",
          "iopub.status.busy": "2025-11-17T18:41:12.832265Z",
          "iopub.status.idle": "2025-11-17T18:41:12.836131Z",
          "shell.execute_reply": "2025-11-17T18:41:12.835634Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "[\"WindowsPath('C:/GH/ras-commander/examples/example_projects/Balde Eagle Creek [AllSequential]')\"]"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the test folder path\n",
        "test_folder = bald_eagle_path.parent / f\"Balde Eagle Creek [AllSequential]\"\n",
        "test_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:12.839999Z",
          "iopub.status.busy": "2025-11-17T18:41:12.839772Z",
          "iopub.status.idle": "2025-11-17T18:41:12.870193Z",
          "shell.execute_reply": "2025-11-17T18:41:12.869668Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test folder exists: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential]\n",
            "\n",
            "Key files in test folder:\n",
            "Project file: BaldEagle.prj\n",
            "Plan files:\n",
            "  BaldEagle.p01: 15.6 KB\n",
            "  BaldEagle.p01.comp_msgs.txt: 1.2 KB\n",
            "  BaldEagle.p01.hdf: 7592.7 KB\n",
            "  BaldEagle.p02: 12.5 KB\n",
            "  BaldEagle.p02.hdf: 4368.0 KB\n",
            "  BaldEagle.prj: 0.9 KB\n",
            "\n",
            "HDF files:\n",
            "  BaldEagle.g01.hdf: 3.8 MB\n",
            "  BaldEagle.p01.hdf: 7.4 MB\n",
            "  BaldEagle.p02.hdf: 4.3 MB\n",
            "  BaldEagle.u02.hdf: 0.0 MB\n",
            "\n",
            "Geometry preprocessor files:\n",
            "  BaldEagle.c01: 522.1 KB\n",
            "  BaldEagle.p01.comp_msgs.txt: 1.2 KB\n",
            "\n",
            "Plans with results in the test folder:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number                                   HDF_Results_Path\n",
              "0          01  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "1          02  C:\\GH\\ras-commander\\examples\\example_projects\\..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create test folder if it doesn't exist using pathlib\n",
        "if not test_folder.exists():\n",
        "    test_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "if test_folder.exists():\n",
        "    print(f\"Test folder exists: {test_folder}\")\n",
        "    \n",
        "    # List the key files in the test folder\n",
        "    print(\"\\nKey files in test folder:\")\n",
        "    \n",
        "    # First, list the project file and all plan files\n",
        "    prj_files = list(test_folder.glob(\"*.prj\"))\n",
        "    plan_files = list(test_folder.glob(\"*.p*\"))\n",
        "    plan_files.sort()\n",
        "    \n",
        "    if prj_files:\n",
        "        print(f\"Project file: {prj_files[0].name}\")\n",
        "    \n",
        "    print(\"Plan files:\")\n",
        "    for plan_file in plan_files:\n",
        "        file_size = plan_file.stat().st_size / 1024  # Size in KB\n",
        "        print(f\"  {plan_file.name}: {file_size:.1f} KB\")\n",
        "    \n",
        "    # Look for HDF result files\n",
        "    hdf_files = list(test_folder.glob(\"*.hdf\"))\n",
        "    hdf_files.sort()\n",
        "    \n",
        "    print(\"\\nHDF files:\")\n",
        "    for hdf_file in hdf_files:\n",
        "        file_size = hdf_file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "        print(f\"  {hdf_file.name}: {file_size:.1f} MB\")\n",
        "    \n",
        "    # Geometry preprocessor files (if any)\n",
        "    geompre_files = list(test_folder.glob(\"*.c*\"))\n",
        "    geompre_files.sort()\n",
        "    \n",
        "    if geompre_files:\n",
        "        print(\"\\nGeometry preprocessor files:\")\n",
        "        for geompre_file in geompre_files:\n",
        "            file_size = geompre_file.stat().st_size / 1024  # Size in KB\n",
        "            print(f\"  {geompre_file.name}: {file_size:.1f} KB\")\n",
        "    else:\n",
        "        print(\"\\nNo geometry preprocessor files found\")\n",
        "        \n",
        "    # Initialize a RAS project in the test folder to inspect results\n",
        "    try:\n",
        "        test_ras = RasPrj()\n",
        "        init_ras_project(test_folder, ras.ras_exe_path, ras_object=test_ras)\n",
        "        print(\"\\nPlans with results in the test folder:\")\n",
        "        test_plans_with_results = test_ras.plan_df[test_ras.plan_df['HDF_Results_Path'].notna()]\n",
        "        display.display(test_plans_with_results[['plan_number', 'HDF_Results_Path']])\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing test folder as a RAS project: {e}\")\n",
        "else:\n",
        "    print(f\"Test folder not found: {test_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Sequential Execution of Specific Plans\n",
        "\n",
        "Now, let's execute only specific plans in the project. We'll select plans \"01\" and \"02\" and run them sequentially with the `clear_geompre` option set to True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:12.873689Z",
          "iopub.status.busy": "2025-11-17T18:41:12.873458Z",
          "iopub.status.idle": "2025-11-17T18:41:32.146605Z",
          "shell.execute_reply": "2025-11-17T18:41:32.146118Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Starting the compute_test_mode...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Creating the test folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Copied project folder to compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Initialized RAS project in compute folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.prj\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Getting plan entries...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Retrieved plan entries successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['01', '02']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Running selected plans sequentially...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:12 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p01\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing specific plans sequentially with clearing geometry preprocessor files...\n",
            "This may take several minutes...\n",
            "Selected plans: 01, 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 15.13 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Successfully computed plan 01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 15.14 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:28 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek [AllSequential] [SpecificSequentialClearGeompre]\\BaldEagle.p02\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.04 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - Successfully computed plan 02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 4.05 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - All selected plans have been executed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - compute_test_mode completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:32 - ras_commander.RasCmdr - INFO - Plan 02: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential execution of specific plans completed in 19.27 seconds\n",
            "\n",
            "Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>True</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success\n",
              "0   01     True\n",
              "1   02     True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing specific plans sequentially with clearing geometry preprocessor files...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Define the plans to execute\n",
        "selected_plans = [\"01\", \"02\"]\n",
        "print(f\"Selected plans: {', '.join(selected_plans)}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute specific plans sequentially\n",
        "# - plan_number: List of plan numbers to execute\n",
        "# - dest_folder_suffix: Suffix to append to the test folder name\n",
        "# - clear_geompre: Clear geometry preprocessor files before execution\n",
        "# - overwrite_dest: Overwrite the destination folder if it exists\n",
        "execution_results = RasCmdr.compute_test_mode(\n",
        "    plan_number=selected_plans,\n",
        "    dest_folder_suffix=\"[SpecificSequentialClearGeompre]\",\n",
        "    clear_geompre=True,\n",
        "    overwrite_dest=True\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "print(f\"Sequential execution of specific plans completed in {total_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success}\n",
        "    for plan, success in execution_results.items()\n",
        "])\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nExecution Results:\")\n",
        "display.display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Sequential Plan Execution\n",
        "\n",
        "In this notebook, we've explored how to execute HEC-RAS plans sequentially using the RAS Commander library. Here's a summary of the key techniques we've covered:\n",
        "\n",
        "1. **Project Setup and Initialization**: Setting up the environment and initializing a HEC-RAS project\n",
        "2. **Example Project Management**: Using `RasExamples` to download and extract sample projects\n",
        "3. **Basic Sequential Execution**: Using `RasCmdr.compute_test_mode()` to run all plans in a project\n",
        "4. **Test Folder Analysis**: Examining the contents and results of sequential execution\n",
        "5. **Selective Plan Execution**: Running specific plans with geometry preprocessor clearing\n",
        "\n",
        "### Key Functions Used\n",
        "\n",
        "- `init_ras_project()`: Initialize a HEC-RAS project\n",
        "- `RasExamples.extract_project()`: Extract example projects for testing\n",
        "- `RasCmdr.compute_test_mode()`: Run plans sequentially in a test folder\n",
        "- `Path.glob()`: Examine test folder contents and results\n",
        "- `RasCmdr.compute_test_mode(clear_geompre=True)`: Execute plans with preprocessor clearing\n",
        "\n",
        "### Best Practices for Sequential Execution\n",
        "\n",
        "1. **Environment Setup**: Ensure all required libraries are installed and properly imported\n",
        "2. **Project Organization**: Clean up existing test folders before new executions\n",
        "3. **Resource Management**: Monitor system resources (CPU cores, memory) for optimal performance\n",
        "4. **Test Folder Naming**: Use meaningful suffixes to distinguish different execution runs\n",
        "5. **Performance Tracking**: Monitor execution times for each sequential run\n",
        "6. **Results Verification**: Check test folders for successful plan execution and result files\n",
        "7. **Selective Execution**: Use plan filtering when only specific plans need to be run\n",
        "\n",
        "With these techniques, you can effectively manage and execute HEC-RAS simulations sequentially, whether running all plans or a selected subset with specific configurations."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\08_parallel_execution.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:49.665313Z",
          "iopub.status.busy": "2025-11-17T18:41:49.665137Z",
          "iopub.status.idle": "2025-11-17T18:41:50.945060Z",
          "shell.execute_reply": "2025-11-17T18:41:50.944588Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 13:41:49 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:50.947436Z",
          "iopub.status.busy": "2025-11-17T18:41:50.947175Z",
          "iopub.status.idle": "2025-11-17T18:41:50.950612Z",
          "shell.execute_reply": "2025-11-17T18:41:50.950086Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil\n",
        "import math  # Import math to avoid NameError in get_optimal_worker_count function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up Our Working Environment\n",
        "\n",
        "Let's set up our working directory and check the system resources available for parallel execution. This will help us make informed decisions about how many workers to use.\n",
        "\n",
        "For this notebook we will be using the \"Muncie\" HEC Example Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:50.952916Z",
          "iopub.status.busy": "2025-11-17T18:41:50.952727Z",
          "iopub.status.idle": "2025-11-17T18:41:51.223399Z",
          "shell.execute_reply": "2025-11-17T18:41:51.222889Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Extracting project 'Muncie'\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Project 'Muncie' already exists. Deleting existing folder...\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Existing folder for project 'Muncie' has been deleted.\n",
            "2025-12-02 17:13:09 - ras_commander.RasExamples - INFO - Successfully extracted project 'Muncie' to c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted project to: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
            "Bald Eagle Creek project exists: True\n",
            "System Resources:\n",
            "- 8 physical CPU cores (8 logical cores with hyper-threading)\n",
            "- 31.9 GB total memory (13.1 GB available)\n",
            "\n",
            "For parallel HEC-RAS execution:\n",
            "- With 2 cores per worker: Can use up to 4 parallel workers\n",
            "- With 4 cores per worker: Can use up to 2 parallel workers\n",
            "\n",
            "Each HEC-RAS instance typically requires 2-4 GB of RAM. Based on your available memory,\n",
            "you could reasonably run 4 instances simultaneously.\n"
          ]
        }
      ],
      "source": [
        "# Extract the Muncie example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
        "print(f\"Extracted project to: {muncie_path}\")  \n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {muncie_path.exists()}\")\n",
        "\n",
        "\n",
        "# Create compute folders\n",
        "compute_folder = muncie_path.parent / \"compute_test_parallel\"\n",
        "specific_compute_folder = muncie_path.parent / \"compute_test_parallel_specific\"\n",
        "dynamic_compute_folder = muncie_path.parent / \"compute_test_parallel_dynamic\"\n",
        "\n",
        "# Check system resources for parallel execution\n",
        "cpu_count = psutil.cpu_count(logical=True)  # Logical cores (including hyper-threading)\n",
        "physical_cores = psutil.cpu_count(logical=False)  # Physical cores only\n",
        "memory_gb = psutil.virtual_memory().total / (1024**3)  # Total RAM in GB\n",
        "available_memory_gb = psutil.virtual_memory().available / (1024**3)  # Available RAM in GB\n",
        "\n",
        "print(f\"System Resources:\")\n",
        "print(f\"- {physical_cores} physical CPU cores ({cpu_count} logical cores with hyper-threading)\")\n",
        "print(f\"- {memory_gb:.1f} GB total memory ({available_memory_gb:.1f} GB available)\")\n",
        "\n",
        "# Functions to help with resource management\n",
        "def get_optimal_worker_count(cores_per_worker=2):\n",
        "    \"\"\"Calculate the optimal number of workers based on available physical cores.\"\"\"\n",
        "    optimal_workers = math.floor(physical_cores / cores_per_worker)\n",
        "    return max(1, optimal_workers)  # Ensure at least 1 worker\n",
        "\n",
        "print(f\"\\nFor parallel HEC-RAS execution:\")\n",
        "print(f\"- With 2 cores per worker: Can use up to {get_optimal_worker_count(2)} parallel workers\")\n",
        "print(f\"- With 4 cores per worker: Can use up to {get_optimal_worker_count(4)} parallel workers\")\n",
        "print(f\"\\nEach HEC-RAS instance typically requires 2-4 GB of RAM. Based on your available memory,\")\n",
        "print(f\"you could reasonably run {math.floor(available_memory_gb / 3)} instances simultaneously.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Parallel Execution in HEC-RAS\n",
        "\n",
        "HEC-RAS simulations can be computationally intensive, especially for large models or long simulation periods. Parallel execution allows you to run multiple plans simultaneously, making better use of your computer's processing power.\n",
        "\n",
        "### Key Concepts in Parallel Execution\n",
        "\n",
        "1. **Workers**: Each worker is a separate process that can execute a HEC-RAS plan. The `max_workers` parameter determines how many plans can be executed simultaneously.\n",
        "\n",
        "2. **Cores per Worker**: Each worker (HEC-RAS instance) can utilize multiple CPU cores. The `num_cores` parameter sets how many cores each worker uses.\n",
        "\n",
        "3. **Resource Balancing**: Effective parallel execution requires balancing the number of workers with the cores per worker. Too many workers or too many cores per worker can lead to resource contention and slower overall performance.\n",
        "\n",
        "4. **Worker Folders**: Each worker gets its own folder with a copy of the project, allowing for isolated execution.\n",
        "\n",
        "### Parallel vs. Sequential Execution\n",
        "\n",
        "- **Parallel**: Multiple plans run simultaneously (good for independent plans, faster overall completion)\n",
        "- **Sequential**: Plans run one after another (good for dependent plans, consistent resource usage)\n",
        "\n",
        "### Optimal Configuration\n",
        "\n",
        "The optimal configuration depends on your hardware and the specific plans you're running:\n",
        "\n",
        "- For most models, 2-4 cores per worker provides good performance\n",
        "- Set `max_workers` based on available physical cores: `max_workers = floor(physical_cores / cores_per_worker)`\n",
        "- Ensure you have enough memory: each worker typically needs 2-4 GB of RAM\n",
        "\n",
        "Now, let's download and extract our example project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading and Extracting Example HEC-RAS Project\n",
        "\n",
        "Let's use the `RasExamples` class to download and extract the \"Balde Eagle Creek\" example project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "Let's initialize the HEC-RAS project using the `init_ras_project()` function. We'll store the initialized object in a variable to use later, rather than relying on the global `ras` object. This approach is more suitable for working with multiple projects or compute folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:51.225789Z",
          "iopub.status.busy": "2025-11-17T18:41:51.225546Z",
          "iopub.status.idle": "2025-11-17T18:41:51.287210Z",
          "shell.execute_reply": "2025-11-17T18:41:51.286430Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized source project: Muncie\n",
            "\n",
            "Available plans in the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>9-SAs</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady Run with 2D 50ft Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>-1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>01</td>\\n', '      <td>04</td>\\n', '      <td>Unsteady Run with 2D 50ft User n Value R</td>\\n', '      <td>5.10</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number  \\\n",
              "0          01              01              01   \n",
              "1          03              01              02   \n",
              "2          04              01              04   \n",
              "\n",
              "                                 Plan Title Program Version  \\\n",
              "0                  Unsteady Multi  9-SA run            5.00   \n",
              "1            Unsteady Run with 2D 50ft Grid            5.10   \n",
              "2  Unsteady Run with 2D 50ft User n Value R            5.10   \n",
              "\n",
              "      Short Identifier                Simulation Date Computation Interval  \\\n",
              "0                9-SAs  02JAN1900,0000,02JAN1900,2400                15SEC   \n",
              "1         2D 50ft Grid  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "2  50ft User n Regions  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "\n",
              "  Mapping Interval Run HTab  ... Friction Slope Method UNET D2 SolverType  \\\n",
              "0             5MIN        1  ...                     1                NaN   \n",
              "1             5MIN       -1  ...                     1   Pardiso (Direct)   \n",
              "2             5MIN        1  ...                     1   Pardiso (Direct)   \n",
              "\n",
              "       UNET D2 Name HDF_Results_Path Geom File  \\\n",
              "0               NaN             None        01   \n",
              "1  2D Interior Area             None        02   \n",
              "2  2D Interior Area             None        04   \n",
              "\n",
              "                                           Geom Path  Flow File  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 plans in the project\n"
          ]
        }
      ],
      "source": [
        "# Initialize the source project\n",
        "source_project = init_ras_project(muncie_path, \"6.6\")\n",
        "print(f\"Initialized source project: {source_project.project_name}\")\n",
        "\n",
        "# Display the current plan files in the project\n",
        "print(\"\\nAvailable plans in the project:\")\n",
        "display.display(source_project.plan_df)\n",
        "\n",
        "# Check how many plans we have\n",
        "plan_count = len(source_project.plan_df)\n",
        "print(f\"Found {plan_count} plans in the project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the RasCmdr.compute_parallel Method\n",
        "\n",
        "Before we start executing plans in parallel, let's understand the `compute_parallel()` method from the `RasCmdr` class.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number` (Union[str, List[str], None]): Plan number(s) to compute. If None, all plans are computed.\n",
        "- `max_workers` (int): Maximum number of parallel workers (default: 2).\n",
        "- `num_cores` (int): Number of cores to use per plan computation (default: 2).\n",
        "- `clear_geompre` (bool): Whether to clear geometry preprocessor files (default: False).\n",
        "- `ras_object` (Optional[RasPrj]): Specific RAS object to use. If None, uses global ras instance.\n",
        "- `dest_folder` (Union[str, Path, None]): Destination folder for computed results.\n",
        "- `overwrite_dest` (bool): Whether to overwrite existing destination folder (default: False).\n",
        "\n",
        "### Return Value\n",
        "- `Dict[str, bool]`: Dictionary of plan numbers and their execution success status.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "1. **Worker Assignment**: Plans are assigned to workers in a round-robin fashion. For example, with 3 workers and 5 plans, workers would be assigned as follows: Worker 1: Plans 1 & 4, Worker 2: Plans 2 & 5, Worker 3: Plan 3.\n",
        "\n",
        "2. **Worker Folders**: Each worker gets its own folder (a subdirectory of the destination folder) for isolated execution.\n",
        "\n",
        "3. **Result Consolidation**: After all plans are executed, results are consolidated into the destination folder.\n",
        "\n",
        "4. **Resource Management**: Each worker can use multiple cores as specified by `num_cores`.\n",
        "\n",
        "Now, let's see how this works in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Parallel Execution of All Plans\n",
        "\n",
        "Let's execute all plans in the project in parallel. We'll use 3 workers, with 2 cores per worker. This approach is good when you have multiple plans that are independent of each other and you want to complete them as quickly as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:41:51.289557Z",
          "iopub.status.busy": "2025-11-17T18:41:51.289374Z",
          "iopub.status.idle": "2025-11-17T18:43:03.218068Z",
          "shell.execute_reply": "2025-11-17T18:43:03.217474Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Destination folder 'c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel' exists. Overwriting as per overwrite_dest=True.\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Copied project folder to destination: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Adjusted max_workers to 3 based on the number of plans: 3\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing all plans in parallel...\n",
            "This may take several minutes...\n",
            "Using 4 parallel workers, each with 1 cores\n",
            "Destination folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\n",
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\n",
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.rasmap\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\n",
            "2025-12-02 17:13:09 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.p04\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.p04\n",
            "2025-12-02 17:13:09 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Set number of cores to 1 for plan: 04\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Set number of cores to 1 for plan: 01\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 3]\\Muncie.p04\"\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Set number of cores to 1 for plan: 03\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 1]\\Muncie.p01\"\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:13:10 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel [Worker 2]\\Muncie.p03\"\n",
            "2025-12-02 17:13:24 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 17:13:24 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 14.84 seconds\n",
            "2025-12-02 17:13:24 - ras_commander.RasCmdr - INFO - Plan 01 executed in worker 1: Successful\n",
            "2025-12-02 17:14:00 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-12-02 17:14:00 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 50.26 seconds\n",
            "2025-12-02 17:14:00 - ras_commander.RasCmdr - INFO - Plan 03 executed in worker 2: Successful\n",
            "2025-12-02 17:14:01 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 04\n",
            "2025-12-02 17:14:01 - ras_commander.RasCmdr - INFO - Total run time for plan 04: 51.37 seconds\n",
            "2025-12-02 17:14:01 - ras_commander.RasCmdr - INFO - Plan 04 executed in worker 3: Successful\n",
            "2025-12-02 17:14:01 - ras_commander.RasCmdr - INFO - Final destination for computed results: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\n",
            "2025-12-02 17:14:07 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\\Muncie.rasmap\n",
            "2025-12-02 17:14:07 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\\Muncie.rasmap\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Plan 03: Successful\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Plan 04: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parallel execution of all plans completed in 58.12 seconds\n",
            "\n",
            "Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>True</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success\n",
              "0   01     True\n",
              "1   03     True\n",
              "2   04     True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing all plans in parallel...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Create compute folder if it doesn't exist\n",
        "compute_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Define the parameters for parallel execution\n",
        "max_workers = 4\n",
        "cores_per_worker = 1\n",
        "\n",
        "print(f\"Using {max_workers} parallel workers, each with {cores_per_worker} cores\")\n",
        "print(f\"Destination folder: {compute_folder}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute all plans in parallel\n",
        "results_all = RasCmdr.compute_parallel(\n",
        "    max_workers=max_workers,\n",
        "    num_cores=cores_per_worker,\n",
        "    dest_folder=compute_folder,\n",
        "    overwrite_dest=True,\n",
        "    ras_object=source_project\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "total_duration = end_time - start_time\n",
        "\n",
        "print(f\"Parallel execution of all plans completed in {total_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success}\n",
        "    for plan, success in results_all.items()\n",
        "])\n",
        "\n",
        "# Sort by plan number\n",
        "results_df = results_df.sort_values(\"Plan\")\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nExecution Results:\")\n",
        "display.display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Examining the Parallel Execution Results\n",
        "\n",
        "Let's initialize a RAS project in the compute folder and examine the results of the parallel execution. This will help us understand what happened during the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:43:03.220580Z",
          "iopub.status.busy": "2025-11-17T18:43:03.220396Z",
          "iopub.status.idle": "2025-11-17T18:43:03.260068Z",
          "shell.execute_reply": "2025-11-17T18:43:03.259635Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:07 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\\Muncie.rasmap\n",
            "2025-12-02 17:14:07 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized compute project: Muncie\n",
            "\n",
            "Plans in the compute folder:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>9-SAs</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady Run with 2D 50ft Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>-1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>01</td>\\n', '      <td>04</td>\\n', '      <td>Unsteady Run with 2D 50ft User n Value R</td>\\n', '      <td>5.10</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number unsteady_number geometry_number  \\\n",
              "0          01              01              01   \n",
              "1          03              01              02   \n",
              "2          04              01              04   \n",
              "\n",
              "                                 Plan Title Program Version  \\\n",
              "0                  Unsteady Multi  9-SA run            5.00   \n",
              "1            Unsteady Run with 2D 50ft Grid            5.10   \n",
              "2  Unsteady Run with 2D 50ft User n Value R            5.10   \n",
              "\n",
              "      Short Identifier                Simulation Date Computation Interval  \\\n",
              "0                9-SAs  02JAN1900,0000,02JAN1900,2400                15SEC   \n",
              "1         2D 50ft Grid  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "2  50ft User n Regions  02JAN1900,0000,02JAN1900,2400                10SEC   \n",
              "\n",
              "  Mapping Interval Run HTab  ... Friction Slope Method UNET D2 SolverType  \\\n",
              "0             5MIN        1  ...                     1                NaN   \n",
              "1             5MIN       -1  ...                     1   Pardiso (Direct)   \n",
              "2             5MIN        1  ...                     1   Pardiso (Direct)   \n",
              "\n",
              "       UNET D2 Name                                   HDF_Results_Path  \\\n",
              "0               NaN  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  2D Interior Area  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "2  2D Interior Area  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "  Geom File                                          Geom Path  Flow File  \\\n",
              "0        01  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "1        02  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "2        04  C:\\GH\\ras-commander\\examples\\example_projects\\...         01   \n",
              "\n",
              "                                           Flow Path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                           full_path flow_type  \n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "1  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "2  C:\\GH\\ras-commander\\examples\\example_projects\\...  Unsteady  \n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 3 plans with results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number                                   HDF_Results_Path\n",
              "0          01  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "1          03  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "2          04  C:\\GH\\ras-commander\\examples\\example_projects\\..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "No worker folders remain in the compute folder (they were removed during results consolidation)\n",
            "\n",
            "Found 7 HDF files in the compute folder:\n",
            "  Muncie.g01.hdf: 0.2 MB\n",
            "  Muncie.g02.hdf: 0.5 MB\n",
            "  Muncie.g04.hdf: 3.0 MB\n",
            "  Muncie.p01.hdf: 3.8 MB\n",
            "  Muncie.p03.hdf: 15.3 MB\n",
            "  Muncie.p04.hdf: 17.9 MB\n",
            "  Muncie.u01.hdf: 0.0 MB\n"
          ]
        }
      ],
      "source": [
        "# Initialize a RAS project in the compute folder\n",
        "compute_project = RasPrj()\n",
        "init_ras_project(compute_folder, \"6.6\", ras_object=compute_project)\n",
        "print(f\"Initialized compute project: {compute_project.project_name}\")\n",
        "\n",
        "# Display the plan files in the compute folder\n",
        "print(\"\\nPlans in the compute folder:\")\n",
        "display.display(compute_project.plan_df)\n",
        "\n",
        "# Check which plans have results\n",
        "plans_with_results = compute_project.plan_df[compute_project.plan_df['HDF_Results_Path'].notna()]\n",
        "print(f\"\\nFound {len(plans_with_results)} plans with results:\")\n",
        "display.display(plans_with_results[['plan_number', 'HDF_Results_Path']])\n",
        "\n",
        "# List the worker folders (they should have been removed during results consolidation)\n",
        "worker_folders = list(compute_folder.glob(\"*Worker*\"))\n",
        "if worker_folders:\n",
        "    print(f\"\\nFound {len(worker_folders)} worker folders:\")\n",
        "    for folder in worker_folders:\n",
        "        print(f\"  {folder.name}\")\n",
        "else:\n",
        "    print(\"\\nNo worker folders remain in the compute folder (they were removed during results consolidation)\")\n",
        "\n",
        "# Check for HDF result files\n",
        "hdf_files = list(compute_folder.glob(\"*.hdf\"))\n",
        "hdf_files.sort()\n",
        "\n",
        "print(f\"\\nFound {len(hdf_files)} HDF files in the compute folder:\")\n",
        "for file in hdf_files:\n",
        "    file_size = file.stat().st_size / (1024 * 1024)  # Size in MB\n",
        "    print(f\"  {file.name}: {file_size:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Additional Examples: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Execution of Specific Plans\n",
        "\n",
        "Now, let's execute only specific plans in the project in parallel. This approach is useful when you only want to run a subset of the available plans, perhaps for testing or comparison purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:43:03.262815Z",
          "iopub.status.busy": "2025-11-17T18:43:03.262412Z",
          "iopub.status.idle": "2025-11-17T18:43:43.246887Z",
          "shell.execute_reply": "2025-11-17T18:43:43.246195Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Destination folder 'c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific' exists. Overwriting as per overwrite_dest=True.\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Copied project folder to destination: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['01', '03']\n",
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Adjusted max_workers to 2 based on the number of plans: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing specific plans in parallel...\n",
            "This may take several minutes...\n",
            "Selected plans: 01, 03\n",
            "Using 2 parallel workers, each with 2 cores\n",
            "Destination folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:07 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\n",
            "2025-12-02 17:14:07 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:14:08 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\n",
            "2025-12-02 17:14:08 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:14:08 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\n",
            "2025-12-02 17:14:08 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:14:08 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:14:08 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:14:08 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 03\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 2]\\Muncie.p03\"\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 01\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:14:08 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific [Worker 1]\\Muncie.p01\"\n",
            "2025-12-02 17:14:22 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 17:14:22 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 14.04 seconds\n",
            "2025-12-02 17:14:22 - ras_commander.RasCmdr - INFO - Plan 01 executed in worker 1: Successful\n",
            "2025-12-02 17:14:37 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-12-02 17:14:37 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 29.45 seconds\n",
            "2025-12-02 17:14:37 - ras_commander.RasCmdr - INFO - Plan 03 executed in worker 2: Successful\n",
            "2025-12-02 17:14:37 - ras_commander.RasCmdr - INFO - Final destination for computed results: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\n",
            "2025-12-02 17:14:41 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\\Muncie.rasmap\n",
            "2025-12-02 17:14:41 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\\Muncie.rasmap\n",
            "2025-12-02 17:14:41 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-12-02 17:14:41 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n",
            "2025-12-02 17:14:41 - ras_commander.RasCmdr - INFO - Plan 03: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parallel execution of specific plans completed in 34.17 seconds\n",
            "\n",
            "Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>True</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success\n",
              "0   01     True\n",
              "1   03     True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:41 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\\Muncie.rasmap\n",
            "2025-12-02 17:14:41 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_specific\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialized specific compute project: Muncie\n",
            "Found 3 plans with results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number                                   HDF_Results_Path\n",
              "0          01  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "1          03  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "2          04  C:\\GH\\ras-commander\\examples\\example_projects\\..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing specific plans in parallel...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Create specific compute folder if it doesn't exist\n",
        "specific_compute_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Define the plans to execute\n",
        "specific_plans = [\"01\", \"03\"]\n",
        "print(f\"Selected plans: {', '.join(specific_plans)}\")\n",
        "\n",
        "# Define the parameters for parallel execution\n",
        "max_workers = 2  # One for each plan\n",
        "cores_per_worker = 2\n",
        "\n",
        "print(f\"Using {max_workers} parallel workers, each with {cores_per_worker} cores\")\n",
        "print(f\"Destination folder: {specific_compute_folder}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute specific plans in parallel\n",
        "results_specific = RasCmdr.compute_parallel(\n",
        "    plan_number=specific_plans,\n",
        "    max_workers=max_workers,\n",
        "    num_cores=cores_per_worker,\n",
        "    dest_folder=specific_compute_folder,\n",
        "    overwrite_dest=True,\n",
        "    ras_object=source_project\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "specific_duration = end_time - start_time\n",
        "\n",
        "print(f\"Parallel execution of specific plans completed in {specific_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "specific_results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success}\n",
        "    for plan, success in results_specific.items()\n",
        "])\n",
        "\n",
        "# Sort by plan number\n",
        "specific_results_df = specific_results_df.sort_values(\"Plan\")\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nExecution Results:\")\n",
        "display.display(specific_results_df)\n",
        "\n",
        "# Initialize a RAS project in the specific compute folder\n",
        "specific_compute_project = RasPrj()\n",
        "init_ras_project(specific_compute_folder, \"6.6\", ras_object=specific_compute_project)\n",
        "print(f\"\\nInitialized specific compute project: {specific_compute_project.project_name}\")\n",
        "\n",
        "# Check which plans have results\n",
        "specific_plans_with_results = specific_compute_project.plan_df[specific_compute_project.plan_df['HDF_Results_Path'].notna()]\n",
        "print(f\"Found {len(specific_plans_with_results)} plans with results:\")\n",
        "display.display(specific_plans_with_results[['plan_number', 'HDF_Results_Path']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Execution with Max Workers Defined by Physical Cores (\"Dynamic Worker Allocation\") \n",
        "\n",
        "In this step, we'll determine the optimal number of workers based on the physical cores available on the system. This approach ensures that we make efficient use of the available hardware without overcommitting resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:43:43.249907Z",
          "iopub.status.busy": "2025-11-17T18:43:43.249674Z",
          "iopub.status.idle": "2025-11-17T18:44:25.607573Z",
          "shell.execute_reply": "2025-11-17T18:44:25.606983Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:41 - ras_commander.RasCmdr - INFO - Destination folder 'c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic' exists. Overwriting as per overwrite_dest=True.\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Copied project folder to destination: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['01', '03']\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Adjusted max_workers to 2 based on the number of plans: 2\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing plans with dynamic worker allocation...\n",
            "This may take several minutes...\n",
            "System has 8 physical cores\n",
            "With 4 cores per worker, optimal worker count is 2\n",
            "Destination folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:14:42 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:14:42 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.rasmap\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Created worker folder: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\n",
            "2025-12-02 17:14:42 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:14:42 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.rasmap\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\n",
            "2025-12-02 17:14:42 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:14:42 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:14:42 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.p01\n",
            "2025-12-02 17:14:42 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.p03\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Set number of cores to 4 for plan: 01\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 1]\\Muncie.p01\"\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Set number of cores to 4 for plan: 03\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 17:14:42 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic [Worker 2]\\Muncie.p03\"\n",
            "2025-12-02 17:14:56 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 17:14:56 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 14.38 seconds\n",
            "2025-12-02 17:14:56 - ras_commander.RasCmdr - INFO - Plan 01 executed in worker 1: Successful\n",
            "2025-12-02 17:15:08 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-12-02 17:15:08 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 26.43 seconds\n",
            "2025-12-02 17:15:08 - ras_commander.RasCmdr - INFO - Plan 03 executed in worker 2: Successful\n",
            "2025-12-02 17:15:08 - ras_commander.RasCmdr - INFO - Final destination for computed results: c:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\n",
            "2025-12-02 17:15:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\\Muncie.rasmap\n",
            "2025-12-02 17:15:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\\Muncie.rasmap\n",
            "2025-12-02 17:15:13 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-12-02 17:15:13 - ras_commander.RasCmdr - INFO - Plan 01: Successful\n",
            "2025-12-02 17:15:13 - ras_commander.RasCmdr - INFO - Plan 03: Successful\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parallel execution with dynamic worker allocation completed in 31.15 seconds\n",
            "\n",
            "Execution Results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>Plan</th>\\n', '      <th>Success</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>True</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>True</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  Plan  Success\n",
              "0   01     True\n",
              "1   03     True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 17:15:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\\Muncie.rasmap\n",
            "2025-12-02 17:15:13 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\compute_test_parallel_dynamic\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initialized dynamic compute project: Muncie\n",
            "Found 3 plans with results:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "  plan_number                                   HDF_Results_Path\n",
              "0          01  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "1          03  C:\\GH\\ras-commander\\examples\\example_projects\\...\n",
              "2          04  C:\\GH\\ras-commander\\examples\\example_projects\\..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Executing plans with dynamic worker allocation...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Create dynamic compute folder if it doesn't exist\n",
        "dynamic_compute_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Define the cores per worker\n",
        "cores_per_worker = 4\n",
        "# 2 cores per worker is the efficiency point for most CPU's, due to L2/L3 cache being shared by 2 cores in most x86 CPU's\n",
        "# 4-8 cores per worker is the maximum performance point for most CPU's, using more compute power to marginally lower runtime \n",
        "# when using parallel compute, 2 cores per worker is typically optimal as it is assumed you are maximizing throughput (efficency) over single-plan runtime (performance)\n",
        "\n",
        "# Calculate the optimal number of workers based on physical cores\n",
        "max_workers = get_optimal_worker_count(cores_per_worker)\n",
        "print(f\"System has {physical_cores} physical cores\")\n",
        "print(f\"With {cores_per_worker} cores per worker, optimal worker count is {max_workers}\")\n",
        "print(f\"Destination folder: {dynamic_compute_folder}\")\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute all plans with dynamic worker allocation\n",
        "results_dynamic = RasCmdr.compute_parallel(\n",
        "    plan_number=specific_plans,\n",
        "    max_workers=max_workers,\n",
        "    num_cores=cores_per_worker,\n",
        "    dest_folder=dynamic_compute_folder,\n",
        "    overwrite_dest=True,\n",
        "    ras_object=source_project\n",
        ")\n",
        "\n",
        "# Record end time and calculate duration\n",
        "end_time = time.time()\n",
        "dynamic_duration = end_time - start_time\n",
        "\n",
        "print(f\"Parallel execution with dynamic worker allocation completed in {dynamic_duration:.2f} seconds\")\n",
        "\n",
        "# Create a DataFrame from the execution results for better visualization\n",
        "dynamic_results_df = pd.DataFrame([\n",
        "    {\"Plan\": plan, \"Success\": success}\n",
        "    for plan, success in results_dynamic.items()\n",
        "])\n",
        "\n",
        "# Sort by plan number\n",
        "dynamic_results_df = dynamic_results_df.sort_values(\"Plan\")\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nExecution Results:\")\n",
        "display.display(dynamic_results_df)\n",
        "\n",
        "# Initialize a RAS project in the dynamic compute folder\n",
        "dynamic_compute_project = RasPrj()\n",
        "init_ras_project(dynamic_compute_folder, \"6.6\", ras_object=dynamic_compute_project)\n",
        "print(f\"\\nInitialized dynamic compute project: {dynamic_compute_project.project_name}\")\n",
        "\n",
        "# Check which plans have results\n",
        "dynamic_plans_with_results = dynamic_compute_project.plan_df[dynamic_compute_project.plan_df['HDF_Results_Path'].notna()]\n",
        "print(f\"Found {len(dynamic_plans_with_results)} plans with results:\")\n",
        "display.display(dynamic_plans_with_results[['plan_number', 'HDF_Results_Path']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Comparison\n",
        "\n",
        "Let's compare the performance of the different parallel execution approaches we've tried. This will help us understand the impact of worker count and plan selection on execution time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:44:25.609864Z",
          "iopub.status.busy": "2025-11-17T18:44:25.609467Z",
          "iopub.status.idle": "2025-11-17T18:44:25.764162Z",
          "shell.execute_reply": "2025-11-17T18:44:25.763452Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a DataFrame for individual plan runtimes\n",
        "plan_data = []\n",
        "\n",
        "# Define the approaches with more descriptive labels including worker and core counts\n",
        "approach_labels = {\n",
        "    \"all_plans\": \"All Plans (2 workers \u00d7 2 cores = 4 cores total)\",\n",
        "    \"specific_plans\": \"Specific Plans (1 worker \u00d7 2 cores = 2 cores total)\",\n",
        "    \"dynamic_workers\": f\"Dynamic Workers (1 worker \u00d7 4 cores = 4 cores total)\"\n",
        "}\n",
        "\n",
        "# Extract runtimes from the log messages\n",
        "# For all plans approach\n",
        "plan_data.append({\"Approach\": approach_labels[\"all_plans\"], \"Plan\": \"01\", \"Runtime\": 35.72})\n",
        "plan_data.append({\"Approach\": approach_labels[\"all_plans\"], \"Plan\": \"03\", \"Runtime\": 82.70})\n",
        "# Omitting plan 04 as it's a 1D model\n",
        "\n",
        "# For specific plans approach (plans 01 and 03 were run)\n",
        "plan_data.append({\"Approach\": approach_labels[\"specific_plans\"], \"Plan\": \"01\", \"Runtime\": 29.10})\n",
        "plan_data.append({\"Approach\": approach_labels[\"specific_plans\"], \"Plan\": \"03\", \"Runtime\": 36.09})\n",
        "\n",
        "# For dynamic worker approach (plans 01 and 03 were run)\n",
        "plan_data.append({\"Approach\": approach_labels[\"dynamic_workers\"], \"Plan\": \"01\", \"Runtime\": 28.48})\n",
        "plan_data.append({\"Approach\": approach_labels[\"dynamic_workers\"], \"Plan\": \"03\", \"Runtime\": 49.43})\n",
        "\n",
        "# Create a DataFrame\n",
        "plan_runtime_df = pd.DataFrame(plan_data)\n",
        "\n",
        "# Create a grouped bar chart for plan runtimes\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Get all unique plan numbers and ensure they're sorted\n",
        "plans = sorted(plan_runtime_df[\"Plan\"].unique())\n",
        "\n",
        "# Create x positions for the bars\n",
        "x = np.arange(len(plans))\n",
        "width = 0.25  # Width of the bars\n",
        "\n",
        "# Plot bars for each approach\n",
        "approaches = plan_runtime_df[\"Approach\"].unique()\n",
        "for i, approach in enumerate(approaches):\n",
        "    # Filter data for this approach\n",
        "    approach_data = plan_runtime_df[plan_runtime_df[\"Approach\"] == approach]\n",
        "    \n",
        "    # Initialize runtimes array with NaN values\n",
        "    runtimes = [np.nan] * len(plans)\n",
        "    \n",
        "    # Fill in runtimes where data exists\n",
        "    for j, plan in enumerate(plans):\n",
        "        plan_runtime = approach_data[approach_data[\"Plan\"] == plan][\"Runtime\"]\n",
        "        if not plan_runtime.empty:\n",
        "            runtimes[j] = plan_runtime.values[0]\n",
        "    \n",
        "    # Create bars for this approach (only where we have data)\n",
        "    valid_indices = [idx for idx, val in enumerate(runtimes) if not np.isnan(val)]\n",
        "    valid_plans = [plans[idx] for idx in valid_indices]\n",
        "    valid_runtimes = [runtimes[idx] for idx in valid_indices]\n",
        "    valid_positions = [x[idx] + (i - len(approaches)/2 + 0.5) * width for idx in valid_indices]\n",
        "    \n",
        "    # Plot the bars\n",
        "    bars = plt.bar(valid_positions, valid_runtimes, width, label=approach)\n",
        "    \n",
        "    # Add runtime labels on top of bars\n",
        "    for pos, runtime in zip(valid_positions, valid_runtimes):\n",
        "        plt.text(pos, runtime + 2, f\"{runtime:.1f}s\", ha='center', va='bottom')\n",
        "\n",
        "# Add labels, title, and custom x-axis tick labels\n",
        "plt.xlabel('Plan Number', fontsize=12)\n",
        "plt.ylabel('Runtime (seconds)', fontsize=12)\n",
        "plt.title('Runtime Comparison by Plan Number and Parallelization Approach', fontsize=14)\n",
        "plt.xticks(x, plans, fontsize=11)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add note about omitting Plan 04\n",
        "plt.figtext(0.5, 0.01, \"\\nNote: Plan 04 (1D model) is omitted from this comparison\", \n",
        "            ha='center', fontsize=10, style='italic')\n",
        "\n",
        "# Ensure all plan numbers show on x-axis regardless of data availability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Parallel Plan Execution\n",
        "\n",
        "In this notebook, we've explored how to execute HEC-RAS plans in parallel using the RAS Commander library. Here's a summary of the key techniques we've covered:\n",
        "\n",
        "1. **Basic Parallel Execution**: Using `RasCmdr.compute_parallel()` to run all plans in a project simultaneously\n",
        "2. **Selective Parallel Execution**: Running only specific plans in parallel\n",
        "3. **Dynamic Worker Allocation**: Determining the optimal number of workers based on available system resources\n",
        "4. **Performance Analysis**: Comparing execution times for different parallel configurations\n",
        "5. **Advanced Parallel Workflows**: Building complex workflows with parallel execution for sensitivity analysis\n",
        "\n",
        "### Key Functions Used\n",
        "\n",
        "- `RasCmdr.compute_parallel()`: Execute multiple plans in parallel\n",
        "- `RasPlan.clone_plan()`: Create a new plan based on an existing one\n",
        "- `RasPlan.update_plan_description()`: Update the description of a plan\n",
        "- `RasPlan.set_num_cores()`: Set the number of cores for a plan to use\n",
        "- `RasPlan.get_results_path()`: Get the path to the results file for a plan\n",
        "\n",
        "### Best Practices for Parallel Execution\n",
        "\n",
        "1. **Use Separate RAS Objects**: Create and use separate RAS objects for different projects or folders\n",
        "2. **Balance Workers and Cores**: Find the right balance between the number of workers and cores per worker\n",
        "3. **Consider Hardware Limits**: Be mindful of your system's physical cores and memory\n",
        "4. **Use Clean Compute Folders**: Use the `dest_folder` parameter to keep your project organized\n",
        "5. **Handle Overwrite Carefully**: Use `overwrite_dest=True` for repeatable workflows, but be cautious about losing results\n",
        "6. **Monitor Performance**: Track execution times and adjust your configuration for optimal performance\n",
        "7. **Match Workers to Plans**: For best results, use one worker per plan when running a small number of plans\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\09_plan_parameter_operations.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:05.817940Z",
          "iopub.status.busy": "2025-11-17T17:40:05.817734Z",
          "iopub.status.idle": "2025-11-17T17:40:07.078302Z",
          "shell.execute_reply": "2025-11-17T17:40:07.077768Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.080820Z",
          "iopub.status.busy": "2025-11-17T17:40:07.080531Z",
          "iopub.status.idle": "2025-11-17T17:40:07.084395Z",
          "shell.execute_reply": "2025-11-17T17:40:07.083885Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.086295Z",
          "iopub.status.busy": "2025-11-17T17:40:07.086112Z",
          "iopub.status.idle": "2025-11-17T17:40:07.136217Z",
          "shell.execute_reply": "2025-11-17T17:40:07.135731Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract the Bald Eagle Creek example project\n",
        "# The extract_project method downloads the project from GitHub if not already present,\n",
        "# and extracts it to the example_projects folder\n",
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(f\"Extracted project to: {bald_eagle_path}\")  \n",
        "\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Plan Files in HEC-RAS\n",
        "\n",
        "Before we dive into the operations, let's understand what HEC-RAS plan files are and why they're important:\n",
        "\n",
        "### What is a Plan File?\n",
        "\n",
        "A HEC-RAS plan file (`.p*`) is a configuration file that defines how a hydraulic simulation will run. It links together:\n",
        "\n",
        "1. **Geometry**: River channel and floodplain physical characteristics (`.g*` files)\n",
        "2. **Flow Data**: Inflow conditions, either steady (`.f*`) or unsteady (`.u*`)\n",
        "3. **Simulation Parameters**: Time steps, computational methods, and output settings\n",
        "\n",
        "### Key Components of Plan Files\n",
        "\n",
        "Plan files contain many parameters that control simulation behavior:\n",
        "\n",
        "- **Simulation Type**: Steady, unsteady, sediment transport, water quality\n",
        "- **Computation Intervals**: Time steps for calculations\n",
        "- **Output Intervals**: How frequently results are saved\n",
        "- **Run Flags**: Which modules to execute (preprocessor, postprocessor, etc.)\n",
        "- **Simulation Period**: Start and end dates for unsteady simulations\n",
        "- **Computation Methods**: Numerical schemes and solver settings\n",
        "- **Resource Allocation**: Number of CPU cores to use\n",
        "\n",
        "### Why Automate Plan Operations?\n",
        "\n",
        "Automating plan operations with RAS Commander allows you to:\n",
        "\n",
        "1. **Batch Processing**: Run multiple scenarios with different parameters\n",
        "2. **Sensitivity Analysis**: Systematically vary parameters to assess their impact\n",
        "3. **Calibration**: Adjust parameters to match observed data\n",
        "4. **Consistency**: Ensure standardized settings across multiple models\n",
        "5. **Documentation**: Programmatically track simulation configurations\n",
        "\n",
        "Now, let's download and extract an example project to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.138031Z",
          "iopub.status.busy": "2025-11-17T17:40:07.137864Z",
          "iopub.status.idle": "2025-11-17T17:40:07.175189Z",
          "shell.execute_reply": "2025-11-17T17:40:07.174773Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create a RasExamples instance\n",
        "ras_examples = RasExamples()\n",
        "\n",
        "# Extract the Bald Eagle Creek example project\n",
        "extracted_paths = ras_examples.extract_project([\"Balde Eagle Creek\"])\n",
        "print(f\"Extracted project to: {extracted_paths}\")\n",
        "\n",
        "# Verify the path exists\n",
        "print(f\"Bald Eagle Creek project exists: {bald_eagle_path.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Project Initialization\n",
        "\n",
        "The first step in any RAS Commander workflow is initializing the HEC-RAS project. This connects the Python environment to the HEC-RAS project files.\n",
        "\n",
        "The `init_ras_project()` function does the following:\n",
        "\n",
        "1. Locates the main project file (`.prj`)\n",
        "2. Reads all associated files (plans, geometries, flows)\n",
        "3. Creates dataframes containing project components\n",
        "4. Sets up the connection to the HEC-RAS executable\n",
        "\n",
        "Let's initialize our project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.176898Z",
          "iopub.status.busy": "2025-11-17T17:40:07.176729Z",
          "iopub.status.idle": "2025-11-17T17:40:07.207883Z",
          "shell.execute_reply": "2025-11-17T17:40:07.207371Z"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize the project (using the default global ras object)\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized project: {ras.project_name}\")\n",
        "\n",
        "# Display basic project information\n",
        "print(\"\\nProject Overview:\")\n",
        "print(f\"Project Folder: {ras.project_folder}\")\n",
        "print(f\"Project File: {ras.prj_file}\")\n",
        "print(f\"Number of Plan Files: {len(ras.plan_df)}\")\n",
        "print(f\"Number of Geometry Files: {len(ras.geom_df)}\")\n",
        "print(f\"Number of Flow Files: {len(ras.flow_df)}\")\n",
        "print(f\"Number of Unsteady Files: {len(ras.unsteady_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also take a look at the plan files in this project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.209780Z",
          "iopub.status.busy": "2025-11-17T17:40:07.209638Z",
          "iopub.status.idle": "2025-11-17T17:40:07.223694Z",
          "shell.execute_reply": "2025-11-17T17:40:07.223174Z"
        }
      },
      "outputs": [],
      "source": [
        "# Display the plan files\n",
        "print(\"Plan Files in Project:\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.225775Z",
          "iopub.status.busy": "2025-11-17T17:40:07.225425Z",
          "iopub.status.idle": "2025-11-17T17:40:07.228598Z",
          "shell.execute_reply": "2025-11-17T17:40:07.228091Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get the first plan number for our examples\n",
        "plan_number = ras.plan_df['plan_number'].iloc[0]\n",
        "print(f\"\\nWe'll work with Plan: {plan_number}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Updating Run Flags\n",
        "\n",
        "Run flags in HEC-RAS control which components of the simulation are executed. The `RasPlan.update_run_flags()` method allows you to modify these flags programmatically.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number_or_path` (str or Path): The plan number or full path to the plan file\n",
        "- `geometry_preprocessor` (bool, optional): Whether to run the geometry preprocessor\n",
        "- `unsteady_flow_simulation` (bool, optional): Whether to run the unsteady flow simulation\n",
        "- `run_sediment` (bool, optional): Whether to run sediment transport calculations\n",
        "- `post_processor` (bool, optional): Whether to run the post-processor\n",
        "- `floodplain_mapping` (bool, optional): Whether to run floodplain mapping\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "\n",
        "### Common Run Flags\n",
        "\n",
        "1. **Geometry Preprocessor**: Computes hydraulic tables from geometry data\n",
        "   - `True`: Recompute tables (useful after geometry changes)\n",
        "   - `False`: Use existing tables (faster but may be outdated)\n",
        "\n",
        "2. **Unsteady Flow Simulation**: The main hydraulic calculations\n",
        "   - `True`: Run unsteady flow calculations\n",
        "   - `False`: Skip unsteady flow calculations\n",
        "\n",
        "3. **Sediment Transport**: Simulates erosion and deposition\n",
        "   - `True`: Calculate sediment transport\n",
        "   - `False`: Skip sediment transport\n",
        "\n",
        "4. **Post-Processor**: Calculates additional variables from results\n",
        "   - `True`: Run post-processing (recommended)\n",
        "   - `False`: Skip post-processing (faster but fewer outputs)\n",
        "\n",
        "5. **Floodplain Mapping**: Generates inundation maps\n",
        "   - `True`: Generate maps (requires terrain data)\n",
        "   - `False`: Skip mapping (faster)\n",
        "\n",
        "Let's update the run flags for our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.230333Z",
          "iopub.status.busy": "2025-11-17T17:40:07.230194Z",
          "iopub.status.idle": "2025-11-17T17:40:07.238230Z",
          "shell.execute_reply": "2025-11-17T17:40:07.237677Z"
        }
      },
      "outputs": [],
      "source": [
        "# Update run flags for the plan\n",
        "print(f\"Updating run flags for plan {plan_number}...\")\n",
        "RasPlan.update_run_flags(\n",
        "    \"01\",\n",
        "    geometry_preprocessor=False,     # This may result in a popup if preprocessor files are not present\n",
        "    unsteady_flow_simulation=False,   # Run the main hydraulic calculations\n",
        "    run_sediment=False,              # Skip sediment transport calculations\n",
        "    post_processor=False,             # Run post-processing for additional outputs\n",
        "    floodplain_mapping=True,        # Skip floodplain mapping\n",
        ")\n",
        "print(\"Run flags updated successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.240129Z",
          "iopub.status.busy": "2025-11-17T17:40:07.239946Z",
          "iopub.status.idle": "2025-11-17T17:40:07.266901Z",
          "shell.execute_reply": "2025-11-17T17:40:07.266480Z"
        }
      },
      "outputs": [],
      "source": [
        "# The dataframes won't automatically update with changes, so re-init to ensure you are reading the latest version\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "\n",
        "# Display the plan dataframe again to show changes were effective\n",
        "print(\"Plan Files in Project:\")\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.268595Z",
          "iopub.status.busy": "2025-11-17T17:40:07.268452Z",
          "iopub.status.idle": "2025-11-17T17:40:07.273516Z",
          "shell.execute_reply": "2025-11-17T17:40:07.273015Z"
        }
      },
      "outputs": [],
      "source": [
        "plan_path = RasPlan.get_plan_path(\"01\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.275164Z",
          "iopub.status.busy": "2025-11-17T17:40:07.275034Z",
          "iopub.status.idle": "2025-11-17T17:40:07.277707Z",
          "shell.execute_reply": "2025-11-17T17:40:07.277250Z"
        }
      },
      "outputs": [],
      "source": [
        "print(plan_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.279943Z",
          "iopub.status.busy": "2025-11-17T17:40:07.279561Z",
          "iopub.status.idle": "2025-11-17T17:40:07.283386Z",
          "shell.execute_reply": "2025-11-17T17:40:07.282845Z"
        }
      },
      "outputs": [],
      "source": [
        "# Print the Plan file's contents to confirm the change\n",
        "\n",
        "# Print the plan file contents to verify the run flag changes\n",
        "with open(plan_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Updating Plan Intervals\n",
        "\n",
        "Time intervals in HEC-RAS control the temporal resolution of simulations and outputs. The `RasPlan.update_plan_intervals()` method allows you to modify these intervals.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number_or_path` (str or Path): The plan number or full path to the plan file\n",
        "- `computation_interval` (str, optional): Time step for calculations\n",
        "- `output_interval` (str, optional): Time step for saving detailed results\n",
        "- `instantaneous_interval` (str, optional): Time step for peak value calculations\n",
        "- `mapping_interval` (str, optional): Time step for map outputs\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "\n",
        "### Valid Interval Values\n",
        "\n",
        "Time intervals must be specified in HEC-RAS format:\n",
        "- Seconds: `1SEC`, `2SEC`, `3SEC`, `4SEC`, `5SEC`, `6SEC`, `10SEC`, `15SEC`, `20SEC`, `30SEC`\n",
        "- Minutes: `1MIN`, `2MIN`, `3MIN`, `4MIN`, `5MIN`, `6MIN`, `10MIN`, `15MIN`, `20MIN`, `30MIN`\n",
        "- Hours: `1HOUR`, `2HOUR`, `3HOUR`, `4HOUR`, `6HOUR`, `8HOUR`, `12HOUR`\n",
        "- Days: `1DAY`\n",
        "\n",
        "### Interval Types\n",
        "\n",
        "1. **Computation Interval**: Time step used for hydraulic calculations\n",
        "   - Smaller intervals: More accurate but slower\n",
        "   - Larger intervals: Faster but may introduce numerical errors\n",
        "   - Rule of thumb: Should be small enough to capture flow changes\n",
        "\n",
        "2. **Output Interval**: How frequently detailed results are saved\n",
        "   - Smaller intervals: More detailed results but larger files\n",
        "   - Larger intervals: Smaller files but less temporal resolution\n",
        "   - Usually larger than computation interval\n",
        "\n",
        "3. **Instantaneous Interval**: Time step for peak value calculations\n",
        "   - Affects when max/min values are checked\n",
        "   - Usually equal to output interval\n",
        "\n",
        "4. **Mapping Interval**: How frequently map data is saved\n",
        "   - Affects animation smoothness and file size\n",
        "   - Usually larger than output interval\n",
        "\n",
        "Let's update the intervals for our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.285664Z",
          "iopub.status.busy": "2025-11-17T17:40:07.285256Z",
          "iopub.status.idle": "2025-11-17T17:40:07.293214Z",
          "shell.execute_reply": "2025-11-17T17:40:07.292712Z"
        }
      },
      "outputs": [],
      "source": [
        "# Update plan intervals\n",
        "print(f\"Updating intervals for plan {plan_number}...\")\n",
        "RasPlan.update_plan_intervals(\n",
        "    plan_number,\n",
        "    computation_interval=\"5SEC\",    # 5-second time step for calculations\n",
        "    output_interval=\"1MIN\",         # Save detailed results every minute\n",
        "    instantaneous_interval=\"5MIN\",  # Check for max/min values every 5 minutes\n",
        "    mapping_interval=\"15MIN\",       # Save map data every 15 minutes\n",
        "\n",
        ")\n",
        "print(\"Plan intervals updated successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Managing Plan Descriptions\n",
        "\n",
        "Plan descriptions provide documentation for simulation configurations. The RAS Commander library offers methods to read and update these descriptions.\n",
        "\n",
        "### Reading Descriptions\n",
        "\n",
        "The `RasPlan.read_plan_description()` method retrieves the current description from a plan file.\n",
        "\n",
        "#### Parameters\n",
        "- `plan_number_or_path` (str or Path): The plan number or full path to the plan file\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "\n",
        "### Updating Descriptions\n",
        "\n",
        "The `RasPlan.update_plan_description()` method sets a new description for a plan file.\n",
        "\n",
        "#### Parameters\n",
        "- `plan_number_or_path` (str or Path): The plan number or full path to the plan file\n",
        "- `description` (str): The new description text\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "\n",
        "### Best Practices for Plan Descriptions\n",
        "\n",
        "Effective plan descriptions should include:\n",
        "1. Purpose of the simulation\n",
        "2. Key parameters and settings\n",
        "3. Date of creation or modification\n",
        "4. Author or organization\n",
        "5. Any special considerations or notes\n",
        "\n",
        "Let's read the current description and then update it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.295204Z",
          "iopub.status.busy": "2025-11-17T17:40:07.295049Z",
          "iopub.status.idle": "2025-11-17T17:40:07.325513Z",
          "shell.execute_reply": "2025-11-17T17:40:07.324993Z"
        }
      },
      "outputs": [],
      "source": [
        "# Read the current plan description\n",
        "current_description = RasPlan.read_plan_description(plan_number)\n",
        "print(f\"Current plan description:\\n{current_description}\")\n",
        "\n",
        "# Create a new description with detailed information\n",
        "new_description = f\"\"\"Modified Plan for RAS Commander Testing\n",
        "Date: {datetime.now().strftime('%Y-%m-%d')}\n",
        "Purpose: Demonstrating RAS Commander plan operations\n",
        "Settings:\n",
        "- Computation Interval: 5SEC\n",
        "- Output Interval: 1MIN\n",
        "- Mapping Interval: 15MIN\n",
        "- Geometry Preprocessor: Enabled\n",
        "- Post-Processor: Enabled\n",
        "Notes: This plan was automatically modified using ras-commander.\"\"\"\n",
        "\n",
        "# Update the plan description\n",
        "print(\"\\nUpdating plan description...\")\n",
        "RasPlan.update_plan_description(plan_number, new_description)\n",
        "print(\"Plan description updated successfully\")\n",
        "\n",
        "# Verify the updated description\n",
        "updated_description = RasPlan.read_plan_description(plan_number)\n",
        "print(f\"\\nUpdated plan description:\\n{updated_description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Updating Simulation Dates\n",
        "\n",
        "For unsteady flow simulations, the simulation period defines the time window for the analysis. The `RasPlan.update_simulation_date()` method allows you to modify this period.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number_or_path` (str or Path): The plan number or full path to the plan file\n",
        "- `start_date` (datetime): The start date and time for the simulation\n",
        "- `end_date` (datetime): The end date and time for the simulation\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "\n",
        "### Considerations for Simulation Dates\n",
        "\n",
        "1. **Hydrograph Coverage**: The simulation period should fully encompass your hydrographs\n",
        "2. **Warm-Up Period**: Include time before the main event for model stabilization\n",
        "3. **Cool-Down Period**: Include time after the main event for complete drainage\n",
        "4. **Computational Efficiency**: Avoid unnecessarily long periods to reduce runtime\n",
        "5. **Consistency**: Ensure dates match available boundary condition data\n",
        "\n",
        "Let's update the simulation dates for our plan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.327353Z",
          "iopub.status.busy": "2025-11-17T17:40:07.327204Z",
          "iopub.status.idle": "2025-11-17T17:40:07.350086Z",
          "shell.execute_reply": "2025-11-17T17:40:07.349576Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get the current simulation date\n",
        "current_sim_date = RasPlan.get_plan_value(plan_number, \"Simulation Date\")\n",
        "print(f\"Current simulation date: {current_sim_date}\")\n",
        "\n",
        "# Parse the current simulation date string\n",
        "current_dates = current_sim_date.split(\",\")\n",
        "current_start = datetime.strptime(f\"{current_dates[0]},{current_dates[1]}\", \"%d%b%Y,%H%M\")\n",
        "current_end = datetime.strptime(f\"{current_dates[2]},{current_dates[3]}\", \"%d%b%Y,%H%M\")\n",
        "\n",
        "# Define new simulation period - adjust by 1 hour from current dates\n",
        "start_date = current_start + timedelta(hours=1)  # Current start + 1 hour\n",
        "end_date = current_end - timedelta(hours=1)      # Current end - 1 hour\n",
        "\n",
        "# Update the simulation date\n",
        "print(f\"\\nUpdating simulation period to: {start_date.strftime('%d%b%Y,%H%M')} - {end_date.strftime('%d%b%Y,%H%M')}\")\n",
        "RasPlan.update_simulation_date(plan_number, start_date, end_date)\n",
        "print(\"Simulation dates updated successfully\")\n",
        "\n",
        "# Verify the updated simulation date\n",
        "updated_sim_date = RasPlan.get_plan_value(plan_number, \"Simulation Date\")\n",
        "print(f\"\\nUpdated simulation date: {updated_sim_date}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Verifying Updated Plan Values\n",
        "\n",
        "After making multiple changes to a plan, it's a good practice to verify that all updates were applied correctly. Let's check the updated values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.352653Z",
          "iopub.status.busy": "2025-11-17T17:40:07.352343Z",
          "iopub.status.idle": "2025-11-17T17:40:07.355587Z",
          "shell.execute_reply": "2025-11-17T17:40:07.355204Z"
        }
      },
      "outputs": [],
      "source": [
        "# Print the Plan file's contents to confirm the change\n",
        "\n",
        "# Print the plan file contents to verify the run flag changes\n",
        "with open(plan_path, 'r') as f:\n",
        "    print(f.read())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Computing the Plan (Optional)\n",
        "\n",
        "After making changes to a plan, you might want to run the simulation to see the effects. The `RasCmdr.compute_plan()` method executes a HEC-RAS simulation with the specified plan.\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- `plan_number` (str): The plan number to execute\n",
        "- `dest_folder` (str, Path, optional): Destination folder for computation\n",
        "- `rasect` (RasPrj, optional): The RAS project object\n",
        "- `clear_geompre` (bool, optional): Whether to clear geometry preprocessor files\n",
        "- `num_cores` (int, optional): Number of processor cores to use\n",
        "- `overwrite_dest` (bool, optional): Whether to overwrite the destination folder\n",
        "\n",
        "If you want to run the simulation, you can uncomment the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:40:07.357493Z",
          "iopub.status.busy": "2025-11-17T17:40:07.357316Z",
          "iopub.status.idle": "2025-11-17T17:43:08.694598Z",
          "shell.execute_reply": "2025-11-17T17:43:08.694040Z"
        }
      },
      "outputs": [],
      "source": [
        "RasCmdr.compute_plan(plan_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:08.697362Z",
          "iopub.status.busy": "2025-11-17T17:43:08.697074Z",
          "iopub.status.idle": "2025-11-17T17:43:08.703989Z",
          "shell.execute_reply": "2025-11-17T17:43:08.703353Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to run the simulation with the updated plan\n",
        "\n",
        "# # Define a destination folder for the computation\n",
        "# dest_folder = script_dir / \"compute_results\"\n",
        "# print(f\"Computing plan {plan_number}...\")\n",
        "# print(f\"Results will be saved to: {dest_folder}\")\n",
        "\n",
        "# # Execute the plan\n",
        "# success = RasCmdr.compute_plan(\n",
        "#     plan_number,\n",
        "#     dest_folder=dest_folder,\n",
        "#     clear_geompre=True,    # Clear preprocessor files to ensure clean results\n",
        "#     num_cores=2,           # Use 2 processor cores\n",
        "#     overwrite_dest=True,   # Overwrite existing destination folder\n",
        "#     rasect=ras\n",
        "# )\n",
        "\n",
        "# if success:\n",
        "#     print(f\"Plan {plan_number} computed successfully\")\n",
        "#     # Check for results file\n",
        "#     results_path = RasPlan.get_results_path(plan_number)\n",
        "#     if results_path:\n",
        "#         print(f\"Results saved to: {results_path}\")\n",
        "# else:\n",
        "#     print(f\"Failed to compute plan {plan_number}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Plan Key Operations\n",
        "\n",
        "In this notebook, we've covered the essential operations for manipulating HEC-RAS plan files programmatically using RAS Commander:\n",
        "\n",
        "1. **Project Initialization**: We initialized a HEC-RAS project using `init_ras_project()`\n",
        "2. **Plan Values**: We retrieved plan values with `RasPlan.get_plan_value()`\n",
        "3. **Run Flags**: We updated simulation components with `RasPlan.update_run_flags()`\n",
        "4. **Plan Intervals**: We modified time steps with `RasPlan.update_plan_intervals()`\n",
        "5. **Plan Descriptions**: We managed documentation with `RasPlan.read_plan_description()` and `RasPlan.update_plan_description()`\n",
        "6. **Simulation Dates**: We changed the analysis period with `RasPlan.update_simulation_date()`\n",
        "7. **Verification**: We verified our changes by comparing initial and updated values\n",
        "\n",
        "### Key Classes and Functions Used\n",
        "\n",
        "- `RasPlan`: The main class for plan operations\n",
        "  - `get_plan_value()`: Retrieve specific values from plan files\n",
        "  - `update_run_flags()`: Configure which components will run\n",
        "  - `update_plan_intervals()`: Set computation and output time intervals\n",
        "  - `read_plan_description()`: Get the current plan description\n",
        "  - `update_plan_description()`: Set a new plan description\n",
        "  - `update_simulation_date()`: Modify the simulation period\n",
        "  - `get_results_path()`: Get the path to results files\n",
        "\n",
        "- `RasCmdr`: The class for executing HEC-RAS simulations\n",
        "  - `compute_plan()`: Run a single plan simulation\n",
        "\n",
        "### Best Practices for Plan Operations\n",
        "\n",
        "1. **Verify Before Updating**: Always check current values before making changes\n",
        "2. **Document Changes**: Use descriptive plan descriptions to track modifications\n",
        "3. **Maintain Consistency**: Ensure flow data matches simulation dates\n",
        "4. **Use Appropriate Intervals**: Balance accuracy and computational efficiency\n",
        "5. **Backup Original Files**: Use destination folders when running simulations\n",
        "6. **Verify After Updates**: Confirm that all changes were applied correctly\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "With these plan operations, you can now:\n",
        "\n",
        "1. **Create Batch Workflows**: Process multiple scenarios with different parameters\n",
        "2. **Perform Sensitivity Analysis**: Systematically vary parameters to assess their impact\n",
        "3. **Automate Calibration**: Adjust parameters to match observed data\n",
        "4. **Build Model Ensembles**: Run multiple configurations for uncertainty analysis\n",
        "5. **Integrate with Other Tools**: Connect HEC-RAS to broader modeling frameworks\n",
        "\n",
        "These operations form the foundation for advanced HEC-RAS automation using the RAS Commander library."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\101_Core_Sensitivity.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "import xarray as xr\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14_Core_Sensitivity.ipynb\n",
        "Testing Core Sensitivity for RAS using the Bald Eagle Creek Multi-Gage 2D project.  \n",
        "\n",
        "\n",
        "This should take around 15-45 minutes to run depending on your hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Found zip file: d:\\GitHub\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n",
            "2025-04-09 08:50:59 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n",
            "2025-04-09 08:51:01 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 08:51:01 - ras_commander.RasPrj - INFO - Initializing global 'ras' object via init_ras_project function.\n",
            "2025-04-09 08:51:01 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n",
            "2025-04-09 08:51:01 - ras_commander.RasPrj - INFO - Project initialized. ras_object project folder: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 08:51:01 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:51:01 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:51:01 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n",
            "2025-04-09 08:51:01 - ras_commander.RasUtils - INFO - Constructed plan file path: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:51:01 - ras_commander.RasUtils - INFO - Successfully updated file: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:51:02 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 08:51:02 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-04-09 08:51:02 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"D:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\" \"d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running sensitivity analysis for Plan 03\n",
            "Running with 1 core(s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-09 08:58:06 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-04-09 08:58:06 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 424.31 seconds\n",
            "2025-04-09 08:58:06 - ras_commander.RasUtils - INFO - Constructed plan file path: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:58:06 - ras_commander.RasUtils - INFO - Successfully updated file: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 08:58:06 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 08:58:06 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-04-09 08:58:06 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"D:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\" \"d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time: 424.34 seconds\n",
            "Running with 2 core(s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-09 09:02:18 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-04-09 09:02:18 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 252.47 seconds\n",
            "2025-04-09 09:02:18 - ras_commander.RasUtils - INFO - Constructed plan file path: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 09:02:18 - ras_commander.RasUtils - INFO - Successfully updated file: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 09:02:18 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 09:02:18 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-04-09 09:02:18 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"D:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\" \"d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time: 252.53 seconds\n",
            "Running with 3 core(s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-09 09:06:39 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-04-09 09:06:39 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 260.34 seconds\n",
            "2025-04-09 09:06:39 - ras_commander.RasUtils - INFO - Constructed plan file path: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 09:06:39 - ras_commander.RasUtils - INFO - Successfully updated file: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\n",
            "2025-04-09 09:06:39 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "2025-04-09 09:06:39 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-04-09 09:06:39 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"D:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\" \"d:\\GitHub\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time: 260.38 seconds\n",
            "Running with 4 core(s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-09 09:10:55 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-04-09 09:10:55 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 256.51 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execution time: 256.55 seconds\n",
            "Sensitivity analysis complete\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, RasGeo\n",
        "\n",
        "# Step 1: Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
        "\n",
        "RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
        "\n",
        "# Use Path.cwd() to get the current working directory in a Jupyter Notebook\n",
        "current_directory = Path.cwd()\n",
        "project_path = current_directory / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "\n",
        "# Step 2: Initialize the RAS Project Folder using init_ras_project (from ras_commander)\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "# Step 3: Initialize a DataFrame to store execution results\n",
        "results = []\n",
        "\n",
        "# Step 4: Run sensitivity analysis for Plan 03 with core counts 1-8\n",
        "plan_number = '03'\n",
        "print(f\"Running sensitivity analysis for Plan {plan_number}\")\n",
        "\n",
        "# Clear geompre files before running the plan\n",
        "plan_path = RasPlan.get_plan_path(plan_number)\n",
        "RasGeo.clear_geompre_files(plan_path)\n",
        "\n",
        "for cores in range(1, 5):\n",
        "    print(f\"Running with {cores} core(s)\")\n",
        "    # Set core count for this plan\n",
        "    RasPlan.set_num_cores(plan_number, cores)\n",
        "    \n",
        "    # Time the execution of the plan\n",
        "    start_time = time.time()\n",
        "    RasCmdr.compute_plan(plan_number)\n",
        "    execution_time = time.time() - start_time\n",
        "    \n",
        "    # Store the results\n",
        "    results.append({\n",
        "        \"plan_number\": plan_number,\n",
        "        \"cores\": cores,\n",
        "        \"execution_time\": execution_time\n",
        "    })\n",
        "    \n",
        "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
        "\n",
        "print(\"Sensitivity analysis complete\")\n",
        "\n",
        "# Step 5: Convert results into a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Optionally, save the results to a CSV file\n",
        "results_df.to_csv(\"core_sensitivity_results.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTES FOR REVISIONS:\n",
        "- Use HDF compute summary to show the time for each preprocesS/unsteady compute/postprocess step. \n",
        "- First, run preprocessor and then toggle options to only run unsteady compute and postprocess. \n",
        "- Plot each step separately. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "results_df DataFrame (time is in seconds):\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>cores</th>\\n', '      <th>execution_time</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>3</td>\\n', '      <td>1</td>\\n', '      <td>424.342272</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>3</td>\\n', '      <td>2</td>\\n', '      <td>252.529661</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>3</td>\\n', '      <td>3</td>\\n', '      <td>260.380589</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>3</td>\\n', '      <td>4</td>\\n', '      <td>256.551776</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "   plan_number  cores  execution_time\n",
              "0            3      1      424.342272\n",
              "1            3      2      252.529661\n",
              "2            3      3      260.380589\n",
              "3            3      4      256.551776"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Optionally, load the results from a CSV file\n",
        "results_df = pd.read_csv(\"core_sensitivity_results.csv\")\n",
        "\n",
        "# Display the results dataframe for verification\n",
        "print(\"results_df DataFrame (time is in seconds):\")\n",
        "display(results_df)\n",
        "\n",
        "# Step 6: Calculate unit runtime (based on 1 core execution time)\n",
        "results_df['unit_runtime'] = results_df.groupby('plan_number')['execution_time'].transform(lambda x: x / x.iloc[0])\n",
        "\n",
        "# Get the project name from the ras object\n",
        "project_name = ras.project_name\n",
        "\n",
        "# Step 7: Plot a line chart for unit runtime vs. cores for each plan\n",
        "plt.figure(figsize=(10, 6))\n",
        "for plan in results_df['plan_number'].unique():\n",
        "    plan_data = results_df[results_df['plan_number'] == plan]\n",
        "    plt.plot(plan_data['cores'], plan_data['unit_runtime'], label=f\"Plan {plan}\")\n",
        "\n",
        "plt.xlabel(\"Number of Cores\")\n",
        "plt.ylabel(\"Unit Runtime (Relative to 1 Core)\")\n",
        "plt.title(f\"{project_name} (HEC Example Project)\\nCore Count Sensitivity Analysis\")\n",
        "plt.legend(title=\"Plan Number\")\n",
        "plt.grid(False)\n",
        "plt.vlines([1,2,3,4], ymin=0, ymax=1.2, linestyles='dotted', alpha=0.3)\n",
        "plt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\102_benchmarking_versions_6.1_to_6.6.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "import xarray as xr\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import psutil\n",
        "import platform\n",
        "import cpuinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define versions to compare\n",
        "versions = ['6.6', '6.5', '6.4.1', '6.3.1', '6.3', '6.2', \"6.1\", \"6.0\"] # NOTE: ras-commander does not support versions prior to 6.2 due to HDF5 file format changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract BaldEagleCrkMulti2D project\n",
        "project_path = RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Init the ras_project with ras-commander to read all HEC-RAS project information \n",
        "init_ras_project(project_path, \"6.5\")\n",
        "print(ras)\n",
        "# If no ras object is defined in init_ras_project, it defaults to \"ras\" (useful for single project scripts)\n",
        "# Display plan dataframe\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export Plan Numbers to List and Print\n",
        "plan_numbers = ras.plan_df['plan_number'].tolist()\n",
        "print(plan_numbers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define run_simulation function for\n",
        "import time\n",
        "from ras_commander import RasGeo\n",
        "\n",
        "def run_simulation(version, plan_number):\n",
        "    # Initialize project for the specific version\n",
        "    ras_project = init_ras_project(project_path, str(version))\n",
        "    \n",
        "    # Clear geometry preprocessor files for the plan\n",
        "    plan_path = RasPlan.get_plan_path(plan_number, ras_object=ras_project)\n",
        "    RasGeo.clear_geompre_files(plan_path, ras_object=ras_project)\n",
        "    \n",
        "    # Set the number of cores to 4\n",
        "    RasPlan.set_num_cores(plan_number, \"4\", ras_object=ras_project)\n",
        "    \n",
        "    # Update plan run flags \u2013 setting \"Run HTab\" flag to 1 to force geometry preprocessing\n",
        "    RasPlan.update_run_flags(plan_number, {\"Run HTab\": 1}, ras_object=ras_project)\n",
        "    \n",
        "    # Compute the plan\n",
        "    start_time = time.time()\n",
        "    success = RasCmdr.compute_plan(plan_number, ras_object=ras_project)\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    if success:\n",
        "        # Get the HDF file path for the plan results\n",
        "        hdf_path = RasPlan.get_results_path(plan_number, ras_object=ras_project)\n",
        "        \n",
        "        # Extract runtime data from the HDF file\n",
        "        runtime_data = HdfResultsPlan.get_runtime_data(hdf_path)\n",
        "        \n",
        "        # Extract required information from the runtime data\n",
        "        preprocessor_time = runtime_data['Preprocessing Geometry (hr)'].values[0]\n",
        "        unsteady_compute_time = runtime_data['Unsteady Flow Computations (hr)'].values[0]\n",
        "        \n",
        "        # Get volume accounting data from the HDF file\n",
        "        volume_accounting = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
        "        # Extract Error Percent from the DataFrame\n",
        "        volume_error = volume_accounting['Error Percent'].values[0] if not volume_accounting.empty else None\n",
        "        \n",
        "        # Print the extracted data\n",
        "        print(f\"\\nExtracted Data for Plan {plan_number} in Version {version}:\")\n",
        "        print(f\"Preprocessor Time: {preprocessor_time:.3f} hr\")\n",
        "        print(f\"Unsteady Compute Time: {unsteady_compute_time:.3f} hr\") \n",
        "        print(f\"Volume Error: {volume_error:.3f}%\" if volume_error is not None else \"Volume Error: None\")\n",
        "        print(f\"Total Time: {total_time/3600:.3f} hr\\n\")\n",
        "        \n",
        "        return {\n",
        "            'Version': version,\n",
        "            'Plan': plan_number,\n",
        "            'Preprocessor Time (hr)': preprocessor_time,\n",
        "            'Unsteady Compute Time (hr)': unsteady_compute_time,\n",
        "            'Volume Error (%)': volume_error,\n",
        "            'Total Time (hr)': total_time / 3600  # convert seconds to hours\n",
        "        }\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the plan number you want to run across all versions\n",
        "plan_number = '02'  # Make sure this is a string and include the leading zero\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run simulations for all versions with plan_number defined by user\n",
        "results = []\n",
        "for version in versions:\n",
        "    print(f\"Running simulation for Version {version}, Plan {plan_number}\")\n",
        "    result = run_simulation(version, plan_number) \n",
        "    if result is not None:  # Check if result is not None\n",
        "        results.append(result)\n",
        "        print(f\"Completed: Version {version}, Plan {plan_number}\")\n",
        "    else:\n",
        "        print(f\"Failed: Version {version}, Plan {plan_number}\")\n",
        "\n",
        "# Create DataFrame from results\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Save initial results to CSV\n",
        "df.to_csv('save_initial_results.csv', index=False)\n",
        "\n",
        "print(\"Initial results saved to 'save_initial_results.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create line graphs\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Unsteady Runtime vs Version\n",
        "plt.subplot(1, 2, 1)\n",
        "# Convert Version to categorical type to handle string versions properly\n",
        "plt.plot(pd.Categorical(df['Version']), df['Unsteady Compute Time (hr)'], marker='o')\n",
        "plt.title(f'Unsteady Runtime vs HEC-RAS Version (Plan {plan_number})')\n",
        "plt.xlabel('HEC-RAS Version')\n",
        "plt.ylabel('Unsteady Runtime (hours)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Volume Error vs Version\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(pd.Categorical(df['Version']), df['Volume Error (%)'], marker='o')\n",
        "plt.title(f'Volume Error vs HEC-RAS Version (Plan {plan_number})')\n",
        "plt.xlabel('HEC-RAS Version')\n",
        "plt.ylabel('Volume Error (%)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Benchmark all plans with 2 cores in HEC-RAS 6.6\n",
        "results_2core = []\n",
        "\n",
        "# Loop through each plan number\n",
        "for plan in plan_numbers:\n",
        "    print(f\"Running simulation for Version 6.6, Plan {plan} with 2 cores\")\n",
        "    \n",
        "    # Initialize project for 6.6\n",
        "    ras_project = init_ras_project(project_path, \"6.6\")\n",
        "    \n",
        "    # Clear geometry preprocessor files\n",
        "    plan_path = RasPlan.get_plan_path(plan, ras_object=ras_project)\n",
        "    RasGeo.clear_geompre_files(plan_path, ras_object=ras_project)\n",
        "    \n",
        "    # Set number of cores to 2\n",
        "    RasPlan.set_num_cores(plan, \"2\", ras_object=ras_project)\n",
        "    \n",
        "    # Update plan run flags\n",
        "    RasPlan.update_run_flags(plan, {\"Run HTab\": 1}, ras_object=ras_project)\n",
        "    \n",
        "    # Compute the plan\n",
        "    start_time = time.time()\n",
        "    success = RasCmdr.compute_plan(plan, ras_object=ras_project)\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    if success:\n",
        "        # Get HDF file path\n",
        "        hdf_path = RasPlan.get_results_path(plan, ras_object=ras_project)\n",
        "        \n",
        "        # Extract runtime data\n",
        "        runtime_data = HdfResultsPlan.get_runtime_data(hdf_path)\n",
        "        preprocessor_time = runtime_data['Preprocessing Geometry (hr)'].values[0]\n",
        "        unsteady_compute_time = runtime_data['Unsteady Flow Computations (hr)'].values[0]\n",
        "        \n",
        "        # Get volume accounting\n",
        "        volume_accounting = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
        "        volume_error = volume_accounting['Error Percent'].values[0] if not volume_accounting.empty else None\n",
        "        \n",
        "        result = {\n",
        "            'Plan': plan,\n",
        "            'Preprocessor Time (hr)': preprocessor_time,\n",
        "            'Unsteady Compute Time (hr)': unsteady_compute_time,\n",
        "            'Volume Error (%)': volume_error,\n",
        "            'Total Time (hr)': total_time / 3600\n",
        "        }\n",
        "        results_2core.append(result)\n",
        "        print(f\"Completed: Plan {plan} with 2 cores\")\n",
        "    else:\n",
        "        print(f\"Failed: Plan {plan} with 2 cores\")\n",
        "\n",
        "# Convert results to DataFrame\n",
        "df_2core = pd.DataFrame(results_2core)\n",
        "\n",
        "# Get plan titles from ras.plan_df and merge with results\n",
        "plan_titles = pd.DataFrame({\n",
        "    'Plan': ras.plan_df['plan_number'].str.zfill(2),\n",
        "    'Short Identifier': ras.plan_df['Short Identifier']\n",
        "})\n",
        "df_2core['Plan'] = df_2core['Plan'].astype(str).str.zfill(2)\n",
        "df_2core = df_2core.merge(plan_titles, on='Plan', how='left')\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Unsteady Runtime\n",
        "plt.subplot(2, 2, 1)\n",
        "bars = plt.bar(range(len(df_2core)), df_2core['Unsteady Compute Time (hr)'], color='blue', alpha=0.7)\n",
        "plt.title('Unsteady Runtime by Plan (2 Cores)', fontsize=12)\n",
        "plt.ylabel('Unsteady Runtime (hours)', fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.xticks(range(len(df_2core)), [f\"Plan {plan}\\n{title}\" for plan, title in zip(df_2core['Plan'], df_2core['Short Identifier'])], rotation=45, ha='right')\n",
        "\n",
        "# Plot 2: Volume Error\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.bar(range(len(df_2core)), df_2core['Volume Error (%)'], color='red', alpha=0.7)\n",
        "plt.title('Volume Error by Plan (2 Cores)', fontsize=12)\n",
        "plt.ylabel('Volume Error (%)', fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.xticks(range(len(df_2core)), [f\"Plan {plan}\\n{title}\" for plan, title in zip(df_2core['Plan'], df_2core['Short Identifier'])], rotation=45, ha='right')\n",
        "\n",
        "# Plot 3: Preprocessor Time\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.bar(range(len(df_2core)), df_2core['Preprocessor Time (hr)'], color='green', alpha=0.7)\n",
        "plt.title('Preprocessor Time by Plan (2 Cores)', fontsize=12)\n",
        "plt.ylabel('Preprocessor Time (hours)', fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.xticks(range(len(df_2core)), [f\"Plan {plan}\\n{title}\" for plan, title in zip(df_2core['Plan'], df_2core['Short Identifier'])], rotation=45, ha='right')\n",
        "\n",
        "# Plot 4: Total Runtime\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.bar(range(len(df_2core)), df_2core['Total Time (hr)'], color='purple', alpha=0.7)\n",
        "plt.title('Total Runtime by Plan (2 Cores)', fontsize=12)\n",
        "plt.ylabel('Total Runtime (hours)', fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.xticks(range(len(df_2core)), [f\"Plan {plan}\\n{title}\" for plan, title in zip(df_2core['Plan'], df_2core['Short Identifier'])], rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.suptitle('Plan Performance Comparison (2 Cores)', fontsize=14, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Save results to CSV\n",
        "df_2core.to_csv('hecras_plan_comparison_2core.csv', index=False)\n",
        "print(\"Results saved to 'hecras_plan_comparison_2core.csv'\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSummary Statistics (2 Cores):\")\n",
        "print(df_2core.describe())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\103_Running_AEP_Events_from_Atlas_14.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# For Development Mode, add the parent directory to the Python path\nimport os\nimport sys\nfrom pathlib import Path\n\ncurrent_file = Path(os.getcwd()).resolve()\nrascmdr_directory = current_file.parent\n\n# Use insert(0) instead of append() to give highest priority to local version\nif str(rascmdr_directory) not in sys.path:\n    sys.path.insert(0, str(rascmdr_directory))\n\nprint(f\"Loading ras-commander from: {rascmdr_directory}\")\nfrom ras_commander import *"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AEP Storm Analysis with RAS-Commander\n",
        "\n",
        "This notebook automates the end-to-end process of analyzing multiple storm events with different Annual Exceedance Probabilities (AEP) in HEC-RAS. It covers:\n",
        "\n",
        "1. Generating hyetographs from NOAA Atlas 14 precipitation data\n",
        "2. Creating HEC-RAS plan files for each AEP event\n",
        "3. Creating unsteady flow files with the generated hyetographs\n",
        "4. Executing multiple plans in parallel\n",
        "5. Analyzing and visualizing the results\n",
        "\n",
        "This automation is particularly useful for analyzing how a drainage system performs under different storm frequencies, from common events (e.g., 2-year) to rare events (e.g., 100-year)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Import Libraries\n",
        "\n",
        "First, we'll import all the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from IPython import display\n",
        "import psutil  # For getting system CPU info\n",
        "\n",
        "# Install ras-commander if not already installed\n",
        "# Uncomment this line if you need to install the package\n",
        "# !pip install ras-commander\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RasExamples.extract_project([\"Davis\"])\n",
        "# This loads the project in fresh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Hyetograph Generation Functions\n",
        "\n",
        "These functions handle reading precipitation frequency data from NOAA Atlas 14 and generating balanced storm hyetographs using the Alternating Block Method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_duration(duration_str):\n",
        "    \"\"\"\n",
        "    Parses a duration string and converts it to hours.\n",
        "    Examples: \"5-min:\" -> 0.0833 hours, \"2-hr:\" -> 2 hours, \"2-day:\" -> 48 hours\n",
        "    \"\"\"\n",
        "    match = re.match(r'(\\d+)-(\\w+):', duration_str.strip())\n",
        "    if not match:\n",
        "        raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
        "    value, unit = match.groups()\n",
        "    value = int(value)\n",
        "    unit = unit.lower()\n",
        "    if unit in ['min', 'minute', 'minutes']:\n",
        "        hours = value / 60.0\n",
        "    elif unit in ['hr', 'hour', 'hours']:\n",
        "        hours = value\n",
        "    elif unit in ['day', 'days']:\n",
        "        hours = value * 24\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown time unit in duration: {unit}\")\n",
        "    return hours\n",
        "\n",
        "def read_precipitation_data(csv_file):\n",
        "    \"\"\"\n",
        "    Reads the precipitation frequency CSV and returns a DataFrame\n",
        "    with durations in hours as the index and ARIs as columns.\n",
        "    \"\"\"\n",
        "    with open(csv_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    header_line_idx = None\n",
        "    header_pattern = re.compile(r'^by duration for ari', re.IGNORECASE)\n",
        "\n",
        "    # Locate the header line\n",
        "    for idx, line in enumerate(lines):\n",
        "        if header_pattern.match(line.strip().lower()):\n",
        "            header_line_idx = idx\n",
        "            break\n",
        "\n",
        "    if header_line_idx is None:\n",
        "        raise ValueError('Header line for precipitation frequency estimates not found in CSV file.')\n",
        "\n",
        "    # Extract the ARI headers from the header line\n",
        "    header_line = lines[header_line_idx].strip()\n",
        "    headers = [item.strip() for item in header_line.split(',')]\n",
        "    \n",
        "    if len(headers) < 2:\n",
        "        raise ValueError('Insufficient number of ARI columns found in the header line.')\n",
        "\n",
        "    aris = headers[1:]  # Exclude the first column which is the duration\n",
        "\n",
        "    # Define the pattern for data lines (e.g., \"5-min:\", \"10-min:\", etc.)\n",
        "    duration_pattern = re.compile(r'^\\d+-(min|hr|day):')\n",
        "\n",
        "    # Initialize lists to store durations and corresponding depths\n",
        "    durations = []\n",
        "    depths = {ari: [] for ari in aris}\n",
        "\n",
        "    # Iterate over the lines following the header to extract data\n",
        "    for line in lines[header_line_idx + 1:]:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue  # Skip empty lines\n",
        "        if not duration_pattern.match(line):\n",
        "            break  # Stop if the line does not match the duration pattern\n",
        "        parts = [part.strip() for part in line.split(',')]\n",
        "        if len(parts) != len(headers):\n",
        "            raise ValueError(f\"Data row does not match header columns: {line}\")\n",
        "        duration_str = parts[0]\n",
        "        try:\n",
        "            duration_hours = parse_duration(duration_str)\n",
        "        except ValueError as ve:\n",
        "            print(f\"Skipping line due to error: {ve}\")\n",
        "            continue  # Skip lines with invalid duration formats\n",
        "        durations.append(duration_hours)\n",
        "        for ari, depth_str in zip(aris, parts[1:]):\n",
        "            try:\n",
        "                depth = float(depth_str)\n",
        "            except ValueError:\n",
        "                depth = np.nan  # Assign NaN for invalid depth values\n",
        "            depths[ari].append(depth)\n",
        "\n",
        "    # Create the DataFrame\n",
        "    df = pd.DataFrame(depths, index=durations)\n",
        "    df.index.name = 'Duration_hours'\n",
        "\n",
        "    # Drop any rows with NaN values\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "def interpolate_depths(df, total_duration):\n",
        "    \"\"\"\n",
        "    Interpolates precipitation depths for each ARI on a log-log scale\n",
        "    for each hour up to the total storm duration.\n",
        "    \"\"\"\n",
        "    T = total_duration\n",
        "    t_hours = np.arange(1, T+1)\n",
        "    D = {}\n",
        "    for ari in df.columns:\n",
        "        durations = df.index.values\n",
        "        depths = df[ari].values\n",
        "        # Ensure all depths are positive\n",
        "        if np.any(depths <= 0):\n",
        "            raise ValueError(f\"Non-positive depth value in ARI {ari}\")\n",
        "        # Log-log interpolation\n",
        "        log_durations = np.log(durations)\n",
        "        log_depths = np.log(depths)\n",
        "        log_t = np.log(t_hours)\n",
        "        log_D_t = np.interp(log_t, log_durations, log_depths)\n",
        "        D_t = np.exp(log_D_t)\n",
        "        D[ari] = D_t\n",
        "    return D\n",
        "\n",
        "def compute_incremental_depths(D, total_duration):\n",
        "    \"\"\"\n",
        "    Computes incremental precipitation depths for each hour.\n",
        "    I(t) = D(t) - D(t-1), with D(0) = 0.\n",
        "    \"\"\"\n",
        "    incremental_depths = {}\n",
        "    for ari, D_t in D.items():\n",
        "        I_t = np.empty(total_duration)\n",
        "        I_t[0] = D_t[0]  # I(1) = D(1) - D(0) = D(1)\n",
        "        I_t[1:] = D_t[1:] - D_t[:-1]\n",
        "        incremental_depths[ari] = I_t\n",
        "    return incremental_depths\n",
        "\n",
        "def assign_alternating_block(sorted_depths, max_depth, central_index, T):\n",
        "    \"\"\"\n",
        "    Assigns incremental depths to the hyetograph using the Alternating Block Method.\n",
        "    \"\"\"\n",
        "    hyetograph = [0.0] * T\n",
        "    hyetograph[central_index] = max_depth\n",
        "    remaining_depths = sorted_depths.copy()\n",
        "    remaining_depths.remove(max_depth)\n",
        "    left = central_index - 1\n",
        "    right = central_index + 1\n",
        "    toggle = True  # Start assigning to the right\n",
        "    for depth in remaining_depths:\n",
        "        if toggle and right < T:\n",
        "            hyetograph[right] = depth\n",
        "            right += 1\n",
        "        elif not toggle and left >= 0:\n",
        "            hyetograph[left] = depth\n",
        "            left -= 1\n",
        "        elif right < T:\n",
        "            hyetograph[right] = depth\n",
        "            right += 1\n",
        "        elif left >= 0:\n",
        "            hyetograph[left] = depth\n",
        "            left -= 1\n",
        "        else:\n",
        "            print(\"Warning: Not all incremental depths assigned.\")\n",
        "            break\n",
        "        toggle = not toggle\n",
        "    return hyetograph\n",
        "\n",
        "def generate_hyetograph(incremental_depths, position_percent, T):\n",
        "    \"\"\"\n",
        "    Generates the hyetograph for a given ARI using the Alternating Block Method.\n",
        "    \"\"\"\n",
        "    max_depth = np.max(incremental_depths)\n",
        "    incremental_depths_list = incremental_depths.tolist()\n",
        "    central_index = int(round(T * position_percent / 100)) - 1\n",
        "    central_index = max(0, min(central_index, T - 1))\n",
        "    sorted_depths = sorted(incremental_depths_list, reverse=True)\n",
        "    hyetograph = assign_alternating_block(sorted_depths, max_depth, central_index, T)\n",
        "    return hyetograph\n",
        "\n",
        "def save_hyetograph(hyetograph, ari, output_dir, position_percent, total_duration):\n",
        "    \"\"\"\n",
        "    Saves the hyetograph to a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\n",
        "        'Time_hour': np.arange(1, total_duration + 1),\n",
        "        'Precipitation_in': hyetograph\n",
        "    })\n",
        "    filename = f'hyetograph_ARI_{ari}_years_pos{position_percent}pct_{total_duration}hr.csv'\n",
        "    output_file = os.path.join(output_dir, filename)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Hyetograph for ARI {ari} years saved to {output_file}\")\n",
        "    return output_file\n",
        "\n",
        "def plot_multiple_hyetographs(aris, position_percent, total_duration, output_dir='hyetographs'):\n",
        "    \"\"\"\n",
        "    Plots multiple hyetographs for specified ARIs on the same figure for comparison.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    \n",
        "    for ari in aris:\n",
        "        # Ensure ARI is a string for consistent filename formatting\n",
        "        ari_str = str(ari)\n",
        "        \n",
        "        # Construct the filename based on the naming convention\n",
        "        filename = f'hyetograph_ARI_{ari_str}_years_pos{position_percent}pct_{total_duration}hr.csv'\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "        \n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Warning: File '{filename}' does not exist in the directory '{output_dir}'. Skipping this ARI.\")\n",
        "            continue\n",
        "        \n",
        "        # Read the hyetograph data\n",
        "        try:\n",
        "            hyetograph_df = pd.read_csv(filepath)\n",
        "            print(f\"Successfully read the hyetograph data from '{filename}'.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading the hyetograph CSV file '{filename}': {e}\")\n",
        "            continue\n",
        "        \n",
        "        # Plot the hyetograph\n",
        "        plt.bar(hyetograph_df['Time_hour'], hyetograph_df['Precipitation_in'], \n",
        "                width=0.8, edgecolor='black', alpha=0.5, label=f'ARI {ari_str} years')\n",
        "    \n",
        "    # Customize the plot\n",
        "    plt.xlabel('Time (Hour)', fontsize=14)\n",
        "    plt.ylabel('Incremental Precipitation (inches)', fontsize=14)\n",
        "    plt.title(f'Comparison of Hyetographs for ARIs {aris}\\nPosition: {position_percent}% | Duration: {total_duration} Hours', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.xticks(range(1, total_duration + 1, max(1, total_duration // 24)))  # Adjust x-ticks based on duration\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate AEP Hydrographs\n",
        "\n",
        "This cell orchestrates the entire AEP analysis process, generating hyetographs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Main function to run the entire AEP analysis process.\n",
        "\"\"\"\n",
        "# Set the paths and parameters\n",
        "input_csv = 'data/PF_Depth_English_PDS_DavisCA.csv'  # Path to NOAA Atlas 14 data\n",
        "output_dir = 'hyetographs'  # Directory for saving hyetographs\n",
        "position_percent = 50  # Position percentage for the maximum incremental depth block\n",
        "total_duration = 24  # Storm duration in hours\n",
        "base_plan = \"02\"  # Base plan to clone\n",
        "\n",
        "# Set the AEP events (return periods in years)\n",
        "aep_events = [2, 5, 10, 25, 50, 100]\n",
        "\n",
        "# Ensure the output directory exists\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output directory is set to: {output_dir}\")\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "# Step 1: Generate hyetographs for each AEP event\n",
        "#-------------------------------------------------------------------------\n",
        "print(\"\\nStep 1: Generating hyetographs for each AEP event...\")\n",
        "\n",
        "try:\n",
        "    # Read precipitation data\n",
        "    df = read_precipitation_data(input_csv)\n",
        "    print(\"Successfully read the input CSV file.\")\n",
        "    \n",
        "    # Display the first few rows of the DataFrame to verify\n",
        "    print(\"\\nPrecipitation Frequency Data from Atlas 14:\")\n",
        "    display.display(df.head())\n",
        "    \n",
        "    # Interpolate depths\n",
        "    D = interpolate_depths(df, total_duration)\n",
        "    print(\"Successfully interpolated precipitation depths.\")\n",
        "\n",
        "    print(\"Array D with interpolated depths\")\n",
        "    display.display(D)\n",
        "    \n",
        "    # Compute incremental depths\n",
        "    inc_depths = compute_incremental_depths(D, total_duration)\n",
        "    print(\"Successfully computed incremental depths.\")\n",
        "    \n",
        "    # Show Incremental Depths\n",
        "    print(\"Array inc_depths Contents \")\n",
        "    display.display(inc_depths)\n",
        "\n",
        "    # Generate and save hyetographs for each AEP\n",
        "    hyetograph_files = {}\n",
        "    for ari in aep_events:\n",
        "        ari_str = str(ari)\n",
        "        if ari_str in inc_depths:\n",
        "            hyetograph = generate_hyetograph(inc_depths[ari_str], position_percent, total_duration)\n",
        "            file_path = save_hyetograph(hyetograph, ari_str, output_dir, position_percent, total_duration)\n",
        "            hyetograph_files[ari_str] = file_path\n",
        "        else:\n",
        "            print(f\"Warning: ARI {ari_str} not found in the data. Skipping.\")\n",
        "    \n",
        "    print(\"\\nAll hyetographs have been generated and saved.\")\n",
        "    \n",
        "    # Plot the hyetographs for comparison\n",
        "    plot_multiple_hyetographs(aep_events, position_percent, total_duration, output_dir)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error generating hyetographs: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# Initialize the HEC-RAS project\n",
        "#-------------------------------------------------------------------------\n",
        "print(\"\\nStep 2: Initializing the HEC-RAS ras...\")\n",
        "\n",
        "# Define the path to the Davis project\n",
        "current_dir = Path.cwd()\n",
        "pipes_ex_path = current_dir / \"example_projects\" / \"Davis\"\n",
        "\n",
        "# Check if the project exists\n",
        "if not pipes_ex_path.exists():\n",
        "    # Extract the project if needed\n",
        "    RasExamples.extract_project([\"Davis\"])\n",
        "\n",
        "# Initialize the RAS project\n",
        "init_ras_project(pipes_ex_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "\n",
        "# Display the existing plans\n",
        "print(\"\\nExisting plans in the project:\")\n",
        "display.display(ras.plan_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Display unsteady_df - note: geometry_number column has been REMOVED\n# This column was incorrectly appearing before; it only belongs in plan_df\nprint(\"Columns in unsteady_df:\")\nprint(list(ras.unsteady_df.columns))\nprint()\n\n# Verify geometry_number is NOT in unsteady_df\nif 'geometry_number' not in ras.unsteady_df.columns:\n    print(\"CORRECT: geometry_number is NOT in unsteady_df (only in plan_df)\")\nelse:\n    print(\"WARNING: geometry_number still in unsteady_df\")\nprint()\n\nras.unsteady_df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Display boundaries_df - Precipitation Hydrograph is now parsed by default!\n# The hydrograph_values column contains the actual precipitation data\nprint(f\"Found {len(ras.boundaries_df)} boundary conditions:\")\nprint()\n\n# Show key columns for boundary conditions\ndisplay_cols = ['unsteady_number', 'boundary_condition_number', 'bc_type', \n                'storage_area_name', 'hydrograph_type', 'hydrograph_num_values', 'Interval']\nprint(ras.boundaries_df[display_cols])\nprint()\n\n# Get Precipitation Hydrograph data directly from boundaries_df\nprecip_bcs = ras.boundaries_df[ras.boundaries_df['bc_type'] == 'Precipitation Hydrograph']\nif not precip_bcs.empty:\n    print(f\"Found {len(precip_bcs)} Precipitation Hydrograph boundary condition(s):\")\n    for idx, row in precip_bcs.iterrows():\n        print(f\"\\n  Boundary #{row['boundary_condition_number']}:\")\n        print(f\"    Storage Area: {row['storage_area_name']}\")\n        print(f\"    Interval: {row['Interval']}\")\n        print(f\"    Number of values: {row['hydrograph_num_values']}\")\n        \n        # Get the hydrograph values directly from boundaries_df\n        if 'hydrograph_values' in row and row['hydrograph_values']:\n            values = row['hydrograph_values']\n            print(f\"    Hydrograph values: {values}\")\n            \n            # Convert to numeric for analysis\n            numeric_values = [float(v) for v in values]\n            print(f\"    Min: {min(numeric_values):.4f}, Max: {max(numeric_values):.4f}, Sum: {sum(numeric_values):.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to unsteady flow file associated with Unsteady Number \"01\"\n",
        "unsteady_file = RasPlan.get_unsteady_path(\"01\")\n",
        "print(f\"Unsteady flow file path: {unsteady_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unsteady_file"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "### Alternative Method: Using RasUnsteady.extract_boundary_and_tables()\n\nThe cell below demonstrates an alternative way to extract boundary conditions and their table data. This method provides more detailed control and returns nested DataFrames in the Tables column.\n\n```python\n# Extract boundary conditions and tables - includes Precipitation Hydrograph data\nboundaries_df = RasUnsteady.extract_boundary_and_tables(unsteady_file)\nprint(f\"Extracted {len(boundaries_df)} boundary conditions from the unsteady flow file.\")\n\n# Show which boundaries have table data\nfor idx, row in boundaries_df.iterrows():\n    tables = row.get('Tables', {})\n    storage_area = row.get('Storage Area Name', 'N/A')\n    print(f\"Boundary {idx + 1} (Storage Area: {storage_area}):\")\n    if tables:\n        for table_name, table_df in tables.items():\n            print(f\"  - {table_name}: {len(table_df)} values\")\n            print(f\"    Values: {table_df['Value'].tolist()}\")\n    else:\n        print(f\"  - No table data (likely a Normal Depth or other non-hydrograph BC)\")\n```"
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "### Alternative Method: Using RasUnsteady.extract_tables()\n\nThis method extracts all tables from an unsteady file as a dictionary of DataFrames. It's useful when you need just the raw table data without boundary location information.\n\n```python\n# Use RasUnsteady.extract_tables() to get detailed precipitation hydrograph values\ntables = RasUnsteady.extract_tables(unsteady_file)\nprint(f\"Tables found in unsteady file:\")\nfor table_name, df in tables.items():\n    print(f\"  - {table_name}: {len(df)} values\")\n\n# Display the Precipitation Hydrograph values\nif 'Precipitation Hydrograph=' in tables:\n    print(\"\\nPrecipitation Hydrograph Values (inches):\")\n    precip_df = tables['Precipitation Hydrograph=']\n    print(f\"  Total values: {len(precip_df)}\")\n    print(f\"  Values: {precip_df['Value'].tolist()}\")\n```"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the contents of Unsteady File\n",
        "with open(unsteady_file, 'r') as f:\n",
        "    unsteady_contents = f.read()\n",
        "print(f\"Contents of unsteady flow file {unsteady_file}:\")\n",
        "print(\"-\" * 80)\n",
        "print(unsteady_contents)\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To implement AEP event hydrographs, we will edit the Precipitation Hydrograph table\n",
        "We will need to edit both the number of values, as well as replacing the existing fixed-width table.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define HEC-RAS Plan and Unsteady Flow File Functions\n",
        "\n",
        "These functions handle creating HEC-RAS plan files and unsteady flow files for each AEP event. They apply the generated hyetographs to the boundary conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_plan_for_aep(base_plan, aep_years, duration_hours, hyetograph_file, project):\n",
        "    \"\"\"\n",
        "    Creates a new plan for a specific AEP event.\n",
        "    \"\"\"\n",
        "    # Create plan name and short ID\n",
        "    plan_name = f\"{aep_years}YR-{duration_hours}HR\"\n",
        "    \n",
        "    print(f\"Creating new plan '{plan_name}'...\")\n",
        "    \n",
        "    # Clone the base plan\n",
        "    new_plan_number = RasPlan.clone_plan(base_plan, new_shortid=plan_name, ras_object=project)\n",
        "    print(f\"Created new plan: {new_plan_number}\")\n",
        "    \n",
        "    # Clone the unsteady flow file from the base plan\n",
        "    base_unsteady = None\n",
        "    for _, row in project.plan_df.iterrows():\n",
        "        if row['plan_number'] == base_plan:\n",
        "            base_unsteady = row.get('unsteady_number', None)\n",
        "            \n",
        "    if base_unsteady is None:\n",
        "        raise ValueError(f\"Could not find unsteady flow file for base plan {base_plan}\")\n",
        "\n",
        "    \n",
        "    new_unsteady_number = RasPlan.clone_unsteady(base_unsteady, ras_object=project)\n",
        "    print(f\"Created new unsteady flow file: {new_unsteady_number}\")\n",
        "    \n",
        "    # Update the unsteady flow file with the hyetograph data\n",
        "    unsteady_file_path = RasPlan.get_unsteady_path(new_unsteady_number, ras_object=project)\n",
        "    \n",
        "    \n",
        "    # Update the flow title to reflect the AEP event\n",
        "    new_title = f\"{aep_years}YR-{duration_hours}HR Storm\"\n",
        "    RasUnsteady.update_flow_title(unsteady_file_path, new_title, ras_object=project)\n",
        "    print(f\"Updated unsteady flow title to: {new_title}\")\n",
        "    \n",
        "    # Modify the unsteady flow file with the hyetograph data\n",
        "    success = modify_unsteady_flow_with_hyetograph(unsteady_file_path, hyetograph_file, project)\n",
        "    if success:\n",
        "        print(f\"Successfully applied hyetograph data from {hyetograph_file} to unsteady flow file\")\n",
        "    else:\n",
        "        print(f\"Warning: Failed to apply hyetograph data. Unsteady flow file may need manual modification.\")\n",
        "    \n",
        "    # Assign the unsteady flow file to the plan\n",
        "    RasPlan.set_unsteady(new_plan_number, new_unsteady_number, ras_object=project)\n",
        "    print(f\"Assigned unsteady flow file {new_unsteady_number} to plan {new_plan_number}\")\n",
        "    '''\n",
        "    # Update the plan description\n",
        "    description = f\"AEP {aep_years}-year, {duration_hours}-hour storm\\n\"\n",
        "    description += f\"Created: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "    description += f\"Based on plan {base_plan}\\n\"\n",
        "    description += f\"Hyetograph from: {os.path.basename(hyetograph_file)}\"\n",
        "    \n",
        "    RasPlan.update_plan_description(new_plan_number, description, ras_object=project)\n",
        "    print(f\"Updated plan description for plan {new_plan_number}\")\n",
        "    \n",
        "    return new_plan_number, new_unsteady_number\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def modify_unsteady_flow_with_hyetograph(unsteady_file_path, hyetograph_file, project):\n",
        "    \"\"\"\n",
        "    Modifies an unsteady flow file to incorporate hyetograph data as precipitation.\n",
        "    \n",
        "    Parameters:\n",
        "    - unsteady_file_path: Path to the unsteady flow file\n",
        "    - hyetograph_file: Path to the hyetograph data CSV\n",
        "    - project: RAS project object\n",
        "    \n",
        "    Returns:\n",
        "    - Boolean indicating success\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the hyetograph data\n",
        "        hyetograph_df = pd.read_csv(hyetograph_file)\n",
        "        print(f\"Loaded hyetograph from {hyetograph_file} with {len(hyetograph_df)} values\")\n",
        "        \n",
        "        # Read the unsteady flow file\n",
        "        with open(unsteady_file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "        \n",
        "        # Find the sections that need to be modified\n",
        "        precip_hydrograph_index = None\n",
        "        \n",
        "        for i, line in enumerate(lines):\n",
        "            if line.startswith(\"Precipitation Hydrograph=\"):\n",
        "                precip_hydrograph_index = i\n",
        "                break\n",
        "        \n",
        "        if precip_hydrograph_index is None:\n",
        "            print(\"Cannot find Precipitation Hydrograph section in unsteady file.\")\n",
        "            return False\n",
        "        \n",
        "        # Get the time interval from the hyetograph\n",
        "        time_interval = \"1HOUR\"  # Default\n",
        "        if \"Time_hour\" in hyetograph_df.columns and len(hyetograph_df) > 1:\n",
        "            hour_diff = hyetograph_df[\"Time_hour\"].iloc[1] - hyetograph_df[\"Time_hour\"].iloc[0]\n",
        "            time_interval = f\"{int(hour_diff)}HOUR\" if hour_diff >= 1 else f\"{int(hour_diff*60)}MIN\"\n",
        "        \n",
        "        # Format the precipitation values for the hydrograph\n",
        "        precipitation_values = hyetograph_df[\"Precipitation_in\"].values\n",
        "        \n",
        "        # Create the Precipitation Hydrograph line\n",
        "        precip_line = f\"Precipitation Hydrograph= {len(precipitation_values)} \\n\"\n",
        "        \n",
        "        # Format the values in groups of 10 per line\n",
        "        value_lines = []\n",
        "        for i in range(0, len(precipitation_values), 10):\n",
        "            row_values = precipitation_values[i:i+10]\n",
        "            row_line = \"\".join([f\"{value:8.2f}\" for value in row_values]) + \"\\n\"\n",
        "            value_lines.append(row_line)\n",
        "            \n",
        "        # Remove old hydrograph data - find end of current hydrograph\n",
        "        current_line = precip_hydrograph_index + 1\n",
        "        while current_line < len(lines) and not any(lines[current_line].startswith(prefix) for prefix in [\"DSS Path=\", \"Use DSS=\", \"Use Fixed Start Time=\"]):\n",
        "            current_line += 1\n",
        "            \n",
        "        # Replace the hydrograph section\n",
        "        lines[precip_hydrograph_index:current_line] = [precip_line] + value_lines\n",
        "            \n",
        "        # Write the modified file back\n",
        "        with open(unsteady_file_path, 'w') as file:\n",
        "            file.writelines(lines)\n",
        "            \n",
        "        print(f\"Successfully applied hyetograph data from {hyetograph_file} to unsteady flow file.\")\n",
        "        print(f\"Added {len(precipitation_values)} precipitation values with interval {time_interval}\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error modifying unsteady flow file: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# Create new plans for each AEP event\n",
        "#-------------------------------------------------------------------------\n",
        "print(\"\\nStep 3: Creating new plans for each AEP event...\")\n",
        "\n",
        "new_plan_numbers = []\n",
        "\n",
        "for ari in aep_events:\n",
        "    ari_str = str(ari)\n",
        "    if ari_str in hyetograph_files:\n",
        "        try:\n",
        "            # Create a new plan for this AEP event\n",
        "            new_plan_number, _ = create_plan_for_aep(\n",
        "                base_plan=base_plan,\n",
        "                aep_years=ari_str,\n",
        "                duration_hours=total_duration,\n",
        "                hyetograph_file=hyetograph_files[ari_str],\n",
        "                project=ras\n",
        "            )\n",
        "            new_plan_numbers.append(new_plan_number)\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating plan for AEP {ari_str}: {e}\")\n",
        "\n",
        "# Display the updated plans\n",
        "print(\"\\nUpdated plans in the project:\")\n",
        "display.display(ras.plan_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to unsteady flow file associated with Unsteady Number \"02\"\n",
        "unsteady_file_rev = RasPlan.get_unsteady_path(\"02\")\n",
        "print(f\"Unsteady flow file path: {unsteady_file_rev}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unsteady_file_rev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(unsteady_file_rev, 'r') as f:\n",
        "    unsteady_contents_rev = f.read()\n",
        "print(f\"Contents of unsteady flow file for plan 02 ({unsteady_file_rev}):\")\n",
        "print(\"-\" * 80)\n",
        "print(unsteady_contents_rev)\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import difflib\n",
        "\n",
        "def show_file_diff(file1_path, file2_path, context_lines=3):\n",
        "    \"\"\"\n",
        "    Shows the differences between two files with context.\n",
        "    \n",
        "    Parameters:\n",
        "    - file1_path: Path to the first file\n",
        "    - file2_path: Path to the second file\n",
        "    - context_lines: Number of context lines to show around differences\n",
        "    \"\"\"\n",
        "    # Read the file contents\n",
        "    with open(file1_path, 'r') as file1:\n",
        "        file1_lines = file1.readlines()\n",
        "    \n",
        "    with open(file2_path, 'r') as file2:\n",
        "        file2_lines = file2.readlines()\n",
        "    \n",
        "    # Create a differ object\n",
        "    differ = difflib.unified_diff(\n",
        "        file1_lines, \n",
        "        file2_lines,\n",
        "        fromfile=str(file1_path),\n",
        "        tofile=str(file2_path),\n",
        "        n=context_lines\n",
        "    )\n",
        "    \n",
        "    # Convert differ output to a string\n",
        "    diff_text = ''.join(differ)\n",
        "    \n",
        "    # If no differences found\n",
        "    if not diff_text:\n",
        "        print(f\"No differences found between {file1_path} and {file2_path}\")\n",
        "        return\n",
        "    \n",
        "    # Print the differences\n",
        "    print(f\"Differences between {file1_path} and {file2_path}:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(diff_text)\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Count added, removed, and modified lines\n",
        "    added = sum(1 for line in diff_text.splitlines() if line.startswith('+') and not line.startswith('+++'))\n",
        "    removed = sum(1 for line in diff_text.splitlines() if line.startswith('-') and not line.startswith('---'))\n",
        "    \n",
        "    print(f\"Summary: {added} additions, {removed} removals\")\n",
        "\n",
        "# Show differences between the unsteady flow files\n",
        "if 'unsteady_file' in locals() and 'unsteady_file_rev' in locals():\n",
        "    show_file_diff(unsteady_file, unsteady_file_rev)\n",
        "else:\n",
        "    print(\"Error: One or both unsteady flow file variables not defined.\")\n",
        "    print(\"Please run the cells that define unsteady_file and unsteady_file_rev first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define Parallel Execution and Results Analysis Functions\n",
        "\n",
        "These functions manage parallel plan execution with resource optimization and extract, analyze, and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_plans_in_parallel(plan_numbers, project, max_workers=None, cores_per_worker=2):\n",
        "    \"\"\"\n",
        "    Executes multiple plans in parallel.\n",
        "    \"\"\"\n",
        "    # Calculate optimal number of workers if not provided\n",
        "    if max_workers is None:\n",
        "        physical_cores = psutil.cpu_count(logical=False)  # Physical cores only\n",
        "        max_workers = max(1, physical_cores // cores_per_worker)\n",
        "    \n",
        "    print(f\"Executing {len(plan_numbers)} plans in parallel with {max_workers} workers, \" + \n",
        "          f\"each using {cores_per_worker} cores...\")\n",
        "    \n",
        "    # Create compute folder\n",
        "    compute_folder = Path(project.project_folder) / \"compute_aep_parallel\"\n",
        "    compute_folder.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Execute plans in parallel\n",
        "    start_time = time.time()\n",
        "    \n",
        "    results = RasCmdr.compute_parallel(\n",
        "        plan_number=plan_numbers,\n",
        "        max_workers=max_workers,\n",
        "        num_cores=cores_per_worker,\n",
        "        dest_folder=compute_folder,\n",
        "        clear_geompre=True,\n",
        "        overwrite_dest=True,\n",
        "        ras_object=project\n",
        "    )\n",
        "    \n",
        "    end_time = time.time()\n",
        "    total_duration = end_time - start_time\n",
        "    \n",
        "    print(f\"Parallel execution completed in {total_duration:.2f} seconds\")\n",
        "    \n",
        "    # Create a DataFrame from the execution results\n",
        "    results_df = pd.DataFrame([\n",
        "        {\"Plan\": plan, \"Success\": success}\n",
        "        for plan, success in results.items()\n",
        "    ])\n",
        "    \n",
        "    # Sort by plan number\n",
        "    results_df = results_df.sort_values(\"Plan\")\n",
        "    \n",
        "    print(\"\\nExecution Results:\")\n",
        "    display.display(results_df)\n",
        "    \n",
        "    return results, compute_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the path to unsteady flow file associated with Plan \"01\"\n",
        "unsteady_file = RasPlan.get_unsteady_path(\"01\")\n",
        "print(f\"Unsteady flow file path: {unsteady_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# Execute all plans in parallel\n",
        "#-------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set computation parameters for better performance\n",
        "for plan_number in new_plan_numbers:\n",
        "    RasPlan.set_num_cores(plan_number, 2, ras_object=ras)\n",
        "    RasPlan.update_plan_intervals(\n",
        "        plan_number,\n",
        "        computation_interval=\"15MIN\",\n",
        "        output_interval=\"30MIN\",\n",
        "        mapping_interval=\"1HOUR\",\n",
        "        ras_object=ras\n",
        "    )\n",
        "    print(f\"Updated computation settings for plan {plan_number}\")\n",
        "\n",
        "# Execute plans in parallel\n",
        "results, compute_folder = execute_plans_in_parallel(\n",
        "    plan_numbers=new_plan_numbers,\n",
        "    project=ras\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print(\"\\nStep 4: Executing all plans in parallel...\")\n",
        "\n",
        "results, compute_folder = execute_plans_in_parallel(\n",
        "    plan_numbers=new_plan_numbers,\n",
        "    project=ras\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime_df = HdfResultsPlan.get_runtime_data(\"02\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_flow_ds = HdfPipe.get_pipe_network_timeseries(\"02\", variable=\"Pipes/Pipe Flow DS\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_flow_ds "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_ws = HdfPipe.get_pipe_network_timeseries(\"02\", variable=\"Nodes/Water Surface\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_results(results, compute_folder, project):\n",
        "    \"\"\"\n",
        "    Analyzes the results from multiple plans.\n",
        "    \"\"\"\n",
        "    print(\"Analyzing results from parallel execution...\")\n",
        "    \n",
        "    # Initialize a RAS project in the compute folder\n",
        "    compute_project = RasPrj()\n",
        "    compute_project = init_ras_project(compute_folder, \"6.6\", ras_object=compute_project)\n",
        "    print(f\"Initialized compute project: {compute_project.project_name}\")\n",
        "    \n",
        "    # Check which plans have results\n",
        "    plans_with_results = compute_project.plan_df[compute_project.plan_df['HDF_Results_Path'].notna()]\n",
        "    print(f\"\\nFound {len(plans_with_results)} plans with results:\")\n",
        "    display.display(plans_with_results[['plan_number', 'Short Identifier', 'HDF_Results_Path']])\n",
        "    \n",
        "    # Initialize a dictionary to store analysis results\n",
        "    analysis_results = {}\n",
        "    \n",
        "    # Analyze each plan's results\n",
        "    for idx, row in plans_with_results.iterrows():\n",
        "        plan_number = row['plan_number']\n",
        "        plan_name = row['Short Identifier']\n",
        "        hdf_path = row['HDF_Results_Path']\n",
        "        \n",
        "        print(f\"\\nAnalyzing results for plan {plan_number} ({plan_name})...\")\n",
        "        \n",
        "        try:\n",
        "            # Get runtime data\n",
        "            runtime_df = HdfResultsPlan.get_runtime_data(hdf_path)\n",
        "            \n",
        "            if runtime_df is not None and not runtime_df.empty:\n",
        "                # Extract key metrics\n",
        "                sim_duration = runtime_df['Simulation Duration (s)'].iloc[0]\n",
        "                compute_time = runtime_df['Complete Process (hr)'].iloc[0]\n",
        "                compute_speed = runtime_df['Complete Process Speed (hr/hr)'].iloc[0]\n",
        "                \n",
        "                # Get pipe network results\n",
        "                try:\n",
        "                    # Get pipe flow data\n",
        "                    pipe_flow_ds = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Pipes/Pipe Flow DS\")\n",
        "                    node_ws = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Nodes/Water Surface\")\n",
        "                    \n",
        "                    # Convert xarray DataArrays to numpy arrays and compute statistics\n",
        "                    pipe_flow_array = pipe_flow_ds.values\n",
        "                    node_ws_array = node_ws.values\n",
        "                    \n",
        "                    # Calculate maximum flows and water surfaces\n",
        "                    max_flows = np.nanmax(pipe_flow_array, axis=0)  # Max over time for each location\n",
        "                    avg_max_flow = np.nanmean(max_flows)\n",
        "                    max_max_flow = np.nanmax(max_flows)\n",
        "                    \n",
        "                    max_ws = np.nanmax(node_ws_array, axis=0)  # Max over time for each node\n",
        "                    avg_max_ws = np.nanmean(max_ws)\n",
        "                    max_max_ws = np.nanmax(max_ws)\n",
        "                    \n",
        "                    # Store results in the dictionary\n",
        "                    analysis_results[plan_name] = {\n",
        "                        'Plan Number': plan_number,\n",
        "                        'Simulation Duration (s)': sim_duration,\n",
        "                        'Compute Time (hr)': compute_time,\n",
        "                        'Compute Speed (hr/hr)': compute_speed,\n",
        "                        'Average Max Pipe Flow (cfs)': avg_max_flow,\n",
        "                        'Maximum Pipe Flow (cfs)': max_max_flow,\n",
        "                        'Average Max Node Water Surface (ft)': avg_max_ws,\n",
        "                        'Maximum Node Water Surface (ft)': max_max_ws,\n",
        "                        'HDF Path': hdf_path\n",
        "                    }\n",
        "                    \n",
        "                    print(f\"  Simulation Duration: {sim_duration:.2f} seconds\")\n",
        "                    print(f\"  Computation Time: {compute_time:.5f} hours\")\n",
        "                    print(f\"  Computation Speed: {compute_speed:.2f} (simulation hours/compute hours)\")\n",
        "                    print(f\"  Average Max Pipe Flow: {avg_max_flow:.2f} cfs\")\n",
        "                    print(f\"  Maximum Pipe Flow: {max_max_flow:.2f} cfs\")\n",
        "                    print(f\"  Average Max Node Water Surface: {avg_max_ws:.2f} ft\")\n",
        "                    print(f\"  Maximum Node Water Surface: {max_max_ws:.2f} ft\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"  Error analyzing pipe network data: {str(e)}\")\n",
        "                    analysis_results[plan_name] = {\n",
        "                        'Plan Number': plan_number,\n",
        "                        'Simulation Duration (s)': sim_duration,\n",
        "                        'Compute Time (hr)': compute_time,\n",
        "                        'Compute Speed (hr/hr)': compute_speed,\n",
        "                        'Average Max Pipe Flow (cfs)': np.nan,\n",
        "                        'Maximum Pipe Flow (cfs)': np.nan,\n",
        "                        'Average Max Node Water Surface (ft)': np.nan,\n",
        "                        'Maximum Node Water Surface (ft)': np.nan,\n",
        "                        'HDF Path': hdf_path\n",
        "                    }\n",
        "            else:\n",
        "                print(\"  No runtime data found.\")\n",
        "                analysis_results[plan_name] = {\n",
        "                    'Plan Number': plan_number,\n",
        "                    'Simulation Duration (s)': np.nan,\n",
        "                    'Compute Time (hr)': np.nan,\n",
        "                    'Compute Speed (hr/hr)': np.nan,\n",
        "                    'Average Max Pipe Flow (cfs)': np.nan,\n",
        "                    'Maximum Pipe Flow (cfs)': np.nan,\n",
        "                    'Average Max Node Water Surface (ft)': np.nan,\n",
        "                    'Maximum Node Water Surface (ft)': np.nan,\n",
        "                    'HDF Path': hdf_path\n",
        "                }\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  Error analyzing plan {plan_number}: {str(e)}\")\n",
        "            analysis_results[plan_name] = {\n",
        "                'Plan Number': plan_number,\n",
        "                'Simulation Duration (s)': np.nan,\n",
        "                'Compute Time (hr)': np.nan,\n",
        "                'Compute Speed (hr/hr)': np.nan,\n",
        "                'Average Max Pipe Flow (cfs)': np.nan,\n",
        "                'Maximum Pipe Flow (cfs)': np.nan,\n",
        "                'Average Max Node Water Surface (ft)': np.nan,\n",
        "                'Maximum Node Water Surface (ft)': np.nan,\n",
        "                'HDF Path': hdf_path\n",
        "            }\n",
        "    \n",
        "    # Create a DataFrame from the analysis results\n",
        "    analysis_df = pd.DataFrame.from_dict(analysis_results, orient='index')\n",
        "    \n",
        "    # Extract AEP years and handle NaN values\n",
        "    analysis_df['AEP_Years'] = analysis_df.index.str.extract(r'(\\d+)YR').astype(float)\n",
        "    \n",
        "    # Sort by AEP years, handling the base plan\n",
        "    analysis_df = analysis_df.sort_values('AEP_Years', na_position='first')\n",
        "    \n",
        "    # Drop the temporary column used for sorting\n",
        "    analysis_df = analysis_df.drop(columns=['AEP_Years'])\n",
        "    \n",
        "    print(\"\\nAnalysis Results:\")\n",
        "    display.display(analysis_df)\n",
        "    \n",
        "    return analysis_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#---------------------------------------------------------------------\n",
        "# Step 5: Analyze the results\n",
        "#---------------------------------------------------------------------\n",
        "print(\"\\nStep 5: Analyzing the results...\")\n",
        "\n",
        "analysis_df = analyze_results(\n",
        "    results=results,\n",
        "    compute_folder=compute_folder,\n",
        "    project=ras\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_results(analysis_df):\n",
        "    \"\"\"\n",
        "    Plots the results from the analysis.\n",
        "    \"\"\"\n",
        "    # Extract AEP values from the index (plan names), skipping non-AEP plans\n",
        "    aep_values = []\n",
        "    aep_data = pd.DataFrame()\n",
        "    \n",
        "    for name in analysis_df.index:\n",
        "        if 'YR' in name:\n",
        "            try:\n",
        "                aep_year = int(name.split('YR')[0])\n",
        "                aep_values.append(aep_year)\n",
        "                aep_data = pd.concat([aep_data, analysis_df.loc[[name]]])\n",
        "            except ValueError:\n",
        "                continue\n",
        "    \n",
        "    if len(aep_values) == 0:\n",
        "        print(\"No valid AEP plans found to plot\")\n",
        "        return\n",
        "        \n",
        "    # Create a figure with multiple subplots\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(14, 12))\n",
        "    \n",
        "    # Plot 1: Maximum Pipe Flow vs AEP\n",
        "    axs[0].semilogx(aep_values, aep_data['Maximum Pipe Flow (cfs)'], 'o-', marker='o', markersize=8)\n",
        "    axs[0].set_title('Maximum Pipe Flow vs Return Period', fontsize=16)\n",
        "    axs[0].set_xlabel('Return Period (years)', fontsize=14)\n",
        "    axs[0].set_ylabel('Maximum Pipe Flow (cfs)', fontsize=14)\n",
        "    axs[0].grid(True)\n",
        "    \n",
        "    # Add data labels\n",
        "    for i, txt in enumerate(aep_values):\n",
        "        axs[0].annotate(f\"{txt} yr\", \n",
        "                      (aep_values[i], aep_data['Maximum Pipe Flow (cfs)'].iloc[i]),\n",
        "                      textcoords=\"offset points\", \n",
        "                      xytext=(0, 10), \n",
        "                      ha='center')\n",
        "    \n",
        "    # Plot 2: Maximum Node Water Surface vs AEP\n",
        "    axs[1].semilogx(aep_values, aep_data['Maximum Node Water Surface (ft)'], 'o-', marker='s', markersize=8, color='green')\n",
        "    axs[1].set_title('Maximum Node Water Surface vs Return Period', fontsize=16)\n",
        "    axs[1].set_xlabel('Return Period (years)', fontsize=14)\n",
        "    axs[1].set_ylabel('Maximum Node Water Surface (ft)', fontsize=14)\n",
        "    axs[1].grid(True)\n",
        "    \n",
        "    # Add data labels\n",
        "    for i, txt in enumerate(aep_values):\n",
        "        axs[1].annotate(f\"{txt} yr\", \n",
        "                      (aep_values[i], aep_data['Maximum Node Water Surface (ft)'].iloc[i]),\n",
        "                      textcoords=\"offset points\", \n",
        "                      xytext=(0, 10), \n",
        "                      ha='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    # Plot time series for each return period\n",
        "    try:\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        \n",
        "        # Create a color map for different return periods\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(aep_values)))\n",
        "        \n",
        "        # Plot each return period\n",
        "        for i, name in enumerate(aep_data.index):\n",
        "            # Get HDF path for this return period\n",
        "            hdf_path = aep_data.loc[name, 'HDF Path']\n",
        "            \n",
        "            # Get pipe network timeseries data\n",
        "            node_ws = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Nodes/Water Surface\")\n",
        "            \n",
        "            # Get data for location 61\n",
        "            loc_61_ws = node_ws.sel(location=61)\n",
        "            \n",
        "            # Plot the time series\n",
        "            plt.plot(loc_61_ws.time.values, loc_61_ws.values, \n",
        "                    label=f'{name}', \n",
        "                    color=colors[i],\n",
        "                    linewidth=2)\n",
        "        \n",
        "        plt.title('Water Surface Elevation Time Series by Return Period - Location 61', fontsize=16)\n",
        "        plt.xlabel('Time', fontsize=14)\n",
        "        plt.ylabel('Water Surface Elevation (ft)', fontsize=14)\n",
        "        plt.grid(True)\n",
        "        plt.legend(fontsize=12)\n",
        "        \n",
        "        # Format x-axis dates\n",
        "        plt.gcf().autofmt_xdate()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Could not create detailed heatmap: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#---------------------------------------------------------------------\n",
        "# Step 6: Plot the results\n",
        "#---------------------------------------------------------------------\n",
        "print(\"\\nStep 6: Plotting the results...\")\n",
        "\n",
        "plot_results(analysis_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "node_ws = HdfPipe.get_pipe_network_timeseries(\"04\", variable=\"Nodes/Water Surface\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_flow_ds = HdfPipe.get_pipe_network_timeseries(\"04\", variable=\"Pipes/Pipe Flow DS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe_flow_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrates a comprehensive workflow for automated AEP storm analysis using RAS-Commander. The key benefits of this approach include:\n",
        "\n",
        "1. **Efficiency**: Automating repetitive tasks saves time and reduces errors\n",
        "2. **Consistency**: Ensures consistent methodology across all return periods\n",
        "3. **Parallel Execution**: Makes optimal use of computational resources\n",
        "4. **Comprehensive Analysis**: Extracts and visualizes key metrics across return periods\n",
        "5. **Reproducibility**: The entire workflow is documented and repeatable\n",
        "\n",
        "This approach can be extended to include additional analyses, such as:\n",
        "\n",
        "- Comparing different storm patterns (e.g., position of peak intensity)\n",
        "- Analyzing climate change scenarios by adjusting precipitation depths\n",
        "- Evaluating infrastructure improvements by comparing baseline and modified geometries\n",
        "- Generating frequency curves for key hydraulic parameters\n",
        "\n",
        "By leveraging the power of RAS-Commander, engineers can focus on interpreting results and making design decisions rather than managing model configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DEV NOTES: \n",
        "\n",
        "Need to add example of setting Start Time and End Time\n",
        "\n",
        "Need to add function to library that will end-to-end model Atlas 14 AEP storms given an input lat/long, Return Interval and Duration, given a working geometry w/infiltration.  Running optional.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\104_Atlas14_AEP_Multi_Project.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Atlas 14 Uncertainty Analysis with Multi-Project Support\n",
        "\n",
        "This notebook performs comprehensive uncertainty analysis of precipitation-driven flooding by:\n",
        "\n",
        "1. **Processing Multiple Durations**: Analyzes 1-hr, 2-hr, 3-hr, 6-hr, 12-hr, 24-hr, and 2-day storms\n",
        "2. **Including Confidence Intervals**: Runs upper and lower confidence bounds for each scenario\n",
        "3. **Quantifying Uncertainty**: Shows how precipitation uncertainty propagates through flood models\n",
        "4. **Comprehensive Visualization**: Creates confidence envelope plots and uncertainty heatmaps\n",
        "5. **Multi-Project Management**: Automatically handles HEC-RAS 99-plan limit by distributing scenarios across multiple project copies\n",
        "\n",
        "## Methodology\n",
        "\n",
        "**Confidence Interval Estimation:**\n",
        "- NOAA Atlas 14 precipitation estimates have inherent uncertainty\n",
        "- Upper confidence bound \u2248 1.4 \u00d7 point estimate\n",
        "- Lower confidence bound \u2248 0.7 \u00d7 point estimate\n",
        "- These factors represent approximate 90% confidence intervals\n",
        "\n",
        "**Scenario Matrix:**\n",
        "- 6 AEP events (2, 5, 10, 25, 50, 100 years)\n",
        "- 7 durations (1hr, 2hr, 3hr, 6hr, 12hr, 24hr, 2day)\n",
        "- 3 confidence levels (lower, point, upper)\n",
        "- **Total: 126 scenarios**\n",
        "\n",
        "**99-Plan Limit Solution:**\n",
        "- HEC-RAS projects limited to 99 plans maximum\n",
        "- Automated distribution across multiple project copies\n",
        "- Preserves original project (all work done in copies)\n",
        "- Results automatically aggregated from all projects\n",
        "\n",
        "**Analysis Outputs:**\n",
        "- Confidence envelopes for peak water surfaces\n",
        "- Uncertainty quantification by duration and location\n",
        "- Design recommendations considering uncertainty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "from IPython import display\n",
        "import psutil\n",
        "from itertools import product\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract and Initialize Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize project\n",
        "current_dir = Path.cwd()\n",
        "pipes_ex_path = current_dir / \"A14_Examples\" / \"Davis\"\n",
        "rasexamples_extract_path = current_dir / \"A14_Examples\"\n",
        "\n",
        "if not pipes_ex_path.exists():\n",
        "    RasExamples.extract_project([\"Davis\"], output_path=rasexamples_extract_path)\n",
        "\n",
        "init_ras_project(pipes_ex_path, \"6.6\")\n",
        "print(f\"Initialized HEC-RAS project: {ras.project_name}\")\n",
        "print(f\"\\nBase plan configuration:\")\n",
        "display.display(ras.plan_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enhanced Hyetograph Generation with Confidence Intervals\n",
        "\n",
        "These functions extend the original hyetograph generation to support:\n",
        "- Multiple durations (not just 24-hour)\n",
        "- Confidence interval calculations\n",
        "- Systematic scenario organization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_duration(duration_str):\n",
        "    \"\"\"\n",
        "    Parses a duration string and converts it to hours.\n",
        "    Examples: \"5-min:\" -> 0.0833 hours, \"2-hr:\" -> 2 hours, \"2-day:\" -> 48 hours\n",
        "    \"\"\"\n",
        "    match = re.match(r'(\\d+)-(\\w+):', duration_str.strip())\n",
        "    if not match:\n",
        "        raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
        "    value, unit = match.groups()\n",
        "    value = int(value)\n",
        "    unit = unit.lower()\n",
        "    if unit in ['min', 'minute', 'minutes']:\n",
        "        hours = value / 60.0\n",
        "    elif unit in ['hr', 'hour', 'hours']:\n",
        "        hours = value\n",
        "    elif unit in ['day', 'days']:\n",
        "        hours = value * 24\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown time unit in duration: {unit}\")\n",
        "    return hours\n",
        "\n",
        "def read_precipitation_data(csv_file):\n",
        "    \"\"\"\n",
        "    Reads the precipitation frequency CSV and returns a DataFrame\n",
        "    with durations in hours as the index and ARIs as columns.\n",
        "    \"\"\"\n",
        "    with open(csv_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    header_line_idx = None\n",
        "    header_pattern = re.compile(r'^by duration for ari', re.IGNORECASE)\n",
        "\n",
        "    # Locate the header line\n",
        "    for idx, line in enumerate(lines):\n",
        "        if header_pattern.match(line.strip().lower()):\n",
        "            header_line_idx = idx\n",
        "            break\n",
        "\n",
        "    if header_line_idx is None:\n",
        "        raise ValueError('Header line for precipitation frequency estimates not found in CSV file.')\n",
        "\n",
        "    # Extract the ARI headers from the header line\n",
        "    header_line = lines[header_line_idx].strip()\n",
        "    headers = [item.strip() for item in header_line.split(',')]\n",
        "    \n",
        "    if len(headers) < 2:\n",
        "        raise ValueError('Insufficient number of ARI columns found in the header line.')\n",
        "\n",
        "    aris = headers[1:]  # Exclude the first column which is the duration\n",
        "\n",
        "    # Define the pattern for data lines\n",
        "    duration_pattern = re.compile(r'^\\d+-(min|hr|day):')\n",
        "\n",
        "    # Initialize lists to store durations and corresponding depths\n",
        "    durations = []\n",
        "    depths = {ari: [] for ari in aris}\n",
        "\n",
        "    # Iterate over the lines following the header to extract data\n",
        "    for line in lines[header_line_idx + 1:]:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        if not duration_pattern.match(line):\n",
        "            break\n",
        "        parts = [part.strip() for part in line.split(',')]\n",
        "        if len(parts) != len(headers):\n",
        "            raise ValueError(f\"Data row does not match header columns: {line}\")\n",
        "        duration_str = parts[0]\n",
        "        try:\n",
        "            duration_hours = parse_duration(duration_str)\n",
        "        except ValueError as ve:\n",
        "            print(f\"Skipping line due to error: {ve}\")\n",
        "            continue\n",
        "        durations.append(duration_hours)\n",
        "        for ari, depth_str in zip(aris, parts[1:]):\n",
        "            try:\n",
        "                depth = float(depth_str)\n",
        "            except ValueError:\n",
        "                depth = np.nan\n",
        "            depths[ari].append(depth)\n",
        "\n",
        "    # Create the DataFrame\n",
        "    df = pd.DataFrame(depths, index=durations)\n",
        "    df.index.name = 'Duration_hours'\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_confidence_intervals(df_point, upper_factor=1.4, lower_factor=0.7):\n",
        "    \"\"\"\n",
        "    Creates upper and lower confidence interval DataFrames from point estimates.\n",
        "    \n",
        "    Parameters:\n",
        "    - df_point: DataFrame with point estimates\n",
        "    - upper_factor: Multiplier for upper CI (default 1.4 for ~90% CI)\n",
        "    - lower_factor: Multiplier for lower CI (default 0.7 for ~90% CI)\n",
        "    \n",
        "    Returns:\n",
        "    - Tuple of (df_lower, df_point, df_upper)\n",
        "    \"\"\"\n",
        "    df_upper = df_point * upper_factor\n",
        "    df_lower = df_point * lower_factor\n",
        "    \n",
        "    return df_lower, df_point, df_upper\n",
        "\n",
        "def get_time_interval(duration_hrs):\n",
        "    \"\"\"\n",
        "    Determines the appropriate time interval based on storm duration.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    duration_hrs : float\n",
        "        Storm duration in hours\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    float : Time interval in hours\n",
        "    \"\"\"\n",
        "    if duration_hrs >= 24:\n",
        "        return 1.0  # 1 hour for 24+ hour storms\n",
        "    elif duration_hrs >= 12:\n",
        "        return 0.5  # 30 minutes for 12-hour storms\n",
        "    elif duration_hrs >= 6:\n",
        "        return 0.25  # 15 minutes for 6-hour storms\n",
        "    else:\n",
        "        return 5.0 / 60.0  # 5 minutes for storms less than 6 hours\n",
        "\n",
        "def interpolate_depths(df, total_duration):\n",
        "    \"\"\"\n",
        "    Interpolates precipitation depths for each ARI on a log-log scale\n",
        "    using appropriate time intervals based on duration.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Precipitation frequency data with durations as index and ARIs as columns\n",
        "    total_duration : float\n",
        "        Total storm duration in hours\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (dict of interpolated depths, time array in hours)\n",
        "    \"\"\"\n",
        "    # Determine time interval based on duration\n",
        "    dt = get_time_interval(total_duration)\n",
        "    \n",
        "    # Create time array with appropriate interval\n",
        "    t_hours = np.arange(dt, total_duration + dt/2, dt)\n",
        "    \n",
        "    D = {}\n",
        "    for ari in df.columns:\n",
        "        durations = df.index.values\n",
        "        depths = df[ari].values\n",
        "        if np.any(depths <= 0):\n",
        "            raise ValueError(f\"Non-positive depth value in ARI {ari}\")\n",
        "        \n",
        "        # Log-log interpolation\n",
        "        log_durations = np.log(durations)\n",
        "        log_depths = np.log(depths)\n",
        "        log_t = np.log(t_hours)\n",
        "        log_D_t = np.interp(log_t, log_durations, log_depths)\n",
        "        D_t = np.exp(log_D_t)\n",
        "        D[ari] = D_t\n",
        "    \n",
        "    return D, t_hours\n",
        "\n",
        "def compute_incremental_depths(D, t_hours):\n",
        "    \"\"\"\n",
        "    Computes incremental precipitation depths for each time interval.\n",
        "    I(t) = D(t) - D(t-1), with D(0) = 0.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    D : dict\n",
        "        Dictionary of cumulative depths for each ARI\n",
        "    t_hours : array\n",
        "        Time array in hours\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary of incremental depths for each ARI\n",
        "    \"\"\"\n",
        "    incremental_depths = {}\n",
        "    for ari, D_t in D.items():\n",
        "        num_intervals = len(t_hours)\n",
        "        I_t = np.empty(num_intervals)\n",
        "        I_t[0] = D_t[0]\n",
        "        I_t[1:] = D_t[1:] - D_t[:-1]\n",
        "        incremental_depths[ari] = I_t\n",
        "    return incremental_depths\n",
        "\n",
        "def assign_alternating_block(sorted_depths, max_depth, central_index, num_intervals):\n",
        "    \"\"\"\n",
        "    Assigns incremental depths to the hyetograph using the Alternating Block Method.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    sorted_depths : list\n",
        "        Sorted incremental depths (descending)\n",
        "    max_depth : float\n",
        "        Maximum depth value\n",
        "    central_index : int\n",
        "        Index for peak position\n",
        "    num_intervals : int\n",
        "        Total number of time intervals\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list : Hyetograph array\n",
        "    \"\"\"\n",
        "    hyetograph = [0.0] * num_intervals\n",
        "    hyetograph[central_index] = max_depth\n",
        "    remaining_depths = sorted_depths.copy()\n",
        "    remaining_depths.remove(max_depth)\n",
        "    left = central_index - 1\n",
        "    right = central_index + 1\n",
        "    toggle = True\n",
        "    for depth in remaining_depths:\n",
        "        if toggle and right < num_intervals:\n",
        "            hyetograph[right] = depth\n",
        "            right += 1\n",
        "        elif not toggle and left >= 0:\n",
        "            hyetograph[left] = depth\n",
        "            left -= 1\n",
        "        elif right < num_intervals:\n",
        "            hyetograph[right] = depth\n",
        "            right += 1\n",
        "        elif left >= 0:\n",
        "            hyetograph[left] = depth\n",
        "            left -= 1\n",
        "        else:\n",
        "            print(\"Warning: Not all incremental depths assigned.\")\n",
        "            break\n",
        "        toggle = not toggle\n",
        "    return hyetograph\n",
        "\n",
        "def generate_hyetograph(incremental_depths, position_percent, num_intervals):\n",
        "    \"\"\"\n",
        "    Generates the hyetograph for a given ARI using the Alternating Block Method.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    incremental_depths : array\n",
        "        Incremental depths for each time interval\n",
        "    position_percent : float\n",
        "        Peak position as percentage (e.g., 50 for middle)\n",
        "    num_intervals : int\n",
        "        Total number of time intervals\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    list : Hyetograph array\n",
        "    \"\"\"\n",
        "    max_depth = np.max(incremental_depths)\n",
        "    incremental_depths_list = incremental_depths.tolist()\n",
        "    central_index = int(round(num_intervals * position_percent / 100)) - 1\n",
        "    central_index = max(0, min(central_index, num_intervals - 1))\n",
        "    sorted_depths = sorted(incremental_depths_list, reverse=True)\n",
        "    hyetograph = assign_alternating_block(sorted_depths, max_depth, central_index, num_intervals)\n",
        "    return hyetograph\n",
        "\n",
        "def save_hyetograph(hyetograph, t_hours, ari, duration_hrs, ci_level, output_dir, position_percent):\n",
        "    \"\"\"\n",
        "    Saves the hyetograph to a CSV file with clear naming convention.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    hyetograph : array\n",
        "        Hyetograph values\n",
        "    t_hours : array\n",
        "        Time array in hours\n",
        "    ari : int or str\n",
        "        Annual recurrence interval\n",
        "    duration_hrs : float\n",
        "        Storm duration in hours\n",
        "    ci_level : str\n",
        "        Confidence level ('lower', 'point', 'upper')\n",
        "    output_dir : str\n",
        "        Output directory path\n",
        "    position_percent : float\n",
        "        Peak position percentage\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    str : Path to saved file\n",
        "    \"\"\"\n",
        "    # Determine time interval\n",
        "    dt = get_time_interval(duration_hrs)\n",
        "    \n",
        "    # Create DataFrame with appropriate time units\n",
        "    if dt >= 1.0:\n",
        "        time_col_name = 'Time_hour'\n",
        "        time_values = t_hours\n",
        "    elif dt >= 1.0/60.0:\n",
        "        time_col_name = 'Time_min'\n",
        "        time_values = t_hours * 60  # Convert to minutes\n",
        "    else:\n",
        "        time_col_name = 'Time_hour'\n",
        "        time_values = t_hours\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        time_col_name: time_values,\n",
        "        'Precipitation_in': hyetograph\n",
        "    })\n",
        "    \n",
        "    # Format duration string\n",
        "    if duration_hrs >= 24:\n",
        "        dur_str = f\"{int(duration_hrs/24)}day\"\n",
        "    else:\n",
        "        dur_str = f\"{int(duration_hrs)}hr\"\n",
        "    \n",
        "    filename = f'hyetograph_ARI_{ari}_DUR_{dur_str}_CI_{ci_level}.csv'\n",
        "    output_file = os.path.join(output_dir, filename)\n",
        "    \n",
        "    # Add metadata as header comment\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(f\"# NOAA Atlas 14 Hyetograph\\n\")\n",
        "        f.write(f\"# ARI: {ari} years\\n\")\n",
        "        f.write(f\"# Duration: {duration_hrs} hours\\n\")\n",
        "        f.write(f\"# Time Interval: {dt*60:.1f} minutes\\n\")\n",
        "        f.write(f\"# Confidence Level: {ci_level}\\n\")\n",
        "        f.write(f\"# Peak Position: {position_percent}%\\n\")\n",
        "        f.write(f\"# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        df.to_csv(f, index=False)\n",
        "    \n",
        "    return output_file\n",
        "\n",
        "print(\"Hyetograph generation functions defined (with variable time intervals)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Complete Scenario Matrix\n",
        "\n",
        "Create hyetographs for all combinations of:\n",
        "- AEP events: 2, 5, 10, 25, 50, 100 years\n",
        "- Durations: 1hr, 2hr, 3hr, 6hr, 12hr, 24hr, 2day\n",
        "- Confidence levels: lower, point, upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "input_csv = 'data/PF_Depth_English_PDS_DavisCA.csv'\n",
        "output_dir = 'hyetographs_uncertainty'\n",
        "position_percent = 50\n",
        "base_plan = \"02\"\n",
        "\n",
        "# Define scenario parameters\n",
        "aep_events = [2, 5, 10, 25, 50, 100]\n",
        "durations = [1, 2, 3, 6, 12, 24, 48]  # hours\n",
        "ci_levels = ['lower', 'point', 'upper']\n",
        "ci_factors = {'lower': 0.7, 'point': 1.0, 'upper': 1.4}\n",
        "\n",
        "# Create output directory\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"\\nScenario Matrix:\")\n",
        "print(f\"  AEP Events: {aep_events}\")\n",
        "print(f\"  Durations: {durations} hours\")\n",
        "print(f\"  CI Levels: {ci_levels}\")\n",
        "print(f\"  Total Scenarios: {len(aep_events) * len(durations) * len(ci_levels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read precipitation data\n",
        "print(\"Reading NOAA Atlas 14 data...\")\n",
        "df_point = read_precipitation_data(input_csv)\n",
        "print(f\"Successfully read data with {len(df_point)} durations and {len(df_point.columns)} ARI values\")\n",
        "\n",
        "# Display the data\n",
        "print(\"\\nPrecipitation Frequency Data (Point Estimates):\")\n",
        "display.display(df_point.head(10))\n",
        "\n",
        "# Create confidence interval DataFrames\n",
        "print(\"\\nGenerating confidence intervals...\")\n",
        "df_lower, df_point, df_upper = create_confidence_intervals(df_point)\n",
        "print(\"Confidence intervals created:\")\n",
        "print(f\"  Lower CI factor: {ci_factors['lower']}\")\n",
        "print(f\"  Point estimate factor: {ci_factors['point']}\")\n",
        "print(f\"  Upper CI factor: {ci_factors['upper']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all hyetographs\n",
        "print(\"Generating hyetographs with variable time intervals...\\n\")\n",
        "print(\"Time Interval Rules:\")\n",
        "print(\"  \u2022 24+ hour storms: 1-hour intervals\")\n",
        "print(\"  \u2022 12-hour storms: 30-minute intervals\")\n",
        "print(\"  \u2022 6-hour storms: 15-minute intervals\")\n",
        "print(\"  \u2022 < 6-hour storms: 5-minute intervals\\n\")\n",
        "\n",
        "scenario_list = []\n",
        "hyetograph_count = 0\n",
        "\n",
        "for ari in aep_events:\n",
        "    ari_str = str(ari)\n",
        "    \n",
        "    # Check if this ARI is in the data\n",
        "    if ari_str not in df_point.columns:\n",
        "        print(f\"Warning: ARI {ari_str} not found in data. Skipping.\")\n",
        "        continue\n",
        "    \n",
        "    for duration in durations:\n",
        "        # Get time interval for this duration\n",
        "        dt = get_time_interval(duration)\n",
        "        print(f\"Processing {ari}-yr, {duration}-hr storm (dt={dt*60:.1f} min)...\")\n",
        "        \n",
        "        # Process each confidence level\n",
        "        for ci_level in ci_levels:\n",
        "            # Select the appropriate DataFrame\n",
        "            if ci_level == 'lower':\n",
        "                df_current = df_lower\n",
        "            elif ci_level == 'upper':\n",
        "                df_current = df_upper\n",
        "            else:\n",
        "                df_current = df_point\n",
        "            \n",
        "            # Interpolate depths with appropriate time interval\n",
        "            D, t_hours = interpolate_depths(df_current, duration)\n",
        "            \n",
        "            # Compute incremental depths\n",
        "            inc_depths = compute_incremental_depths(D, t_hours)\n",
        "            \n",
        "            # Generate hyetograph\n",
        "            num_intervals = len(t_hours)\n",
        "            hyetograph = generate_hyetograph(inc_depths[ari_str], position_percent, num_intervals)\n",
        "            \n",
        "            # Save hyetograph\n",
        "            file_path = save_hyetograph(hyetograph, t_hours, ari_str, duration, ci_level, \n",
        "                                       output_dir, position_percent)\n",
        "            \n",
        "            # Record scenario\n",
        "            scenario_list.append({\n",
        "                'ari': ari,\n",
        "                'duration_hrs': duration,\n",
        "                'time_interval_min': dt * 60,\n",
        "                'num_intervals': num_intervals,\n",
        "                'ci_level': ci_level,\n",
        "                'hyetograph_file': file_path,\n",
        "                'total_depth_in': sum(hyetograph)\n",
        "            })\n",
        "            \n",
        "            hyetograph_count += 1\n",
        "\n",
        "# Create scenario DataFrame\n",
        "scenario_df = pd.DataFrame(scenario_list)\n",
        "\n",
        "print(f\"\\n\u2713 Generated {hyetograph_count} hyetographs\")\n",
        "print(f\"\\nScenario Summary (first 12 rows):\")\n",
        "display.display(scenario_df.head(12))\n",
        "\n",
        "# Save scenario list\n",
        "scenario_csv = 'scenarios_uncertainty.csv'\n",
        "scenario_df.to_csv(scenario_csv, index=False)\n",
        "print(f\"\\nScenario list saved to: {scenario_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "precip-depth-header",
      "metadata": {},
      "source": [
        "## Total Precipitation Depth Analysis\n",
        "\n",
        "Visualize total precipitation depths across all scenarios with confidence intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "precip-depth-plot",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your data is in scenario_df with columns: duration_hrs, ari, ci_level, total_depth_in\n",
        "\n",
        "# Create the plots\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Define your ARI events (adjust based on your data)\n",
        "aep_events = [2, 5, 10, 25, 50, 100]\n",
        "\n",
        "for idx, ari in enumerate(aep_events):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Extract data for this specific ARI\n",
        "    ari_data = scenario_df[scenario_df['ari'] == ari].copy()\n",
        "\n",
        "    # Get unique durations\n",
        "    durations = sorted(ari_data['duration_hrs'].unique())\n",
        "\n",
        "    # Initialize lists to store values\n",
        "    lower_vals = []\n",
        "    upper_vals = []\n",
        "    point_vals = []\n",
        "    ci_percentages = []\n",
        "\n",
        "    # Process each duration\n",
        "    for dur in durations:\n",
        "        # Get data for this specific duration\n",
        "        dur_data = ari_data[ari_data['duration_hrs'] == dur]\n",
        "\n",
        "        # Extract values for each CI level\n",
        "        lower_val = dur_data[dur_data['ci_level'] == 'lower']['total_depth_in'].values\n",
        "        upper_val = dur_data[dur_data['ci_level'] == 'upper']['total_depth_in'].values\n",
        "        point_val = dur_data[dur_data['ci_level'] == 'point']['total_depth_in'].values\n",
        "\n",
        "        # Handle missing data\n",
        "        if len(lower_val) > 0 and len(upper_val) > 0 and len(point_val) > 0:\n",
        "            lower = float(lower_val[0])\n",
        "            upper = float(upper_val[0])\n",
        "            point = float(point_val[0])\n",
        "\n",
        "            # Calculate CI width as percentage of point estimate\n",
        "            # Using point estimate as the reference (you could also use mean of upper/lower)\n",
        "            if point > 0:\n",
        "                ci_width = upper - lower\n",
        "                ci_pct = (ci_width / point) * 100\n",
        "            else:\n",
        "                ci_pct = np.nan\n",
        "        else:\n",
        "            lower = upper = point = ci_pct = np.nan\n",
        "\n",
        "        lower_vals.append(lower)\n",
        "        upper_vals.append(upper)\n",
        "        point_vals.append(point)\n",
        "        ci_percentages.append(ci_pct)\n",
        "\n",
        "    # Convert to arrays\n",
        "    lower_vals = np.array(lower_vals)\n",
        "    upper_vals = np.array(upper_vals)\n",
        "    point_vals = np.array(point_vals)\n",
        "    ci_percentages = np.array(ci_percentages)\n",
        "\n",
        "    # Plot the data\n",
        "    ax.plot(durations, point_vals,\n",
        "            'ko-', linewidth=2, markersize=6, label='Point Estimate')\n",
        "    ax.fill_between(durations,\n",
        "                    lower_vals,\n",
        "                    upper_vals,\n",
        "                    alpha=0.3, color='gray', label='90% CI')\n",
        "\n",
        "    # Calculate spacing for annotations\n",
        "    y_range = np.nanmax(upper_vals) - np.nanmin(lower_vals)\n",
        "\n",
        "    # Add annotations for each point\n",
        "    for i, (x, y_lower, y_upper, y_point, ci_pct) in enumerate(zip(\n",
        "            durations, lower_vals, upper_vals, point_vals, ci_percentages)):\n",
        "\n",
        "        if not np.isnan(y_lower):\n",
        "            # Annotate lower bound\n",
        "            ax.text(x, y_lower - 0.02 * y_range, f'{y_lower:.2f}',\n",
        "                    fontsize=8, ha='center', va='top')\n",
        "\n",
        "        if not np.isnan(y_upper):\n",
        "            # Annotate upper bound\n",
        "            ax.text(x, y_upper + 0.02 * y_range, f'{y_upper:.2f}',\n",
        "                    fontsize=8, ha='center', va='bottom')\n",
        "\n",
        "        if not np.isnan(y_point):\n",
        "            # Annotate point estimate\n",
        "            ax.text(x, y_point, f'{y_point:.2f}',\n",
        "                    fontsize=8, color='darkgray', ha='left', va='bottom',\n",
        "                    fontweight='bold')\n",
        "\n",
        "        if not np.isnan(ci_pct):\n",
        "            # Annotate CI percentage in the middle of the CI band\n",
        "            y_mid = (y_lower + y_upper) / 2\n",
        "            ax.text(x, y_mid, f'{ci_pct:.1f}%',\n",
        "                    fontsize=8, color='royalblue', ha='center', va='center',\n",
        "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='white',\n",
        "                             edgecolor='none', alpha=0.7))\n",
        "\n",
        "    # Set labels and formatting\n",
        "    ax.set_xlabel('Duration (hours)', fontsize=10)\n",
        "    ax.set_ylabel('Total Precipitation (inches)', fontsize=10)\n",
        "    ax.set_title(f'{ari}-Year Event', fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(loc='upper left', fontsize=8)\n",
        "\n",
        "    # Set x-axis to log scale\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xticks(durations)\n",
        "    ax.set_xticklabels([str(d) for d in durations])\n",
        "\n",
        "    # Adjust y-limits to accommodate annotations\n",
        "    y_min = np.nanmin(lower_vals) - 0.1 * y_range\n",
        "    y_max = np.nanmax(upper_vals) + 0.1 * y_range\n",
        "    ax.set_ylim(y_min, y_max)\n",
        "\n",
        "plt.suptitle('Total Precipitation Depth vs Duration with Confidence Intervals\\n(CI width as % of point estimate at each duration)',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Also print out the actual CI percentages to verify\n",
        "print(\"\\nConfidence Interval Width as % of Point Estimate:\")\n",
        "print(\"=\"*60)\n",
        "for ari in aep_events:\n",
        "    print(f\"\\n{ari}-Year Event:\")\n",
        "    ari_data = scenario_df[scenario_df['ari'] == ari].copy()\n",
        "    durations = sorted(ari_data['duration_hrs'].unique())\n",
        "\n",
        "    for dur in durations:\n",
        "        dur_data = ari_data[ari_data['duration_hrs'] == dur]\n",
        "        lower = dur_data[dur_data['ci_level'] == 'lower']['total_depth_in'].values\n",
        "        upper = dur_data[dur_data['ci_level'] == 'upper']['total_depth_in'].values\n",
        "        point = dur_data[dur_data['ci_level'] == 'point']['total_depth_in'].values\n",
        "\n",
        "        if len(lower) > 0 and len(upper) > 0 and len(point) > 0:\n",
        "            ci_width = upper[0] - lower[0]\n",
        "            ci_pct = (ci_width / point[0]) * 100\n",
        "            print(f\"  {dur:2d} hr: {ci_pct:.1f}% (L:{lower[0]:.2f}, P:{point[0]:.2f}, U:{upper[0]:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Sample Hyetographs\n",
        "\n",
        "Show how confidence intervals affect hyetograph shapes for a few example scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hyeto-plot-functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_hyetograph_with_ci(ari, duration, output_dir, save_dir=None):\n",
        "    \"\"\"\n",
        "    Plot hyetograph showing lower CI, Atlas 14 estimate, and upper CI.\n",
        "    Handles variable time intervals (hours or minutes) based on duration.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    ari : int\n",
        "        Annual recurrence interval (return period)\n",
        "    duration : int\n",
        "        Storm duration in hours\n",
        "    output_dir : str\n",
        "        Directory containing hyetograph CSV files\n",
        "    save_dir : str, optional\n",
        "        Directory to save PNG files. If None, only displays plot.\n",
        "    \"\"\"\n",
        "    # Format duration string\n",
        "    if duration >= 24:\n",
        "        dur_str = f\"{int(duration/24)}day\"\n",
        "        dur_label = f\"{int(duration/24)}-day\"\n",
        "    else:\n",
        "        dur_str = f\"{int(duration)}hr\"\n",
        "        dur_label = f\"{int(duration)}-hr\"\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    # Define colors - using distinct, professional colors without transparency\n",
        "    colors = {\n",
        "        'lower': '#4472C4',   # Professional blue\n",
        "        'point': '#2C2C2C',   # Dark gray/black\n",
        "        'upper': '#C55A5A'    # Professional red\n",
        "    }\n",
        "\n",
        "    # Store data for proper ordering\n",
        "    ci_data = {}\n",
        "\n",
        "    # Read hyetographs for each CI level\n",
        "    for ci_level in ['lower', 'point', 'upper']:\n",
        "        filename = f'hyetograph_ARI_{ari}_DUR_{dur_str}_CI_{ci_level}.csv'\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "        # Skip header lines\n",
        "        df = pd.read_csv(filepath, comment='#')\n",
        "        ci_data[ci_level] = df\n",
        "\n",
        "    # Determine time column name and units\n",
        "    if 'Time_hour' in ci_data['point'].columns:\n",
        "        time_col = 'Time_hour'\n",
        "        time_label = 'Time (hours)'\n",
        "        time_values = ci_data['point'][time_col]\n",
        "        bar_width = 0.8  # Standard width for hourly data\n",
        "    elif 'Time_min' in ci_data['point'].columns:\n",
        "        time_col = 'Time_min'\n",
        "        time_label = 'Time (minutes)'\n",
        "        time_values = ci_data['point'][time_col]\n",
        "        # Adjust bar width based on time interval\n",
        "        time_interval = time_values.iloc[1] - time_values.iloc[0] if len(time_values) > 1 else 5\n",
        "        bar_width = time_interval * 0.8  # 80% of interval width\n",
        "    else:\n",
        "        raise ValueError(\"Could not find time column (Time_hour or Time_min) in CSV\")\n",
        "\n",
        "    # Get the data arrays\n",
        "    x_time = ci_data['point'][time_col]\n",
        "    lower_precip = ci_data['lower']['Precipitation_in']\n",
        "    point_precip = ci_data['point']['Precipitation_in']\n",
        "    upper_precip = ci_data['upper']['Precipitation_in']\n",
        "\n",
        "    # Calculate the incremental heights for stacking\n",
        "    height_lower = lower_precip\n",
        "    height_point_increment = point_precip - lower_precip\n",
        "    height_upper_increment = upper_precip - point_precip\n",
        "\n",
        "    # Plot stacked bars\n",
        "    ax.bar(x_time, height_lower,\n",
        "           width=bar_width,\n",
        "           alpha=1.0,\n",
        "           color=colors['lower'],\n",
        "           label='90% Lower CI',\n",
        "           edgecolor='none')\n",
        "\n",
        "    ax.bar(x_time, height_point_increment,\n",
        "           width=bar_width,\n",
        "           bottom=height_lower,\n",
        "           alpha=1.0,\n",
        "           color=colors['point'],\n",
        "           label='NOAA Atlas 14 Estimate',\n",
        "           edgecolor='none')\n",
        "\n",
        "    ax.bar(x_time, height_upper_increment,\n",
        "           width=bar_width,\n",
        "           bottom=point_precip,\n",
        "           alpha=1.0,\n",
        "           color=colors['upper'],\n",
        "           label='90% Upper CI',\n",
        "           edgecolor='none')\n",
        "\n",
        "    ax.set_xlabel(time_label, fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Incremental Precipitation (inches)', fontsize=12, fontweight='bold')\n",
        "\n",
        "    title = f'{ari}-Year {dur_label} Design Storm\\nNOAA Atlas 14 Precipitation with 90% Confidence Bounds'\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "\n",
        "    ax.legend(fontsize=10, loc='upper right', framealpha=0.95)\n",
        "    ax.grid(axis='y', alpha=0.3, zorder=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save if directory specified\n",
        "    if save_dir is not None:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        filename = f'{ari}yr_{dur_str}_storm_CI.png'\n",
        "        filepath = os.path.join(save_dir, filename)\n",
        "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Hyetograph plotting functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# HYETOGRAPH VISUALIZATION WITH CONFIDENCE INTERVALS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"HYETOGRAPH VISUALIZATION WITH CONFIDENCE INTERVALS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Generate ALL hyetographs and save to folder (without displaying)\n",
        "print(\"\\nGenerating and saving all hyetograph plots...\")\n",
        "print(\"(Only displaying 10-Year 6-Hour and 100-Year 24-Hour storms)\\n\")\n",
        "\n",
        "# Define all scenarios\n",
        "ari_values = [2, 5, 10, 25, 50, 100]\n",
        "duration_values = [1, 2, 3, 6, 12, 24, 48]  # 48 = 2 days\n",
        "save_dir = \"Atlas 14 Storm Hyetographs\"\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "total_plots = len(ari_values) * len(duration_values)\n",
        "current = 0\n",
        "generated_count = 0\n",
        "\n",
        "for ari in ari_values:\n",
        "    for duration in duration_values:\n",
        "        current += 1\n",
        "\n",
        "        # Format duration string\n",
        "        if duration >= 24:\n",
        "            dur_str = f\"{int(duration/24)}day\"\n",
        "        else:\n",
        "            dur_str = f\"{int(duration)}hr\"\n",
        "\n",
        "        # Check if files exist\n",
        "        filename = f'hyetograph_ARI_{ari}_DUR_{dur_str}_CI_point.csv'\n",
        "        filepath = os.path.join(output_dir, filename)\n",
        "\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"[{current}/{total_plots}] Skipping {ari}-yr, {dur_str} - files not found\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Only DISPLAY these two specific plots\n",
        "            if (ari == 10 and duration == 6) or (ari == 100 and duration == 24):\n",
        "                print(f\"\\n[{current}/{total_plots}] Displaying {ari}-yr, {dur_str} storm...\")\n",
        "                plot_hyetograph_with_ci(ari, duration, output_dir, save_dir)\n",
        "            else:\n",
        "                # Generate and save without displaying\n",
        "                print(f\"[{current}/{total_plots}] Generating {ari}-yr, {dur_str} storm...\", end='')\n",
        "\n",
        "                # Call the function but close the plot immediately to avoid display\n",
        "                import matplotlib\n",
        "                matplotlib.use('Agg')  # Use non-interactive backend\n",
        "                plot_hyetograph_with_ci(ari, duration, output_dir, save_dir)\n",
        "                plt.close('all')  # Close all figures\n",
        "                matplotlib.use('module://matplotlib_inline.backend_inline')  # Restore interactive backend\n",
        "\n",
        "                print(\" saved.\")\n",
        "\n",
        "            generated_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "\n",
        "print(f\"\\n{'=' * 70}\")\n",
        "print(f\"COMPLETE\")\n",
        "print(f\"{'=' * 70}\")\n",
        "print(f\"\u2713 Generated and saved {generated_count} hyetograph plots to: {save_dir}\")\n",
        "print(f\"\u2713 Displayed 2 key scenarios (10-Year 6-Hour and 100-Year 24-Hour)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison of Total Depths Across Scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyetograph visualization completed in cell above\n",
        "# All hyetograph plots have been generated and saved to \"Atlas 14 Storm Hyetographs\" directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize HEC-RAS Project and Create Plans\n",
        "\n",
        "Now we'll create a plan for each scenario in our matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plan Creation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_simulation_duration_from_plan(plan_number, project):\n",
        "    \"\"\"\n",
        "    Get the simulation duration in hours from a plan file.\n",
        "\n",
        "    Parameters:\n",
        "    - plan_number: Plan number\n",
        "    - project: RAS project object\n",
        "\n",
        "    Returns:\n",
        "    - tuple: (start_datetime, end_datetime, duration_hours)\n",
        "    \"\"\"\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    plan_path = RasPlan.get_plan_path(plan_number, ras_object=project)\n",
        "\n",
        "    with open(plan_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Find Simulation Date line\n",
        "    for line in lines:\n",
        "        if line.startswith('Simulation Date='):\n",
        "            # Format: Simulation Date=10JAN2000,1200,11JAN2000,2400\n",
        "            parts = line.strip().split('=')[1].split(',')\n",
        "\n",
        "            start_date = parts[0]\n",
        "            start_time = parts[1]\n",
        "            end_date = parts[2]\n",
        "            end_time = parts[3]\n",
        "\n",
        "            # Parse dates (format: DDMMMYYYY, time: HHMM)\n",
        "            start_dt = datetime.strptime(f\"{start_date}{start_time}\", \"%d%b%Y%H%M\")\n",
        "            \n",
        "            # Handle special case: HEC-RAS uses \"2400\" to mean midnight (end of day)\n",
        "            if end_time == \"2400\":\n",
        "                end_dt = datetime.strptime(f\"{end_date}0000\", \"%d%b%Y%H%M\")\n",
        "                end_dt = end_dt + timedelta(days=1)\n",
        "            else:\n",
        "                end_dt = datetime.strptime(f\"{end_date}{end_time}\", \"%d%b%Y%H%M\")\n",
        "\n",
        "            # Calculate duration in hours\n",
        "            duration_hours = (end_dt - start_dt).total_seconds() / 3600\n",
        "\n",
        "            return start_dt, end_dt, duration_hours\n",
        "\n",
        "    # Default fallback\n",
        "    return None, None, 24.0\n",
        "\n",
        "\n",
        "def format_interval_for_hecras(interval_hours):\n",
        "    \"\"\"\n",
        "    Convert interval in hours to HEC-RAS format string.\n",
        "\n",
        "    Parameters:\n",
        "    - interval_hours: Time interval in hours (e.g., 0.0833 for 5 minutes)\n",
        "\n",
        "    Returns:\n",
        "    - str: HEC-RAS format (e.g., \"5MIN\", \"15MIN\", \"1HOUR\")\n",
        "    \"\"\"\n",
        "    interval_minutes = interval_hours * 60\n",
        "\n",
        "    if interval_minutes < 1.0:\n",
        "        # Less than 1 minute - shouldn't happen but handle it\n",
        "        seconds = interval_minutes * 60\n",
        "        return f\"{int(seconds)}SEC\"\n",
        "    elif interval_minutes < 60:\n",
        "        # Minutes\n",
        "        return f\"{int(interval_minutes)}MIN\"\n",
        "    else:\n",
        "        # Hours\n",
        "        hours = interval_hours\n",
        "        if hours == int(hours):\n",
        "            return f\"{int(hours)}HOUR\"\n",
        "        else:\n",
        "            # Fractional hours - convert to minutes\n",
        "            return f\"{int(interval_minutes)}MIN\"\n",
        "\n",
        "\n",
        "def modify_unsteady_flow_with_hyetograph(unsteady_file_path, hyetograph_file, plan_number=None, project=None):\n",
        "    \"\"\"\n",
        "    Modifies an unsteady flow file to incorporate hyetograph data as precipitation.\n",
        "    Handles time intervals and pads the hyetograph to cover the full simulation window.\n",
        "\n",
        "    Parameters:\n",
        "    - unsteady_file_path: Path to the unsteady flow file\n",
        "    - hyetograph_file: Path to the hyetograph data CSV\n",
        "    - plan_number: Plan number (for getting simulation duration)\n",
        "    - project: RAS project object\n",
        "\n",
        "    Returns:\n",
        "    - Boolean indicating success\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the hyetograph data (skip comment lines)\n",
        "        hyetograph_df = pd.read_csv(hyetograph_file, comment='#')\n",
        "\n",
        "        # Get the time interval from the hyetograph\n",
        "        if 'Time_hour' in hyetograph_df.columns:\n",
        "            time_values = hyetograph_df['Time_hour'].values\n",
        "        elif 'Time_min' in hyetograph_df.columns:\n",
        "            time_values = hyetograph_df['Time_min'].values / 60.0  # Convert to hours\n",
        "        else:\n",
        "            raise ValueError(\"Could not find time column in hyetograph file\")\n",
        "\n",
        "        # Calculate interval\n",
        "        if len(time_values) > 1:\n",
        "            interval_hours = time_values[1] - time_values[0]\n",
        "        else:\n",
        "            interval_hours = time_values[0]\n",
        "\n",
        "        # Get storm duration in hours\n",
        "        storm_duration_hours = time_values[-1]\n",
        "\n",
        "        # Get simulation duration from plan file\n",
        "        if plan_number and project:\n",
        "            start_dt, end_dt, sim_duration_hours = get_simulation_duration_from_plan(plan_number, project)\n",
        "        else:\n",
        "            # Default: assume 36-hour simulation\n",
        "            sim_duration_hours = 36.0\n",
        "\n",
        "        print(f\"  Storm duration: {storm_duration_hours:.2f} hours\")\n",
        "        print(f\"  Time interval: {interval_hours*60:.1f} minutes\")\n",
        "        print(f\"  Simulation duration: {sim_duration_hours:.1f} hours\")\n",
        "\n",
        "        # Calculate total number of intervals needed\n",
        "        total_intervals = int(sim_duration_hours / interval_hours)\n",
        "\n",
        "        # Get precipitation values from hyetograph\n",
        "        precip_values = hyetograph_df[\"Precipitation_in\"].values\n",
        "\n",
        "        # Calculate where to place the storm (at the beginning of simulation)\n",
        "        warmup_hours = 0.0\n",
        "        warmup_intervals = int(warmup_hours / interval_hours)\n",
        "\n",
        "        # Create full precipitation array with zeros\n",
        "        full_precip = np.zeros(total_intervals)\n",
        "\n",
        "        # Insert storm values after warmup period\n",
        "        storm_intervals = len(precip_values)\n",
        "        if warmup_intervals + storm_intervals <= total_intervals:\n",
        "            full_precip[warmup_intervals:warmup_intervals + storm_intervals] = precip_values\n",
        "        else:\n",
        "            # If storm doesn't fit, place at start\n",
        "            end_idx = min(storm_intervals, total_intervals)\n",
        "            full_precip[0:end_idx] = precip_values[0:end_idx]\n",
        "\n",
        "        print(f\"  Total intervals in simulation: {total_intervals}\")\n",
        "        print(f\"  Storm placed at interval {warmup_intervals} (at simulation start)\")\n",
        "\n",
        "        # Read the unsteady flow file\n",
        "        with open(unsteady_file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        # Find the Interval line and update it\n",
        "        interval_line_idx = None\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.startswith(\"Interval=\"):\n",
        "                interval_line_idx = i\n",
        "                break\n",
        "\n",
        "        if interval_line_idx is not None:\n",
        "            # Update the interval\n",
        "            interval_str = format_interval_for_hecras(interval_hours)\n",
        "            lines[interval_line_idx] = f\"Interval={interval_str}\\n\"\n",
        "            print(f\"  Updated Interval to: {interval_str}\")\n",
        "\n",
        "        # Find the Precipitation Hydrograph section\n",
        "        precip_hydrograph_index = None\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.startswith(\"Precipitation Hydrograph=\"):\n",
        "                precip_hydrograph_index = i\n",
        "                break\n",
        "\n",
        "        if precip_hydrograph_index is None:\n",
        "            print(\"Cannot find Precipitation Hydrograph section in unsteady file.\")\n",
        "            return False\n",
        "\n",
        "        # Create the Precipitation Hydrograph line\n",
        "        precip_line = f\"Precipitation Hydrograph= {len(full_precip)} \\n\"\n",
        "\n",
        "        # Format the values in groups of 10 per line\n",
        "        value_lines = []\n",
        "        for i in range(0, len(full_precip), 10):\n",
        "            row_values = full_precip[i:i+10]\n",
        "            row_line = \"\".join([f\"{value:8.2f}\" for value in row_values]) + \"\\n\"\n",
        "            value_lines.append(row_line)\n",
        "\n",
        "        # Find end of current hydrograph\n",
        "        current_line = precip_hydrograph_index + 1\n",
        "        end_markers = [\"DSS Path=\", \"Use DSS=\", \"Use Fixed Start Time=\"]\n",
        "        while current_line < len(lines) and not any(lines[current_line].startswith(marker) for marker in end_markers):\n",
        "            current_line += 1\n",
        "\n",
        "        # Replace the hydrograph section\n",
        "        lines[precip_hydrograph_index:current_line] = [precip_line] + value_lines\n",
        "\n",
        "        # Write the modified file back\n",
        "        with open(unsteady_file_path, 'w') as file:\n",
        "            file.writelines(lines)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error modifying unsteady flow file: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "\n",
        "def create_plan_for_scenario(scenario_row, base_plan, project):\n",
        "    \"\"\"\n",
        "    Creates a new plan for a specific scenario.\n",
        "\n",
        "    Parameters:\n",
        "    - scenario_row: Row from scenario DataFrame\n",
        "    - base_plan: Base plan number to clone from\n",
        "    - project: RAS project object\n",
        "\n",
        "    Returns:\n",
        "    - new_plan_number\n",
        "    \"\"\"\n",
        "    ari = scenario_row['ari']\n",
        "    duration = scenario_row['duration_hrs']\n",
        "    ci_level = scenario_row['ci_level']\n",
        "    hyetograph_file = scenario_row['hyetograph_file']\n",
        "\n",
        "    # Format duration string\n",
        "    if duration >= 24:\n",
        "        dur_str = f\"{int(duration/24)}D\"\n",
        "    else:\n",
        "        dur_str = f\"{int(duration)}H\"\n",
        "\n",
        "    # Create plan name (keep it short for HEC-RAS)\n",
        "    ci_abbrev = ci_level[0].upper()  # L, P, or U\n",
        "    plan_name = f\"{ari}YR-{dur_str}-{ci_abbrev}\"\n",
        "\n",
        "    # Clone the base plan\n",
        "    new_plan_number = RasPlan.clone_plan(base_plan, new_shortid=plan_name, ras_object=project)\n",
        "\n",
        "    # Get unsteady number from base plan\n",
        "    base_unsteady = None\n",
        "    for _, row in project.plan_df.iterrows():\n",
        "        if row['plan_number'] == base_plan:\n",
        "            base_unsteady = row.get('unsteady_number', None)\n",
        "            break\n",
        "\n",
        "    if base_unsteady is None:\n",
        "        raise ValueError(f\"Could not find unsteady flow file for base plan {base_plan}\")\n",
        "\n",
        "    # Clone the unsteady flow file\n",
        "    new_unsteady_number = RasPlan.clone_unsteady(base_unsteady, ras_object=project)\n",
        "\n",
        "    # Get unsteady file path\n",
        "    unsteady_file_path = RasPlan.get_unsteady_path(new_unsteady_number, ras_object=project)\n",
        "\n",
        "    # Update the flow title\n",
        "    new_title = f\"{ari}YR-{dur_str}-{ci_level.upper()} Storm\"\n",
        "    RasUnsteady.update_flow_title(unsteady_file_path, new_title, ras_object=project)\n",
        "\n",
        "    # Modify the unsteady flow file with the hyetograph data\n",
        "    # Pass plan number and project so we can get simulation duration\n",
        "    hyetograph_file_abs = Path(hyetograph_file).absolute()\n",
        "    success = modify_unsteady_flow_with_hyetograph(\n",
        "        unsteady_file_path,\n",
        "        hyetograph_file_abs,\n",
        "        plan_number=new_plan_number,\n",
        "        project=project\n",
        "    )\n",
        "    if not success:\n",
        "        raise RuntimeError(f\"Failed to apply hyetograph data to plan {new_plan_number}\")\n",
        "\n",
        "    # Assign the unsteady flow file to the plan\n",
        "    RasPlan.set_unsteady(new_plan_number, new_unsteady_number, ras_object=project)\n",
        "\n",
        "    return new_plan_number\n",
        "\n",
        "print(\"Plan creation functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling the 99-Plan Limit in HEC-RAS\n",
        "\n",
        "**IMPORTANT**: HEC-RAS projects can only contain a maximum of 99 plans. Since this analysis requires 126 scenarios (6 AEPs \u00d7 7 durations \u00d7 3 confidence levels), we need to distribute scenarios across multiple project copies.\n",
        "\n",
        "**Solution Approach:**\n",
        "1. **Automatic Project Distribution**: The `distribute_scenarios_across_projects()` function automatically:\n",
        "   - Checks existing plan count in the base project\n",
        "   - Calculates available slots (99 - existing plans)\n",
        "   - Creates multiple project copies as needed\n",
        "   - Groups scenarios logically (by AEP) to keep related runs together\n",
        "   \n",
        "2. **Project Naming**: New projects are created with meaningful names:\n",
        "   - Format: `{project_name}{suffix}_{number}`\n",
        "   - Example: `Davis_atlas14_01`, `Davis_atlas14_02`, etc.\n",
        "   - The suffix is user-configurable (default: `_atlas14`)\n",
        "\n",
        "3. **Plan Descriptions**: Each plan's description includes:\n",
        "   - AEP (return period)\n",
        "   - Storm duration\n",
        "   - Confidence level\n",
        "   - Analysis set identifier (the folder suffix)\n",
        "   \n",
        "4. **Original Project Preservation**: The base project is never modified - all new plans are created in project copies\n",
        "\n",
        "**Configuration Options:**\n",
        "- `folder_suffix`: Change the suffix added to project folders (default: `\"_atlas14\"`)\n",
        "- Modify the grouping strategy in `distribute_scenarios_across_projects()` if needed\n",
        "  (currently groups by AEP to keep related scenarios together)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Multi-Project Management Functions for 99-Plan Limit\n",
        "\n",
        "import shutil\n",
        "\n",
        "def copy_ras_project(source_folder, dest_folder, suffix=\"\"):\n",
        "    \"\"\"\n",
        "    Copy a HEC-RAS project to a new folder.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    source_folder : Path or str\n",
        "        Source project folder\n",
        "    dest_folder : Path or str\n",
        "        Destination folder\n",
        "    suffix : str, optional\n",
        "        Suffix to add to project name\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Path : Path to destination folder\n",
        "    \"\"\"\n",
        "    source_folder = Path(source_folder)\n",
        "    dest_folder = Path(dest_folder)\n",
        "\n",
        "    # Create destination\n",
        "    dest_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copy all files\n",
        "    for item in source_folder.iterdir():\n",
        "        if item.is_file():\n",
        "            shutil.copy2(item, dest_folder / item.name)\n",
        "        elif item.is_dir() and item.name not in ['compute_uncertainty', '.ipynb_checkpoints']:\n",
        "            shutil.copytree(item, dest_folder / item.name, dirs_exist_ok=True)\n",
        "\n",
        "    print(f\"Copied project to: {dest_folder}\")\n",
        "    return dest_folder\n",
        "\n",
        "\n",
        "def distribute_scenarios_across_projects(scenario_df, base_project_path, base_plan=\"02\",\n",
        "                                         folder_suffix=\"_atlas14\", ras_version=\"6.6\"):\n",
        "    \"\"\"\n",
        "    Distribute scenarios across multiple HEC-RAS project copies to handle 99-plan limit.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    scenario_df : DataFrame\n",
        "        Scenarios to process\n",
        "    base_project_path : Path or str\n",
        "        Original project path\n",
        "    base_plan : str\n",
        "        Base plan number to clone from\n",
        "    folder_suffix : str\n",
        "        Suffix for project folders (default: \"_atlas14\")\n",
        "    ras_version : str\n",
        "        HEC-RAS version\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    DataFrame : scenario_df with added columns: project_folder, project_object, plan_number\n",
        "    \"\"\"\n",
        "    base_project_path = Path(base_project_path)\n",
        "\n",
        "    # Check base project existing plans\n",
        "    temp_proj = RasPrj()\n",
        "    init_ras_project(base_project_path, ras_version, ras_object=temp_proj)\n",
        "    existing_plans_in_base = len(temp_proj.plan_df)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"DISTRIBUTING SCENARIOS ACROSS PROJECTS (99-PLAN LIMIT)\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nBase project has {existing_plans_in_base} existing plans\")\n",
        "    print(f\"Maximum plans per project: 99\")\n",
        "    print(f\"Total scenarios to distribute: {len(scenario_df)}\\n\")\n",
        "\n",
        "    # Calculate how many scenarios we can fit per project\n",
        "    max_scenarios_per_project = 99 - existing_plans_in_base\n",
        "\n",
        "    # Group scenarios by ARI to keep related scenarios together\n",
        "    ari_groups = scenario_df.groupby('ari')\n",
        "\n",
        "    results_list = []\n",
        "    current_project_num = 1\n",
        "    current_project_path = None\n",
        "    current_project_obj = None\n",
        "    current_project_plan_count = 0\n",
        "\n",
        "    for ari, ari_df in ari_groups:\n",
        "        num_scenarios_in_group = len(ari_df)\n",
        "\n",
        "        print(f\"Processing {ari}-year AEP ({num_scenarios_in_group} scenarios)...\")\n",
        "\n",
        "        # Check if we need to create a new project\n",
        "        if current_project_obj is None or (current_project_plan_count + num_scenarios_in_group) > max_scenarios_per_project:\n",
        "            # Create a new project\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"Creating Project #{current_project_num}\")\n",
        "            print(f\"{'='*70}\")\n",
        "\n",
        "            # Create project folder with meaningful name\n",
        "            project_folder_name = f\"{base_project_path.name}{folder_suffix}_{current_project_num:02d}\"\n",
        "            current_project_path = base_project_path.parent / project_folder_name\n",
        "\n",
        "            # Copy the project\n",
        "            copy_ras_project(base_project_path, current_project_path)\n",
        "\n",
        "            # Initialize the project\n",
        "            current_project_obj = RasPrj()\n",
        "            init_ras_project(current_project_path, ras_version, ras_object=current_project_obj)\n",
        "\n",
        "            # Reset counter to existing plans in the new copy\n",
        "            current_project_plan_count = len(current_project_obj.plan_df)\n",
        "            print(f\"Project initialized with {current_project_plan_count} existing plans\")\n",
        "            print(f\"Available slots: {99 - current_project_plan_count}\")\n",
        "\n",
        "            current_project_num += 1\n",
        "\n",
        "        # Add all scenarios from this ARI group to the current project\n",
        "        for idx, scenario in ari_df.iterrows():\n",
        "            scenario['project_folder'] = str(current_project_path)\n",
        "            scenario['project_object'] = current_project_obj\n",
        "            scenario['project_suffix'] = folder_suffix\n",
        "            results_list.append(scenario)\n",
        "            current_project_plan_count += 1\n",
        "\n",
        "        print(f\"  Added {num_scenarios_in_group} scenarios to project {current_project_path.name}\")\n",
        "        print(f\"  Current plan count: {current_project_plan_count}/{99}\")\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"DISTRIBUTION SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total scenarios: {len(results_df)}\")\n",
        "    print(f\"Projects created: {current_project_num - 1}\")\n",
        "    print(f\"\\nScenarios per project:\")\n",
        "    for proj_folder in results_df['project_folder'].unique():\n",
        "        count = len(results_df[results_df['project_folder'] == proj_folder])\n",
        "        print(f\"  {Path(proj_folder).name}: {count} scenarios\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "\n",
        "def create_plan_with_description(scenario_row, base_plan, project, folder_suffix):\n",
        "    \"\"\"\n",
        "    Creates a new plan for a scenario with description including folder suffix.\n",
        "\n",
        "    Parameters:\n",
        "    - scenario_row: Row from scenario DataFrame\n",
        "    - base_plan: Base plan number to clone from\n",
        "    - project: RAS project object\n",
        "    - folder_suffix: Folder suffix to add to description\n",
        "\n",
        "    Returns:\n",
        "    - new_plan_number\n",
        "    \"\"\"\n",
        "    ari = scenario_row['ari']\n",
        "    duration = scenario_row['duration_hrs']\n",
        "    ci_level = scenario_row['ci_level']\n",
        "    hyetograph_file = scenario_row['hyetograph_file']\n",
        "\n",
        "    # Format duration string\n",
        "    if duration >= 24:\n",
        "        dur_str = f\"{int(duration/24)}D\"\n",
        "    else:\n",
        "        dur_str = f\"{int(duration)}H\"\n",
        "\n",
        "    # Create plan name (keep it short for HEC-RAS)\n",
        "    ci_abbrev = ci_level[0].upper()  # L, P, or U\n",
        "    plan_name = f\"{ari}YR-{dur_str}-{ci_abbrev}\"\n",
        "\n",
        "    # Clone the base plan\n",
        "    new_plan_number = RasPlan.clone_plan(base_plan, new_shortid=plan_name, ras_object=project)\n",
        "\n",
        "    # Update description with folder suffix\n",
        "    description_text = f\"Atlas 14 Uncertainty Analysis\\n\"\n",
        "    description_text += f\"AEP: {ari} years\\n\"\n",
        "    description_text += f\"Duration: {duration} hours\\n\"\n",
        "    description_text += f\"Confidence Level: {ci_level}\\n\"\n",
        "    description_text += f\"Analysis Set: {folder_suffix}\"\n",
        "\n",
        "    #RasPlan.update_plan_description(new_plan_number, description_text, ras_object=project)\n",
        "\n",
        "    # Get unsteady number from base plan\n",
        "    base_unsteady = None\n",
        "    for _, row in project.plan_df.iterrows():\n",
        "        if row['plan_number'] == base_plan:\n",
        "            base_unsteady = row.get('unsteady_number', None)\n",
        "            break\n",
        "\n",
        "    if base_unsteady is None:\n",
        "        raise ValueError(f\"Could not find unsteady flow file for base plan {base_plan}\")\n",
        "\n",
        "    # Clone the unsteady flow file\n",
        "    new_unsteady_number = RasPlan.clone_unsteady(base_unsteady, ras_object=project)\n",
        "\n",
        "    # Get unsteady file path\n",
        "    unsteady_file_path = RasPlan.get_unsteady_path(new_unsteady_number, ras_object=project)\n",
        "\n",
        "    # Update the flow title\n",
        "    new_title = f\"{ari}YR-{dur_str}-{ci_level.upper()} Storm\"\n",
        "    RasUnsteady.update_flow_title(unsteady_file_path, new_title, ras_object=project)\n",
        "\n",
        "    # Modify the unsteady flow file with the hyetograph data\n",
        "    # Need to ensure hyetograph path is accessible from new project location\n",
        "    hyetograph_file_abs = Path(hyetograph_file).absolute()\n",
        "    success = modify_unsteady_flow_with_hyetograph(\n",
        "        unsteady_file_path,\n",
        "        hyetograph_file_abs,\n",
        "        plan_number=new_plan_number,\n",
        "        project=project\n",
        "    )\n",
        "    if not success:\n",
        "        raise RuntimeError(f\"Failed to apply hyetograph data to plan {new_plan_number}\")\n",
        "\n",
        "    # Assign the unsteady flow file to the plan\n",
        "    RasPlan.set_unsteady(new_plan_number, new_unsteady_number, ras_object=project)\n",
        "\n",
        "    return new_plan_number\n",
        "\n",
        "\n",
        "print(\"Multi-project management functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribute scenarios across projects and create plans\n",
        "print(\"=\"*70)\n",
        "print(\"CREATING PLANS WITH 99-PLAN LIMIT HANDLING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTotal scenarios to process: {len(scenario_df)}\")\n",
        "print(f\"Base project: {pipes_ex_path}\\n\")\n",
        "\n",
        "# Distribute scenarios across multiple projects as needed\n",
        "scenario_df_distributed = distribute_scenarios_across_projects(\n",
        "    scenario_df, \n",
        "    base_project_path=pipes_ex_path,\n",
        "    base_plan=base_plan,\n",
        "    folder_suffix=\"_atlas14\",\n",
        "    ras_version=\"6.6\"\n",
        ")\n",
        "\n",
        "# Now create plans in each project\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CREATING PLANS IN DISTRIBUTED PROJECTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "plan_numbers = []\n",
        "failed_scenarios = []\n",
        "\n",
        "# Group by project\n",
        "project_groups = scenario_df_distributed.groupby('project_folder')\n",
        "\n",
        "for proj_folder, proj_scenarios in project_groups:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Processing Project: {Path(proj_folder).name}\")\n",
        "    print(f\"Scenarios: {len(proj_scenarios)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Get the project object (they should all be the same within a group)\n",
        "    proj_obj = proj_scenarios.iloc[0]['project_object']\n",
        "    folder_suffix = proj_scenarios.iloc[0]['project_suffix']\n",
        "    \n",
        "    for idx, row in proj_scenarios.iterrows():\n",
        "        try:\n",
        "            new_plan = create_plan_with_description(row, base_plan, proj_obj, folder_suffix)\n",
        "            plan_numbers.append(new_plan)\n",
        "            \n",
        "            # Update the row with the plan number\n",
        "            scenario_df_distributed.at[idx, 'plan_number'] = new_plan\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  Error creating plan for scenario {idx}: {e}\")\n",
        "            failed_scenarios.append(idx)\n",
        "            plan_numbers.append(None)\n",
        "            scenario_df_distributed.at[idx, 'plan_number'] = None\n",
        "    \n",
        "    # Show progress\n",
        "    successful = len([p for p in plan_numbers if p is not None])\n",
        "    print(f\"\\nProject {Path(proj_folder).name}: Created {len(proj_scenarios)} plans\")\n",
        "\n",
        "# Remove failed scenarios\n",
        "scenario_df = scenario_df_distributed[scenario_df_distributed['plan_number'].notna()].copy()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PLAN CREATION SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\u2713 Successfully created {len(plan_numbers) - len(failed_scenarios)} plans\")\n",
        "if failed_scenarios:\n",
        "    print(f\"\u2717 Failed to create {len(failed_scenarios)} plans\")\n",
        "\n",
        "print(f\"\\nPlan Summary (first 15 rows):\")\n",
        "display.display(scenario_df[['ari', 'duration_hrs', 'ci_level', 'plan_number', 'project_folder']].head(15))\n",
        "\n",
        "# Save updated scenario list\n",
        "scenario_df.to_csv('scenarios_with_plans.csv', index=False)\n",
        "print(f\"\\nScenario list with plan numbers saved to: scenarios_with_plans.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set computation parameters for all new plans across all projects\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURING COMPUTATION PARAMETERS ACROSS ALL PROJECTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Group by project\n",
        "project_groups = scenario_df.groupby('project_folder')\n",
        "\n",
        "total_configured = 0\n",
        "\n",
        "for proj_folder, proj_scenarios in project_groups:\n",
        "    print(f\"\\nConfiguring {len(proj_scenarios)} plans in: {Path(proj_folder).name}\")\n",
        "    \n",
        "    # Get the project object\n",
        "    proj_obj = proj_scenarios.iloc[0]['project_object']\n",
        "    \n",
        "    for idx, row in proj_scenarios.iterrows():\n",
        "        plan_number = row['plan_number']\n",
        "        \n",
        "        try:\n",
        "            RasPlan.set_num_cores(plan_number, 2, ras_object=proj_obj)\n",
        "#            RasPlan.update_plan_intervals(\n",
        "#                plan_number,\n",
        "#                computation_interval=\"15MIN\",\n",
        "#                output_interval=\"30MIN\",\n",
        "#                mapping_interval=\"1HOUR\",\n",
        "#                ras_object=proj_obj\n",
        "#            )\n",
        "            total_configured += 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  Error configuring plan {plan_number}: {e}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"CONFIGURATION SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\u2713 Configured {total_configured} plans across {len(project_groups)} projects\")\n",
        "print(\"  - Cores per plan: 2\")\n",
        "#print(\"  - Computation interval: 15 MIN\")\n",
        "#print(\"  - Output interval: 30 MIN\")\n",
        "#print(\"  - Mapping interval: 1 HOUR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_scenarios_in_batches(scenario_df, batch_size=20, max_workers=4, cores_per_worker=2, ras_object=None):\n",
        "    \"\"\"\n",
        "    Execute scenarios in batches with progress tracking.\n",
        "    \n",
        "    Parameters:\n",
        "    - scenario_df: DataFrame with scenario information\n",
        "    - batch_size: Number of plans per batch\n",
        "    - max_workers: Number of parallel workers\n",
        "    - cores_per_worker: Cores per worker\n",
        "    - ras_object: RAS project object (uses global 'ras' if None)\n",
        "    \n",
        "    Returns:\n",
        "    - results_dict: Dictionary of execution results\n",
        "    - compute_folder: Path to compute folder\n",
        "    \"\"\"\n",
        "    # Use provided ras_object or try to get from DataFrame\n",
        "    if ras_object is None:\n",
        "        if 'project_object' in scenario_df.columns:\n",
        "            ras_obj = scenario_df.iloc[0]['project_object']\n",
        "        else:\n",
        "            ras_obj = ras  # Fall back to global\n",
        "    else:\n",
        "        ras_obj = ras_object\n",
        "    \n",
        "    # Create compute folder\n",
        "    compute_folder = Path(ras_obj.project_folder) / \"compute_uncertainty\"\n",
        "    compute_folder.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Get all plan numbers\n",
        "    all_plans = scenario_df['plan_number'].tolist()\n",
        "    \n",
        "    # Split into batches\n",
        "    batches = [all_plans[i:i+batch_size] for i in range(0, len(all_plans), batch_size)]\n",
        "    \n",
        "    print(f\"Executing {len(all_plans)} plans in {len(batches)} batches\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Max workers: {max_workers}\")\n",
        "    print(f\"Cores per worker: {cores_per_worker}\")\n",
        "    print(f\"Compute folder: {compute_folder}\\n\")\n",
        "    \n",
        "    all_results = {}\n",
        "    overall_start = time.time()\n",
        "\n",
        "    from ras_commander import RasPlan  # Make sure RasPlan is imported\n",
        "\n",
        "    for batch_idx, batch_plans in enumerate(batches, 1):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Batch {batch_idx}/{len(batches)}: Processing {len(batch_plans)} plans\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Set plan title for each plan in the batch, showing scenario information from scenario_df\n",
        "        for plan_number in batch_plans:\n",
        "            # Find the scenario row for this plan number\n",
        "            scenario_row = scenario_df.loc[scenario_df['plan_number'] == plan_number].squeeze()\n",
        "            # Compose a scenario title string\n",
        "            # This can be customized as needed. Here, include ARI, Duration, Project (if columns exist).\n",
        "            scenario_title_parts = []\n",
        "            for field in ['ARI', 'Duration', 'project_folder']:\n",
        "                if field in scenario_row:\n",
        "                    value = scenario_row[field]\n",
        "                    if pd.notna(value):\n",
        "                        scenario_title_parts.append(f\"{field}:{value}\")\n",
        "            # Join up to 32 chars (RAS limit)\n",
        "            scenario_title = \" | \".join(scenario_title_parts)[:32] or f\"Plan {plan_number}\"\n",
        "            # Set plan title using RasPlan\n",
        "            RasPlan.set_plan_title(plan_number, scenario_title, ras_object=ras_obj)\n",
        "\n",
        "        batch_start = time.time()\n",
        "        \n",
        "        # Execute batch\n",
        "        results = RasCmdr.compute_parallel(\n",
        "            plan_number=batch_plans,\n",
        "            max_workers=max_workers,\n",
        "            num_cores=cores_per_worker,\n",
        "            dest_folder=compute_folder,\n",
        "            clear_geompre=True,\n",
        "            overwrite_dest=True,\n",
        "            ras_object=ras_obj\n",
        "        )\n",
        "        \n",
        "        batch_duration = time.time() - batch_start\n",
        "        \n",
        "        # Update results\n",
        "        all_results.update(results)\n",
        "        \n",
        "        # Report batch results\n",
        "        success_count = sum(1 for v in results.values() if v)\n",
        "        print(f\"\\nBatch {batch_idx} completed in {batch_duration:.1f} seconds\")\n",
        "        print(f\"Success: {success_count}/{len(batch_plans)}\")\n",
        "        \n",
        "        # Progress summary\n",
        "        total_completed = batch_idx * batch_size\n",
        "        if total_completed > len(all_plans):\n",
        "            total_completed = len(all_plans)\n",
        "        print(f\"Overall progress: {total_completed}/{len(all_plans)} plans completed\")\n",
        "    \n",
        "    overall_duration = time.time() - overall_start\n",
        "\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ALL BATCHES COMPLETED\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total time: {overall_duration/60:.1f} minutes\")\n",
        "    print(f\"Average per plan: {overall_duration/len(all_plans):.1f} seconds\")\n",
        "    \n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame([\n",
        "        {\"plan_number\": plan, \"success\": success}\n",
        "        for plan, success in all_results.items()\n",
        "    ])\n",
        "    \n",
        "    success_rate = (results_df['success'].sum() / len(results_df)) * 100\n",
        "    print(f\"\\nSuccess rate: {success_rate:.1f}%\")\n",
        "    print(f\"Successful: {results_df['success'].sum()}\")\n",
        "    print(f\"Failed: {(~results_df['success']).sum()}\")\n",
        "    \n",
        "    return all_results, compute_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute scenarios across all projects\n",
        "print(\"=\"*70)\n",
        "print(\"EXECUTING SCENARIOS ACROSS ALL PROJECTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_results = {}\n",
        "all_compute_folders = {}\n",
        "\n",
        "# Group by project\n",
        "project_groups = scenario_df.groupby('project_folder')\n",
        "\n",
        "for proj_folder, proj_scenarios in project_groups:\n",
        "    proj_name = Path(proj_folder).name\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Processing Project: {proj_name}\")\n",
        "    print(f\"Scenarios: {len(proj_scenarios)}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    # Get the project object\n",
        "    proj_obj = proj_scenarios.iloc[0]['project_object']\n",
        "    \n",
        "    # Execute scenarios for this project in batches\n",
        "    results, compute_folder = execute_scenarios_in_batches(\n",
        "        proj_scenarios,\n",
        "        batch_size=21,  # 3 CI levels \u00d7 7 durations = 21 plans per ARI\n",
        "        max_workers=4,\n",
        "        cores_per_worker=2\n",
        "    )\n",
        "    \n",
        "    # Store results and compute folder for later processing\n",
        "    all_results.update(results)\n",
        "    all_compute_folders[proj_folder] = compute_folder\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ALL PROJECTS EXECUTION COMPLETE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Total scenarios executed: {len(all_results)}\")\n",
        "print(f\"Projects: {len(all_compute_folders)}\")\n",
        "\n",
        "# Save compute folder mapping\n",
        "compute_folders_df = pd.DataFrame([\n",
        "    {'project_folder': pf, 'compute_folder': str(cf)}\n",
        "    for pf, cf in all_compute_folders.items()\n",
        "])\n",
        "compute_folders_df.to_csv('compute_folders.csv', index=False)\n",
        "print(f\"\\nCompute folder mapping saved to: compute_folders.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize compute projects and extract results from all projects\n",
        "print(\"=\"*70)\n",
        "print(\"EXTRACTING RESULTS FROM ALL PROJECTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_plans_with_results = []\n",
        "\n",
        "# Process each project's compute folder\n",
        "for proj_folder, compute_folder in all_compute_folders.items():\n",
        "    proj_name = Path(proj_folder).name\n",
        "    print(f\"\\nProcessing results from: {proj_name}\")\n",
        "    print(f\"Compute folder: {compute_folder}\")\n",
        "\n",
        "    # Initialize compute project to access results\n",
        "    compute_project = RasPrj()\n",
        "    compute_project = init_ras_project(compute_folder, \"6.6\", ras_object=compute_project)\n",
        "\n",
        "    # Check which plans have results\n",
        "    plans_with_results = compute_project.plan_df[compute_project.plan_df['HDF_Results_Path'].notna()].copy()\n",
        "    plans_with_results['source_project'] = proj_folder\n",
        "    plans_with_results['compute_folder'] = str(compute_folder)\n",
        "\n",
        "    all_plans_with_results.append(plans_with_results)\n",
        "\n",
        "    print(f\"  Found {len(plans_with_results)} plans with HDF results\")\n",
        "\n",
        "# Combine all results\n",
        "if len(all_plans_with_results) > 0:\n",
        "    combined_results_df = pd.concat(all_plans_with_results, ignore_index=True)\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"RESULTS EXTRACTION SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total plans with results: {len(combined_results_df)}\")\n",
        "\n",
        "    # Debug: Show what columns we have before merge\n",
        "    print(f\"\\nColumns in combined_results_df: {list(combined_results_df.columns)}\")\n",
        "    print(f\"Columns in scenario_df: {list(scenario_df.columns)}\")\n",
        "\n",
        "    # Merge with scenario information\n",
        "    results_df = scenario_df.merge(\n",
        "        combined_results_df[['plan_number', 'Short Identifier', 'HDF_Results_Path', 'source_project', 'compute_folder']],\n",
        "        on='plan_number',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    print(f\"\\nAfter merge:\")\n",
        "    print(f\"  Total rows in results_df: {len(results_df)}\")\n",
        "    print(f\"  Rows with HDF paths: {len(results_df[results_df['HDF_Results_Path'].notna()])}\")\n",
        "    print(f\"  Columns in results_df: {list(results_df.columns)}\")\n",
        "\n",
        "    # Check if scenario info is preserved\n",
        "    if 'ari' in results_df.columns:\n",
        "        print(f\"  \u2713 'ari' column preserved\")\n",
        "    else:\n",
        "        print(f\"  \u2717 'ari' column MISSING!\")\n",
        "\n",
        "    if 'duration_hrs' in results_df.columns:\n",
        "        print(f\"  \u2713 'duration_hrs' column preserved\")\n",
        "    else:\n",
        "        print(f\"  \u2717 'duration_hrs' column MISSING!\")\n",
        "\n",
        "    print(f\"\\nResults summary (first 15 rows):\")\n",
        "    display.display(results_df[['ari', 'duration_hrs', 'ci_level', 'plan_number', 'HDF_Results_Path']].head(15))\n",
        "\n",
        "    # Save results summary\n",
        "    results_df.to_csv('results_uncertainty_scenarios.csv', index=False)\n",
        "    print(f\"\\nResults summary saved to: results_uncertainty_scenarios.csv\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nERROR: No plans with results found!\")\n",
        "    results_df = scenario_df.copy()\n",
        "    results_df['HDF_Results_Path'] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Metrics from All Scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diagnostic-check",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DIAGNOSTIC: Check DataFrame Columns\n",
        "# ============================================================================\n",
        "# Run this cell if you encounter KeyError: 'ari' in later cells\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DATAFRAME DIAGNOSTIC CHECK\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check scenario_df\n",
        "if 'scenario_df' in dir():\n",
        "    print(f\"\\n1. scenario_df:\")\n",
        "    print(f\"   Shape: {scenario_df.shape}\")\n",
        "    print(f\"   Columns: {list(scenario_df.columns)}\")\n",
        "\n",
        "    required = ['ari', 'duration_hrs', 'ci_level', 'plan_number']\n",
        "    missing = [c for c in required if c not in scenario_df.columns]\n",
        "    if missing:\n",
        "        print(f\"   \u26a0\ufe0f  Missing: {missing}\")\n",
        "    else:\n",
        "        print(f\"   \u2713 Has all required scenario columns\")\n",
        "else:\n",
        "    print(f\"\\n1. scenario_df: NOT FOUND\")\n",
        "\n",
        "# Check results_df\n",
        "if 'results_df' in dir():\n",
        "    print(f\"\\n2. results_df:\")\n",
        "    print(f\"   Shape: {results_df.shape}\")\n",
        "    print(f\"   Columns: {list(results_df.columns)}\")\n",
        "\n",
        "    required = ['ari', 'duration_hrs', 'ci_level', 'plan_number', 'HDF_Results_Path']\n",
        "    missing = [c for c in required if c not in results_df.columns]\n",
        "    if missing:\n",
        "        print(f\"   \u26a0\ufe0f  Missing: {missing}\")\n",
        "    else:\n",
        "        print(f\"   \u2713 Has all required columns\")\n",
        "\n",
        "    if 'HDF_Results_Path' in results_df.columns:\n",
        "        with_hdf = results_df['HDF_Results_Path'].notna().sum()\n",
        "        print(f\"   Rows with HDF paths: {with_hdf}/{len(results_df)}\")\n",
        "else:\n",
        "    print(f\"\\n2. results_df: NOT FOUND\")\n",
        "\n",
        "# Check metrics_df\n",
        "if 'metrics_df' in dir():\n",
        "    print(f\"\\n3. metrics_df:\")\n",
        "    print(f\"   Shape: {metrics_df.shape}\")\n",
        "    print(f\"   Columns: {list(metrics_df.columns)}\")\n",
        "\n",
        "    required = ['ari', 'duration_hrs', 'ci_level']\n",
        "    missing = [c for c in required if c not in metrics_df.columns]\n",
        "    if missing:\n",
        "        print(f\"   \u26a0\ufe0f  Missing: {missing}\")\n",
        "        print(f\"   \\n   ACTION REQUIRED:\")\n",
        "        print(f\"   The metrics extraction didn't preserve scenario columns.\")\n",
        "        print(f\"   This means results_df was missing them.\")\n",
        "        print(f\"   Re-run the results extraction cell (Cell 28)\")\n",
        "    else:\n",
        "        print(f\"   \u2713 Has all required columns\")\n",
        "else:\n",
        "    print(f\"\\n3. metrics_df: NOT CREATED YET\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"END DIAGNOSTIC\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_scenario_metrics(results_df):\n",
        "    \"\"\"\n",
        "    Extract key metrics from all scenarios.\n",
        "    \"\"\"\n",
        "    metrics_list = []\n",
        "\n",
        "    print(\"Extracting metrics from all scenarios...\\n\")\n",
        "\n",
        "    # SAFETY CHECK: Verify required columns exist\n",
        "    required_cols = ['ari', 'duration_hrs', 'ci_level', 'total_depth_in', 'HDF_Results_Path', 'plan_number']\n",
        "    missing_cols = [col for col in required_cols if col not in results_df.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        print(f\"ERROR: results_df is missing required columns: {missing_cols}\")\n",
        "        print(f\"Available columns: {list(results_df.columns)}\")\n",
        "        print(f\"\\nCannot extract metrics without scenario information!\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        hdf_path = row.get('HDF_Results_Path')\n",
        "\n",
        "        if pd.isna(hdf_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Get runtime data\n",
        "            runtime_df = HdfResultsPlan.get_runtime_data(hdf_path)\n",
        "\n",
        "            # Get pipe network results\n",
        "            pipe_flow_ds = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Pipes/Pipe Flow DS\")\n",
        "            node_ws = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Nodes/Water Surface\")\n",
        "\n",
        "            # Calculate statistics\n",
        "            pipe_flow_array = pipe_flow_ds.values\n",
        "            node_ws_array = node_ws.values\n",
        "\n",
        "            max_flows = np.nanmax(pipe_flow_array, axis=0)\n",
        "            max_ws = np.nanmax(node_ws_array, axis=0)\n",
        "\n",
        "            metrics = {\n",
        "                'plan_number': row['plan_number'],\n",
        "                'ari': row['ari'],\n",
        "                'duration_hrs': row['duration_hrs'],\n",
        "                'ci_level': row['ci_level'],\n",
        "                'total_precip_in': row['total_depth_in'],\n",
        "                'compute_time_hr': runtime_df['Complete Process (hr)'].iloc[0] if not runtime_df.empty else np.nan,\n",
        "                'avg_max_pipe_flow_cfs': np.nanmean(max_flows),\n",
        "                'max_pipe_flow_cfs': np.nanmax(max_flows),\n",
        "                'avg_max_node_ws_ft': np.nanmean(max_ws),\n",
        "                'max_node_ws_ft': np.nanmax(max_ws),\n",
        "                'hdf_path': hdf_path\n",
        "            }\n",
        "\n",
        "            metrics_list.append(metrics)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting metrics for plan {row.get('plan_number', 'unknown')}: {e}\")\n",
        "            continue\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "    if len(metrics_df) > 0:\n",
        "        print(f\"\\n\u2713 Extracted metrics from {len(metrics_df)} scenarios\")\n",
        "        print(f\"Columns in metrics_df: {list(metrics_df.columns)}\")\n",
        "    else:\n",
        "        print(\"\\n\u2717 No metrics extracted!\")\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "\n",
        "# SAFETY CHECK: Verify results_df has required columns before extraction\n",
        "print(\"=\"*70)\n",
        "print(\"PRE-EXTRACTION SAFETY CHECKS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "required_cols = ['ari', 'duration_hrs', 'ci_level', 'total_depth_in', 'plan_number', 'HDF_Results_Path']\n",
        "print(f\"\\nChecking results_df for required columns...\")\n",
        "print(f\"Required: {required_cols}\")\n",
        "\n",
        "if 'results_df' in dir():\n",
        "    print(f\"\\nresults_df columns: {list(results_df.columns)}\")\n",
        "    missing = [col for col in required_cols if col not in results_df.columns]\n",
        "\n",
        "    if missing:\n",
        "        print(f\"\\n\u26a0\ufe0f  WARNING: Missing columns: {missing}\")\n",
        "        print(\"\\nThis will cause KeyError in uncertainty analysis!\")\n",
        "        print(\"\\nDEBUGGING INFO:\")\n",
        "        print(f\"  - results_df shape: {results_df.shape}\")\n",
        "        print(f\"  - rows with HDF paths: {results_df['HDF_Results_Path'].notna().sum() if 'HDF_Results_Path' in results_df.columns else 'N/A'}\")\n",
        "        print(\"\\nLikely cause: Merge in results extraction didn't preserve scenario_df columns\")\n",
        "        print(\"Solution: Re-run results extraction cell (Cell 28)\")\n",
        "    else:\n",
        "        print(f\"\\n\u2713 All required columns present!\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f  results_df not found in namespace\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Extract metrics\n",
        "metrics_df = extract_scenario_metrics(results_df)\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nMetrics Summary:\")\n",
        "if len(metrics_df) > 0:\n",
        "    display.display(metrics_df.head(15))\n",
        "\n",
        "    # Save metrics\n",
        "    metrics_df.to_csv('metrics_uncertainty_analysis.csv', index=False)\n",
        "    print(\"\\nMetrics saved to: metrics_uncertainty_analysis.csv\")\n",
        "else:\n",
        "    print(\"\\nNo metrics to display. Check errors above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uncertainty Quantification\n",
        "\n",
        "Calculate uncertainty metrics for each ARI-Duration combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_uncertainty_metrics(metrics_df):\n",
        "    \"\"\"\n",
        "    Calculate uncertainty metrics for each ARI-Duration combination.\n",
        "    \"\"\"\n",
        "    # SAFETY CHECK: Verify required columns exist\n",
        "    required_cols = ['ari', 'duration_hrs', 'ci_level']\n",
        "    missing_cols = [col for col in required_cols if col not in metrics_df.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        print(f\"ERROR: metrics_df is missing required columns: {missing_cols}\")\n",
        "        print(f\"Available columns: {list(metrics_df.columns)}\")\n",
        "        print(f\"Cannot calculate uncertainty without these columns!\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame\n",
        "\n",
        "    if len(metrics_df) == 0:\n",
        "        print(\"ERROR: metrics_df is empty!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    uncertainty_list = []\n",
        "\n",
        "    for ari in metrics_df['ari'].unique():\n",
        "        for duration in metrics_df['duration_hrs'].unique():\n",
        "            # Filter data\n",
        "            subset = metrics_df[\n",
        "                (metrics_df['ari'] == ari) &\n",
        "                (metrics_df['duration_hrs'] == duration)\n",
        "            ]\n",
        "\n",
        "            if len(subset) < 3:\n",
        "                continue\n",
        "\n",
        "            # Get values by CI level\n",
        "            lower = subset[subset['ci_level'] == 'lower']\n",
        "            point = subset[subset['ci_level'] == 'point']\n",
        "            upper = subset[subset['ci_level'] == 'upper']\n",
        "\n",
        "            if len(lower) == 0 or len(point) == 0 or len(upper) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate uncertainty for max pipe flow\n",
        "            flow_point = point['max_pipe_flow_cfs'].values[0]\n",
        "            flow_lower = lower['max_pipe_flow_cfs'].values[0]\n",
        "            flow_upper = upper['max_pipe_flow_cfs'].values[0]\n",
        "            flow_range = flow_upper - flow_lower\n",
        "            flow_rel_uncertainty = (flow_range / flow_point) * 100 if flow_point > 0 else np.nan\n",
        "\n",
        "            # Calculate uncertainty for max node WS\n",
        "            ws_point = point['max_node_ws_ft'].values[0]\n",
        "            ws_lower = lower['max_node_ws_ft'].values[0]\n",
        "            ws_upper = upper['max_node_ws_ft'].values[0]\n",
        "            ws_range = ws_upper - ws_lower\n",
        "            ws_rel_uncertainty = (ws_range / ws_point) * 100 if ws_point > 0 else np.nan\n",
        "\n",
        "            uncertainty_list.append({\n",
        "                'ari': ari,\n",
        "                'duration_hrs': duration,\n",
        "                'max_flow_point_cfs': flow_point,\n",
        "                'max_flow_lower_cfs': flow_lower,\n",
        "                'max_flow_upper_cfs': flow_upper,\n",
        "                'max_flow_range_cfs': flow_range,\n",
        "                'max_flow_rel_uncertainty_pct': flow_rel_uncertainty,\n",
        "                'max_ws_point_ft': ws_point,\n",
        "                'max_ws_lower_ft': ws_lower,\n",
        "                'max_ws_upper_ft': ws_upper,\n",
        "                'max_ws_range_ft': ws_range,\n",
        "                'max_ws_rel_uncertainty_pct': ws_rel_uncertainty\n",
        "            })\n",
        "\n",
        "    uncertainty_df = pd.DataFrame(uncertainty_list)\n",
        "    return uncertainty_df\n",
        "\n",
        "# Calculate uncertainties\n",
        "uncertainty_df = calculate_uncertainty_metrics(metrics_df)\n",
        "\n",
        "if len(uncertainty_df) > 0:\n",
        "    print(\"Uncertainty Analysis:\")\n",
        "    display.display(uncertainty_df)\n",
        "\n",
        "    # Save uncertainty metrics\n",
        "    uncertainty_df.to_csv('uncertainty_metrics.csv', index=False)\n",
        "    print(\"\\nUncertainty metrics saved to: uncertainty_metrics.csv\")\n",
        "else:\n",
        "    print(\"\\nCannot perform uncertainty analysis - metrics_df has missing or invalid data\")\n",
        "    print(\"Please check the results extraction and metrics extraction steps above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Suite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Peak Flow vs Duration with Confidence Envelopes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Peak Water Surface vs Duration with Confidence Envelopes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot peak water surface vs duration for each ARI\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, ari in enumerate(sorted(metrics_df['ari'].unique())):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Get data for this ARI\n",
        "    ari_data = uncertainty_df[uncertainty_df['ari'] == ari].sort_values('duration_hrs')\n",
        "    \n",
        "    if len(ari_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    # Plot point estimate\n",
        "    ax.plot(ari_data['duration_hrs'], ari_data['max_ws_point_ft'], \n",
        "            'ko-', linewidth=2, markersize=6, label='Point Estimate', zorder=3)\n",
        "    \n",
        "    # Plot confidence envelope\n",
        "    ax.fill_between(ari_data['duration_hrs'], \n",
        "                     ari_data['max_ws_lower_ft'], \n",
        "                     ari_data['max_ws_upper_ft'],\n",
        "                     alpha=0.3, color='green', label='90% CI', zorder=1)\n",
        "    \n",
        "    ax.set_xlabel('Duration (hours)', fontsize=11)\n",
        "    ax.set_ylabel('Peak Water Surface (ft)', fontsize=11)\n",
        "    ax.set_title(f'{ari}-Year Event', fontsize=13, fontweight='bold')\n",
        "    ax.legend(fontsize=9)\n",
        "    ax.grid(alpha=0.3, zorder=0)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xticks(durations)\n",
        "    ax.set_xticklabels(durations)\n",
        "\n",
        "plt.suptitle('Peak Water Surface vs Storm Duration with Confidence Intervals', \n",
        "             fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.savefig('peak_ws_uncertainty.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Figure saved: peak_ws_uncertainty.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Relative Uncertainty Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create heatmaps for relative uncertainty\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Pivot data for heatmaps\n",
        "flow_uncertainty_pivot = uncertainty_df.pivot(\n",
        "    index='ari',\n",
        "    columns='duration_hrs',\n",
        "    values='max_flow_rel_uncertainty_pct'\n",
        ")\n",
        "\n",
        "ws_uncertainty_pivot = uncertainty_df.pivot(\n",
        "    index='ari',\n",
        "    columns='duration_hrs',\n",
        "    values='max_ws_rel_uncertainty_pct'\n",
        ")\n",
        "\n",
        "# Plot flow uncertainty heatmap\n",
        "sns.heatmap(flow_uncertainty_pivot, annot=True, fmt='.1f', cmap='YlOrRd', \n",
        "            cbar_kws={'label': 'Relative Uncertainty (%)'}, ax=ax1)\n",
        "ax1.set_title('Relative Uncertainty in Peak Flow', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Duration (hours)', fontsize=12)\n",
        "ax1.set_ylabel('Return Period (years)', fontsize=12)\n",
        "\n",
        "# Plot WS uncertainty heatmap\n",
        "sns.heatmap(ws_uncertainty_pivot, annot=True, fmt='.1f', cmap='YlGnBu',\n",
        "            cbar_kws={'label': 'Relative Uncertainty (%)'}, ax=ax2)\n",
        "ax2.set_title('Relative Uncertainty in Peak Water Surface', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Duration (hours)', fontsize=12)\n",
        "ax2.set_ylabel('Return Period (years)', fontsize=12)\n",
        "\n",
        "plt.suptitle('Precipitation Uncertainty Propagation Through Flood Model', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('uncertainty_heatmaps.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Figure saved: uncertainty_heatmaps.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Time Series with Confidence Envelope at Critical Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_timeseries_with_ci(ari, duration, location_id=61):\n",
        "    \"\"\"\n",
        "    Plot time series showing confidence envelope at a specific location.\n",
        "    \"\"\"\n",
        "    # Get scenarios for this ARI and duration\n",
        "    scenarios = metrics_df[\n",
        "        (metrics_df['ari'] == ari) & \n",
        "        (metrics_df['duration_hrs'] == duration)\n",
        "    ]\n",
        "    \n",
        "    if len(scenarios) == 0:\n",
        "        print(f\"No data found for {ari}-year, {duration}-hour storm\")\n",
        "        return\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    \n",
        "    # Extract time series for each CI level\n",
        "    for ci_level in ['lower', 'point', 'upper']:\n",
        "        scenario = scenarios[scenarios['ci_level'] == ci_level]\n",
        "        \n",
        "        if len(scenario) == 0:\n",
        "            continue\n",
        "        \n",
        "        hdf_path = scenario['hdf_path'].values[0]\n",
        "        \n",
        "        try:\n",
        "            # Get node water surface time series\n",
        "            node_ws = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Nodes/Water Surface\")\n",
        "            \n",
        "            # Extract data for specified location\n",
        "            loc_ws = node_ws.sel(location=location_id)\n",
        "            \n",
        "            # Plot\n",
        "            if ci_level == 'point':\n",
        "                ax.plot(loc_ws.time.values, loc_ws.values, \n",
        "                       'k-', linewidth=2, label='Point Estimate', zorder=3)\n",
        "            elif ci_level == 'lower':\n",
        "                lower_data = loc_ws.values\n",
        "                lower_time = loc_ws.time.values\n",
        "            elif ci_level == 'upper':\n",
        "                upper_data = loc_ws.values\n",
        "                upper_time = loc_ws.time.values\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting {ci_level} data: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # Plot confidence envelope\n",
        "    if 'lower_data' in locals() and 'upper_data' in locals():\n",
        "        ax.fill_between(lower_time, lower_data, upper_data, \n",
        "                       alpha=0.3, color='blue', label='90% CI', zorder=1)\n",
        "    \n",
        "    ax.set_xlabel('Time', fontsize=12)\n",
        "    ax.set_ylabel('Water Surface Elevation (ft)', fontsize=12)\n",
        "    ax.set_title(f'Water Surface at Node {location_id}\\n' +\n",
        "                f'{ari}-Year, {duration}-Hour Storm with Confidence Interval', \n",
        "                fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(alpha=0.3, zorder=0)\n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot time series for selected scenarios\n",
        "print(\"Time Series with Confidence Envelopes\\n\")\n",
        "plot_timeseries_with_ci(10, 24, location_id=61)\n",
        "plot_timeseries_with_ci(100, 24, location_id=61)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_all_aeps_for_duration(duration, location_id=61):\n",
        "    \"\"\"\n",
        "    Plot all AEP/ARI levels for a specific duration with confidence intervals.\n",
        "    Creates one plot showing all storm frequencies for the given duration.\n",
        "    \"\"\"\n",
        "    # Get all unique ARIs for this duration\n",
        "    duration_data = metrics_df[metrics_df['duration_hrs'] == duration]\n",
        "    aris = sorted(duration_data['ari'].unique())\n",
        "    \n",
        "    if len(aris) == 0:\n",
        "        print(f\"No data found for {duration}-hour duration\")\n",
        "        return\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "    \n",
        "    # Color palette for different ARIs\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(aris)))\n",
        "    \n",
        "    for idx, ari in enumerate(aris):\n",
        "        scenarios = duration_data[duration_data['ari'] == ari]\n",
        "        \n",
        "        lower_data = None\n",
        "        upper_data = None\n",
        "        point_data = None\n",
        "        time_data = None\n",
        "        \n",
        "        # Extract time series for each CI level\n",
        "        for ci_level in ['lower', 'point', 'upper']:\n",
        "            scenario = scenarios[scenarios['ci_level'] == ci_level]\n",
        "            \n",
        "            if len(scenario) == 0:\n",
        "                continue\n",
        "            \n",
        "            hdf_path = scenario['hdf_path'].values[0]\n",
        "            \n",
        "            try:\n",
        "                # Get node water surface time series\n",
        "                node_ws = HdfPipe.get_pipe_network_timeseries(hdf_path, variable=\"Nodes/Water Surface\")\n",
        "                \n",
        "                # Extract data for specified location\n",
        "                loc_ws = node_ws.sel(location=location_id)\n",
        "                \n",
        "                if ci_level == 'point':\n",
        "                    point_data = loc_ws.values\n",
        "                    time_data = loc_ws.time.values\n",
        "                elif ci_level == 'lower':\n",
        "                    lower_data = loc_ws.values\n",
        "                elif ci_level == 'upper':\n",
        "                    upper_data = loc_ws.values\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting {ari}-year {ci_level} data: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Plot confidence envelope and point estimate\n",
        "        if point_data is not None and time_data is not None:\n",
        "            # Plot confidence envelope first (lower z-order)\n",
        "            if lower_data is not None and upper_data is not None:\n",
        "                ax.fill_between(time_data, lower_data, upper_data, \n",
        "                               alpha=0.2, color=colors[idx], zorder=1)\n",
        "            \n",
        "            # Plot point estimate on top\n",
        "            ax.plot(time_data, point_data, \n",
        "                   color=colors[idx], linewidth=2.5, \n",
        "                   label=f'{ari}-Year (90% CI)', zorder=2)\n",
        "    \n",
        "    ax.set_xlabel('Time', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Water Surface Elevation (ft)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title(f'Water Surface at Node {location_id}\\n' +\n",
        "                f'{duration}-Hour Duration - All Return Periods with 90% Confidence Intervals', \n",
        "                fontsize=15, fontweight='bold')\n",
        "    ax.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "    ax.grid(alpha=0.3, linestyle='--', zorder=0)\n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_all_durations_all_aeps(location_id=61):\n",
        "    \"\"\"\n",
        "    Create a separate plot for each duration showing all AEP levels.\n",
        "    \"\"\"\n",
        "    # Get all unique durations\n",
        "    durations = sorted(metrics_df['duration_hrs'].unique())\n",
        "    \n",
        "    print(f\"Creating plots for {len(durations)} durations at Node {location_id}\\n\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for duration in durations:\n",
        "        print(f\"\\n{duration}-Hour Duration Storm\")\n",
        "        print(\"-\" * 70)\n",
        "        plot_all_aeps_for_duration(duration, location_id)\n",
        "\n",
        "\n",
        "# Generate all plots\n",
        "plot_all_durations_all_aeps(location_id=61)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate summary statistics\n",
        "print(\"=\"*70)\n",
        "print(\"UNCERTAINTY ANALYSIS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. OVERALL UNCERTAINTY STATISTICS\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Average relative uncertainty in peak flow: {uncertainty_df['max_flow_rel_uncertainty_pct'].mean():.1f}%\")\n",
        "print(f\"Average relative uncertainty in peak WSE: {uncertainty_df['max_ws_rel_uncertainty_pct'].mean():.1f}%\")\n",
        "print(f\"Range of uncertainty in peak flow: {uncertainty_df['max_flow_rel_uncertainty_pct'].min():.1f}% - {uncertainty_df['max_flow_rel_uncertainty_pct'].max():.1f}%\")\n",
        "print(f\"Range of uncertainty in peak WSE: {uncertainty_df['max_ws_rel_uncertainty_pct'].min():.1f}% - {uncertainty_df['max_ws_rel_uncertainty_pct'].max():.1f}%\")\n",
        "\n",
        "print(\"\\n2. SCENARIOS WITH HIGHEST UNCERTAINTY\")\n",
        "print(\"-\" * 70)\n",
        "top_flow_uncertainty = uncertainty_df.nlargest(5, 'max_flow_rel_uncertainty_pct')\n",
        "print(\"\\nTop 5 - Peak Flow Uncertainty:\")\n",
        "for idx, row in top_flow_uncertainty.iterrows():\n",
        "    print(f\"  {row['ari']}-year, {row['duration_hrs']}-hour: {row['max_flow_rel_uncertainty_pct']:.1f}%\")\n",
        "\n",
        "top_ws_uncertainty = uncertainty_df.nlargest(5, 'max_ws_rel_uncertainty_pct')\n",
        "print(\"\\nTop 5 - Water Surface Uncertainty:\")\n",
        "for idx, row in top_ws_uncertainty.iterrows():\n",
        "    print(f\"  {row['ari']}-year, {row['duration_hrs']}-hour: {row['max_ws_rel_uncertainty_pct']:.1f}%\")\n",
        "\n",
        "print(\"\\n3. UNCERTAINTY BY RETURN PERIOD\")\n",
        "print(\"-\" * 70)\n",
        "by_ari = uncertainty_df.groupby('ari').agg({\n",
        "    'max_flow_rel_uncertainty_pct': 'mean',\n",
        "    'max_ws_rel_uncertainty_pct': 'mean'\n",
        "}).round(1)\n",
        "print(by_ari)\n",
        "\n",
        "print(\"\\n4. UNCERTAINTY BY DURATION\")\n",
        "print(\"-\" * 70)\n",
        "by_duration = uncertainty_df.groupby('duration_hrs').agg({\n",
        "    'max_flow_rel_uncertainty_pct': 'mean',\n",
        "    'max_ws_rel_uncertainty_pct': 'mean'\n",
        "}).round(1)\n",
        "print(by_duration)\n",
        "\n",
        "print(\"\\n5. DESIGN IMPLICATIONS\")\n",
        "print(\"-\" * 70)\n",
        "print(\"Based on the uncertainty analysis:\")\n",
        "print(f\"  \u2022 Precipitation uncertainty of \u00b140% results in:\")\n",
        "print(f\"    - Peak flow uncertainty: {uncertainty_df['max_flow_rel_uncertainty_pct'].mean():.1f}%\")\n",
        "print(f\"    - Peak WSE uncertainty: {uncertainty_df['max_ws_rel_uncertainty_pct'].mean():.1f}%\")\n",
        "print(f\"  \u2022 Higher uncertainties observed for:\")\n",
        "most_uncertain_duration = by_duration['max_flow_rel_uncertainty_pct'].idxmax()\n",
        "print(f\"    - Duration: {most_uncertain_duration} hours\")\n",
        "most_uncertain_ari = by_ari['max_flow_rel_uncertainty_pct'].idxmax()\n",
        "print(f\"    - Return period: {most_uncertain_ari} years\")\n",
        "print(f\"  \u2022 Designers should consider upper bound scenarios for critical infrastructure\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Analysis complete. All results saved to CSV files.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "\n",
        "This comprehensive uncertainty analysis demonstrates:\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **Uncertainty Propagation**: Precipitation uncertainty of approximately \u00b140% (90% confidence interval) propagates through the hydraulic model with varying impacts depending on storm characteristics.\n",
        "\n",
        "2. **Duration Effects**: Different storm durations exhibit varying sensitivity to precipitation uncertainty, with some durations showing amplified uncertainty in hydraulic responses.\n",
        "\n",
        "3. **Return Period Patterns**: The relationship between return period and uncertainty provides insights into which design events have the most variability.\n",
        "\n",
        "4. **Spatial Considerations**: Peak water surface elevations and pipe flows show different uncertainty patterns, important for infrastructure design decisions.\n",
        "\n",
        "### Design Recommendations\n",
        "\n",
        "- **Use upper confidence bounds** for critical infrastructure design\n",
        "- **Consider duration sensitivity** when selecting design storms\n",
        "- **Account for uncertainty** in flood risk communication\n",
        "- **Evaluate multiple scenarios** rather than single point estimates\n",
        "\n",
        "### Methodology Advantages\n",
        "\n",
        "- **Comprehensive Coverage**: All practical durations analyzed\n",
        "- **Systematic Approach**: Consistent methodology across all scenarios\n",
        "- **Quantified Uncertainty**: Clear metrics for decision-making\n",
        "- **Reproducible**: Fully documented workflow\n",
        "\n",
        "### Future Enhancements\n",
        "\n",
        "This framework can be extended to include:\n",
        "- Climate change adjustments to precipitation\n",
        "- Infiltration parameter uncertainty\n",
        "- Manning's n coefficient uncertainty\n",
        "- Combined uncertainty analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\105_mannings_sensitivity_bulk_analysis.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mannings Bulk Sensitivity Analysis\n",
        "\n",
        "This notebook provides tools for efficiently analyzing the sensitivity of HEC-RAS models to changing Mannings roughness coefficient values. The main function `autoras_mannings_bulk_sensitivity` automates the creation, execution, and comparison of model runs with different Mannings n values based on recommended ranges from literature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries and Setup ras-commander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from seaborn) (2.2.6)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from seaborn) (2.3.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from seaborn) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ras_commander imported successfully\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# This cell will try to import the pip package; if it fails, it will \n",
        "# add the parent directory to the Python path and try to import again\n",
        "# This assumes you are working in a subfolder of the ras-commander repository\n",
        "\n",
        "# Flexible imports to allow for development without installation\n",
        "try:\n",
        "    # Try to import from the installed package\n",
        "    from ras_commander import *\n",
        "except ImportError:\n",
        "    # If the import fails, add the parent directory to the Python path\n",
        "    current_file = Path(os.getcwd()).resolve()\n",
        "    rascmdr_directory = current_file.parent\n",
        "    sys.path.append(str(rascmdr_directory))\n",
        "    print(\"Loading ras-commander from local dev copy\")\n",
        "    # Now try to import again\n",
        "    from ras_commander import *\n",
        "\n",
        "print(\"ras_commander imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note on DataFrame Column Naming\n",
        "\n",
        "**Important:** The ras-commander library uses simplified column names in DataFrames for Manning's n values:\n",
        "\n",
        "- DataFrame column:  (no apostrophe)\n",
        "- HEC-RAS HDF files:  (with apostrophe - official technical term)\n",
        "\n",
        "This design decision simplifies DataFrame operations by avoiding special characters in column names, \n",
        "while HEC-RAS's internal HDF structure retains the technically correct spelling with the apostrophe.\n",
        "\n",
        "When working with Manning's n values from , always reference the column as  (without apostrophe)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Mannings n Value Ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mannings n value ranges for 16 land cover types:\n",
            "                 Land Cover Name  min_n  max_n   mid_n\n",
            "0     Barren Land Rock/Sand/Clay  0.023   0.10  0.0615\n",
            "1               Cultivated Crops  0.020   0.10  0.0600\n",
            "2               Deciduous Forest  0.100   0.20  0.1500\n",
            "3      Developed, High Intensity  0.120   0.20  0.1600\n",
            "4       Developed, Low Intensity  0.060   0.12  0.0900\n",
            "5    Developed, Medium Intensity  0.080   0.16  0.1200\n",
            "6          Developed, Open Space  0.030   0.09  0.0600\n",
            "7   Emergent Herbaceous Wetlands  0.050   0.12  0.0850\n",
            "8               Evergreen Forest  0.080   0.16  0.1200\n",
            "9           Grassland/Herbaceous  0.025   0.07  0.0475\n",
            "10                  Mixed Forest  0.080   0.20  0.1400\n",
            "11                        NoData  0.050   0.07  0.0600\n",
            "12                    Open Water  0.025   0.05  0.0375\n",
            "13                   Pasture/Hay  0.025   0.09  0.0575\n",
            "14                   Shrub/Scrub  0.070   0.16  0.1150\n",
            "15                Woody Wetlands  0.045   0.15  0.0975\n"
          ]
        }
      ],
      "source": [
        "def create_manning_minmax_df():\n",
        "    \"\"\"\n",
        "    Create a dataframe containing minimum and maximum Mannings n values\n",
        "    based on recommended ranges from literature.\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with columns for Land Cover Name, min_n, max_n\n",
        "    \"\"\"\n",
        "    # Define the data as a list of dictionaries\n",
        "    manning_data = [\n",
        "        {\"Land Cover Name\": \"NoData\", \"min_n\": 0.050, \"max_n\": 0.070},\n",
        "        {\"Land Cover Name\": \"Barren Land Rock/Sand/Clay\", \"min_n\": 0.023, \"max_n\": 0.100},\n",
        "        {\"Land Cover Name\": \"Cultivated Crops\", \"min_n\": 0.020, \"max_n\": 0.100},\n",
        "        {\"Land Cover Name\": \"Deciduous Forest\", \"min_n\": 0.100, \"max_n\": 0.200},\n",
        "        {\"Land Cover Name\": \"Developed, High Intensity\", \"min_n\": 0.120, \"max_n\": 0.200},\n",
        "        {\"Land Cover Name\": \"Developed, Low Intensity\", \"min_n\": 0.060, \"max_n\": 0.120},\n",
        "        {\"Land Cover Name\": \"Developed, Medium Intensity\", \"min_n\": 0.080, \"max_n\": 0.160},\n",
        "        {\"Land Cover Name\": \"Developed, Open Space\", \"min_n\": 0.030, \"max_n\": 0.090},\n",
        "        {\"Land Cover Name\": \"Emergent Herbaceous Wetlands\", \"min_n\": 0.050, \"max_n\": 0.120},\n",
        "        {\"Land Cover Name\": \"Evergreen Forest\", \"min_n\": 0.080, \"max_n\": 0.160},\n",
        "        {\"Land Cover Name\": \"Grassland/Herbaceous\", \"min_n\": 0.025, \"max_n\": 0.070},\n",
        "        {\"Land Cover Name\": \"Mixed Forest\", \"min_n\": 0.080, \"max_n\": 0.200},\n",
        "        {\"Land Cover Name\": \"Open Water\", \"min_n\": 0.025, \"max_n\": 0.050},\n",
        "        {\"Land Cover Name\": \"Pasture/Hay\", \"min_n\": 0.025, \"max_n\": 0.090},\n",
        "        {\"Land Cover Name\": \"Shrub/Scrub\", \"min_n\": 0.070, \"max_n\": 0.160},\n",
        "        {\"Land Cover Name\": \"Woody Wetlands\", \"min_n\": 0.045, \"max_n\": 0.150}\n",
        "    ]\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(manning_data)\n",
        "    \n",
        "    # Calculate the midpoint value\n",
        "    df['mid_n'] = (df['min_n'] + df['max_n']) / 2\n",
        "    \n",
        "    # Sort by land cover name\n",
        "    df = df.sort_values('Land Cover Name').reset_index(drop=True)\n",
        "    \n",
        "    # Print summary information\n",
        "    print(f\"Mannings n value ranges for {len(df)} land cover types:\")\n",
        "    print(df)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Create the Mannings n ranges dataframe\n",
        "manning_minmax_df = create_manning_minmax_df()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mannings Bulk Sensitivity Analysis Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def autoras_mannings_bulk_sensitivity(\n",
        "    project_folder,\n",
        "    template_plan,\n",
        "    manning_minmax_df=None,\n",
        "    include_regional_overrides=True,\n",
        "    include_base_overrides=True,\n",
        "    point_of_interest=None,\n",
        "    output_folder=\"Mannings_Bulk_Sensitivity\",\n",
        "    run_parallel=True,\n",
        "    max_workers=2,\n",
        "    num_cores=2\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform Mannings n bulk sensitivity analysis by running model with minimum,\n",
        "    maximum, and current Mannings n values.\n",
        "    \n",
        "    Args:\n",
        "        project_folder (str): Path to HEC-RAS project folder\n",
        "        template_plan (str): Plan number to use as template (e.g., \"01\")\n",
        "        manning_minmax_df (pd.DataFrame, optional): DataFrame with min/max n values\n",
        "        include_regional_overrides (bool, optional): Whether to adjust regional\n",
        "            Mannings values. Default is True.\n",
        "        include_base_overrides (bool, optional): Whether to adjust base \n",
        "            Mannings values. Default is True.\n",
        "        point_of_interest (tuple or Point, optional): Coordinates for extracting results\n",
        "        output_folder (str, optional): Name of output folder for results\n",
        "        run_parallel (bool, optional): Whether to run plans in parallel\n",
        "        max_workers (int, optional): Number of parallel workers\n",
        "        num_cores (int, optional): Number of cores per worker\n",
        "    \n",
        "    Returns:\n",
        "        dict: Results of sensitivity analysis\n",
        "    \"\"\"\n",
        "    import time\n",
        "    from datetime import datetime\n",
        "    \n",
        "    # Validate inputs\n",
        "    if not include_regional_overrides and not include_base_overrides:\n",
        "        raise ValueError(\"At least one of include_regional_overrides or include_base_overrides must be True\")\n",
        "    \n",
        "    # Use default manning_minmax_df if none provided\n",
        "    if manning_minmax_df is None:\n",
        "        manning_minmax_df = create_manning_minmax_df()\n",
        "    \n",
        "    # Convert point_of_interest to Point if provided\n",
        "    if point_of_interest is not None and not isinstance(point_of_interest, Point):\n",
        "        point_of_interest = Point(point_of_interest[0], point_of_interest[1])\n",
        "    \n",
        "    # Create timestamp for unique run identifier\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Initialize RAS project using HEC-RAS Version 6.6 (Change if needed)\n",
        "    print(f\"Initializing HEC-RAS project: {project_folder}\")\n",
        "    ras = init_ras_project(project_folder, \"6.6\")\n",
        "    \n",
        "    # Create output directory\n",
        "    results_dir = Path(project_folder) / output_folder\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "    print(f\"Results will be saved to: {results_dir}\")\n",
        "    \n",
        "    # Display available plans\n",
        "    print(\"\\nAvailable plans:\")\n",
        "    print(ras.plan_df[['plan_number', 'Plan Title', 'Short Identifier']])\n",
        "    \n",
        "    # Verify template plan exists\n",
        "    if template_plan not in ras.plan_df['plan_number'].values:\n",
        "        raise ValueError(f\"Template plan {template_plan} not found in project\")\n",
        "    \n",
        "    # Get the geometry number associated with the template plan\n",
        "    template_geom = ras.plan_df.loc[ras.plan_df['plan_number'] == template_plan, 'geometry_number'].values[0]\n",
        "    print(f\"\\nTemplate plan: {template_plan} (Geometry: {template_geom})\")\n",
        "    \n",
        "    # Get the geometry file path\n",
        "    geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == template_geom, 'full_path'].values[0]\n",
        "    \n",
        "    # Get the original Mannings values\n",
        "    original_baseoverrides = RasGeo.get_mannings_baseoverrides(geom_path)\n",
        "    original_regionoverrides = RasGeo.get_mannings_regionoverrides(geom_path)\n",
        "    \n",
        "    # Check if regional overrides exist\n",
        "    has_regional_overrides = not original_regionoverrides.empty\n",
        "    \n",
        "    if include_regional_overrides and not has_regional_overrides:\n",
        "        raise ValueError(\"include_regional_overrides is True, but no regional overrides found in the model\")\n",
        "    \n",
        "    # Store the current plan as \"current\" scenario\n",
        "    scenarios = [{\n",
        "        'name': 'Current',\n",
        "        'plan_number': template_plan,\n",
        "        'geom_number': template_geom,\n",
        "        'shortid': f\"Current\",\n",
        "        'description': \"Current Mannings n Values\"\n",
        "    }]\n",
        "    \n",
        "    # Function to create a modified plan with adjusted Mannings values\n",
        "    def create_modified_plan(name, shortid, description, min_values=False, max_values=False):\n",
        "        print(f\"\\nCreating plan: {name} (ShortID: {shortid})\")\n",
        "        print(f\"Description: {description}\")\n",
        "        \n",
        "        # Clone the template plan\n",
        "        new_plan_number = RasPlan.clone_plan(template_plan, new_plan_shortid=shortid)\n",
        "        \n",
        "        # Clone the template geometry\n",
        "        new_geom_number = RasPlan.clone_geom(template_geom)\n",
        "        \n",
        "        # Set the new plan to use the new geometry\n",
        "        RasPlan.set_geom(new_plan_number, new_geom_number)\n",
        "        \n",
        "        # Get the new geometry file path\n",
        "        new_geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == new_geom_number, 'full_path'].values[0]\n",
        "        \n",
        "        # Adjust base Mannings values if enabled\n",
        "        if include_base_overrides:\n",
        "            modified_baseoverrides = original_baseoverrides.copy()\n",
        "            \n",
        "            # For each land cover type in the base overrides\n",
        "            for idx, row in modified_baseoverrides.iterrows():\n",
        "                land_cover = row['Land Cover Name']\n",
        "                \n",
        "                # Find matching land cover in manning_minmax_df\n",
        "                match = manning_minmax_df[manning_minmax_df['Land Cover Name'] == land_cover]\n",
        "                \n",
        "                if not match.empty:\n",
        "                    current_value = row[\"Base Mannings n Value\"]\n",
        "                    \n",
        "                    if min_values:\n",
        "                        new_value = match['min_n'].values[0]\n",
        "                    elif max_values:\n",
        "                        new_value = match['max_n'].values[0]\n",
        "                    else:\n",
        "                        new_value = current_value  # No change\n",
        "                    \n",
        "                    modified_baseoverrides.loc[idx, \"Base Mannings n Value\"] = new_value\n",
        "                    print(f\"  Adjusted base override for '{land_cover}': {current_value:.4f} \u2192 {new_value:.4f}\")\n",
        "            \n",
        "            # Apply modified base Mannings values\n",
        "            RasGeo.set_mannings_baseoverrides(new_geom_path, modified_baseoverrides)\n",
        "        else:\n",
        "            # Just copy the original base overrides\n",
        "            RasGeo.set_mannings_baseoverrides(new_geom_path, original_baseoverrides)\n",
        "        \n",
        "        # Adjust regional Mannings values if enabled and they exist\n",
        "        if include_regional_overrides and has_regional_overrides:\n",
        "            modified_regionoverrides = original_regionoverrides.copy()\n",
        "            \n",
        "            # For each row in the region overrides\n",
        "            for idx, row in modified_regionoverrides.iterrows():\n",
        "                land_cover = row['Land Cover Name']\n",
        "                region_name = row['Region Name']\n",
        "                \n",
        "                # Find matching land cover in manning_minmax_df\n",
        "                match = manning_minmax_df[manning_minmax_df['Land Cover Name'] == land_cover]\n",
        "                \n",
        "                if not match.empty:\n",
        "                    current_value = row[\"MainChannel\"]\n",
        "                    \n",
        "                    if min_values:\n",
        "                        new_value = match['min_n'].values[0]\n",
        "                    elif max_values:\n",
        "                        new_value = match['max_n'].values[0]\n",
        "                    else:\n",
        "                        new_value = current_value  # No change\n",
        "                    \n",
        "                    modified_regionoverrides.loc[idx, \"MainChannel\"] = new_value\n",
        "                    print(f\"  Adjusted region override for '{land_cover}' in '{region_name}': {current_value:.4f} \u2192 {new_value:.4f}\")\n",
        "            \n",
        "            # Apply modified regional Mannings values\n",
        "            RasGeo.set_mannings_regionoverrides(new_geom_path, modified_regionoverrides)\n",
        "        elif has_regional_overrides:\n",
        "            # Just copy the original region overrides\n",
        "            RasGeo.set_mannings_regionoverrides(new_geom_path, original_regionoverrides)\n",
        "        \n",
        "        # Store scenario details\n",
        "        return {\n",
        "            'name': name,\n",
        "            'plan_number': new_plan_number,\n",
        "            'geom_number': new_geom_number,\n",
        "            'shortid': shortid,\n",
        "            'description': description\n",
        "        }\n",
        "    \n",
        "    # Create minimum and maximum scenarios\n",
        "    min_scenario = create_modified_plan(\n",
        "        name=\"Minimum\",\n",
        "        shortid=\"Min_n\",\n",
        "        description=\"Minimum Recommended Mannings n Values\",\n",
        "        min_values=True\n",
        "    )\n",
        "\n",
        "    print(f\"Minimum Scenario Plan Number: {min_scenario}\")\n",
        "    \n",
        "    max_scenario = create_modified_plan(\n",
        "        name=\"Maximum\",\n",
        "        shortid=\"Max_n\",\n",
        "        description=\"Maximum Recommended Mannings n Values\",\n",
        "        max_values=True\n",
        "    )\n",
        "    \n",
        "    print(f\"Maximum Scenario Plan Number: {max_scenario}\")\n",
        "\n",
        "    # Add scenarios to list\n",
        "    scenarios.append(min_scenario)\n",
        "    scenarios.append(max_scenario)\n",
        "\n",
        "    print(f\"Scenarios: \\n{scenarios}\")\n",
        "    \n",
        "    # Get plan numbers for the new scenarios (excluding template which is already computed)\n",
        "    plan_numbers = [str(scenario['plan_number']) for scenario in scenarios]\n",
        "    print(f\"Plan Numbers: \\n{plan_numbers}\")\n",
        "\n",
        "    # Save scenario information\n",
        "    scenario_info = pd.DataFrame(scenarios)\n",
        "    scenario_info_path = results_dir / \"scenarios.csv\"\n",
        "    scenario_info.to_csv(scenario_info_path, index=False)\n",
        "    print(f\"\\nScenario information saved to: {scenario_info_path}\")\n",
        "    \n",
        "    # Run the plans (either in parallel or sequentially)\n",
        "    if run_parallel:\n",
        "        print(f\"\\nRunning {len(plan_numbers)} plans in parallel...\")\n",
        "        results = RasCmdr.compute_parallel(\n",
        "            plan_number=plan_numbers,\n",
        "            max_workers=max_workers,\n",
        "            num_cores=num_cores,\n",
        "            clear_geompre=True\n",
        "        )\n",
        "    else:\n",
        "        print(f\"\\nRunning {len(plan_numbers)} plans sequentially...\")\n",
        "        results = {}\n",
        "        for plan_number in plan_numbers:\n",
        "            print(f\"  Running plan {plan_number}...\")\n",
        "            result = RasCmdr.compute_plan(plan_number, num_cores=num_cores, clear_geompre=True)\n",
        "            results[plan_number] = result\n",
        "    \n",
        "    print(\"\\nExecution results:\")\n",
        "    for plan, success in results.items():\n",
        "        print(f\"  Plan {plan}: {'Successful' if success else 'Failed'}\")\n",
        "    \n",
        "    # Early return if no point of interest is provided\n",
        "    if point_of_interest is None:\n",
        "        print(\"\\nNo point of interest provided. Skipping results extraction and analysis.\")\n",
        "        return {\n",
        "            'scenarios': scenarios,\n",
        "            'execution_results': results,\n",
        "            'output_folder': results_dir\n",
        "        }\n",
        "    \n",
        "    # Find nearest mesh cell for result extraction\n",
        "    # Use the geometry from the first executed plan for cell identification\n",
        "    geom_hdf_path = None\n",
        "    for scenario in scenarios:\n",
        "        geom_number = scenario['geom_number']\n",
        "        try:\n",
        "            geom_hdf_path = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    if geom_hdf_path is None:\n",
        "        print(\"ERROR: Could not find HDF path for any geometry\")\n",
        "        return {\n",
        "            'scenarios': scenarios,\n",
        "            'execution_results': results,\n",
        "            'output_folder': results_dir\n",
        "        }\n",
        "    \n",
        "    plan_number = scenario['plan_number']\n",
        "\n",
        "    # Find the nearest mesh cell to the point of interest\n",
        "    mesh_cells_gdf = HdfMesh.get_mesh_cell_points(plan_number)\n",
        "    \n",
        "    # Calculate distances from the point to all mesh cells\n",
        "    distances = mesh_cells_gdf.geometry.apply(lambda geom: geom.distance(point_of_interest))\n",
        "    \n",
        "    # Find the index of the minimum distance\n",
        "    nearest_idx = distances.idxmin()\n",
        "    \n",
        "    # Get the cell ID for results extraction\n",
        "    mesh_cell_for_results = mesh_cells_gdf.loc[nearest_idx, 'cell_id']\n",
        "    mesh_name = mesh_cells_gdf.loc[nearest_idx, 'mesh_name']\n",
        "    \n",
        "    print(f\"\\nNearest cell ID: {mesh_cell_for_results}\")\n",
        "    print(f\"Distance: {distances[nearest_idx]:.2f} units\")\n",
        "    print(f\"Mesh area: {mesh_name}\")\n",
        "    \n",
        "    # Extract and store results\n",
        "    all_results = {}\n",
        "    max_ws_values = []\n",
        "    \n",
        "    # Get results for each scenario\n",
        "    for scenario in scenarios:\n",
        "        plan_number = scenario['plan_number']\n",
        "        name = scenario['name']\n",
        "        shortid = scenario['shortid']\n",
        "        \n",
        "        # Get the results for this plan\n",
        "        try:\n",
        "            results_xr = HdfResultsMesh.get_mesh_cells_timeseries(plan_number)\n",
        "            \n",
        "            # Extract water surface data for the specific cell\n",
        "            ws_data = results_xr[mesh_name]['Water Surface'].sel(cell_id=int(mesh_cell_for_results))\n",
        "            \n",
        "            # Convert to DataFrame for easier handling\n",
        "            ws_df = pd.DataFrame({\n",
        "                'time': ws_data.time.values,\n",
        "                'water_surface': ws_data.values\n",
        "            })\n",
        "            \n",
        "            # Store in results dictionary\n",
        "            all_results[plan_number] = {\n",
        "                'name': name,\n",
        "                'shortid': shortid,\n",
        "                'df': ws_df,\n",
        "                'max_water_surface': ws_df['water_surface'].max()\n",
        "            }\n",
        "            \n",
        "            # Store the maximum water surface value for summary\n",
        "            max_ws = ws_df['water_surface'].max()\n",
        "            max_ws_values.append({\n",
        "                'plan_number': plan_number,\n",
        "                'name': name,\n",
        "                'shortid': shortid,\n",
        "                'max_water_surface': max_ws\n",
        "            })\n",
        "            \n",
        "            print(f\"Scenario: {name} ({shortid}): Max Water Surface = {max_ws:.2f}\")\n",
        "            \n",
        "            # Save time series to CSV\n",
        "            plan_csv_path = results_dir / f\"timeseries_{shortid}.csv\"\n",
        "            ws_df.to_csv(plan_csv_path, index=False)\n",
        "            print(f\"  Time series saved to: {plan_csv_path}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting results for scenario {name}: {str(e)}\")\n",
        "    \n",
        "    # Create a summary DataFrame for maximum water surface values\n",
        "    max_ws_df = pd.DataFrame(max_ws_values)\n",
        "    \n",
        "    # Save the summary to CSV\n",
        "    summary_csv_path = results_dir / \"max_water_surface_summary.csv\"\n",
        "    max_ws_df.to_csv(summary_csv_path, index=False)\n",
        "    print(f\"\\nSummary of maximum water surface elevations saved to: {summary_csv_path}\")\n",
        "    \n",
        "    # Create and save plots if results were successfully extracted\n",
        "    if all_results:\n",
        "        # Plot time series for all scenarios\n",
        "        plt.figure(figsize=(14, 8))\n",
        "        \n",
        "        # Define colors for scenarios\n",
        "        colors = {'Current': 'black', 'Minimum': 'blue', 'Maximum': 'red'}\n",
        "        \n",
        "        # Plot each scenario\n",
        "        for scenario in scenarios:\n",
        "            plan_number = scenario['plan_number']\n",
        "            name = scenario['name']\n",
        "            \n",
        "            if plan_number in all_results:\n",
        "                result = all_results[plan_number]\n",
        "                df = result['df']\n",
        "                \n",
        "                color = colors.get(name, 'gray')\n",
        "                linestyle = '-' if name == 'Current' else '--'\n",
        "                linewidth = 2 if name == 'Current' else 1.5\n",
        "                \n",
        "                plt.plot(df['time'], df['water_surface'], \n",
        "                         label=f\"{name} ({result['shortid']})\",\n",
        "                         color=color, linestyle=linestyle, linewidth=linewidth)\n",
        "        \n",
        "        # Add plot details\n",
        "        plt.title(f'Water Surface Sensitivity to Manning\\'s Roughness at Cell ID: {mesh_cell_for_results}')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Water Surface Elevation (ft)')\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.legend()\n",
        "        \n",
        "        # Save the time series plot\n",
        "        timeseries_plot_path = results_dir / \"water_surface_timeseries.png\"\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(timeseries_plot_path)\n",
        "        print(f\"Time series plot saved to: {timeseries_plot_path}\")\n",
        "        \n",
        "        # Create bar chart of maximum water surface elevations\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        \n",
        "        # Sort by name for consistent ordering\n",
        "        max_ws_df_sorted = max_ws_df.sort_values('name')\n",
        "        \n",
        "        # Create bar colors\n",
        "        bar_colors = [colors.get(name, 'gray') for name in max_ws_df_sorted['name']]\n",
        "        \n",
        "        # Create bar chart\n",
        "        plt.bar(max_ws_df_sorted['name'], max_ws_df_sorted['max_water_surface'], color=bar_colors)\n",
        "        \n",
        "        # Add values on top of bars\n",
        "        for i, value in enumerate(max_ws_df_sorted['max_water_surface']):\n",
        "            plt.text(i, value + 0.1, f'{value:.2f}', ha='center')\n",
        "        \n",
        "        # Add plot details\n",
        "        plt.title('Maximum Water Surface Elevation by Manning\\'s Roughness Scenario')\n",
        "        plt.ylabel('Maximum Water Surface Elevation (ft)')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        \n",
        "        # Save the bar chart\n",
        "        bar_plot_path = results_dir / \"max_water_surface_comparison.png\"\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(bar_plot_path)\n",
        "        print(f\"Bar chart saved to: {bar_plot_path}\")\n",
        "        \n",
        "        # Show plots\n",
        "        plt.show()\n",
        "    \n",
        "    # Calculate differences between scenarios\n",
        "    if len(max_ws_df) >= 2:\n",
        "        # Get values for each scenario\n",
        "        try:\n",
        "            current_ws = max_ws_df.loc[max_ws_df['name'] == 'Current', 'max_water_surface'].values[0]\n",
        "            min_ws = max_ws_df.loc[max_ws_df['name'] == 'Minimum', 'max_water_surface'].values[0]\n",
        "            max_ws = max_ws_df.loc[max_ws_df['name'] == 'Maximum', 'max_water_surface'].values[0]\n",
        "            \n",
        "            print(\"\\nSensitivity Analysis Summary:\")\n",
        "            print(f\"  Current maximum WSE: {current_ws:.2f} ft\")\n",
        "            print(f\"  Minimum n maximum WSE: {min_ws:.2f} ft\")\n",
        "            print(f\"  Maximum n maximum WSE: {max_ws:.2f} ft\")\n",
        "            print(f\"  Range: {max_ws - min_ws:.2f} ft\")\n",
        "            print(f\"  Current vs Min: {current_ws - min_ws:.2f} ft\")\n",
        "            print(f\"  Current vs Max: {max_ws - current_ws:.2f} ft\")\n",
        "            \n",
        "            # Calculate the percentage of the range\n",
        "            if max_ws != min_ws:\n",
        "                current_position = (current_ws - min_ws) / (max_ws - min_ws) * 100\n",
        "                print(f\"  Current position within range: {current_position:.1f}%\")\n",
        "        except:\n",
        "            print(\"Could not calculate differences between scenarios\")\n",
        "    \n",
        "    # Return results\n",
        "    return {\n",
        "        'scenarios': scenarios,\n",
        "        'execution_results': results,\n",
        "        'results': all_results if 'all_results' in locals() else None,\n",
        "        'max_ws_summary': max_ws_df if 'max_ws_df' in locals() else None,\n",
        "        'mesh_cell_id': mesh_cell_for_results if 'mesh_cell_for_results' in locals() else None,\n",
        "        'mesh_name': mesh_name if 'mesh_name' in locals() else None,\n",
        "        'output_folder': results_dir\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n",
            "2025-11-21 18:16:04 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n",
            "2025-11-21 18:16:05 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        }
      ],
      "source": [
        "# Run this code cell if you want to use the BaldEagleCrkMulti2D Example Project\n",
        "\n",
        "RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
        "\n",
        "import os\n",
        "# Get the current directory for the project path\n",
        "current_dir = Path(os.getcwd()).resolve()\n",
        "\n",
        "project_folder = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "template_plan = \"03\"  # This plan number has both base and regional overrides\n",
        "\n",
        "# Either as a tuple (x, y) or as a Point object\n",
        "point_of_interest = (2081544, 365715)  # Adjust coordinates as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and Run this Code Cell if you are using your own project\n",
        "#project_folder = r\"C:\\Path\\To\\HEC-RAS\\Project\"\n",
        "#template_plan = \"01\"  # Change to your desired template plan number\n",
        "\n",
        "# Either as a tuple (x, y) or as a Point object\n",
        "#point_of_interest = (2081544, 365715)  # Adjust coordinates as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mannings n value ranges for 16 land cover types:\n",
            "                 Land Cover Name  min_n  max_n   mid_n\n",
            "0     Barren Land Rock/Sand/Clay  0.023   0.10  0.0615\n",
            "1               Cultivated Crops  0.020   0.10  0.0600\n",
            "2               Deciduous Forest  0.100   0.20  0.1500\n",
            "3      Developed, High Intensity  0.120   0.20  0.1600\n",
            "4       Developed, Low Intensity  0.060   0.12  0.0900\n",
            "5    Developed, Medium Intensity  0.080   0.16  0.1200\n",
            "6          Developed, Open Space  0.030   0.09  0.0600\n",
            "7   Emergent Herbaceous Wetlands  0.050   0.12  0.0850\n",
            "8               Evergreen Forest  0.080   0.16  0.1200\n",
            "9           Grassland/Herbaceous  0.025   0.07  0.0475\n",
            "10                  Mixed Forest  0.080   0.20  0.1400\n",
            "11                        NoData  0.050   0.07  0.0600\n",
            "12                    Open Water  0.025   0.05  0.0375\n",
            "13                   Pasture/Hay  0.025   0.09  0.0575\n",
            "14                   Shrub/Scrub  0.070   0.16  0.1150\n",
            "15                Woody Wetlands  0.045   0.15  0.0975\n"
          ]
        }
      ],
      "source": [
        "# Define a point of interest for result extraction\n",
        "\n",
        "\n",
        "# Create the Mannings n ranges dataframe (or use the default)\n",
        "manning_ranges = create_manning_minmax_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:16:05 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03 to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Project file updated with new Plan entry: 07\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing HEC-RAS project: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n",
            "Results will be saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\n",
            "\n",
            "Available plans:\n",
            "   plan_number                               Plan Title  \\\n",
            "0           13                  PMF with Multi 2D Areas   \n",
            "1           15              1d-2D Dambreak Refined Grid   \n",
            "2           17                          2D to 1D No Dam   \n",
            "3           18                             2D to 2D Run   \n",
            "4           19                   SA to 2D Dam Break Run   \n",
            "5           03  Single 2D Area - Internal Dam Structure   \n",
            "6           04  SA to 2D Area Conn - 2D Levee Structure   \n",
            "7           02                 SA to Detailed 2D Breach   \n",
            "8           01             SA to Detailed 2D Breach FEQ   \n",
            "9           05          Single 2D area with Bridges FEQ   \n",
            "10          06            Gridded Precip - Infiltration   \n",
            "\n",
            "            Short Identifier  \n",
            "0               PMF Multi 2D  \n",
            "1         1D-2D Refined Grid  \n",
            "2            2D to 1D No Dam  \n",
            "3               2D to 2D Run  \n",
            "4         SA to 2D Dam Break  \n",
            "5                  Single 2D  \n",
            "6             2D Levee Struc  \n",
            "7             SA-2D Det Brch  \n",
            "8              SA-2D Det FEQ  \n",
            "9      Single 2D Bridges FEQ  \n",
            "10  Grid Precip Infiltration  \n",
            "\n",
            "Template plan: 03 (Geometry: 09)\n",
            "\n",
            "Creating plan: Minimum (ShortID: Min_n)\n",
            "Description: Minimum Recommended Mannings n Values\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:16:05 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09 to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g04\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g04.hdf\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Project file updated with new Geom entry: 04\n",
            "2025-11-21 18:16:05 - ras_commander.RasPlan - INFO - Updated Geom File in plan file to g04 for plan 07\n",
            "2025-11-21 18:16:05 - ras_commander.RasPlan - INFO - Geometry for plan 07 set to 04\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03 to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Project file updated with new Plan entry: 08\n",
            "2025-11-21 18:16:05 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09 to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g05\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - File cloned from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g05.hdf\n",
            "2025-11-21 18:16:05 - ras_commander.RasUtils - INFO - Project file updated with new Geom entry: 05\n",
            "2025-11-21 18:16:05 - ras_commander.RasPlan - INFO - Updated Geom File in plan file to g05 for plan 08\n",
            "2025-11-21 18:16:05 - ras_commander.RasPlan - INFO - Geometry for plan 08 set to 05\n",
            "2025-11-21 18:16:05 - ras_commander.RasCmdr - INFO - Filtered plans to execute: ['03', '07', '08']\n",
            "2025-11-21 18:16:05 - ras_commander.RasCmdr - INFO - Adjusted max_workers to 2 based on the number of plans: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Adjusted base override for 'NoData': 0.0600 \u2192 0.0500\n",
            "  Adjusted base override for 'Barren Land Rock/Sand/Clay': 0.0400 \u2192 0.0230\n",
            "  Adjusted base override for 'Cultivated Crops': 0.0600 \u2192 0.0200\n",
            "  Adjusted base override for 'Deciduous Forest': 0.1000 \u2192 0.1000\n",
            "  Adjusted base override for 'Developed, High Intensity': 0.1500 \u2192 0.1200\n",
            "  Adjusted base override for 'Developed, Low Intensity': 0.1000 \u2192 0.0600\n",
            "  Adjusted base override for 'Developed, Medium Intensity': 0.0800 \u2192 0.0800\n",
            "  Adjusted base override for 'Developed, Open Space': 0.0400 \u2192 0.0300\n",
            "  Adjusted base override for 'Emergent Herbaceous Wetlands': 0.0800 \u2192 0.0500\n",
            "  Adjusted base override for 'Evergreen Forest': 0.1200 \u2192 0.0800\n",
            "  Adjusted base override for 'Grassland/Herbaceous': 0.0450 \u2192 0.0250\n",
            "  Adjusted base override for 'Mixed Forest': 0.0800 \u2192 0.0800\n",
            "  Adjusted base override for 'Open Water': 0.0350 \u2192 0.0250\n",
            "  Adjusted base override for 'Pasture/Hay': 0.0600 \u2192 0.0250\n",
            "  Adjusted base override for 'Shrub/Scrub': 0.0800 \u2192 0.0700\n",
            "  Adjusted base override for 'Woody Wetlands': 0.1200 \u2192 0.0450\n",
            "  Adjusted region override for 'NoData' in 'Main Channel': 0.0400 \u2192 0.0500\n",
            "  Adjusted region override for 'Barren Land Rock/Sand/Clay' in 'Main Channel': 0.0400 \u2192 0.0230\n",
            "  Adjusted region override for 'Cultivated Crops' in 'Main Channel': 0.0400 \u2192 0.0200\n",
            "  Adjusted region override for 'Deciduous Forest' in 'Main Channel': 0.0400 \u2192 0.1000\n",
            "  Adjusted region override for 'Developed, High Intensity' in 'Main Channel': 0.0400 \u2192 0.1200\n",
            "  Adjusted region override for 'Developed, Low Intensity' in 'Main Channel': 0.0400 \u2192 0.0600\n",
            "  Adjusted region override for 'Developed, Medium Intensity' in 'Main Channel': 0.0400 \u2192 0.0800\n",
            "  Adjusted region override for 'Developed, Open Space' in 'Main Channel': 0.0400 \u2192 0.0300\n",
            "  Adjusted region override for 'Emergent Herbaceous Wetlands' in 'Main Channel': 0.0400 \u2192 0.0500\n",
            "  Adjusted region override for 'Evergreen Forest' in 'Main Channel': 0.0400 \u2192 0.0800\n",
            "  Adjusted region override for 'Grassland/Herbaceous' in 'Main Channel': 0.0400 \u2192 0.0250\n",
            "  Adjusted region override for 'Mixed Forest' in 'Main Channel': 0.0400 \u2192 0.0800\n",
            "  Adjusted region override for 'Open Water' in 'Main Channel': 0.0400 \u2192 0.0250\n",
            "  Adjusted region override for 'Pasture/Hay' in 'Main Channel': 0.0400 \u2192 0.0250\n",
            "  Adjusted region override for 'Shrub/Scrub' in 'Main Channel': 0.0400 \u2192 0.0700\n",
            "  Adjusted region override for 'Woody Wetlands' in 'Main Channel': 0.0400 \u2192 0.0450\n",
            "Minimum Scenario Plan Number: {'name': 'Minimum', 'plan_number': '07', 'geom_number': '04', 'shortid': 'Min_n', 'description': 'Minimum Recommended Mannings n Values'}\n",
            "\n",
            "Creating plan: Maximum (ShortID: Max_n)\n",
            "Description: Maximum Recommended Mannings n Values\n",
            "  Adjusted base override for 'NoData': 0.0600 \u2192 0.0700\n",
            "  Adjusted base override for 'Barren Land Rock/Sand/Clay': 0.0400 \u2192 0.1000\n",
            "  Adjusted base override for 'Cultivated Crops': 0.0600 \u2192 0.1000\n",
            "  Adjusted base override for 'Deciduous Forest': 0.1000 \u2192 0.2000\n",
            "  Adjusted base override for 'Developed, High Intensity': 0.1500 \u2192 0.2000\n",
            "  Adjusted base override for 'Developed, Low Intensity': 0.1000 \u2192 0.1200\n",
            "  Adjusted base override for 'Developed, Medium Intensity': 0.0800 \u2192 0.1600\n",
            "  Adjusted base override for 'Developed, Open Space': 0.0400 \u2192 0.0900\n",
            "  Adjusted base override for 'Emergent Herbaceous Wetlands': 0.0800 \u2192 0.1200\n",
            "  Adjusted base override for 'Evergreen Forest': 0.1200 \u2192 0.1600\n",
            "  Adjusted base override for 'Grassland/Herbaceous': 0.0450 \u2192 0.0700\n",
            "  Adjusted base override for 'Mixed Forest': 0.0800 \u2192 0.2000\n",
            "  Adjusted base override for 'Open Water': 0.0350 \u2192 0.0500\n",
            "  Adjusted base override for 'Pasture/Hay': 0.0600 \u2192 0.0900\n",
            "  Adjusted base override for 'Shrub/Scrub': 0.0800 \u2192 0.1600\n",
            "  Adjusted base override for 'Woody Wetlands': 0.1200 \u2192 0.1500\n",
            "  Adjusted region override for 'NoData' in 'Main Channel': 0.0400 \u2192 0.0700\n",
            "  Adjusted region override for 'Barren Land Rock/Sand/Clay' in 'Main Channel': 0.0400 \u2192 0.1000\n",
            "  Adjusted region override for 'Cultivated Crops' in 'Main Channel': 0.0400 \u2192 0.1000\n",
            "  Adjusted region override for 'Deciduous Forest' in 'Main Channel': 0.0400 \u2192 0.2000\n",
            "  Adjusted region override for 'Developed, High Intensity' in 'Main Channel': 0.0400 \u2192 0.2000\n",
            "  Adjusted region override for 'Developed, Low Intensity' in 'Main Channel': 0.0400 \u2192 0.1200\n",
            "  Adjusted region override for 'Developed, Medium Intensity' in 'Main Channel': 0.0400 \u2192 0.1600\n",
            "  Adjusted region override for 'Developed, Open Space' in 'Main Channel': 0.0400 \u2192 0.0900\n",
            "  Adjusted region override for 'Emergent Herbaceous Wetlands' in 'Main Channel': 0.0400 \u2192 0.1200\n",
            "  Adjusted region override for 'Evergreen Forest' in 'Main Channel': 0.0400 \u2192 0.1600\n",
            "  Adjusted region override for 'Grassland/Herbaceous' in 'Main Channel': 0.0400 \u2192 0.0700\n",
            "  Adjusted region override for 'Mixed Forest' in 'Main Channel': 0.0400 \u2192 0.2000\n",
            "  Adjusted region override for 'Open Water' in 'Main Channel': 0.0400 \u2192 0.0500\n",
            "  Adjusted region override for 'Pasture/Hay' in 'Main Channel': 0.0400 \u2192 0.0900\n",
            "  Adjusted region override for 'Shrub/Scrub' in 'Main Channel': 0.0400 \u2192 0.1600\n",
            "  Adjusted region override for 'Woody Wetlands' in 'Main Channel': 0.0400 \u2192 0.1500\n",
            "Maximum Scenario Plan Number: {'name': 'Maximum', 'plan_number': '08', 'geom_number': '05', 'shortid': 'Max_n', 'description': 'Maximum Recommended Mannings n Values'}\n",
            "Scenarios: \n",
            "[{'name': 'Current', 'plan_number': '03', 'geom_number': '09', 'shortid': 'Current', 'description': 'Current Mannings n Values'}, {'name': 'Minimum', 'plan_number': '07', 'geom_number': '04', 'shortid': 'Min_n', 'description': 'Minimum Recommended Mannings n Values'}, {'name': 'Maximum', 'plan_number': '08', 'geom_number': '05', 'shortid': 'Max_n', 'description': 'Maximum Recommended Mannings n Values'}]\n",
            "Plan Numbers: \n",
            "['03', '07', '08']\n",
            "\n",
            "Scenario information saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\scenarios.csv\n",
            "\n",
            "Running 3 plans in parallel...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Removed existing worker folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Created worker folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\n",
            "2025-11-21 18:16:06 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:06 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Removed existing worker folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Created worker folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\n",
            "2025-11-21 18:16:06 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:06 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p03\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p03\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 07\n",
            "2025-11-21 18:16:06 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n",
            "2025-11-21 18:16:06 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 03\n",
            "2025-11-21 18:16:06 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p03\n",
            "2025-11-21 18:16:06 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.p07\n",
            "2025-11-21 18:16:06 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p03\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 07\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 2]\\BaldEagleDamBrk.p07\"\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 03\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-11-21 18:16:06 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p03\"\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 03\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Total run time for plan 03: 159.92 seconds\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Plan 03 executed in worker 1: Successful\n",
            "2025-11-21 18:18:46 - ras_commander.RasGeo - INFO - Clearing geometry preprocessor file for single plan: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:18:46 - ras_commander.RasGeo - WARNING - No geometry preprocessor file found for: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:18:46 - ras_commander.RasGeo - INFO - Geometry dataframe updated successfully.\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Cleared geometry preprocessor files for plan: 08\n",
            "2025-11-21 18:18:46 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:18:46 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p08\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Set number of cores to 2 for plan: 08\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-11-21 18:18:46 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Worker 1]\\BaldEagleDamBrk.p08\"\n",
            "2025-11-21 18:19:21 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 07\n",
            "2025-11-21 18:19:21 - ras_commander.RasCmdr - INFO - Total run time for plan 07: 194.93 seconds\n",
            "2025-11-21 18:19:21 - ras_commander.RasCmdr - INFO - Plan 07 executed in worker 2: Successful\n",
            "2025-11-21 18:20:54 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 08\n",
            "2025-11-21 18:20:54 - ras_commander.RasCmdr - INFO - Total run time for plan 08: 127.76 seconds\n",
            "2025-11-21 18:20:54 - ras_commander.RasCmdr - INFO - Plan 08 executed in worker 1: Successful\n",
            "2025-11-21 18:20:54 - ras_commander.RasCmdr - INFO - Final destination for computed results: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\n",
            "2025-11-21 18:20:59 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:20:59 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.rasmap\n",
            "2025-11-21 18:20:59 - ras_commander.RasCmdr - INFO - \n",
            "Execution Results:\n",
            "2025-11-21 18:20:59 - ras_commander.RasCmdr - INFO - Plan 03: Successful\n",
            "2025-11-21 18:20:59 - ras_commander.RasCmdr - INFO - Plan 07: Successful\n",
            "2025-11-21 18:20:59 - ras_commander.RasCmdr - INFO - Plan 08: Successful\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Execution results:\n",
            "  Plan 03: Successful\n",
            "  Plan 07: Successful\n",
            "  Plan 08: Successful\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p03.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Nearest cell ID: 943\n",
            "Distance: 56.22 units\n",
            "Mesh area: BaldEagleCr\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Froude Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Courant Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Bed Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Precipitation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Infiltration Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Evaporation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Percolation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Water Surface' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Courant' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Cumulative Volume' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Eddy Viscosity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow Period Average' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Friction Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Pressure Gradient Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Tangential Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:20:59 - ras_commander.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p07.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p07.hdf\n",
            "2025-11-21 18:20:59 - ras_commander.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p07.hdf\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Froude Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Courant Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Bed Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Precipitation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Infiltration Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Evaporation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Percolation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scenario: Current (Current): Max Water Surface = 560.73\n",
            "  Time series saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\timeseries_Current.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Water Surface' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Courant' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Cumulative Volume' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Eddy Viscosity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow Period Average' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Friction Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Pressure Gradient Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Tangential Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p08.hdf\n",
            "2025-11-21 18:21:00 - ras_commander.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p08.hdf\n",
            "2025-11-21 18:21:00 - ras_commander.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D [Computed]\\BaldEagleDamBrk.p08.hdf\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Froude Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Courant Number' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Bed Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Precipitation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Infiltration Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Evaporation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Percolation Rate' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Elevation' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Depth' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity X' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Groundwater Velocity Y' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scenario: Minimum (Min_n): Max Water Surface = 560.11\n",
            "  Time series saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\timeseries_Min_n.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Water Surface' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Courant' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Cumulative Volume' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Eddy Viscosity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Flow Period Average' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Friction Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Pressure Gradient Term' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Shear Stress' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n",
            "2025-11-21 18:21:00 - ras_commander.HdfResultsMesh - WARNING - Variable 'Face Tangential Velocity' not found in the HDF file for mesh 'BaldEagleCr'. Skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scenario: Maximum (Max_n): Max Water Surface = 559.45\n",
            "  Time series saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\timeseries_Max_n.csv\n",
            "\n",
            "Summary of maximum water surface elevations saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\max_water_surface_summary.csv\n",
            "Time series plot saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\water_surface_timeseries.png\n",
            "Bar chart saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\\max_water_surface_comparison.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sensitivity Analysis Summary:\n",
            "  Current maximum WSE: 560.73 ft\n",
            "  Minimum n maximum WSE: 560.11 ft\n",
            "  Maximum n maximum WSE: 559.45 ft\n",
            "  Range: -0.66 ft\n",
            "  Current vs Min: 0.62 ft\n",
            "  Current vs Max: -1.28 ft\n",
            "  Current position within range: -93.9%\n"
          ]
        }
      ],
      "source": [
        "# Example usage of the Mannings Bulk Sensitivity Analysis function\n",
        "\n",
        "\n",
        "\n",
        "# Optional: Modify the ranges if needed\n",
        "# manning_ranges.loc[manning_ranges['Land Cover Name'] == 'Open Water', 'min_n'] = 0.03\n",
        "# manning_ranges.loc[manning_ranges['Land Cover Name'] == 'Open Water', 'max_n'] = 0.04\n",
        "\n",
        "# Run the analysis\n",
        "sensitivity_results = autoras_mannings_bulk_sensitivity(\n",
        "    project_folder=project_folder,\n",
        "    template_plan=template_plan,\n",
        "    manning_minmax_df=manning_ranges,\n",
        "    include_regional_overrides=True,\n",
        "    include_base_overrides=True,\n",
        "    point_of_interest=point_of_interest,\n",
        "    output_folder=\"Mannings_Bulk_Sensitivity\",\n",
        "    run_parallel=True,\n",
        "    max_workers=2,\n",
        "    num_cores=2\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results saved to: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Mannings_Bulk_Sensitivity\n"
          ]
        }
      ],
      "source": [
        "# Access the results\n",
        "scenarios = sensitivity_results['scenarios']\n",
        "max_ws_summary = sensitivity_results['max_ws_summary']\n",
        "output_folder = sensitivity_results['output_folder']\n",
        "\n",
        "print(f\"\\nResults saved to: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook provides a comprehensive framework for Mannings n sensitivity analysis in HEC-RAS models. It allows you to:\n",
        "\n",
        "1. Create models with minimum and maximum recommended Mannings n values\n",
        "2. Run simulations and extract results at locations of interest\n",
        "3. Visualize and compare water surface elevations across scenarios\n",
        "4. Understand the sensitivity of your model to roughness parameters\n",
        "\n",
        "The function gives you flexibility to include or exclude regional and base Mannings overrides, and to customize the analysis based on your specific project needs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\106_mannings_sensitivity_multi-interval.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "# Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Manning's n Sensitivity Analysis: Multi-Interval Approach\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates advanced Manning's n sensitivity analysis for HEC-RAS 2D models using the `ras-commander` library. It provides two complementary approaches to assess the impact of roughness parameter variations on model results:\n",
        "\n",
        "1. **Base Override Sensitivity**: Varies Manning's n values for individual land cover types in the base mesh roughness\n",
        "2. **Regional Override Sensitivity**: Varies Manning's n values for land cover types within defined calibration regions\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Literature-Based Ranges**: Uses documented Manning's n ranges for various land cover types\n",
        "- **Intelligent Filtering**: Automatically identifies significant land uses based on area coverage thresholds\n",
        "- **Multi-Interval Testing**: Tests multiple Manning's n values at specified intervals within the literature range\n",
        "- **Parallel Execution**: Efficiently runs multiple scenarios using HEC-RAS parallel computing\n",
        "- **Comprehensive Visualization**: Generates sensitivity plots and time series comparisons\n",
        "- **Automated Reporting**: Creates CSV summaries and exports results for further analysis\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "### Part 1: Setup and Configuration\n",
        "- Environment setup and imports\n",
        "- Manning's n range definitions\n",
        "- Helper functions for sensitivity analysis\n",
        "\n",
        "### Part 2: Base Override Sensitivity Analysis\n",
        "- Analysis of land cover statistics for the entire 2D mesh\n",
        "- Sensitivity testing by varying individual land cover Manning's n values\n",
        "- Results extraction and visualization\n",
        "\n",
        "### Part 3: Regional Override Sensitivity Analysis\n",
        "- Focus on specific calibration regions within the mesh\n",
        "- Analysis of main channel or other regional overrides\n",
        "- Targeted sensitivity testing for regional parameters\n",
        "\n",
        "## Navigation Tips\n",
        "\n",
        "- Use the table of contents or search for \"# Part\" to jump between major sections\n",
        "- Each analysis section includes execution examples with the BaldEagleCrkMulti2D sample project\n",
        "- Results are displayed with both plots and summary tables for easy interpretation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Setup and Configuration\n",
        "\n",
        "## Important Note on DataFrame Column Naming\n",
        "\n",
        "**Column Naming Convention in ras-commander:**\n",
        "\n",
        "The `ras-commander` library uses simplified column names in DataFrames for Manning's n values:\n",
        "\n",
        "- **DataFrame column**: `Mannings n` (no apostrophe)\n",
        "- **HEC-RAS HDF files**: `Manning's n` (with apostrophe - official technical term)\n",
        "\n",
        "This design decision simplifies DataFrame operations by avoiding special characters in column names, while HEC-RAS's internal HDF structure retains the technically correct spelling with the apostrophe.\n",
        "\n",
        "**Key Point**: When working with Manning's n values from `ras-commander`, always reference the column as `Mannings n` (without apostrophe) in your DataFrame operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Standard Library and Third-Party Imports\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from shapely.geometry import Point\n",
        "import math\n",
        "\n",
        "# Configure matplotlib for inline display in Jupyter\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 150\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the mannings n max and min values as a range. \n",
        "\n",
        "manning_data = [\n",
        "    {\"Land Cover Name\": \"NoData\", \"min_n\": 0.050, \"max_n\": 0.070},\n",
        "    {\"Land Cover Name\": \"Barren Land Rock/Sand/Clay\", \"min_n\": 0.023, \"max_n\": 0.100},\n",
        "    {\"Land Cover Name\": \"Cultivated Crops\", \"min_n\": 0.020, \"max_n\": 0.100},\n",
        "    {\"Land Cover Name\": \"Deciduous Forest\", \"min_n\": 0.100, \"max_n\": 0.200},\n",
        "    {\"Land Cover Name\": \"Developed, High Intensity\", \"min_n\": 0.120, \"max_n\": 0.200},\n",
        "    {\"Land Cover Name\": \"Developed, Low Intensity\", \"min_n\": 0.060, \"max_n\": 0.120},\n",
        "    {\"Land Cover Name\": \"Developed, Medium Intensity\", \"min_n\": 0.080, \"max_n\": 0.160},\n",
        "    {\"Land Cover Name\": \"Developed, Open Space\", \"min_n\": 0.030, \"max_n\": 0.090},\n",
        "    {\"Land Cover Name\": \"Emergent Herbaceous Wetlands\", \"min_n\": 0.050, \"max_n\": 0.120},\n",
        "    {\"Land Cover Name\": \"Evergreen Forest\", \"min_n\": 0.080, \"max_n\": 0.160},\n",
        "    {\"Land Cover Name\": \"Grassland/Herbaceous\", \"min_n\": 0.025, \"max_n\": 0.070},\n",
        "    {\"Land Cover Name\": \"Mixed Forest\", \"min_n\": 0.080, \"max_n\": 0.200},\n",
        "    {\"Land Cover Name\": \"Open Water\", \"min_n\": 0.025, \"max_n\": 0.050},\n",
        "    {\"Land Cover Name\": \"Pasture/Hay\", \"min_n\": 0.025, \"max_n\": 0.090},\n",
        "    {\"Land Cover Name\": \"Shrub/Scrub\", \"min_n\": 0.070, \"max_n\": 0.160},\n",
        "    {\"Land Cover Name\": \"Woody Wetlands\", \"min_n\": 0.045, \"max_n\": 0.150}\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "manning_minmax_df = pd.DataFrame(manning_data)\n",
        "\n",
        "# Calculate the midpoint value\n",
        "manning_minmax_df['mid_n'] = (manning_minmax_df['min_n'] + manning_minmax_df['max_n']) / 2\n",
        "\n",
        "# Sort by land cover name\n",
        "manning_minmax_df = manning_minmax_df.sort_values('Land Cover Name').reset_index(drop=True)\n",
        "\n",
        "# Print summary information\n",
        "print(f\"Manning's n value ranges for {len(manning_minmax_df)} land cover types:\")\n",
        "print(manning_minmax_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions for Sensitivity Analysis\n",
        "\n",
        "The following functions support the sensitivity analysis workflow by:\n",
        "1. **Analyzing land cover statistics** in the 2D mesh\n",
        "2. **Generating test values** at specified intervals\n",
        "3. **Estimating plan counts** to avoid exceeding HEC-RAS limits\n",
        "\n",
        "These utilities are used by both base and regional override sensitivity functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_mesh_land_cover_statistics(project_folder, geom_number=None, plan_number=None):\n",
        "    \"\"\"\n",
        "    Analyze the land cover statistics for a 2D mesh area in a HEC-RAS model,\n",
        "    excluding areas controlled by regional Manning's n overrides.\n",
        "    \n",
        "    Args:\n",
        "        project_folder (str): Path to the HEC-RAS project folder\n",
        "        geom_number (str, optional): Geometry number to use. If None, will use\n",
        "                                    geometry from plan_number or the first geometry.\n",
        "        plan_number (str, optional): Plan number to use. If None, will use the first plan.\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with land cover statistics for areas controlled by base overrides\n",
        "    \"\"\"\n",
        "    # Initialize RAS project\n",
        "    ras = init_ras_project(project_folder, \"6.6\")\n",
        "        \n",
        "    # Get the geometry file path\n",
        "    geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number, 'full_path'].values[0]\n",
        "    \n",
        "    # Get the geometry HDF path\n",
        "    geom_hdf_path = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n",
        "    \n",
        "    # Get mesh areas from the geometry\n",
        "    mesh_areas_gdf = HdfMesh.get_mesh_areas(geom_hdf_path)\n",
        "    num_mesh_areas = len(mesh_areas_gdf)\n",
        "    \n",
        "    # Get the base Manning's overrides to compare with land cover statistics\n",
        "    base_overrides = RasGeo.get_mannings_baseoverrides(geom_path)\n",
        "    \n",
        "    # Get regional override information\n",
        "    region_overrides = RasGeo.get_mannings_regionoverrides(geom_path)\n",
        "    regional_mask = None\n",
        "    \n",
        "    # If regional overrides exist, get their geometries to exclude them\n",
        "    if not region_overrides.empty:\n",
        "        print(\"Regional Manning's n overrides found - these areas will be excluded from base sensitivity analysis\")\n",
        "        # Get regional override polygons from the geometry\n",
        "        regional_polygons_gdf = get_regional_override_polygons(geom_hdf_path)\n",
        "        \n",
        "        if not regional_polygons_gdf.empty:\n",
        "            # Create a union of all regional override polygons to use as a mask\n",
        "            regional_mask = regional_polygons_gdf.unary_union\n",
        "            print(f\"Excluding {len(regional_polygons_gdf)} regional override areas from analysis\")\n",
        "    \n",
        "    all_results = {}\n",
        "    \n",
        "    for idx, row in mesh_areas_gdf.iterrows():\n",
        "        mesh_name = row['mesh_name']\n",
        "        mesh_geom = row['geometry']\n",
        "        \n",
        "        print(f\"Analyzing land cover for mesh area: {mesh_name}\")\n",
        "        \n",
        "        # Get effective mesh area (excluding regional overrides)\n",
        "        effective_mesh_geom = mesh_geom\n",
        "        if regional_mask is not None:\n",
        "            if mesh_geom.intersects(regional_mask):\n",
        "                effective_mesh_geom = mesh_geom.difference(regional_mask)\n",
        "                print(f\"  Excluded regional override areas from mesh {mesh_name}\")\n",
        "        \n",
        "        total_area = effective_mesh_geom.area\n",
        "        \n",
        "        # Create a simulated land cover distribution based on base_overrides\n",
        "        # In reality, you would use actual spatial analysis with the land cover raster\n",
        "        landcover_stats = []\n",
        "        \n",
        "        # Use the land cover types from the base overrides\n",
        "        for _, override_row in base_overrides.iterrows():\n",
        "            land_cover = override_row['Land Cover Name']\n",
        "            n_value = override_row[\"Base Manning's n Value\"]\n",
        "            \n",
        "            # Generate a random percentage for this example\n",
        "            # In reality, this would come from actual spatial analysis\n",
        "            np.random.seed(hash(land_cover) % 2**32)  # Use the land cover name as a seed\n",
        "            percentage = np.random.random() * 25  # Random percentage between 0-25%\n",
        "            \n",
        "            area = total_area * (percentage / 100)\n",
        "            \n",
        "            landcover_stats.append({\n",
        "                'Land Cover Type': land_cover,\n",
        "                'Area': area,\n",
        "                'Percentage': percentage,\n",
        "                'Current_n': n_value\n",
        "            })\n",
        "        \n",
        "        # Create DataFrame and sort by percentage\n",
        "        landcover_df = pd.DataFrame(landcover_stats)\n",
        "        landcover_df = landcover_df.sort_values('Percentage', ascending=False).reset_index(drop=True)\n",
        "        \n",
        "        # Store the results\n",
        "        all_results[mesh_name] = landcover_df\n",
        "    \n",
        "    # If there's only one mesh area, return its dataframe directly\n",
        "    if len(all_results) == 1:\n",
        "        return next(iter(all_results.values()))\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "def get_regional_override_polygons(geom_hdf_path):\n",
        "    \"\"\"\n",
        "    Extract regional override polygon geometries from a HEC-RAS geometry HDF file.\n",
        "    \n",
        "    Args:\n",
        "        geom_hdf_path (str): Path to the HEC-RAS geometry HDF file\n",
        "        \n",
        "    Returns:\n",
        "        geopandas.GeoDataFrame: GeoDataFrame with regional override polygons\n",
        "    \"\"\"\n",
        "    import h5py\n",
        "    import geopandas as gpd\n",
        "    from shapely.geometry import Polygon\n",
        "    \n",
        "    try:\n",
        "        with h5py.File(geom_hdf_path, 'r') as f:\n",
        "            # Navigate to regional override polygons in the HDF structure\n",
        "            # This path would need to be determined based on the HEC-RAS HDF structure\n",
        "            if 'Geometry/Regional Manning Areas' in f:\n",
        "                region_group = f['Geometry/Regional Manning Areas']\n",
        "                \n",
        "                polygons = []\n",
        "                region_names = []\n",
        "                \n",
        "                # Process each regional override polygon\n",
        "                for region_name, region_data in region_group.items():\n",
        "                    # Extract polygon coordinates\n",
        "                    # This is a simplified example; actual implementation would depend on HDF structure\n",
        "                    if 'Polygon' in region_data:\n",
        "                        coords = region_data['Polygon'][:]\n",
        "                        polygon = Polygon(coords)\n",
        "                        polygons.append(polygon)\n",
        "                        region_names.append(region_name)\n",
        "                \n",
        "                # Create GeoDataFrame\n",
        "                if polygons:\n",
        "                    gdf = gpd.GeoDataFrame(\n",
        "                        {'region_name': region_names, 'geometry': polygons},\n",
        "                        crs='EPSG:4326'  # Set appropriate CRS\n",
        "                    )\n",
        "                    return gdf\n",
        "        \n",
        "        # Return empty GeoDataFrame if no regional overrides found\n",
        "        return gpd.GeoDataFrame(columns=['region_name', 'geometry'])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting regional override polygons: {str(e)}\")\n",
        "        return gpd.GeoDataFrame(columns=['region_name', 'geometry'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_sensitivity_values(min_val, max_val, current_val, interval=0.01):\n",
        "    \"\"\"\n",
        "    Generate a list of Manning's n values for sensitivity testing.\n",
        "    \n",
        "    Args:\n",
        "        min_val (float): Minimum value from literature\n",
        "        max_val (float): Maximum value from literature\n",
        "        current_val (float): Current value in the model\n",
        "        interval (float): Interval between test values\n",
        "    \n",
        "    Returns:\n",
        "        list: List of n values to test\n",
        "    \"\"\"\n",
        "    # Round values to avoid floating point issues\n",
        "    min_val = round(min_val, 4)\n",
        "    max_val = round(max_val, 4)\n",
        "    current_val = round(current_val, 4)\n",
        "    interval = round(interval, 4)\n",
        "    \n",
        "    # Generate values from min to max at specified interval\n",
        "    all_values = np.arange(min_val, max_val + interval/2, interval)\n",
        "    all_values = np.round(all_values, 4)  # Round to avoid floating point issues\n",
        "    \n",
        "    # Remove current value if it's in the range\n",
        "    values = [val for val in all_values if abs(val - current_val) > interval/2]\n",
        "    \n",
        "    # Make sure current value is not in the list\n",
        "    if current_val in values:\n",
        "        values.remove(current_val)\n",
        "    \n",
        "    return values\n",
        "\n",
        "def estimate_plan_count(significant_landuses, n_ranges, interval=0.01):\n",
        "    \"\"\"\n",
        "    Estimate the number of plans that will be created for sensitivity analysis.\n",
        "    \n",
        "    Args:\n",
        "        significant_landuses (pd.DataFrame): DataFrame with significant land cover types\n",
        "        n_ranges (pd.DataFrame): DataFrame with Manning's n ranges\n",
        "        interval (float): Interval between test values\n",
        "    \n",
        "    Returns:\n",
        "        int: Estimated number of plans\n",
        "    \"\"\"\n",
        "    total_plans = 0\n",
        "    \n",
        "    for _, landuse in significant_landuses.iterrows():\n",
        "        land_cover = landuse['Land Cover Type']\n",
        "        current_n = landuse['Current_n']\n",
        "        \n",
        "        # Find matching land cover in n_ranges\n",
        "        match = n_ranges[n_ranges['Land Cover Name'] == land_cover]\n",
        "        if match.empty:\n",
        "            continue\n",
        "            \n",
        "        min_n = match['min_n'].values[0]\n",
        "        max_n = match['max_n'].values[0]\n",
        "        \n",
        "        # Count values between min and max at interval spacing, excluding current value\n",
        "        values = generate_sensitivity_values(min_n, max_n, current_n, interval)\n",
        "        total_plans += len(values)\n",
        "    \n",
        "    return total_plans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_mesh_land_cover_statistics(project_folder, geom_number=None, plan_number=None):\n",
        "    \"\"\"\n",
        "    Analyze the land cover statistics for a 2D mesh area in a HEC-RAS model,\n",
        "    excluding areas controlled by regional Manning's n overrides.\n",
        "    \n",
        "    Args:\n",
        "        project_folder (str): Path to the HEC-RAS project folder\n",
        "        geom_number (str, optional): Geometry number to use. If None, will use\n",
        "                                    geometry from plan_number or the first geometry.\n",
        "        plan_number (str, optional): Plan number to use. If None, will use the first plan.\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with land cover statistics for areas controlled by base overrides\n",
        "    \"\"\"\n",
        "    # Initialize RAS project\n",
        "    ras = init_ras_project(project_folder, \"6.6\")\n",
        "    \n",
        "    # [existing code to get geometry number and paths]\n",
        "    \n",
        "    # Get the geometry file path\n",
        "    geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number, 'full_path'].values[0]\n",
        "    \n",
        "    # Get the geometry HDF path\n",
        "    geom_hdf_path = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n",
        "    \n",
        "    # Get mesh areas from the geometry\n",
        "    mesh_areas_gdf = HdfMesh.get_mesh_areas(geom_hdf_path)\n",
        "    num_mesh_areas = len(mesh_areas_gdf)\n",
        "    \n",
        "    # Get the base Manning's overrides to compare with land cover statistics\n",
        "    base_overrides = RasGeo.get_mannings_baseoverrides(geom_path)\n",
        "    \n",
        "    # Get regional override information\n",
        "    region_overrides = RasGeo.get_mannings_regionoverrides(geom_path)\n",
        "    regional_mask = None\n",
        "    \n",
        "    # If regional overrides exist, get their geometries to exclude them\n",
        "    if not region_overrides.empty:\n",
        "        print(\"Regional Manning's n overrides found - these areas will be excluded from base sensitivity analysis\")\n",
        "        # Get regional override polygons from the geometry\n",
        "        regional_polygons_gdf = get_regional_override_polygons(geom_hdf_path)\n",
        "        \n",
        "        if not regional_polygons_gdf.empty:\n",
        "            # Create a union of all regional override polygons to use as a mask\n",
        "            regional_mask = regional_polygons_gdf.unary_union\n",
        "            print(f\"Excluding {len(regional_polygons_gdf)} regional override areas from analysis\")\n",
        "    \n",
        "    all_results = {}\n",
        "    \n",
        "    for idx, row in mesh_areas_gdf.iterrows():\n",
        "        mesh_name = row['mesh_name']\n",
        "        mesh_geom = row['geometry']\n",
        "        \n",
        "        print(f\"Analyzing land cover for mesh area: {mesh_name}\")\n",
        "        \n",
        "        # Get effective mesh area (excluding regional overrides)\n",
        "        effective_mesh_geom = mesh_geom\n",
        "        if regional_mask is not None:\n",
        "            if mesh_geom.intersects(regional_mask):\n",
        "                effective_mesh_geom = mesh_geom.difference(regional_mask)\n",
        "                print(f\"  Excluded regional override areas from mesh {mesh_name}\")\n",
        "        \n",
        "        total_area = effective_mesh_geom.area\n",
        "        \n",
        "        # Create a simulated land cover distribution based on base_overrides\n",
        "        # In reality, you would use actual spatial analysis with the land cover raster\n",
        "        landcover_stats = []\n",
        "        \n",
        "        # Use the land cover types from the base overrides\n",
        "        for _, override_row in base_overrides.iterrows():\n",
        "            land_cover = override_row['Land Cover Name']\n",
        "            n_value = override_row[\"Base Mannings n Value\"]\n",
        "            \n",
        "            # Generate a random percentage for this example\n",
        "            # In reality, this would come from actual spatial analysis\n",
        "            np.random.seed(hash(land_cover) % 2**32)  # Use the land cover name as a seed\n",
        "            percentage = np.random.random() * 25  # Random percentage between 0-25%\n",
        "            \n",
        "            area = total_area * (percentage / 100)\n",
        "            \n",
        "            landcover_stats.append({\n",
        "                'Land Cover Type': land_cover,\n",
        "                'Area': area,\n",
        "                'Percentage': percentage,\n",
        "                'Current_n': n_value\n",
        "            })\n",
        "        \n",
        "        # Create DataFrame and sort by percentage\n",
        "        landcover_df = pd.DataFrame(landcover_stats)\n",
        "        landcover_df = landcover_df.sort_values('Percentage', ascending=False).reset_index(drop=True)\n",
        "        \n",
        "        # Store the results\n",
        "        all_results[mesh_name] = landcover_df\n",
        "    \n",
        "    # If there's only one mesh area, return its dataframe directly\n",
        "    if len(all_results) == 1:\n",
        "        return next(iter(all_results.values()))\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "def get_regional_override_polygons(geom_hdf_path):\n",
        "    \"\"\"\n",
        "    Extract regional override polygon geometries from a HEC-RAS geometry HDF file.\n",
        "    \n",
        "    Args:\n",
        "        geom_hdf_path (str): Path to the HEC-RAS geometry HDF file\n",
        "        \n",
        "    Returns:\n",
        "        geopandas.GeoDataFrame: GeoDataFrame with regional override polygons\n",
        "    \"\"\"\n",
        "    import h5py\n",
        "    import geopandas as gpd\n",
        "    from shapely.geometry import Polygon\n",
        "    \n",
        "    try:\n",
        "        with h5py.File(geom_hdf_path, 'r') as f:\n",
        "            # Navigate to regional override polygons in the HDF structure\n",
        "            # This path would need to be determined based on the HEC-RAS HDF structure\n",
        "            if 'Geometry/Regional Manning Areas' in f:\n",
        "                region_group = f['Geometry/Regional Manning Areas']\n",
        "                \n",
        "                polygons = []\n",
        "                region_names = []\n",
        "                \n",
        "                # Process each regional override polygon\n",
        "                for region_name, region_data in region_group.items():\n",
        "                    # Extract polygon coordinates\n",
        "                    # This is a simplified example; actual implementation would depend on HDF structure\n",
        "                    if 'Polygon' in region_data:\n",
        "                        coords = region_data['Polygon'][:]\n",
        "                        polygon = Polygon(coords)\n",
        "                        polygons.append(polygon)\n",
        "                        region_names.append(region_name)\n",
        "                \n",
        "                # Create GeoDataFrame\n",
        "                if polygons:\n",
        "                    gdf = gpd.GeoDataFrame(\n",
        "                        {'region_name': region_names, 'geometry': polygons},\n",
        "                        crs='EPSG:4326'  # Set appropriate CRS\n",
        "                    )\n",
        "                    return gdf\n",
        "        \n",
        "        # Return empty GeoDataFrame if no regional overrides found\n",
        "        return gpd.GeoDataFrame(columns=['region_name', 'geometry'])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting regional override polygons: {str(e)}\")\n",
        "        return gpd.GeoDataFrame(columns=['region_name', 'geometry'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Base Override Sensitivity Analysis\n",
        "\n",
        "## Overview\n",
        "\n",
        "Base override sensitivity analysis varies Manning's n values for individual land cover types across the entire 2D mesh area. This approach is appropriate when:\n",
        "- Evaluating the impact of global land cover roughness changes\n",
        "- Calibrating models with uniform land cover distributions\n",
        "- Assessing which land cover types have the greatest influence on results\n",
        "\n",
        "The analysis automatically:\n",
        "1. Identifies land covers exceeding the area coverage threshold\n",
        "2. Generates test scenarios at specified intervals within literature ranges\n",
        "3. Executes plans in parallel\n",
        "4. Extracts results at a point of interest\n",
        "5. Creates sensitivity plots and time series comparisons\n",
        "\n",
        "## Function: individual_landuse_sensitivity_base()\n",
        "\n",
        "This function performs the complete base override sensitivity workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def individual_landuse_sensitivity_base(\n",
        "    project_folder,\n",
        "    template_plan,\n",
        "    point_of_interest,\n",
        "    area_threshold=10.0,  # percentage threshold for significant land uses\n",
        "    interval=0.01,\n",
        "    max_workers=2,\n",
        "    num_cores=2,\n",
        "    output_folder=\"Individual_Landuse_Sensitivity\",\n",
        "    n_ranges=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform sensitivity analysis by varying individual land use Manning's n values\n",
        "    in the base overrides.\n",
        "\n",
        "    Args:\n",
        "        project_folder (str): Path to HEC-RAS project folder\n",
        "        template_plan (str): Plan number to use as template\n",
        "        point_of_interest (tuple or Point): Coordinates for extracting results\n",
        "        area_threshold (float): Percentage threshold for significant land uses\n",
        "        interval (float): Interval for Manning's n test values\n",
        "        max_workers (int): Number of parallel workers\n",
        "        num_cores (int): Number of cores per worker\n",
        "        output_folder (str): Name of output folder\n",
        "        n_ranges (pd.DataFrame): DataFrame containing min/max Manning's n values.\n",
        "                                    Must contain columns: 'Land Cover Name', 'min_n', 'max_n'\n",
        "\n",
        "    Returns:\n",
        "        dict: Results of sensitivity analysis\n",
        "    \"\"\"\n",
        "    import time\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Convert point_of_interest to Point if not already\n",
        "    if not isinstance(point_of_interest, Point):\n",
        "        point_of_interest = Point(point_of_interest[0], point_of_interest[1])\n",
        "\n",
        "    # Verify n_ranges is provided\n",
        "    if n_ranges is None:\n",
        "        raise ValueError(\"n_ranges DataFrame must be provided\")\n",
        "\n",
        "    # Create timestamp for unique run identifier\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Initialize RAS project\n",
        "    print(f\"Initializing HEC-RAS project: {project_folder}\")\n",
        "    ras = init_ras_project(project_folder, \"6.6\")\n",
        "\n",
        "    # Create output directory\n",
        "    results_dir = Path(project_folder) / output_folder\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "    print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "    # Verify template plan exists\n",
        "    if template_plan not in ras.plan_df['plan_number'].values:\n",
        "        raise ValueError(f\"Template plan {template_plan} not found in project\")\n",
        "\n",
        "    # Get the geometry number for the template plan\n",
        "    template_geom = ras.plan_df.loc[ras.plan_df['plan_number'] == template_plan, 'geometry_number'].values[0]\n",
        "    print(f\"\\nTemplate plan: {template_plan} (Geometry: {template_geom})\")\n",
        "\n",
        "    # Get the geometry file path\n",
        "    geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == template_geom, 'full_path'].values[0]\n",
        "\n",
        "    # Get the original Manning's values\n",
        "    original_baseoverrides = RasGeo.get_mannings_baseoverrides(geom_path)\n",
        "    original_regionoverrides = RasGeo.get_mannings_regionoverrides(geom_path)\n",
        "\n",
        "    # Analyze land cover statistics for the 2D mesh areas\n",
        "    print(\"\\nAnalyzing land cover statistics for the 2D mesh areas...\")\n",
        "    landcover_stats = analyze_mesh_land_cover_statistics(\n",
        "        project_folder, \n",
        "        geom_number=template_geom\n",
        "    )\n",
        "\n",
        "    if landcover_stats is None:\n",
        "        raise ValueError(\"Could not analyze land cover statistics\")\n",
        "\n",
        "    # Identify significant land uses (above threshold)\n",
        "    significant_landuses = landcover_stats[landcover_stats['Percentage'] >= area_threshold].copy()\n",
        "    significant_landuses = significant_landuses.sort_values('Percentage', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    if len(significant_landuses) == 0:\n",
        "        print(f\"No land uses found with coverage above {area_threshold}% threshold\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nFound {len(significant_landuses)} significant land uses (>= {area_threshold}% coverage):\")\n",
        "    print(significant_landuses[['Land Cover Type', 'Percentage', 'Current_n']])\n",
        "\n",
        "    # Check if we'll exceed the plan limit\n",
        "    current_plan_count = len(ras.plan_df)\n",
        "    max_plans = 99  # HEC-RAS limit\n",
        "    remaining_plans = max_plans - current_plan_count\n",
        "\n",
        "    # Estimate the number of plans needed\n",
        "    estimated_plan_count = estimate_plan_count(significant_landuses, n_ranges, interval)\n",
        "\n",
        "    if estimated_plan_count > remaining_plans:\n",
        "        print(f\"\\nWARNING: This analysis would create approximately {estimated_plan_count} plans, but only {remaining_plans} more plans can be added (limit is 99)\")\n",
        "        print(\"Consider adjusting the following to reduce the number of plans:\")\n",
        "        print(f\"1. Increase the area threshold (currently {area_threshold}%)\")\n",
        "        print(f\"2. Increase the interval between test values (currently {interval})\")\n",
        "        print(f\"3. Reduce the min/max ranges for land uses\")\n",
        "        print(f\"4. Select fewer land uses to test\")\n",
        "\n",
        "        # Ask for confirmation to continue\n",
        "        response = input(\"\\nDo you want to continue anyway? (y/n): \")\n",
        "        if response.lower() != 'y':\n",
        "            print(\"Analysis canceled\")\n",
        "            return None\n",
        "\n",
        "    # Store the current (template) plan as base scenario\n",
        "    scenarios = [{\n",
        "        'name': 'Template',\n",
        "        'plan_number': template_plan,\n",
        "        'geom_number': template_geom,\n",
        "        'shortid': 'Template',\n",
        "        'land_cover': None,\n",
        "        'n_value': None,\n",
        "        'description': \"Original Manning's n Values\"\n",
        "    }]\n",
        "\n",
        "    # Function to create a modified plan with adjusted Manning's values for a specific land use\n",
        "    def create_modified_plan(land_cover, new_n_value):\n",
        "        # Create a shortid based on land cover and n value\n",
        "        # Convert land cover name to code (e.g. \"Open Water\" -> \"OW\")\n",
        "        code = ''.join([word[0] for word in land_cover.split() if word[0].isalpha()])\n",
        "        if not code:\n",
        "            code = land_cover[:2]\n",
        "        code = code.upper()\n",
        "\n",
        "        # Format n value for shortid\n",
        "        n_str = f\"{new_n_value:.3f}\".replace(\".\", \"\")\n",
        "        shortid = f\"B_{code}_{n_str}\"\n",
        "\n",
        "        print(f\"\\nCreating plan for '{land_cover}' with n = {new_n_value} (ShortID: {shortid})\")\n",
        "\n",
        "        # Clone the template plan\n",
        "        new_plan_number = RasPlan.clone_plan(template_plan, new_plan_shortid=shortid)\n",
        "\n",
        "        # Clone the template geometry\n",
        "        new_geom_number = RasPlan.clone_geom(template_geom)\n",
        "\n",
        "        # Set the new plan to use the new geometry\n",
        "        RasPlan.set_geom(new_plan_number, new_geom_number)\n",
        "\n",
        "        # Get the new geometry file path\n",
        "        new_geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == new_geom_number, 'full_path'].values[0]\n",
        "\n",
        "        # Create modified base overrides\n",
        "        modified_baseoverrides = original_baseoverrides.copy()\n",
        "\n",
        "        # Update the Manning's n value for this specific land cover type\n",
        "        land_cover_mask = modified_baseoverrides['Land Cover Name'] == land_cover\n",
        "        if land_cover_mask.any():\n",
        "            current_n = modified_baseoverrides.loc[land_cover_mask, \"Base Mannings n Value\"].values[0]\n",
        "            print(f\"  Changing '{land_cover}' from {current_n:.4f} to {new_n_value:.4f}\")\n",
        "            modified_baseoverrides.loc[land_cover_mask, \"Base Mannings n Value\"] = new_n_value\n",
        "        else:\n",
        "            print(f\"  Warning: Land cover '{land_cover}' not found in base overrides\")\n",
        "\n",
        "        # Apply the modified base overrides\n",
        "        RasGeo.set_mannings_baseoverrides(new_geom_path, modified_baseoverrides)\n",
        "\n",
        "        # Copy regional overrides unchanged if they exist\n",
        "        if not original_regionoverrides.empty:\n",
        "            RasGeo.set_mannings_regionoverrides(new_geom_path, original_regionoverrides)\n",
        "\n",
        "        # Store scenario details\n",
        "        return {\n",
        "            'name': f\"{land_cover}_{new_n_value:.3f}\",\n",
        "            'plan_number': new_plan_number,\n",
        "            'geom_number': new_geom_number,\n",
        "            'shortid': shortid,\n",
        "            'land_cover': land_cover,\n",
        "            'n_value': new_n_value,\n",
        "            'description': f\"Manning's n = {new_n_value:.3f} for {land_cover}\"\n",
        "        }\n",
        "\n",
        "    # Create plans for each significant land use with varying n values\n",
        "    all_plans_to_run = []\n",
        "\n",
        "    for _, landuse in significant_landuses.iterrows():\n",
        "        land_cover = landuse['Land Cover Type']\n",
        "        current_n = landuse['Current_n']\n",
        "\n",
        "        # Find matching land cover in n_ranges\n",
        "        match = n_ranges[n_ranges['Land Cover Name'] == land_cover]\n",
        "\n",
        "        if match.empty:\n",
        "            print(f\"Warning: No Manning's n range found for '{land_cover}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        min_n = match['min_n'].values[0]\n",
        "        max_n = match['max_n'].values[0]\n",
        "\n",
        "        print(f\"\\nProcessing land cover: {land_cover}\")\n",
        "        print(f\"  Current n: {current_n:.4f}\")\n",
        "        print(f\"  Literature range: {min_n:.4f} to {max_n:.4f}\")\n",
        "\n",
        "        # Generate test values within the range, excluding the current value\n",
        "        test_values = generate_sensitivity_values(min_n, max_n, current_n, interval)\n",
        "\n",
        "        print(f\"  Testing {len(test_values)} values: {[round(val, 3) for val in test_values]}\")\n",
        "\n",
        "        # Create a plan for each test value\n",
        "        for n_value in test_values:\n",
        "            new_scenario = create_modified_plan(land_cover, n_value)\n",
        "            scenarios.append(new_scenario)\n",
        "            all_plans_to_run.append(new_scenario['plan_number'])\n",
        "\n",
        "    # Save scenario information\n",
        "    scenario_info = pd.DataFrame(scenarios)\n",
        "    scenario_info_path = results_dir / \"scenarios.csv\"\n",
        "    scenario_info.to_csv(scenario_info_path, index=False)\n",
        "    print(f\"\\nScenario information saved to: {scenario_info_path}\")\n",
        "\n",
        "    # Run the plans (excluding the template which is already computed)\n",
        "    plans_to_run = [plan for plan in all_plans_to_run if plan != template_plan]\n",
        "\n",
        "    if not plans_to_run:\n",
        "        print(\"No plans to run.\")\n",
        "        return {'scenarios': scenarios, 'output_folder': results_dir}\n",
        "\n",
        "    print(f\"\\nRunning {len(plans_to_run)} plans in parallel...\")\n",
        "    execution_results = RasCmdr.compute_parallel(\n",
        "        plan_number=plans_to_run,\n",
        "        max_workers=max_workers,\n",
        "        num_cores=num_cores,\n",
        "        clear_geompre=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nExecution results:\")\n",
        "    for plan, success in execution_results.items():\n",
        "        print(f\"  Plan {plan}: {'Successful' if success else 'Failed'}\")\n",
        "\n",
        "    # If point of interest provided, extract and compare results\n",
        "    if point_of_interest is not None:\n",
        "        # Get geometry HDF path for cell identification\n",
        "        geom_hdf_path = ras.geom_df.loc[ras.geom_df['geom_number'] == template_geom, 'hdf_path'].values[0]\n",
        "\n",
        "        # Find the nearest mesh cell\n",
        "        mesh_cells_gdf = HdfMesh.get_mesh_cell_points(geom_hdf_path)\n",
        "        distances = mesh_cells_gdf.geometry.apply(lambda geom: geom.distance(point_of_interest))\n",
        "        nearest_idx = distances.idxmin()\n",
        "        mesh_cell_id = mesh_cells_gdf.loc[nearest_idx, 'cell_id']\n",
        "        mesh_name = mesh_cells_gdf.loc[nearest_idx, 'mesh_name']\n",
        "\n",
        "        print(f\"\\nNearest cell ID: {mesh_cell_id}\")\n",
        "        print(f\"Distance: {distances[nearest_idx]:.2f} units\")\n",
        "        print(f\"Mesh area: {mesh_name}\")\n",
        "\n",
        "        # Extract results for each scenario\n",
        "        all_results = {}\n",
        "        max_ws_values = []\n",
        "\n",
        "        for scenario in scenarios:\n",
        "            plan_number = scenario['plan_number']\n",
        "            land_cover = scenario['land_cover']\n",
        "            n_value = scenario['n_value']\n",
        "            shortid = scenario['shortid']\n",
        "\n",
        "            try:\n",
        "                results_xr = HdfResultsMesh.get_mesh_cells_timeseries(plan_number)\n",
        "\n",
        "                # Extract water surface data\n",
        "                ws_data = results_xr[mesh_name]['Water Surface'].sel(cell_id=int(mesh_cell_id))\n",
        "\n",
        "                # Convert to DataFrame\n",
        "                ws_df = pd.DataFrame({\n",
        "                    'time': ws_data.time.values,\n",
        "                    'water_surface': ws_data.values\n",
        "                })\n",
        "\n",
        "                # Store results\n",
        "                max_ws = ws_df['water_surface'].max()\n",
        "\n",
        "                all_results[plan_number] = {\n",
        "                    'scenario': scenario,\n",
        "                    'df': ws_df,\n",
        "                    'max_water_surface': max_ws\n",
        "                }\n",
        "\n",
        "                max_ws_values.append({\n",
        "                    'plan_number': plan_number,\n",
        "                    'shortid': shortid,\n",
        "                    'land_cover': land_cover,\n",
        "                    'n_value': n_value,\n",
        "                    'max_water_surface': max_ws\n",
        "                })\n",
        "\n",
        "                print(f\"  {shortid}: Max WSE = {max_ws:.2f}\")\n",
        "\n",
        "                # Save time series to CSV\n",
        "                ws_df.to_csv(results_dir / f\"timeseries_{shortid}.csv\", index=False)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error extracting results for {shortid}: {str(e)}\")\n",
        "\n",
        "        # Create summary DataFrame\n",
        "        if max_ws_values:\n",
        "            max_ws_df = pd.DataFrame(max_ws_values)\n",
        "            max_ws_df.to_csv(results_dir / \"max_water_surface_summary.csv\", index=False)\n",
        "\n",
        "            # Prepare mapping of land cover -> percentage (from significant_landuses)\n",
        "            lc_percentage_dict = dict(zip(significant_landuses['Land Cover Type'], significant_landuses['Percentage']))\n",
        "\n",
        "            # Create plots by land cover type\n",
        "            for land_cover in significant_landuses['Land Cover Type']:\n",
        "                # Filter scenarios for this land cover\n",
        "                land_cover_scenarios = max_ws_df[max_ws_df['land_cover'] == land_cover].copy()\n",
        "\n",
        "                # Add the template scenario\n",
        "                template_row = max_ws_df[max_ws_df['shortid'] == 'Template']\n",
        "                if not template_row.empty:\n",
        "                    land_cover_scenarios = pd.concat([template_row, land_cover_scenarios])\n",
        "\n",
        "                if land_cover_scenarios.empty:\n",
        "                    continue\n",
        "\n",
        "                # Sort by n_value\n",
        "                land_cover_scenarios = land_cover_scenarios.sort_values('n_value').reset_index(drop=True)\n",
        "\n",
        "                # Add coverage percentage string to label\n",
        "                perc = lc_percentage_dict.get(land_cover, None)\n",
        "                if perc is not None:\n",
        "                    perc_str = f\" ({perc:.1f}% coverage)\"\n",
        "                else:\n",
        "                    perc_str = \"\"\n",
        "\n",
        "                # Create plot\n",
        "                fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                ax.plot(land_cover_scenarios['n_value'], land_cover_scenarios['max_water_surface'], \n",
        "                         marker='o', linestyle='-', linewidth=2)\n",
        "\n",
        "                # Add template point in a different color if it exists\n",
        "                template_idx = land_cover_scenarios[land_cover_scenarios['shortid'] == 'Template'].index\n",
        "                if not template_idx.empty:\n",
        "                    ax.scatter(land_cover_scenarios.loc[template_idx, 'n_value'], \n",
        "                                land_cover_scenarios.loc[template_idx, 'max_water_surface'],\n",
        "                                color='red', s=100, zorder=5, label='Template')\n",
        "\n",
        "                # Add labels and title, showing percentage of coverage\n",
        "                ax.set_xlabel(f\"Manning's n for {land_cover}{perc_str}\")\n",
        "                ax.set_ylabel(\"Maximum Water Surface Elevation (ft)\")\n",
        "                ax.set_title(f\"Sensitivity to {land_cover}{perc_str} Manning's n Value\")\n",
        "                ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "                if not template_idx.empty:\n",
        "                    ax.legend()\n",
        "\n",
        "                # Save plot\n",
        "                plot_path = results_dir / f\"sensitivity_{land_cover.replace(' ', '_').replace('/', '_')}.png\"\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(plot_path)\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "                print(f\"Created sensitivity plot for {land_cover}\")\n",
        "\n",
        "            # Create time series comparison plot for each land cover\n",
        "            for land_cover in significant_landuses['Land Cover Type']:\n",
        "                fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "                # Add coverage percentage string to label\n",
        "                perc = lc_percentage_dict.get(land_cover, None)\n",
        "                if perc is not None:\n",
        "                    perc_str = f\" ({perc:.1f}% coverage)\"\n",
        "                else:\n",
        "                    perc_str = \"\"\n",
        "\n",
        "                # Get template results\n",
        "                template_plan = scenarios[0]['plan_number']\n",
        "                if template_plan in all_results:\n",
        "                    template_df = all_results[template_plan]['df']\n",
        "                    ax.plot(template_df['time'], template_df['water_surface'],\n",
        "                             color='black', linewidth=2, label='Template')\n",
        "\n",
        "                # Filter scenarios for this land cover and plot\n",
        "                land_cover_scenarios = [s for s in scenarios if s['land_cover'] == land_cover]\n",
        "\n",
        "                if not land_cover_scenarios:\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "                    continue\n",
        "\n",
        "                # Setup colormap for n values\n",
        "                n_values = [s['n_value'] for s in land_cover_scenarios if s['n_value'] is not None]\n",
        "                if not n_values:\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "                    continue\n",
        "\n",
        "                min_n = min(n_values)\n",
        "                max_n = max(n_values)\n",
        "                norm = plt.Normalize(min_n, max_n)\n",
        "                cmap = plt.cm.viridis\n",
        "\n",
        "                # Plot each scenario with explicit legend entries, showing label with percentage\n",
        "                for scenario in land_cover_scenarios:\n",
        "                    plan_number = scenario['plan_number']\n",
        "                    n_value = scenario['n_value']\n",
        "                    if plan_number in all_results and n_value is not None:\n",
        "                        df = all_results[plan_number]['df']\n",
        "                        color = cmap(norm(n_value))\n",
        "                        label = f\"{land_cover}{perc_str}: n = {n_value:.3f}\"\n",
        "                        ax.plot(df['time'], df['water_surface'], color=color, \n",
        "                                 linewidth=1, alpha=0.7, label=label)\n",
        "\n",
        "                # Add labels and title, showing percentage of coverage\n",
        "                ax.set_xlabel(\"Time\")\n",
        "                ax.set_ylabel(\"Water Surface Elevation (ft)\")\n",
        "                ax.set_title(f\"WSE Time Series for Different {land_cover}{perc_str} Manning's n Values\")\n",
        "                ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "                # Add legend with land cover and n values\n",
        "                ax.legend(loc='best', fontsize='small', title=\"Scenarios\")\n",
        "\n",
        "                # Add colorbar\n",
        "                sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "                sm.set_array([])\n",
        "                plt.colorbar(sm, ax=ax).set_label(f\"Manning's n for {land_cover}{perc_str}\")\n",
        "\n",
        "                # Save plot\n",
        "                plot_path = results_dir / f\"timeseries_{land_cover.replace(' ', '_').replace('/', '_')}.png\"\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(plot_path)\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "                print(f\"Created time series plot for {land_cover}\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'scenarios': scenarios,\n",
        "        'execution_results': execution_results if 'execution_results' in locals() else None,\n",
        "        'results': all_results if 'all_results' in locals() else None,\n",
        "        'max_ws_summary': max_ws_df if 'max_ws_df' in locals() else None,\n",
        "        'significant_landuses': significant_landuses,\n",
        "        'output_folder': results_dir\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executing Base Override Sensitivity Analysis\n",
        "\n",
        "### Configuration Parameters\n",
        "\n",
        "The following example demonstrates how to run the base override sensitivity analysis with the BaldEagleCrkMulti2D sample project.\n",
        "\n",
        "**Key Parameters:**\n",
        "- `project_folder`: Path to the HEC-RAS project\n",
        "- `template_plan`: Base plan number to clone for sensitivity tests\n",
        "- `point_of_interest`: Coordinates where results will be extracted (x, y)\n",
        "- `area_threshold`: Minimum percentage of mesh coverage for land use to be analyzed (default: 10%)\n",
        "- `interval`: Step size for Manning's n test values (default: 0.01)\n",
        "- `max_workers`: Number of parallel execution workers\n",
        "- `num_cores`: CPU cores per HEC-RAS instance\n",
        "- `output_folder`: Directory name for results\n",
        "\n",
        "### Execution Steps\n",
        "\n",
        "1. Extract the example project\n",
        "2. Configure analysis parameters\n",
        "3. Run the sensitivity analysis (creates plans, executes them, and generates plots)\n",
        "4. Review results in the output folder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Managing Plan Limits with Separate Project Folders\n",
        "\n",
        "**Why are we creating copies of the project folder?**\n",
        "\n",
        "HEC-RAS has a hard limit of 99 plans per project (.p01 to .p99). Sensitivity analyses, especially those testing multiple parameters at fine intervals, can easily generate dozens of plans.\n",
        "\n",
        "To avoid hitting this limit and to keep our analyses organized, we will:\n",
        "1.  **Extract** the base project once.\n",
        "2.  **Copy** it to a dedicated folder for **Base Override** sensitivity (suffix `_BOMIS`).\n",
        "3.  **Copy** it again to a dedicated folder for **Regional Override** sensitivity (suffix `_ROMIS`).\n",
        "\n",
        "This approach ensures that:\n",
        "*   Each analysis starts with a clean slate.\n",
        "*   We have a full 99-plan capacity for *each* type of sensitivity analysis.\n",
        "*   We don't accidentally overwrite or interfere with plans from the other analysis.\n",
        "*   The original extracted project remains a pristine backup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage for Base Overrides Sensitivity Analysis\n",
        "# To run this, uncomment the code, adjust parameters as needed, and execute the cell\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Extract the example project (the source)\n",
        "#    We extract to the default location first\n",
        "RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
        "source_project_folder = Path(os.getcwd()) / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "\n",
        "# 2. Create a specific folder for Base Override Multi-Interval Sensitivity (BOMIS)\n",
        "#    This prevents hitting the 99-plan limit by isolating this analysis\n",
        "project_folder = Path(os.getcwd()) / \"example_projects\" / \"BaldEagleCrkMulti2D_BOMIS\"\n",
        "\n",
        "# Clean up if it already exists to ensure a fresh start\n",
        "if project_folder.exists():\n",
        "    shutil.rmtree(project_folder)\n",
        "\n",
        "# Copy the fresh source project to the BOMIS folder\n",
        "print(f\"Creating dedicated BOMIS project folder...\")\n",
        "shutil.copytree(source_project_folder, project_folder)\n",
        "print(f\"Created: {project_folder}\")\n",
        "\n",
        "# 3. Initialize the BOMIS project\n",
        "#    (This updates the global 'ras' object to point to this new folder)\n",
        "init_ras_project(project_folder, \"6.6\")\n",
        "\n",
        "# Define parameters\n",
        "template_plan = \"03\"  # Use plan 03 as the template\n",
        "point_of_interest = (2076402, 366670)  # Coordinates where you want to extract results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Run the base sensitivity analysis\n",
        "base_sensitivity_results = individual_landuse_sensitivity_base(\n",
        "    project_folder=project_folder,\n",
        "    template_plan=template_plan,\n",
        "    point_of_interest=point_of_interest,\n",
        "    area_threshold=15.0,  # Only analyze land uses covering at least 10% of the mesh area\n",
        "    interval=0.02,       # Adjust interval to reduce the number of test values\n",
        "    max_workers=4,\n",
        "    num_cores=2,\n",
        "    output_folder=\"Base_Landuse_Sensitivity\",\n",
        "    n_ranges=manning_minmax_df\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Print summary information\n",
        "if base_sensitivity_results:\n",
        "    print(\"\\nAnalysis complete! Results saved to:\", base_sensitivity_results['output_folder'])\n",
        "    if 'significant_landuses' in base_sensitivity_results:\n",
        "        print(\"\\nSignificant land uses analyzed:\")\n",
        "        print(base_sensitivity_results['significant_landuses'][['Land Cover Type', 'Percentage']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base Override Sensitivity Results\n",
        "\n",
        "### Interpreting the Results\n",
        "\n",
        "The following plots show sensitivity analysis results from the BaldEagleCrkMulti2D example project (Plan 03):\n",
        "\n",
        "**Sensitivity Plots (Right):**\n",
        "- Show how maximum water surface elevation varies with Manning's n\n",
        "- X-axis: Manning's n value for the specific land cover type\n",
        "- Y-axis: Maximum water surface elevation at the point of interest\n",
        "- Red dot: Current/template Manning's n value\n",
        "- Steeper slopes indicate higher sensitivity to that parameter\n",
        "\n",
        "**Time Series Plots (Left):**\n",
        "- Show complete hydrographs for all Manning's n scenarios\n",
        "- Color gradient represents different Manning's n values\n",
        "- Black line: Template (original) scenario\n",
        "- Useful for understanding how timing and peak magnitude respond to parameter changes\n",
        "\n",
        "**Key Observations to Look For:**\n",
        "- Which land covers cause the largest changes in water surface elevation?\n",
        "- Are the responses linear or non-linear?\n",
        "- Does increasing roughness always increase water levels (as expected)?\n",
        "- Are there threshold effects or inflection points?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: Regional Override Sensitivity Analysis\n",
        "\n",
        "## Overview\n",
        "\n",
        "Regional override sensitivity analysis focuses on Manning's n variations within specific calibration regions of the model. This approach is appropriate when:\n",
        "- Calibrating main channel roughness separately from floodplain\n",
        "- Analyzing the impact of localized land cover changes\n",
        "- Testing region-specific parameter uncertainty\n",
        "- Evaluating different roughness values in distinct hydraulic zones\n",
        "\n",
        "**Key Differences from Base Sensitivity:**\n",
        "- Tests only land covers present in the specified region(s)\n",
        "- Can target a single region or analyze all regions\n",
        "- Useful for main channel calibration or localized sensitivity testing\n",
        "- Regional overrides take precedence over base mesh values in HEC-RAS\n",
        "\n",
        "## Function: individual_landuse_sensitivity_region()\n",
        "\n",
        "This function performs the complete regional override sensitivity workflow with region-specific filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def individual_landuse_sensitivity_region(\n",
        "    project_folder,\n",
        "    template_plan,\n",
        "    point_of_interest,\n",
        "    area_threshold=10.0,  # percentage threshold for significant land uses\n",
        "    interval=0.01,\n",
        "    max_workers=2,\n",
        "    num_cores=2,\n",
        "    region_name=None,  # optional specific region to analyze\n",
        "    output_folder=\"Regional_Landuse_Sensitivity\",\n",
        "    n_ranges=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform sensitivity analysis by varying individual land use Manning's n values\n",
        "    in the regional overrides.\n",
        "    \n",
        "    Args:\n",
        "        project_folder (str): Path to HEC-RAS project folder\n",
        "        template_plan (str): Plan number to use as template\n",
        "        point_of_interest (tuple or Point): Coordinates for extracting results\n",
        "        area_threshold (float): Percentage threshold for significant land uses\n",
        "        interval (float): Interval for Manning's n test values\n",
        "        max_workers (int): Number of parallel workers\n",
        "        num_cores (int): Number of cores per worker\n",
        "        region_name (str): Optional specific region to analyze\n",
        "        output_folder (str): Name of output folder\n",
        "        n_ranges (pd.DataFrame): DataFrame containing min/max Manning's n values.\n",
        "                                    Must contain columns: 'Land Cover Name', 'min_n', 'max_n'\n",
        "    \n",
        "    Returns:\n",
        "        dict: Results of sensitivity analysis\n",
        "    \"\"\"\n",
        "    import time\n",
        "    from datetime import datetime\n",
        "    \n",
        "    # Convert point_of_interest to Point if not already\n",
        "    if not isinstance(point_of_interest, Point):\n",
        "        point_of_interest = Point(point_of_interest[0], point_of_interest[1])\n",
        "    \n",
        "    # Verify n_ranges is provided\n",
        "    if n_ranges is None:\n",
        "        raise ValueError(\"n_ranges DataFrame must be provided\")\n",
        "    \n",
        "    # Create timestamp for unique run identifier\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Initialize RAS project\n",
        "    print(f\"Initializing HEC-RAS project: {project_folder}\")\n",
        "    ras = init_ras_project(project_folder, \"6.6\")\n",
        "    \n",
        "    # Create output directory\n",
        "    results_dir = Path(project_folder) / output_folder\n",
        "    results_dir.mkdir(exist_ok=True)\n",
        "    print(f\"Results will be saved to: {results_dir}\")\n",
        "    \n",
        "    # Verify template plan exists\n",
        "    if template_plan not in ras.plan_df['plan_number'].values:\n",
        "        raise ValueError(f\"Template plan {template_plan} not found in project\")\n",
        "    \n",
        "    # Get the geometry number for the template plan\n",
        "    template_geom = ras.plan_df.loc[ras.plan_df['plan_number'] == template_plan, 'geometry_number'].values[0]\n",
        "    print(f\"\\nTemplate plan: {template_plan} (Geometry: {template_geom})\")\n",
        "    \n",
        "    # Get the geometry file path\n",
        "    geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == template_geom, 'full_path'].values[0]\n",
        "    \n",
        "    # Get the original Manning's values\n",
        "    original_baseoverrides = RasGeo.get_mannings_baseoverrides(geom_path)\n",
        "    original_regionoverrides = RasGeo.get_mannings_regionoverrides(geom_path)\n",
        "    \n",
        "    # Check if regional overrides exist\n",
        "    if original_regionoverrides.empty:\n",
        "        print(\"No regional Manning's overrides found in the model\")\n",
        "        return None\n",
        "    \n",
        "    # If a specific region name is provided, filter the regional overrides\n",
        "    if region_name is not None:\n",
        "        region_mask = original_regionoverrides['Region Name'] == region_name\n",
        "        if not region_mask.any():\n",
        "            print(f\"Region '{region_name}' not found in the model\")\n",
        "            available_regions = original_regionoverrides['Region Name'].unique()\n",
        "            print(f\"Available regions: {available_regions}\")\n",
        "            return None\n",
        "        \n",
        "        region_overrides = original_regionoverrides[region_mask].copy()\n",
        "        print(f\"\\nAnalyzing sensitivity for region: {region_name}\")\n",
        "    else:\n",
        "        region_overrides = original_regionoverrides.copy()\n",
        "        print(\"\\nAnalyzing sensitivity for all regions\")\n",
        "    \n",
        "    # Get unique region tables\n",
        "    region_tables = region_overrides['Table Number'].unique()\n",
        "    print(f\"Region tables: {region_tables}\")\n",
        "    \n",
        "    # Analyze land cover statistics for the 2D mesh areas\n",
        "    print(\"\\nAnalyzing land cover statistics for the 2D mesh areas...\")\n",
        "    landcover_stats = analyze_mesh_land_cover_statistics(\n",
        "        project_folder, \n",
        "        geom_number=template_geom\n",
        "    )\n",
        "    \n",
        "    if landcover_stats is None:\n",
        "        raise ValueError(\"Could not analyze land cover statistics\")\n",
        "    \n",
        "    # Identify significant land uses (above threshold)\n",
        "    significant_landuses = landcover_stats[landcover_stats['Percentage'] >= area_threshold].copy()\n",
        "    significant_landuses = significant_landuses.sort_values('Percentage', ascending=False).reset_index(drop=True)\n",
        "    \n",
        "    if len(significant_landuses) == 0:\n",
        "        print(f\"No land uses found with coverage above {area_threshold}% threshold\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"\\nFound {len(significant_landuses)} significant land uses (>= {area_threshold}% coverage):\")\n",
        "    print(significant_landuses[['Land Cover Type', 'Percentage', 'Current_n']])\n",
        "    \n",
        "    # Filter significant land uses to only those present in the region overrides\n",
        "    region_landcover_types = set(region_overrides['Land Cover Name'].unique())\n",
        "    filtered_landuses = significant_landuses[\n",
        "        significant_landuses['Land Cover Type'].isin(region_landcover_types)\n",
        "    ].copy()\n",
        "    \n",
        "    if len(filtered_landuses) == 0:\n",
        "        print(\"None of the significant land uses are present in the regional overrides\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"\\nSignificant land uses present in regional overrides:\")\n",
        "    print(filtered_landuses[['Land Cover Type', 'Percentage']])\n",
        "    \n",
        "    # Check if we'll exceed the plan limit\n",
        "    current_plan_count = len(ras.plan_df)\n",
        "    max_plans = 99  # HEC-RAS limit\n",
        "    remaining_plans = max_plans - current_plan_count\n",
        "    \n",
        "    # Estimate the number of plans needed\n",
        "    estimated_plan_count = 0\n",
        "    \n",
        "    # Create a table to store land use sensitivity information\n",
        "    sensitivity_table = []\n",
        "    \n",
        "    for _, landuse in filtered_landuses.iterrows():\n",
        "        land_cover = landuse['Land Cover Type']\n",
        "        \n",
        "        # Find this land cover in the region overrides\n",
        "        for region_table in region_tables:\n",
        "            # Create mask for this land cover and table\n",
        "            mask = (region_overrides['Land Cover Name'] == land_cover) & \\\n",
        "                   (region_overrides['Table Number'] == region_table)\n",
        "            \n",
        "            if not mask.any():\n",
        "                continue\n",
        "                \n",
        "            current_n = region_overrides.loc[mask, 'MainChannel'].values[0]\n",
        "            \n",
        "            # Find matching land cover in n_ranges\n",
        "            match = n_ranges[n_ranges['Land Cover Name'] == land_cover]\n",
        "            if match.empty:\n",
        "                continue\n",
        "                \n",
        "            min_n = match['min_n'].values[0]\n",
        "            max_n = match['max_n'].values[0]\n",
        "            \n",
        "            # Count values between min and max at interval spacing, excluding current value\n",
        "            values = generate_sensitivity_values(min_n, max_n, current_n, interval)\n",
        "            num_values = len(values)\n",
        "            estimated_plan_count += num_values\n",
        "            \n",
        "            # Add to sensitivity table\n",
        "            region_name = region_overrides.loc[mask, 'Region Name'].values[0] if 'Region Name' in region_overrides.columns else f\"Table {region_table}\"\n",
        "            sensitivity_table.append({\n",
        "                'Land Cover': land_cover,\n",
        "                'Region': region_name,\n",
        "                'Table': region_table,\n",
        "                'Current n': current_n,\n",
        "                'Min n': min_n,\n",
        "                'Max n': max_n,\n",
        "                'Test Values': num_values,\n",
        "                'n Range': f\"{min_n:.3f} - {max_n:.3f}\"\n",
        "            })\n",
        "    \n",
        "    # Print the sensitivity analysis table\n",
        "    if sensitivity_table:\n",
        "        print(\"\\nSensitivity Analysis Plan:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(f\"{'Land Cover':<20} {'Region':<15} {'Current n':<10} {'n Range':<15} {'Test Values':<12}\")\n",
        "        print(\"-\" * 80)\n",
        "        for row in sensitivity_table:\n",
        "            print(f\"{row['Land Cover']:<20} {row['Region']:<15} {row['Current n']:<10.3f} {row['n Range']:<15} {row['Test Values']:<12}\")\n",
        "        print(\"-\" * 80)\n",
        "        print(f\"Total estimated plans to be created: {estimated_plan_count}\")\n",
        "        print(\"-\" * 80)\n",
        "    if estimated_plan_count > remaining_plans:\n",
        "        print(f\"\\nWARNING: This analysis would create approximately {estimated_plan_count} plans, but only {remaining_plans} more plans can be added (limit is 99)\")\n",
        "        print(\"Consider adjusting the following to reduce the number of plans:\")\n",
        "        print(f\"1. Increase the area threshold (currently {area_threshold}%)\")\n",
        "        print(f\"2. Increase the interval between test values (currently {interval})\")\n",
        "        print(f\"3. Reduce the min/max ranges for land uses\")\n",
        "        print(f\"4. Select fewer land uses to test\")\n",
        "        print(f\"5. Specify a single region to test (currently {'specific region' if region_name else 'all regions'})\")\n",
        "        \n",
        "        # Ask for confirmation to continue\n",
        "        response = input(\"\\nDo you want to continue anyway? (y/n): \")\n",
        "        if response.lower() != 'y':\n",
        "            print(\"Analysis canceled\")\n",
        "            return None\n",
        "    \n",
        "    # Store the current (template) plan as base scenario\n",
        "    scenarios = [{\n",
        "        'name': 'Template',\n",
        "        'plan_number': template_plan,\n",
        "        'geom_number': template_geom,\n",
        "        'shortid': 'Template',\n",
        "        'land_cover': None,\n",
        "        'region_name': None,\n",
        "        'table_number': None,\n",
        "        'n_value': None,\n",
        "        'description': \"Original Manning's n Values\"\n",
        "    }]\n",
        "    \n",
        "    # Function to create a modified plan with adjusted Manning's n values for a specific land use in a region\n",
        "    def create_modified_plan(land_cover, table_number, region_name, new_n_value):\n",
        "        # Create a shortid based on land cover, region, and n value\n",
        "        # Convert land cover name to code (e.g. \"Open Water\" -> \"OW\")\n",
        "        lc_code = ''.join([word[0] for word in land_cover.split() if word[0].isalpha()])\n",
        "        if not lc_code:\n",
        "            lc_code = land_cover[:2]\n",
        "        lc_code = lc_code.upper()\n",
        "        \n",
        "        # Convert region name to code\n",
        "        rg_code = ''.join([word[0] for word in region_name.split() if word[0].isalpha()])\n",
        "        if not rg_code:\n",
        "            rg_code = region_name[:2]\n",
        "        rg_code = rg_code.upper()\n",
        "        \n",
        "        # Format n value for shortid\n",
        "        n_str = f\"{new_n_value:.3f}\".replace(\".\", \"\")\n",
        "        shortid = f\"R_{lc_code}_{rg_code}_{n_str}\"\n",
        "        \n",
        "        print(f\"\\nCreating plan for '{land_cover}' in '{region_name}' with n = {new_n_value} (ShortID: {shortid})\")\n",
        "        \n",
        "        # Clone the template plan\n",
        "        new_plan_number = RasPlan.clone_plan(template_plan, new_plan_shortid=shortid)\n",
        "        \n",
        "        # Clone the template geometry\n",
        "        new_geom_number = RasPlan.clone_geom(template_geom)\n",
        "        \n",
        "        # Set the new plan to use the new geometry\n",
        "        RasPlan.set_geom(new_plan_number, new_geom_number)\n",
        "        \n",
        "        # Get the new geometry file path\n",
        "        new_geom_path = ras.geom_df.loc[ras.geom_df['geom_number'] == new_geom_number, 'full_path'].values[0]\n",
        "        \n",
        "        # Copy base overrides unchanged\n",
        "        RasGeo.set_mannings_baseoverrides(new_geom_path, original_baseoverrides)\n",
        "        \n",
        "        # Create modified region overrides\n",
        "        modified_regionoverrides = original_regionoverrides.copy()\n",
        "        \n",
        "        # Update the Manning's n value for this specific land cover type in this region and table\n",
        "        region_mask = (modified_regionoverrides['Land Cover Name'] == land_cover) & \\\n",
        "                     (modified_regionoverrides['Table Number'] == table_number) & \\\n",
        "                     (modified_regionoverrides['Region Name'] == region_name)\n",
        "                     \n",
        "        if region_mask.any():\n",
        "            current_n = modified_regionoverrides.loc[region_mask, 'MainChannel'].values[0]\n",
        "            print(f\"  Changing '{land_cover}' in '{region_name}' (Table {table_number}) from {current_n:.4f} to {new_n_value:.4f}\")\n",
        "            modified_regionoverrides.loc[region_mask, 'MainChannel'] = new_n_value\n",
        "        else:\n",
        "            print(f\"  Warning: Land cover '{land_cover}' not found in region '{region_name}' (Table {table_number})\")\n",
        "        \n",
        "        # Apply the modified region overrides\n",
        "        RasGeo.set_mannings_regionoverrides(new_geom_path, modified_regionoverrides)\n",
        "        \n",
        "        # Store scenario details\n",
        "        return {\n",
        "            'name': f\"{land_cover}_{region_name}_{new_n_value:.3f}\",\n",
        "            'plan_number': new_plan_number,\n",
        "            'geom_number': new_geom_number,\n",
        "            'shortid': shortid,\n",
        "            'land_cover': land_cover,\n",
        "            'region_name': region_name,\n",
        "            'table_number': table_number,\n",
        "            'n_value': new_n_value,\n",
        "            'description': f\"Manning's n = {new_n_value:.3f} for {land_cover} in {region_name}\"\n",
        "        }\n",
        "    \n",
        "    # Create plans for each significant land use with varying n values\n",
        "    all_plans_to_run = []\n",
        "    \n",
        "    for _, landuse in filtered_landuses.iterrows():\n",
        "        land_cover = landuse['Land Cover Type']\n",
        "        \n",
        "        # Find matching land cover in n_ranges\n",
        "        match = n_ranges[n_ranges['Land Cover Name'] == land_cover]\n",
        "        \n",
        "        if match.empty:\n",
        "            print(f\"Warning: No Manning's n range found for '{land_cover}'. Skipping.\")\n",
        "            continue\n",
        "            \n",
        "        min_n = match['min_n'].values[0]\n",
        "        max_n = match['max_n'].values[0]\n",
        "        \n",
        "        # Process each region table for this land cover\n",
        "        for region_table in region_tables:\n",
        "            # Get all regions with this land cover in this table\n",
        "            regions_mask = (region_overrides['Land Cover Name'] == land_cover) & \\\n",
        "                          (region_overrides['Table Number'] == region_table)\n",
        "            \n",
        "            if not regions_mask.any():\n",
        "                continue\n",
        "            \n",
        "            # Get unique region names for this land cover and table\n",
        "            unique_regions = region_overrides.loc[regions_mask, 'Region Name'].unique()\n",
        "            \n",
        "            for region in unique_regions:\n",
        "                # If a specific region was requested, skip others\n",
        "                if region_name is not None and region != region_name:\n",
        "                    continue\n",
        "                \n",
        "                # Create mask for this specific combination\n",
        "                specific_mask = (region_overrides['Land Cover Name'] == land_cover) & \\\n",
        "                               (region_overrides['Table Number'] == region_table) & \\\n",
        "                               (region_overrides['Region Name'] == region)\n",
        "                \n",
        "                if not specific_mask.any():\n",
        "                    continue\n",
        "                \n",
        "                current_n = region_overrides.loc[specific_mask, 'MainChannel'].values[0]\n",
        "                \n",
        "                print(f\"\\nProcessing land cover: {land_cover} in region: {region} (Table {region_table})\")\n",
        "                print(f\"  Current n: {current_n:.4f}\")\n",
        "                print(f\"  Literature range: {min_n:.4f} to {max_n:.4f}\")\n",
        "                \n",
        "                # Generate test values within the range, excluding the current value\n",
        "                test_values = generate_sensitivity_values(min_n, max_n, current_n, interval)\n",
        "                \n",
        "                print(f\"  Testing {len(test_values)} values: {[round(val, 3) for val in test_values]}\")\n",
        "                \n",
        "                # Create a plan for each test value\n",
        "                for n_value in test_values:\n",
        "                    new_scenario = create_modified_plan(land_cover, region_table, region, n_value)\n",
        "                    scenarios.append(new_scenario)\n",
        "                    all_plans_to_run.append(new_scenario['plan_number'])\n",
        "    \n",
        "    # Save scenario information\n",
        "    scenario_info = pd.DataFrame(scenarios)\n",
        "    scenario_info_path = results_dir / \"scenarios.csv\"\n",
        "    scenario_info.to_csv(scenario_info_path, index=False)\n",
        "    print(f\"\\nScenario information saved to: {scenario_info_path}\")\n",
        "    \n",
        "    # Run the plans (excluding the template which is already computed)\n",
        "    plans_to_run = [plan for plan in all_plans_to_run if plan != template_plan]\n",
        "    \n",
        "    if not plans_to_run:\n",
        "        print(\"No plans to run.\")\n",
        "        return {'scenarios': scenarios, 'output_folder': results_dir}\n",
        "    \n",
        "    print(f\"\\nRunning {len(plans_to_run)} plans in parallel...\")\n",
        "    execution_results = RasCmdr.compute_parallel(\n",
        "        plan_number=plans_to_run,\n",
        "        max_workers=max_workers,\n",
        "        num_cores=num_cores,\n",
        "        clear_geompre=True\n",
        "    )\n",
        "    \n",
        "    print(\"\\nExecution results:\")\n",
        "    for plan, success in execution_results.items():\n",
        "        print(f\"  Plan {plan}: {'Successful' if success else 'Failed'}\")\n",
        "    \n",
        "    # If point of interest provided, extract and compare results\n",
        "    if point_of_interest is not None:\n",
        "        # Get geometry HDF path for cell identification\n",
        "        geom_hdf_path = ras.geom_df.loc[ras.geom_df['geom_number'] == template_geom, 'hdf_path'].values[0]\n",
        "        \n",
        "        # Find the nearest mesh cell\n",
        "        mesh_cells_gdf = HdfMesh.get_mesh_cell_points(geom_hdf_path)\n",
        "        distances = mesh_cells_gdf.geometry.apply(lambda geom: geom.distance(point_of_interest))\n",
        "        nearest_idx = distances.idxmin()\n",
        "        mesh_cell_id = mesh_cells_gdf.loc[nearest_idx, 'cell_id']\n",
        "        mesh_name = mesh_cells_gdf.loc[nearest_idx, 'mesh_name']\n",
        "        \n",
        "        print(f\"\\nNearest cell ID: {mesh_cell_id}\")\n",
        "        print(f\"Distance: {distances[nearest_idx]:.2f} units\")\n",
        "        print(f\"Mesh area: {mesh_name}\")\n",
        "        \n",
        "        # Extract results for each scenario\n",
        "        all_results = {}\n",
        "        max_ws_values = []\n",
        "        \n",
        "        for scenario in scenarios:\n",
        "            plan_number = scenario['plan_number']\n",
        "            land_cover = scenario['land_cover']\n",
        "            region_name = scenario['region_name']\n",
        "            n_value = scenario['n_value']\n",
        "            shortid = scenario['shortid']\n",
        "            \n",
        "            try:\n",
        "                results_xr = HdfResultsMesh.get_mesh_cells_timeseries(plan_number)\n",
        "                \n",
        "                # Extract water surface data\n",
        "                ws_data = results_xr[mesh_name]['Water Surface'].sel(cell_id=int(mesh_cell_id))\n",
        "                \n",
        "                # Convert to DataFrame\n",
        "                ws_df = pd.DataFrame({\n",
        "                    'time': ws_data.time.values,\n",
        "                    'water_surface': ws_data.values\n",
        "                })\n",
        "                \n",
        "                # Store results\n",
        "                max_ws = ws_df['water_surface'].max()\n",
        "                \n",
        "                all_results[plan_number] = {\n",
        "                    'scenario': scenario,\n",
        "                    'df': ws_df,\n",
        "                    'max_water_surface': max_ws\n",
        "                }\n",
        "                \n",
        "                max_ws_values.append({\n",
        "                    'plan_number': plan_number,\n",
        "                    'shortid': shortid,\n",
        "                    'land_cover': land_cover,\n",
        "                    'region_name': region_name,\n",
        "                    'n_value': n_value,\n",
        "                    'max_water_surface': max_ws\n",
        "                })\n",
        "                \n",
        "                print(f\"  {shortid}: Max WSE = {max_ws:.2f}\")\n",
        "                \n",
        "                # Save time series to CSV\n",
        "                ws_df.to_csv(results_dir / f\"timeseries_{shortid}.csv\", index=False)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  Error extracting results for {shortid}: {str(e)}\")\n",
        "        \n",
        "        # Create summary DataFrame\n",
        "        if max_ws_values:\n",
        "            max_ws_df = pd.DataFrame(max_ws_values)\n",
        "            max_ws_df.to_csv(results_dir / \"max_water_surface_summary.csv\", index=False)\n",
        "            \n",
        "            # Create plots by land cover type and region\n",
        "            land_cover_region_combinations = []\n",
        "            \n",
        "            for _, row in max_ws_df.iterrows():\n",
        "                if row['land_cover'] is not None and row['region_name'] is not None:\n",
        "                    combination = (row['land_cover'], row['region_name'])\n",
        "                    if combination not in land_cover_region_combinations:\n",
        "                        land_cover_region_combinations.append(combination)\n",
        "            \n",
        "            # Create sensitivity plots for each land cover + region combination\n",
        "            for land_cover, region in land_cover_region_combinations:\n",
        "                # Filter scenarios for this combination\n",
        "                combo_scenarios = max_ws_df[\n",
        "                    (max_ws_df['land_cover'] == land_cover) & \n",
        "                    (max_ws_df['region_name'] == region)\n",
        "                ].copy()\n",
        "                \n",
        "                # Add the template scenario\n",
        "                template_row = max_ws_df[max_ws_df['shortid'] == 'Template']\n",
        "                if not template_row.empty:\n",
        "                    combo_scenarios = pd.concat([template_row, combo_scenarios])\n",
        "                \n",
        "                if combo_scenarios.empty:\n",
        "                    continue\n",
        "                \n",
        "                # Sort by n_value\n",
        "                combo_scenarios = combo_scenarios.sort_values('n_value').reset_index(drop=True)\n",
        "                \n",
        "                # Create plot\n",
        "                fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                ax.plot(combo_scenarios['n_value'], combo_scenarios['max_water_surface'], \n",
        "                         marker='o', linestyle='-', linewidth=2)\n",
        "                \n",
        "                # Add template point in a different color if it exists\n",
        "                template_idx = combo_scenarios[combo_scenarios['shortid'] == 'Template'].index\n",
        "                if not template_idx.empty:\n",
        "                    ax.scatter(combo_scenarios.loc[template_idx, 'n_value'], \n",
        "                                combo_scenarios.loc[template_idx, 'max_water_surface'],\n",
        "                                color='red', s=100, zorder=5, label='Template')\n",
        "                \n",
        "                # Add labels and title\n",
        "                ax.set_xlabel(f\"Manning's n for {land_cover} in {region}\")\n",
        "                ax.set_ylabel(\"Maximum Water Surface Elevation (ft)\")\n",
        "                ax.set_title(f\"Sensitivity to {land_cover} Manning's n Value in {region}\")\n",
        "                ax.grid(True, linestyle='--', alpha=0.7)\n",
        "                \n",
        "                if not template_idx.empty:\n",
        "                    ax.legend()\n",
        "                \n",
        "                # Save plot\n",
        "                safe_lc = land_cover.replace(' ', '_').replace('/', '_')\n",
        "                safe_rg = region.replace(' ', '_').replace('/', '_')\n",
        "                plot_path = results_dir / f\"sensitivity_{safe_lc}_{safe_rg}.png\"\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(plot_path)\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "                print(f\"Created sensitivity plot for {land_cover} in {region}\")\n",
        "            \n",
        "            # Create time series comparison plots for each land cover + region combination\n",
        "            for land_cover, region in land_cover_region_combinations:\n",
        "                fig, ax = plt.subplots(figsize=(12, 6))\n",
        "                \n",
        "                # Get template results\n",
        "                template_plan = scenarios[0]['plan_number']\n",
        "                if template_plan in all_results:\n",
        "                    template_df = all_results[template_plan]['df']\n",
        "                    ax.plot(template_df['time'], template_df['water_surface'], \n",
        "                             color='black', linewidth=2, label='Template')\n",
        "                \n",
        "                # Filter scenarios for this combination\n",
        "                combo_scenarios = [\n",
        "                    s for s in scenarios \n",
        "                    if s['land_cover'] == land_cover and s['region_name'] == region\n",
        "                ]\n",
        "                \n",
        "                if not combo_scenarios:\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "                    continue\n",
        "                \n",
        "                # Setup colormap for n values\n",
        "                n_values = [s['n_value'] for s in combo_scenarios if s['n_value'] is not None]\n",
        "                if not n_values:\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "                    continue\n",
        "                    \n",
        "                min_n = min(n_values)\n",
        "                max_n = max(n_values)\n",
        "                norm = plt.Normalize(min_n, max_n)\n",
        "                cmap = plt.cm.viridis\n",
        "                \n",
        "                # Plot each scenario\n",
        "                for scenario in combo_scenarios:\n",
        "                    plan_number = scenario['plan_number']\n",
        "                    n_value = scenario['n_value']\n",
        "                    \n",
        "                    if plan_number in all_results and n_value is not None:\n",
        "                        df = all_results[plan_number]['df']\n",
        "                        color = cmap(norm(n_value))\n",
        "                        ax.plot(df['time'], df['water_surface'], color=color, \n",
        "                                 linewidth=1, alpha=0.7, label=f\"n = {n_value:.3f}\")\n",
        "                \n",
        "                # Add labels and title\n",
        "                ax.set_xlabel(\"Time\")\n",
        "                ax.set_ylabel(\"Water Surface Elevation (ft)\")\n",
        "                ax.set_title(f\"WSE Time Series for {land_cover} in {region}\")\n",
        "                ax.grid(True, linestyle='--', alpha=0.7)\n",
        "                \n",
        "                # Add colorbar\n",
        "                sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "                sm.set_array([])\n",
        "                cbar = plt.colorbar(sm, ax=ax)\n",
        "                cbar.set_label(f\"Manning's n for {land_cover}\")\n",
        "                \n",
        "                # Save plot\n",
        "                safe_lc = land_cover.replace(' ', '_').replace('/', '_')\n",
        "                safe_rg = region.replace(' ', '_').replace('/', '_')\n",
        "                plot_path = results_dir / f\"timeseries_{safe_lc}_{safe_rg}.png\"\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(plot_path)\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "                print(f\"Created time series plot for {land_cover} in {region}\")\n",
        "    \n",
        "    # Return results\n",
        "    return {\n",
        "        'scenarios': scenarios,\n",
        "        'execution_results': execution_results if 'execution_results' in locals() else None,\n",
        "        'results': all_results if 'all_results' in locals() else None,\n",
        "        'max_ws_summary': max_ws_df if 'max_ws_df' in locals() else None,\n",
        "        'significant_landuses': filtered_landuses,\n",
        "        'output_folder': results_dir\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u26a0\ufe0f Important Engineering Note on Regional Overrides\n",
        "\n",
        "We are using a HEC Example project with regional overriddes in the main channel.  A better application would be to vary values individually within larger calibration regions.  A further explanation follows: \n",
        "\n",
        "**Main Channel vs. Floodplain Application:**\n",
        "\n",
        "For **main channel** regional overrides, a **bulk sensitivity approach** is typically more appropriate (see notebook 105 for bulk Manning's n variation). This is because:\n",
        "\n",
        "1. **Land use-based roughness** values are derived from satellite imagery, which may not correlate well with main channel hydraulic roughness\n",
        "2. **Main channel roughness** is typically governed by bed material, channel shape, and vegetation conditions\u2014not upland land cover classifications\n",
        "3. **Bulk variation** allows testing a continuous range of main channel n values without land use constraints\n",
        "\n",
        "**This Methodology Best Applied To:**\n",
        "- Large calibration regions within the 2D mesh area\n",
        "- Floodplain zones with distinct land cover characteristics\n",
        "- Areas where satellite-derived land use correlates with hydraulic roughness\n",
        "\n",
        "**For Main Channel Calibration:**\n",
        "- Use the bulk sensitivity approach from notebook 105\n",
        "- Create multiple regional overrides to test different main channel reaches independently\n",
        "- Consider physical channel characteristics rather than land cover when selecting test values\n",
        "\n",
        "**Note on Example Project:**\n",
        "This notebook demonstrates the regional sensitivity methodology using the BaldEagleCrkMulti2D main channel region due to limited availability of example models with large floodplain calibration regions. In practice, apply this approach to appropriate floodplain or mesh regions where land cover-based roughness is hydraulically meaningful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executing Regional Override Sensitivity Analysis\n",
        "\n",
        "### Configuration Parameters\n",
        "\n",
        "The following example demonstrates how to run the regional override sensitivity analysis with the BaldEagleCrkMulti2D sample project.\n",
        "\n",
        "**Key Parameters (in addition to base parameters):**\n",
        "- `region_name`: Specific region to analyze (e.g., \"Main Channel\"), or `None` to analyze all regions\n",
        "- All other parameters match the base sensitivity function\n",
        "\n",
        "**Region-Specific Behavior:**\n",
        "- Only land covers present in the specified region(s) will be tested\n",
        "- The function automatically filters significant land uses based on region membership\n",
        "- Multiple regions with the same land cover will be tested independently\n",
        "\n",
        "### Execution Steps\n",
        "\n",
        "1. Use the same project from the base analysis (already extracted)\n",
        "2. Configure regional analysis parameters (note the `region_name` parameter)\n",
        "3. Run the sensitivity analysis\n",
        "4. Review region-specific results in the output folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the mannings n max and min values as a range. \n",
        "\n",
        "manning_data = [\n",
        "    {\"Land Cover Name\": \"NoData\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Barren Land Rock/Sand/Clay\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Cultivated Crops\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Deciduous Forest\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Developed, High Intensity\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Developed, Low Intensity\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Developed, Medium Intensity\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Developed, Open Space\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Emergent Herbaceous Wetlands\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Evergreen Forest\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Grassland/Herbaceous\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Mixed Forest\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Open Water\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Pasture/Hay\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Shrub/Scrub\", \"min_n\": 0.03, \"max_n\": 0.23},\n",
        "    {\"Land Cover Name\": \"Woody Wetlands\", \"min_n\": 0.03, \"max_n\": 0.23}\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "manning_minmax_df = pd.DataFrame(manning_data)\n",
        "\n",
        "# Calculate the midpoint value\n",
        "manning_minmax_df['mid_n'] = (manning_minmax_df['min_n'] + manning_minmax_df['max_n']) / 2\n",
        "\n",
        "# Sort by land cover name\n",
        "manning_minmax_df = manning_minmax_df.sort_values('Land Cover Name').reset_index(drop=True)\n",
        "\n",
        "# Print summary information\n",
        "print(f\"Manning's n value ranges for {len(manning_minmax_df)} land cover types:\")\n",
        "print(manning_minmax_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage for Regional Overrides Sensitivity Analysis\n",
        "# To run this, uncomment the code, adjust parameters as needed, and execute the cell\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Define source and destination paths\n",
        "#    (We use the original extracted project as source, not the BOMIS one)\n",
        "source_project_folder = Path(os.getcwd()) / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "\n",
        "# 2. Create a specific folder for Regional Override Multi-Interval Sensitivity (ROMIS)\n",
        "project_folder = Path(os.getcwd()) / \"example_projects\" / \"BaldEagleCrkMulti2D_ROMIS\"\n",
        "\n",
        "# Clean up if it already exists\n",
        "if project_folder.exists():\n",
        "    shutil.rmtree(project_folder)\n",
        "\n",
        "# Copy the source project to the ROMIS folder\n",
        "print(f\"Creating dedicated ROMIS project folder...\")\n",
        "shutil.copytree(source_project_folder, project_folder)\n",
        "print(f\"Created: {project_folder}\")\n",
        "\n",
        "# 3. Initialize the ROMIS project\n",
        "#    (This updates the global 'ras' object to point to this new folder, replacing the BOMIS context)\n",
        "init_ras_project(project_folder, \"6.6\")\n",
        "\n",
        "# Define parameters\n",
        "template_plan = \"03\"  # Plan 03 has regional overrides\n",
        "point_of_interest = (2081544, 365715) # Coordinates for regional analysis\n",
        "\n",
        "# Run the regional sensitivity analysis\n",
        "run_region_sensitivity_results = individual_landuse_sensitivity_region(\n",
        "    project_folder=project_folder,\n",
        "    template_plan=template_plan,\n",
        "    point_of_interest=point_of_interest,\n",
        "    area_threshold=10.0,  # Only analyze land uses covering at least 10% of the mesh area\n",
        "    interval=0.04,       # Adjust interval to reduce the number of test values\n",
        "    max_workers=4,\n",
        "    num_cores=2,\n",
        "    region_name=\"Main Channel\",  # Specify a region or set to None for all regions\n",
        "    output_folder=\"Regional_Landuse_Sensitivity\",\n",
        "    n_ranges=manning_minmax_df\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print summary information\n",
        "if run_region_sensitivity_results:\n",
        "    print(\"\\nAnalysis complete! Results saved to:\", run_region_sensitivity_results['output_folder'])\n",
        "    if 'significant_landuses' in run_region_sensitivity_results:\n",
        "        print(\"\\nSignificant land uses analyzed in regions:\")\n",
        "        print(run_region_sensitivity_results['significant_landuses'][['Land Cover Type', 'Percentage']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regional Override Sensitivity Results\n",
        "\n",
        "### Interpreting Regional Results\n",
        "\n",
        "The following plots show sensitivity analysis results for regional Manning's n overrides from the BaldEagleCrkMulti2D example project (Plan 03). The plots follow the same format as the base sensitivity results, but focus on parameters within specific calibration regions.\n",
        "\n",
        "**Key Differences from Base Results:**\n",
        "- Plots are labeled with both land cover type AND region name\n",
        "- Changes affect only the specified region, not the entire mesh\n",
        "- Sensitivity may be higher or lower depending on the hydraulic importance of the region\n",
        "- Useful for understanding which regional parameters require the most careful calibration\n",
        "\n",
        "**Regional vs. Base Comparison:**\n",
        "- Compare the magnitude of water surface changes between regional and base sensitivity\n",
        "- Regional parameters that cause large changes should be prioritized in calibration\n",
        "- If a land cover has low sensitivity in a particular region, it may be acceptable to use default values\n",
        "\n",
        "**Application to Your Models:**\n",
        "- Identify which regions have the strongest influence on your points of interest\n",
        "- Focus calibration efforts on high-sensitivity regions\n",
        "- Consider simplifying regions with low sensitivity\n",
        "\n",
        "---\n",
        "\n",
        "### Results from BaldEagleCrkMulti2D, Plan 03 (Main Channel Region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Summary and Best Practices\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "### Analysis Methodology\n",
        "\n",
        "This notebook demonstrated two complementary approaches to Manning's n sensitivity analysis:\n",
        "\n",
        "1. **Base Override Sensitivity**: Tests global land cover roughness parameters across the entire 2D mesh\n",
        "2. **Regional Override Sensitivity**: Tests localized roughness parameters within specific calibration regions\n",
        "\n",
        "Both approaches use literature-based ranges to ensure physically reasonable parameter variations and automatically generate comprehensive visualizations.\n",
        "\n",
        "### Practical Applications\n",
        "\n",
        "**When to Use Base Sensitivity:**\n",
        "- Initial model exploration and parameter importance ranking\n",
        "- Models with uniform land cover distributions\n",
        "- Assessing global calibration uncertainty\n",
        "- Identifying which land covers dominate model response\n",
        "\n",
        "**When to Use Regional Sensitivity:**\n",
        "- Main channel calibration (use bulk approach from notebook 105)\n",
        "- Localized parameter testing in specific hydraulic zones\n",
        "- Floodplain region calibration with distinct characteristics\n",
        "- Focused calibration in areas of interest\n",
        "\n",
        "### Calibration Workflow Recommendations\n",
        "\n",
        "1. **Start with base sensitivity** to identify globally important land covers\n",
        "2. **Rank parameters by sensitivity** - focus on land covers causing largest water surface changes\n",
        "3. **Use regional sensitivity** for localized refinement in hydraulically important areas\n",
        "4. **Iterate with observed data** - compare sensitivity results against measured water surfaces\n",
        "5. **Document assumptions** - record which parameters were adjusted and why\n",
        "\n",
        "### Computational Efficiency Tips\n",
        "\n",
        "**Plan Count Management:**\n",
        "- Use larger `interval` values (e.g., 0.02-0.05) to reduce plan count\n",
        "- Increase `area_threshold` to focus only on dominant land covers\n",
        "- Target specific regions rather than analyzing all regions simultaneously\n",
        "- HEC-RAS limits projects to 99 plans maximum\n",
        "\n",
        "**Parallel Execution:**\n",
        "- Balance `max_workers` and `num_cores` based on available CPU and RAM\n",
        "- Rule of thumb: `max_workers * num_cores \u2264 total_logical_cores`\n",
        "- Monitor system resources during execution\n",
        "- Consider sequential execution for very large or memory-intensive models\n",
        "\n",
        "### Output Files\n",
        "\n",
        "Each analysis creates a structured output folder containing:\n",
        "- `scenarios.csv`: Complete plan inventory with parameter values\n",
        "- `max_water_surface_summary.csv`: Peak water surface elevations for all scenarios\n",
        "- `timeseries_*.csv`: Complete hydrographs for each scenario\n",
        "- `sensitivity_*.png`: Parameter sensitivity plots\n",
        "- `timeseries_*.png`: Time series comparison plots\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Compare with observed data**: Use sensitivity plots to guide calibration toward measured values\n",
        "- **Uncertainty quantification**: Analyze the range of results to understand prediction uncertainty\n",
        "- **Spatial analysis**: Extract results at multiple points to understand spatial variability\n",
        "- **Multi-objective calibration**: Consider multiple performance metrics beyond peak water surface\n",
        "\n",
        "### Related Notebooks\n",
        "\n",
        "- **Notebook 105**: Bulk Manning's n sensitivity analysis (recommended for main channel calibration)\n",
        "- **Notebook 09**: Plan parameter operations for additional customization\n",
        "- **Notebook 08**: Parallel execution techniques for large-scale analyses\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "**Manning's n Value Resources:**\n",
        "- Chow, V.T. (1959). Open-Channel Hydraulics. McGraw-Hill\n",
        "- Arcement, G.J., & Schneider, V.R. (1989). Guide for Selecting Manning's Roughness Coefficients. USGS Water Supply Paper 2339\n",
        "- HEC-RAS Hydraulic Reference Manual (current version)\n",
        "\n",
        "**Sensitivity Analysis:**\n",
        "- Saltelli, A., et al. (2008). Global Sensitivity Analysis: The Primer. Wiley\n",
        "- Tate, E., et al. (2015). Uncertainty Analysis for Flood Risk Assessment. Natural Hazards\n",
        "\n",
        "---\n",
        "\n",
        "*End of Notebook*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\10_1d_hdf_data_extraction.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEC-RAS 1D HDF Data Analysis Notebook\n",
        "\n",
        "This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup\n",
        "Uncomment and run package installation commands if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ras-commander from pip (uncomment to install if needed)\n",
        "!pip install --upgrade ras-commander\n",
        "# This installs ras-commander and all dependencies\n",
        "\n",
        "# Set to false to disable plot generation for llm-friendly outputs\n",
        "generate_plots = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required modules\n",
        "from ras_commander import *  # Import all ras-commander modules\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path  # Ensure pathlib is imported for file operations\n",
        "from shapely.geometry import LineString\n",
        "\n",
        "\n",
        "# Set pandas display options to show only 7 rows by default\n",
        "pd.set_option('display.max_rows', 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use Example Project or Load Your Own Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the Balde Eagle Creek 1D Example project from HEC and run plan 01\n",
        "\n",
        "# Define the path to the 1D Balde Eagle Creek project\n",
        "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
        "bald_eagle_path = current_dir / \"example_projects\" / \"Balde Eagle Creek\"\n",
        "import logging\n",
        "\n",
        "# Check if BaldEagle.p01.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
        "hdf_file = bald_eagle_path / \"BaldEagle.p01.hdf\"\n",
        "\n",
        "if not hdf_file.exists():\n",
        "    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
        "    RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "\n",
        "    # Initialize the RAS project using the custom ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    logging.info(f\"Balde Eagle project initialized with folder: {ras.project_folder}\")\n",
        "    \n",
        "    logging.info(f\"Balde Eagle object id: {id(ras)}\")\n",
        "    \n",
        "    # Define the plan number to execute\n",
        "    plan_number = \"01\"\n",
        "\n",
        "    # Execute Plan 01 using RasCmdr for Bald Eagle\n",
        "    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n",
        "    success_bald_eagle = RasCmdr.compute_plan(plan_number)\n",
        "    if success_bald_eagle:\n",
        "        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n",
        "else:\n",
        "    print(\"BaldEagle.p01.hdf already exists. Skipping project extraction and plan execution.\")\n",
        "    # Initialize the RAS project using the custom ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    plan_number = \"01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  OPTIONAL: Use your own project instead\n",
        "\n",
        "your_project_path = Path(r\"D:\\yourprojectpath\")\n",
        "\n",
        "init_ras_project(your_project_path, \"6.6\")\n",
        "plan_number = \"01\"  # Plan number to use for this notebook \n",
        "\n",
        "\n",
        "\n",
        "### If you use this code cell, don't run the previous cell or change to markdown\n",
        "### NOTE: Ensure the HDF Results file was generated by HEC-RAS Version 6.x or above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Project Dataframes using 'ras' Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Plan DataFrame for the project:\")\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nGeometry DataFrame for the project:\")\n",
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nUnsteady DataFrame for the project:\")\n",
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nBoundary Conditions DataFrame for the project:\")\n",
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get HDF Results Entries (only present when results are present)\n",
        "ras.get_hdf_entries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find Paths for Results and Geometry HDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the plan HDF path for the plan_number defined above\n",
        "plan_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plan_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the geometry HDF path\n",
        "geom_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'Geom Path'].values[0] + '.hdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n",
        "print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAS-Commander's Decorators Allow for Flexible Function Calling\n",
        "You can call most of the functions in the HDF* Classes using any of the following:\n",
        "1. Plan/Geometry Number (with or without leading zeros):\n",
        "   - \"01\", \"1\" - Plan/geometry number as string\n",
        "   - 1 - Plan/geometry number as integer\n",
        "   - \"p01\", \"p1\" - Plan number with 'p' prefix\n",
        "2. Direct File Paths:\n",
        "   - pathlib.Path object pointing to HDF file\n",
        "   - String path to HDF file\n",
        "\n",
        "3. h5py.File Objects:\n",
        "   - Already opened HDF file object\n",
        "\n",
        "The @standardize_input decorator handles all these input types consistently:\n",
        "   - Validates the input exists and is accessible\n",
        "   - Converts to proper pathlib.Path object\n",
        "   - Handles RAS object references\n",
        "   - Provides logging and error handling\n",
        "\n",
        "This flexibility makes it easier to work with HDF files in different contexts while maintaining consistent behavior \n",
        "across the codebase, and helps prevent strict typing from introducing unnecessary friction for LLM Coding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1D HDF Data Extraction Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract runtime and compute time data as dataframe\n",
        "print(\"\\nExtracting runtime and compute time data\")\n",
        "runtime_df = HdfResultsPlan.get_runtime_data(hdf_path=plan_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfUtils for extracting projection\n",
        "# This returns a string with the projection as EPSG code (e.g. \"EPSG:6556\"), or None if not found.\n",
        "print(\"\\nExtracting Projection from HDF\")\n",
        "projection = HdfBase.get_projection(hdf_path=geom_hdf_path)  \n",
        "# This projection is returned as EPSG to improve compatibility with geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "projection\n",
        "### The example project we are using does not have a projection  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfPlan to Get Geometry Information (Base Geometry Attributes) as dataframes\n",
        "print(\"\\nExtracting Base Geometry Attributes\")\n",
        "geom_attrs_df = HdfPlan.get_geometry_information(\"01\")  \n",
        "# NOTE: Here we call the function using the plan number instead of the hdf path to demonstrate that the decorator will work with the plan number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_attrs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get geometry structures attributes as dataframe\n",
        "print(\"\\nGetting geometry structures attributes\")\n",
        "geom_structures_attrs_df = HdfStruc.get_geom_structures_attrs(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_structures_attrs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instead of hdf_input, USE plan_hdf_path or geom_hdf_path, or the plan number as \"8\" or \"08\" \n",
        "# Input decorators allow for flexible inputs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get structures as geodataframe\n",
        "structures_gdf = HdfStruc.get_structures(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "structures_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get reference lines as geodataframe\n",
        "ref_lines_gdf = HdfBndry.get_reference_lines(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ref_lines_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get reference points as geodataframe\n",
        "ref_points_gdf = HdfBndry.get_reference_points(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ref_points_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cross sections as geodataframe\n",
        "cross_sections_gdf = HdfXsec.get_cross_sections(geom_hdf_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_sections_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all columns for the first cross section (transpose for readability)\n",
        "import pandas as pd\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "    print(cross_sections_gdf.head(1).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all columns in cross_sections_gdf\n",
        "\n",
        "print(\"Columns in cross_sections_gdf:\")\n",
        "for col in cross_sections_gdf.columns:\n",
        "    print(col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Showing only cross sections with ineffective flow areas\n",
        "\n",
        "# Filter rows where ineffective_blocks is not empty\n",
        "ineffective_xs_gdf = cross_sections_gdf[cross_sections_gdf['ineffective_blocks'].apply(len) > 0]\n",
        "print(\"\\nCross Sections with Ineffective Flow Areas:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ineffective_xs_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print first 5 cross sections data\n",
        "print(\"\\nCross Section Information:\")\n",
        "\n",
        "for idx, row in cross_sections_gdf.head(5).iterrows():\n",
        "    print(f\"\\nCross Section {idx + 1}:\")\n",
        "    print(f\"River: {row['River']}\")\n",
        "    print(f\"Reach: {row['Reach']}\")\n",
        "    print(\"\\nGeometry:\")\n",
        "    print(row['geometry'])\n",
        "    print(\"\\nStation-Elevation Points:\")\n",
        "    \n",
        "    # Print header\n",
        "    print(\"     #      Station   Elevation        #      Station   Elevation        #      Station   Elevation        #      Station   Elevation        #      Station   Elevation\")\n",
        "    print(\"-\" * 150)\n",
        "    \n",
        "    # Calculate number of rows needed\n",
        "    points = row['station_elevation']\n",
        "    num_rows = (len(points) + 4) // 5  # Round up division\n",
        "    \n",
        "    # Print points in 5 columns\n",
        "    for i in range(num_rows):\n",
        "        line = \"\"\n",
        "        for j in range(5):\n",
        "            point_idx = i + j * num_rows\n",
        "            if point_idx < len(points):\n",
        "                station, elevation = points[point_idx]\n",
        "                line += f\"{point_idx+1:6d} {station:10.2f} {elevation:10.2f}    \"\n",
        "        print(line)\n",
        "    print(\"-\" * 150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cross sections on map with matplotlib\n",
        "\n",
        "if generate_plots:\n",
        "    # Create figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(15,10))\n",
        "    \n",
        "    # Plot cross sections\n",
        "    cross_sections_gdf.plot(ax=ax, color='red', linewidth=1, label='Cross Sections')\n",
        "    \n",
        "    # Add river name and reach labels\n",
        "    #for idx, row in cross_sections_gdf.iterrows():\n",
        "    #    # Get midpoint of cross section line for label placement\n",
        "    #    midpoint = row.geometry.centroid\n",
        "    #    label = f\"{row['River']}\\n{row['Reach']}\\nRS: {row['RS']}\"\n",
        "    #    ax.annotate(label, (midpoint.x, midpoint.y), \n",
        "    #               xytext=(5, 5), textcoords='offset points',\n",
        "    #               fontsize=8, bbox=dict(facecolor='white', alpha=0.7))\n",
        "    \n",
        "    # Customize plot\n",
        "    ax.set_title('Cross Sections Location Map')\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Equal aspect ratio to preserve shape\n",
        "    ax.set_aspect('equal')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cross sections with Manning's n values colored by value\n",
        "\n",
        "if generate_plots:\n",
        "    # Create figure\n",
        "    fig, ax1 = plt.subplots(figsize=(20,10))\n",
        "\n",
        "    # Create colormap\n",
        "    cmap = plt.cm.viridis\n",
        "    norm = plt.Normalize(vmin=0.02, vmax=0.08)  # Typical Manning's n range\n",
        "\n",
        "    # Plot cross sections colored by Manning's n\n",
        "    for idx, row in cross_sections_gdf.iterrows():\n",
        "        # Extract Manning's n values and stations\n",
        "        mannings = row['mannings_n']\n",
        "        n_values = mannings['Mann n']\n",
        "        stations = mannings['Station']\n",
        "        \n",
        "        # Get the full linestring coordinates\n",
        "        line_coords = list(row.geometry.coords)\n",
        "        \n",
        "        # Calculate total length of the cross section\n",
        "        total_length = row.geometry.length\n",
        "        \n",
        "        # For each Manning's n segment\n",
        "        for i in range(len(n_values)-1):\n",
        "            # Calculate the start and end proportions along the line\n",
        "            start_prop = stations[i] / stations[-1]\n",
        "            end_prop = stations[i+1] / stations[-1]\n",
        "            \n",
        "            # Get the start and end points for this segment\n",
        "            start_idx = int(start_prop * (len(line_coords)-1))\n",
        "            end_idx = int(end_prop * (len(line_coords)-1))\n",
        "            \n",
        "            # Extract the segment coordinates\n",
        "            segment_coords = line_coords[start_idx:end_idx+1]\n",
        "            \n",
        "            if len(segment_coords) >= 2:\n",
        "                # Create a line segment\n",
        "                segment = LineString(segment_coords)\n",
        "                \n",
        "                # Get color from colormap for this n value\n",
        "                color = cmap(norm(n_values[i]))\n",
        "                \n",
        "                # Plot the segment\n",
        "                ax1.plot(*segment.xy, color=color, linewidth=2)\n",
        "\n",
        "    # Add colorbar\n",
        "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])\n",
        "    plt.colorbar(sm, ax=ax1, label=\"Manning's n Value\")\n",
        "\n",
        "    ax1.set_title(\"Cross Sections Colored by Manning's n Values\")\n",
        "    ax1.grid(True)\n",
        "    ax1.set_aspect('equal')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cross sections with ineffective flow areas\n",
        "\n",
        "if generate_plots:\n",
        "    # Create figure\n",
        "    fig, ax2 = plt.subplots(figsize=(20,10))\n",
        "\n",
        "    # Plot all cross sections first\n",
        "    cross_sections_gdf.plot(ax=ax2, color='lightgray', linewidth=1, label='Cross Sections')\n",
        "\n",
        "    # Plot ineffective flow areas with thicker lines\n",
        "    ineffective_sections = cross_sections_gdf[cross_sections_gdf['ineffective_blocks'].apply(lambda x: len(x) > 0)]\n",
        "    ineffective_sections.plot(ax=ax2, color='red', linewidth=3, label='Ineffective Flow Areas')\n",
        "\n",
        "    # Add ineffective flow area labels with offset to lower right\n",
        "    for idx, row in cross_sections_gdf.iterrows():\n",
        "        # Get midpoint of cross section line\n",
        "        midpoint = row.geometry.centroid\n",
        "        \n",
        "        # Extract ineffective flow blocks\n",
        "        ineff_blocks = row['ineffective_blocks']\n",
        "        \n",
        "        if ineff_blocks:  # Only label if there are ineffective blocks\n",
        "            label_parts = []\n",
        "            # Add RS to first line of label\n",
        "            label_parts.append(f\"RS: {row['RS']}\")\n",
        "            for block in ineff_blocks:\n",
        "                label_parts.append(\n",
        "                    f\"L:{block['Left Sta']:.0f}-R:{block['Right Sta']:.0f}\\n\"\n",
        "                    f\"Elev: {block['Elevation']:.2f}\\n\"\n",
        "                    f\"Permanent: {block['Permanent']}\"\n",
        "                )\n",
        "            \n",
        "            label = '\\n'.join(label_parts)\n",
        "            \n",
        "            ax2.annotate(label, (midpoint.x, midpoint.y),\n",
        "                        xytext=(15, -15),  # Offset to lower right\n",
        "                        textcoords='offset points',\n",
        "                        fontsize=8, \n",
        "                        bbox=dict(facecolor='white', alpha=0.7),\n",
        "                        arrowprops=dict(arrowstyle='->'),\n",
        "                        horizontalalignment='left',\n",
        "                        verticalalignment='top')\n",
        "\n",
        "    ax2.set_title('Cross Sections with Ineffective Flow Areas')\n",
        "    ax2.grid(True)\n",
        "    ax2.legend()\n",
        "    ax2.set_aspect('equal')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cross section elevation for cross section 42\n",
        "if generate_plots:\n",
        "    # Get cross sections data\n",
        "    cross_sections_gdf = HdfXsec.get_cross_sections(geom_hdf_path)\n",
        "\n",
        "    if not cross_sections_gdf.empty:\n",
        "        # Get station-elevation data for cross section 42\n",
        "        station_elevation = cross_sections_gdf.iloc[42]['station_elevation']\n",
        "        \n",
        "        # Convert list of lists to numpy arrays for plotting\n",
        "        stations = np.array([point[0] for point in station_elevation])\n",
        "        elevations = np.array([point[1] for point in station_elevation])\n",
        "        \n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(12,8))\n",
        "        \n",
        "        # Plot cross section\n",
        "        ax.plot(stations, elevations, 'b-', linewidth=2)\n",
        "        \n",
        "        # Add labels and title\n",
        "        river = cross_sections_gdf.iloc[42]['River']\n",
        "        reach = cross_sections_gdf.iloc[42]['Reach'] \n",
        "        rs = cross_sections_gdf.iloc[42]['RS']\n",
        "        \n",
        "        # Show bank stations as dots\n",
        "        left_bank_station = cross_sections_gdf.iloc[42]['Left Bank']\n",
        "        right_bank_station = cross_sections_gdf.iloc[42]['Right Bank']\n",
        "        \n",
        "        # Get elevations at bank stations\n",
        "        left_bank_elev = elevations[np.searchsorted(stations, left_bank_station)]\n",
        "        right_bank_elev = elevations[np.searchsorted(stations, right_bank_station)]\n",
        "        \n",
        "        # Plot bank stations with dots\n",
        "        ax.plot(left_bank_station, left_bank_elev, 'ro')\n",
        "        ax.plot(right_bank_station, right_bank_elev, 'ro')\n",
        "        \n",
        "        # Add bank station labels with station and elevation\n",
        "        ax.annotate(f'Left Bank\\nStation: {left_bank_station:.1f}\\nElevation: {left_bank_elev:.1f}',\n",
        "                   (left_bank_station, left_bank_elev),\n",
        "                   xytext=(-50, 30),\n",
        "                   textcoords='offset points',\n",
        "                   bbox=dict(facecolor='white', alpha=0.8),\n",
        "                   arrowprops=dict(arrowstyle='->'))\n",
        "                   \n",
        "        ax.annotate(f'Right Bank\\nStation: {right_bank_station:.1f}\\nElevation: {right_bank_elev:.1f}',\n",
        "                   (right_bank_station, right_bank_elev), \n",
        "                   xytext=(50, 30),\n",
        "                   textcoords='offset points',\n",
        "                   bbox=dict(facecolor='white', alpha=0.8),\n",
        "                   arrowprops=dict(arrowstyle='->'))\n",
        "        \n",
        "        ax.set_title(f'Cross Section Profile\\nRiver: {river}, Reach: {reach}, RS: {rs}')\n",
        "        ax.set_xlabel('Station (ft)')\n",
        "        ax.set_ylabel('Elevation (ft)')\n",
        "        \n",
        "        # Add grid\n",
        "        ax.grid(True)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get river centerlines as geodataframe\n",
        "centerlines_gdf = HdfXsec.get_river_centerlines(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nRiver Centerlines:\")\n",
        "centerlines_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot river centerlines with labels\n",
        "if generate_plots:\n",
        "    # Create figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "    # Plot centerlines\n",
        "    centerlines_gdf.plot(ax=ax, color='blue', linewidth=2, label='River Centerline')\n",
        "\n",
        "    # Add river/reach labels\n",
        "    for idx, row in centerlines_gdf.iterrows():\n",
        "        # Get midpoint of the line for label placement\n",
        "        midpoint = row.geometry.interpolate(0.5, normalized=True)\n",
        "        \n",
        "        # Create label text combining river and reach names\n",
        "        label = f\"{row['River Name']}\\n{row['Reach Name']}\"\n",
        "        \n",
        "        # Add text annotation\n",
        "        ax.annotate(label, \n",
        "                    xy=(midpoint.x, midpoint.y),\n",
        "                    xytext=(10, 10), # Offset text slightly\n",
        "                    textcoords='offset points',\n",
        "                    fontsize=10,\n",
        "                    bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
        "\n",
        "    # Add labels and title\n",
        "    ax.set_title('River Centerlines', fontsize=14)\n",
        "    ax.set_xlabel('Easting', fontsize=12)\n",
        "    ax.set_ylabel('Northing', fontsize=12)\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend(fontsize=12)\n",
        "\n",
        "    # Add grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get river edge lines as geodataframe\n",
        "edge_lines_gdf = HdfXsec.get_river_edge_lines(geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nRiver Edge Lines:\")\n",
        "edge_lines_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get bank lines as geodataframe\n",
        "bank_lines_gdf = HdfXsec.get_river_bank_lines(geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nRiver Bank Lines:\")\n",
        "bank_lines_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create figure and axis\n",
        "\n",
        "if generate_plots:\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "    # Plot river edge lines\n",
        "    edge_lines_gdf.plot(ax=ax, color='blue', linewidth=2, label='River Edge Lines')\n",
        "\n",
        "    # Plot centerlines for reference\n",
        "    centerlines_gdf.plot(ax=ax, color='red', linewidth=2, linestyle='--', label='River Centerline')\n",
        "\n",
        "    # Plot river bank lines\n",
        "    bank_lines_gdf.plot(ax=ax, color='green', linewidth=2, label='River Bank Lines')\n",
        "\n",
        "    # Add title and labels\n",
        "    ax.set_title('River Edge Lines, Centerline, and Bank Lines', fontsize=14)\n",
        "    ax.set_xlabel('Easting', fontsize=12)\n",
        "    ax.set_ylabel('Northing', fontsize=12)\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend(fontsize=12)\n",
        "\n",
        "    # Add grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract 1D Structures Geodataframe\n",
        "\n",
        "\n",
        "\n",
        "# Display basic information about the structures\n",
        "print(\"\\nStructures Summary:\")\n",
        "print(f\"Number of structures found: {len(structures_gdf)}\")\n",
        "structures_gdf\n",
        "\n",
        "# Display first few rows of key attributes\n",
        "print(\"\\nStructure Details:\")\n",
        "display_cols = ['Structure ID', 'Structure Type', 'River Name', 'Reach Name', 'Station']\n",
        "display_cols = [col for col in display_cols if col in structures_gdf.columns]\n",
        "if display_cols:\n",
        "    print(structures_gdf[display_cols].head())\n",
        "\n",
        "\n",
        "if generate_plots:\n",
        "\n",
        "    # Create visualization\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "    # Plot river centerlines\n",
        "    if not centerlines_gdf.empty:\n",
        "        centerlines_gdf.plot(ax=ax, color='blue', linewidth=2, label='River Centerlines')\n",
        "\n",
        "    # Plot cross sections\n",
        "    if not cross_sections_gdf.empty:\n",
        "        cross_sections_gdf.plot(ax=ax, color='green', linewidth=1, label='Cross Sections')\n",
        "\n",
        "    # Plot structures\n",
        "    if not structures_gdf.empty:\n",
        "        structures_gdf.plot(ax=ax, color='red', marker='s', markersize=100, label='Structures')\n",
        "\n",
        "    # Add title and labels\n",
        "    ax.set_title('HEC-RAS Model Components', fontsize=14)\n",
        "    ax.set_xlabel('Easting', fontsize=12)\n",
        "    ax.set_ylabel('Northing', fontsize=12)\n",
        "\n",
        "    # Add legend\n",
        "    ax.legend(fontsize=12)\n",
        "\n",
        "    # Add grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n",
        "# Print summary of cross sections\n",
        "print(\"\\nCross Sections Summary:\")\n",
        "print(f\"Number of cross sections found: {len(cross_sections_gdf)}\")\n",
        "if not cross_sections_gdf.empty:\n",
        "    print(\"\\nCross Section Details:\")\n",
        "    xs_display_cols = ['River', 'Reach', 'Station']\n",
        "    xs_display_cols = [col for col in xs_display_cols if col in cross_sections_gdf.columns]\n",
        "    if xs_display_cols:\n",
        "        print(cross_sections_gdf[xs_display_cols].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Plan Parameters\n",
        "print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n",
        "\n",
        "plan_parameters_df = HdfPlan.get_plan_parameters(hdf_path=plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nPlan Parameters DataFrame:\")\n",
        "plan_parameters_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract volume accounting data\n",
        "volume_accounting_df = HdfResultsPlan.get_volume_accounting(hdf_path=plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nVolume Accounting DataFrame:\")\n",
        "volume_accounting_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get simulation start time\n",
        "start_time = HdfPlan.get_plan_start_time(plan_hdf_path)\n",
        "print(f\"Simulation start time: {start_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get plan end time\n",
        "end_time = HdfPlan.get_plan_end_time(plan_hdf_path)\n",
        "print(f\"Simulation end time: {end_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cross section results timeseries\n",
        "xsec_results_xr = HdfResultsXsec.get_xsec_timeseries(plan_hdf_path)\n",
        "print(\"\\nCross Section Results Shape:\", xsec_results_xr['Water_Surface'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xsec_results_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the time of maximum water surface elevation (WSEL) for cross sections\n",
        "\n",
        "\n",
        "\n",
        "# Get cross section geometry data\n",
        "xsec_geom = HdfXsec.get_cross_sections(plan_hdf_path)\n",
        "print(\"\\nNumber of cross sections in geometry:\", len(xsec_geom))\n",
        "\n",
        "# Create dataframe with cross section locations and max WSEL times\n",
        "xs_data = []\n",
        "\n",
        "# Extract water surface data from xarray Dataset\n",
        "water_surface = xsec_results_xr['Water_Surface'].values\n",
        "times = pd.to_datetime(xsec_results_xr.time.values)\n",
        "\n",
        "# Debug print\n",
        "print(\"\\nFirst few cross section names:\")\n",
        "print(xsec_results_xr.cross_section.values[:5])\n",
        "\n",
        "# Iterate through cross sections\n",
        "for xs_idx in range(len(xsec_results_xr.cross_section)):\n",
        "    # Get WSEL timeseries for this cross section\n",
        "    wsel_series = water_surface[:, xs_idx]\n",
        "    \n",
        "    # Get cross section name and parse components\n",
        "    xs_name = xsec_results_xr.cross_section.values[xs_idx]\n",
        "    \n",
        "    # Split the string and remove empty strings\n",
        "    xs_parts = [part for part in xs_name.split() if part]\n",
        "    \n",
        "    if len(xs_parts) >= 3:\n",
        "        river = \"Bald Eagle\"  # Combine first two words\n",
        "        reach = \"Loc Hav\"     # Next two words\n",
        "        rs = xs_parts[-1]     # Last part is the station\n",
        "        \n",
        "        # Get geometry for this cross section\n",
        "        xs_match = xsec_geom[\n",
        "            (xsec_geom['River'] == river) & \n",
        "            (xsec_geom['Reach'] == reach) & \n",
        "            (xsec_geom['RS'] == rs)\n",
        "        ]\n",
        "        \n",
        "        if not xs_match.empty:\n",
        "            geom = xs_match.iloc[0]\n",
        "            # Use first point of cross section line for plotting\n",
        "            x = geom.geometry.coords[0][0]\n",
        "            y = geom.geometry.coords[0][1]\n",
        "            \n",
        "            # Find time of max WSEL\n",
        "            max_wsel_idx = np.argmax(wsel_series)\n",
        "            max_wsel = np.max(wsel_series)\n",
        "            max_time = times[max_wsel_idx]\n",
        "            \n",
        "            xs_data.append({\n",
        "                'xs_name': xs_name,\n",
        "                'x': x,\n",
        "                'y': y,\n",
        "                'max_wsel': max_wsel,\n",
        "                'time_of_max': max_time\n",
        "            })\n",
        "        else:\n",
        "            print(f\"\\nWarning: No geometry match found for {xs_name}\")\n",
        "            print(f\"River: {river}, Reach: {reach}, RS: {rs}\")\n",
        "    else:\n",
        "        print(f\"\\nWarning: Could not parse cross section name: {xs_name}\")\n",
        "\n",
        "# Create dataframe\n",
        "xs_df = pd.DataFrame(xs_data)\n",
        "\n",
        "# Debug print\n",
        "print(\"\\nNumber of cross sections processed:\", len(xs_df))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if generate_plots:\n",
        "    print(\"\\nColumns in xs_df:\", xs_df.columns.tolist())\n",
        "    print(\"\\nFirst row of xs_df:\")\n",
        "    print(xs_df.iloc[0])\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Convert datetime to hours since start for colormap\n",
        "    min_time = min(xs_df['time_of_max'])\n",
        "    color_values = [(t - min_time).total_seconds() / 3600 for t in xs_df['time_of_max']]\n",
        "\n",
        "    # Plot cross section points\n",
        "    scatter = ax.scatter(xs_df['x'], xs_df['y'],\n",
        "                        c=color_values,\n",
        "                        cmap='viridis',\n",
        "                        s=50)\n",
        "\n",
        "    # Customize plot\n",
        "    ax.set_title('Time of Maximum Water Surface Elevation at Cross Sections')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Hours since simulation start')\n",
        "\n",
        "    # Format colorbar ticks\n",
        "    max_hours = int(max(color_values))\n",
        "    tick_interval = max(1, max_hours // 6)  # Show ~6 ticks\n",
        "    cbar.set_ticks(range(0, max_hours + 1, tick_interval))\n",
        "    cbar.set_ticklabels([f'{h}h' for h in range(0, max_hours + 1, tick_interval)])\n",
        "\n",
        "    # Add grid and adjust styling\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary statistics\n",
        "    max_wsel_xs = xs_df.loc[xs_df['max_wsel'].idxmax()]\n",
        "    hours_since_start = (max_wsel_xs['time_of_max'] - min_time).total_seconds() / 3600\n",
        "\n",
        "    print(f\"\\nOverall Maximum WSEL: {max_wsel_xs['max_wsel']:.2f} ft\")\n",
        "    print(f\"Time of Overall Maximum WSEL: {max_wsel_xs['time_of_max']}\")\n",
        "    print(f\"Hours since simulation start: {hours_since_start:.2f} hours\")\n",
        "    print(f\"Location of Overall Maximum WSEL: X={max_wsel_xs['x']:.2f}, Y={max_wsel_xs['y']:.2f}\")\n",
        "    print(f\"Cross Section: {max_wsel_xs['xs_name']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unsteady attributes as dataframe\n",
        "results_unsteady_attrs = HdfResultsPlan.get_unsteady_info(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_unsteady_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unsteady summary attributes as dataframe\n",
        "results_unsteady_summary_attrs = HdfResultsPlan.get_unsteady_summary(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_unsteady_summary_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1D Cross Section Results as Xarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cross section results timeseries as xarray dataset\n",
        "xsec_results_xr = HdfResultsXsec.get_xsec_timeseries(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xsec_results_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print time series for specific cross section\n",
        "target_xs = \"Bald Eagle       Loc Hav          136202.3\"\n",
        "\n",
        "print(\"\\nTime Series Data for Cross Section:\", target_xs)\n",
        "for var in ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']:\n",
        "    print(f\"\\n{var}:\")\n",
        "    print(xsec_results_xr[var].sel(cross_section=target_xs).values[:5])  # Show first 5 values\n",
        "\n",
        "# Create time series plots\n",
        "\n",
        "if generate_plots:\n",
        "\n",
        "    # Create a figure for each variable\n",
        "    variables = ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']\n",
        "\n",
        "    for var in variables:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        # Convert time values to datetime if needed\n",
        "        time_values = pd.to_datetime(xsec_results_xr.time.values)\n",
        "        values = xsec_results_xr[var].sel(cross_section=target_xs).values\n",
        "        \n",
        "        # Plot with explicit x and y values\n",
        "        plt.plot(time_values, values, '-', linewidth=2)\n",
        "        \n",
        "        plt.title(f'{var} at {target_xs}')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel(var.replace('_', ' '))\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Force display\n",
        "        plt.draw()\n",
        "        plt.pause(0.1)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced HDF Data Extraction\n",
        "This section focuses on directly accessing the HDF file from a jupyter notebook for use cases not directly supported by the RAS-Commander libary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Compute Messages using HdfResultsPlan\n",
        "print(\"Extracting Compute Messages\")\n",
        "\n",
        "# Use the built-in function to extract computation messages from HDF\n",
        "# This function automatically handles HDF extraction with fallback to .txt files if needed\n",
        "compute_msgs = HdfResultsPlan.get_compute_messages(plan_number)\n",
        "\n",
        "if compute_msgs:\n",
        "    print(\"=\"*80)\n",
        "    print(\"COMPUTATION MESSAGES\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Parse and display the messages in a readable format\n",
        "    messages = compute_msgs.split('\\r\\n')\n",
        "    \n",
        "    # Display all messages with formatting\n",
        "    for message in messages:\n",
        "        if message.strip():  # Skip empty lines\n",
        "            if ':' in message:\n",
        "                # Format key-value pairs\n",
        "                parts = message.split(':', 1)\n",
        "                if len(parts) == 2:\n",
        "                    key, value = parts\n",
        "                    print(f\"{key.strip():40} : {value.strip()}\")\n",
        "                else:\n",
        "                    print(message)\n",
        "            else:\n",
        "                print(f\"\\n{message.strip()}\")\n",
        "    \n",
        "    # Display computation summary table (if present)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPUTATION SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    summary_lines = [line for line in messages if 'Computation Task' in line or 'Computation Speed' in line]\n",
        "    if summary_lines:\n",
        "        for line in summary_lines:\n",
        "            print(line)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Total message length: {len(compute_msgs)} characters\")\n",
        "    print(\"=\"*80)\n",
        "else:\n",
        "    print(\"No computation messages available for this plan.\")\n",
        "    print(\"\\nNote: Computation messages are generated when HEC-RAS runs a plan.\")\n",
        "    print(\"If no messages are found, the plan may not have been computed yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring HDF Datasets with HdfBase.get_dataset_info\n",
        "This allows users to find HDF information that is not included in the ras-commander library.  Find the path in HDFView and set the group_path below to explore the HDF datasets and attributes.  Then, use the output to write your own function to extract the data.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Get HDF Paths with Properties (For Exploring HDF Files)\n",
        "HdfBase.get_dataset_info(plan_number, group_path=\"/Geometry\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use get_hdf5_dataset_info function to get dataset structure:\n",
        "HdfBase.get_dataset_info(plan_hdf_path, \"/Geometry/River Bank Lines/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "HdfBase.get_dataset_info(plan_hdf_path, \"/Geometry/Structures\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "HdfBase.get_dataset_info(plan_hdf_path, \"/Results/Unsteady/Output/Output Blocks/Computation Block/Global/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use the get_hdf5_dataset_info function from HdfUtils to explore the Cross Sections structure in the geometry HDF file\n",
        "\n",
        "print(\"\\nExploring Cross Sections structure in geometry file:\")\n",
        "print(\"HDF Base Path: /Geometry/Cross Sections \")\n",
        "HdfBase.get_dataset_info(geom_hdf_path, group_path='/Geometry/Cross Sections')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "print(\"\\n=== HDF5 File Structure ===\\n\")\n",
        "print(plan_hdf_path)\n",
        "HdfBase.get_dataset_info(plan_hdf_path, group_path='/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Cross Sections')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For HDF datasets that are not supported by the RAS-Commadner library, provide the dataset path to HdfBase.get_dataset_info and provide the output to an LLM along with a relevent HDF* class(es) to generate new functions that extend the library's coverage.   "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\11_2d_hdf_data_extraction.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEC-RAS 2D HDF Data Analysis Notebook\n",
        "\n",
        "This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ras-commander from pip (uncomment to install if needed)\n",
        "#!pip install ras-commander\n",
        "# This installs ras-commander and all dependencies\n",
        "\n",
        "# Use this setting to disable plot generation within the notebook\n",
        "generate_plots = True\n",
        "# Use this setting to disable map generation within the notebook\n",
        "generate_maps = True\n",
        "# Set both to false for llm-friendly outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required modules\n",
        "#from ras_commander import *  # Import all ras-commander modules\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path  # Ensure pathlib is imported for file operations\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import ConnectionPatch\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell will try to import the pip package, if it fails it will \n",
        "# add the parent directory to the Python path and try to import again\n",
        "# This assumes you are working in a subfolder of the ras-commander repository\n",
        "# This allows a user's revisions to be tested locally without installing the package\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Flexible imports to allow for development without installation \n",
        "#  ** Use this version with Jupyter Notebooks **\n",
        "try:\n",
        "    # Try to import from the installed package\n",
        "    from ras_commander import *\n",
        "except ImportError:\n",
        "    # If the import fails, add the parent directory to the Python path\n",
        "    import os\n",
        "    current_file = Path(os.getcwd()).resolve()\n",
        "    rascmdr_directory = current_file.parent\n",
        "    sys.path.append(str(rascmdr_directory))\n",
        "    print(\"Loading ras-commander from local dev copy\")\n",
        "    # Now try to import again\n",
        "    from ras_commander import *\n",
        "print(\"ras_commander imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use Example Project or Load Your Own Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To Use the HEC Example Project:\n",
        "# Download the BaldEagleCrkMulti2D project from HEC and Run Plan 06\n",
        "\n",
        "# Define the path to the BaldEagleCrkMulti2D project\n",
        "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
        "the_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "import logging\n",
        "\n",
        "# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
        "hdf_file = the_path / \"BaldEagleDamBrk.p06.hdf\"\n",
        "\n",
        "if not hdf_file.exists():\n",
        "    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
        "    RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
        "\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(the_path, \"6.6\")\n",
        "    logging.info(f\"Bald Eagle project initialized with folder: {ras.project_folder}\")\n",
        "    \n",
        "    logging.info(f\"Bald Eagle object id: {id(ras)}\")\n",
        "    \n",
        "    # Define the plan number to execute\n",
        "    plan_number = \"06\"\n",
        "\n",
        "    # Update run flags for the project\n",
        "    RasPlan.update_run_flags(\n",
        "        plan_number,\n",
        "        geometry_preprocessor=True,\n",
        "        unsteady_flow_simulation=True,\n",
        "        run_sediment=False,\n",
        "        post_processor=True,\n",
        "        floodplain_mapping=False\n",
        "    )\n",
        "\n",
        "    # Execute Plan 06 using RasCmdr for Bald Eagle\n",
        "    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n",
        "    success_the = RasCmdr.compute_plan(plan_number)\n",
        "    if success_the:\n",
        "        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n",
        "else:\n",
        "    print(\"Project already exists. Skipping project extraction and plan execution.\")\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(the_path, \"6.6\")\n",
        "    plan_number = \"06\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting 2D Computation Messages\n",
        "\n",
        "For 2D models, computation messages are especially important for understanding:\n",
        "- 2D mesh stability and timestep information\n",
        "- Wet/dry cell transitions\n",
        "- Volume accounting and mass balance\n",
        "- Performance metrics for large 2D meshes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract computation messages for 2D analysis\n",
        "from ras_commander import HdfResultsPlan\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"2D MODEL COMPUTATION MESSAGES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "msgs_2d = HdfResultsPlan.get_compute_messages(plan_number)\n",
        "\n",
        "if msgs_2d:\n",
        "    print(f\"\\nExtracted {len(msgs_2d)} characters of computation messages\\n\")\n",
        "    \n",
        "    # Display first portion\n",
        "    print(\"Computation messages (first 1000 characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(msgs_2d[:1000])\n",
        "    \n",
        "    if len(msgs_2d) > 1000:\n",
        "        print(\"\\n... (truncated for display) ...\")\n",
        "    \n",
        "    # Check for 2D-specific information\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Looking for 2D-specific information...\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    lines = msgs_2d.split('\\n')\n",
        "    keywords = ['2d', 'mesh', 'timestep', 'volume', 'courant']\n",
        "    relevant = [l for l in lines if any(kw in l.lower() for kw in keywords)]\n",
        "    \n",
        "    if relevant:\n",
        "        print(f\"Found {len(relevant)} lines with 2D-related information:\")\n",
        "        for line in relevant[:10]:\n",
        "            print(f\"  - {line.strip()}\")\n",
        "    else:\n",
        "        print(\"No specific 2D keywords found in messages\")\n",
        "else:\n",
        "    print(\"No computation messages available for this 2D plan\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  OPTIONAL: Use your own project instead\n",
        "\n",
        "your_project_path = Path(r\"D:\\yourprojectpath\")\n",
        "\n",
        "init_ras_project(your_project_path, \"6.6\")\n",
        "plan_number = \"01\"  # Plan number to use for this notebook \n",
        "\n",
        "\n",
        "\n",
        "### If you use this code cell, don't run the previous cell or change to markdown\n",
        "### NOTE: Ensure the HDF Results file was generated by HEC-RAS Version 6.x or above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Project Dataframes using 'ras' Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show ras object info\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ras.get_hdf_entries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find Paths for Results and Geometry HDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the plan HDF path for the plan_number defined above\n",
        "plan_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plan_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternate: Get the geometry HDF path if you are extracting geometry elements from the geometry HDF\n",
        "geom_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'Geom Path'].values[0] + '.hdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_hdf_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAS-Commander's Decorators Allow for Flexible Function Calling\n",
        "You can call most of the functions in the HDF* Classes using any of the following:\n",
        "1. Plan/Geometry Number (with or without leading zeros):\n",
        "   - \"01\", \"1\" - Plan/geometry number as string\n",
        "   - 1 - Plan/geometry number as integer\n",
        "   - \"p01\", \"p1\" - Plan number with 'p' prefix\n",
        "2. Direct File Paths:\n",
        "   - pathlib.Path object pointing to HDF file\n",
        "   - String path to HDF file\n",
        "\n",
        "3. h5py.File Objects:\n",
        "   - Already opened HDF file object\n",
        "\n",
        "The @standardize_input decorator handles all these input types consistently:\n",
        "   - Validates the input exists and is accessible\n",
        "   - Converts to proper pathlib.Path object\n",
        "   - Handles RAS object references\n",
        "   - Provides logging and error handling\n",
        "\n",
        "This flexibility makes it easier to work with HDF files in different contexts while maintaining consistent behavior \n",
        "across the codebase, and helps prevent strict typing from introducing unnecessary friction for LLM Coding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2D HDF Data Extraction Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract runtime and compute time data as dataframe\n",
        "print(\"\\nExtracting runtime and compute time data\")\n",
        "runtime_df = HdfResultsPlan.get_runtime_data(hdf_path=plan_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n",
        "print(geom_hdf_path)\n",
        "\n",
        "# For the example project, plan 06 is associated with geometry 09\n",
        "# If you want to call the geometry by number, call RasHdfGeom functions with a number\n",
        "# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfUtils for extracting projection\n",
        "print(\"\\nExtracting Projection from HDF\")\n",
        "projection = HdfBase.get_projection(hdf_path=geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfPlan for geometry-related operations\n",
        "print(\"\\nExtracting Geometry Information\")\n",
        "geom_attrs = HdfPlan.get_geometry_information(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfMesh for geometry-related operations\n",
        "print(\"\\nListing 2D Flow Area Names\")\n",
        "flow_area_names = HdfMesh.get_mesh_area_names(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"2D Flow Area Name (returned as list):\")\n",
        "flow_area_names\n",
        "# Note: this is returned as a list because it is used internally by other functions.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get 2D Flow Area Attributes (get_mesh_area_attributes)\n",
        "print(\"\\nExtracting 2D Flow Area Attributes\")\n",
        "flow_area_attributes = HdfMesh.get_mesh_area_attributes(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flow_area_attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get 2D Flow Area Perimeter Polygons (get_mesh_areas)\n",
        "print(\"\\nExtracting 2D Flow Area Perimeter Polygons\")\n",
        "mesh_areas = HdfMesh.get_mesh_areas(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mesh_areas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Map of Mesh Areas\n",
        "if generate_plots:\n",
        "    # Plot the 2D Flow Area Perimeter Polygons\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none')\n",
        "\n",
        "    # Add labels for each polygon\n",
        "    for idx, row in mesh_areas.iterrows():\n",
        "        centroid = row.geometry.centroid\n",
        "        # Check if 'Name' column exists, otherwise use a default label\n",
        "        label = row.get('Name', f'Area {idx}')\n",
        "        ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n",
        "\n",
        "    plt.title('2D Flow Area Perimeter Polygons')\n",
        "    plt.xlabel('Easting')\n",
        "    plt.ylabel('Northing')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh cell faces as geodatframe\n",
        "mesh_cell_faces_gdf = HdfMesh.get_mesh_cell_faces(geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mesh_cell_faces_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.collections import LineCollection\n",
        "import numpy as np\n",
        "\n",
        "# Calculate and display statistics\n",
        "print(\"\\nMesh Cell Faces Statistics:\")\n",
        "print(f\"Total number of cell faces: {len(mesh_cell_faces_gdf)}\")\n",
        "print(f\"Number of unique meshes: {mesh_cell_faces_gdf['mesh_name'].nunique()}\")\n",
        "\n",
        "if generate_maps:\n",
        "    # Plot the mesh cell faces more efficiently\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Convert all geometries to numpy arrays at once for faster plotting\n",
        "    lines = [list(zip(*line.xy)) for line in mesh_cell_faces_gdf.geometry]\n",
        "    lines_collection = LineCollection(lines, colors='blue', linewidth=0.5, alpha=0.5)\n",
        "    ax.add_collection(lines_collection)\n",
        "\n",
        "    # Set plot title and labels\n",
        "    plt.title('Mesh Cell Faces')\n",
        "    plt.xlabel('Easting')\n",
        "    plt.ylabel('Northing')\n",
        "\n",
        "    # Calculate centroids once and store as numpy arrays\n",
        "    centroids = np.array([[geom.centroid.x, geom.centroid.y] for geom in mesh_cell_faces_gdf.geometry])\n",
        "\n",
        "    # Create scatter plot with numpy arrays\n",
        "    scatter = ax.scatter(\n",
        "        centroids[:, 0],\n",
        "        centroids[:, 1], \n",
        "        c=mesh_cell_faces_gdf['face_id'],\n",
        "        cmap='viridis',\n",
        "        s=1,\n",
        "        alpha=0.5\n",
        "    )\n",
        "    plt.colorbar(scatter, label='Face ID')\n",
        "\n",
        "    # Set axis limits based on data bounds\n",
        "    ax.set_xlim(centroids[:, 0].min(), centroids[:, 0].max())\n",
        "    ax.set_ylim(centroids[:, 1].min(), centroids[:, 1].max())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is False\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to find the nearest cell face to a given point\n",
        "def find_nearest_cell_face(point, cell_faces_df):\n",
        "    \"\"\"\n",
        "    Find the nearest cell face to a given point.\n",
        "\n",
        "    Args:\n",
        "        point (shapely.geometry.Point): The input point.\n",
        "        cell_faces_df (GeoDataFrame): DataFrame containing cell face linestrings.\n",
        "\n",
        "    Returns:\n",
        "        int: The face_id of the nearest cell face.\n",
        "        float: The distance to the nearest cell face.\n",
        "    \"\"\"\n",
        "    # Calculate distances from the input point to all cell faces\n",
        "    distances = cell_faces_df.geometry.distance(point)\n",
        "\n",
        "    # Find the index of the minimum distance\n",
        "    nearest_index = distances.idxmin()\n",
        "\n",
        "    # Get the face_id and distance of the nearest cell face\n",
        "    nearest_face_id = cell_faces_df.loc[nearest_index, 'face_id']\n",
        "    nearest_distance = distances[nearest_index]\n",
        "\n",
        "    return nearest_face_id, nearest_distance\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nFinding the nearest cell face to a given point\")\n",
        "\n",
        "# Create a sample point (you can replace this with any point of interest)\n",
        "from shapely.geometry import Point\n",
        "from geopandas import GeoDataFrame\n",
        "\n",
        "# Get the centroid of the mesh cell faces\n",
        "print(\"Getting Centroid of 2D Mesh Polygon\")\n",
        "centroid = mesh_cell_faces_gdf.geometry.union_all().centroid\n",
        "\n",
        "# Create GeoDataFrame with the centroid point, using same CRS as mesh_cell_faces_gdf\n",
        "sample_point = GeoDataFrame(\n",
        "    {'geometry': [centroid]}, \n",
        "    crs=mesh_cell_faces_gdf.crs\n",
        ")\n",
        "\n",
        "if not mesh_cell_faces_gdf.empty and not sample_point.empty:\n",
        "    print(\"Searching Cell\")\n",
        "    nearest_face_id, distance = find_nearest_cell_face(sample_point.geometry.iloc[0], mesh_cell_faces_gdf)\n",
        "    print(f\"Nearest cell face to point {sample_point.geometry.iloc[0].coords[0]}:\")\n",
        "    print(f\"Face ID: {nearest_face_id}\")\n",
        "    print(f\"Distance: {distance:.2f} units\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate map of cell faces with sample point and nearest cell face shown\n",
        "if generate_maps:\n",
        "    # Visualize the result\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "    # Plot all cell faces\n",
        "    mesh_cell_faces_gdf.plot(ax=ax, color='blue', linewidth=0.5, alpha=0.5, label='Cell Faces')\n",
        "    \n",
        "    # Plot the sample point\n",
        "    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n",
        "    \n",
        "    # Plot the nearest cell face\n",
        "    nearest_face = mesh_cell_faces_gdf[mesh_cell_faces_gdf['face_id'] == nearest_face_id]\n",
        "    nearest_face.plot(ax=ax, color='green', linewidth=2, alpha=0.7, label='Nearest Face')\n",
        "    \n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    ax.set_title('Nearest Cell Face to Sample Point')\n",
        "    \n",
        "    # Add legend and grid\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    \n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Cell Polygons\n",
        "print(\"\\nExample 6: Extracting Cell Polygons\")\n",
        "cell_polygons_df = HdfMesh.get_mesh_cell_polygons(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cell_polygons_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cell polygons\n",
        "\n",
        "if generate_maps:\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Plot cell polygons\n",
        "    cell_polygons_df.plot(ax=ax, edgecolor='blue', facecolor='none')\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    ax.set_title('2D Flow Area Cell Polygons')\n",
        "\n",
        "    # Add grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Cell Info\n",
        "print(\"\\nExample 5: Extracting Cell Info\")\n",
        "cell_info_df = HdfMesh.get_mesh_cell_points(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cell_info_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot cell centers\n",
        "\n",
        "if generate_maps:\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Plot cell centers\n",
        "    cell_info_df.plot(ax=ax, color='red', markersize=5)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    ax.set_title('2D Flow Area Cell Centers')\n",
        "\n",
        "    # Add grid\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to find the nearest cell center to a given point\n",
        "def find_nearest_cell(point, cell_centers_df):\n",
        "    \"\"\"\n",
        "    Find the nearest cell center to a given point.\n",
        "\n",
        "    Args:\n",
        "        point (shapely.geometry.Point): The input point.\n",
        "        cell_centers_df (GeoDataFrame): DataFrame containing cell center points.\n",
        "\n",
        "    Returns:\n",
        "        int: The cell_id of the nearest cell.\n",
        "        float: The distance to the nearest cell center.\n",
        "    \"\"\"\n",
        "    # Calculate distances from the input point to all cell centers\n",
        "    distances = cell_centers_df.geometry.distance(point)\n",
        "\n",
        "    # Find the index of the minimum distance\n",
        "    nearest_index = distances.idxmin()\n",
        "\n",
        "    # Get the cell_id and distance of the nearest cell\n",
        "    nearest_cell_id = cell_centers_df.loc[nearest_index, 'cell_id']\n",
        "    nearest_distance = distances[nearest_index]\n",
        "\n",
        "    return nearest_cell_id, nearest_distance\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nFinding the nearest cell to a given point\")\n",
        "\n",
        "# Sample point was created in a previous code cell \n",
        "\n",
        "# Get the projection from the geometry file\n",
        "# projection = HdfUtils.get_projection(hdf_path=geom_hdf_path) # This was done in a previous code cell\n",
        "if projection:\n",
        "    print(f\"Using projection: {projection}\")\n",
        "else:\n",
        "    print(\"No projection information found. Using default CRS.\")\n",
        "    projection = \"EPSG:4326\"  # Default to WGS84 if no projection is found\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the CRS of the sample point matches the cell_info_df\n",
        "if sample_point.crs != cell_info_df.crs:\n",
        "    sample_point = sample_point.to_crs(cell_info_df.crs)\n",
        "\n",
        "nearest_cell_id, distance = find_nearest_cell(sample_point.geometry.iloc[0], cell_info_df)\n",
        "print(f\"Nearest cell to point {sample_point.geometry.iloc[0].coords[0]}:\")\n",
        "print(f\"Cell ID: {nearest_cell_id}\")\n",
        "print(f\"Distance: {distance:.2f} units\")\n",
        "\n",
        "if generate_maps:\n",
        "    # Visualize the result\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Plot all cell centers\n",
        "    cell_info_df.plot(ax=ax, color='blue', markersize=5, alpha=0.5, label='Cell Centers')\n",
        "\n",
        "    # Plot the sample point\n",
        "    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n",
        "\n",
        "    # Plot the nearest cell center\n",
        "    nearest_cell = cell_info_df[cell_info_df['cell_id'] == nearest_cell_id]\n",
        "    nearest_cell.plot(ax=ax, color='green', markersize=100, alpha=0.7, label='Nearest Cell')\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    ax.set_title('Nearest Cell to Sample Point')\n",
        "\n",
        "    # Add legend and grid\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get geometry structures attributes\n",
        "print(\"\\nGetting geometry structures attributes as Dataframe\")\n",
        "geom_structures_attrs = HdfStruc.get_geom_structures_attrs(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_structures_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Paths and Functions for each type of structure: \n",
        "\n",
        "# Getting geometry structures attributes\n",
        "# Geometry structures attributes:\n",
        "# Bridge/Culvert Count: 0\n",
        "# Connection Count: 4\n",
        "# Has Bridge Opening (2D): 0\n",
        "# Inline Structure Count: 0\n",
        "# Lateral Structure Count: 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get boundary condition lines\n",
        "print(\"\\nExtracting Boundary Condition Lines as Geodataframe\")\n",
        "bc_lines_df = HdfBndry.get_bc_lines(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bc_lines_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Boundary Condition Lines with Perimeter\n",
        "\n",
        "if generate_maps:\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    if not mesh_areas.empty:\n",
        "        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n",
        "        \n",
        "        # Add labels for each polygon\n",
        "        for idx, row in mesh_areas.iterrows():\n",
        "            centroid = row.geometry.centroid\n",
        "            label = row.get('Name', f'Area {idx}')\n",
        "            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n",
        "\n",
        "    # Plot boundary condition lines\n",
        "    if not bc_lines_df.empty:\n",
        "        bc_lines_df.plot(ax=ax, color='red', linewidth=2, label='Boundary Condition Lines')\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Easting')\n",
        "    ax.set_ylabel('Northing')\n",
        "    ax.set_title('2D Flow Area Perimeter Polygons and Boundary Condition Lines')\n",
        "\n",
        "    # Add grid and legend\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n",
        "# Plot 2D Flow Area Perimeter Polygons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Breaklines as Geodataframe\n",
        "print(\"\\nExtracting Breaklines\")\n",
        "breaklines_gdf = HdfBndry.get_breaklines(geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "breaklines_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot breaklines and 2D Flow Area Perimeter Polygons\n",
        "\n",
        "if generate_plots:\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Plot 2D Flow Area Perimeter Polygons\n",
        "    if not mesh_areas.empty:\n",
        "        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n",
        "        \n",
        "        # Add labels for each polygon\n",
        "        for idx, row in mesh_areas.iterrows():\n",
        "            centroid = row.geometry.centroid\n",
        "            label = row.get('Name', f'Area {idx}')\n",
        "            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n",
        "\n",
        "    # Plot breaklines\n",
        "    if not breaklines_gdf.empty:\n",
        "        breaklines_gdf.plot(ax=ax, color='blue', linewidth=2, label='Breaklines')\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Easting')\n",
        "    ax.set_ylabel('Northing')\n",
        "    ax.set_title('2D Flow Area Perimeter Polygons and Breaklines')\n",
        "\n",
        "    # Add grid and legend\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get structures as GeoDatframe\n",
        "structures_gdf = HdfStruc.get_structures(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "structures_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get boundary condition lines as GeoDatframe\n",
        "bc_lines_gdf = HdfBndry.get_bc_lines(geom_hdf_path)\n",
        "print(\"\\nBoundary Condition Lines:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bc_lines_gdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dev Note: Need to add function for Reference Lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get reference points as Geodataframe\n",
        "ref_points_gdf = HdfBndry.get_reference_points(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nReference Points:\")\n",
        "ref_points_gdf\n",
        "# There are no reference points in this example project (for demonstration only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Refinement Regions\n",
        "refinement_regions_df = HdfBndry.get_refinement_regions(geom_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "refinement_regions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Refinement Regions\n",
        "\n",
        "if not refinement_regions_df.empty:\n",
        "    print(\"Refinement Regions DataFrame:\")\n",
        "    display(refinement_regions_df.head())\n",
        "    \n",
        "    # Plot refinement regions\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    refinement_regions_df.plot(ax=ax, column='CellSize', legend=True, \n",
        "                               legend_kwds={'label': 'Cell Size', 'orientation': 'horizontal'},\n",
        "                               cmap='viridis')\n",
        "    ax.set_title('2D Mesh Area Refinement Regions')\n",
        "    ax.set_xlabel('Easting')\n",
        "    ax.set_ylabel('Northing')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No refinement regions found in the geometry file.\")\n",
        "\n",
        "# Analyze Refinement Regions\n",
        "if not refinement_regions_df.empty:\n",
        "    print(\"\\nRefinement Regions Analysis:\")\n",
        "    print(f\"Total number of refinement regions: {len(refinement_regions_df)}\")\n",
        "    print(\"\\nCell Size Statistics:\")\n",
        "    print(refinement_regions_df['CellSize'].describe())\n",
        "    \n",
        "    # Group by Shape Type\n",
        "    shape_type_counts = refinement_regions_df['ShapeType'].value_counts()\n",
        "    print(\"\\nRefinement Region Shape Types:\")\n",
        "    print(shape_type_counts)\n",
        "    \n",
        "    # Plot Shape Type distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shape_type_counts.plot(kind='bar')\n",
        "    plt.title('Distribution of Refinement Region Shape Types')\n",
        "    plt.xlabel('Shape Type')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Plan Parameters \n",
        "plan_parameters_df = HdfPlan.get_plan_parameters(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plan_parameters_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract volume accounting data\n",
        "volume_accounting_df = HdfResultsPlan.get_volume_accounting(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "volume_accounting_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RasPlanHdf Class Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get plan start time as datetime object\n",
        "start_time = HdfPlan.get_plan_start_time(plan_hdf_path)\n",
        "print(f\"Simulation start time: {start_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulation start time: 2018-09-09 00:00:00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get plan end time as datetime object\n",
        "end_time = HdfPlan.get_plan_end_time(plan_hdf_path)\n",
        "print(f\"Simulation end time: {end_time}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulation end time: 2018-09-14 00:00:00"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get maximum iteration count for mesh cells\n",
        "max_iter_gdf = HdfResultsMesh.get_mesh_max_iter(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_iter_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get cell coordinates \n",
        "cell_coords = HdfMesh.get_mesh_cell_points(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Mesh Max Iterations\n",
        "\n",
        "if generate_maps:\n",
        "    # Extract x and y coordinates from the geometry column\n",
        "    max_iter_gdf['x'] = max_iter_gdf['geometry'].apply(lambda geom: geom.x if geom is not None else None)\n",
        "    max_iter_gdf['y'] = max_iter_gdf['geometry'].apply(lambda geom: geom.y if geom is not None else None)\n",
        "\n",
        "    # Remove rows with None coordinates\n",
        "    max_iter_gdf = max_iter_gdf.dropna(subset=['x', 'y'])\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    scatter = ax.scatter(max_iter_gdf['x'], max_iter_gdf['y'], \n",
        "                         c=max_iter_gdf['cell_last_iteration'], \n",
        "                         cmap='viridis', \n",
        "                         s=1)\n",
        "\n",
        "    # Customize the plot\n",
        "    ax.set_title('Max Iterations per Cell')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    plt.colorbar(scatter, label='Max Iterations')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")\n",
        "\n",
        "# Print the first few rows of the dataframe for verification\n",
        "print(\"\\nFirst few rows of the dataframe:\")\n",
        "max_iter_gdf[['mesh_name', 'cell_id', 'geometry']]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List top 10 points for Max Iteration per Cell\n",
        "# Sort the dataframe by cell_last_iteration in descending order\n",
        "top_iterations = max_iter_gdf.sort_values(by='cell_last_iteration', ascending=False).head(10)\n",
        "\n",
        "# Create a more informative display with coordinates\n",
        "print(\"\\nTop 10 Cells with Highest Iteration Counts:\")\n",
        "top_iterations_display = top_iterations.copy()\n",
        "top_iterations_display['x_coord'] = top_iterations_display['geometry'].apply(lambda geom: round(geom.x, 2))\n",
        "top_iterations_display['y_coord'] = top_iterations_display['geometry'].apply(lambda geom: round(geom.y, 2))\n",
        "\n",
        "# Display the results in a formatted table\n",
        "print(top_iterations_display[['mesh_name', 'cell_id', 'cell_last_iteration', 'x_coord', 'y_coord']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh maximum water surface elevation as Geodataframe\n",
        "max_ws_gdf = HdfResultsMesh.get_mesh_max_ws(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Dataframe Attributes (the HDF Attributes are also imported as Geoataframe Attributes)\n",
        "max_ws_gdf.attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_ws_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the max water surface as a map\n",
        "if generate_maps:\n",
        "    # Extract x and y coordinates from the geometry column\n",
        "    max_ws_gdf['x'] = max_ws_gdf['geometry'].apply(lambda geom: geom.x if geom is not None else None)\n",
        "    max_ws_gdf['y'] = max_ws_gdf['geometry'].apply(lambda geom: geom.y if geom is not None else None)\n",
        "\n",
        "    # Remove rows with None coordinates\n",
        "    max_ws_gdf = max_ws_gdf.dropna(subset=['x', 'y'])\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    scatter = ax.scatter(max_ws_gdf['x'], max_ws_gdf['y'], \n",
        "                         c=max_ws_gdf['maximum_water_surface'], \n",
        "                         cmap='viridis', \n",
        "                         s=10)\n",
        "\n",
        "    # Customize the plot\n",
        "    ax.set_title('Max Water Surface per Cell')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    plt.colorbar(scatter, label='Max Water Surface (ft)')\n",
        "\n",
        "    # Add grid lines\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Increase font size for better readability\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    # Adjust layout to prevent cutting off labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"generate_maps is set to False\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the time of the max water surface elevation (WSEL)\n",
        "if generate_maps:\n",
        "    import matplotlib.dates as mdates\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Convert the 'maximum_water_surface_time' to datetime objects\n",
        "    max_ws_gdf['max_wsel_time'] = pd.to_datetime(max_ws_gdf['maximum_water_surface_time'])\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Convert datetime to hours since the start for colormap\n",
        "    min_time = max_ws_gdf['max_wsel_time'].min()\n",
        "    color_values = (max_ws_gdf['max_wsel_time'] - min_time).dt.total_seconds() / 3600  # Convert to hours\n",
        "\n",
        "    scatter = ax.scatter(max_ws_gdf['x'], max_ws_gdf['y'], \n",
        "                        c=color_values, \n",
        "                        cmap='viridis', \n",
        "                        s=10)\n",
        "\n",
        "    # Customize the plot\n",
        "    ax.set_title('Time of Maximum Water Surface Elevation per Cell')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "\n",
        "    # Set up the colorbar\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Hours since simulation start')\n",
        "\n",
        "    # Format the colorbar ticks to show hours\n",
        "    cbar.set_ticks(range(0, int(color_values.max()) + 1, 6))  # Set ticks every 6 hours\n",
        "    cbar.set_ticklabels([f'{h}h' for h in range(0, int(color_values.max()) + 1, 6)])\n",
        "\n",
        "    # Add grid lines\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Increase font size for better readability\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    # Adjust layout to prevent cutting off labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    # Find the overall maximum WSEL and its time\n",
        "    max_wsel_row = max_ws_gdf.loc[max_ws_gdf['maximum_water_surface'].idxmax()]\n",
        "    hours_since_start = (max_wsel_row['max_wsel_time'] - min_time).total_seconds() / 3600\n",
        "    print(f\"\\nOverall Maximum WSEL: {max_wsel_row['maximum_water_surface']:.2f} ft\")\n",
        "    print(f\"Time of Overall Maximum WSEL: {max_wsel_row['max_wsel_time']}\")\n",
        "    print(f\"Hours since simulation start: {hours_since_start:.2f} hours\")\n",
        "    print(f\"Location of Overall Maximum WSEL: X={max_wsel_row['x']}, Y={max_wsel_row['y']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh minimum water surface elevation as geodataframe\n",
        "min_ws_gdf = HdfResultsMesh.get_mesh_min_ws(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_ws_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh maximum face velocity as geodataframe\n",
        "max_face_v_gdf = HdfResultsMesh.get_mesh_max_face_v(plan_hdf_path)\n",
        "print(\"\\nMesh Max Face Velocity:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_face_v_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract midpoint coordinates from the LineString geometries\n",
        "max_face_v_gdf['x'] = max_face_v_gdf['geometry'].apply(lambda geom: geom.centroid.x)\n",
        "max_face_v_gdf['y'] = max_face_v_gdf['geometry'].apply(lambda geom: geom.centroid.y)\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "scatter = ax.scatter(max_face_v_gdf['x'], max_face_v_gdf['y'], \n",
        "                    c=max_face_v_gdf['maximum_face_velocity'].abs(),\n",
        "                    cmap='viridis',\n",
        "                    s=10)\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_title('Max Face Velocity per Face')\n",
        "ax.set_xlabel('X Coordinate') \n",
        "ax.set_ylabel('Y Coordinate')\n",
        "plt.colorbar(scatter, label='Max Face Velocity (ft/s)')\n",
        "\n",
        "# Add grid lines\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Increase font size for better readability\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "# Adjust layout to prevent cutting off labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh minimum face velocity as geodataframe\n",
        "min_face_v_gdf = HdfResultsMesh.get_mesh_min_face_v(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Min Face Velocity:\")\n",
        "min_face_v_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh max water surface error as geodataframe\n",
        "\n",
        "max_ws_err_gdf = HdfResultsMesh.get_mesh_max_ws_err(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Max Water Surface Error:\")\n",
        "max_ws_err_gdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot max water surface error\n",
        "\n",
        "if generate_maps:\n",
        "# Extract x and y coordinates from the geometry points, handling None values\n",
        "    max_ws_err_gdf['x'] = max_ws_err_gdf['geometry'].apply(lambda geom: geom.x if geom is not None else None)\n",
        "    max_ws_err_gdf['y'] = max_ws_err_gdf['geometry'].apply(lambda geom: geom.y if geom is not None else None)\n",
        "\n",
        "    # Remove any rows with None coordinates\n",
        "    max_ws_err_gdf = max_ws_err_gdf.dropna(subset=['x', 'y'])\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    scatter = ax.scatter(max_ws_err_gdf['x'], max_ws_err_gdf['y'],\n",
        "                        c=max_ws_err_gdf['cell_maximum_water_surface_error'],\n",
        "                        cmap='viridis',\n",
        "                        s=10)\n",
        "\n",
        "    # Customize the plot\n",
        "    ax.set_title('Max Water Surface Error per Cell')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    plt.colorbar(scatter, label='Max Water Surface Error (ft)')\n",
        "\n",
        "    # Add grid lines\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Increase font size for better readability\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    # Adjust layout to prevent cutting off labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort Dataframe to show top 10 maximum water surface errors:\n",
        "max_ws_err_gdf_sorted = max_ws_err_gdf.sort_values(by='cell_maximum_water_surface_error', ascending=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nTop 10 maximum water surface errors:\")\n",
        "max_ws_err_gdf_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant) as geodataframe\n",
        "max_courant_gdf = HdfResultsMesh.get_mesh_summary(plan_hdf_path, var=\"Maximum Face Courant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Summary Output (Maximum Courant):\")\n",
        "max_courant_gdf.attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_courant_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot max Courant number\n",
        "\n",
        "# Convert to GeoDataFrame if not empty\n",
        "if not max_courant_gdf.empty:\n",
        "    if generate_maps:\n",
        "        # Get centroids of line geometries for plotting\n",
        "        max_courant_gdf['centroid'] = max_courant_gdf.geometry.centroid\n",
        "        max_courant_gdf['x'] = max_courant_gdf.centroid.x\n",
        "        max_courant_gdf['y'] = max_courant_gdf.centroid.y\n",
        "\n",
        "        # Create the plot\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        scatter = ax.scatter(max_courant_gdf['x'], max_courant_gdf['y'],\n",
        "                        c=max_courant_gdf['maximum_face_courant'],\n",
        "                        cmap='viridis',\n",
        "                        s=10)\n",
        "\n",
        "        # Customize the plot\n",
        "        ax.set_title('Max Courant Number per Face')\n",
        "        ax.set_xlabel('X Coordinate')\n",
        "        ax.set_ylabel('Y Coordinate')\n",
        "        plt.colorbar(scatter, label='Max Courant Number')\n",
        "\n",
        "        # Add grid lines\n",
        "        ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Increase font size for better readability\n",
        "        plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "        # Adjust layout to prevent cutting off labels\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "# Print the first few rows of the dataframe for verification\n",
        "print(\"\\nFirst few rows of the Courant number dataframe:\")\n",
        "max_courant_gdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant)\n",
        "\n",
        "max_face_shear_gdf = HdfResultsMesh.get_mesh_summary(plan_hdf_path, var=\"Maximum Face Shear Stress\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Summary Output (Maximum Face Shear Stress:\")\n",
        "print(max_face_shear_gdf.attrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_face_shear_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot max face shear stress\n",
        "\n",
        "if generate_maps and not max_face_shear_gdf.empty:\n",
        "    # Calculate centroids of the line geometries and extract coordinates\n",
        "    max_face_shear_gdf['centroid'] = max_face_shear_gdf['geometry'].apply(lambda line: line.centroid)\n",
        "    max_face_shear_gdf['x'] = max_face_shear_gdf['centroid'].apply(lambda point: point.x)\n",
        "    max_face_shear_gdf['y'] = max_face_shear_gdf['centroid'].apply(lambda point: point.y)\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    scatter = ax.scatter(max_face_shear_gdf['x'], max_face_shear_gdf['y'],\n",
        "                        c=max_face_shear_gdf['maximum_face_shear_stress'],\n",
        "                        cmap='viridis',\n",
        "                        s=10)\n",
        "\n",
        "    # Customize the plot\n",
        "    ax.set_title('Max Face Shear Stress per Face')\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    plt.colorbar(scatter, label='Max Face Shear Stress (PSF)')\n",
        "\n",
        "    # Add grid lines\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Increase font size for better readability\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "    # Adjust layout to prevent cutting off labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh summary output for Minimum Water Surface as geodataframe\n",
        "summary_gdf_min_ws = HdfResultsMesh.get_mesh_summary(plan_hdf_path, var=\"Minimum Water Surface\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Summary Output (Minimum Water Surface):\")\n",
        "summary_gdf_min_ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh summary output for Minimum Face Velocity as geodataframe\n",
        "summary_gdf_min_fv = HdfResultsMesh.get_mesh_summary(plan_hdf_path, var=\"Minimum Face Velocity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Summary Output (Minimum Face Velocity):\")\n",
        "summary_gdf_min_fv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh summary output for Cell Cumulative Iteration as geodataframe\n",
        "summary_gdf_cum_iter = HdfResultsMesh.get_mesh_summary(plan_hdf_path, var=\"Cell Cumulative Iteration\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nMesh Summary Output (Cell Cumulative Iteration):\")\n",
        "summary_gdf_cum_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh timeseries output as xarray\n",
        "# The mesh name is part of the timeseries HDF path, so you must pass the mesh_name to retrieve it\n",
        "\n",
        "# Get mesh areas from previous code cell\n",
        "mesh_areas = HdfMesh.get_mesh_area_names(geom_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mesh_areas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the first mesh area name to extract mesh timeseries output as xarray\n",
        "timeseries_xr = HdfResultsMesh.get_mesh_timeseries(plan_hdf_path, mesh_areas[0], \"Water Surface\") # Use the first 2D flow area name for mesh_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timeseries_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time Series Output Variables for Cells\n",
        "# \n",
        "# Variable Name: Description\n",
        "# Water Surface: Water surface elevation\n",
        "# Depth: Water depth\n",
        "# Velocity: Magnitude of velocity\n",
        "# Velocity X: X-component of velocity\n",
        "# Velocity Y: Y-component of velocity\n",
        "# Froude Number: Froude number\n",
        "# Courant Number: Courant number\n",
        "# Shear Stress: Shear stress on the bed\n",
        "# Bed Elevation: Elevation of the bed\n",
        "# Precipitation Rate: Rate of precipitation\n",
        "# Infiltration Rate: Rate of infiltration\n",
        "# Evaporation Rate: Rate of evaporation\n",
        "# Percolation Rate: Rate of percolation\n",
        "# Groundwater Elevation: Elevation of groundwater\n",
        "# Groundwater Depth: Depth to groundwater\n",
        "# Groundwater Flow: Groundwater flow rate\n",
        "# Groundwater Velocity: Magnitude of groundwater velocity\n",
        "# Groundwater Velocity X: X-component of groundwater velocity\n",
        "# Groundwater Velocity Y: Y-component of groundwater velocity\n",
        "# \n",
        "# These variables are available for time series output at the cell level in 2D flow areas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh cells timeseries output as xarray\n",
        "cells_timeseries_xr = HdfResultsMesh.get_mesh_cells_timeseries(plan_hdf_path, mesh_areas[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cells_timeseries_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot WSE Time Series Data (Random Cell ID) \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if generate_plots:\n",
        "    import numpy as np\n",
        "    import random\n",
        "\n",
        "    # Extract Water Surface data\n",
        "    water_surface = cells_timeseries_xr[mesh_areas[0]]['Water Surface']\n",
        "\n",
        "    # Get the time values\n",
        "    time_values = water_surface.coords['time'].values\n",
        "\n",
        "    # Pick a random cell_id\n",
        "    random_cell_id = random.choice(water_surface.coords['cell_id'].values)\n",
        "\n",
        "    # Extract the water surface elevation time series for the random cell\n",
        "    wsel_timeseries = water_surface.sel(cell_id=random_cell_id)\n",
        "\n",
        "    # Find the peak value and its index\n",
        "    peak_value = wsel_timeseries.max().item()\n",
        "    peak_index = wsel_timeseries.argmax().item()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(time_values, wsel_timeseries, label=f'Cell ID: {random_cell_id}')\n",
        "    plt.scatter(time_values[peak_index], peak_value, color='red', s=100, zorder=5)\n",
        "    plt.annotate(f'Peak: {peak_value:.2f} ft', \n",
        "                (time_values[peak_index], peak_value),\n",
        "                xytext=(10, 10), textcoords='offset points',\n",
        "                ha='left', va='bottom',\n",
        "                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "    plt.title(f'Water Surface Elevation Time Series for Random Cell (ID: {random_cell_id})')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Water Surface Elevation (ft)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Log the plotting action\n",
        "    logging.info(f\"Plotted water surface elevation time series for random cell ID: {random_cell_id}\")\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    # Print some statistics\n",
        "    print(f\"Statistics for Cell ID {random_cell_id}:\")\n",
        "    print(f\"Minimum WSEL: {wsel_timeseries.min().item():.2f} ft\")\n",
        "    print(f\"Maximum WSEL: {peak_value:.2f} ft\")\n",
        "    print(f\"Mean WSEL: {wsel_timeseries.mean().item():.2f} ft\")\n",
        "    print(f\"Time of peak: {time_values[peak_index]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get mesh faces timeseries output as xarray\n",
        "faces_timeseries_xr = HdfResultsMesh.get_mesh_faces_timeseries(plan_hdf_path, mesh_areas[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "faces_timeseries_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Random Face Results and Label Peak, Plus Map View\n",
        "\n",
        "if generate_maps:\n",
        "\n",
        "    # Select a random valid face ID number\n",
        "    random_face = np.random.randint(0, faces_timeseries_xr.sizes['face_id'])\n",
        "\n",
        "    # Extract time series data for the selected face\n",
        "    variable = 'face_velocity'  # We could also use 'face_flow'\n",
        "    face_data = faces_timeseries_xr[variable].sel(face_id=random_face)\n",
        "\n",
        "    # Find peak value and its corresponding time\n",
        "    peak_value = face_data.max().item()\n",
        "    peak_time = face_data.idxmax().values\n",
        "\n",
        "    # Plot time series\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(faces_timeseries_xr.time, face_data)\n",
        "    plt.title(f'{variable.capitalize()} Time Series for Face {random_face}')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel(f'{variable.capitalize()} ({faces_timeseries_xr.attrs[\"units\"]})')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Annotate the peak point\n",
        "    plt.annotate(f'Peak: ({peak_time}, {peak_value:.2f})', \n",
        "                (peak_time, peak_value),\n",
        "                xytext=(10, 10), textcoords='offset points',\n",
        "                arrowprops=dict(arrowstyle=\"->\"))\n",
        "\n",
        "    # Check for negative values and label the minimum if present\n",
        "    min_value = face_data.min().item()\n",
        "    if min_value < 0:\n",
        "        min_time = face_data.idxmin().values\n",
        "        plt.annotate(f'Min: ({min_time}, {min_value:.2f})', \n",
        "                    (min_time, min_value),\n",
        "                    xytext=(10, -10), textcoords='offset points',\n",
        "                    arrowprops=dict(arrowstyle=\"->\"))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Create map view plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "\n",
        "    # Calculate mesh faces extents with 10% buffer\n",
        "    faces_bounds = mesh_cell_faces_gdf.total_bounds\n",
        "    x_min, y_min, x_max, y_max = faces_bounds\n",
        "    buffer_x = (x_max - x_min) * 0.1\n",
        "    buffer_y = (y_max - y_min) * 0.1\n",
        "    plot_xlim = [x_min - buffer_x, x_max + buffer_x]\n",
        "    plot_ylim = [y_min - buffer_y, y_max + buffer_y]\n",
        "\n",
        "    # Set plot limits before adding terrain\n",
        "    ax.set_xlim(plot_xlim)\n",
        "    ax.set_ylim(plot_ylim)\n",
        "\n",
        "    # Add the terrain TIFF to the map, clipped to our desired extent\n",
        "    tiff_path = Path.cwd() / 'example_projects' / 'BaldEagleCrkMulti2D' / 'Terrain' / 'Terrain50.baldeagledem.tif'\n",
        "    with rasterio.open(tiff_path) as src:\n",
        "        show(src, ax=ax, cmap='terrain', alpha=0.5)\n",
        "        \n",
        "    # Reset the limits after terrain plot\n",
        "    ax.set_xlim(plot_xlim)\n",
        "    ax.set_ylim(plot_ylim)\n",
        "\n",
        "    # Plot all faces in gray\n",
        "    mesh_cell_faces_gdf.plot(ax=ax, color='lightgray', alpha=0.5, zorder=2)\n",
        "\n",
        "    # Get the selected face geometry\n",
        "    selected_face = mesh_cell_faces_gdf[mesh_cell_faces_gdf['face_id'] == random_face]\n",
        "\n",
        "    # Highlight the selected face in red\n",
        "    selected_face.plot(\n",
        "        ax=ax, \n",
        "        color='red',\n",
        "        linewidth=2,\n",
        "        label=f'Selected Face (ID: {random_face})',\n",
        "        zorder=3\n",
        "    )\n",
        "\n",
        "    # Get bounds of selected face for zoomed inset\n",
        "    bounds = selected_face.geometry.bounds.iloc[0]\n",
        "    x_center = (bounds.iloc[0] + bounds.iloc[2]) / 2\n",
        "    y_center = (bounds.iloc[1] + bounds.iloc[3]) / 2\n",
        "    buffer = max(bounds.iloc[2] - bounds.iloc[0], bounds.iloc[3] - bounds.iloc[1]) * 2\n",
        "\n",
        "    # Create zoomed inset with a larger size, inside the map frame\n",
        "    axins = inset_axes(ax, width=\"70%\", height=\"70%\", loc='lower right',\n",
        "                    bbox_to_anchor=(0.65, 0.05, 0.35, 0.35),\n",
        "                    bbox_transform=ax.transAxes)\n",
        "\n",
        "    # Plot terrain and faces in inset\n",
        "    with rasterio.open(tiff_path) as src:\n",
        "        show(src, ax=axins, cmap='terrain', alpha=0.5)\n",
        "        \n",
        "    # Plot zoomed view in inset\n",
        "    mesh_cell_faces_gdf.plot(ax=axins, color='lightgray', alpha=0.5, zorder=2)\n",
        "    selected_face.plot(ax=axins, color='red', linewidth=2, zorder=3)\n",
        "\n",
        "    # Set inset limits with slightly more context\n",
        "    axins.set_xlim(x_center - buffer/1.5, x_center + buffer/1.5)\n",
        "    axins.set_ylim(y_center - buffer/1.5, y_center + buffer/1.5)\n",
        "\n",
        "    # Remove inset ticks for cleaner look\n",
        "    axins.set_xticks([])\n",
        "    axins.set_yticks([])\n",
        "\n",
        "    # Add a border to the inset\n",
        "    for spine in axins.spines.values():\n",
        "        spine.set_edgecolor('black')\n",
        "        spine.set_linewidth(1.5)\n",
        "\n",
        "    # Create connection lines between main plot and inset\n",
        "    # Get the selected face centroid for connection point\n",
        "    centroid = selected_face.geometry.centroid.iloc[0]\n",
        "    con1 = ConnectionPatch(\n",
        "        xyA=(centroid.x, centroid.y), coordsA=ax.transData,\n",
        "        xyB=(0.02, 0.98), coordsB=axins.transAxes,\n",
        "        arrowstyle=\"-\", linestyle=\"--\", color=\"gray\", alpha=0.6\n",
        "    )\n",
        "    con2 = ConnectionPatch(\n",
        "        xyA=(centroid.x, centroid.y), coordsA=ax.transData,\n",
        "        xyB=(0.98, 0.02), coordsB=axins.transAxes,\n",
        "        arrowstyle=\"-\", linestyle=\"--\", color=\"gray\", alpha=0.6\n",
        "    )\n",
        "\n",
        "    ax.add_artist(con1)\n",
        "    ax.add_artist(con2)\n",
        "\n",
        "    # Add title and legend to main plot\n",
        "    ax.set_title('Mesh Face Map View with Terrain')\n",
        "    ax.legend()\n",
        "\n",
        "    # Ensure equal aspect ratio while maintaining our desired extents\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary information\n",
        "    print(f\"Random Face: {random_face}\")\n",
        "    print(f\"Peak Value: {peak_value:.2f} {faces_timeseries_xr.attrs['units']} at {peak_time}\")\n",
        "    if min_value < 0:\n",
        "        print(f\"Minimum Value: {min_value:.2f} {faces_timeseries_xr.attrs['units']} at {min_time}\")\n",
        "\n",
        "    # Log the plotting action\n",
        "    logging.info(f\"Plotted mesh face time series and map view for random face ID: {random_face} with terrain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get meteorology precipitation attributes\n",
        "meteo_precip_attrs = HdfPlan.get_plan_met_precip(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "meteo_precip_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get results unsteady attributes\n",
        "results_unsteady_attrs = HdfResultsPlan.get_unsteady_info(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_unsteady_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get results unsteady summary attributes\n",
        "results_unsteady_summary_attrs = HdfResultsPlan.get_unsteady_summary(plan_hdf_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_unsteady_summary_attrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get results volume accounting attributes\n",
        "volume_accounting_attrs = HdfResultsPlan.get_volume_accounting(plan_hdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "volume_accounting_attrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Compute Messages as String\n",
        "print(\"Extracting Compute Messages\")\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def extract_string_from_hdf(results_hdf_filename: str, hdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract string from HDF object at a given path\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    results_hdf_filename : str\n",
        "        Name of the HDF file\n",
        "    hdf_path : str\n",
        "        Path of the object in the HDF file\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Extracted string from the specified HDF object\n",
        "    \"\"\"\n",
        "    with h5py.File(results_hdf_filename, 'r') as hdf_file:\n",
        "        try:\n",
        "            hdf_object = hdf_file[hdf_path]\n",
        "            if isinstance(hdf_object, h5py.Group):\n",
        "                return f\"Group: {hdf_path}\\nContents: {list(hdf_object.keys())}\"\n",
        "            elif isinstance(hdf_object, h5py.Dataset):\n",
        "                data = hdf_object[()]\n",
        "                if isinstance(data, bytes):\n",
        "                    return data.decode('utf-8')\n",
        "                elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':\n",
        "                    return [v.decode('utf-8') for v in data]\n",
        "                else:\n",
        "                    return str(data)\n",
        "            else:\n",
        "                return f\"Unsupported object type: {type(hdf_object)}\"\n",
        "        except KeyError:\n",
        "            return f\"Path not found: {hdf_path}\"\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    results_summary_string = extract_string_from_hdf(plan_hdf_path, '/Results/Summary/Compute Messages (text)')\n",
        "    print(\"Compute Messages:\")\n",
        "    \n",
        "    # Parse and print the compute messages in a more visually friendly way\n",
        "    messages = results_summary_string[0].split('\\r\\n')\n",
        "    \n",
        "    for message in messages:\n",
        "        if message.strip():  # Skip empty lines\n",
        "            if ':' in message:\n",
        "                key, value = message.split(':', 1)\n",
        "                print(f\"{key.strip():40} : {value.strip()}\")\n",
        "            else:\n",
        "                print(f\"\\n{message.strip()}\")\n",
        "    \n",
        "    # Print computation summary in a table format\n",
        "    print(\"\\nComputation Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Computation Task':<30} {'Time':<20}\")\n",
        "    print(\"-\" * 50)\n",
        "    for line in messages:\n",
        "        if 'Computation Task' in line:\n",
        "            task, time = line.split('\\t')\n",
        "            print(f\"{task:<30} {time:<20}\")\n",
        "    \n",
        "    print(\"\\nComputation Speed:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Task':<30} {'Simulation/Runtime':<20}\")\n",
        "    print(\"-\" * 50)\n",
        "    for line in messages:\n",
        "        if 'Computation Speed' in line:\n",
        "            task, speed = line.split('\\t')\n",
        "            print(f\"{task:<30} {speed:<20}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting compute messages: {str(e)}\")\n",
        "    print(\"\\nNote: If 'Results/Summary Output' is not in the file structure, it might indicate that the simulation didn't complete successfully or the results weren't saved properly.\")\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring HDF Datasets with HdfBase.get_dataset_info\n",
        "This allows users to find HDF information that is not included in the ras-commander library.  Find the path in HDFView and set the group_path below to explore the HDF datasets and attributes.  Then, use the output to write your own function to extract the data.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get HDF Paths with Properties (For Exploring HDF Files)\n",
        "HdfBase.get_dataset_info(plan_number, group_path=\"/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For HDF datasets that are not supported by the RAS-Commadner library, provide the dataset path to HdfBase.get_dataset_info and provide the output to an LLM along with a relevent HDF* class(es) to generate new functions that extend the library's coverage.   "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\12_2d_hdf_data_extraction pipes and pumps.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import shutil\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path  # Ensure pathlib is imported for file operations\n",
        "import pyproj\n",
        "from shapely.geometry import Point, LineString, Polygon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use Example Project or Load Your Own Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the Pipes Beta project from HEC and run plan 01\n",
        "\n",
        "# Define the path to the Pipes Beta project\n",
        "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
        "pipes_ex_path = current_dir / \"example_projects\" / \"Davis\"\n",
        "import logging\n",
        "\n",
        "# Check if Pipes Beta.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
        "hdf_file = pipes_ex_path / \"DavisStormSystem.p02.hdf\"\n",
        "\n",
        "if not hdf_file.exists():\n",
        "    # Initialize RasExamples and extract the Pipes Beta project\n",
        "    RasExamples.extract_project([\"Davis\"])\n",
        "\n",
        "    # Initialize the RAS project using the ras. (Pipe Networks are only supported in versions 6.6 and above)\n",
        "    init_ras_project(pipes_ex_path, \"6.6\")\n",
        "    logging.info(f\"Pipes Beta project initialized with folder: {ras.project_folder}\")\n",
        "    \n",
        "    logging.info(f\"Pipes Beta object id: {id(ras)}\")\n",
        "    \n",
        "    # Define the plan number to execute\n",
        "    plan_number = \"02\"\n",
        "\n",
        "    # Update run flags for the project\n",
        "    RasPlan.update_run_flags(\n",
        "        plan_number,\n",
        "        geometry_preprocessor=True,\n",
        "        unsteady_flow_simulation=True,\n",
        "        run_sediment=False,\n",
        "        post_processor=True,\n",
        "        floodplain_mapping=False\n",
        "    )\n",
        "\n",
        "    # Execute Plan 06 using RasCmdr for Pipes Beta\n",
        "    print(f\"Executing Plan {plan_number} for the Pipes Beta Creek project...\")\n",
        "    success_pipes_ex = RasCmdr.compute_plan(plan_number)\n",
        "    if success_pipes_ex:\n",
        "        print(f\"Plan {plan_number} executed successfully for Pipes Beta.\\n\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed for Pipes Beta.\\n\")\n",
        "else:\n",
        "    print(\"Pipes Beta.p06.hdf already exists. Skipping project extraction and plan execution.\")\n",
        "    # Initialize the RAS project using the ras.\n",
        "    init_ras_project(pipes_ex_path, \"6.6\")\n",
        "    plan_number = \"02\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  OPTIONAL: Use your own project instead\n",
        "\n",
        "your_project_path = Path(r\"D:\\yourprojectpath\")\n",
        "\n",
        "init_ras_project(your_project_path, \"6.6\")\n",
        "plan_number = \"01\"  # Plan number to use for this notebook \n",
        "\n",
        "\n",
        "\n",
        "### If you use this code cell, don't run the previous cell or change to markdown\n",
        "### NOTE: Ensure the HDF Results file was generated by HEC-RAS Version 6.x or above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Project Dataframes using 'ras' Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Plan DataFrame for the project:\")\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nUnsteady DataFrame for the project:\")\n",
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nBoundary Conditions DataFrame for the project:\")\n",
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get HDF Results Entries (only present when results are present)\n",
        "ras.get_hdf_entries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find Paths for Results and Geometry HDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the plan HDF path for the plan_number defined above\n",
        "plan_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plan_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternate: Get the geometry HDF path if you are extracting geometry elements from the geometry HDF\n",
        "geom_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'Geom Path'].values[0] + '.hdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geom_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract runtime and compute time data\n",
        "print(\"\\nExtracting runtime and compute time data\")\n",
        "runtime_df = HdfResultsPlan.get_runtime_data(hdf_path=plan_number)\n",
        "runtime_df\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2D Models with Pipe Networks: HDF Data Extraction Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pipe conduits\n",
        "pipe_conduits_gdf = HdfPipe.get_pipe_conduits(\"02\") # NOTE: Here we use the plan number instead of the path variable.  The library decorators ensure this maps correctly.  \n",
        "print(\"\\nPipe Conduits: pipe_conduits_gdf\")\n",
        "pipe_conduits_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the pipe conduit linestrings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a new figure with a specified size\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "# Plot each linestring from the GeoDataFrame\n",
        "for idx, row in pipe_conduits_gdf.iterrows():\n",
        "    # Extract coordinates from the linestring\n",
        "    x_coords, y_coords = row['Polyline'].xy\n",
        "    \n",
        "    # Plot the linestring\n",
        "    plt.plot(x_coords, y_coords, 'b-', linewidth=1, alpha=0.7)\n",
        "    \n",
        "    # Add vertical line markers at endpoints\n",
        "    plt.plot([x_coords[0]], [y_coords[0]], 'x', color='black', markersize=4)\n",
        "    plt.plot([x_coords[-1]], [y_coords[-1]], 'x', color='black', markersize=4)\n",
        "    \n",
        "    # Calculate center point of the line\n",
        "    center_x = (x_coords[0] + x_coords[-1]) / 2\n",
        "    center_y = (y_coords[0] + y_coords[-1]) / 2\n",
        "    \n",
        "    # Add pipe name label at center, oriented top-right\n",
        "    plt.text(center_x, center_y, f'{row[\"Name\"]}', fontsize=8, \n",
        "             verticalalignment='bottom', horizontalalignment='left',\n",
        "             rotation=45)  # 45 degree angle for top-right orientation\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Pipe Conduit Network Layout')\n",
        "plt.xlabel('Easting')\n",
        "plt.ylabel('Northing')\n",
        "\n",
        "# Add grid\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Adjust layout to prevent label clipping\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the first 2 terrain profiles\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract terrain profiles from the GeoDataFrame\n",
        "terrain_profiles = pipe_conduits_gdf['Terrain_Profiles'].tolist()\n",
        "\n",
        "# Create separate plots for the first 2 terrain profiles\n",
        "for i in range(2):\n",
        "    profile = terrain_profiles[i]\n",
        "    \n",
        "    # Unzip the profile into x and y coordinates\n",
        "    x_coords, y_coords = zip(*profile)\n",
        "    \n",
        "    # Create a new figure for each profile\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x_coords, y_coords, marker='o', linestyle='-', color='g', alpha=0.7)\n",
        "    \n",
        "    # Add title and labels\n",
        "    plt.title(f'Terrain Profile {i + 1}')\n",
        "    plt.xlabel('Distance along profile (m)')\n",
        "    plt.ylabel('Elevation (m)')\n",
        "    \n",
        "    # Add grid\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    \n",
        "    # Adjust layout to prevent label clipping\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Display the plot\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "#HdfUtils.get_hdf5_dataset_info(plan_hdf_path, \"/Geometry/Pipe Nodes/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pipe nodes\n",
        "pipe_nodes_gdf = HdfPipe.get_pipe_nodes(plan_hdf_path)\n",
        "print(\"\\nPipe Nodes:\")\n",
        "pipe_nodes_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "#HdfUtils.get_hdf5_dataset_info(plan_hdf_path, \"/Geometry/Pipe Networks/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pipe network data\n",
        "pipe_network_gdf = HdfPipe.get_pipe_network(plan_hdf_path)\n",
        "print(\"\\nPipe Network Data:\")\n",
        "pipe_network_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pump stations\n",
        "pump_stations_gdf = HdfPump.get_pump_stations(plan_hdf_path)\n",
        "print(\"\\nPump Stations:\")\n",
        "pump_stations_gdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get pump groups\n",
        "pump_groups_df = HdfPump.get_pump_groups(plan_hdf_path)\n",
        "print(\"\\nPump Groups:\")\n",
        "pump_groups_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use HdfUtils for extracting projection\n",
        "print(\"\\nExtracting Projection from HDF\")\n",
        "projection = HdfBase.get_projection(hdf_path=geom_hdf_path)\n",
        "print(f\"Projection: {projection}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set CRS for GeoDataFrames\n",
        "if projection:\n",
        "    pipe_conduits_gdf.set_crs(projection, inplace=True, allow_override=True)\n",
        "    pipe_nodes_gdf.set_crs(projection, inplace=True, allow_override=True)\n",
        "\n",
        "print(\"Pipe Conduits GeoDataFrame columns:\")\n",
        "print(pipe_conduits_gdf.columns)\n",
        "\n",
        "print(\"\\nPipe Nodes GeoDataFrame columns:\")\n",
        "print(pipe_nodes_gdf.columns)\n",
        "\n",
        "perimeter_polygons = HdfMesh.get_mesh_areas(geom_hdf_path)\n",
        "if projection:\n",
        "    perimeter_polygons.set_crs(projection, inplace=True, allow_override=True)\n",
        "    \n",
        "print(\"\\nPerimeter Polygons GeoDataFrame columns:\")\n",
        "print(perimeter_polygons.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from shapely import wkt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(28, 20))\n",
        "\n",
        "# Plot cell polygons with 50% transparency behind the pipe network\n",
        "cell_polygons_df = HdfMesh.get_mesh_cell_polygons(geom_hdf_path)\n",
        "if not cell_polygons_df.empty:\n",
        "    cell_polygons_df.plot(ax=ax, edgecolor='lightgray', facecolor='lightgray', alpha=0.5)\n",
        "\n",
        "# Plot pipe conduits - the Polyline column already contains LineString geometries\n",
        "pipe_conduits_gdf.set_geometry('Polyline', inplace=True)\n",
        "\n",
        "# Plot each pipe conduit individually to ensure all are shown\n",
        "for idx, row in pipe_conduits_gdf.iterrows():\n",
        "    ax.plot(*row.Polyline.xy, color='blue', linewidth=1)\n",
        "\n",
        "# Create a colormap for node elevations\n",
        "norm = plt.Normalize(pipe_nodes_gdf['Invert Elevation'].min(), \n",
        "                    pipe_nodes_gdf['Invert Elevation'].max())\n",
        "cmap = plt.cm.viridis\n",
        "\n",
        "# Plot pipe nodes colored by invert elevation\n",
        "scatter = ax.scatter(pipe_nodes_gdf.geometry.x, pipe_nodes_gdf.geometry.y,\n",
        "                    c=pipe_nodes_gdf['Invert Elevation'], \n",
        "                    cmap=cmap, norm=norm,\n",
        "                    s=100)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('Invert Elevation (ft)', rotation=270, labelpad=15)\n",
        "\n",
        "# Add combined labels for invert and drop inlet elevations\n",
        "for idx, row in pipe_nodes_gdf.iterrows():\n",
        "    label_text = \"\"  # Initialize label_text for each node\n",
        "    # Add drop inlet elevation label if it exists and is not NaN\n",
        "    if 'Drop Inlet Elevation' in row and not np.isnan(row['Drop Inlet Elevation']):\n",
        "        label_text += f\"TOC: {row['Drop Inlet Elevation']:.2f}\\n\"\n",
        "    label_text += f\"INV: {row['Invert Elevation']:.2f}\"\n",
        "    \n",
        "    ax.annotate(label_text,\n",
        "                xy=(row.geometry.x, row.geometry.y),\n",
        "                xytext=(-10, -10), textcoords='offset points',\n",
        "                fontsize=8,\n",
        "                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
        "\n",
        "# Add perimeter polygons \n",
        "if not perimeter_polygons.empty:\n",
        "    perimeter_polygons.plot(ax=ax, edgecolor='black', facecolor='none')\n",
        "\n",
        "# Create proxy artists for legend\n",
        "conduit_line = mlines.Line2D([], [], color='blue', label='Conduits')\n",
        "node_point = mlines.Line2D([], [], color='blue', marker='o', linestyle='None',\n",
        "                          markersize=10, label='Nodes')\n",
        "perimeter = mpatches.Patch(facecolor='none', edgecolor='black',\n",
        "                          label='Perimeter Polygons')\n",
        "\n",
        "ax.set_title('Pipe Network with Node Elevations')\n",
        "\n",
        "# Add legend with proxy artists\n",
        "ax.legend(handles=[conduit_line, node_point, perimeter])\n",
        "\n",
        "# Set aspect ratio to be equal and adjust limits\n",
        "ax.set_aspect('equal', 'datalim')\n",
        "ax.autoscale_view()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize pump stations on a map\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "pump_stations_gdf.plot(ax=ax, color='green', markersize=50, label='Pump Station')\n",
        "\n",
        "# Add perimeter polygons\n",
        "if not perimeter_polygons.empty:\n",
        "    perimeter_polygons.plot(ax=ax, edgecolor='black', facecolor='none', label='Perimeter Polygons')\n",
        "\n",
        "ax.set_title('Pump Station Location')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Get pipe network timeseries\n",
        "valid_variables = [\n",
        "    \"Cell Courant\", \"Cell Water Surface\", \"Face Flow\", \"Face Velocity\",\n",
        "    \"Face Water Surface\", \"Pipes/Pipe Flow DS\", \"Pipes/Pipe Flow US\",\n",
        "    \"Pipes/Vel DS\", \"Pipes/Vel US\", \"Nodes/Depth\", \"Nodes/Drop Inlet Flow\",\n",
        "    \"Nodes/Water Surface\"\n",
        "]\n",
        "\n",
        "print(\"Valid variables for pipe network timeseries:\")\n",
        "for var in valid_variables:\n",
        "    print(f\"- {var}\")\n",
        "\n",
        "# Extract pipe network timeseries for each valid pipe-related variable\n",
        "pipe_variables = [var for var in valid_variables if var.startswith(\"Pipes/\") or var.startswith(\"Nodes/\")]\n",
        "\n",
        "for variable in pipe_variables:\n",
        "    try:\n",
        "        pipe_timeseries = HdfPipe.get_pipe_network_timeseries(plan_hdf_path, variable=variable)\n",
        "        print(f\"\\nPipe Network Timeseries ({variable}):\")\n",
        "        print(pipe_timeseries.head())  # Print first few rows to avoid overwhelming output\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {variable}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipe Network Timeseries Data Description\n",
        "\n",
        "The `get_pipe_network_timeseries` function returns an xarray DataArray for each variable. Here's a general description of the data structure:\n",
        "\n",
        "1. **Pipes/Pipe Flow DS and Pipes/Pipe Flow US**:\n",
        "   - Dimensions: time, location (pipe IDs)\n",
        "   - Units: ft^3/s (cubic feet per second)\n",
        "   - Description: Represents the flow rate at the downstream (DS) and upstream (US) ends of pipes over time.\n",
        "\n",
        "2. **Pipes/Vel DS and Pipes/Vel US**:\n",
        "   - Dimensions: time, location (pipe IDs)\n",
        "   - Units: ft/s (feet per second)\n",
        "   - Description: Shows the velocity at the downstream (DS) and upstream (US) ends of pipes over time.\n",
        "\n",
        "3. **Nodes/Depth**:\n",
        "   - Dimensions: time, location (node IDs)\n",
        "   - Units: ft (feet)\n",
        "   - Description: Indicates the depth of water at each node over time.\n",
        "\n",
        "4. **Nodes/Drop Inlet Flow**:\n",
        "   - Dimensions: time, location (node IDs)\n",
        "   - Units: cfs (cubic feet per second)\n",
        "   - Description: Represents the flow rate through drop inlets at each node over time.\n",
        "\n",
        "5. **Nodes/Water Surface**:\n",
        "   - Dimensions: time, location (node IDs)\n",
        "   - Units: ft (feet)\n",
        "   - Description: Shows the water surface elevation at each node over time.\n",
        "\n",
        "General notes:\n",
        "- The 'time' dimension represents the simulation timesteps.\n",
        "- The 'location' dimension represents either pipe IDs or node IDs, depending on the variable.\n",
        "- The number of timesteps and locations may vary depending on the specific dataset and simulation setup.\n",
        "- Negative values in flow variables may indicate reverse flow direction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the variables we want to plot\n",
        "variables = [\n",
        "    \"Pipes/Pipe Flow DS\", \"Pipes/Pipe Flow US\", \"Pipes/Vel DS\", \"Pipes/Vel US\",\n",
        "    \"Nodes/Depth\", \"Nodes/Drop Inlet Flow\", \"Nodes/Water Surface\"\n",
        "]\n",
        "\n",
        "# Create a separate plot for each variable\n",
        "for variable in variables:\n",
        "    try:\n",
        "        # Get the data for the current variable\n",
        "        data = HdfPipe.get_pipe_network_timeseries(plan_hdf_path, variable=variable)\n",
        "        \n",
        "        # Create a new figure\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        \n",
        "        # Pick one random location\n",
        "        random_location = random.choice(data.location.values)\n",
        "        \n",
        "        # Determine if it's a pipe or node variable\n",
        "        if variable.startswith(\"Pipes/\"):\n",
        "            location_type = \"Conduit ID\"\n",
        "        else:\n",
        "            location_type = \"Node ID\"\n",
        "        \n",
        "        # Plot the data for the randomly selected location\n",
        "        ax.plot(data.time, data.sel(location=random_location), label=f'{location_type} {random_location}')\n",
        "        \n",
        "        # Set the title and labels\n",
        "        ax.set_title(f'{variable} Over Time ({location_type} {random_location})')\n",
        "        ax.set_xlabel('Time')  # Corrected from ax.xlabel to ax.set_xlabel\n",
        "        ax.set_ylabel(f'{variable} ({data.attrs[\"units\"]})')  # Corrected from ax.ylabel to ax.set_ylabel\n",
        "        \n",
        "        # Format the x-axis to show dates nicely\n",
        "        ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M'))\n",
        "        plt.xticks(rotation=45)\n",
        "        \n",
        "        # Add a legend\n",
        "        ax.legend(title=location_type, loc='upper left')\n",
        "        \n",
        "        # Adjust the layout\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting {variable}: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 8: Get pump station timeseries\n",
        "pump_station_name = pump_stations_gdf.iloc[0]['Name']  # Get the first pump station name\n",
        "# Use the results_pump_station_timeseries method \n",
        "pump_timeseries = HdfPump.get_pump_station_timeseries(plan_hdf_path, pump_station=pump_station_name)\n",
        "print(f\"\\nPump Station Timeseries ({pump_station_name}):\")\n",
        "print(pump_timeseries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "HdfBase.get_dataset_info(plan_hdf_path, \"/Geometry/Pump Stations/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the pump station timeseries data\n",
        "pump_station_name = pump_stations_gdf.iloc[0]['Name']  # Get the first pump station name\n",
        "pump_timeseries = HdfPump.get_pump_station_timeseries(plan_hdf_path, pump_station=pump_station_name)\n",
        "\n",
        "# Print the pump station timeseries\n",
        "print(f\"\\nPump Station Timeseries ({pump_station_name}):\")\n",
        "print(pump_timeseries)\n",
        "\n",
        "# Create a new figure for plotting\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Plot each variable in the timeseries\n",
        "for variable in pump_timeseries.coords['variable'].values:\n",
        "    data = pump_timeseries.sel(variable=variable)\n",
        "    \n",
        "    # Decode units to strings\n",
        "    unit = pump_timeseries.attrs[\"units\"][list(pump_timeseries.coords[\"variable\"].values).index(variable)][1].decode('utf-8')\n",
        "    \n",
        "    # Check if the variable is 'Pumps on' to plot it differently\n",
        "    if variable == 'Pumps on':\n",
        "        # Plot with color based on the on/off status\n",
        "        colors = ['green' if val > 0 else 'red' for val in data.values.flatten()]\n",
        "        ax.scatter(pump_timeseries['time'], data, label=f'{variable} ({unit})', color=colors)\n",
        "    else:\n",
        "        ax.plot(pump_timeseries['time'], data, label=f'{variable} ({unit})')\n",
        "        \n",
        "        # Label the peak values\n",
        "        peak_time = pump_timeseries['time'][data.argmax()]\n",
        "        peak_value = data.max()\n",
        "        ax.annotate(f'Peak: {peak_value:.2f}', xy=(peak_time, peak_value), \n",
        "                    xytext=(peak_time, peak_value + 0.1 * peak_value), \n",
        "                    arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
        "                    fontsize=10, color='black', ha='center')\n",
        "\n",
        "# Set the title and labels\n",
        "ax.set_title(f'Timeseries Data for Pump Station: {pump_station_name}')\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylabel('Values')\n",
        "\n",
        "# Format the x-axis to show dates nicely\n",
        "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M'))\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add a legend\n",
        "ax.legend(title='Variables', loc='upper left')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring HDF Datasets with HdfBase.get_dataset_info\n",
        "This allows users to find HDF information that is not included in the ras-commander library.  Find the path in HDFView and set the group_path below to explore the HDF datasets and attributes.  Then, use the output to write your own function to extract the data.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use get_hdf5_dataset_info function to get Pipe Conduits data:\n",
        "HdfBase.get_dataset_info(plan_hdf_path, \"/Geometry/Pipe Conduits/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For HDF datasets that are not supported by the RAS-Commander library, provide the dataset path to HdfBase.get_dataset_info and provide the output to an LLM along with a relevent HDF* class(es) to generate new functions that extend the library's coverage.   "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\13_2d_detail_face_data_extraction.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:12.556104Z",
          "iopub.status.busy": "2025-11-17T17:54:12.555873Z",
          "iopub.status.idle": "2025-11-17T17:54:14.120379Z",
          "shell.execute_reply": "2025-11-17T17:54:14.119652Z"
        }
      },
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEC-RAS 2D Detail Face Data Extraction Examples\n",
        "\n",
        "This notebook demonstrates how to extract detailed 2D face data, display individual cell face results and calculate a discharge weighted velocity using a user-provided profile line located where cell faces are perpendicular to flow. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup\n",
        "Uncomment and run package installation commands if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.123844Z",
          "iopub.status.busy": "2025-11-17T17:54:14.123420Z",
          "iopub.status.idle": "2025-11-17T17:54:14.126763Z",
          "shell.execute_reply": "2025-11-17T17:54:14.126205Z"
        }
      },
      "outputs": [],
      "source": [
        "# Install ras-commander from pip (uncomment to install if needed)\n",
        "#!pip install ras-commander\n",
        "# This installs ras-commander and all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.129391Z",
          "iopub.status.busy": "2025-11-17T17:54:14.129086Z",
          "iopub.status.idle": "2025-11-17T17:54:14.133196Z",
          "shell.execute_reply": "2025-11-17T17:54:14.132652Z"
        }
      },
      "outputs": [],
      "source": [
        "# Enable this cell for local development version of ras-commander\n",
        "import os\n",
        "import sys      \n",
        "from pathlib import Path\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.135307Z",
          "iopub.status.busy": "2025-11-17T17:54:14.135029Z",
          "iopub.status.idle": "2025-11-17T17:54:14.271967Z",
          "shell.execute_reply": "2025-11-17T17:54:14.271464Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import all required modules\n",
        "#from ras_commander import *  # Import all ras-commander modules\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "import xarray as xr\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import psutil  # For getting system CPU info\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path  # Ensure pathlib is imported for file operations\n",
        "import pyproj\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "import xarray as xr\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import ConnectionPatch\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.274202Z",
          "iopub.status.busy": "2025-11-17T17:54:14.273727Z",
          "iopub.status.idle": "2025-11-17T17:54:14.277517Z",
          "shell.execute_reply": "2025-11-17T17:54:14.276983Z"
        }
      },
      "outputs": [],
      "source": [
        "# This cell will try to import the pip package, if it fails it will \n",
        "# add the parent directory to the Python path and try to import again\n",
        "# This assumes you are working in a subfolder of the ras-commander repository\n",
        "# This allows a user's revisions to be tested locally without installing the package\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Flexible imports to allow for development without installation \n",
        "#  ** Use this version with Jupyter Notebooks **\n",
        "try:\n",
        "    # Try to import from the installed package\n",
        "    from ras_commander import *\n",
        "except ImportError:\n",
        "    # If the import fails, add the parent directory to the Python path\n",
        "    import os\n",
        "    current_file = Path(os.getcwd()).resolve()\n",
        "    rascmdr_directory = current_file.parent\n",
        "    sys.path.append(str(rascmdr_directory))\n",
        "    print(\"Loading ras-commander from local dev copy\")\n",
        "    # Now try to import again\n",
        "    from ras_commander import *\n",
        "print(\"ras_commander imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: This notebook relies on the Chippewa 2D Project along with:\n",
        " - A user-generated GeoJSON containing the proposed profile lines\n",
        " - An example is provided in the \"data\" subfolder with name profile_lines_chippewa2D.geojson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.280146Z",
          "iopub.status.busy": "2025-11-17T17:54:14.279857Z",
          "iopub.status.idle": "2025-11-17T17:54:14.329842Z",
          "shell.execute_reply": "2025-11-17T17:54:14.329348Z"
        }
      },
      "outputs": [],
      "source": [
        "# Download the Chippewa_2D project from HEC and run plan 02\n",
        "\n",
        "# Define the path to the Chippewa_2D project\n",
        "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
        "bald_eagle_path = current_dir / \"example_projects\" / \"Chippewa_2D\"\n",
        "\n",
        "# Check if Chippewa_2D.p02.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
        "hdf_file = bald_eagle_path / \"Chippewa_2D.p02.hdf\"\n",
        "\n",
        "if not hdf_file.exists():\n",
        "    # Initialize RasExamples and extract the Chippewa_2D project\n",
        "    RasExamples.extract_project([\"Chippewa_2D\"])\n",
        "\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    from ras_commander import get_logger  # Import after sys.path is set if not installed\n",
        "    logger = get_logger(__name__)\n",
        "    logger.info(f\"Bald Eagle project initialized with folder: {ras.project_folder}\")\n",
        "    logger.info(f\"Bald Eagle object id: {id(ras)}\")\n",
        "    \n",
        "    # Define the plan number to execute\n",
        "    plan_number = \"02\"\n",
        "\n",
        "    # Update run flags for the project\n",
        "    RasPlan.update_run_flags(\n",
        "        plan_number,\n",
        "        geometry_preprocessor=True,\n",
        "        unsteady_flow_simulation=True,\n",
        "        run_sediment=False,\n",
        "        post_processor=True,\n",
        "        floodplain_mapping=False\n",
        "    )\n",
        "    \n",
        "    # Enable Face Flow output - required for discharge-weighted velocity calculations\n",
        "    # This adds \"HDF Additional Output Variable=Face Flow\" to the plan file\n",
        "    RasPlan.add_hdf_output_variable(plan_number, \"Face Flow\")\n",
        "    print(\"Enabled Face Flow HDF output for discharge-weighted velocity calculations\")\n",
        "\n",
        "    # Execute Plan 02 using RasCmdr for Bald Eagle\n",
        "    print(f\"Executing Plan {plan_number} for the Chippewa_2D project...\")\n",
        "    success_bald_eagle = RasCmdr.compute_plan(plan_number)\n",
        "    if success_bald_eagle:\n",
        "        print(f\"Plan {plan_number} executed successfully for Chippewa_2D.\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed for Chippewa_2D.\")\n",
        "else:\n",
        "    print(\"Chippewa_2D.p02.hdf already exists. Skipping project extraction and plan execution.\")\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    plan_number = \"02\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.331640Z",
          "iopub.status.busy": "2025-11-17T17:54:14.331416Z",
          "iopub.status.idle": "2025-11-17T17:54:14.344359Z",
          "shell.execute_reply": "2025-11-17T17:54:14.343847Z"
        }
      },
      "outputs": [],
      "source": [
        "# Show ras object info\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.346857Z",
          "iopub.status.busy": "2025-11-17T17:54:14.346423Z",
          "iopub.status.idle": "2025-11-17T17:54:14.353301Z",
          "shell.execute_reply": "2025-11-17T17:54:14.352835Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.355344Z",
          "iopub.status.busy": "2025-11-17T17:54:14.355126Z",
          "iopub.status.idle": "2025-11-17T17:54:14.365901Z",
          "shell.execute_reply": "2025-11-17T17:54:14.365356Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.367964Z",
          "iopub.status.busy": "2025-11-17T17:54:14.367735Z",
          "iopub.status.idle": "2025-11-17T17:54:14.377692Z",
          "shell.execute_reply": "2025-11-17T17:54:14.377108Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.get_hdf_entries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find Paths for Results and Geometry HDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.380161Z",
          "iopub.status.busy": "2025-11-17T17:54:14.379777Z",
          "iopub.status.idle": "2025-11-17T17:54:14.382257Z",
          "shell.execute_reply": "2025-11-17T17:54:14.381800Z"
        }
      },
      "outputs": [],
      "source": [
        "# Define the HDF input path as Plan Number\n",
        "\n",
        "plan_number = \"02\"  # Assuming we're using plan 01 as in the previous code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.384232Z",
          "iopub.status.busy": "2025-11-17T17:54:14.384011Z",
          "iopub.status.idle": "2025-11-17T17:54:14.388036Z",
          "shell.execute_reply": "2025-11-17T17:54:14.387530Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get the plan HDF path for the plan_number defined above\n",
        "plan_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.389926Z",
          "iopub.status.busy": "2025-11-17T17:54:14.389698Z",
          "iopub.status.idle": "2025-11-17T17:54:14.393011Z",
          "shell.execute_reply": "2025-11-17T17:54:14.392538Z"
        }
      },
      "outputs": [],
      "source": [
        "plan_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.394925Z",
          "iopub.status.busy": "2025-11-17T17:54:14.394707Z",
          "iopub.status.idle": "2025-11-17T17:54:14.398227Z",
          "shell.execute_reply": "2025-11-17T17:54:14.397802Z"
        }
      },
      "outputs": [],
      "source": [
        "# Alternate: Get the geometry HDF path if you are extracting geometry elements from the geometry HDF \n",
        "geom_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'Geom Path'].values[0] + '.hdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.399868Z",
          "iopub.status.busy": "2025-11-17T17:54:14.399669Z",
          "iopub.status.idle": "2025-11-17T17:54:14.402798Z",
          "shell.execute_reply": "2025-11-17T17:54:14.402343Z"
        }
      },
      "outputs": [],
      "source": [
        "geom_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.404424Z",
          "iopub.status.busy": "2025-11-17T17:54:14.404225Z",
          "iopub.status.idle": "2025-11-17T17:54:14.421904Z",
          "shell.execute_reply": "2025-11-17T17:54:14.421457Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Extract runtime and compute time data\n",
        "print(\"\\nExample 2: Extracting runtime and compute time data\")\n",
        "runtime_df = HdfResultsPlan.get_runtime_data(hdf_path=plan_number)\n",
        "if runtime_df is not None:\n",
        "    runtime_df\n",
        "else:\n",
        "    print(\"No runtime data found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.423699Z",
          "iopub.status.busy": "2025-11-17T17:54:14.423468Z",
          "iopub.status.idle": "2025-11-17T17:54:14.426313Z",
          "shell.execute_reply": "2025-11-17T17:54:14.425857Z"
        }
      },
      "outputs": [],
      "source": [
        "# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n",
        "print(geom_hdf_path)\n",
        "\n",
        "# For the example project, plan 02 is associated with geometry 09\n",
        "# If you want to call the geometry by number, call RasHdfGeom functions with a number\n",
        "# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.428153Z",
          "iopub.status.busy": "2025-11-17T17:54:14.427939Z",
          "iopub.status.idle": "2025-11-17T17:54:14.442345Z",
          "shell.execute_reply": "2025-11-17T17:54:14.441804Z"
        }
      },
      "outputs": [],
      "source": [
        "# Use HdfUtils for extracting projection\n",
        "print(\"\\nExtracting Projection from HDF\")\n",
        "projection = HdfBase.get_projection(hdf_path=geom_hdf_path)\n",
        "if projection:\n",
        "    print(f\"Projection: {projection}\")\n",
        "else:\n",
        "    print(\"No projection information found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.444852Z",
          "iopub.status.busy": "2025-11-17T17:54:14.444544Z",
          "iopub.status.idle": "2025-11-17T17:54:14.447286Z",
          "shell.execute_reply": "2025-11-17T17:54:14.446835Z"
        }
      },
      "outputs": [],
      "source": [
        "# Set the  to USA Contiguous Albers Equal Area Conic (USGS version)\n",
        "# Note, we would usually call the projection function in HdfMesh but the projection is not set in this example project\n",
        "projection = 'EPSG:5070'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.449057Z",
          "iopub.status.busy": "2025-11-17T17:54:14.448842Z",
          "iopub.status.idle": "2025-11-17T17:54:14.456604Z",
          "shell.execute_reply": "2025-11-17T17:54:14.456207Z"
        }
      },
      "outputs": [],
      "source": [
        "# Use HdfPlan for geometry-related operations\n",
        "print(\"\\nExample: Extracting Base Geometry Attributes\")\n",
        "geom_attrs = HdfPlan.get_geometry_information(geom_hdf_path)\n",
        "\n",
        "if not geom_attrs.empty:\n",
        "    # Display the DataFrame directly\n",
        "    print(\"Base Geometry Attributes:\")\n",
        "    geom_attrs\n",
        "else:\n",
        "    print(\"No base geometry attributes found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.458443Z",
          "iopub.status.busy": "2025-11-17T17:54:14.458240Z",
          "iopub.status.idle": "2025-11-17T17:54:14.463735Z",
          "shell.execute_reply": "2025-11-17T17:54:14.463290Z"
        }
      },
      "outputs": [],
      "source": [
        "# Use HdfMesh for geometry-related operations\n",
        "print(\"\\nExample 3: Listing 2D Flow Area Names\")\n",
        "flow_area_names = HdfMesh.get_mesh_area_names(geom_hdf_path)\n",
        "print(\"2D Flow Area Names:\", flow_area_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.465410Z",
          "iopub.status.busy": "2025-11-17T17:54:14.465210Z",
          "iopub.status.idle": "2025-11-17T17:54:14.474269Z",
          "shell.execute_reply": "2025-11-17T17:54:14.473805Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Get 2D Flow Area Attributes (get_geom_2d_flow_area_attrs)\n",
        "print(\"\\nExample: Extracting 2D Flow Area Attributes\")\n",
        "flow_area_attributes = HdfMesh.get_mesh_area_attributes(geom_hdf_path)\n",
        "flow_area_attributes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.476096Z",
          "iopub.status.busy": "2025-11-17T17:54:14.475752Z",
          "iopub.status.idle": "2025-11-17T17:54:14.485638Z",
          "shell.execute_reply": "2025-11-17T17:54:14.485212Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n",
        "print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n",
        "mesh_areas = HdfMesh.get_mesh_areas(geom_hdf_path)  # Corrected function name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.487541Z",
          "iopub.status.busy": "2025-11-17T17:54:14.487154Z",
          "iopub.status.idle": "2025-11-17T17:54:14.514244Z",
          "shell.execute_reply": "2025-11-17T17:54:14.513716Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Extract mesh cell faces\n",
        "print(\"\\nExample: Extracting mesh cell faces\")\n",
        "\n",
        "# Get mesh cell faces using the standardize_input decorator for consistent file handling\n",
        "mesh_cell_faces = HdfMesh.get_mesh_cell_faces(geom_hdf_path)\n",
        "\n",
        "# Display the first few rows of the mesh cell faces GeoDataFrame\n",
        "print(\"First few rows of mesh cell faces:\")\n",
        "mesh_cell_faces.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.516237Z",
          "iopub.status.busy": "2025-11-17T17:54:14.516004Z",
          "iopub.status.idle": "2025-11-17T17:54:14.518641Z",
          "shell.execute_reply": "2025-11-17T17:54:14.518153Z"
        }
      },
      "outputs": [],
      "source": [
        "# Set the projection to USA Contiguous Albers Equal Area Conic (USGS version)\n",
        "# Note, we would usually call the projection function in HdfMesh but the projection is not set in this example project\n",
        "projection = 'EPSG:5070'  # NAD83 / Conus Albers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.520706Z",
          "iopub.status.busy": "2025-11-17T17:54:14.520475Z",
          "iopub.status.idle": "2025-11-17T17:54:14.754294Z",
          "shell.execute_reply": "2025-11-17T17:54:14.753786Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example Function: Find the nearest cell face to a given point\n",
        "# This provides enough basic information the face cell logic in the notebook\n",
        "\n",
        "def find_nearest_cell_face(point, cell_faces_df):\n",
        "    \"\"\"\n",
        "    Find the nearest cell face to a given point.\n",
        "\n",
        "    Args:\n",
        "        point (shapely.geometry.Point): The input point.\n",
        "        cell_faces_df (GeoDataFrame): DataFrame containing cell face linestrings.\n",
        "\n",
        "    Returns:\n",
        "        int: The face_id of the nearest cell face.\n",
        "        float: The distance to the nearest cell face.\n",
        "    \"\"\"\n",
        "    # Calculate distances from the input point to all cell faces\n",
        "    distances = cell_faces_df.geometry.distance(point)\n",
        "\n",
        "    # Find the index of the minimum distance\n",
        "    nearest_index = distances.idxmin()\n",
        "\n",
        "    # Get the face_id and distance of the nearest cell face\n",
        "    nearest_face_id = cell_faces_df.loc[nearest_index, 'face_id']\n",
        "    nearest_distance = distances[nearest_index]\n",
        "\n",
        "    return nearest_face_id, nearest_distance\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nExample: Finding the nearest cell face to a given point\")\n",
        "\n",
        "# Create a sample point (you can replace this with any point of interest)\n",
        "from shapely.geometry import Point\n",
        "from geopandas import GeoDataFrame\n",
        "\n",
        "# Create the sample point with the same CRS as mesh_cell_faces\n",
        "sample_point = GeoDataFrame(\n",
        "    {'geometry': [Point(1025677, 7853731)]}, \n",
        "    crs=mesh_cell_faces.crs\n",
        ")\n",
        "\n",
        "if not mesh_cell_faces.empty and not sample_point.empty:\n",
        "    nearest_face_id, distance = find_nearest_cell_face(sample_point.geometry.iloc[0], mesh_cell_faces)\n",
        "    print(f\"Nearest cell face to point {sample_point.geometry.iloc[0].coords[0]}:\")\n",
        "    print(f\"Face ID: {nearest_face_id}\")\n",
        "    print(f\"Distance: {distance:.2f} units\")\n",
        "\n",
        "    # Visualize the result\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    \n",
        "    # Plot all cell faces\n",
        "    mesh_cell_faces.plot(ax=ax, color='blue', linewidth=0.5, alpha=0.5, label='Cell Faces')\n",
        "    \n",
        "    # Plot the sample point\n",
        "    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n",
        "    \n",
        "    # Plot the nearest cell face\n",
        "    nearest_face = mesh_cell_faces[mesh_cell_faces['face_id'] == nearest_face_id]\n",
        "    nearest_face.plot(ax=ax, color='green', linewidth=2, alpha=0.7, label='Nearest Face')\n",
        "    \n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('X Coordinate')\n",
        "    ax.set_ylabel('Y Coordinate')\n",
        "    ax.set_title('Nearest Cell Face to Sample Point')\n",
        "    \n",
        "    # Add legend and grid\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    \n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Unable to perform nearest cell face search due to missing data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:14.756123Z",
          "iopub.status.busy": "2025-11-17T17:54:14.755947Z",
          "iopub.status.idle": "2025-11-17T17:54:15.086495Z",
          "shell.execute_reply": "2025-11-17T17:54:15.085857Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Extract mesh cell faces and plot with profile lines\n",
        "print(\"\\nExample: Extracting mesh cell faces and plotting with profile lines\")\n",
        "\n",
        "# Get mesh cell faces\n",
        "mesh_cell_faces = HdfMesh.get_mesh_cell_faces(geom_hdf_path)\n",
        "\n",
        "# Display the first few rows of the mesh cell faces DataFrame\n",
        "print(\"First few rows of mesh cell faces:\")\n",
        "mesh_cell_faces\n",
        "\n",
        "# Load the GeoJSON file for profile lines\n",
        "geojson_path = Path(r'data/profile_lines_chippewa2D.geojson')  # Update with the correct path\n",
        "profile_lines_gdf = gpd.read_file(geojson_path)\n",
        "\n",
        "# Set the Coordinate Reference System (CRS) to EPSG:5070\n",
        "profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n",
        "\n",
        "# Plot the mesh cell faces and profile lines together\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "mesh_cell_faces.plot(ax=ax, color='blue', alpha=0.5, edgecolor='k', label='Mesh Cell Faces')\n",
        "profile_lines_gdf.plot(ax=ax, color='orange', linewidth=2, label='Profile Lines')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Easting')\n",
        "ax.set_ylabel('Northing')\n",
        "ax.set_title('Mesh Cell Faces and Profile Lines')\n",
        "\n",
        "# Add grid and legend\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:15.088949Z",
          "iopub.status.busy": "2025-11-17T17:54:15.088648Z",
          "iopub.status.idle": "2025-11-17T17:54:17.465221Z",
          "shell.execute_reply": "2025-11-17T17:54:17.464583Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Extracting mesh cell faces near profile lines\n",
        "print(\"\\nExample: Extracting mesh cell faces near profile lines\")\n",
        "\n",
        "# Get mesh cell faces using HdfMesh class\n",
        "mesh_cell_faces = HdfMesh.get_mesh_cell_faces(geom_hdf_path)\n",
        "\n",
        "# Display the first few rows of the mesh cell faces DataFrame\n",
        "print(\"First few rows of mesh cell faces:\")\n",
        "mesh_cell_faces\n",
        "\n",
        "# Load the GeoJSON file for profile lines\n",
        "geojson_path = Path(r'data/profile_lines_chippewa2D.geojson')  # Update with the correct path\n",
        "profile_lines_gdf = gpd.read_file(geojson_path)\n",
        "\n",
        "# Set the Coordinate Reference System (CRS) to EPSG:5070\n",
        "profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n",
        "\n",
        "# Initialize a dictionary to store faces near each profile line\n",
        "faces_near_profile_lines = {}\n",
        "\n",
        "# Define distance threshold (10 ft converted to meters)\n",
        "distance_threshold = 10\n",
        "angle_threshold = 60  # degrees\n",
        "\n",
        "# Function to calculate the smallest angle between two lines or line segments.\n",
        "def calculate_angle(line):\n",
        "    if isinstance(line, LineString):\n",
        "        x_diff = line.xy[0][-1] - line.xy[0][0]\n",
        "        y_diff = line.xy[1][-1] - line.xy[1][0]\n",
        "    else:\n",
        "        x_diff = line[1][0] - line[0][0]\n",
        "        y_diff = line[1][1] - line[0][1]\n",
        "    \n",
        "    angle = np.degrees(np.arctan2(y_diff, x_diff))\n",
        "    return angle % 360 if angle >= 0 else (angle + 360) % 360\n",
        "\n",
        "# Function to break line into segments\n",
        "def break_line_into_segments(line, segment_length):\n",
        "    segments = []\n",
        "    segment_angles = []\n",
        "    \n",
        "    distances = np.arange(0, line.length, segment_length)\n",
        "    if distances[-1] != line.length:\n",
        "        distances = np.append(distances, line.length)\n",
        "        \n",
        "    for i in range(len(distances)-1):\n",
        "        point1 = line.interpolate(distances[i])\n",
        "        point2 = line.interpolate(distances[i+1])\n",
        "        segment = LineString([point1, point2])\n",
        "        segments.append(segment)\n",
        "        segment_angles.append(calculate_angle([point1.coords[0], point2.coords[0]]))\n",
        "        \n",
        "    return segments, segment_angles\n",
        "\n",
        "# Function to calculate angle difference accounting for 180 degree equivalence\n",
        "def angle_difference(angle1, angle2):\n",
        "    diff = abs(angle1 - angle2) % 180\n",
        "    return min(diff, 180 - diff)\n",
        "\n",
        "# Function to order faces along profile line\n",
        "def order_faces_along_profile(profile_line, faces_gdf):\n",
        "    profile_start = Point(profile_line.coords[0])\n",
        "    \n",
        "    faces_with_dist = []\n",
        "    for idx, face in faces_gdf.iterrows():\n",
        "        face_start = Point(face.geometry.coords[0])\n",
        "        dist = profile_start.distance(face_start)\n",
        "        faces_with_dist.append((idx, dist))\n",
        "    \n",
        "    faces_with_dist.sort(key=lambda x: x[1])\n",
        "    return [x[0] for x in faces_with_dist]\n",
        "\n",
        "# Function to combine ordered faces into single linestring\n",
        "def combine_faces_to_linestring(ordered_faces_gdf):\n",
        "    coords = []\n",
        "    for _, face in ordered_faces_gdf.iterrows():\n",
        "        if not coords:  # First face - add all coordinates\n",
        "            coords.extend(list(face.geometry.coords))\n",
        "        else:  # Subsequent faces - add only end coordinate\n",
        "            coords.append(face.geometry.coords[-1])\n",
        "    return LineString(coords)\n",
        "\n",
        "# Initialize GeoDataFrame for final profile-to-faceline results\n",
        "profile_to_faceline = gpd.GeoDataFrame(columns=['profile_name', 'geometry'], crs=profile_lines_gdf.crs)\n",
        "\n",
        "# Iterate through each profile line\n",
        "for index, profile_line in profile_lines_gdf.iterrows():\n",
        "    profile_geom = profile_line.geometry\n",
        "    \n",
        "    # Break profile line into segments\n",
        "    segments, segment_angles = break_line_into_segments(profile_geom, distance_threshold)\n",
        "    \n",
        "    # Initialize set to store nearby faces\n",
        "    nearby_faces = set()\n",
        "    \n",
        "    # For each face, check distance to segments and angle difference\n",
        "    for face_idx, face in mesh_cell_faces.iterrows():\n",
        "        face_geom = face.geometry\n",
        "        \n",
        "        if isinstance(face_geom, LineString):\n",
        "            face_angle = calculate_angle(face_geom)\n",
        "            \n",
        "            for segment, segment_angle in zip(segments, segment_angles):\n",
        "                if face_geom.distance(segment) <= distance_threshold:\n",
        "                    if angle_difference(face_angle, segment_angle) <= angle_threshold:\n",
        "                        nearby_faces.add(face_idx)\n",
        "                        break\n",
        "    \n",
        "    # Convert the set of indices back to a GeoDataFrame\n",
        "    nearby_faces_gdf = mesh_cell_faces.loc[list(nearby_faces)]\n",
        "    \n",
        "    # Order faces along profile line\n",
        "    ordered_indices = order_faces_along_profile(profile_geom, nearby_faces_gdf)\n",
        "    ordered_faces_gdf = nearby_faces_gdf.loc[ordered_indices]\n",
        "    \n",
        "    # Combine ordered faces into single linestring\n",
        "    combined_linestring = combine_faces_to_linestring(ordered_faces_gdf)\n",
        "    \n",
        "    # Add to profile_to_faceline GeoDataFrame\n",
        "    new_row = gpd.GeoDataFrame({'profile_name': [profile_line['Name']], \n",
        "                               'geometry': [combined_linestring]}, \n",
        "                              crs=profile_lines_gdf.crs)\n",
        "    profile_to_faceline = pd.concat([profile_to_faceline, new_row], ignore_index=True)\n",
        "    \n",
        "    # Store the ordered faces in the dictionary\n",
        "    faces_near_profile_lines[profile_line['Name']] = ordered_faces_gdf\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plot all mesh cell faces in light blue\n",
        "mesh_cell_faces.plot(ax=ax, color='lightblue', alpha=0.3, edgecolor='k', label='All Mesh Faces')\n",
        "\n",
        "# Plot selected faces for each profile line with numbers\n",
        "colors = ['red', 'green', 'blue']\n",
        "for (profile_name, faces), color in zip(faces_near_profile_lines.items(), colors):\n",
        "    if not faces.empty:\n",
        "        faces.plot(ax=ax, color=color, alpha=0.6, label=f'Faces near {profile_name}')\n",
        "        \n",
        "        # Add numbers to faces\n",
        "        for i, (idx, face) in enumerate(faces.iterrows()):\n",
        "            midpoint = face.geometry.interpolate(0.5, normalized=True)\n",
        "            ax.text(midpoint.x, midpoint.y, str(i+1), \n",
        "                   color=color, fontweight='bold', ha='center', va='center')\n",
        "\n",
        "# Plot the combined linestrings\n",
        "profile_to_faceline.plot(ax=ax, color='black', linewidth=2, \n",
        "                        linestyle='--', label='Combined Face Lines')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Easting')\n",
        "ax.set_ylabel('Northing')\n",
        "ax.set_title('Mesh Cell Faces and Profile Lines\\nNumbered in order along profile')\n",
        "\n",
        "# Add grid and legend\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nOriginal ordered faces near profile lines:\")\n",
        "faces_near_profile_lines\n",
        "\n",
        "print(\"\\nCombined profile-to-faceline results:\")\n",
        "profile_to_faceline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.467693Z",
          "iopub.status.busy": "2025-11-17T17:54:17.467507Z",
          "iopub.status.idle": "2025-11-17T17:54:17.492345Z",
          "shell.execute_reply": "2025-11-17T17:54:17.491730Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get face property tables with error handling\n",
        "face_property_tables = HdfMesh.get_mesh_face_property_tables(geom_hdf_path)\n",
        "face_property_tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.494190Z",
          "iopub.status.busy": "2025-11-17T17:54:17.494025Z",
          "iopub.status.idle": "2025-11-17T17:54:17.642978Z",
          "shell.execute_reply": "2025-11-17T17:54:17.642319Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract the face property table for Face ID 4 and display it\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "face_id = 4\n",
        "face_properties = face_property_tables['Perimeter 1'][face_property_tables['Perimeter 1']['Face ID'] == face_id]\n",
        "\n",
        "# Create subplots arranged horizontally\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot Z vs Area\n",
        "axs[0].plot(face_properties['Z'], face_properties['Area'], marker='o', color='blue', label='Area')\n",
        "axs[0].set_title(f'Face ID {face_id}: Z vs Area')\n",
        "axs[0].set_xlabel('Z')\n",
        "axs[0].set_ylabel('Area')\n",
        "axs[0].grid(True)\n",
        "axs[0].legend()\n",
        "\n",
        "# Plot Z vs Wetted Perimeter\n",
        "axs[1].plot(face_properties['Z'], face_properties['Wetted Perimeter'], marker='o', color='green', label='Wetted Perimeter')\n",
        "axs[1].set_title(f'Face ID {face_id}: Z vs Wetted Perimeter')\n",
        "axs[1].set_xlabel('Z')\n",
        "axs[1].set_ylabel('Wetted Perimeter')\n",
        "axs[1].grid(True)\n",
        "axs[1].legend()\n",
        "\n",
        "# Plot Z vs Manning's n\n",
        "axs[2].plot(face_properties['Z'], face_properties[\"Manning's n\"], marker='o', color='red', label=\"Manning's n\")\n",
        "axs[2].set_title(f'Face ID {face_id}: Z vs Manning\\'s n')\n",
        "axs[2].set_xlabel('Z')\n",
        "axs[2].set_ylabel(\"Manning's n\")\n",
        "axs[2].grid(True)\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.645090Z",
          "iopub.status.busy": "2025-11-17T17:54:17.644908Z",
          "iopub.status.idle": "2025-11-17T17:54:17.876769Z",
          "shell.execute_reply": "2025-11-17T17:54:17.876260Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get mesh timeseries output\n",
        "# Get mesh areas from previous code cell\n",
        "mesh_areas = HdfMesh.get_mesh_area_names(geom_hdf_path)\n",
        "\n",
        "mesh_name = mesh_areas[0]  # Use the first 2D flow area name\n",
        "timeseries_da = HdfResultsMesh.get_mesh_timeseries(plan_hdf_path, mesh_name, \"Water Surface\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.879028Z",
          "iopub.status.busy": "2025-11-17T17:54:17.878725Z",
          "iopub.status.idle": "2025-11-17T17:54:17.892957Z",
          "shell.execute_reply": "2025-11-17T17:54:17.892424Z"
        }
      },
      "outputs": [],
      "source": [
        "print(f\"\\nMesh Timeseries Output (Water Surface) for {mesh_name}:\")\n",
        "timeseries_da"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.895069Z",
          "iopub.status.busy": "2025-11-17T17:54:17.894661Z",
          "iopub.status.idle": "2025-11-17T17:54:17.991634Z",
          "shell.execute_reply": "2025-11-17T17:54:17.991057Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get mesh cells timeseries output\n",
        "cells_timeseries_ds = HdfResultsMesh.get_mesh_cells_timeseries(plan_hdf_path, mesh_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:17.993977Z",
          "iopub.status.busy": "2025-11-17T17:54:17.993611Z",
          "iopub.status.idle": "2025-11-17T17:54:18.000048Z",
          "shell.execute_reply": "2025-11-17T17:54:17.999453Z"
        }
      },
      "outputs": [],
      "source": [
        "print(\"\\nMesh Cells Timeseries Output:\")\n",
        "cells_timeseries_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.002295Z",
          "iopub.status.busy": "2025-11-17T17:54:18.001971Z",
          "iopub.status.idle": "2025-11-17T17:54:18.071710Z",
          "shell.execute_reply": "2025-11-17T17:54:18.071156Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get mesh faces timeseries output\n",
        "faces_timeseries_ds = HdfResultsMesh.get_mesh_faces_timeseries(plan_hdf_path, mesh_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.074007Z",
          "iopub.status.busy": "2025-11-17T17:54:18.073754Z",
          "iopub.status.idle": "2025-11-17T17:54:18.083499Z",
          "shell.execute_reply": "2025-11-17T17:54:18.083106Z"
        }
      },
      "outputs": [],
      "source": [
        "print(\"\\nMesh Faces Timeseries Output:\")\n",
        "faces_timeseries_ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.085694Z",
          "iopub.status.busy": "2025-11-17T17:54:18.085418Z",
          "iopub.status.idle": "2025-11-17T17:54:18.098450Z",
          "shell.execute_reply": "2025-11-17T17:54:18.098013Z"
        }
      },
      "outputs": [],
      "source": [
        "# Convert all face velocities and face flow values to positive for further calculations\n",
        "# We have visually confirmed for this model that all flow is moving in the same direction\n",
        "\n",
        "# Function to process and convert face data to positive values\n",
        "def convert_to_positive_values(faces_timeseries_ds, cells_timeseries_ds):\n",
        "    \"\"\"\n",
        "    Convert face velocities and flows to positive values while maintaining their relationships.\n",
        "    \n",
        "    Args:\n",
        "        faces_timeseries_ds (xarray.Dataset): Dataset containing face timeseries data\n",
        "        cells_timeseries_ds (xarray.Dataset): Dataset containing cell timeseries data\n",
        "        \n",
        "    Returns:\n",
        "        xarray.Dataset: Modified dataset with positive values\n",
        "    \"\"\"\n",
        "    # Get the face velocity variable (always available)\n",
        "    face_velocity = faces_timeseries_ds['face_velocity']\n",
        "    \n",
        "    # Calculate the sign of the velocity to maintain flow direction relationships\n",
        "    velocity_sign = xr.where(face_velocity >= 0, 1, -1)\n",
        "    \n",
        "    # Convert velocities to absolute values\n",
        "    faces_timeseries_ds['face_velocity'] = abs(face_velocity)\n",
        "    \n",
        "    # Check if face_flow exists and process it if available\n",
        "    if 'face_flow' in faces_timeseries_ds:\n",
        "        face_flow = faces_timeseries_ds['face_flow']\n",
        "        faces_timeseries_ds['face_flow'] = abs(face_flow)\n",
        "        print(\"Face flow data processed.\")\n",
        "    else:\n",
        "        print(\"Note: face_flow not available in this dataset (depends on HEC-RAS output settings)\")\n",
        "    \n",
        "    # Store the original sign as a new variable for reference\n",
        "    faces_timeseries_ds['velocity_direction'] = velocity_sign\n",
        "    \n",
        "    print(\"Conversion to positive values complete.\")\n",
        "    print(f\"Number of faces processed: {len(faces_timeseries_ds.face_id)}\")\n",
        "    print(f\"Available variables: {list(faces_timeseries_ds.data_vars)}\")\n",
        "    \n",
        "    return faces_timeseries_ds, cells_timeseries_ds\n",
        "\n",
        "# Convert the values in our datasets\n",
        "faces_timeseries_ds_positive, cells_timeseries_ds_positive = convert_to_positive_values(\n",
        "    faces_timeseries_ds, \n",
        "    cells_timeseries_ds\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.100444Z",
          "iopub.status.busy": "2025-11-17T17:54:18.100274Z",
          "iopub.status.idle": "2025-11-17T17:54:18.104071Z",
          "shell.execute_reply": "2025-11-17T17:54:18.103680Z"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "\n",
        "# Function to process faces for a single profile line\n",
        "def process_profile_line(profile_name, faces, cells_timeseries_ds, faces_timeseries_ds):\n",
        "    face_ids = faces['face_id'].tolist()\n",
        "    \n",
        "    # Extract relevant data for these faces\n",
        "    face_velocities = faces_timeseries_ds['face_velocity'].sel(face_id=face_ids)\n",
        "    \n",
        "    # Build dataset with available data\n",
        "    data_vars = {'face_velocity': face_velocities}\n",
        "    \n",
        "    # Check if face_flow exists and add it if available\n",
        "    if 'face_flow' in faces_timeseries_ds:\n",
        "        face_flows = faces_timeseries_ds['face_flow'].sel(face_id=face_ids)\n",
        "        data_vars['face_flow'] = face_flows\n",
        "    \n",
        "    # Create a new dataset with calculated results\n",
        "    results_ds = xr.Dataset(data_vars)\n",
        "    \n",
        "    # Convert to dataframe for easier manipulation\n",
        "    results_df = results_ds.to_dataframe().reset_index()\n",
        "    \n",
        "    # Add profile name and face order\n",
        "    results_df['profile_name'] = profile_name\n",
        "    results_df['face_order'] = results_df.groupby('time')['face_id'].transform(lambda x: pd.factorize(x)[0])\n",
        "    \n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Vave = Sum Qn / Sum An for each profile line\n",
        "where Vave = the summation of face flow / flow area for all the faces in the profile line\n",
        "\n",
        "Then, save the results to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.106234Z",
          "iopub.status.busy": "2025-11-17T17:54:18.105973Z",
          "iopub.status.idle": "2025-11-17T17:54:18.610270Z",
          "shell.execute_reply": "2025-11-17T17:54:18.609734Z"
        }
      },
      "outputs": [],
      "source": [
        "# Process all profile lines\n",
        "all_results = []\n",
        "for profile_name, faces in faces_near_profile_lines.items():\n",
        "    profile_results = process_profile_line(profile_name, faces, cells_timeseries_ds, faces_timeseries_ds)\n",
        "    all_results.append(profile_results)\n",
        "\n",
        "# Combine results from all profile lines\n",
        "combined_results_df = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined results\n",
        "combined_results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.612506Z",
          "iopub.status.busy": "2025-11-17T17:54:18.612332Z",
          "iopub.status.idle": "2025-11-17T17:54:18.625988Z",
          "shell.execute_reply": "2025-11-17T17:54:18.625554Z"
        }
      },
      "outputs": [],
      "source": [
        "profile_time_series = {}\n",
        "\n",
        "# Iterate through each profile line and extract its corresponding data\n",
        "for profile_name, faces_gdf in faces_near_profile_lines.items():\n",
        "    # Get the list of face_ids for this profile line\n",
        "    face_ids = faces_gdf['face_id'].tolist()\n",
        "    \n",
        "    # Filter the combined_results_df for these face_ids\n",
        "    profile_df = combined_results_df[combined_results_df['face_id'].isin(face_ids)].copy()\n",
        "    \n",
        "    # Add the profile name as a column\n",
        "    profile_df['profile_name'] = profile_name\n",
        "    \n",
        "    # Reset index for cleanliness\n",
        "    profile_df.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    # Store in the dictionary\n",
        "    profile_time_series[profile_name] = profile_df\n",
        "    \n",
        "    # Display a preview\n",
        "    print(f\"\\nTime Series DataFrame for {profile_name}:\")\n",
        "    profile_df\n",
        "\n",
        "# Optionally, display all profile names\n",
        "print(\"\\nProfile Lines Processed:\")\n",
        "profile_time_series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.628203Z",
          "iopub.status.busy": "2025-11-17T17:54:18.628006Z",
          "iopub.status.idle": "2025-11-17T17:54:18.636639Z",
          "shell.execute_reply": "2025-11-17T17:54:18.636261Z"
        }
      },
      "outputs": [],
      "source": [
        "all_profiles_df = pd.concat(profile_time_series.values(), ignore_index=True)\n",
        "\n",
        "# Display the combined dataframe\n",
        "print(\"Combined Time Series DataFrame for All Profiles:\")\n",
        "all_profiles_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.638602Z",
          "iopub.status.busy": "2025-11-17T17:54:18.638332Z",
          "iopub.status.idle": "2025-11-17T17:54:18.641759Z",
          "shell.execute_reply": "2025-11-17T17:54:18.641396Z"
        }
      },
      "outputs": [],
      "source": [
        "# Check if we have the necessary variables\n",
        "print(\"Available variables:\")\n",
        "print(\"profile_time_series:\", 'profile_time_series' in locals())\n",
        "print(\"faces_near_profile_lines:\", 'faces_near_profile_lines' in locals())\n",
        "print(\"profile_averages:\", 'profile_averages' in locals())\n",
        "\n",
        "# Look at the structure of profile_time_series\n",
        "if 'profile_time_series' in locals():\n",
        "    for name, df in profile_time_series.items():\n",
        "        print(f\"\\nColumns in {name}:\")\n",
        "        print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.643977Z",
          "iopub.status.busy": "2025-11-17T17:54:18.643663Z",
          "iopub.status.idle": "2025-11-17T17:54:18.647883Z",
          "shell.execute_reply": "2025-11-17T17:54:18.647312Z"
        }
      },
      "outputs": [],
      "source": [
        "def calculate_discharge_weighted_velocity(profile_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate discharge-weighted average velocity for a profile line\n",
        "    Vw = Sum(|Qi|*Vi)/Sum(|Qi|) where Qi is face flow and Vi is face velocity\n",
        "\n",
        "    If face_flow is not available, falls back to simple average velocity.\n",
        "    \"\"\"\n",
        "    print(\"Calculating weighted velocity...\")\n",
        "    print(f\"Input DataFrame columns: {list(profile_df.columns)}\")\n",
        "\n",
        "    has_face_flow = 'face_flow' in profile_df.columns\n",
        "    if not has_face_flow:\n",
        "        print(\"Note: face_flow not available, using simple average velocity instead\")\n",
        "\n",
        "    # Calculate weighted velocity for each timestep\n",
        "    weighted_velocities = []\n",
        "    for time in profile_df['time'].unique():\n",
        "        time_data = profile_df[profile_df['time'] == time]\n",
        "        abs_velocities = np.abs(time_data['face_velocity'])\n",
        "\n",
        "        if has_face_flow:\n",
        "            # Discharge-weighted velocity\n",
        "            abs_flows = np.abs(time_data['face_flow'])\n",
        "            if abs_flows.sum() > 0:\n",
        "                weighted_vel = (abs_flows * abs_velocities).sum() / abs_flows.sum()\n",
        "            else:\n",
        "                weighted_vel = abs_velocities.mean()\n",
        "        else:\n",
        "            # Simple average velocity\n",
        "            weighted_vel = abs_velocities.mean()\n",
        "\n",
        "        weighted_velocities.append({\n",
        "            'time': time,\n",
        "            'weighted_velocity': weighted_vel\n",
        "        })\n",
        "\n",
        "    weighted_df = pd.DataFrame(weighted_velocities)\n",
        "    print(f\"Calculated velocities:\\n{weighted_df.head()}\")\n",
        "    return weighted_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:18.650302Z",
          "iopub.status.busy": "2025-11-17T17:54:18.650108Z",
          "iopub.status.idle": "2025-11-17T17:54:20.595754Z",
          "shell.execute_reply": "2025-11-17T17:54:20.595210Z"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate for each profile line\n",
        "for profile_name, profile_df in profile_time_series.items():\n",
        "    print(f\"\\nProcessing profile: {profile_name}\")\n",
        "\n",
        "    # Calculate discharge-weighted velocity\n",
        "    weighted_velocities = calculate_discharge_weighted_velocity(profile_df)\n",
        "    \n",
        "    print(\"Weighted velocities calculated.\")\n",
        "    # Get ordered faces for this profile\n",
        "    ordered_faces = faces_near_profile_lines[profile_name]\n",
        "    print(f\"Number of ordered faces: {len(ordered_faces)}\")\n",
        "    \n",
        "    print(\"Converted time to datetime format.\")\n",
        "\n",
        "    # Get ordered faces for this profile\n",
        "    ordered_faces = faces_near_profile_lines[profile_name]\n",
        "    print(f\"Number of ordered faces: {len(ordered_faces)}\")\n",
        "    \n",
        "    # Save dataframes in the output directory\n",
        "    output_file = ras.project_folder / f\"{profile_name}_discharge_weighted_velocity.csv\"\n",
        "    weighted_velocities.to_csv(output_file, index=False)\n",
        "    print(f\"Saved weighted velocities to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:20.597954Z",
          "iopub.status.busy": "2025-11-17T17:54:20.597777Z",
          "iopub.status.idle": "2025-11-17T17:54:24.594148Z",
          "shell.execute_reply": "2025-11-17T17:54:24.593672Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create plots comparing discharge-weighted velocity and simple average for each profile line\n",
        "for profile_name, profile_df in profile_time_series.items():\n",
        "    \n",
        "    print(f\"\\nGenerating comparison plot for profile: {profile_name}\")\n",
        "    \n",
        "    # Calculate discharge-weighted velocity\n",
        "    weighted_velocities = calculate_discharge_weighted_velocity(profile_df)\n",
        "    weighted_velocities['time'] = pd.to_datetime(weighted_velocities['time'])\n",
        "    \n",
        "    # Calculate simple average velocity for each timestep\n",
        "    simple_averages = profile_df.groupby('time')['face_velocity'].mean().reset_index()\n",
        "    simple_averages['time'] = pd.to_datetime(simple_averages['time'])\n",
        "    \n",
        "    # Create figure for comparison plot\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    \n",
        "    # Plot individual face velocities with thin lines\n",
        "    for face_id in profile_df['face_id'].unique():\n",
        "        face_data = profile_df[profile_df['face_id'] == face_id]\n",
        "        plt.plot(face_data['time'], \n",
        "                face_data['face_velocity'], \n",
        "                alpha=0.8,  # More transparent\n",
        "                linewidth=0.3,  # Thinner line\n",
        "                color='gray',  # Consistent color\n",
        "                label=f'Face ID {face_id}')\n",
        "        \n",
        "        # Find and annotate peak value for each face\n",
        "        peak_idx = face_data['face_velocity'].idxmax()\n",
        "        peak_time = face_data.loc[peak_idx, 'time']\n",
        "        peak_vel = face_data.loc[peak_idx, 'face_velocity']\n",
        "        plt.annotate(f'{peak_vel:.2f} ({face_id})',\n",
        "                    xy=(peak_time, peak_vel),\n",
        "                    xytext=(10, 10),\n",
        "                    textcoords='offset points',\n",
        "                    fontsize=8,\n",
        "                    alpha=0.5)\n",
        "    \n",
        "    # Plot discharge-weighted velocity\n",
        "    plt.plot(weighted_velocities['time'], \n",
        "            weighted_velocities['weighted_velocity'], \n",
        "            color='red', \n",
        "            alpha=1.0, \n",
        "            linewidth=2,\n",
        "            label='Discharge-Weighted Velocity')\n",
        "    \n",
        "    # Find and annotate peak weighted velocity\n",
        "    peak_idx = weighted_velocities['weighted_velocity'].idxmax()\n",
        "    peak_time = weighted_velocities.loc[peak_idx, 'time']\n",
        "    peak_vel = weighted_velocities.loc[peak_idx, 'weighted_velocity']\n",
        "    plt.annotate(f'Peak Weighted: {peak_vel:.2f}',\n",
        "                xy=(peak_time, peak_vel),\n",
        "                xytext=(10, 10),\n",
        "                textcoords='offset points',\n",
        "                color='red',\n",
        "                fontweight='bold')\n",
        "    \n",
        "    # Plot simple average\n",
        "    plt.plot(simple_averages['time'], \n",
        "            simple_averages['face_velocity'], \n",
        "            color='blue', \n",
        "            alpha=0.5, \n",
        "            linewidth=1,\n",
        "            linestyle='--',\n",
        "            label='Simple Average')\n",
        "    \n",
        "    # Find and annotate peak simple average\n",
        "    peak_idx = simple_averages['face_velocity'].idxmax()\n",
        "    peak_time = simple_averages.loc[peak_idx, 'time']\n",
        "    peak_vel = simple_averages.loc[peak_idx, 'face_velocity']\n",
        "    plt.annotate(f'Peak Average: {peak_vel:.2f}',\n",
        "                xy=(peak_time, peak_vel),\n",
        "                xytext=(10, -10),\n",
        "                textcoords='offset points',\n",
        "                color='blue',\n",
        "                fontweight='bold')\n",
        "    \n",
        "    # Configure plot\n",
        "    plt.title(f'Velocity Comparison for {profile_name} \\nIndividual Face Velocities vs Simple Average Velocity vs Discharge-Weighted Average Velocity')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Velocity (ft/s)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add legend with better placement\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "    # Adjust layout to accommodate legend and stats\n",
        "    plt.subplots_adjust(right=0.8)\n",
        "    \n",
        "    # Save plot to file\n",
        "    plot_file = ras.project_folder / f\"{profile_name}_velocity_comparison.png\"\n",
        "    plt.savefig(plot_file, bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "    \n",
        "    # Print detailed comparison\n",
        "    print(f\"\\nVelocity Comparison for {profile_name} \\nIndividual Face Velocities vs Simple Average Velocity vs Discharge-Weighted Average Velocity\")\n",
        "    print(f\"Number of faces: {profile_df['face_id'].nunique()}\")\n",
        "    print(\"\\nDischarge-Weighted Velocity Statistics:\")\n",
        "    print(f\"Mean: {weighted_velocities['weighted_velocity'].mean():.2f} ft/s\")\n",
        "    print(f\"Max: {weighted_velocities['weighted_velocity'].max():.2f} ft/s\")\n",
        "    print(f\"Min: {weighted_velocities['weighted_velocity'].min():.2f} ft/s\")\n",
        "    print(\"\\nSimple Average Velocity Statistics:\")\n",
        "    print(f\"Mean: {simple_averages['face_velocity'].mean():.2f} ft/s\")\n",
        "    print(f\"Max: {simple_averages['face_velocity'].max():.2f} ft/s\")\n",
        "    print(f\"Min: {simple_averages['face_velocity'].min():.2f} ft/s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:54:24.596452Z",
          "iopub.status.busy": "2025-11-17T17:54:24.596251Z",
          "iopub.status.idle": "2025-11-17T17:54:27.147137Z",
          "shell.execute_reply": "2025-11-17T17:54:27.146462Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Extracting mesh cell faces near profile lines\n",
        "print(\"\\nExample: Extracting mesh cell faces near profile lines\")\n",
        "\n",
        "# Get mesh cell faces using HdfMesh class\n",
        "mesh_cell_faces = HdfMesh.get_mesh_cell_faces(geom_hdf_path)\n",
        "\n",
        "# Display the first few rows of the mesh cell faces DataFrame\n",
        "print(\"First few rows of mesh cell faces:\")\n",
        "mesh_cell_faces\n",
        "\n",
        "# Load the GeoJSON file for profile lines\n",
        "geojson_path = Path(r'data/profile_lines_chippewa2D.geojson')  # Update with the correct path\n",
        "profile_lines_gdf = gpd.read_file(geojson_path)\n",
        "\n",
        "# Set the Coordinate Reference System (CRS) to EPSG:5070\n",
        "profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n",
        "\n",
        "# Initialize a dictionary to store faces near each profile line\n",
        "faces_near_profile_lines = {}\n",
        "\n",
        "# Define distance threshold (10 ft converted to meters)\n",
        "distance_threshold = 10\n",
        "angle_threshold = 60  # degrees\n",
        "\n",
        "# Function to calculate the smallest angle between two lines or line segments.\n",
        "def calculate_angle(line):\n",
        "    if isinstance(line, LineString):\n",
        "        x_diff = line.xy[0][-1] - line.xy[0][0]\n",
        "        y_diff = line.xy[1][-1] - line.xy[1][0]\n",
        "    else:\n",
        "        x_diff = line[1][0] - line[0][0]\n",
        "        y_diff = line[1][1] - line[0][1]\n",
        "    \n",
        "    angle = np.degrees(np.arctan2(y_diff, x_diff))\n",
        "    return angle % 360 if angle >= 0 else (angle + 360) % 360\n",
        "\n",
        "# Function to break line into segments\n",
        "def break_line_into_segments(line, segment_length):\n",
        "    segments = []\n",
        "    segment_angles = []\n",
        "    \n",
        "    distances = np.arange(0, line.length, segment_length)\n",
        "    if distances[-1] != line.length:\n",
        "        distances = np.append(distances, line.length)\n",
        "        \n",
        "    for i in range(len(distances)-1):\n",
        "        point1 = line.interpolate(distances[i])\n",
        "        point2 = line.interpolate(distances[i+1])\n",
        "        segment = LineString([point1, point2])\n",
        "        segments.append(segment)\n",
        "        segment_angles.append(calculate_angle([point1.coords[0], point2.coords[0]]))\n",
        "        \n",
        "    return segments, segment_angles\n",
        "\n",
        "# Function to calculate angle difference accounting for 180 degree equivalence\n",
        "def angle_difference(angle1, angle2):\n",
        "    diff = abs(angle1 - angle2) % 180\n",
        "    return min(diff, 180 - diff)\n",
        "\n",
        "# Function to order faces along profile line\n",
        "def order_faces_along_profile(profile_line, faces_gdf):\n",
        "    profile_start = Point(profile_line.coords[0])\n",
        "    \n",
        "    faces_with_dist = []\n",
        "    for idx, face in faces_gdf.iterrows():\n",
        "        face_start = Point(face.geometry.coords[0])\n",
        "        dist = profile_start.distance(face_start)\n",
        "        faces_with_dist.append((idx, dist))\n",
        "    \n",
        "    faces_with_dist.sort(key=lambda x: x[1])\n",
        "    return [x[0] for x in faces_with_dist]\n",
        "\n",
        "# Function to combine ordered faces into single linestring\n",
        "def combine_faces_to_linestring(ordered_faces_gdf):\n",
        "    coords = []\n",
        "    for _, face in ordered_faces_gdf.iterrows():\n",
        "        if not coords:  # First face - add all coordinates\n",
        "            coords.extend(list(face.geometry.coords))\n",
        "        else:  # Subsequent faces - add only end coordinate\n",
        "            coords.append(face.geometry.coords[-1])\n",
        "    return LineString(coords)\n",
        "\n",
        "# Initialize GeoDataFrame for final profile-to-faceline results\n",
        "profile_to_faceline = gpd.GeoDataFrame(columns=['profile_name', 'geometry'], crs=profile_lines_gdf.crs)\n",
        "\n",
        "# Iterate through each profile line\n",
        "for index, profile_line in profile_lines_gdf.iterrows():\n",
        "    profile_geom = profile_line.geometry\n",
        "    \n",
        "    # Break profile line into segments\n",
        "    segments, segment_angles = break_line_into_segments(profile_geom, distance_threshold)\n",
        "    \n",
        "    # Initialize set to store nearby faces\n",
        "    nearby_faces = set()\n",
        "    \n",
        "    # For each face, check distance to segments and angle difference\n",
        "    for face_idx, face in mesh_cell_faces.iterrows():\n",
        "        face_geom = face.geometry\n",
        "        \n",
        "        if isinstance(face_geom, LineString):\n",
        "            face_angle = calculate_angle(face_geom)\n",
        "            \n",
        "            for segment, segment_angle in zip(segments, segment_angles):\n",
        "                if face_geom.distance(segment) <= distance_threshold:\n",
        "                    if angle_difference(face_angle, segment_angle) <= angle_threshold:\n",
        "                        nearby_faces.add(face_idx)\n",
        "                        break\n",
        "    \n",
        "    # Convert the set of indices back to a GeoDataFrame\n",
        "    nearby_faces_gdf = mesh_cell_faces.loc[list(nearby_faces)]\n",
        "    \n",
        "    # Order faces along profile line\n",
        "    ordered_indices = order_faces_along_profile(profile_geom, nearby_faces_gdf)\n",
        "    ordered_faces_gdf = nearby_faces_gdf.loc[ordered_indices]\n",
        "    \n",
        "    # Combine ordered faces into single linestring\n",
        "    combined_linestring = combine_faces_to_linestring(ordered_faces_gdf)\n",
        "    \n",
        "    # Add to profile_to_faceline GeoDataFrame\n",
        "    new_row = gpd.GeoDataFrame({'profile_name': [profile_line['Name']], \n",
        "                               'geometry': [combined_linestring]}, \n",
        "                              crs=profile_lines_gdf.crs)\n",
        "    profile_to_faceline = pd.concat([profile_to_faceline, new_row], ignore_index=True)\n",
        "    \n",
        "    # Store the ordered faces in the dictionary\n",
        "    faces_near_profile_lines[profile_line['Name']] = ordered_faces_gdf\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots(figsize=(24, 16))\n",
        "\n",
        "# Plot all mesh cell faces in light blue\n",
        "mesh_cell_faces.plot(ax=ax, color='lightblue', alpha=0.3, edgecolor='k', label='All Mesh Faces')\n",
        "\n",
        "# Plot selected faces for each profile line with numbers and velocities\n",
        "colors = ['red', 'green', 'blue']\n",
        "for (profile_name, faces), color in zip(faces_near_profile_lines.items(), colors):\n",
        "    if not faces.empty:\n",
        "        faces.plot(ax=ax, color=color, alpha=0.6, label=f'Faces near {profile_name}')\n",
        "        \n",
        "        # Get velocity data for this profile from profile_time_series\n",
        "        profile_data = profile_time_series[profile_name]\n",
        "        \n",
        "        # Add face_id above and peak velocity below for each face\n",
        "        for idx, face in faces.iterrows():\n",
        "            midpoint = face.geometry.interpolate(0.5, normalized=True)\n",
        "            \n",
        "            # Get peak velocity for this face\n",
        "            face_velocities = profile_data[profile_data['face_id'] == face['face_id']]['face_velocity']\n",
        "            peak_velocity = face_velocities.max() if not face_velocities.empty else 0.0\n",
        "            # Add face_id above the face\n",
        "            ax.text(midpoint.x, midpoint.y + 50,  # Adjust the +50 offset as needed\n",
        "                   f\"{face['face_id']}\", \n",
        "                   color=color, \n",
        "                   fontweight='bold',\n",
        "                   fontsize=8,\n",
        "                   ha='center', \n",
        "                   va='bottom')\n",
        "            \n",
        "            # Add peak velocity below the face\n",
        "            ax.text(midpoint.x, midpoint.y - 50,  # Adjust the -50 offset as needed\n",
        "                   f\"{peak_velocity:.2f}fps\", \n",
        "                   color=color, \n",
        "                   fontweight='bold',\n",
        "                   fontsize=6,\n",
        "                   ha='center', \n",
        "                   va='top')\n",
        "\n",
        "\n",
        "# Plot the combined linestrings\n",
        "profile_to_faceline.plot(ax=ax, color='black', linewidth=2, \n",
        "                        linestyle='--', label='Combined Face Lines')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Easting')\n",
        "ax.set_ylabel('Northing')\n",
        "ax.set_title('Mesh Cell Faces and Profile Lines\\nNumbered in order along profile\\nFace ID and Peak Face Velocity Shown')\n",
        "\n",
        "# Add grid and legend\n",
        "ax.grid(True)\n",
        "ax.legend()\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the results\n",
        "print(\"\\nOriginal ordered faces near profile lines:\")\n",
        "faces_near_profile_lines\n",
        "\n",
        "print(\"\\nCombined profile-to-faceline results:\")\n",
        "profile_to_faceline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE:  We are using the face normal velocity that is available in the HDF.  This will only be accurate if you pick cell faces that are perpendicular to flow.  Depending on the application, a more robust calculation may be required. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\14_fluvial_pluvial_delineation.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n"
          ]
        }
      ],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Delineate Fluvial and Pluvial Areas using RAS-Commander\n",
        "\n",
        "We will leverage the HEC RAS Summary Outputs to delineate the Fluvial and Pluvial Areas\n",
        "\n",
        "Maximum Water Surface Elevation (WSEL) for each cell is recorded, along with the timestamps of when the maximum WSEL occurs.\n",
        "\n",
        "By locating adjacent cells with dissimilar timestamps, we can delineate the Fluvial and Pluvial Areas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A note about datframe types: \n",
        "\n",
        "Information from the HEC-RAS plan files are generally dataframes.  The text file interface is for the 32-bit side of HEC-RAS and all spatial data is most easily accessed in the HDF files.  This includes plan_df, geom_df, hdf_paths_df\n",
        "\n",
        "Geometry elements (Mesh Faces and Nodes) are provided as Geodataframes (cell_polygons_gdf, boundary_gdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup\n",
        "Uncomment and run package installation commands if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ras-commander from pip (uncomment to install if needed)\n",
        "#!pip install ras-commander\n",
        "# This installs ras-commander and all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required modules\n",
        "#from ras_commander import *  # Import all ras-commander modules\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import h5py\n",
        "import numpy as np\n",
        "import requests\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "import xarray as xr\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:29 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BaldEagleCrkMulti2D.p06.hdf already exists. Skipping project extraction and plan execution.\n"
          ]
        }
      ],
      "source": [
        "# Download the BaldEagleCrkMulti2D project from HEC and run plan 06\n",
        "\n",
        "# Define the path to the BaldEagleCrkMulti2D project\n",
        "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
        "bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
        "import logging\n",
        "\n",
        "# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
        "hdf_file = bald_eagle_path / \"BaldEagleDamBrk.p06.hdf\"\n",
        "\n",
        "if not hdf_file.exists():\n",
        "    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
        "    RasExamples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
        "\n",
        "\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    logging.info(f\"Bald Eagle project initialized with folder: {ras.project_folder}\")\n",
        "    \n",
        "    logging.info(f\"Bald Eagle object id: {id(ras)}\")\n",
        "    \n",
        "    # Define the plan number to execute\n",
        "    plan_number = \"06\"\n",
        "\n",
        "    # Update the run flags in the plan file\n",
        "    RasPlan.update_run_flags(\n",
        "        plan_number,\n",
        "        geometry_preprocessor=True,  # Run HTab\n",
        "        unsteady_flow_simulation=True,  # Run UNet\n",
        "        post_processor=True,  # Run PostProcess\n",
        "        floodplain_mapping=False,  # Run RASMapper\n",
        "    )\n",
        "\n",
        "    # Execute Plan 06 using RasCmdr for Bald Eagle\n",
        "    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n",
        "    success_bald_eagle = RasCmdr.compute_plan(plan_number)\n",
        "    if success_bald_eagle:\n",
        "        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n",
        "else:\n",
        "    print(\"BaldEagleCrkMulti2D.p06.hdf already exists. Skipping project extraction and plan execution.\")\n",
        "    # Initialize the RAS project using the default global ras object\n",
        "    init_ras_project(bald_eagle_path, \"6.6\")\n",
        "    plan_number = 6\n",
        "your_project_path = bald_eagle_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  OPTIONAL: Use your own project instead\n",
        "\n",
        "your_project_path = Path(r\"D:\\yourprojectpath\")\n",
        "\n",
        "init_ras_project(your_project_path, \"6.6\")\n",
        "plan_number = \"01\"  # Plan number to use for this notebook \n",
        "\n",
        "\n",
        "\n",
        "### If you use this code cell, don't run the previous cell or change to markdown\n",
        "### NOTE: Ensure the HDF Results file was generated by HEC-RAS Version 6.x or above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Project Dataframes using 'ras' Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan DataFrame for bald_eagle project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>13</td>\\n', '      <td>07</td>\\n', '      <td>06</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.10</td>\\n', '      <td>PMF Multi 2D</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>30SEC</td>\\n', '      <td>30MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>193</td>\\n', '      <td>None</td>\\n', '      <td>06</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>07</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>15</td>\\n', '      <td>12</td>\\n', '      <td>08</td>\\n', '      <td>1d-2D Dambreak Refined Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>1D-2D Refined Grid</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>08</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>12</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>17</td>\\n', '      <td>09</td>\\n', '      <td>10</td>\\n', '      <td>2D to 1D No Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>2D to 1D No Dam</td>\\n', '      <td>01JAN1999,1200,06JAN1999,1200</td>\\n', '      <td>1MIN</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>Upstream2D</td>\\n', '      <td>None</td>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>09</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>18</td>\\n', '      <td>10</td>\\n', '      <td>11</td>\\n', '      <td>2D to 2D Run</td>\\n', '      <td>5.00</td>\\n', '      <td>2D to 2D Run</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>19</td>\\n', '      <td>11</td>\\n', '      <td>12</td>\\n', '      <td>SA to 2D Dam Break Run</td>\\n', '      <td>5.00</td>\\n', '      <td>SA to 2D Dam Break</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>10MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>12</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['   plan_number unsteady_number geometry_number  \\\\\\n', '0           13              07              06   \\n', '1           15              12              08   \\n', '2           17              09              10   \\n', '3           18              10              11   \\n', '4           19              11              12   \\n', '5           03              13              09   \\n', '6           04              01              13   \\n', '7           02              01              01   \\n', '8           01              01              01   \\n', '9           05              02              03   \\n', '10          06              03              09   \\n', '\\n', '                                 Plan Title Program Version  \\\\\\n', '0                   PMF with Multi 2D Areas            5.10   \\n', '1               1d-2D Dambreak Refined Grid            5.10   \\n', '2                           2D to 1D No Dam            5.00   \\n', '3                              2D to 2D Run            5.0\n...\n[Output truncated, 7422 characters total]"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n",
        "\n",
        "# Display plan_df for bald_eagle project\n",
        "print(\"Plan DataFrame for bald_eagle project:\")\n",
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Geometry DataFrame for the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>geom_file</th>\\n', '      <th>geom_number</th>\\n', '      <th>full_path</th>\\n', '      <th>hdf_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>g06</td>\\n', '      <td>06</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>g08</td>\\n', '      <td>08</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>g10</td>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>g11</td>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>g12</td>\\n', '      <td>12</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  geom_file geom_number                                          full_path  \\\\\\n', '0       g06          06  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '1       g08          08  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '2       g10          10  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '3       g11          11  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '4       g12          12  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '5       g09          09  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '6       g13          13  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '7       g01          01  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '8       g03          03  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '9       g02          02  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '\\n', '                                            hdf_path  \\n', '0  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '1  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '2  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '3  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '4  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '5  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '6  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '7  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '8  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '9  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  ']"
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nGeometry DataFrame for the project:\")\n",
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Unsteady DataFrame for the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>unsteady_number</th>\\n', '      <th>full_path</th>\\n', '      <th>Flow Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Use Restart</th>\\n', '      <th>Precipitation Mode</th>\\n', '      <th>Wind Mode</th>\\n', '      <th>Met BC=Precipitation|Mode</th>\\n', '      <th>Met BC=Evapotranspiration|Mode</th>\\n', '      <th>Met BC=Precipitation|Expanded View</th>\\n', '      <th>Met BC=Precipitation|Constant Units</th>\\n', '      <th>Met BC=Precipitation|Gridded Source</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>07</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>08</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>PMF for Upstream 2D</td>\\n', '      <td>4.20</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>09</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Upstream 2D</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>1972 Flood Event - 2D to 2D Run</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>1972 Flood Event - SA to 2D Run</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  unsteady_number                                          full_path  \\\\\\n', '0              07  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '1              08  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '2              09  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '3              10  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '4              11  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '5              12  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '6              13  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '7              01  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '8              02  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '9              03  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '\\n', '                             Flow Title Program Version Use Restart  \\\\\\n', '0               P\n...\n[Output truncated, 4267 characters total]"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nUnsteady DataFrame for the project:\")\n",
        "ras.unsteady_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Boundary Conditions DataFrame for the project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>unsteady_number</th>\\n', '      <th>boundary_condition_number</th>\\n', '      <th>river_reach_name</th>\\n', '      <th>river_station</th>\\n', '      <th>storage_area_name</th>\\n', '      <th>pump_station_name</th>\\n', '      <th>bc_type</th>\\n', '      <th>hydrograph_type</th>\\n', '      <th>Interval</th>\\n', '      <th>DSS File</th>\\n', '      <th>...</th>\\n', '      <th>Flow Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Use Restart</th>\\n', '      <th>Precipitation Mode</th>\\n', '      <th>Wind Mode</th>\\n', '      <th>Met BC=Precipitation|Mode</th>\\n', '      <th>Met BC=Evapotranspiration|Mode</th>\\n', '      <th>Met BC=Precipitation|Expanded View</th>\\n', '      <th>Met BC=Precipitation|Constant Units</th>\\n', '      <th>Met BC=Precipitation|Gridded Source</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>07</td>\\n', '      <td>1</td>\\n', '      <td>Bald Eagle Cr.</td>\\n', '      <td>Lock Haven</td>\\n', '      <td>137520</td>\\n', '      <td></td>\\n', '      <td>Flow Hydrograph</td>\\n', '      <td>Flow Hydrograph</td>\\n', '      <td>1HOUR</td>\\n', '      <td>Bald_Eagle_Creek.dss</td>\\n', '      <td>...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>07</td>\\n', '      <td>2</td>\\n', '      <td>Bald Eagle Cr.</td>\\n', '      <td>Lock Haven</td>\\n', '      <td>81454</td>\\n', '      <td></td>\\n', '      <td>Gate Opening</td>\\n', '      <td>None</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>07</td>\\n', '      <td>3</td>\\n', '      <td>Bald Eagle Cr.</td>\\n', '      <td>Lock Haven</td>\\n', '      <td>28519</td>\\n', '      <td></td>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>1HOUR</td>\\n', '      <td>Bald_Eagle_Creek.dss</td>\\n', '      <td>...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>07</td>\\n', '      <td>4</td>\\n', '      <td>Bald Eagle Cr.</td>\\n', '      <td>Lock Haven</td>\\n', '      <td>1</td>\\n', '      <td></td>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>1HOUR</td>\\n', '      <td>NaN</td>\\n', '      <td>...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>07</td>\\n', '      <td>5</td>\\n', '      <td>Bald Eagle Cr.</td>\\n', '      <td>Lock Haven</td>\\n', '      <td>136948</td>\\n', '      <td>82303</td>\\n', '      <td>Uniform Lateral Inflow Hydrograph</td>\\n', '      <td>Uniform Lateral Inflow Hydrograph</td>\\n', '      <td>1HOUR</td>\\n', '      <td>Bald_Eagle_Creek.dss</td>\\n', '      <td>...</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.00</td>\\n', '      <td>0</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['   unsteady_number  boundary_condition_number river_reach_name river_station  \\\\\\n', '0               07                          1   Bald Eagle Cr.    Lock Haven   \\n', '1               07                          2   Bald Eagle Cr.    Lock Haven   \\n', '2               07                          3   Bald Eagle Cr.    Lock Haven   \\n', '3               07                          4   Bald Eagle Cr.    Lock Haven   \\n', '4               07                          5   Bald Eagle Cr.    Lock Haven   \\n', '5               07                          6   Bald Eagle Cr.    Lock Haven   \\n', '6               07                          7   Bald Eagle Cr.    Lock Haven   \\n', '7               07                          8   Bald Eagle Cr.    Lock Haven   \\n', '8               07                          9   Bald Eagle Cr.    Lock Haven   \\n', '9               07                         10   Bald Eagle Cr.    Lock Haven   \\n', '10              08                          1   Bald Eagle Cr.\n...\n[Output truncated, 29090 characters total]"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nBoundary Conditions DataFrame for the project:\")\n",
        "ras.boundaries_df "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Find Paths for Results and Geometry HDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "06\n"
          ]
        }
      ],
      "source": [
        "plan_number = \"06\"\n",
        "print(plan_number)\n",
        "\n",
        "# Get the plan HDF path for the plan_number defined above\n",
        "plan_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[\"'C:\\\\\\\\GH\\\\\\\\ras-commander\\\\\\\\examples\\\\\\\\example_projects\\\\\\\\BaldEagleCrkMulti2D\\\\\\\\BaldEagleDamBrk.p06.hdf'\"]"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plan_hdf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the geometry HDF path\n",
        "geom_hdf_path = ras.plan_df.loc[ras.plan_df['plan_number'] == plan_number, 'Geom Path'].values[0] + '.hdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "[\"'C:\\\\\\\\GH\\\\\\\\ras-commander\\\\\\\\examples\\\\\\\\example_projects\\\\\\\\BaldEagleCrkMulti2D\\\\\\\\BaldEagleDamBrk.g09.hdf'\"]"
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "geom_hdf_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Plan HDF path for Plan 06: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "Geometry HDF path for Plan 06: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n",
        "print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fluvial Pluvial Delineation using RAS-Commander \n",
        "\n",
        "Using the Maximum WSE Results layer, which contains the maximum water surface and time stamp of the maximum water surface, mesh cell faces are categorized.  If the difference in time (delta_t) in hours is greater than the (user defined, default 12) duration specified, that mesh cell face is added to the fluvial-pluvial boundary dataset. \n",
        "\n",
        "This is meant to provide a draft fluvial-pluvial boundary for floodplain analysis, to the extent it can be derived directly from the HEC-RAS results files. \n",
        "\n",
        "The function attempts to combine adjacent line segments to simplify the resulting geometry, but GIS cleanup and manual interpolation will be required to create a closed polygon boundary that could be used for further processing steps.  However, this approach does provide an efficient method for providing a draft boundary that is based on HEC-RAS's direct computations and mesh cell faces. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfResultsMesh - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:29 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_ws_df\n",
            "         mesh_name  cell_id  maximum_water_surface maximum_water_surface_time  \\\n",
            "0      BaldEagleCr        0             704.054443        2018-09-10 18:00:00   \n",
            "1      BaldEagleCr        1             692.377991        2018-09-10 18:04:00   \n",
            "2      BaldEagleCr        2             671.183472        2018-09-10 18:13:20   \n",
            "3      BaldEagleCr        3             660.605469        2018-09-10 18:54:40   \n",
            "4      BaldEagleCr        4             660.586243        2018-09-10 18:55:20   \n",
            "...            ...      ...                    ...                        ...   \n",
            "19592  BaldEagleCr    19592               0.000000        2018-09-09 00:00:00   \n",
            "19593  BaldEagleCr    19593               0.000000        2018-09-09 00:00:00   \n",
            "19594  BaldEagleCr    19594               0.000000        2018-09-09 00:00:00   \n",
            "19595  BaldEagleCr    19595               0.000000        2018-09-09 00:00:00   \n",
            "19596  BaldEagleCr    19596               0.000000        2018-09-09 00:00:00   \n",
            "\n",
            "                             geometry  \n",
            "0              POINT (2083000 370750)  \n",
            "1              POINT (2083250 370750)  \n",
            "2              POINT (2083500 370750)  \n",
            "3              POINT (2083750 370750)  \n",
            "4              POINT (2084000 370750)  \n",
            "...                               ...  \n",
            "19592  POINT (1978423.032 300718.897)  \n",
            "19593  POINT (1973389.375 297311.928)  \n",
            "19594   POINT (1968834.79 295808.861)  \n",
            "19595  POINT (1966130.942 291879.395)  \n",
            "19596   POINT (1969660.046 289673.23)  \n",
            "\n",
            "[19597 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Using mesh_max_ws, get the cell coordinates and plot the max water surface as a map\n",
        "import matplotlib.pyplot as plt\n",
        "from ras_commander import HdfMesh\n",
        "from ras_commander import HdfResultsMesh\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Get mesh max water surface\n",
        "max_ws_df = HdfResultsMesh.get_mesh_max_ws(plan_hdf_path)\n",
        "\n",
        "print(\"max_ws_df\")\n",
        "print(max_ws_df)\n",
        "\n",
        "# If you get an error here, you may have a pre-6.0 HDF.  Re-run in 6.x to generate a new results file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Simulation Start Time: 2018-09-09 00:00:00\n",
            "Time Range: 120.0 hours\n",
            "\n",
            "Timing Statistics (hours since start):\n",
            "count    19597.000000\n",
            "mean        63.225584\n",
            "std         40.179644\n",
            "min          0.000000\n",
            "25%         34.000000\n",
            "50%         42.700000\n",
            "75%        115.677778\n",
            "max        120.000000\n",
            "Name: max_wsel_time, dtype: float64\n",
            "\n",
            "First few rows of the merged dataframe:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>mesh_name</th>\\n', '      <th>cell_id</th>\\n', '      <th>maximum_water_surface</th>\\n', '      <th>maximum_water_surface_time</th>\\n', '      <th>geometry</th>\\n', '      <th>x</th>\\n', '      <th>y</th>\\n', '      <th>max_wsel_time</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>0</td>\\n', '      <td>704.054443</td>\\n', '      <td>2018-09-10 18:00:00</td>\\n', '      <td>POINT (2083000 370750)</td>\\n', '      <td>2.083000e+06</td>\\n', '      <td>370750.000000</td>\\n', '      <td>2018-09-10 18:00:00</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>1</td>\\n', '      <td>692.377991</td>\\n', '      <td>2018-09-10 18:04:00</td>\\n', '      <td>POINT (2083250 370750)</td>\\n', '      <td>2.083250e+06</td>\\n', '      <td>370750.000000</td>\\n', '      <td>2018-09-10 18:04:00</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>2</td>\\n', '      <td>671.183472</td>\\n', '      <td>2018-09-10 18:13:20</td>\\n', '      <td>POINT (2083500 370750)</td>\\n', '      <td>2.083500e+06</td>\\n', '      <td>370750.000000</td>\\n', '      <td>2018-09-10 18:13:20</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>3</td>\\n', '      <td>660.605469</td>\\n', '      <td>2018-09-10 18:54:40</td>\\n', '      <td>POINT (2083750 370750)</td>\\n', '      <td>2.083750e+06</td>\\n', '      <td>370750.000000</td>\\n', '      <td>2018-09-10 18:54:40</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>4</td>\\n', '      <td>660.586243</td>\\n', '      <td>2018-09-10 18:55:20</td>\\n', '      <td>POINT (2084000 370750)</td>\\n', '      <td>2.084000e+06</td>\\n', '      <td>370750.000000</td>\\n', '      <td>2018-09-10 18:55:20</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['         mesh_name  cell_id  maximum_water_surface maximum_water_surface_time  \\\\\\n', '0      BaldEagleCr        0             704.054443        2018-09-10 18:00:00   \\n', '1      BaldEagleCr        1             692.377991        2018-09-10 18:04:00   \\n', '2      BaldEagleCr        2             671.183472        2018-09-10 18:13:20   \\n', '3      BaldEagleCr        3             660.605469        2018-09-10 18:54:40   \\n', '4      BaldEagleCr        4             660.586243        2018-09-10 18:55:20   \\n', '...            ...      ...                    ...                        ...   \\n', '19592  BaldEagleCr    19592               0.000000        2018-09-09 00:00:00   \\n', '19593  BaldEagleCr    19593               0.000000        2018-09-09 00:00:00   \\n', '19594  BaldEagleCr    19594               0.000000        2018-09-09 00:00:00   \\n', '19595  BaldEagleCr    19595               0.000000        2018-09-09 00:00:00   \\n', '19596  BaldEagleCr    19596               0.000000 \n...\n[Output truncated, 2376 characters total]"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Call the function to plot\n",
        "HdfResultsPlot.plot_results_max_wsel(max_ws_df)\n",
        "\n",
        "# Plot the time of maximum water surface elevation\n",
        "HdfResultsPlot.plot_results_max_wsel_time(max_ws_df)\n",
        "\n",
        "# Print the first few rows of the merged dataframe for verification\n",
        "print(\"\\nFirst few rows of the merged dataframe:\")\n",
        "max_ws_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfBase - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Projection from HDF\n",
            "Projection: PROJCS[\"NAD_1983_StatePlane_Pennsylvania_North_FIPS_3701_Feet\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Lambert_Conformal_Conic\"],PARAMETER[\"False_Easting\",1968500.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-77.75],PARAMETER[\"Standard_Parallel_1\",40.88333333333333],PARAMETER[\"Standard_Parallel_2\",41.95],PARAMETER[\"Latitude_Of_Origin\",40.16666666666666],UNIT[\"Foot_US\",0.3048006096012192]]\n"
          ]
        }
      ],
      "source": [
        "# Use HdfUtils for extracting projection\n",
        "print(\"\\nExtracting Projection from HDF\")\n",
        "projection = HdfBase.get_projection(hdf_path=geom_hdf_path)\n",
        "if projection:\n",
        "    print(f\"Projection: {projection}\")\n",
        "else:\n",
        "    print(\"No projection information found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:30 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 6: Extracting Cell Polygons\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.g09.hdf\n"
          ]
        }
      ],
      "source": [
        "# Example: Extract Cell Polygons\n",
        "print(\"\\nExample 6: Extracting Cell Polygons\")\n",
        "cell_polygons_gdf = HdfMesh.get_mesh_cell_polygons(geom_hdf_path)\n",
        "\n",
        "\n",
        "# Call the function to plot cell polygons\n",
        "#cell_polygons_gdf = HdfFluvialPluvial.plot_cell_polygons(cell_polygons_gdf, projection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfFluvialPluvial - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfFluvialPluvial - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfFluvialPluvial - INFO - Getting cell polygons from HDF file...\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:31 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfFluvialPluvial - INFO - Getting maximum water surface data from HDF file...\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfResultsMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfFluvialPluvial - INFO - Converting maximum water surface timestamps...\n",
            "2025-12-02 20:12:32 - ras_commander.hdf.HdfFluvialPluvial - INFO - Processing cell adjacencies...\n",
            "2025-12-02 20:12:34 - ras_commander.hdf.HdfFluvialPluvial - INFO - Extracting cell times from maximum water surface data...\n",
            "2025-12-02 20:12:34 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identifying boundary edges...\n",
            "2025-12-02 20:12:35 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identified 3201 boundary edges using delta_t of 72 hours.\n",
            "2025-12-02 20:12:35 - ras_commander.hdf.HdfFluvialPluvial - INFO - Creating final GeoDataFrame for boundaries...\n",
            "2025-12-02 20:12:35 - ras_commander.hdf.HdfFluvialPluvial - INFO - Boundary line calculation completed successfully.\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely.geometry import LineString, Polygon, MultiLineString\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from rtree import index\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "boundary_gdf = HdfFluvialPluvial.calculate_fluvial_pluvial_boundary(plan_hdf_path, delta_t=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boundary line length statistics:\n",
            "Max length: 441.63\n",
            "Min length: 1.57\n",
            "Average length: 242.54\n",
            "Median length: 250.00\n",
            "\n",
            "Boundary GeoDataFrame info:\n",
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 3201 entries, 0 to 3200\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype   \n",
            "---  ------    --------------  -----   \n",
            " 0   geometry  3201 non-null   geometry\n",
            "dtypes: geometry(1)\n",
            "memory usage: 25.1 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Calculate statistics about the boundary line lengths\n",
        "boundary_lengths = boundary_gdf.geometry.length\n",
        "\n",
        "print(\"Boundary line length statistics:\")\n",
        "print(f\"Max length: {boundary_lengths.max():.2f}\")\n",
        "print(f\"Min length: {boundary_lengths.min():.2f}\")\n",
        "print(f\"Average length: {boundary_lengths.mean():.2f}\")\n",
        "print(f\"Median length: {boundary_lengths.median():.2f}\")\n",
        "\n",
        "# Print general information about the boundary GeoDataFrame\n",
        "print(\"\\nBoundary GeoDataFrame info:\")\n",
        "print(boundary_gdf.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the results\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "cell_polygons_gdf.plot(ax=ax, edgecolor='gray', facecolor='none', alpha=0.5)\n",
        "boundary_gdf.plot(ax=ax, color='red', linewidth=2)\n",
        "plt.title('Fluvial-Pluvial Boundary')\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\billk_clb\\AppData\\Local\\Temp\\ipykernel_57556\\1399630256.py:10: UserWarning: The GeoDataFrame you are attempting to plot is empty. Nothing has been displayed.\n",
            "  filtered_boundary_gdf.plot(ax=ax, color='red', linewidth=2, label='Valid Boundaries')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "length_threshold = 3000 #in same units as X and Y coordinates\n",
        "\n",
        "# Filter out boundary lines below the length threshold\n",
        "filtered_boundary_gdf = boundary_gdf[boundary_lengths >= length_threshold]\n",
        "highlighted_boundary_gdf = boundary_gdf[boundary_lengths < length_threshold]\n",
        "\n",
        "# Visualize the results with highlighted boundaries below the threshold\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "cell_polygons_gdf.plot(ax=ax, edgecolor='gray', facecolor='none', alpha=0.5)\n",
        "filtered_boundary_gdf.plot(ax=ax, color='red', linewidth=2, label='Valid Boundaries')\n",
        "highlighted_boundary_gdf.plot(ax=ax, color='blue', linewidth=2, linestyle='--', label='Highlighted Boundaries Below Threshold')\n",
        "plt.title('Fluvial-Pluvial Boundary with Length Threshold')\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfFluvialPluvial - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfFluvialPluvial - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfFluvialPluvial - INFO - Getting cell polygons from HDF file...\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:39 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:40 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:40 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:40 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfFluvialPluvial - INFO - Getting maximum water surface data from HDF file...\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfResultsMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfFluvialPluvial - INFO - Converting maximum water surface timestamps...\n",
            "2025-12-02 20:12:41 - ras_commander.hdf.HdfFluvialPluvial - INFO - Processing cell adjacencies...\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Extracting cell times from maximum water surface data...\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identifying boundary edges...\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identified 3201 boundary edges using delta_t of 72 hours.\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - 3201 boundary line(s) shorter than 3000 units were dropped after filtering.\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Creating final GeoDataFrame for boundaries...\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Boundary line calculation completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Example usage using Optional min_line_length argument:\n",
        "boundary_gdf = HdfFluvialPluvial.calculate_fluvial_pluvial_boundary(plan_hdf_path, delta_t=72, min_line_length=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfFluvialPluvial - INFO - Loading mesh and results data...\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:43 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfResultsMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n",
            "2025-12-02 20:12:44 - ras_commander.hdf.HdfFluvialPluvial - INFO - Processing cell adjacencies...\n",
            "2025-12-02 20:12:47 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identifying initial boundary seeds with delta_t = 10 hours...\n",
            "2025-12-02 20:12:48 - ras_commander.hdf.HdfFluvialPluvial - INFO - Starting iterative region growth with tolerance = 1.0 hours...\n",
            "Region Growing: 33iter [00:00, 81.92iter/s, Fluvial=0, Pluvial=0, Ambiguous=0]      \n",
            "2025-12-02 20:12:48 - ras_commander.hdf.HdfFluvialPluvial - INFO - Region growing completed in 33 iterations.\n",
            "2025-12-02 20:12:48 - ras_commander.hdf.HdfFluvialPluvial - INFO - Merging classifications with cell polygons...\n",
            "2025-12-02 20:12:48 - ras_commander.hdf.HdfFluvialPluvial - INFO - Dissolving polygons by classification...\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Applying minimum polygon area filter: 1000 acres\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Found 235 small fluvial and 140 small pluvial polygons to reclassify.\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Redissolved polygons after reclassification of small areas.\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Polygon generation completed successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To get the classified flood zones as polygons:\n",
        "flood_polygons_gdf = HdfFluvialPluvial.generate_fluvial_pluvial_polygons(\n",
        "    plan_hdf_path, \n",
        "    delta_t=10, \n",
        "    temporal_tolerance_hours=1.0,\n",
        "    min_polygon_area_acres=1000\n",
        ")\n",
        "\n",
        "flood_polygons_gdf\n",
        "\n",
        "# Plot the classified flood zones as polygons, colored by classification\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "flood_polygons_gdf.plot(\n",
        "    ax=ax,\n",
        "    column=\"classification\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    edgecolor=\"black\",\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title(\"Fluvial-Pluvial Classified Flood Zones\")\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfFluvialPluvial - INFO - Loading mesh and results data...\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:49 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfResultsMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n",
            "2025-12-02 20:12:51 - ras_commander.hdf.HdfFluvialPluvial - INFO - Processing cell adjacencies...\n",
            "2025-12-02 20:12:53 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identifying initial boundary seeds with delta_t = 12 hours...\n",
            "2025-12-02 20:12:54 - ras_commander.hdf.HdfFluvialPluvial - INFO - Starting iterative region growth with tolerance = 1.0 hours...\n",
            "Region Growing: 37iter [00:00, 91.41iter/s, Fluvial=0, Pluvial=0, Ambiguous=0]      \n",
            "2025-12-02 20:12:54 - ras_commander.hdf.HdfFluvialPluvial - INFO - Region growing completed in 37 iterations.\n",
            "2025-12-02 20:12:54 - ras_commander.hdf.HdfFluvialPluvial - INFO - Merging classifications with cell polygons...\n",
            "2025-12-02 20:12:54 - ras_commander.hdf.HdfFluvialPluvial - INFO - Dissolving polygons by classification...\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Applying minimum polygon area filter: 200 acres\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Found 214 small fluvial and 96 small pluvial polygons to reclassify.\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Redissolved polygons after reclassification of small areas.\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Polygon generation completed successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To get the classified flood zones as polygons:\n",
        "flood_polygons_gdf = HdfFluvialPluvial.generate_fluvial_pluvial_polygons(\n",
        "    plan_hdf_path, \n",
        "    delta_t=12, \n",
        "    temporal_tolerance_hours=1.0,\n",
        "    min_polygon_area_acres=200\n",
        ")\n",
        "\n",
        "flood_polygons_gdf\n",
        "\n",
        "# Plot the classified flood zones as polygons, colored by classification\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "flood_polygons_gdf.plot(\n",
        "    ax=ax,\n",
        "    column=\"classification\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    edgecolor=\"black\",\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title(\"Fluvial-Pluvial Classified Flood Zones\")\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Using HDF file from direct string path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfFluvialPluvial - INFO - Loading mesh and results data...\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:55 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfResultsMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfResultsMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfResultsMesh - INFO - Processing summary output for variable: Maximum Water Surface\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfMesh - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfMesh - INFO - Using existing Path object HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfMesh - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Using HDF file from h5py.File object: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfBase - INFO - Found projection in HDF file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.hdf\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfResultsMesh - INFO - Processed 19597 rows of summary output data\n",
            "2025-12-02 20:12:56 - ras_commander.hdf.HdfFluvialPluvial - INFO - Processing cell adjacencies...\n",
            "2025-12-02 20:12:58 - ras_commander.hdf.HdfFluvialPluvial - INFO - Identifying initial boundary seeds with delta_t = 14 hours...\n",
            "2025-12-02 20:12:59 - ras_commander.hdf.HdfFluvialPluvial - INFO - Starting iterative region growth with tolerance = 1.0 hours...\n",
            "Region Growing: 42iter [00:00, 96.83iter/s, Fluvial=0, Pluvial=0, Ambiguous=0]      \n",
            "2025-12-02 20:12:59 - ras_commander.hdf.HdfFluvialPluvial - INFO - Region growing completed in 42 iterations.\n",
            "2025-12-02 20:12:59 - ras_commander.hdf.HdfFluvialPluvial - INFO - Merging classifications with cell polygons...\n",
            "2025-12-02 20:12:59 - ras_commander.hdf.HdfFluvialPluvial - INFO - Dissolving polygons by classification...\n",
            "2025-12-02 20:13:00 - ras_commander.hdf.HdfFluvialPluvial - INFO - Applying minimum polygon area filter: 1000 acres\n",
            "2025-12-02 20:13:00 - ras_commander.hdf.HdfFluvialPluvial - INFO - Found 182 small fluvial and 69 small pluvial polygons to reclassify.\n",
            "2025-12-02 20:13:00 - ras_commander.hdf.HdfFluvialPluvial - INFO - Redissolved polygons after reclassification of small areas.\n",
            "2025-12-02 20:13:00 - ras_commander.hdf.HdfFluvialPluvial - INFO - Polygon generation completed successfully.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To get the classified flood zones as polygons:\n",
        "flood_polygons_gdf = HdfFluvialPluvial.generate_fluvial_pluvial_polygons(\n",
        "    plan_hdf_path, \n",
        "    delta_t=14, \n",
        "    temporal_tolerance_hours=1.0,\n",
        "    min_polygon_area_acres=1000\n",
        ")\n",
        "\n",
        "flood_polygons_gdf\n",
        "\n",
        "# Plot the classified flood zones as polygons, colored by classification\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "flood_polygons_gdf.plot(\n",
        "    ax=ax,\n",
        "    column=\"classification\",\n",
        "    categorical=True,\n",
        "    legend=True,\n",
        "    edgecolor=\"black\",\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title(\"Fluvial-Pluvial Classified Flood Zones\")\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:13:00 - pyogrio._io - INFO - Created 3 records\n"
          ]
        }
      ],
      "source": [
        "flood_polygons_gdf.to_file(driver='GeoJSON', filename='flood_polygons.geojson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:13:00 - pyogrio._io - INFO - Created 0 records\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output directory created/verified at: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\fluvial_pluvial_boundary\n"
          ]
        }
      ],
      "source": [
        "# Create fluvial_pluvial_boundary subfolder\n",
        "output_dir = your_project_path / \"fluvial_pluvial_boundary\"\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "print(f\"Output directory created/verified at: {output_dir}\")\n",
        "\n",
        "# Save to GeoJSON in output directory\n",
        "boundary_gdf.to_file(output_dir / 'fluvial_pluvial_boundary.geojson', driver='GeoJSON')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\15_stored_map_generation.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:28.559444Z",
          "iopub.status.busy": "2025-11-17T18:53:28.559259Z",
          "iopub.status.idle": "2025-11-17T18:53:30.114200Z",
          "shell.execute_reply": "2025-11-17T18:53:30.113608Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAS Commander: Post-Processing Stored Maps\n",
        "\n",
        "This notebook demonstrates how to automate the generation of stored floodplain map outputs (like `.tif` files for Depth, WSEL, and Velocity) using the `ras-commander` library. This is a common post-processing step that can be time-consuming to do manually for multiple plans.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1.  **Initialize Project**: Set up the HEC-RAS project.\n",
        "2.  **Run Simulation**: Ensure a plan has been computed to generate base results.\n",
        "3.  **Automate Post-Processing**: Use the new `RasMap.postprocess_stored_maps` function to:\n",
        "    -   Modify the `.rasmap` file to include stored map definitions.\n",
        "    -   Update plan flags to *only* run the floodplain mapping component.\n",
        "    -   Execute the plan, which quickly generates the `.tif` files.\n",
        "    -   Restore the original plan and `.rasmap` files, keeping the new map layers.\n",
        "4.  **Verify Output**: Load and visualize one of the generated `.tif` files to confirm success."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install necessary packages if not already installed\n",
        "!pip install --upgrade ras-commander\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative: Multi-Plan Mapping in RASMapper\n",
        "\n",
        "Right click on the results layer, and \"Manage Results Maps\", then select all and click \"Compute/Update Stored Maps\".  This will create all results maps in RASMapper.\n",
        "\n",
        "Note: For large batches, RASMapper can run out of memory and fail.  The workflow below, which uses pre-sets the floodplain mapping option for HEC-RAS's Unsteady Flow Analysis or Run Multiple Plans mode which is more reliable for larger datasets/batching.  \n",
        "\n",
        "Use the simplest method that works!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run with Full Windows GUI\n",
        "\n",
        "[RAS Commander Stored Map Assistant](https://github.com/gpt-cmdr/ras-stored-map-assistant)  (Coming soon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.116870Z",
          "iopub.status.busy": "2025-11-17T18:53:30.116475Z",
          "iopub.status.idle": "2025-11-17T18:53:30.121350Z",
          "shell.execute_reply": "2025-11-17T18:53:30.120743Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n",
            "ras-commander loaded from: c:\\Users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\Lib\\site-packages\n",
            "Expected local path: C:\\GH\\ras-commander\n",
            "Successfully using local copy: False\n"
          ]
        }
      ],
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Now try to import again\n",
        "from ras_commander import *\n",
        "\n",
        "# Verify we're loading from the local copy\n",
        "import ras_commander\n",
        "local_path = Path(ras_commander.__file__).parent.parent\n",
        "print(f\"ras-commander loaded from: {local_path}\")\n",
        "print(f\"Expected local path: {rascmdr_directory}\")\n",
        "print(f\"Successfully using local copy: {local_path == rascmdr_directory}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install necessary packages if not already installed\n",
        "!pip install --upgrade ras-commander\n",
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.123790Z",
          "iopub.status.busy": "2025-11-17T18:53:30.123459Z",
          "iopub.status.idle": "2025-11-17T18:53:30.223841Z",
          "shell.execute_reply": "2025-11-17T18:53:30.223284Z"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from ras_commander import *\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Prepare the HEC-RAS Project\n",
        "\n",
        "First, we'll use `RasExamples` to get the `BaldEagleCrkMulti2D` project. Then, we'll run **Plan 06** to ensure we have a base set of results to work with. If the results already exist, the execution will be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.226925Z",
          "iopub.status.busy": "2025-11-17T18:53:30.226499Z",
          "iopub.status.idle": "2025-11-17T18:53:30.256162Z",
          "shell.execute_reply": "2025-11-17T18:53:30.255710Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:30:57 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for Plan 06 already exist. Skipping initial computation.\n"
          ]
        }
      ],
      "source": [
        "# If /example_projects/BaldEagleCrkMulti2D does not exist, extract it\n",
        "project_path = Path(\"./example_projects/BaldEagleCrkMulti2D\").resolve()\n",
        "\n",
        "if not os.path.exists(project_path):\n",
        "    project_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
        "\n",
        "# Initialize the RAS project\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "# Define the plan to work with\n",
        "plan_number = \"06\"\n",
        "\n",
        "# Check if the plan's HDF results file already exists\n",
        "plan_hdf_path = ras.project_folder / f\"{ras.project_name}.p{plan_number}.hdf\"\n",
        "if not plan_hdf_path.exists():\n",
        "    print(f\"Results for Plan {plan_number} not found. Running the simulation first...\")\n",
        "    success = RasCmdr.compute_plan(plan_number, num_cores=4)\n",
        "    if not success:\n",
        "        raise RuntimeError(f\"Initial computation of plan {plan_number} failed.\")\n",
        "    print(f\"Plan {plan_number} successfully computed.\")\n",
        "else:\n",
        "    print(f\"Results for Plan {plan_number} already exist. Skipping initial computation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Use `postprocess_stored_maps` to Generate Floodplain Maps\n",
        "\n",
        "Now we'll call the new function. It will handle all the file modifications, run HEC-RAS in mapping-only mode, and clean up afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.258309Z",
          "iopub.status.busy": "2025-11-17T18:53:30.257971Z",
          "iopub.status.idle": "2025-11-17T18:53:30.273936Z",
          "shell.execute_reply": "2025-11-17T18:53:30.273428Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>13</td>\\n', '      <td>07</td>\\n', '      <td>06</td>\\n', '      <td>PMF with Multi 2D Areas</td>\\n', '      <td>5.10</td>\\n', '      <td>PMF Multi 2D</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>30SEC</td>\\n', '      <td>30MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>193</td>\\n', '      <td>None</td>\\n', '      <td>06</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>07</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>15</td>\\n', '      <td>12</td>\\n', '      <td>08</td>\\n', '      <td>1d-2D Dambreak Refined Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>1D-2D Refined Grid</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>08</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>12</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>17</td>\\n', '      <td>09</td>\\n', '      <td>10</td>\\n', '      <td>2D to 1D No Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>2D to 1D No Dam</td>\\n', '      <td>01JAN1999,1200,06JAN1999,1200</td>\\n', '      <td>1MIN</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>Upstream2D</td>\\n', '      <td>None</td>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>09</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>18</td>\\n', '      <td>10</td>\\n', '      <td>11</td>\\n', '      <td>2D to 2D Run</td>\\n', '      <td>5.00</td>\\n', '      <td>2D to 2D Run</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>10</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>19</td>\\n', '      <td>11</td>\\n', '      <td>12</td>\\n', '      <td>SA to 2D Dam Break Run</td>\\n', '      <td>5.00</td>\\n', '      <td>SA to 2D Dam Break</td>\\n', '      <td>01JAN1999,1200,04JAN1999,1200</td>\\n', '      <td>20SEC</td>\\n', '      <td>10MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>BaldEagleCr</td>\\n', '      <td>None</td>\\n', '      <td>12</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>11</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['   plan_number unsteady_number geometry_number  \\\\\\n', '0           13              07              06   \\n', '1           15              12              08   \\n', '2           17              09              10   \\n', '3           18              10              11   \\n', '4           19              11              12   \\n', '5           03              13              09   \\n', '6           04              01              13   \\n', '7           02              01              01   \\n', '8           01              01              01   \\n', '9           05              02              03   \\n', '10          06              03              09   \\n', '\\n', '                                 Plan Title Program Version  \\\\\\n', '0                   PMF with Multi 2D Areas            5.10   \\n', '1               1d-2D Dambreak Refined Grid            5.10   \\n', '2                           2D to 1D No Dam            5.00   \\n', '3                              2D to 2D Run            5.0\n...\n[Output truncated, 7422 characters total]"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.276358Z",
          "iopub.status.busy": "2025-11-17T18:53:30.276028Z",
          "iopub.status.idle": "2025-11-17T18:53:30.278579Z",
          "shell.execute_reply": "2025-11-17T18:53:30.278127Z"
        }
      },
      "outputs": [],
      "source": [
        "# NOTE: For HEC-RAS 5.0.7 projects being run in HEC-RAS 6.x, you must manually open Ras.exe and use RASMapper to generate easmapper entries.\n",
        "# This step is only required for 5.0.7 projects run in 6.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:30.280651Z",
          "iopub.status.busy": "2025-11-17T18:53:30.280431Z",
          "iopub.status.idle": "2025-11-17T18:53:50.318595Z",
          "shell.execute_reply": "2025-11-17T18:53:50.317872Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MANUAL STEP REQUIRED: Update .rasmap to Version 6.x\n",
            "This project was created in HEC-RAS 5.0.7. To generate stored maps in HEC-RAS 6.x, you must:\n",
            "1. HEC-RAS will now be opened with this project.\n",
            "2. In HEC-RAS, open RAS Mapper (from the main toolbar).\n",
            "3. When prompted, allow RAS Mapper to update the .rasmap file to the new version.\n",
            "4. Once the update is complete, close RAS Mapper and exit HEC-RAS.\n",
            "\n",
            "After closing HEC-RAS, return here and continue running the notebook.\n",
            "============================================================\n",
            "\n",
            "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\"\n",
            "Opened HEC-RAS with Process ID: 236432\n",
            "Please wait for the next cell to automate RAS Mapper...\n",
            "Looking for HEC-RAS windows for process ID: 236432\n",
            "Waiting for HEC-RAS to fully load...\n",
            "No HEC-RAS windows found yet, waiting 2 seconds...\n",
            "Found 2 window(s) for this HEC-RAS process:\n",
            "  - HEC-RAS 6.6\n",
            "  - RAS\n",
            "\n",
            "Using main window: HEC-RAS 6.6\n",
            "\n",
            "Attempting to open RAS Mapper via menu...\n",
            "\n",
            "Found 7 top-level menus:\n",
            "\n",
            "Menu 0: '&File'\n",
            "  Contains 27 items:\n",
            "    Item 0: '&New Project ...' (ID: 2)\n",
            "    Item 1: '&Open Project ...' (ID: 3)\n",
            "    Item 2: '&Save Project' (ID: 4)\n",
            "    Item 3: 'Save Project &As ...' (ID: 5)\n",
            "    Item 4: '&Rename Project Title ...' (ID: 6)\n",
            "    Item 5: '&Delete Project ...' (ID: 7)\n",
            "    Item 6: '' (ID: 8)\n",
            "    Item 7: '&Project Summary ...' (ID: 9)\n",
            "    Item 8: 'Compare Model Data ...' (ID: 10)\n",
            "    Item 9: '' (ID: 11)\n",
            "    Item 10: '&Import HEC-2 Data ...' (ID: 12)\n",
            "    Item 11: 'I&mport HEC-RAS Data ...' (ID: 13)\n",
            "    Item 12: '&Generate Report ...' (ID: 14)\n",
            "    Item 13: '&Export GIS Data ...' (ID: 15)\n",
            "    Item 14: 'Export to HEC-&DSS ...' (ID: 16)\n",
            "    Item 15: 'Restore Backup Data ' (ID: -1)\n",
            "    Item 16: '' (ID: 23)\n",
            "    Item 17: 'Zip Plan(s) or Archive Project...' (ID: 24)\n",
            "    Item 18: '' (ID: 25)\n",
            "    Item 19: 'E&xit' (ID: 26)\n",
            "    Item 20: '' (ID: 27)\n",
            "    Item 21: 'C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj' (ID: 28)\n",
            "    Item 22: 'C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.prj' (ID: 29)\n",
            "    Item 23: 'C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.prj' (ID: 30)\n",
            "    Item 24: 'C:\\HCFCD\\Standard_Benefits_Process\\3 - Model Data\\Storm Interpolator - Log Linear\\Output Projects\\South_Belt_RAS66_2025-11-13_044255\\A120-00-00_RAS 4.1\\A100_00_00.prj' (ID: 31)\n",
            "    Item 25: 'C:\\HCFCD\\Standard_Benefits_Process\\3 - Model Data\\Storm Interpolator - Log Linear\\Input Projects\\A520-03-00-E003 - South Belt Stormwater Detention Basin\\A120-00-00_RAS 4.1\\A100_00_00.prj' (ID: 32)\n",
            "    Item 26: 'C:\\GH\\TNTech\\data\\EarlyDevTesting\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj' (ID: 33)\n",
            "\n",
            "Menu 1: '&Edit'\n",
            "  Contains 8 items:\n",
            "    Item 0: '&Geometric Data ...' (ID: 37)\n",
            "    Item 1: '' (ID: 38)\n",
            "    Item 2: '&Steady Flow Data ...' (ID: 39)\n",
            "    Item 3: '&Quasi Unsteady Flow (Sediment) ...' (ID: 40)\n",
            "    Item 4: '&Unsteady Flow Data ...' (ID: 41)\n",
            "    Item 5: '' (ID: 42)\n",
            "    Item 6: 'Se&diment Data ...' (ID: 43)\n",
            "    Item 7: '&Water Quality Data ...' (ID: 44)\n",
            "\n",
            "Menu 2: '&Run'\n",
            "  Contains 9 items:\n",
            "    Item 0: '&Steady Flow Analysis ...' (ID: 46)\n",
            "    Item 1: '&Unsteady Flow Analysis ...' (ID: 47)\n",
            "    Item 2: 'Quasi-Unsteady Analysis (Sediment)...' (ID: 48)\n",
            "    Item 3: 'Water Quality Analysis ...' (ID: 49)\n",
            "    Item 4: '&Hydraulic Design Functions ...' (ID: 50)\n",
            "    Item 5: '' (ID: 51)\n",
            "    Item 6: 'Run Multiple Plans ...' (ID: 52)\n",
            "    Item 7: '' (ID: 54)\n",
            "    Item 8: 'Uncertainty Analysis' (ID: -1)\n",
            "\n",
            "Menu 3: '&View'\n",
            "  Contains 23 items:\n",
            "    Item 0: '&Cross-Sections ...' (ID: 61)\n",
            "    Item 1: '&Water Surface Profiles ...' (ID: 62)\n",
            "    Item 2: '&General Profile Plot ...' (ID: 63)\n",
            "    Item 3: '&Rating Curves ...' (ID: 64)\n",
            "    Item 4: '3D View ...' (ID: 65)\n",
            "    Item 5: '&X-Y-Z Perspective Plots (Classic) ...' (ID: 66)\n",
            "    Item 6: '&Stage and Flow Hydrographs ...' (ID: 67)\n",
            "    Item 7: '&Hydraulic Property Tables ...' (ID: 68)\n",
            "    Item 8: '' (ID: 69)\n",
            "    Item 9: '&Detailed Output Tables ...' (ID: 70)\n",
            "    Item 10: '&Profile Summary Table ...' (ID: 71)\n",
            "    Item 11: '&Summary Err,Warn, Notes ...' (ID: 72)\n",
            "    Item 12: '' (ID: 73)\n",
            "    Item 13: 'DSS Data ...' (ID: 74)\n",
            "    Item 14: '' (ID: 75)\n",
            "    Item 15: 'Unsteady Flow Spatial Plot (computation interval) ...' (ID: 76)\n",
            "    Item 16: 'Unsteady Flow Time Series Plot (computation interval) ...' (ID: 77)\n",
            "    Item 17: '' (ID: 78)\n",
            "    Item 18: 'WQ Spatial Plot ...' (ID: 79)\n",
            "    Item 19: 'WQ Time Series Plot ...' (ID: 80)\n",
            "    Item 20: '' (ID: 81)\n",
            "    Item 21: 'Sediment Output ...' (ID: 82)\n",
            "    Item 22: 'Legacy Sediment Output' (ID: -1)\n",
            "\n",
            "Menu 4: '&Options'\n",
            "  Contains 5 items:\n",
            "    Item 0: '&Program Setup' (ID: -1)\n",
            "    Item 1: '&Default Parameters' (ID: -1)\n",
            "    Item 2: '&Unit system (US Customary/SI) ...' (ID: 98)\n",
            "    Item 3: '&Convert Project Units ...' (ID: 99)\n",
            "    Item 4: 'Convert &Horizontal Coordinate Systems ...' (ID: 100)\n",
            "\n",
            "Menu 5: '&GIS Tools'\n",
            "  Contains 1 items:\n",
            "    Item 0: 'RAS Mapper ...' (ID: 102)\n",
            "\n",
            "Menu 6: '&Help'\n",
            "  Contains 21 items:\n",
            "    Item 0: 'HEC-RAS Online Documentation ...\tF1' (ID: 104)\n",
            "    Item 1: 'Release Notes ...' (ID: 105)\n",
            "    Item 2: 'Known Issues ...' (ID: 106)\n",
            "    Item 3: 'Community Support on Discourse ...' (ID: 107)\n",
            "    Item 4: '' (ID: 108)\n",
            "    Item 5: 'Users Manual ...' (ID: 109)\n",
            "    Item 6: '2D Modeling User's Manual \u2026' (ID: 110)\n",
            "    Item 7: 'RAS Mapper User's Manual \u2026' (ID: 111)\n",
            "    Item 8: 'Hydraulic Reference \u2026' (ID: 112)\n",
            "    Item 9: 'Applications Guide \u2026' (ID: 113)\n",
            "    Item 10: '1D Sediment User's Manual \u2026' (ID: 114)\n",
            "    Item 11: '2D Sediment User's Manual \u2026' (ID: 115)\n",
            "    Item 12: '2D Sediment Technical Reference \u2026' (ID: 116)\n",
            "    Item 13: 'Mud and Debris Manuals \u2026' (ID: 117)\n",
            "    Item 14: '' (ID: 118)\n",
            "    Item 15: 'Download Example Projects ...' (ID: 119)\n",
            "    Item 16: '' (ID: 120)\n",
            "    Item 17: 'HEC-RAS Webpage ...' (ID: 121)\n",
            "    Item 18: '' (ID: 122)\n",
            "    Item 19: 'View Terms and Conditions of Use ...' (ID: 123)\n",
            "    Item 20: '&About HEC-RAS ...' (ID: 124)\n",
            "\n",
            "Found RAS Mapper: 'RAS Mapper ...' with ID: 102\n",
            "RAS Mapper opening via menu...\n",
            "\n",
            "Waiting for RAS Mapper to open...\n",
            "Window not found, waiting 2 seconds...\n",
            "RAS Mapper is open: RAS Mapper\n",
            "Allowing time for .rasmap update...\n",
            "Attempting to close RAS Mapper...\n",
            "Closed: RAS Mapper\n",
            "RAS Mapper closed successfully.\n",
            "Waiting for RAS Mapper to fully close...\n",
            "\n",
            "Closing HEC-RAS...\n",
            "HEC-RAS closing...\n",
            "\n",
            "Automation complete. You can now continue with the notebook.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Print instructions to the user\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MANUAL STEP REQUIRED: Update .rasmap to Version 6.x\")\n",
        "print(\"This project was created in HEC-RAS 5.0.7. To generate stored maps in HEC-RAS 6.x, you must:\")\n",
        "print(\"1. HEC-RAS will now be opened with this project.\")\n",
        "print(\"2. In HEC-RAS, open RAS Mapper (from the main toolbar).\") \n",
        "print(\"3. When prompted, allow RAS Mapper to update the .rasmap file to the new version.\")\n",
        "print(\"4. Once the update is complete, close RAS Mapper and exit HEC-RAS.\")\n",
        "print(\"\\nAfter closing HEC-RAS, return here and continue running the notebook.\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "ras_exe = ras.ras_exe_path\n",
        "prj_path = f'\"{str(ras.prj_file)}\"'  # Add quotes around project path\n",
        "\n",
        "command = f\"{ras_exe} {prj_path}\"\n",
        "print(command)\n",
        "\n",
        "try:\n",
        "    # Capture the process object so we can get its PID\n",
        "    if sys.platform == \"win32\":\n",
        "        hecras_process = subprocess.Popen(command)\n",
        "    else:\n",
        "        hecras_process = subprocess.Popen([ras_exe, prj_path])\n",
        "    \n",
        "    # Store the process ID for use in the next cell\n",
        "    hecras_pid = hecras_process.pid\n",
        "    print(f\"Opened HEC-RAS with Process ID: {hecras_pid}\")\n",
        "    print(\"Please wait for the next cell to automate RAS Mapper...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Failed to launch HEC-RAS: {e}\")\n",
        "    hecras_pid = None\n",
        "\n",
        "\n",
        "\n",
        "import win32gui\n",
        "import win32con\n",
        "import win32api\n",
        "import win32com.client\n",
        "import win32process\n",
        "import time\n",
        "import ctypes\n",
        "from ctypes import wintypes\n",
        "\n",
        "# Constants\n",
        "WM_COMMAND = 0x0111\n",
        "MIIM_STRING = 0x00000040\n",
        "MIIM_ID = 0x00000002\n",
        "MIIM_SUBMENU = 0x00000004\n",
        "MIIM_TYPE = 0x00000010\n",
        "MIIM_DATA = 0x00000020\n",
        "MF_BYPOSITION = 0x00000400\n",
        "\n",
        "def get_windows_by_pid(pid):\n",
        "    \"\"\"Find all windows belonging to a specific process ID\"\"\"\n",
        "    def callback(hwnd, hwnds):\n",
        "        if win32gui.IsWindowVisible(hwnd) and win32gui.IsWindowEnabled(hwnd):\n",
        "            # Get the process ID for this window\n",
        "            _, window_pid = win32process.GetWindowThreadProcessId(hwnd)\n",
        "            if window_pid == pid:\n",
        "                window_title = win32gui.GetWindowText(hwnd)\n",
        "                if window_title:  # Only include windows with titles\n",
        "                    hwnds.append((hwnd, window_title))\n",
        "        return True\n",
        "    \n",
        "    hwnds = []\n",
        "    win32gui.EnumWindows(callback, hwnds)\n",
        "    return hwnds\n",
        "\n",
        "def find_main_hecras_window(windows):\n",
        "    \"\"\"Find the main HEC-RAS window from a list of windows\"\"\"\n",
        "    for hwnd, title in windows:\n",
        "        # Main window usually has \"HEC-RAS\" in title and has a menu bar\n",
        "        if \"HEC-RAS\" in title and win32gui.GetMenu(hwnd):\n",
        "            return hwnd, title\n",
        "    return None, None\n",
        "\n",
        "def get_menu_string(menu_handle, pos):\n",
        "    \"\"\"Get menu item string at position\"\"\"\n",
        "    # Create buffer for menu string\n",
        "    buf_size = 256\n",
        "    buf = ctypes.create_unicode_buffer(buf_size)\n",
        "    \n",
        "    # Get menu item info\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuStringW(\n",
        "        menu_handle,\n",
        "        pos,\n",
        "        buf,\n",
        "        buf_size,\n",
        "        MF_BYPOSITION\n",
        "    )\n",
        "    \n",
        "    if result:\n",
        "        return buf.value\n",
        "    return \"\"\n",
        "\n",
        "def enumerate_all_menus(hwnd):\n",
        "    \"\"\"Enumerate all menus and their items\"\"\"\n",
        "    menu_bar = win32gui.GetMenu(hwnd)\n",
        "    if not menu_bar:\n",
        "        print(\"No menu bar found\")\n",
        "        return None\n",
        "    \n",
        "    menu_count = win32gui.GetMenuItemCount(menu_bar)\n",
        "    print(f\"\\nFound {menu_count} top-level menus:\")\n",
        "    \n",
        "    gis_tools_info = None\n",
        "    \n",
        "    for i in range(menu_count):\n",
        "        # Get menu text\n",
        "        menu_text = get_menu_string(menu_bar, i)\n",
        "        print(f\"\\nMenu {i}: '{menu_text}'\")\n",
        "        \n",
        "        # Get submenu handle\n",
        "        submenu = win32gui.GetSubMenu(menu_bar, i)\n",
        "        if submenu:\n",
        "            item_count = win32gui.GetMenuItemCount(submenu)\n",
        "            print(f\"  Contains {item_count} items:\")\n",
        "            \n",
        "            for j in range(item_count):\n",
        "                item_text = get_menu_string(submenu, j)\n",
        "                # Get menu item ID\n",
        "                menu_id = win32gui.GetMenuItemID(submenu, j)\n",
        "                print(f\"    Item {j}: '{item_text}' (ID: {menu_id})\")\n",
        "                \n",
        "                # Store GIS Tools info if found\n",
        "                if \"gis tools\" in menu_text.lower():\n",
        "                    if \"ras mapper\" in item_text.lower():\n",
        "                        gis_tools_info = (submenu, menu_id, item_text)\n",
        "    \n",
        "    return gis_tools_info\n",
        "\n",
        "def open_rasmapper_via_menu(hec_ras_hwnd):\n",
        "    \"\"\"Open RASMapper through HEC-RAS menu system\"\"\"\n",
        "    try:\n",
        "        # Enumerate all menus to find RAS Mapper\n",
        "        gis_tools_info = enumerate_all_menus(hec_ras_hwnd)\n",
        "        \n",
        "        if gis_tools_info:\n",
        "            submenu, menu_id, item_text = gis_tools_info\n",
        "            print(f\"\\nFound RAS Mapper: '{item_text}' with ID: {menu_id}\")\n",
        "            \n",
        "            # Send command to open RASMapper\n",
        "            win32api.PostMessage(hec_ras_hwnd, WM_COMMAND, menu_id, 0)\n",
        "            return True\n",
        "        else:\n",
        "            print(\"\\nCould not find RAS Mapper in any menu\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Menu method failed with error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def open_rasmapper_keyboard(hwnd):\n",
        "    \"\"\"Alternative method using keyboard shortcuts\"\"\"\n",
        "    try:\n",
        "        shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
        "        \n",
        "        # More robust window activation\n",
        "        # First, check if window is minimized and restore it\n",
        "        if win32gui.IsIconic(hwnd):\n",
        "            win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)\n",
        "            time.sleep(0.5)\n",
        "        \n",
        "        # Try multiple methods to bring window to foreground\n",
        "        try:\n",
        "            # Method 1: Direct SetForegroundWindow\n",
        "            win32gui.SetForegroundWindow(hwnd)\n",
        "        except:\n",
        "            try:\n",
        "                # Method 2: Use ShowWindow then SetForegroundWindow\n",
        "                win32gui.ShowWindow(hwnd, win32con.SW_SHOW)\n",
        "                win32gui.SetForegroundWindow(hwnd)\n",
        "            except:\n",
        "                # Method 3: Use BringWindowToTop\n",
        "                win32gui.BringWindowToTop(hwnd)\n",
        "        \n",
        "        time.sleep(0.5)\n",
        "        \n",
        "        # Send Alt+G for GIS Tools menu\n",
        "        shell.SendKeys(\"%g\")\n",
        "        time.sleep(0.2)\n",
        "        \n",
        "        # Send R for RAS Mapper\n",
        "        shell.SendKeys(\"r\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Keyboard method failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def find_rasmapper_window():\n",
        "    \"\"\"Find any RAS Mapper window\"\"\"\n",
        "    def callback(hwnd, windows):\n",
        "        if win32gui.IsWindowVisible(hwnd) and win32gui.IsWindowEnabled(hwnd):\n",
        "            window_title = win32gui.GetWindowText(hwnd)\n",
        "            if \"RAS Mapper\" in window_title:\n",
        "                windows.append((hwnd, window_title))\n",
        "        return True\n",
        "    \n",
        "    windows = []\n",
        "    win32gui.EnumWindows(callback, windows)\n",
        "    return windows\n",
        "\n",
        "def close_rasmapper():\n",
        "    \"\"\"Close RASMapper window\"\"\"\n",
        "    windows = find_rasmapper_window()\n",
        "    \n",
        "    for hwnd, title in windows:\n",
        "        try:\n",
        "            win32gui.PostMessage(hwnd, win32con.WM_CLOSE, 0, 0)\n",
        "            print(f\"Closed: {title}\")\n",
        "            return True\n",
        "        except:\n",
        "            continue\n",
        "    return False\n",
        "\n",
        "def wait_for_window(find_window_func, timeout=60, check_interval=2):\n",
        "    \"\"\"Wait for a window to appear\"\"\"\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout:\n",
        "        windows = find_window_func()\n",
        "        if windows:\n",
        "            return windows\n",
        "        print(f\"Window not found, waiting {check_interval} seconds...\")\n",
        "        time.sleep(check_interval)\n",
        "    return None\n",
        "\n",
        "# Main automation\n",
        "if 'hecras_pid' not in globals() or hecras_pid is None:\n",
        "    print(\"ERROR: HEC-RAS process ID not found. Please run the previous cell first.\")\n",
        "else:\n",
        "    print(f\"Looking for HEC-RAS windows for process ID: {hecras_pid}\")\n",
        "    print(\"Waiting for HEC-RAS to fully load...\")\n",
        "    \n",
        "    # Wait for HEC-RAS window to appear\n",
        "    windows = None\n",
        "    while True:\n",
        "        windows = get_windows_by_pid(hecras_pid)\n",
        "        if windows:\n",
        "            print(f\"Found {len(windows)} window(s) for this HEC-RAS process:\")\n",
        "            for hwnd, title in windows:\n",
        "                print(f\"  - {title}\")\n",
        "            \n",
        "            # Find the main HEC-RAS window\n",
        "            hec_ras_hwnd, title = find_main_hecras_window(windows)\n",
        "            \n",
        "            if hec_ras_hwnd:\n",
        "                print(f\"\\nUsing main window: {title}\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Main HEC-RAS window not ready yet, waiting 2 seconds...\")\n",
        "                time.sleep(2)\n",
        "        else:\n",
        "            print(\"No HEC-RAS windows found yet, waiting 2 seconds...\")\n",
        "            time.sleep(2)\n",
        "            \n",
        "    # Continue with the rest of the automation\n",
        "    print(\"\\nAttempting to open RAS Mapper via menu...\")\n",
        "    if open_rasmapper_via_menu(hec_ras_hwnd):\n",
        "        print(\"RAS Mapper opening via menu...\")\n",
        "    else:\n",
        "        # Fallback to keyboard method\n",
        "        print(\"\\nMenu method failed, trying keyboard shortcuts...\")\n",
        "        if open_rasmapper_keyboard(hec_ras_hwnd):\n",
        "            print(\"RAS Mapper opening via keyboard...\")\n",
        "        else:\n",
        "            # Last resort: try common menu IDs\n",
        "            print(\"\\nTrying direct menu activation with common IDs...\")\n",
        "            try:\n",
        "                # Common IDs for RAS Mapper (may vary by version)\n",
        "                possible_ids = [40305, 40306, 40307, 40308, 40309, 40310, \n",
        "                               32854, 32855, 32856, 32857, 32858]\n",
        "                for menu_id in possible_ids:\n",
        "                    win32api.PostMessage(hec_ras_hwnd, WM_COMMAND, menu_id, 0)\n",
        "                    time.sleep(0.5)\n",
        "                    # Check if RAS Mapper opened\n",
        "                    if find_rasmapper_window():\n",
        "                        print(f\"RAS Mapper opened successfully with ID {menu_id}!\")\n",
        "                        break\n",
        "                else:\n",
        "                    print(\"Failed to open RAS Mapper automatically.\")\n",
        "                    print(\"Please open it manually from HEC-RAS: GIS Tools > RAS Mapper\")\n",
        "            except Exception as e:\n",
        "                print(f\"Direct menu activation failed: {e}\")\n",
        "                print(\"Please open RAS Mapper manually from HEC-RAS: GIS Tools > RAS Mapper\")\n",
        "    \n",
        "    # Wait for RAS Mapper window to appear\n",
        "    print(\"\\nWaiting for RAS Mapper to open...\")\n",
        "    rasmapper_windows = wait_for_window(find_rasmapper_window)\n",
        "    \n",
        "    if rasmapper_windows:\n",
        "        print(f\"RAS Mapper is open: {rasmapper_windows[0][1]}\")\n",
        "        print(\"Allowing time for .rasmap update...\")\n",
        "        time.sleep(2)  # Give extra time for file updates\n",
        "        \n",
        "        # Keep trying to close RAS Mapper until successful\n",
        "        print(\"Attempting to close RAS Mapper...\")\n",
        "        while True:\n",
        "            if close_rasmapper():\n",
        "                print(\"RAS Mapper closed successfully.\")\n",
        "                break\n",
        "            print(\"Waiting 2 seconds before trying to close RAS Mapper again...\")\n",
        "            time.sleep(2)\n",
        "        \n",
        "        # Wait until RAS Mapper is fully closed before closing HEC-RAS\n",
        "        while find_rasmapper_window():\n",
        "            print(\"Waiting for RAS Mapper to fully close...\")\n",
        "            time.sleep(2)\n",
        "        \n",
        "        # Now close HEC-RAS\n",
        "        print(\"\\nClosing HEC-RAS...\")\n",
        "        try:\n",
        "            win32gui.PostMessage(hec_ras_hwnd, win32con.WM_CLOSE, 0, 0)\n",
        "            print(\"HEC-RAS closing...\")\n",
        "        except:\n",
        "            print(\"Could not close HEC-RAS automatically. Please close it manually.\")\n",
        "    else:\n",
        "        print(\"RAS Mapper window not detected after waiting.\")\n",
        "\n",
        "print(\"\\nAutomation complete. You can now continue with the notebook.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:50.320856Z",
          "iopub.status.busy": "2025-11-17T18:53:50.320624Z",
          "iopub.status.idle": "2025-11-17T18:53:55.324168Z",
          "shell.execute_reply": "2025-11-17T18:53:55.323527Z"
        }
      },
      "outputs": [],
      "source": [
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTE: You MUST open the HEC-RAS Main Window for Floodplain Mapping to Work\n",
        "\n",
        "This is being massively improved in HEC-RAS 2025, but for now can't use the -c flag to compute floodplain maps like we do for unsteady computations.  \n",
        "\n",
        "There should also be a way to implement this with Win32COM (similar to above), but for now opening the window is required. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T18:53:55.326329Z",
          "iopub.status.busy": "2025-11-17T18:53:55.326189Z",
          "iopub.status.idle": "2025-11-17T19:10:16.387525Z",
          "shell.execute_reply": "2025-11-17T19:10:16.387056Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Extracted terrain names: ['Terrain50']\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Backing up plan file C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06 to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.storedmap.bak\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Updating plan run flags for floodplain mapping for plan 06...\n",
            "2025-11-17 21:31:10 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06 (flags modified: 4)\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Backing up rasmap file C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap to C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap.storedmap.bak\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Added 'Depth' stored map to results layer for plan 06.\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Added 'WSE' stored map to results layer for plan 06.\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Filtered terrains, keeping only 'Terrain50'.\n",
            "2025-11-17 21:31:10 - ras_commander.RasMap - INFO - Using GUI automation to run floodplain mapping...\n",
            "2025-11-17 21:31:10 - ras_commander.RasGuiAutomation - INFO - Setting current plan to 06 in project file...\n",
            "2025-11-17 21:31:10 - ras_commander.RasPrj - INFO - Set current plan to p06 in C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\n",
            "2025-11-17 21:31:10 - ras_commander.RasGuiAutomation - INFO - Current plan set to 06 in C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\n",
            "2025-11-17 21:31:10 - ras_commander.RasGuiAutomation - INFO - Opening HEC-RAS...\n",
            "2025-11-17 21:31:10 - ras_commander.RasGuiAutomation - INFO - HEC-RAS opened with Process ID: 204712\n",
            "2025-11-17 21:31:10 - ras_commander.RasGuiAutomation - INFO - Waiting for HEC-RAS main window...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available terrains: ['Terrain50']\n",
            "Using terrain: Terrain50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:31:13 - ras_commander.RasGuiAutomation - INFO - Found HEC-RAS main window: HEC-RAS 6.6\n",
            "2025-11-17 21:31:14 - ras_commander.RasGuiAutomation - INFO - Clicking 'Run > Unsteady Flow Analysis' menu...\n",
            "2025-11-17 21:31:14 - ras_commander.RasGuiAutomation - INFO - Clicked menu item ID: 47\n",
            "2025-11-17 21:31:16 - ras_commander.RasGuiAutomation - INFO - Looking for Unsteady Flow Analysis dialog...\n",
            "2025-11-17 21:31:16 - ras_commander.RasGuiAutomation - INFO - Found Unsteady Flow Analysis dialog\n",
            "2025-11-17 21:31:16 - ras_commander.RasGuiAutomation - INFO - Looking for Compute button...\n",
            "2025-11-17 21:31:16 - ras_commander.RasGuiAutomation - WARNING - Could not find Compute button - user must click manually\n",
            "2025-11-17 21:31:16 - ras_commander.RasGuiAutomation - INFO - Trying keyboard shortcut as fallback...\n",
            "2025-11-17 21:31:17 - ras_commander.RasGuiAutomation - INFO - Sent Enter key to dialog\n",
            "2025-11-17 21:31:17 - ras_commander.RasGuiAutomation - INFO - Waiting for user to close HEC-RAS...\n",
            "2025-11-17 21:31:17 - ras_commander.RasGuiAutomation - INFO - Please monitor plan 06 execution and close HEC-RAS when complete\n",
            "2025-11-17 21:34:49 - ras_commander.RasGuiAutomation - INFO - HEC-RAS has been closed\n",
            "2025-11-17 21:34:49 - ras_commander.RasMap - INFO - Floodplain mapping computation successful.\n",
            "2025-11-17 21:34:49 - ras_commander.RasMap - INFO - Restoring original plan file from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p06.storedmap.bak\n",
            "2025-11-17 21:34:49 - ras_commander.RasMap - INFO - Restoring original rasmap file from C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap.storedmap.bak\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully generated stored maps.\n"
          ]
        }
      ],
      "source": [
        "# First, let's get the names of available terrains\n",
        "rasmap_path = ras.project_folder / f\"{ras.project_name}.rasmap\"\n",
        "terrains = RasMap.get_terrain_names(rasmap_path)\n",
        "print(f\"Available terrains: {terrains}\")\n",
        "\n",
        "# Specify the terrain we want to use for mapping\n",
        "target_terrain = None\n",
        "if terrains:\n",
        "    target_terrain = terrains[0]\n",
        "    print(f\"Using terrain: {target_terrain}\")\n",
        "\n",
        "# Generate the stored maps for our plan and terrain\n",
        "success = RasMap.postprocess_stored_maps(\n",
        "    plan_number=plan_number,\n",
        "    specify_terrain=target_terrain,\n",
        "    layers=['Depth', 'WSEL']  # Let's just generate Depth and WSEL for this example\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"Successfully generated stored maps.\")\n",
        "else:\n",
        "    print(\"Failed to generate stored maps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify the Output\n",
        "\n",
        "The `postprocess_stored_maps` function should have created a folder named after the plan's `Short Identifier` (or the plan name if no short ID exists) inside the project directory. Let's find the generated `.tif` file for Depth and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:10:16.389696Z",
          "iopub.status.busy": "2025-11-17T19:10:16.389476Z",
          "iopub.status.idle": "2025-11-17T19:10:16.394796Z",
          "shell.execute_reply": "2025-11-17T19:10:16.394271Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found depth map at: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Grid Precip Infiltration\\Depth (Max).vrt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Find the output directory and the depth map file\n",
        "plan_info = ras.plan_df[ras.plan_df['plan_number'] == plan_number].iloc[0]\n",
        "short_id = plan_info.get('Short Identifier', f'Plan_{plan_number}')\n",
        "output_folder = ras.project_folder / short_id\n",
        "\n",
        "# HEC-RAS creates a VRT file that points to the actual TIF(s)\n",
        "depth_map_path = output_folder / \"Depth (Max).vrt\"\n",
        "\n",
        "if depth_map_path.exists():\n",
        "    print(f\"Found depth map at: {depth_map_path}\")\n",
        "\n",
        "    # Open and plot the raster using rasterio\n",
        "    with rasterio.open(depth_map_path) as src:\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "        show(src, ax=ax, cmap='Blues', title=f'Maximum Depth - Plan {plan_number}')\n",
        "        plt.show()\n",
        "else:\n",
        "    print(f\"Could not find the generated depth map at {depth_map_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to use the `RasMap.postprocess_stored_maps` function to automate a critical post-processing step. By programmatically generating stored maps, you can easily create the necessary outputs for all your plans without manual intervention in the RASMapper interface, significantly speeding up workflows that involve multiple scenarios or models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\16_automating_ras_with_win32com.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n"
          ]
        }
      ],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 20:20:29 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
          ]
        }
      ],
      "source": [
        "# If /example_projects/BaldEagleCrkMulti2D does not exist, extract it\n",
        "project_path = \"./example_projects/BaldEagleCrkMulti2D\"\n",
        "\n",
        "if not os.path.exists(project_path):\n",
        "    project_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
        "\n",
        "# Initialize the RAS project\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "# Define the plan to work with\n",
        "plan_number = \"06\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "MANUAL STEP REQUIRED: Update .rasmap to Version 6.x\n",
            "This project was created in HEC-RAS 5.0.7. To generate stored maps in HEC-RAS 6.x, you must:\n",
            "1. HEC-RAS will now be opened with this project.\n",
            "2. In HEC-RAS, open RAS Mapper (from the main toolbar).\n",
            "3. When prompted, allow RAS Mapper to update the .rasmap file to the new version.\n",
            "4. Once the update is complete, close RAS Mapper and exit HEC-RAS.\n",
            "\n",
            "After closing HEC-RAS, return here and continue running the notebook.\n",
            "============================================================\n",
            "\n",
            "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe \"C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj\"\n",
            "Opened HEC-RAS with Process ID: 100620\n",
            "Please wait for the next cell to automate RAS Mapper...\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Print instructions to the user\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MANUAL STEP REQUIRED: Update .rasmap to Version 6.x\")\n",
        "print(\"This project was created in HEC-RAS 5.0.7. To generate stored maps in HEC-RAS 6.x, you must:\")\n",
        "print(\"1. HEC-RAS will now be opened with this project.\")\n",
        "print(\"2. In HEC-RAS, open RAS Mapper (from the main toolbar).\") \n",
        "print(\"3. When prompted, allow RAS Mapper to update the .rasmap file to the new version.\")\n",
        "print(\"4. Once the update is complete, close RAS Mapper and exit HEC-RAS.\")\n",
        "print(\"\\nAfter closing HEC-RAS, return here and continue running the notebook.\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "ras_exe = ras.ras_exe_path\n",
        "prj_path = f'\"{str(ras.prj_file)}\"'  # Add quotes around project path\n",
        "\n",
        "command = f\"{ras_exe} {prj_path}\"\n",
        "print(command)\n",
        "\n",
        "try:\n",
        "    # Capture the process object so we can get its PID\n",
        "    if sys.platform == \"win32\":\n",
        "        hecras_process = subprocess.Popen(command)\n",
        "    else:\n",
        "        hecras_process = subprocess.Popen([ras_exe, prj_path])\n",
        "    \n",
        "    # Store the process ID for use in the next cell\n",
        "    hecras_pid = hecras_process.pid\n",
        "    print(f\"Opened HEC-RAS with Process ID: {hecras_pid}\")\n",
        "    print(\"Please wait for the next cell to automate RAS Mapper...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Failed to launch HEC-RAS: {e}\")\n",
        "    hecras_pid = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pywinauto in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (0.6.9)\n",
            "Requirement already satisfied: six in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from pywinauto) (1.17.0)\n",
            "Requirement already satisfied: comtypes in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from pywinauto) (1.4.13)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_piptest\\lib\\site-packages (from pywinauto) (311)\n"
          ]
        }
      ],
      "source": [
        "!pip install pywinauto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for HEC-RAS windows for process ID: 100620\n",
            "\n",
            "Found main HEC-RAS window: 'HEC-RAS 6.6' (HWND: 1182634)\n",
            "============================================================\n",
            "\n",
            "--- Enumerating Menus (7 top-level) ---\n",
            "\n",
            "Menu 0: 'File'\n",
            "  Contains 27 items:\n",
            "    Item 0: '&New Project ...' (ID: 2)\n",
            "    Item 1: '&Open Project ...' (ID: 3)\n",
            "    Item 2: '&Save Project' (ID: 4)\n",
            "    Item 3: 'Save Project &As ...' (ID: 5)\n",
            "    Item 4: '&Rename Project Title ...' (ID: 6)\n",
            "    Item 5: '&Delete Project ...' (ID: 7)\n",
            "    Item 6: '' (ID: 8)\n",
            "    Item 7: '&Project Summary ...' (ID: 9)\n",
            "    Item 8: 'Compare Model Data ...' (ID: 10)\n",
            "    Item 9: '' (ID: 11)\n",
            "    Item 10: '&Import HEC-2 Data ...' (ID: 12)\n",
            "    Item 11: 'I&mport HEC-RAS Data ...' (ID: 13)\n",
            "    Item 12: '&Generate Report ...' (ID: 14)\n",
            "    Item 13: '&Export GIS Data ...' (ID: 15)\n",
            "    Item 14: 'Export to HEC-&DSS ...' (ID: 16)\n",
            "    Item 15: 'Restore Backup Data ' -> [Submenu]\n",
            "      - 'Restore Geometry ...' (ID: 18)\n",
            "      - 'Restore Steady Flow ...' (ID: 19)\n",
            "      - 'Restore Unsteady Flow ...' (ID: 20)\n",
            "      - 'Restore Plan ...' (ID: 21)\n",
            "      - 'Restore Hydr Design ...' (ID: 22)\n",
            "    Item 16: '' (ID: 23)\n",
            "    Item 17: 'Zip Plan(s) or Archive Project...' (ID: 24)\n",
            "    Item 18: '' (ID: 25)\n",
            "    Item 19: 'E&xit' (ID: 26)\n",
            "    Item 20: '' (ID: 27)\n",
            "    Item 21: 'C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj' (ID: 28)\n",
            "    Item 22: 'C:\\GH\\ras-commander\\examples\\example_projects\\Chippewa_2D\\Chippewa_2D.prj' (ID: 29)\n",
            "    Item 23: 'C:\\GH\\ras-commander\\research\\RasMapper Interpolation\\Test Data\\BaldEagleCrkMulti2D - Horizontal\\BaldEagleDamBrk.prj' (ID: 30)\n",
            "    Item 24: 'C:\\HCFCD\\Standard_Benefits_Process\\3 - Model Data\\Storm Interpolator - Log Linear\\Output Projects\\South_Belt_RAS66_2025-11-13_044255\\A120-00-00_RAS 4.1\\A100_00_00.prj' (ID: 31)\n",
            "    Item 25: 'C:\\HCFCD\\Standard_Benefits_Process\\3 - Model Data\\Storm Interpolator - Log Linear\\Input Projects\\A520-03-00-E003 - South Belt Stormwater Detention Basin\\A120-00-00_RAS 4.1\\A100_00_00.prj' (ID: 32)\n",
            "    Item 26: 'C:\\GH\\TNTech\\data\\EarlyDevTesting\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.prj' (ID: 33)\n",
            "\n",
            "Menu 1: 'Edit'\n",
            "  Contains 8 items:\n",
            "    Item 0: '&Geometric Data ...' (ID: 37)\n",
            "    Item 1: '' (ID: 38)\n",
            "    Item 2: '&Steady Flow Data ...' (ID: 39)\n",
            "    Item 3: '&Quasi Unsteady Flow (Sediment) ...' (ID: 40)\n",
            "    Item 4: '&Unsteady Flow Data ...' (ID: 41)\n",
            "    Item 5: '' (ID: 42)\n",
            "    Item 6: 'Se&diment Data ...' (ID: 43)\n",
            "    Item 7: '&Water Quality Data ...' (ID: 44)\n",
            "\n",
            "Menu 2: 'Run'\n",
            "  Contains 9 items:\n",
            "    Item 0: '&Steady Flow Analysis ...' (ID: 46)\n",
            "    Item 1: '&Unsteady Flow Analysis ...' (ID: 47)\n",
            "    Item 2: 'Quasi-Unsteady Analysis (Sediment)...' (ID: 48)\n",
            "    Item 3: 'Water Quality Analysis ...' (ID: 49)\n",
            "    Item 4: '&Hydraulic Design Functions ...' (ID: 50)\n",
            "    Item 5: '' (ID: 51)\n",
            "    Item 6: 'Run Multiple Plans ...' (ID: 52)\n",
            "    Item 7: '' (ID: 54)\n",
            "    Item 8: 'Uncertainty Analysis' -> [Submenu]\n",
            "      - 'Setup Parameters ...' (ID: 56)\n",
            "      - 'Run Monte Carlo Analysis ...' (ID: 57)\n",
            "      - 'Summarize Results' (ID: 58)\n",
            "\n",
            "Menu 3: 'View'\n",
            "  Contains 23 items:\n",
            "    Item 0: '&Cross-Sections ...' (ID: 61)\n",
            "    Item 1: '&Water Surface Profiles ...' (ID: 62)\n",
            "    Item 2: '&General Profile Plot ...' (ID: 63)\n",
            "    Item 3: '&Rating Curves ...' (ID: 64)\n",
            "    Item 4: '3D View ...' (ID: 65)\n",
            "    Item 5: '&X-Y-Z Perspective Plots (Classic) ...' (ID: 66)\n",
            "    Item 6: '&Stage and Flow Hydrographs ...' (ID: 67)\n",
            "    Item 7: '&Hydraulic Property Tables ...' (ID: 68)\n",
            "    Item 8: '' (ID: 69)\n",
            "    Item 9: '&Detailed Output Tables ...' (ID: 70)\n",
            "    Item 10: '&Profile Summary Table ...' (ID: 71)\n",
            "    Item 11: '&Summary Err,Warn, Notes ...' (ID: 72)\n",
            "    Item 12: '' (ID: 73)\n",
            "    Item 13: 'DSS Data ...' (ID: 74)\n",
            "    Item 14: '' (ID: 75)\n",
            "    Item 15: 'Unsteady Flow Spatial Plot (computation interval) ...' (ID: 76)\n",
            "    Item 16: 'Unsteady Flow Time Series Plot (computation interval) ...' (ID: 77)\n",
            "    Item 17: '' (ID: 78)\n",
            "    Item 18: 'WQ Spatial Plot ...' (ID: 79)\n",
            "    Item 19: 'WQ Time Series Plot ...' (ID: 80)\n",
            "    Item 20: '' (ID: 81)\n",
            "    Item 21: 'Sediment Output ...' (ID: 82)\n",
            "    Item 22: 'Legacy Sediment Output' -> [Submenu]\n",
            "      - 'Sediment Output (5.0)...' (ID: 84)\n",
            "      - '4.x - Sediment Spatial Plot ...' (ID: 85)\n",
            "      - '4.x - Sediment Time Series Plot ...' (ID: 86)\n",
            "      - '4.x - XS Bed Change Plot...' (ID: 87)\n",
            "\n",
            "Menu 4: 'Options'\n",
            "  Contains 5 items:\n",
            "    Item 0: '&Program Setup' -> [Submenu]\n",
            "      - 'Default File &Viewer ...' (ID: 91)\n",
            "      - 'Default Project Folder ...' (ID: 92)\n",
            "      - '&Open last project on startup' (ID: 93)\n",
            "      - 'Automatically Backup Data' (ID: 94)\n",
            "      - 'Set Time for Automatic Backup ...' (ID: 95)\n",
            "    Item 1: '&Default Parameters' -> [Submenu]\n",
            "      - '&Expansion and Contraction Coef ...' (ID: 97)\n",
            "    Item 2: '&Unit system (US Customary/SI) ...' (ID: 98)\n",
            "    Item 3: '&Convert Project Units ...' (ID: 99)\n",
            "    Item 4: 'Convert &Horizontal Coordinate Systems ...' (ID: 100)\n",
            "\n",
            "Menu 5: 'GIS Tools'\n",
            "  Contains 1 items:\n",
            "    Item 0: 'RAS Mapper ...' (ID: 102)\n",
            "\n",
            "Menu 6: 'Help'\n",
            "  Contains 21 items:\n",
            "    Item 0: 'HEC-RAS Online Documentation ...\tF1' (ID: 104)\n",
            "    Item 1: 'Release Notes ...' (ID: 105)\n",
            "    Item 2: 'Known Issues ...' (ID: 106)\n",
            "    Item 3: 'Community Support on Discourse ...' (ID: 107)\n",
            "    Item 4: '' (ID: 108)\n",
            "    Item 5: 'Users Manual ...' (ID: 109)\n",
            "    Item 6: '2D Modeling User's Manual \u2026' (ID: 110)\n",
            "    Item 7: 'RAS Mapper User's Manual \u2026' (ID: 111)\n",
            "    Item 8: 'Hydraulic Reference \u2026' (ID: 112)\n",
            "    Item 9: 'Applications Guide \u2026' (ID: 113)\n",
            "    Item 10: '1D Sediment User's Manual \u2026' (ID: 114)\n",
            "    Item 11: '2D Sediment User's Manual \u2026' (ID: 115)\n",
            "    Item 12: '2D Sediment Technical Reference \u2026' (ID: 116)\n",
            "    Item 13: 'Mud and Debris Manuals \u2026' (ID: 117)\n",
            "    Item 14: '' (ID: 118)\n",
            "    Item 15: 'Download Example Projects ...' (ID: 119)\n",
            "    Item 16: '' (ID: 120)\n",
            "    Item 17: 'HEC-RAS Webpage ...' (ID: 121)\n",
            "    Item 18: '' (ID: 122)\n",
            "    Item 19: 'View Terms and Conditions of Use ...' (ID: 123)\n",
            "    Item 20: '&About HEC-RAS ...' (ID: 124)\n",
            "\n",
            "--- Enumerating Child Controls (36 found) ---\n",
            "\n",
            "Control 0:\n",
            "  - HWND:        2427996\n",
            "  - Class Name:  'ThunderRT6Timer'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  1\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 438, T: 340, R: 438, B: 340)\n",
            "\n",
            "Control 1:\n",
            "  - HWND:        1050472\n",
            "  - Class Name:  'ThunderRT6TextBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  2\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 1066, T: 104, R: 1091, B: 121)\n",
            "\n",
            "Control 2:\n",
            "  - HWND:        919462\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  3\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 862, T: 100, R: 888, B: 126)\n",
            "\n",
            "Control 3:\n",
            "  - HWND:        1050616\n",
            "  - Class Name:  'ThunderRT6TextBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  4\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 1034, T: 104, R: 1063, B: 121)\n",
            "\n",
            "Control 4:\n",
            "  - HWND:        919270\n",
            "  - Class Name:  'ThunderRT6Timer'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  5\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 410, T: 340, R: 410, B: 340)\n",
            "\n",
            "Control 5:\n",
            "  - HWND:        4589300\n",
            "  - Class Name:  'ThunderRT6TextBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  6\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 1002, T: 104, R: 1031, B: 120)\n",
            "\n",
            "Control 6:\n",
            "  - HWND:        1706916\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  7\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 998, T: 100, R: 1024, B: 126)\n",
            "\n",
            "Control 7:\n",
            "  - HWND:        1445948\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  8\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 972, T: 100, R: 998, B: 126)\n",
            "\n",
            "Control 8:\n",
            "  - HWND:        657176\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  9\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 946, T: 100, R: 972, B: 126)\n",
            "\n",
            "Control 9:\n",
            "  - HWND:        1508260\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  10\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 920, T: 100, R: 946, B: 126)\n",
            "\n",
            "Control 10:\n",
            "  - HWND:        790556\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  11\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 894, T: 100, R: 920, B: 126)\n",
            "\n",
            "Control 11:\n",
            "  - HWND:        2232354\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  12\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 836, T: 100, R: 862, B: 126)\n",
            "\n",
            "Control 12:\n",
            "  - HWND:        790552\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  13\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 810, T: 100, R: 836, B: 126)\n",
            "\n",
            "Control 13:\n",
            "  - HWND:        657182\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  14\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 784, T: 100, R: 810, B: 126)\n",
            "\n",
            "Control 14:\n",
            "  - HWND:        2953504\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  15\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 758, T: 100, R: 784, B: 126)\n",
            "\n",
            "Control 15:\n",
            "  - HWND:        8262022\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  16\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 732, T: 100, R: 758, B: 126)\n",
            "\n",
            "Control 16:\n",
            "  - HWND:        1184556\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  17\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 706, T: 100, R: 732, B: 126)\n",
            "\n",
            "Control 17:\n",
            "  - HWND:        657152\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  18\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 672, T: 100, R: 701, B: 126)\n",
            "\n",
            "Control 18:\n",
            "  - HWND:        984952\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  19\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 641, T: 100, R: 667, B: 126)\n",
            "\n",
            "Control 19:\n",
            "  - HWND:        2297116\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  20\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 615, T: 100, R: 641, B: 126)\n",
            "\n",
            "Control 20:\n",
            "  - HWND:        4722740\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  21\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 589, T: 100, R: 615, B: 126)\n",
            "\n",
            "Control 21:\n",
            "  - HWND:        2690402\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  22\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 563, T: 100, R: 589, B: 126)\n",
            "\n",
            "Control 22:\n",
            "  - HWND:        2887252\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  23\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 537, T: 100, R: 563, B: 126)\n",
            "\n",
            "Control 23:\n",
            "  - HWND:        1445516\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  24\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 505, T: 100, R: 531, B: 126)\n",
            "\n",
            "Control 24:\n",
            "  - HWND:        10948336\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  25\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 479, T: 100, R: 505, B: 126)\n",
            "\n",
            "Control 25:\n",
            "  - HWND:        2822022\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  26\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 448, T: 100, R: 474, B: 126)\n",
            "\n",
            "Control 26:\n",
            "  - HWND:        4198340\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  27\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 422, T: 100, R: 448, B: 126)\n",
            "\n",
            "Control 27:\n",
            "  - HWND:        723576\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  28\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 396, T: 100, R: 422, B: 126)\n",
            "\n",
            "Control 28:\n",
            "  - HWND:        2493512\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  29\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 370, T: 100, R: 396, B: 126)\n",
            "\n",
            "Control 29:\n",
            "  - HWND:        1969932\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  30\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 339, T: 100, R: 365, B: 126)\n",
            "\n",
            "Control 30:\n",
            "  - HWND:        2953618\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  31\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 313, T: 100, R: 339, B: 126)\n",
            "\n",
            "Control 31:\n",
            "  - HWND:        12914684\n",
            "  - Class Name:  'ThunderRT6CheckBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  32\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 1013, T: 236, R: 1030, B: 257)\n",
            "\n",
            "Control 32:\n",
            "  - HWND:        3543782\n",
            "  - Class Name:  'ThunderRT6CommandButton'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  33\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 1130, T: 135, R: 1151, B: 154)\n",
            "\n",
            "Control 33:\n",
            "  - HWND:        1510746\n",
            "  - Class Name:  'ThunderRT6PictureBoxDC'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  34\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 374, T: 340, R: 403, B: 362)\n",
            "\n",
            "Control 34:\n",
            "  - HWND:        3081052\n",
            "  - Class Name:  'ThunderRT6Timer'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  35\n",
            "  - Visible:     False\n",
            "  - Position:    (L: 350, T: 340, R: 350, B: 340)\n",
            "\n",
            "Control 35:\n",
            "  - HWND:        2625852\n",
            "  - Class Name:  'ThunderRT6TextBox'\n",
            "  - Text/Caption: ''\n",
            "  - Control ID:  36\n",
            "  - Visible:     True\n",
            "  - Position:    (L: 398, T: 236, R: 1009, B: 257)\n",
            "\n",
            "============================================================\n",
            "Inspection complete. The lists above show all menus and controls discoverable with pywin32.\n"
          ]
        }
      ],
      "source": [
        "# This cell will inspect the HEC-RAS window and list all interactable elements.\n",
        "# It also provides an example of how to use the pywinauto library for more robust automation,\n",
        "# including interaction with 64-bit processes like RAS Mapper.\n",
        "\n",
        "import win32gui\n",
        "import win32con\n",
        "import win32api\n",
        "import win32process\n",
        "import time\n",
        "import ctypes\n",
        "from ctypes import wintypes\n",
        "\n",
        "# ==============================================================================\n",
        "# Part 1: Inspecting the HEC-RAS Window with pywin32\n",
        "# ==============================================================================\n",
        "# This section uses the original pywin32 approach to list all menus and\n",
        "# child controls (buttons, text boxes, etc.) of the main HEC-RAS window.\n",
        "\n",
        "# Constants from original script\n",
        "MF_BYPOSITION = 0x00000400\n",
        "\n",
        "def get_windows_by_pid(pid):\n",
        "    \"\"\"Find all windows belonging to a specific process ID\"\"\"\n",
        "    def callback(hwnd, hwnds):\n",
        "        if win32gui.IsWindowVisible(hwnd) and win32gui.IsWindowEnabled(hwnd):\n",
        "            _, window_pid = win32process.GetWindowThreadProcessId(hwnd)\n",
        "            if window_pid == pid:\n",
        "                window_title = win32gui.GetWindowText(hwnd)\n",
        "                if window_title:\n",
        "                    hwnds.append((hwnd, window_title))\n",
        "        return True\n",
        "    hwnds = []\n",
        "    win32gui.EnumWindows(callback, hwnds)\n",
        "    return hwnds\n",
        "\n",
        "def find_main_hecras_window(windows):\n",
        "    \"\"\"Find the main HEC-RAS window from a list of windows\"\"\"\n",
        "    for hwnd, title in windows:\n",
        "        if \"HEC-RAS\" in title and win32gui.GetMenu(hwnd):\n",
        "            return hwnd, title\n",
        "    return None, None\n",
        "\n",
        "def get_menu_string(menu_handle, pos):\n",
        "    \"\"\"Get menu item string at position\"\"\"\n",
        "    buf_size = 256\n",
        "    buf = ctypes.create_unicode_buffer(buf_size)\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuStringW(menu_handle, pos, buf, buf_size, MF_BYPOSITION)\n",
        "    if result:\n",
        "        return buf.value\n",
        "    return \"\"\n",
        "\n",
        "def enumerate_all_menus(hwnd):\n",
        "    \"\"\"Enumerate all menus and their items in great detail.\"\"\"\n",
        "    menu_bar = win32gui.GetMenu(hwnd)\n",
        "    if not menu_bar:\n",
        "        print(\"No menu bar found on the window.\")\n",
        "        return\n",
        "\n",
        "    menu_count = win32gui.GetMenuItemCount(menu_bar)\n",
        "    print(f\"\\n--- Enumerating Menus ({menu_count} top-level) ---\")\n",
        "\n",
        "    for i in range(menu_count):\n",
        "        menu_text = get_menu_string(menu_bar, i).replace('&', '')\n",
        "        submenu = win32gui.GetSubMenu(menu_bar, i)\n",
        "        print(f\"\\nMenu {i}: '{menu_text}'\")\n",
        "\n",
        "        if submenu:\n",
        "            item_count = win32gui.GetMenuItemCount(submenu)\n",
        "            print(f\"  Contains {item_count} items:\")\n",
        "            for j in range(item_count):\n",
        "                item_text = get_menu_string(submenu, j)\n",
        "                menu_id = win32gui.GetMenuItemID(submenu, j)\n",
        "                \n",
        "                id_str = f\"(ID: {menu_id})\" if menu_id != -1 and menu_id != 0 else \"\"\n",
        "                \n",
        "                sub_submenu = win32gui.GetSubMenu(submenu, j)\n",
        "                if sub_submenu:\n",
        "                    print(f\"    Item {j}: '{item_text}' -> [Submenu]\")\n",
        "                    sub_item_count = win32gui.GetMenuItemCount(sub_submenu)\n",
        "                    for k in range(sub_item_count):\n",
        "                        sub_item_text = get_menu_string(sub_submenu, k)\n",
        "                        sub_menu_id = win32gui.GetMenuItemID(sub_submenu, k)\n",
        "                        sub_id_str = f\"(ID: {sub_menu_id})\" if sub_menu_id != -1 and sub_menu_id != 0 else \"\"\n",
        "                        print(f\"      - '{sub_item_text}' {sub_id_str}\")\n",
        "                else:\n",
        "                    print(f\"    Item {j}: '{item_text}' {id_str}\")\n",
        "        else:\n",
        "            print(\"  (This top-level item is not a menu)\")\n",
        "\n",
        "def enumerate_child_controls(hwnd):\n",
        "    \"\"\"Enumerates all child controls (widgets) of a window.\"\"\"\n",
        "    child_windows = []\n",
        "    def callback(child_hwnd, _):\n",
        "        child_windows.append(child_hwnd)\n",
        "        return True\n",
        "\n",
        "    win32gui.EnumChildWindows(hwnd, callback, None)\n",
        "    \n",
        "    print(f\"\\n--- Enumerating Child Controls ({len(child_windows)} found) ---\")\n",
        "    if not child_windows:\n",
        "        print(\"No child controls found.\")\n",
        "        return\n",
        "        \n",
        "    for i, child_hwnd in enumerate(child_windows):\n",
        "        class_name = win32gui.GetClassName(child_hwnd)\n",
        "        window_text = win32gui.GetWindowText(child_hwnd)\n",
        "        control_id = win32gui.GetDlgCtrlID(child_hwnd)\n",
        "        \n",
        "        style = win32gui.GetWindowLong(child_hwnd, win32con.GWL_STYLE)\n",
        "        is_visible = (style & win32con.WS_VISIBLE) != 0\n",
        "        \n",
        "        rect = win32gui.GetWindowRect(child_hwnd)\n",
        "        \n",
        "        print(f\"\\nControl {i}:\")\n",
        "        print(f\"  - HWND:        {child_hwnd}\")\n",
        "        print(f\"  - Class Name:  '{class_name}'\")\n",
        "        print(f\"  - Text/Caption: '{window_text}'\")\n",
        "        print(f\"  - Control ID:  {control_id}\")\n",
        "        print(f\"  - Visible:     {is_visible}\")\n",
        "        print(f\"  - Position:    (L: {rect[0]}, T: {rect[1]}, R: {rect[2]}, B: {rect[3]})\")\n",
        "\n",
        "# Main execution for pywin32 inspection\n",
        "if 'hecras_pid' not in globals() or hecras_pid is None:\n",
        "    print(\"ERROR: HEC-RAS process ID not found. Please run the previous cell to launch HEC-RAS first.\")\n",
        "else:\n",
        "    print(f\"Looking for HEC-RAS windows for process ID: {hecras_pid}\")\n",
        "    time.sleep(2)\n",
        "    \n",
        "    windows = get_windows_by_pid(hecras_pid)\n",
        "    if not windows:\n",
        "        print(f\"Could not find any windows for process ID {hecras_pid}\")\n",
        "    else:\n",
        "        hec_ras_hwnd, title = find_main_hecras_window(windows)\n",
        "        if not hec_ras_hwnd:\n",
        "            print(\"Could not identify the main HEC-RAS window from the found windows:\")\n",
        "            for hwnd, title in windows:\n",
        "                print(f\"  - {title} (HWND: {hwnd})\")\n",
        "        else:\n",
        "            print(f\"\\nFound main HEC-RAS window: '{title}' (HWND: {hec_ras_hwnd})\")\n",
        "            print(\"=\"*60)\n",
        "            \n",
        "            enumerate_all_menus(hec_ras_hwnd)\n",
        "            enumerate_child_controls(hec_ras_hwnd)\n",
        "            \n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"Inspection complete. The lists above show all menus and controls discoverable with pywin32.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Performing detailed menu enumeration...\n",
            "\n",
            "=== Complete Menu Tree Analysis ===\n",
            "\n",
            "\n",
            "Top Level Menu 0: &File\n",
            "Details: {'id': 2428699, 'type_flags': [], 'state': [], 'text': '&File', 'has_submenu': True}\n",
            "Contains 27 items:\n",
            "  \u2514\u2500 Item 0: &New Project ...\n",
            "     Details: {'id': 2, 'type_flags': [], 'state': [], 'text': '&New Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Open Project ...\n",
            "     Details: {'id': 3, 'type_flags': [], 'state': [], 'text': '&Open Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Save Project\n",
            "     Details: {'id': 4, 'type_flags': [], 'state': [], 'text': '&Save Project', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Save Project &As ...\n",
            "     Details: {'id': 5, 'type_flags': [], 'state': [], 'text': 'Save Project &As ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Rename Project Title ...\n",
            "     Details: {'id': 6, 'type_flags': [], 'state': [], 'text': '&Rename Project Title ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: &Delete Project ...\n",
            "     Details: {'id': 7, 'type_flags': [], 'state': [], 'text': '&Delete Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: \n",
            "     Details: {'id': 8, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Project Summary ...\n",
            "     Details: {'id': 9, 'type_flags': [], 'state': [], 'text': '&Project Summary ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Compare Model Data ...\n",
            "     Details: {'id': 10, 'type_flags': [], 'state': [], 'text': 'Compare Model Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: \n",
            "     Details: {'id': 11, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  ... and 17 more items\n",
            "\n",
            "Top Level Menu 1: &Edit\n",
            "Details: {'id': 12519335, 'type_flags': [], 'state': [], 'text': '&Edit', 'has_submenu': True}\n",
            "Contains 8 items:\n",
            "  \u2514\u2500 Item 0: &Geometric Data ...\n",
            "     Details: {'id': 37, 'type_flags': [], 'state': [], 'text': '&Geometric Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: \n",
            "     Details: {'id': 38, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Steady Flow Data ...\n",
            "     Details: {'id': 39, 'type_flags': [], 'state': [], 'text': '&Steady Flow Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Quasi Unsteady Flow (Sediment) ...\n",
            "     Details: {'id': 40, 'type_flags': [], 'state': [], 'text': '&Quasi Unsteady Flow (Sediment) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Unsteady Flow Data ...\n",
            "     Details: {'id': 41, 'type_flags': [], 'state': [], 'text': '&Unsteady Flow Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: \n",
            "     Details: {'id': 42, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: Se&diment Data ...\n",
            "     Details: {'id': 43, 'type_flags': [], 'state': [], 'text': 'Se&diment Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Water Quality Data ...\n",
            "     Details: {'id': 44, 'type_flags': [], 'state': [], 'text': '&Water Quality Data ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 2: &Run\n",
            "Details: {'id': 1380203, 'type_flags': [], 'state': [], 'text': '&Run', 'has_submenu': True}\n",
            "Contains 9 items:\n",
            "  \u2514\u2500 Item 0: &Steady Flow Analysis ...\n",
            "     Details: {'id': 46, 'type_flags': [], 'state': [], 'text': '&Steady Flow Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Unsteady Flow Analysis ...\n",
            "     Details: {'id': 47, 'type_flags': [], 'state': [], 'text': '&Unsteady Flow Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: Quasi-Unsteady Analysis (Sediment)...\n",
            "     Details: {'id': 48, 'type_flags': [], 'state': [], 'text': 'Quasi-Unsteady Analysis (Sediment)...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Water Quality Analysis ...\n",
            "     Details: {'id': 49, 'type_flags': [], 'state': [], 'text': 'Water Quality Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Hydraulic Design Functions ...\n",
            "     Details: {'id': 50, 'type_flags': [], 'state': [], 'text': '&Hydraulic Design Functions ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: \n",
            "     Details: {'id': 51, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: Run Multiple Plans ...\n",
            "     Details: {'id': 52, 'type_flags': [], 'state': [], 'text': 'Run Multiple Plans ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: \n",
            "     Details: {'id': 54, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Uncertainty Analysis\n",
            "     Details: {'id': 4327313, 'type_flags': [], 'state': ['DISABLED', 'GRAYED'], 'text': 'Uncertainty Analysis', 'has_submenu': True}\n",
            "     Has submenu with 3 items:\n",
            "       \u2514\u2500 Sub-item 0: Setup Parameters ...\n",
            "          Details: {'id': 56, 'type_flags': [], 'state': [], 'text': 'Setup Parameters ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 1: Run Monte Carlo Analysis ...\n",
            "          Details: {'id': 57, 'type_flags': [], 'state': [], 'text': 'Run Monte Carlo Analysis ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 2: Summarize Results\n",
            "          Details: {'id': 58, 'type_flags': [], 'state': [], 'text': 'Summarize Results', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 3: &View\n",
            "Details: {'id': 136188355, 'type_flags': [], 'state': [], 'text': '&View', 'has_submenu': True}\n",
            "Contains 23 items:\n",
            "  \u2514\u2500 Item 0: &Cross-Sections ...\n",
            "     Details: {'id': 61, 'type_flags': [], 'state': [], 'text': '&Cross-Sections ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Water Surface Profiles ...\n",
            "     Details: {'id': 62, 'type_flags': [], 'state': [], 'text': '&Water Surface Profiles ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &General Profile Plot ...\n",
            "     Details: {'id': 63, 'type_flags': [], 'state': [], 'text': '&General Profile Plot ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Rating Curves ...\n",
            "     Details: {'id': 64, 'type_flags': [], 'state': [], 'text': '&Rating Curves ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: 3D View ...\n",
            "     Details: {'id': 65, 'type_flags': [], 'state': [], 'text': '3D View ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: &X-Y-Z Perspective Plots (Classic) ...\n",
            "     Details: {'id': 66, 'type_flags': [], 'state': [], 'text': '&X-Y-Z Perspective Plots (Classic) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: &Stage and Flow Hydrographs ...\n",
            "     Details: {'id': 67, 'type_flags': [], 'state': [], 'text': '&Stage and Flow Hydrographs ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Hydraulic Property Tables ...\n",
            "     Details: {'id': 68, 'type_flags': [], 'state': [], 'text': '&Hydraulic Property Tables ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: \n",
            "     Details: {'id': 69, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: &Detailed Output Tables ...\n",
            "     Details: {'id': 70, 'type_flags': [], 'state': [], 'text': '&Detailed Output Tables ...', 'has_submenu': False}\n",
            "  ... and 13 more items\n",
            "\n",
            "Top Level Menu 4: &Options\n",
            "Details: {'id': 1050507, 'type_flags': [], 'state': [], 'text': '&Options', 'has_submenu': True}\n",
            "Contains 5 items:\n",
            "  \u2514\u2500 Item 0: &Program Setup\n",
            "     Details: {'id': 348720343, 'type_flags': [], 'state': [], 'text': '&Program Setup', 'has_submenu': True}\n",
            "     Has submenu with 5 items:\n",
            "       \u2514\u2500 Sub-item 0: Default File &Viewer ...\n",
            "          Details: {'id': 91, 'type_flags': [], 'state': [], 'text': 'Default File &Viewer ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 1: Default Project Folder ...\n",
            "          Details: {'id': 92, 'type_flags': [], 'state': [], 'text': 'Default Project Folder ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 2: &Open last project on startup\n",
            "          Details: {'id': 93, 'type_flags': [], 'state': [], 'text': '&Open last project on startup', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 3: Automatically Backup Data\n",
            "          Details: {'id': 94, 'type_flags': [], 'state': ['CHECKED'], 'text': 'Automatically Backup Data', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 4: Set Time for Automatic Backup ...\n",
            "          Details: {'id': 95, 'type_flags': [], 'state': [], 'text': 'Set Time for Automatic Backup ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Default Parameters\n",
            "     Details: {'id': 139527055, 'type_flags': [], 'state': [], 'text': '&Default Parameters', 'has_submenu': True}\n",
            "     Has submenu with 1 items:\n",
            "       \u2514\u2500 Sub-item 0: &Expansion and Contraction Coef ...\n",
            "          Details: {'id': 97, 'type_flags': [], 'state': [], 'text': '&Expansion and Contraction Coef ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Unit system (US Customary/SI) ...\n",
            "     Details: {'id': 98, 'type_flags': [], 'state': [], 'text': '&Unit system (US Customary/SI) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Convert Project Units ...\n",
            "     Details: {'id': 99, 'type_flags': [], 'state': [], 'text': '&Convert Project Units ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: Convert &Horizontal Coordinate Systems ...\n",
            "     Details: {'id': 100, 'type_flags': [], 'state': [], 'text': 'Convert &Horizontal Coordinate Systems ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 5: &GIS Tools\n",
            "Details: {'id': 3737661, 'type_flags': [], 'state': [], 'text': '&GIS Tools', 'has_submenu': True}\n",
            "Contains 1 items:\n",
            "  \u2514\u2500 Item 0: RAS Mapper ...\n",
            "     Details: {'id': 102, 'type_flags': [], 'state': [], 'text': 'RAS Mapper ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 6: &Help\n",
            "Details: {'id': 2297713, 'type_flags': [], 'state': [], 'text': '&Help', 'has_submenu': True}\n",
            "Contains 21 items:\n",
            "  \u2514\u2500 Item 0: HEC-RAS Online Documentation ...\tF1\n",
            "     Details: {'id': 104, 'type_flags': [], 'state': [], 'text': 'HEC-RAS Online Documentation ...\\tF1', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: Release Notes ...\n",
            "     Details: {'id': 105, 'type_flags': [], 'state': [], 'text': 'Release Notes ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: Known Issues ...\n",
            "     Details: {'id': 106, 'type_flags': [], 'state': [], 'text': 'Known Issues ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Community Support on Discourse ...\n",
            "     Details: {'id': 107, 'type_flags': [], 'state': [], 'text': 'Community Support on Discourse ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: \n",
            "     Details: {'id': 108, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: Users Manual ...\n",
            "     Details: {'id': 109, 'type_flags': [], 'state': [], 'text': 'Users Manual ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: 2D Modeling User's Manual \u2026\n",
            "     Details: {'id': 110, 'type_flags': [], 'state': [], 'text': \"2D Modeling User's Manual \u2026\", 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: RAS Mapper User's Manual \u2026\n",
            "     Details: {'id': 111, 'type_flags': [], 'state': [], 'text': \"RAS Mapper User's Manual \u2026\", 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Hydraulic Reference \u2026\n",
            "     Details: {'id': 112, 'type_flags': [], 'state': [], 'text': 'Hydraulic Reference \u2026', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: Applications Guide \u2026\n",
            "     Details: {'id': 113, 'type_flags': [], 'state': [], 'text': 'Applications Guide \u2026', 'has_submenu': False}\n",
            "  ... and 11 more items\n",
            "\n",
            "================================================================================\n",
            "Performing detailed window hierarchy enumeration...\n",
            "Main window: HEC-RAS 6.6\n",
            "Window Handle: 1182634\n",
            "Class: ThunderRT6FormDC\n",
            "Text: HEC-RAS 6.6\n",
            "Position: (307, 50, 1157, 266)\n",
            "Style: 0x16CA0000\n",
            "Extended Style: 0x00040100\n",
            "Children: 36 found\n",
            "---\n",
            "  Window Handle: 2427996\n",
            "  Class: ThunderRT6Timer\n",
            "  Text: \n",
            "  Position: (438, 340, 438, 340)\n",
            "  Style: 0x44010000\n",
            "  Extended Style: 0x00000004\n",
            "---\n",
            "  Window Handle: 1050472\n",
            "  Class: ThunderRT6TextBox\n",
            "  Text: \n",
            "  Position: (1066, 104, 1091, 121)\n",
            "  Style: 0x440100C0\n",
            "  Extended Style: 0x00000204\n",
            "---\n",
            "  Window Handle: 919462\n",
            "  Class: ThunderRT6CheckBox\n",
            "  Text: \n",
            "  Position: (862, 100, 888, 126)\n",
            "  Style: 0x5401000B\n",
            "  Extended Style: 0x00000004\n",
            "---\n",
            "  Window Handle: 1050616\n",
            "  Class: ThunderRT6TextBox\n",
            "  Text: \n",
            "  Position: (1034, 104, 1063, 121)\n",
            "  Style: 0x440100C0\n",
            "  Extended Style: 0x00000204\n",
            "---\n",
            "  Window Handle: 919270\n",
            "  Class: ThunderRT6Timer\n",
            "  Text: \n",
            "  Position: (410, 340, 410, 340)\n",
            "  Style: 0x44010000\n",
            "  Extended Style: 0x00000004\n",
            "... and 31 more children\n",
            "\n",
            "================================================================================\n",
            "Detailed enumeration complete.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Part 1b: Deeper Menu and Window Object Enumeration using ctypes\n",
        "# ==============================================================================\n",
        "\n",
        "import win32gui\n",
        "import win32con\n",
        "import win32api\n",
        "import win32process\n",
        "import ctypes\n",
        "from ctypes import wintypes\n",
        "\n",
        "# Define MENUITEMINFO structure using ctypes\n",
        "class MENUITEMINFO(ctypes.Structure):\n",
        "    _fields_ = [\n",
        "        (\"cbSize\", wintypes.UINT),\n",
        "        (\"fMask\", wintypes.UINT),\n",
        "        (\"fType\", wintypes.UINT),\n",
        "        (\"fState\", wintypes.UINT),\n",
        "        (\"wID\", wintypes.UINT),\n",
        "        (\"hSubMenu\", wintypes.HMENU),\n",
        "        (\"hbmpChecked\", wintypes.HBITMAP),\n",
        "        (\"hbmpUnchecked\", wintypes.HBITMAP),\n",
        "        (\"dwItemData\", ctypes.POINTER(ctypes.c_ulong)),\n",
        "        (\"dwTypeData\", wintypes.LPWSTR),\n",
        "        (\"cch\", wintypes.UINT),\n",
        "        (\"hbmpItem\", wintypes.HBITMAP)\n",
        "    ]\n",
        "\n",
        "def get_menu_string(menu_handle, pos):\n",
        "    \"\"\"Get menu item string at position\"\"\"\n",
        "    buf_size = 256\n",
        "    buf = ctypes.create_unicode_buffer(buf_size)\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuStringW(menu_handle, pos, buf, buf_size, MF_BYPOSITION)\n",
        "    if result:\n",
        "        return buf.value\n",
        "    return \"\"\n",
        "\n",
        "def enumerate_menu_item_details(menu_handle, item_index):\n",
        "    \"\"\"Get detailed information about a menu item using ctypes\"\"\"\n",
        "    # Create and initialize MENUITEMINFO structure\n",
        "    mii = MENUITEMINFO()\n",
        "    mii.cbSize = ctypes.sizeof(MENUITEMINFO)\n",
        "    mii.fMask = win32con.MIIM_STATE | win32con.MIIM_ID | win32con.MIIM_TYPE | win32con.MIIM_SUBMENU\n",
        "    \n",
        "    # Call GetMenuItemInfo using ctypes\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuItemInfoW(\n",
        "        menu_handle, \n",
        "        item_index, \n",
        "        True,  # fByPosition\n",
        "        ctypes.byref(mii)\n",
        "    )\n",
        "    \n",
        "    if result:\n",
        "        # Parse state flags\n",
        "        state_flags = []\n",
        "        if mii.fState & win32con.MFS_CHECKED:\n",
        "            state_flags.append(\"CHECKED\")\n",
        "        if mii.fState & win32con.MFS_DISABLED:\n",
        "            state_flags.append(\"DISABLED\")\n",
        "        if mii.fState & win32con.MFS_GRAYED:\n",
        "            state_flags.append(\"GRAYED\")\n",
        "        if mii.fState & win32con.MFS_HILITE:\n",
        "            state_flags.append(\"HIGHLIGHTED\")\n",
        "        if mii.fState & win32con.MFS_DEFAULT:\n",
        "            state_flags.append(\"DEFAULT\")\n",
        "            \n",
        "        # Parse type flags\n",
        "        type_flags = []\n",
        "        if mii.fType & win32con.MFT_STRING:\n",
        "            type_flags.append(\"STRING\")\n",
        "        if mii.fType & win32con.MFT_SEPARATOR:\n",
        "            type_flags.append(\"SEPARATOR\")\n",
        "        if mii.fType & win32con.MFT_BITMAP:\n",
        "            type_flags.append(\"BITMAP\")\n",
        "        if mii.fType & win32con.MFT_OWNERDRAW:\n",
        "            type_flags.append(\"OWNERDRAW\")\n",
        "        \n",
        "        return {\n",
        "            \"id\": mii.wID,\n",
        "            \"type_flags\": type_flags,\n",
        "            \"state\": state_flags,\n",
        "            \"text\": get_menu_string(menu_handle, item_index),\n",
        "            \"has_submenu\": bool(mii.hSubMenu)\n",
        "        }\n",
        "    else:\n",
        "        # Fallback to simpler approach if GetMenuItemInfo fails\n",
        "        try:\n",
        "            menu_id = win32gui.GetMenuItemID(menu_handle, item_index)\n",
        "            menu_state = win32gui.GetMenuState(menu_handle, item_index, win32con.MF_BYPOSITION)\n",
        "            \n",
        "            state_flags = []\n",
        "            if menu_state & win32con.MF_CHECKED:\n",
        "                state_flags.append(\"CHECKED\")\n",
        "            if menu_state & win32con.MF_DISABLED:\n",
        "                state_flags.append(\"DISABLED\")\n",
        "            if menu_state & win32con.MF_GRAYED:\n",
        "                state_flags.append(\"GRAYED\")\n",
        "            if menu_state & win32con.MF_SEPARATOR:\n",
        "                state_flags.append(\"SEPARATOR\")\n",
        "            \n",
        "            return {\n",
        "                \"id\": menu_id if menu_id != -1 else None,\n",
        "                \"state\": state_flags,\n",
        "                \"text\": get_menu_string(menu_handle, item_index),\n",
        "                \"has_submenu\": win32gui.GetSubMenu(menu_handle, item_index) is not None,\n",
        "                \"fallback\": True\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"text\": get_menu_string(menu_handle, item_index)\n",
        "            }\n",
        "\n",
        "def enumerate_window_details(hwnd, indent=0):\n",
        "    \"\"\"Recursively enumerate window details including styles and extended styles\"\"\"\n",
        "    if not hwnd:\n",
        "        return\n",
        "        \n",
        "    # Get basic window info\n",
        "    class_name = win32gui.GetClassName(hwnd)\n",
        "    window_text = win32gui.GetWindowText(hwnd)\n",
        "    \n",
        "    # Get window styles\n",
        "    style = win32gui.GetWindowLong(hwnd, win32con.GWL_STYLE)\n",
        "    ex_style = win32gui.GetWindowLong(hwnd, win32con.GWL_EXSTYLE)\n",
        "    \n",
        "    # Get window metrics\n",
        "    rect = win32gui.GetWindowRect(hwnd)\n",
        "    \n",
        "    # Print window details\n",
        "    indent_str = \"  \" * indent\n",
        "    print(f\"{indent_str}Window Handle: {hwnd}\")\n",
        "    print(f\"{indent_str}Class: {class_name}\")\n",
        "    print(f\"{indent_str}Text: {window_text}\")\n",
        "    print(f\"{indent_str}Position: {rect}\")\n",
        "    print(f\"{indent_str}Style: 0x{style:08X}\")\n",
        "    print(f\"{indent_str}Extended Style: 0x{ex_style:08X}\")\n",
        "    \n",
        "    # Enumerate child windows recursively (limit depth to avoid too much output)\n",
        "    if indent < 3:  # Limit recursion depth\n",
        "        try:\n",
        "            child_windows = []\n",
        "            win32gui.EnumChildWindows(\n",
        "                hwnd,\n",
        "                lambda child_hwnd, windows: windows.append(child_hwnd) or True,\n",
        "                child_windows\n",
        "            )\n",
        "            \n",
        "            if child_windows:\n",
        "                print(f\"{indent_str}Children: {len(child_windows)} found\")\n",
        "                for child_hwnd in child_windows[:5]:  # Show first 5 children\n",
        "                    print(f\"{indent_str}---\")\n",
        "                    enumerate_window_details(child_hwnd, indent + 1)\n",
        "                if len(child_windows) > 5:\n",
        "                    print(f\"{indent_str}... and {len(child_windows) - 5} more children\")\n",
        "        except Exception as e:\n",
        "            print(f\"{indent_str}Error enumerating children: {e}\")\n",
        "\n",
        "def enumerate_full_menu_tree(hwnd):\n",
        "    \"\"\"Enumerate complete menu tree with all available details\"\"\"\n",
        "    menu_bar = win32gui.GetMenu(hwnd)\n",
        "    if not menu_bar:\n",
        "        print(\"No menu bar found\")\n",
        "        return\n",
        "        \n",
        "    print(\"\\n=== Complete Menu Tree Analysis ===\\n\")\n",
        "    \n",
        "    menu_count = win32gui.GetMenuItemCount(menu_bar)\n",
        "    for i in range(menu_count):\n",
        "        menu_text = get_menu_string(menu_bar, i)\n",
        "        menu_details = enumerate_menu_item_details(menu_bar, i)\n",
        "        print(f\"\\nTop Level Menu {i}: {menu_text}\")\n",
        "        print(f\"Details: {menu_details}\")\n",
        "        \n",
        "        submenu = win32gui.GetSubMenu(menu_bar, i)\n",
        "        if submenu:\n",
        "            submenu_count = win32gui.GetMenuItemCount(submenu)\n",
        "            print(f\"Contains {submenu_count} items:\")\n",
        "            \n",
        "            for j in range(min(submenu_count, 10)):  # Show first 10 items\n",
        "                submenu_text = get_menu_string(submenu, j)\n",
        "                submenu_details = enumerate_menu_item_details(submenu, j)\n",
        "                print(f\"  \u2514\u2500 Item {j}: {submenu_text}\")\n",
        "                print(f\"     Details: {submenu_details}\")\n",
        "                \n",
        "                # Check for sub-submenus\n",
        "                sub_submenu = win32gui.GetSubMenu(submenu, j)\n",
        "                if sub_submenu:\n",
        "                    sub_count = win32gui.GetMenuItemCount(sub_submenu)\n",
        "                    print(f\"     Has submenu with {sub_count} items:\")\n",
        "                    for k in range(min(sub_count, 5)):  # Show first 5 sub-items\n",
        "                        sub_text = get_menu_string(sub_submenu, k)\n",
        "                        sub_details = enumerate_menu_item_details(sub_submenu, k)\n",
        "                        print(f\"       \u2514\u2500 Sub-item {k}: {sub_text}\")\n",
        "                        print(f\"          Details: {sub_details}\")\n",
        "            \n",
        "            if submenu_count > 10:\n",
        "                print(f\"  ... and {submenu_count - 10} more items\")\n",
        "\n",
        "# Main execution\n",
        "if 'hecras_pid' in globals() and hecras_pid is not None:\n",
        "    # Wait for windows to be ready\n",
        "    import time\n",
        "    time.sleep(1)\n",
        "    \n",
        "    # Find HEC-RAS windows\n",
        "    windows = get_windows_by_pid(hecras_pid)\n",
        "    hec_ras_hwnd, title = find_main_hecras_window(windows)\n",
        "    \n",
        "    if hec_ras_hwnd:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Performing detailed menu enumeration...\")\n",
        "        enumerate_full_menu_tree(hec_ras_hwnd)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Performing detailed window hierarchy enumeration...\")\n",
        "        print(f\"Main window: {title}\")\n",
        "        enumerate_window_details(hec_ras_hwnd)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Detailed enumeration complete.\")\n",
        "    else:\n",
        "        print(\"Could not find main HEC-RAS window\")\n",
        "else:\n",
        "    print(\"HEC-RAS process ID not found. Please run the cell that launches HEC-RAS first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enumerate_menu_item_details(menu_handle, item_index):\n",
        "    \"\"\"Get detailed information about a menu item\"\"\"\n",
        "    # Since win32gui doesn't have MENUITEMINFO, we'll use a simpler approach\n",
        "    try:\n",
        "        # Get menu item ID\n",
        "        menu_id = win32gui.GetMenuItemID(menu_handle, item_index)\n",
        "        \n",
        "        # Get menu state\n",
        "        menu_state = win32gui.GetMenuState(menu_handle, item_index, win32con.MF_BYPOSITION)\n",
        "        \n",
        "        # Parse state flags\n",
        "        state_flags = []\n",
        "        if menu_state & win32con.MF_CHECKED:\n",
        "            state_flags.append(\"CHECKED\")\n",
        "        if menu_state & win32con.MF_DISABLED:\n",
        "            state_flags.append(\"DISABLED\")\n",
        "        if menu_state & win32con.MF_GRAYED:\n",
        "            state_flags.append(\"GRAYED\")\n",
        "        if menu_state & win32con.MF_SEPARATOR:\n",
        "            state_flags.append(\"SEPARATOR\")\n",
        "        \n",
        "        # Get menu text\n",
        "        text = get_menu_string(menu_handle, item_index)\n",
        "        \n",
        "        return {\n",
        "            \"id\": menu_id if menu_id != -1 else None,\n",
        "            \"state\": state_flags,\n",
        "            \"text\": text,\n",
        "            \"has_submenu\": win32gui.GetSubMenu(menu_handle, item_index) is not None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"text\": get_menu_string(menu_handle, item_index)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- pywinauto Example ---\n",
            "This section shows how to inspect an application like RAS Mapper using pywinauto.\n",
            "You may need to install it first: !pip install pywinauto\n",
            "pywinauto is installed.\n",
            "\n",
            "Attempting to find a RAS Mapper window to demonstrate pywinauto...\n",
            "\n",
            "Could not find a running RAS Mapper window.\n",
            "To run this for real, open HEC-RAS and then RAS Mapper, then execute this cell again.\n",
            "Example code to list controls once connected:\n",
            "  from pywinauto import Application\n",
            "  app = Application(backend='uia').connect(title_re='.*RAS Mapper.*') # uia backend might also work\n",
            "  ras_mapper_window = app.window(title_re='.*RAS Mapper.*')\n",
            "  ras_mapper_window.print_control_identifiers()\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Part 2: Interacting with 64-bit Processes using pywinauto\n",
        "# ==============================================================================\n",
        "print(\"\\n--- pywinauto Example ---\")\n",
        "print(\"This section shows how to inspect an application like RAS Mapper using pywinauto.\")\n",
        "print(\"You may need to install it first: !pip install pywinauto\")\n",
        "try:\n",
        "    import pywinauto\n",
        "    from pywinauto import timings, findwindows\n",
        "    print(\"pywinauto is installed.\")\n",
        "    \n",
        "    print(\"\\nAttempting to find a RAS Mapper window to demonstrate pywinauto...\")\n",
        "    \n",
        "    try:\n",
        "        # Connect to RAS Mapper window (title might vary slightly by version)\n",
        "        # Using win32 backend as RAS Mapper is a mix of technologies\n",
        "        app = pywinauto.Application(backend=\"win32\").connect(title_re=\".*RAS Mapper.*\", timeout=5)\n",
        "        \n",
        "        ras_mapper_window = app.window(title_re=\".*RAS Mapper.*\")\n",
        "        \n",
        "        print(\"\\nSuccessfully connected to RAS Mapper!\")\n",
        "        print(\"Now, listing all its controls using pywinauto's print_control_identifiers():\")\n",
        "        \n",
        "        # This will print a tree of all interactable controls.\n",
        "        # It's a very useful function for exploration.\n",
        "        ras_mapper_window.print_control_identifiers()\n",
        "        \n",
        "    except (findwindows.ElementNotFoundError, timings.TimeoutError):\n",
        "        print(\"\\nCould not find a running RAS Mapper window.\")\n",
        "        print(\"To run this for real, open HEC-RAS and then RAS Mapper, then execute this cell again.\")\n",
        "        print(\"Example code to list controls once connected:\")\n",
        "        print(\"  from pywinauto import Application\")\n",
        "        print(\"  app = Application(backend='uia').connect(title_re='.*RAS Mapper.*') # uia backend might also work\")\n",
        "        print(\"  ras_mapper_window = app.window(title_re='.*RAS Mapper.*')\")\n",
        "        print(\"  ras_mapper_window.print_control_identifiers()\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\npywinauto is not installed. Please install it to run this example:\")\n",
        "    print(\"In a new cell, run: !pip install pywinauto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Performing detailed menu enumeration...\n",
            "\n",
            "=== Complete Menu Tree Analysis ===\n",
            "\n",
            "\n",
            "Top Level Menu 0: &File\n",
            "Details: {'id': 2428699, 'type_flags': [], 'state': [], 'text': '&File', 'has_submenu': True}\n",
            "Contains 27 items:\n",
            "  \u2514\u2500 Item 0: &New Project ...\n",
            "     Details: {'id': 2, 'type_flags': [], 'state': [], 'text': '&New Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Open Project ...\n",
            "     Details: {'id': 3, 'type_flags': [], 'state': [], 'text': '&Open Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Save Project\n",
            "     Details: {'id': 4, 'type_flags': [], 'state': [], 'text': '&Save Project', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Save Project &As ...\n",
            "     Details: {'id': 5, 'type_flags': [], 'state': [], 'text': 'Save Project &As ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Rename Project Title ...\n",
            "     Details: {'id': 6, 'type_flags': [], 'state': [], 'text': '&Rename Project Title ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: &Delete Project ...\n",
            "     Details: {'id': 7, 'type_flags': [], 'state': [], 'text': '&Delete Project ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: \n",
            "     Details: {'id': 8, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Project Summary ...\n",
            "     Details: {'id': 9, 'type_flags': [], 'state': [], 'text': '&Project Summary ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Compare Model Data ...\n",
            "     Details: {'id': 10, 'type_flags': [], 'state': [], 'text': 'Compare Model Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: \n",
            "     Details: {'id': 11, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  ... and 17 more items\n",
            "\n",
            "Top Level Menu 1: &Edit\n",
            "Details: {'id': 12519335, 'type_flags': [], 'state': [], 'text': '&Edit', 'has_submenu': True}\n",
            "Contains 8 items:\n",
            "  \u2514\u2500 Item 0: &Geometric Data ...\n",
            "     Details: {'id': 37, 'type_flags': [], 'state': [], 'text': '&Geometric Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: \n",
            "     Details: {'id': 38, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Steady Flow Data ...\n",
            "     Details: {'id': 39, 'type_flags': [], 'state': [], 'text': '&Steady Flow Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Quasi Unsteady Flow (Sediment) ...\n",
            "     Details: {'id': 40, 'type_flags': [], 'state': [], 'text': '&Quasi Unsteady Flow (Sediment) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Unsteady Flow Data ...\n",
            "     Details: {'id': 41, 'type_flags': [], 'state': [], 'text': '&Unsteady Flow Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: \n",
            "     Details: {'id': 42, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: Se&diment Data ...\n",
            "     Details: {'id': 43, 'type_flags': [], 'state': [], 'text': 'Se&diment Data ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Water Quality Data ...\n",
            "     Details: {'id': 44, 'type_flags': [], 'state': [], 'text': '&Water Quality Data ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 2: &Run\n",
            "Details: {'id': 1380203, 'type_flags': [], 'state': [], 'text': '&Run', 'has_submenu': True}\n",
            "Contains 9 items:\n",
            "  \u2514\u2500 Item 0: &Steady Flow Analysis ...\n",
            "     Details: {'id': 46, 'type_flags': [], 'state': [], 'text': '&Steady Flow Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Unsteady Flow Analysis ...\n",
            "     Details: {'id': 47, 'type_flags': [], 'state': [], 'text': '&Unsteady Flow Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: Quasi-Unsteady Analysis (Sediment)...\n",
            "     Details: {'id': 48, 'type_flags': [], 'state': [], 'text': 'Quasi-Unsteady Analysis (Sediment)...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Water Quality Analysis ...\n",
            "     Details: {'id': 49, 'type_flags': [], 'state': [], 'text': 'Water Quality Analysis ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: &Hydraulic Design Functions ...\n",
            "     Details: {'id': 50, 'type_flags': [], 'state': [], 'text': '&Hydraulic Design Functions ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: \n",
            "     Details: {'id': 51, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: Run Multiple Plans ...\n",
            "     Details: {'id': 52, 'type_flags': [], 'state': [], 'text': 'Run Multiple Plans ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: \n",
            "     Details: {'id': 54, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Uncertainty Analysis\n",
            "     Details: {'id': 4327313, 'type_flags': [], 'state': ['DISABLED', 'GRAYED'], 'text': 'Uncertainty Analysis', 'has_submenu': True}\n",
            "     Has submenu with 3 items:\n",
            "       \u2514\u2500 Sub-item 0: Setup Parameters ...\n",
            "          Details: {'id': 56, 'type_flags': [], 'state': [], 'text': 'Setup Parameters ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 1: Run Monte Carlo Analysis ...\n",
            "          Details: {'id': 57, 'type_flags': [], 'state': [], 'text': 'Run Monte Carlo Analysis ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 2: Summarize Results\n",
            "          Details: {'id': 58, 'type_flags': [], 'state': [], 'text': 'Summarize Results', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 3: &View\n",
            "Details: {'id': 136188355, 'type_flags': [], 'state': [], 'text': '&View', 'has_submenu': True}\n",
            "Contains 23 items:\n",
            "  \u2514\u2500 Item 0: &Cross-Sections ...\n",
            "     Details: {'id': 61, 'type_flags': [], 'state': [], 'text': '&Cross-Sections ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Water Surface Profiles ...\n",
            "     Details: {'id': 62, 'type_flags': [], 'state': [], 'text': '&Water Surface Profiles ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &General Profile Plot ...\n",
            "     Details: {'id': 63, 'type_flags': [], 'state': [], 'text': '&General Profile Plot ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Rating Curves ...\n",
            "     Details: {'id': 64, 'type_flags': [], 'state': [], 'text': '&Rating Curves ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: 3D View ...\n",
            "     Details: {'id': 65, 'type_flags': [], 'state': [], 'text': '3D View ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: &X-Y-Z Perspective Plots (Classic) ...\n",
            "     Details: {'id': 66, 'type_flags': [], 'state': [], 'text': '&X-Y-Z Perspective Plots (Classic) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: &Stage and Flow Hydrographs ...\n",
            "     Details: {'id': 67, 'type_flags': [], 'state': [], 'text': '&Stage and Flow Hydrographs ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: &Hydraulic Property Tables ...\n",
            "     Details: {'id': 68, 'type_flags': [], 'state': [], 'text': '&Hydraulic Property Tables ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: \n",
            "     Details: {'id': 69, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: &Detailed Output Tables ...\n",
            "     Details: {'id': 70, 'type_flags': [], 'state': [], 'text': '&Detailed Output Tables ...', 'has_submenu': False}\n",
            "  ... and 13 more items\n",
            "\n",
            "Top Level Menu 4: &Options\n",
            "Details: {'id': 1050507, 'type_flags': [], 'state': [], 'text': '&Options', 'has_submenu': True}\n",
            "Contains 5 items:\n",
            "  \u2514\u2500 Item 0: &Program Setup\n",
            "     Details: {'id': 348720343, 'type_flags': [], 'state': [], 'text': '&Program Setup', 'has_submenu': True}\n",
            "     Has submenu with 5 items:\n",
            "       \u2514\u2500 Sub-item 0: Default File &Viewer ...\n",
            "          Details: {'id': 91, 'type_flags': [], 'state': [], 'text': 'Default File &Viewer ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 1: Default Project Folder ...\n",
            "          Details: {'id': 92, 'type_flags': [], 'state': [], 'text': 'Default Project Folder ...', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 2: &Open last project on startup\n",
            "          Details: {'id': 93, 'type_flags': [], 'state': [], 'text': '&Open last project on startup', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 3: Automatically Backup Data\n",
            "          Details: {'id': 94, 'type_flags': [], 'state': ['CHECKED'], 'text': 'Automatically Backup Data', 'has_submenu': False}\n",
            "       \u2514\u2500 Sub-item 4: Set Time for Automatic Backup ...\n",
            "          Details: {'id': 95, 'type_flags': [], 'state': [], 'text': 'Set Time for Automatic Backup ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: &Default Parameters\n",
            "     Details: {'id': 139527055, 'type_flags': [], 'state': [], 'text': '&Default Parameters', 'has_submenu': True}\n",
            "     Has submenu with 1 items:\n",
            "       \u2514\u2500 Sub-item 0: &Expansion and Contraction Coef ...\n",
            "          Details: {'id': 97, 'type_flags': [], 'state': [], 'text': '&Expansion and Contraction Coef ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: &Unit system (US Customary/SI) ...\n",
            "     Details: {'id': 98, 'type_flags': [], 'state': [], 'text': '&Unit system (US Customary/SI) ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: &Convert Project Units ...\n",
            "     Details: {'id': 99, 'type_flags': [], 'state': [], 'text': '&Convert Project Units ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: Convert &Horizontal Coordinate Systems ...\n",
            "     Details: {'id': 100, 'type_flags': [], 'state': [], 'text': 'Convert &Horizontal Coordinate Systems ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 5: &GIS Tools\n",
            "Details: {'id': 3737661, 'type_flags': [], 'state': [], 'text': '&GIS Tools', 'has_submenu': True}\n",
            "Contains 1 items:\n",
            "  \u2514\u2500 Item 0: RAS Mapper ...\n",
            "     Details: {'id': 102, 'type_flags': [], 'state': [], 'text': 'RAS Mapper ...', 'has_submenu': False}\n",
            "\n",
            "Top Level Menu 6: &Help\n",
            "Details: {'id': 2297713, 'type_flags': [], 'state': [], 'text': '&Help', 'has_submenu': True}\n",
            "Contains 21 items:\n",
            "  \u2514\u2500 Item 0: HEC-RAS Online Documentation ...\tF1\n",
            "     Details: {'id': 104, 'type_flags': [], 'state': [], 'text': 'HEC-RAS Online Documentation ...\\tF1', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 1: Release Notes ...\n",
            "     Details: {'id': 105, 'type_flags': [], 'state': [], 'text': 'Release Notes ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 2: Known Issues ...\n",
            "     Details: {'id': 106, 'type_flags': [], 'state': [], 'text': 'Known Issues ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 3: Community Support on Discourse ...\n",
            "     Details: {'id': 107, 'type_flags': [], 'state': [], 'text': 'Community Support on Discourse ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 4: \n",
            "     Details: {'id': 108, 'type_flags': ['SEPARATOR'], 'state': ['DISABLED', 'GRAYED'], 'text': '', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 5: Users Manual ...\n",
            "     Details: {'id': 109, 'type_flags': [], 'state': [], 'text': 'Users Manual ...', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 6: 2D Modeling User's Manual \u2026\n",
            "     Details: {'id': 110, 'type_flags': [], 'state': [], 'text': \"2D Modeling User's Manual \u2026\", 'has_submenu': False}\n",
            "  \u2514\u2500 Item 7: RAS Mapper User's Manual \u2026\n",
            "     Details: {'id': 111, 'type_flags': [], 'state': [], 'text': \"RAS Mapper User's Manual \u2026\", 'has_submenu': False}\n",
            "  \u2514\u2500 Item 8: Hydraulic Reference \u2026\n",
            "     Details: {'id': 112, 'type_flags': [], 'state': [], 'text': 'Hydraulic Reference \u2026', 'has_submenu': False}\n",
            "  \u2514\u2500 Item 9: Applications Guide \u2026\n",
            "     Details: {'id': 113, 'type_flags': [], 'state': [], 'text': 'Applications Guide \u2026', 'has_submenu': False}\n",
            "  ... and 11 more items\n",
            "\n",
            "================================================================================\n",
            "Performing detailed window hierarchy enumeration...\n",
            "Main window: HEC-RAS 6.6\n",
            "Window Handle: 1182634\n",
            "Class: ThunderRT6FormDC\n",
            "Text: HEC-RAS 6.6\n",
            "Position: (307, 50, 1157, 266)\n",
            "Style: 0x16CA0000\n",
            "Extended Style: 0x00040100\n",
            "Children: 36 found\n",
            "---\n",
            "  Window Handle: 2427996\n",
            "  Class: ThunderRT6Timer\n",
            "  Text: \n",
            "  Position: (438, 340, 438, 340)\n",
            "  Style: 0x44010000\n",
            "  Extended Style: 0x00000004\n",
            "---\n",
            "  Window Handle: 1050472\n",
            "  Class: ThunderRT6TextBox\n",
            "  Text: \n",
            "  Position: (1066, 104, 1091, 121)\n",
            "  Style: 0x440100C0\n",
            "  Extended Style: 0x00000204\n",
            "---\n",
            "  Window Handle: 919462\n",
            "  Class: ThunderRT6CheckBox\n",
            "  Text: \n",
            "  Position: (862, 100, 888, 126)\n",
            "  Style: 0x5401000B\n",
            "  Extended Style: 0x00000004\n",
            "---\n",
            "  Window Handle: 1050616\n",
            "  Class: ThunderRT6TextBox\n",
            "  Text: \n",
            "  Position: (1034, 104, 1063, 121)\n",
            "  Style: 0x440100C0\n",
            "  Extended Style: 0x00000204\n",
            "---\n",
            "  Window Handle: 919270\n",
            "  Class: ThunderRT6Timer\n",
            "  Text: \n",
            "  Position: (410, 340, 410, 340)\n",
            "  Style: 0x44010000\n",
            "  Extended Style: 0x00000004\n",
            "... and 31 more children\n",
            "\n",
            "================================================================================\n",
            "Detailed enumeration complete.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Part 1b: Deeper Menu and Window Object Enumeration using ctypes\n",
        "# ==============================================================================\n",
        "\n",
        "import win32gui\n",
        "import win32con\n",
        "import win32api\n",
        "import win32process\n",
        "import ctypes\n",
        "from ctypes import wintypes\n",
        "\n",
        "# Define MENUITEMINFO structure using ctypes\n",
        "class MENUITEMINFO(ctypes.Structure):\n",
        "    _fields_ = [\n",
        "        (\"cbSize\", wintypes.UINT),\n",
        "        (\"fMask\", wintypes.UINT),\n",
        "        (\"fType\", wintypes.UINT),\n",
        "        (\"fState\", wintypes.UINT),\n",
        "        (\"wID\", wintypes.UINT),\n",
        "        (\"hSubMenu\", wintypes.HMENU),\n",
        "        (\"hbmpChecked\", wintypes.HBITMAP),\n",
        "        (\"hbmpUnchecked\", wintypes.HBITMAP),\n",
        "        (\"dwItemData\", ctypes.POINTER(ctypes.c_ulong)),\n",
        "        (\"dwTypeData\", wintypes.LPWSTR),\n",
        "        (\"cch\", wintypes.UINT),\n",
        "        (\"hbmpItem\", wintypes.HBITMAP)\n",
        "    ]\n",
        "\n",
        "def get_menu_string(menu_handle, pos):\n",
        "    \"\"\"Get menu item string at position\"\"\"\n",
        "    buf_size = 256\n",
        "    buf = ctypes.create_unicode_buffer(buf_size)\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuStringW(menu_handle, pos, buf, buf_size, MF_BYPOSITION)\n",
        "    if result:\n",
        "        return buf.value\n",
        "    return \"\"\n",
        "\n",
        "def enumerate_menu_item_details(menu_handle, item_index):\n",
        "    \"\"\"Get detailed information about a menu item using ctypes\"\"\"\n",
        "    # Create and initialize MENUITEMINFO structure\n",
        "    mii = MENUITEMINFO()\n",
        "    mii.cbSize = ctypes.sizeof(MENUITEMINFO)\n",
        "    mii.fMask = win32con.MIIM_STATE | win32con.MIIM_ID | win32con.MIIM_TYPE | win32con.MIIM_SUBMENU\n",
        "    \n",
        "    # Call GetMenuItemInfo using ctypes\n",
        "    user32 = ctypes.windll.user32\n",
        "    result = user32.GetMenuItemInfoW(\n",
        "        menu_handle, \n",
        "        item_index, \n",
        "        True,  # fByPosition\n",
        "        ctypes.byref(mii)\n",
        "    )\n",
        "    \n",
        "    if result:\n",
        "        # Parse state flags\n",
        "        state_flags = []\n",
        "        if mii.fState & win32con.MFS_CHECKED:\n",
        "            state_flags.append(\"CHECKED\")\n",
        "        if mii.fState & win32con.MFS_DISABLED:\n",
        "            state_flags.append(\"DISABLED\")\n",
        "        if mii.fState & win32con.MFS_GRAYED:\n",
        "            state_flags.append(\"GRAYED\")\n",
        "        if mii.fState & win32con.MFS_HILITE:\n",
        "            state_flags.append(\"HIGHLIGHTED\")\n",
        "        if mii.fState & win32con.MFS_DEFAULT:\n",
        "            state_flags.append(\"DEFAULT\")\n",
        "            \n",
        "        # Parse type flags\n",
        "        type_flags = []\n",
        "        if mii.fType & win32con.MFT_STRING:\n",
        "            type_flags.append(\"STRING\")\n",
        "        if mii.fType & win32con.MFT_SEPARATOR:\n",
        "            type_flags.append(\"SEPARATOR\")\n",
        "        if mii.fType & win32con.MFT_BITMAP:\n",
        "            type_flags.append(\"BITMAP\")\n",
        "        if mii.fType & win32con.MFT_OWNERDRAW:\n",
        "            type_flags.append(\"OWNERDRAW\")\n",
        "        \n",
        "        return {\n",
        "            \"id\": mii.wID,\n",
        "            \"type_flags\": type_flags,\n",
        "            \"state\": state_flags,\n",
        "            \"text\": get_menu_string(menu_handle, item_index),\n",
        "            \"has_submenu\": bool(mii.hSubMenu)\n",
        "        }\n",
        "    else:\n",
        "        # Fallback to simpler approach if GetMenuItemInfo fails\n",
        "        try:\n",
        "            menu_id = win32gui.GetMenuItemID(menu_handle, item_index)\n",
        "            menu_state = win32gui.GetMenuState(menu_handle, item_index, win32con.MF_BYPOSITION)\n",
        "            \n",
        "            state_flags = []\n",
        "            if menu_state & win32con.MF_CHECKED:\n",
        "                state_flags.append(\"CHECKED\")\n",
        "            if menu_state & win32con.MF_DISABLED:\n",
        "                state_flags.append(\"DISABLED\")\n",
        "            if menu_state & win32con.MF_GRAYED:\n",
        "                state_flags.append(\"GRAYED\")\n",
        "            if menu_state & win32con.MF_SEPARATOR:\n",
        "                state_flags.append(\"SEPARATOR\")\n",
        "            \n",
        "            return {\n",
        "                \"id\": menu_id if menu_id != -1 else None,\n",
        "                \"state\": state_flags,\n",
        "                \"text\": get_menu_string(menu_handle, item_index),\n",
        "                \"has_submenu\": win32gui.GetSubMenu(menu_handle, item_index) is not None,\n",
        "                \"fallback\": True\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"text\": get_menu_string(menu_handle, item_index)\n",
        "            }\n",
        "\n",
        "def enumerate_window_details(hwnd, indent=0):\n",
        "    \"\"\"Recursively enumerate window details including styles and extended styles\"\"\"\n",
        "    if not hwnd:\n",
        "        return\n",
        "        \n",
        "    # Get basic window info\n",
        "    class_name = win32gui.GetClassName(hwnd)\n",
        "    window_text = win32gui.GetWindowText(hwnd)\n",
        "    \n",
        "    # Get window styles\n",
        "    style = win32gui.GetWindowLong(hwnd, win32con.GWL_STYLE)\n",
        "    ex_style = win32gui.GetWindowLong(hwnd, win32con.GWL_EXSTYLE)\n",
        "    \n",
        "    # Get window metrics\n",
        "    rect = win32gui.GetWindowRect(hwnd)\n",
        "    \n",
        "    # Print window details\n",
        "    indent_str = \"  \" * indent\n",
        "    print(f\"{indent_str}Window Handle: {hwnd}\")\n",
        "    print(f\"{indent_str}Class: {class_name}\")\n",
        "    print(f\"{indent_str}Text: {window_text}\")\n",
        "    print(f\"{indent_str}Position: {rect}\")\n",
        "    print(f\"{indent_str}Style: 0x{style:08X}\")\n",
        "    print(f\"{indent_str}Extended Style: 0x{ex_style:08X}\")\n",
        "    \n",
        "    # Enumerate child windows recursively (limit depth to avoid too much output)\n",
        "    if indent < 3:  # Limit recursion depth\n",
        "        try:\n",
        "            child_windows = []\n",
        "            win32gui.EnumChildWindows(\n",
        "                hwnd,\n",
        "                lambda child_hwnd, windows: windows.append(child_hwnd) or True,\n",
        "                child_windows\n",
        "            )\n",
        "            \n",
        "            if child_windows:\n",
        "                print(f\"{indent_str}Children: {len(child_windows)} found\")\n",
        "                for child_hwnd in child_windows[:5]:  # Show first 5 children\n",
        "                    print(f\"{indent_str}---\")\n",
        "                    enumerate_window_details(child_hwnd, indent + 1)\n",
        "                if len(child_windows) > 5:\n",
        "                    print(f\"{indent_str}... and {len(child_windows) - 5} more children\")\n",
        "        except Exception as e:\n",
        "            print(f\"{indent_str}Error enumerating children: {e}\")\n",
        "\n",
        "def enumerate_full_menu_tree(hwnd):\n",
        "    \"\"\"Enumerate complete menu tree with all available details\"\"\"\n",
        "    menu_bar = win32gui.GetMenu(hwnd)\n",
        "    if not menu_bar:\n",
        "        print(\"No menu bar found\")\n",
        "        return\n",
        "        \n",
        "    print(\"\\n=== Complete Menu Tree Analysis ===\\n\")\n",
        "    \n",
        "    menu_count = win32gui.GetMenuItemCount(menu_bar)\n",
        "    for i in range(menu_count):\n",
        "        menu_text = get_menu_string(menu_bar, i)\n",
        "        menu_details = enumerate_menu_item_details(menu_bar, i)\n",
        "        print(f\"\\nTop Level Menu {i}: {menu_text}\")\n",
        "        print(f\"Details: {menu_details}\")\n",
        "        \n",
        "        submenu = win32gui.GetSubMenu(menu_bar, i)\n",
        "        if submenu:\n",
        "            submenu_count = win32gui.GetMenuItemCount(submenu)\n",
        "            print(f\"Contains {submenu_count} items:\")\n",
        "            \n",
        "            for j in range(min(submenu_count, 10)):  # Show first 10 items\n",
        "                submenu_text = get_menu_string(submenu, j)\n",
        "                submenu_details = enumerate_menu_item_details(submenu, j)\n",
        "                print(f\"  \u2514\u2500 Item {j}: {submenu_text}\")\n",
        "                print(f\"     Details: {submenu_details}\")\n",
        "                \n",
        "                # Check for sub-submenus\n",
        "                sub_submenu = win32gui.GetSubMenu(submenu, j)\n",
        "                if sub_submenu:\n",
        "                    sub_count = win32gui.GetMenuItemCount(sub_submenu)\n",
        "                    print(f\"     Has submenu with {sub_count} items:\")\n",
        "                    for k in range(min(sub_count, 5)):  # Show first 5 sub-items\n",
        "                        sub_text = get_menu_string(sub_submenu, k)\n",
        "                        sub_details = enumerate_menu_item_details(sub_submenu, k)\n",
        "                        print(f\"       \u2514\u2500 Sub-item {k}: {sub_text}\")\n",
        "                        print(f\"          Details: {sub_details}\")\n",
        "            \n",
        "            if submenu_count > 10:\n",
        "                print(f\"  ... and {submenu_count - 10} more items\")\n",
        "\n",
        "# Main execution\n",
        "if 'hecras_pid' in globals() and hecras_pid is not None:\n",
        "    # Wait for windows to be ready\n",
        "    import time\n",
        "    time.sleep(1)\n",
        "    \n",
        "    # Find HEC-RAS windows\n",
        "    windows = get_windows_by_pid(hecras_pid)\n",
        "    hec_ras_hwnd, title = find_main_hecras_window(windows)\n",
        "    \n",
        "    if hec_ras_hwnd:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Performing detailed menu enumeration...\")\n",
        "        enumerate_full_menu_tree(hec_ras_hwnd)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Performing detailed window hierarchy enumeration...\")\n",
        "        print(f\"Main window: {title}\")\n",
        "        enumerate_window_details(hec_ras_hwnd)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"Detailed enumeration complete.\")\n",
        "    else:\n",
        "        print(\"Could not find main HEC-RAS window\")\n",
        "else:\n",
        "    print(\"HEC-RAS process ID not found. Please run the cell that launches HEC-RAS first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This provides the basic building blocks for GUI-driven automations for HEC-RAS without the HECRASController"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_piptest",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
==================================================

File: C:\GH\ras-commander\examples\17_extracting_profiles_with_hecrascontroller and RasControl.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:26.598182Z",
          "iopub.status.busy": "2025-11-17T19:05:26.597941Z",
          "iopub.status.idle": "2025-11-17T19:05:28.305562Z",
          "shell.execute_reply": "2025-11-17T19:05:28.305031Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "```python\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working with Legacy HEC-RAS Using RasControl\n",
        "\n",
        "This notebook demonstrates **RasControl**, which provides a ras-commander style API for legacy HEC-RAS versions (3.x-4.x) using the HECRASController COM interface.\n",
        "\n",
        "## What is RasControl?\n",
        "\n",
        "**RasControl** wraps the HECRASController COM API with ras-commander conventions:\n",
        "\n",
        "- \u2705 **Use plan numbers** - `RasControl.run_plan(\"02\")` not file paths\n",
        "- \u2705 **Integrated with ras object** - Works with `init_ras_project()`\n",
        "- \u2705 **Steady AND unsteady** - Extract profiles and time series\n",
        "- \u2705 **Auto-sets current plan** - Just pass the plan number!\n",
        "- \u2705 **No COM complexity** - Clean public API\n",
        "\n",
        "## When to Use RasControl\n",
        "\n",
        "| Use RasControl | Use HDF Methods |\n",
        "|----------------|----------------|\n",
        "| HEC-RAS 3.1, 4.1 | HEC-RAS 6.0+ |\n",
        "| No HDF support | Modern versions |\n",
        "| Legacy models | 2D mesh data |\n",
        "| Version migration | Better performance |\n",
        "\n",
        "## Supported Versions\n",
        "\n",
        "3.0, 3.1, 4.0, 4.1, 5.0-5.0.7, 6.0-6.7 Beta\n",
        "\n",
        "Accepts: `\"4.1\"`, `\"41\"`, `\"5.0.6\"`, `\"506\"`, `\"6.6\"`, `\"66\"`, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.307996Z",
          "iopub.status.busy": "2025-11-17T19:05:28.307624Z",
          "iopub.status.idle": "2025-11-17T19:05:28.310145Z",
          "shell.execute_reply": "2025-11-17T19:05:28.309754Z"
        }
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade ras-commander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.312286Z",
          "iopub.status.busy": "2025-11-17T19:05:28.311987Z",
          "iopub.status.idle": "2025-11-17T19:05:28.315882Z",
          "shell.execute_reply": "2025-11-17T19:05:28.315329Z"
        }
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.318508Z",
          "iopub.status.busy": "2025-11-17T19:05:28.318153Z",
          "iopub.status.idle": "2025-11-17T19:05:28.321877Z",
          "shell.execute_reply": "2025-11-17T19:05:28.321380Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PLOTTING CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Set better default plotting parameters\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 9\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "\n",
        "import numpy as np  # Add if not already imported\n",
        "\n",
        "print(\"\u2713 Plotting configuration loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.323634Z",
          "iopub.status.busy": "2025-11-17T19:05:28.323423Z",
          "iopub.status.idle": "2025-11-17T19:05:28.327130Z",
          "shell.execute_reply": "2025-11-17T19:05:28.326476Z"
        }
      },
      "outputs": [],
      "source": [
        "# Enable this cell for local development version of ras-commander\n",
        "import os\n",
        "import sys      \n",
        "from pathlib import Path\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.329457Z",
          "iopub.status.busy": "2025-11-17T19:05:28.329226Z",
          "iopub.status.idle": "2025-11-17T19:05:28.333188Z",
          "shell.execute_reply": "2025-11-17T19:05:28.332632Z"
        }
      },
      "outputs": [],
      "source": [
        "# 2. Import all required modules\n",
        "\n",
        "# Import all ras-commander modules\n",
        "from ras_commander import *\n",
        "\n",
        "# Import the required libraries for this notebook\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.336035Z",
          "iopub.status.busy": "2025-11-17T19:05:28.335610Z",
          "iopub.status.idle": "2025-11-17T19:05:28.345204Z",
          "shell.execute_reply": "2025-11-17T19:05:28.344712Z"
        }
      },
      "outputs": [],
      "source": [
        "# Helper Plotting Functions\n",
        "\n",
        "def plot_steady_profiles_by_reach(df, title_prefix=\"Steady Flow Profiles\"):\n",
        "    \"\"\"\n",
        "    Plot steady flow profiles separated by River/Reach.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        Steady results from RasControl.get_steady_results()\n",
        "    title_prefix : str\n",
        "        Prefix for plot titles\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # Group by River/Reach\n",
        "    for (river, reach), group_df in df.groupby(['river', 'reach']):\n",
        "        fig, ax = plt.subplots(figsize=(14, 6))\n",
        "        \n",
        "        # Sort by station (descending - upstream to downstream)\n",
        "        group_df_sorted = group_df.sort_values('node_id', ascending=False)\n",
        "        \n",
        "        # Plot each profile\n",
        "        profiles = group_df['profile'].unique()\n",
        "        for profile in profiles:\n",
        "            prof_data = group_df_sorted[group_df_sorted['profile'] == profile]\n",
        "            ax.plot(prof_data['node_id'], prof_data['wsel'], \n",
        "                    marker='o', label=f'{profile}', linewidth=2, markersize=4)\n",
        "        \n",
        "        # Add channel invert\n",
        "        invert = group_df_sorted.drop_duplicates('node_id')[['node_id', 'min_ch_el']]\n",
        "        ax.plot(invert['node_id'], invert['min_ch_el'], \n",
        "                'k--', label='Channel Invert', linewidth=2, alpha=0.7)\n",
        "        \n",
        "        ax.set_xlabel('River Station', fontsize=12)\n",
        "        ax.set_ylabel('Elevation (ft)', fontsize=12)\n",
        "        ax.set_title(f'{title_prefix}\\n{river} - {reach}', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "        ax.legend(loc='best', fontsize=9, ncol=2)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.invert_xaxis()  # Upstream on left\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_unsteady_timeseries_multi_xs(df_timeseries, df_maxws, selected_xs=None, n_xs=5):\n",
        "    \"\"\"\n",
        "    Plot unsteady time series at multiple cross sections with Max WS annotations.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df_timeseries : DataFrame\n",
        "        Unsteady results WITHOUT 'Max WS' rows, with 'datetime' column\n",
        "    df_maxws : DataFrame\n",
        "        Unsteady results for ONLY 'Max WS' rows\n",
        "    selected_xs : list, optional\n",
        "        List of specific cross sections to plot. If None, selects evenly spaced XS\n",
        "    n_xs : int\n",
        "        Number of cross sections to plot (used if selected_xs is None)\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.dates as mdates\n",
        "    \n",
        "    # Select cross sections if not provided\n",
        "    if selected_xs is None:\n",
        "        all_xs = sorted(df_timeseries['node_id'].unique(), reverse=True)\n",
        "        step = max(1, len(all_xs) // n_xs)\n",
        "        selected_xs = all_xs[::step][:n_xs]\n",
        "    \n",
        "    # Create subplots\n",
        "    n_xs_plot = len(selected_xs)\n",
        "    fig, axes = plt.subplots(n_xs_plot, 1, figsize=(14, 4*n_xs_plot))\n",
        "    if n_xs_plot == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, xs in enumerate(selected_xs):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Get data for this XS\n",
        "        xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "        maxws_data = df_maxws[df_maxws['node_id'] == xs]\n",
        "        \n",
        "        # Plot time series\n",
        "        ax.plot(xs_data['datetime'], xs_data['wsel'], \n",
        "                'b-o', linewidth=2, markersize=4, label='WSE at Output Timesteps')\n",
        "        \n",
        "        # Get values for annotation\n",
        "        max_ws_value = maxws_data['wsel'].iloc[0] if len(maxws_data) > 0 else None\n",
        "        max_output_value = xs_data['wsel'].max()\n",
        "        \n",
        "        # Add horizontal reference for Max WS\n",
        "        if max_ws_value:\n",
        "            ax.axhline(max_ws_value, color='r', linestyle='--', \n",
        "                       linewidth=2, alpha=0.7, label='Max WS (computational)')\n",
        "        \n",
        "        # Add annotations\n",
        "        annotation_text = f\"Max WS (computational): {max_ws_value:.2f} ft\\n\"\n",
        "        annotation_text += f\"Max (output interval): {max_output_value:.2f} ft\"\n",
        "        \n",
        "        ax.text(0.02, 0.98, annotation_text, \n",
        "                transform=ax.transAxes, fontsize=10,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "        \n",
        "        ax.set_ylabel('WSE (ft)', fontsize=11)\n",
        "        ax.set_title(f'Station {xs}', fontsize=12, fontweight='bold')\n",
        "        ax.legend(loc='upper right', fontsize=9)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Format x-axis for dates\n",
        "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))\n",
        "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "    axes[-1].set_xlabel('Date/Time', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\u2713 Helper plotting functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.347374Z",
          "iopub.status.busy": "2025-11-17T19:05:28.347110Z",
          "iopub.status.idle": "2025-11-17T19:05:28.350335Z",
          "shell.execute_reply": "2025-11-17T19:05:28.349925Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import ras-commander\n",
        "sys.path.append(str(Path(os.getcwd()).parent))\n",
        "from ras_commander import RasExamples, init_ras_project, RasControl, ras, RasCmdr\n",
        "\n",
        "print(f\"RasControl supports: {list(RasControl.SUPPORTED_VERSIONS.keys())[:5]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract and Initialize Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.352379Z",
          "iopub.status.busy": "2025-11-17T19:05:28.352111Z",
          "iopub.status.idle": "2025-11-17T19:05:28.490274Z",
          "shell.execute_reply": "2025-11-17T19:05:28.489921Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract Bald Eagle Creek (has steady Plan 02 and unsteady Plan 01)\n",
        "project_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "\n",
        "# Initialize with version (required for RasControl)\n",
        "init_ras_project(project_path, \"6.6\")  # or \"66\", \"6.5\", \"4.1\", \"41\", etc.\n",
        "\n",
        "print(f\"Project: {ras.project_name}\")\n",
        "print(f\"Version: {ras.ras_version}\")\n",
        "print(f\"\\nPlans:\")\n",
        "print(ras.plan_df[['plan_number', 'Plan Title', 'flow_type',\"full_path\"]])\n",
        "\n",
        "# Use the full_path from plan_df to do the following for each plain text plan file: \n",
        "# Find the following values and change them\n",
        "# Change \"Output Interval=10MIN\" \n",
        "# Change \"Mapping Interval=10MIN\" \n",
        "\n",
        "\n",
        "import re, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ...existing code...\n",
        "def update_plan_intervals_from_plan_df(plan_df, plan_numbers=None,\n",
        "                                       output_interval=None, mapping_interval=None,\n",
        "                                       make_backup=True, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    Replace Output Interval and Mapping Interval in plain-text plan files referenced by plan_df['full_path'].\n",
        "    - plan_numbers: list of plan_number strings to limit changes (e.g. ['01','02']) or None for all.\n",
        "    - output_interval / mapping_interval: strings like '6MIN', '10MIN' (include unit).\n",
        "    \"\"\"\n",
        "    for _, row in plan_df.iterrows():\n",
        "        plan_no = str(row.get('plan_number', '')).zfill(2)\n",
        "        if plan_numbers and plan_no not in [str(p).zfill(2) for p in plan_numbers]:\n",
        "            continue\n",
        "\n",
        "        fp = Path(row.get('full_path', ''))\n",
        "        if not fp.exists():\n",
        "            print(f\"Missing file: {fp}\")\n",
        "            continue\n",
        "\n",
        "        text = fp.read_text(encoding=encoding, errors='ignore')\n",
        "        new_text = text\n",
        "\n",
        "        if output_interval:\n",
        "            # Use a callable replacement to avoid accidental numeric backreference parsing (e.g. \"\\16MIN\")\n",
        "            new_text = re.sub(\n",
        "                r'(?i)(Output\\s*Interval\\s*=\\s*)(\\S+)',\n",
        "                lambda m, out=output_interval: m.group(1) + out,\n",
        "                new_text\n",
        "            )\n",
        "\n",
        "        if mapping_interval:\n",
        "            new_text = re.sub(\n",
        "                r'(?i)(Mapping\\s*Interval\\s*=\\s*)(\\S+)',\n",
        "                lambda m, mp=mapping_interval: m.group(1) + mp,\n",
        "                new_text\n",
        "            )\n",
        "\n",
        "        if new_text != text:\n",
        "            if make_backup:\n",
        "                bak = fp.with_suffix(fp.suffix + '.bak')\n",
        "                shutil.copy(fp, bak)\n",
        "            fp.write_text(new_text, encoding=encoding)\n",
        "            print(f\"Updated {fp} (Plan {plan_no})\")\n",
        "        else:\n",
        "            print(f\"No change needed: {fp} (Plan {plan_no})\")\n",
        "# ...existing code...\n",
        "\n",
        "# Example usage: update Plan 01 (unsteady) to 6MIN intervals\n",
        "update_plan_intervals_from_plan_df(ras.plan_df, plan_numbers=['01'],\n",
        "                                   output_interval='10MIN', mapping_interval='10MIN',\n",
        "                                   make_backup=True)\n",
        "update_plan_intervals_from_plan_df(ras.plan_df, plan_numbers=['02'],\n",
        "                                   output_interval='10MIN', mapping_interval='10MIN',\n",
        "                                   make_backup=True)\n",
        "init_ras_project(project_path, \"6.6\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.492030Z",
          "iopub.status.busy": "2025-11-17T19:05:28.491822Z",
          "iopub.status.idle": "2025-11-17T19:05:28.505453Z",
          "shell.execute_reply": "2025-11-17T19:05:28.505039Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Steady State (Plan 02)\n",
        "\n",
        "Extract steady profiles. **Note:** `run_plan()` automatically sets Plan 02 as current!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:28.507423Z",
          "iopub.status.busy": "2025-11-17T19:05:28.507171Z",
          "iopub.status.idle": "2025-11-17T19:05:51.438318Z",
          "shell.execute_reply": "2025-11-17T19:05:51.437852Z"
        }
      },
      "outputs": [],
      "source": [
        "# Run Plan 02 (auto-sets as current, then runs)\n",
        "print(\"Running Plan 02 (Steady)...\")\n",
        "\n",
        "# NEW BEHAVIOR: run_plan() now checks if plan is current before running\n",
        "# - If plan is already current (results are up-to-date), it skips the computation\n",
        "# - To force recomputation regardless: RasControl.run_plan(\"02\", force_recompute=True)\n",
        "success, msgs = RasControl.run_plan(\"02\", force_recompute=True)\n",
        "print(f\"Success: {success}, Messages: {len(msgs)}\")\n",
        "print(msgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Computation Messages (Steady Flow)\n",
        "\n",
        "After running the plan, we can extract detailed computation messages using `RasControl.get_comp_msgs()`. This method:\n",
        "- Reads from `.comp_msgs.txt` or `.computeMsgs.txt` files (version-dependent)\n",
        "- Falls back to HDF extraction if .txt files not available\n",
        "- Returns detailed information about the computation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:51.440440Z",
          "iopub.status.busy": "2025-11-17T19:05:51.440210Z",
          "iopub.status.idle": "2025-11-17T19:05:51.449904Z",
          "shell.execute_reply": "2025-11-17T19:05:51.448693Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract computation messages for steady flow Plan 02\n",
        "print(\"=\"*80)\n",
        "print(\"COMPUTATION MESSAGES - Plan 02 (Steady Flow)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "msgs_steady = RasControl.get_comp_msgs(\"02\")\n",
        "\n",
        "if msgs_steady:\n",
        "    print(f\"\\nExtracted {len(msgs_steady)} characters of computation messages\\n\")\n",
        "    \n",
        "    # Display first 800 characters\n",
        "    print(\"Computation messages (first 800 characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(msgs_steady[:800])\n",
        "    \n",
        "    if len(msgs_steady) > 800:\n",
        "        print(\"\\n... (truncated) ...\")\n",
        "else:\n",
        "    print(\"No computation messages available for Plan 02\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:51.452979Z",
          "iopub.status.busy": "2025-11-17T19:05:51.452668Z",
          "iopub.status.idle": "2025-11-17T19:05:54.930528Z",
          "shell.execute_reply": "2025-11-17T19:05:54.929999Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract steady results (auto-sets Plan 02 as current)\n",
        "df_steady = RasControl.get_steady_results(\"02\")\n",
        "\n",
        "print(f\"Rows: {len(df_steady)}\")\n",
        "print(f\"Profiles: {df_steady['profile'].nunique()}\")\n",
        "print(f\"XS: {df_steady['node_id'].nunique()}\")\n",
        "df_steady.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:54.932440Z",
          "iopub.status.busy": "2025-11-17T19:05:54.932282Z",
          "iopub.status.idle": "2025-11-17T19:05:55.133019Z",
          "shell.execute_reply": "2025-11-17T19:05:55.132476Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEADY FLOW: Longitudinal Profiles by River/Reach\n",
        "# ============================================================================\n",
        "\n",
        "# Convert node_id to float for proper sorting\n",
        "df_steady['node_id'] = df_steady['node_id'].astype(float)\n",
        "\n",
        "# Group by River/Reach and create separate plots\n",
        "for (river, reach), group_df in df_steady.groupby(['river', 'reach']):\n",
        "    \n",
        "    # Sort by station (descending - upstream to downstream per HEC-RAS convention)\n",
        "    group_df_sorted = group_df.sort_values('node_id', ascending=False)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(16, 7))\n",
        "    \n",
        "    # Get unique profiles and plot each one\n",
        "    profiles = sorted(group_df['profile'].unique())\n",
        "    colors = plt.cm.viridis(np.linspace(0, 0.9, len(profiles)))\n",
        "    \n",
        "    for idx, profile in enumerate(profiles):\n",
        "        prof_data = group_df_sorted[group_df_sorted['profile'] == profile]\n",
        "        ax.plot(prof_data['node_id'], prof_data['wsel'], \n",
        "                marker='o', markersize=3, linewidth=2, \n",
        "                color=colors[idx], label=f'WSE: {profile}', alpha=0.8)\n",
        "    \n",
        "    # Add channel invert (plot once, not for each profile)\n",
        "    invert = group_df_sorted.drop_duplicates('node_id')[['node_id', 'min_ch_el']].sort_values('node_id', ascending=False)\n",
        "    ax.plot(invert['node_id'], invert['min_ch_el'], \n",
        "            'k--', linewidth=2.5, alpha=0.7, label='Channel Invert')\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_xlabel('River Station', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Elevation (ft)', fontsize=13, fontweight='bold')\n",
        "    ax.set_title(f'{river} - {reach}\\nSteady Flow Water Surface Profiles', \n",
        "                 fontsize=15, fontweight='bold', pad=15)\n",
        "    ax.legend(loc='best', fontsize=10, framealpha=0.9)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    ax.invert_xaxis()  # Upstream (larger stations) on left\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\u2713 Plotted {len(profiles)} profiles for {river} - {reach}\")\n",
        "    print(f\"  Station range: {group_df['node_id'].min():.1f} to {group_df['node_id'].max():.1f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:55.135745Z",
          "iopub.status.busy": "2025-11-17T19:05:55.135457Z",
          "iopub.status.idle": "2025-11-17T19:05:55.149829Z",
          "shell.execute_reply": "2025-11-17T19:05:55.149281Z"
        }
      },
      "outputs": [],
      "source": [
        "# Export\n",
        "Path(\"working\").mkdir(exist_ok=True)\n",
        "df_steady.to_csv(\"working/steady_plan02.csv\", index=False)\n",
        "print(f\"Exported {len(df_steady)} rows to working/steady_plan02.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Unsteady Time Series (Plan 01)\n",
        "\n",
        "Extract unsteady results. **Note:** Methods automatically set Plan 01 as current!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:05:55.151959Z",
          "iopub.status.busy": "2025-11-17T19:05:55.151619Z",
          "iopub.status.idle": "2025-11-17T19:07:31.696996Z",
          "shell.execute_reply": "2025-11-17T19:07:31.696555Z"
        }
      },
      "outputs": [],
      "source": [
        "# Run Plan 01 (auto-sets as current, waits for completion)\n",
        "# This may take 5-10 minutes!\n",
        "print(\"Running Plan 01 (Unsteady)...\")\n",
        "# success, msgs = RasControl.run_plan(new_plan)  >> Don't use this, it always sets cores to max\n",
        "RasCmdr.compute_plan(\"01\", clear_geompre=True, num_cores=2)  ## Use this instead, it's ras-commander's direct command line wrapper with extra arguments\n",
        "   \n",
        "print(f\"Success: {success}\")\n",
        "print(f\"Messages: {msgs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:31.699394Z",
          "iopub.status.busy": "2025-11-17T19:07:31.699111Z",
          "iopub.status.idle": "2025-11-17T19:07:32.773695Z",
          "shell.execute_reply": "2025-11-17T19:07:32.773223Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get output times (auto-sets Plan 01 as current)\n",
        "times = RasControl.get_output_times(\"01\")\n",
        "print(f\"Found {len(times)} timesteps\")\n",
        "print(f\"First: {times[0]}\")\n",
        "print(f\"Last: {times[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Computation Messages (Unsteady Flow)\n",
        "\n",
        "Similarly, we can extract computation messages for the unsteady flow plan to review:\n",
        "- Simulation timing and performance\n",
        "- Convergence information\n",
        "- Any warnings or errors encountered during computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:32.775767Z",
          "iopub.status.busy": "2025-11-17T19:07:32.775512Z",
          "iopub.status.idle": "2025-11-17T19:07:32.789775Z",
          "shell.execute_reply": "2025-11-17T19:07:32.789282Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract computation messages for unsteady flow Plan 01\n",
        "print(\"=\"*80)\n",
        "print(\"COMPUTATION MESSAGES - Plan 01 (Unsteady Flow)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "msgs_unsteady = RasControl.get_comp_msgs(\"01\")\n",
        "\n",
        "if msgs_unsteady:\n",
        "    print(f\"\\nExtracted {len(msgs_unsteady)} characters of computation messages\\n\")\n",
        "    \n",
        "    # Display first 800 characters\n",
        "    print(\"Computation messages (first 800 characters):\")\n",
        "    print(\"-\" * 80)\n",
        "    print(msgs_unsteady[:800])\n",
        "    \n",
        "    if len(msgs_unsteady) > 800:\n",
        "        print(\"\\n... (truncated) ...\")\n",
        "    \n",
        "    # Check for errors/warnings\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Checking for warnings/errors...\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    lines = msgs_unsteady.split('\\n')\n",
        "    issues = [l for l in lines if 'error' in l.lower() or 'warning' in l.lower()]\n",
        "    \n",
        "    if issues:\n",
        "        print(f\"Found {len(issues)} warning/error lines:\")\n",
        "        for issue in issues[:5]:  # Show first 5\n",
        "            print(f\"  - {issue.strip()}\")\n",
        "    else:\n",
        "        print(\"\u2713 No warnings or errors found\")\n",
        "else:\n",
        "    print(\"No computation messages available for Plan 01\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:07:32.791418Z",
          "iopub.status.busy": "2025-11-17T19:07:32.791276Z",
          "iopub.status.idle": "2025-11-17T19:08:04.208694Z",
          "shell.execute_reply": "2025-11-17T19:08:04.208082Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract unsteady (limit to 10 timesteps for demo)\n",
        "df_unsteady = RasControl.get_unsteady_results(\"01\")\n",
        "\n",
        "print(f\"Rows: {len(df_unsteady)}\")\n",
        "print(f\"Timesteps: {df_unsteady['time_index'].nunique()}\")\n",
        "print(f\"XS: {df_unsteady['node_id'].nunique()}\")\n",
        "df_unsteady.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding \"Max WS\" in Unsteady Output\n",
        "\n",
        "**Important:** HEC-RAS unsteady results include a special row with `time_string=\"Max WS\"` (time_index=1). This contains the **maximum values that occurred at ANY computational timestep** during the entire simulation, not just at output intervals.\n",
        "\n",
        "**Why this matters:**\n",
        "- Output intervals (e.g., every 1 hour) may miss the peak flow/WSE\n",
        "- Computational timesteps (e.g., every 30 seconds) capture the true maximum\n",
        "- \"Max WS\" shows the absolute peak, even if it wasn't saved to an output interval\n",
        "\n",
        "**How to use it:**\n",
        "- Include in DataFrame for reference (critical data!)\n",
        "- Filter out when plotting time series (it's not a timestep)\n",
        "- Show as horizontal reference line on plots to indicate peak\n",
        "\n",
        "The next cell demonstrates this pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:04.211178Z",
          "iopub.status.busy": "2025-11-17T19:08:04.210883Z",
          "iopub.status.idle": "2025-11-17T19:08:05.861386Z",
          "shell.execute_reply": "2025-11-17T19:08:05.860496Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Time Series at Multiple Cross Sections\n",
        "# ============================================================================\n",
        "# NOTE: This cell shows LEGACY manual datetime parsing for reference.\n",
        "# For v0.81.0+, see the cell below for automatic datetime usage!\n",
        "# ============================================================================\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "\n",
        "# Convert node_id to float\n",
        "df_unsteady['node_id'] = df_unsteady['node_id'].astype(float)\n",
        "\n",
        "# Separate Max WS from timeseries data\n",
        "df_maxws = df_unsteady[df_unsteady['time_string'] == 'Max WS'].copy()\n",
        "df_timeseries = df_unsteady[df_unsteady['time_string'] != 'Max WS'].copy()\n",
        "\n",
        "# LEGACY: Parse datetime for timeseries (NOT NEEDED in v0.81.0+ - datetime column auto-included!)\n",
        "df_timeseries['datetime'] = pd.to_datetime(df_timeseries['time_string'], \n",
        "                                           format='%d%b%Y %H%M', errors='coerce')\n",
        "\n",
        "# Select cross sections to plot (every 20th station for manageable plot count)\n",
        "all_xs = sorted(df_timeseries['node_id'].unique(), reverse=True)  # Upstream to downstream\n",
        "selected_xs = all_xs[::20]  # Adjust step size as needed (20, 30, etc.)\n",
        "\n",
        "if len(selected_xs) == 0:\n",
        "    selected_xs = [all_xs[0]]  # At least plot one\n",
        "\n",
        "print(f\"Creating time series plots for {len(selected_xs)} cross sections:\")\n",
        "print(f\"  Stations: {[f'{xs:.1f}' for xs in selected_xs]}\\n\")\n",
        "\n",
        "# Create subplots - one per cross section\n",
        "n_xs = len(selected_xs)\n",
        "fig, axes = plt.subplots(n_xs, 1, figsize=(16, 4*n_xs))\n",
        "if n_xs == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, xs in enumerate(selected_xs):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Get data for this cross section\n",
        "    xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "    maxws_data = df_maxws[df_maxws['node_id'] == xs]\n",
        "    \n",
        "    if len(xs_data) == 0:\n",
        "        ax.text(0.5, 0.5, f'No data for station {xs:.1f}', \n",
        "                ha='center', va='center', transform=ax.transAxes)\n",
        "        continue\n",
        "    \n",
        "    # Plot WSE time series\n",
        "    ax.plot(xs_data['datetime'], xs_data['wsel'], \n",
        "            'b-o', linewidth=2, markersize=5, label='WSE (output intervals)', \n",
        "            alpha=0.8)\n",
        "    \n",
        "    # Get max values\n",
        "    max_ws_value = maxws_data['wsel'].iloc[0] if len(maxws_data) > 0 else None\n",
        "    max_output_value = xs_data['wsel'].max()\n",
        "    max_output_time = xs_data.loc[xs_data['wsel'].idxmax(), 'datetime']\n",
        "    \n",
        "    # Add horizontal line for computational Max WS\n",
        "    #if max_ws_value:\n",
        "    #    ax.axhline(max_ws_value, color='r', linestyle='--', \n",
        "    #               linewidth=2, alpha=0.7, label='Max WS (computational)')\n",
        "    \n",
        "    # Create annotation text box\n",
        "    annotation_lines = [\n",
        "        f\"Max WS (computational): {max_ws_value:.2f} ft\" if max_ws_value else \"Max WS: N/A\",\n",
        "        f\"Max (output interval): {max_output_value:.2f} ft\",\n",
        "        f\"  at {max_output_time.strftime('%m/%d %H:%M')}\" if pd.notna(max_output_time) else \"\"\n",
        "    ]\n",
        "    annotation_text = '\\n'.join(annotation_lines)\n",
        "    \n",
        "    ax.text(0.02, 0.98, annotation_text, \n",
        "            transform=ax.transAxes, fontsize=10,\n",
        "            verticalalignment='top', horizontalalignment='left',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.9, pad=0.5))\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_ylabel('WSE (ft)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'Station {xs:.1f}', fontsize=12, fontweight='bold', loc='left')\n",
        "    ax.legend(loc='upper right', fontsize=9, framealpha=0.9)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Format x-axis for dates\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M'))\n",
        "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))  # Adjust interval as needed\n",
        "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center', fontsize=9)\n",
        "\n",
        "# Add common x-label to bottom subplot\n",
        "axes[-1].set_xlabel('Date / Time', fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Unsteady Flow: Water Surface Time Series at Selected Cross Sections',\n",
        "             fontsize=16, fontweight='bold', y=1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u2713 Created time series plots for {len(selected_xs)} stations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NEW in v0.81.0: Automatic Datetime Parsing\n",
        "\n",
        "Starting in version 0.81.0, `get_unsteady_results()` automatically includes a `datetime` column with proper datetime64[ns] objects. **Manual parsing is no longer needed!**\n",
        "\n",
        "**Key Improvements:**\n",
        "- \u2705 `datetime` column added automatically\n",
        "- \u2705 Already in datetime64[ns] format (not strings)\n",
        "- \u2705 \"Max WS\" rows have `pd.NaT` for clean filtering\n",
        "- \u2705 Immediate compatibility with pandas datetime operations\n",
        "- \u2705 Backward compatible - `time_string` still included\n",
        "\n",
        "The cell above shows the old manual parsing method (kept for reference). The next cell demonstrates the modern approach using the automatic `datetime` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:05.867596Z",
          "iopub.status.busy": "2025-11-17T19:08:05.867396Z",
          "iopub.status.idle": "2025-11-17T19:08:05.884233Z",
          "shell.execute_reply": "2025-11-17T19:08:05.883715Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# MODERN APPROACH: Using Automatic datetime Column (v0.81.0+)\n",
        "# ============================================================================\n",
        "\n",
        "# Check that datetime column exists and is already parsed\n",
        "print(\"DataFrame columns:\")\n",
        "print(df_unsteady.columns.tolist())\n",
        "print(f\"\\ndatetime column type: {df_unsteady['datetime'].dtype}\")\n",
        "print(f\"Sample datetime values:\")\n",
        "print(df_unsteady[['time_string', 'datetime']].head(10))\n",
        "\n",
        "# Separate using datetime column (NaT for Max WS rows)\n",
        "df_maxws_modern = df_unsteady[df_unsteady['datetime'].isna()].copy()\n",
        "df_timeseries_modern = df_unsteady[df_unsteady['datetime'].notna()].copy()\n",
        "\n",
        "print(f\"\\nMax WS rows: {len(df_maxws_modern)}\")\n",
        "print(f\"Timeseries rows: {len(df_timeseries_modern)}\")\n",
        "\n",
        "# Use pandas datetime accessors directly - no manual parsing needed!\n",
        "print(\"\\nDatetime operations (no parsing required!):\")\n",
        "print(f\"  Simulation start: {df_timeseries_modern['datetime'].min()}\")\n",
        "print(f\"  Simulation end: {df_timeseries_modern['datetime'].max()}\")\n",
        "print(f\"  Duration: {df_timeseries_modern['datetime'].max() - df_timeseries_modern['datetime'].min()}\")\n",
        "print(f\"  Unique hours: {df_timeseries_modern['datetime'].dt.hour.unique()[:10]}\")\n",
        "\n",
        "# Time-based filtering (modern approach)\n",
        "# Example: Get data for a specific date\n",
        "specific_date = pd.Timestamp('1999-02-19')\n",
        "feb_19_data = df_timeseries_modern[df_timeseries_modern['datetime'].dt.date == specific_date.date()]\n",
        "print(f\"\\nData points on {specific_date.date()}: {len(feb_19_data)}\")\n",
        "\n",
        "# Example: Get data for specific time range\n",
        "start_time = pd.Timestamp('1999-02-18 12:00:00')\n",
        "end_time = pd.Timestamp('1999-02-20 12:00:00')\n",
        "time_range_data = df_timeseries_modern[\n",
        "    (df_timeseries_modern['datetime'] >= start_time) & \n",
        "    (df_timeseries_modern['datetime'] <= end_time)\n",
        "]\n",
        "print(f\"Data points between {start_time} and {end_time}: {len(time_range_data)}\")\n",
        "\n",
        "print(\"\\n\u2713 Modern datetime functionality demonstrated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:05.886246Z",
          "iopub.status.busy": "2025-11-17T19:08:05.885985Z",
          "iopub.status.idle": "2025-11-17T19:08:06.063285Z",
          "shell.execute_reply": "2025-11-17T19:08:06.062819Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Maximum Water Surface Envelope\n",
        "# ============================================================================\n",
        "\n",
        "# Sort by station for profile view\n",
        "max_wse_sorted = df_maxws.sort_values('node_id', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 7))\n",
        "\n",
        "# Plot maximum WSE envelope\n",
        "ax.plot(max_wse_sorted['node_id'], max_wse_sorted['wsel'],\n",
        "        'r-o', linewidth=2.5, markersize=5, \n",
        "        label='Max WS Envelope (peak at any computational timestep)', \n",
        "        alpha=0.8)\n",
        "\n",
        "# Add channel invert\n",
        "invert = max_wse_sorted[['node_id', 'min_ch_el']].drop_duplicates('node_id').sort_values('node_id', ascending=False)\n",
        "ax.plot(invert['node_id'], invert['min_ch_el'],\n",
        "        'k--', linewidth=2.5, alpha=0.7, label='Channel Invert')\n",
        "\n",
        "# Fill between for visual clarity\n",
        "ax.fill_between(max_wse_sorted['node_id'], \n",
        "                max_wse_sorted['min_ch_el'], \n",
        "                max_wse_sorted['wsel'],\n",
        "                alpha=0.2, color='blue', label='Maximum Flow Depth')\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('River Station', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Elevation (ft)', fontsize=13, fontweight='bold')\n",
        "ax.set_title('Maximum Water Surface Envelope\\n(Peak elevation reached at any computational timestep during simulation)',\n",
        "             fontsize=15, fontweight='bold', pad=15)\n",
        "ax.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.invert_xaxis()  # Upstream on left\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "max_depth = (max_wse_sorted['wsel'] - max_wse_sorted['min_ch_el']).max()\n",
        "max_depth_station = max_wse_sorted.loc[(max_wse_sorted['wsel'] - max_wse_sorted['min_ch_el']).idxmax(), 'node_id']\n",
        "\n",
        "print(f\"\\n\u2713 Maximum Water Surface Envelope\")\n",
        "print(f\"  Max depth: {max_depth:.2f} ft at station {max_depth_station:.1f}\")\n",
        "print(f\"  Highest WSE: {max_wse_sorted['wsel'].max():.2f} ft at station {max_wse_sorted.loc[max_wse_sorted['wsel'].idxmax(), 'node_id']:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:06.065813Z",
          "iopub.status.busy": "2025-11-17T19:08:06.065276Z",
          "iopub.status.idle": "2025-11-17T19:08:06.214514Z",
          "shell.execute_reply": "2025-11-17T19:08:06.213873Z"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# UNSTEADY FLOW: Velocity Hydrographs at Key Locations\n",
        "# ============================================================================\n",
        "\n",
        "# Select critical stations (upstream, middle, downstream)\n",
        "all_stations = sorted(df_timeseries['node_id'].unique(), reverse=True)\n",
        "n_stations = len(all_stations)\n",
        "\n",
        "if n_stations >= 3:\n",
        "    critical_xs = [\n",
        "        all_stations[0],                    # Upstream\n",
        "        all_stations[n_stations // 2],      # Middle\n",
        "        all_stations[-1]                    # Downstream\n",
        "    ]\n",
        "    labels = ['Upstream', 'Midstream', 'Downstream']\n",
        "else:\n",
        "    critical_xs = all_stations\n",
        "    labels = [f'Station {i+1}' for i in range(len(critical_xs))]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "# Plot velocity hydrographs\n",
        "for idx, (xs, label) in enumerate(zip(critical_xs, labels)):\n",
        "    xs_data = df_timeseries[df_timeseries['node_id'] == xs].sort_values('datetime')\n",
        "    ax.plot(xs_data['datetime'], xs_data['velocity'],\n",
        "            marker='o', linewidth=2, markersize=5,\n",
        "            color=colors[idx % len(colors)],\n",
        "            label=f'{label} (Sta {xs:.1f})', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Date / Time', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Velocity (ft/s)', fontsize=13, fontweight='bold')\n",
        "ax.set_title('Velocity Hydrographs at Key Cross Sections', \n",
        "              fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n\u2713 Created velocity hydrographs for {len(critical_xs)} key locations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "## Complete RasControl API\n",
        "\n",
        "```python\n",
        "# Initialize with version (flexible formats)\n",
        "init_ras_project(path, \"4.1\")  # or \"41\", \"66\", \"5.0.6\", \"506\", etc.\n",
        "\n",
        "# Run plans (auto-sets as current, waits for completion)\n",
        "# NOTE: run_plan() now checks if plan is current before running\n",
        "# If results are up-to-date, it skips computation (faster workflow)\n",
        "success, msgs = RasControl.run_plan(\"02\")\n",
        "\n",
        "# To force recomputation regardless of current status:\n",
        "success, msgs = RasControl.run_plan(\"02\", force_recompute=True)\n",
        "\n",
        "# Extract steady (auto-sets as current)\n",
        "df_steady = RasControl.get_steady_results(\"02\")\n",
        "\n",
        "# Extract unsteady (auto-sets as current, includes Max WS)\n",
        "df_unsteady = RasControl.get_unsteady_results(\"01\")\n",
        "\n",
        "# Filter for time series plotting\n",
        "df_timeseries = df_unsteady[df_unsteady['time_string'] != 'Max WS']\n",
        "max_wse = df_unsteady[df_unsteady['time_string'] == 'Max WS']['wsel'].iloc[0]\n",
        "```\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- \u2705 Plan numbers (not file paths)\n",
        "- \u2705 Auto-sets current plan\n",
        "- \u2705 Blocks until completion\n",
        "- \u2705 Steady AND unsteady\n",
        "- \u2705 All versions 3.0-6.7\n",
        "- \u2705 Flexible version formats\n",
        "- \u2705 Includes Max WS data\n",
        "- \u2705 Multi-version comparison (optional)\n",
        "\n",
        "## What Was Demonstrated\n",
        "\n",
        "1. **Steady workflow** - Plan 02 extraction and plotting\n",
        "2. **Unsteady workflow** - Plan 01 time series with Max WS reference\n",
        "3. **Max WS handling** - Understanding and visualizing peak values\n",
        "4. **Multi-version comparison** - Optional cells for version validation\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Apply to your legacy HEC-RAS models\n",
        "- Run multi-version comparison for migration validation\n",
        "- For HEC-RAS 6.0+: Use HDF methods for better performance\n",
        "  - `19_steady_flow_analysis.ipynb`\n",
        "  - `10_1d_hdf_data_extraction.ipynb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What This Creates\n",
        "\n",
        "Running the multi-version comparison cells will:\n",
        "\n",
        "**New Plans in Project:**\n",
        "- `02_41`, `02_506`, `02_63`, `02_66` (steady)\n",
        "- `01_41`, `01_506`, `01_63`, `01_66` (unsteady)\n",
        "\n",
        "**CSV Files in working/:**\n",
        "- `steady_v41.csv`, `steady_v506.csv`, `steady_v63.csv`, `steady_v66.csv`\n",
        "- `unsteady_v41.csv`, `unsteady_v506.csv`, `unsteady_v63.csv`, `unsteady_v66.csv`\n",
        "\n",
        "**Results:**\n",
        "- All plans remain in project for further analysis\n",
        "- CSV files for external comparison\n",
        "- Plots showing version differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:08:06.216949Z",
          "iopub.status.busy": "2025-11-17T19:08:06.216484Z",
          "iopub.status.idle": "2025-11-17T19:17:53.446182Z",
          "shell.execute_reply": "2025-11-17T19:17:53.445593Z"
        }
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Multi-version unsteady comparison\n",
        "# Uncomment to run (may take 1-2 Hr)\n",
        "\n",
        "from ras_commander import RasPlan\n",
        "\n",
        "# Step 1: Update Plan 01 output intervals for more detail\n",
        "print(\"Step 1: Updating Plan 01 intervals...\")\n",
        "init_ras_project(project_path, \"6.6\")  # Use latest for modification\n",
        "\n",
        "# Update intervals: Output=15MIN, Mapping=15MIN\n",
        "RasPlan.update_plan_intervals(\"01\", \n",
        "                              output_interval=\"10MIN\",\n",
        "                              mapping_interval=\"10MIN\")\n",
        "print(\"  \u2713 Output Interval: 1HOUR \u2192 6MIN\")\n",
        "print(\"  \u2713 Mapping Interval: 1HOUR \u2192 6MIN\\n\")\n",
        "\n",
        "# Step 2: Run across versions\n",
        "# All versions with actual COM interfaces\n",
        "test_versions = [\n",
        "    (\"4.1\", \"41\"),       # HEC-RAS 4.1     \u2192 RAS41.HECRASController\n",
        "#    (\"5.0.1\", \"501\"),    # HEC-RAS 5.0.1   \u2192 RAS501.HECRASController  >> FREEZES, SKIP, LIKELY ISSUE WITH HECRASCONTROLLER\n",
        "#    (\"5.0.3\", \"503\"),    # HEC-RAS 5.0.3   \u2192 RAS503.HECRASController\n",
        "    (\"5.0.4\", \"504\"),    # HEC-RAS 5.0.4   \u2192 RAS504.HECRASController\n",
        "    (\"5.0.6\", \"506\"),    # HEC-RAS 5.0.6   \u2192 RAS506.HECRASController\n",
        "    (\"6.3.1\", \"631\"),    # HEC-RAS 6.3.1   \u2192 RAS631.HECRASController\n",
        "    (\"6.6\", \"66\"),       # HEC-RAS 6.6     \u2192 RAS66.HECRASController\n",
        "]\n",
        "\n",
        "unsteady_results = {}\n",
        "max_ws_data = {}  # Store Max WS separately\n",
        "\n",
        "print(\"=== MULTI-VERSION UNSTEADY COMPARISON ===\\n\")\n",
        "\n",
        "for version_name, version_code in test_versions:\n",
        "    print(f\"Processing HEC-RAS {version_name}...\")\n",
        "    \n",
        "    # Clone Plan 01 for this version\n",
        "    new_plan = RasPlan.clone_plan(\"01\",\n",
        "                      new_shortid=f\"Unsteady_{version_code}\",\n",
        "                      new_title=f\"Unsteady - v{version_name}\")\n",
        "    print(f\"  Cloned to Plan {new_plan}\")\n",
        "    \n",
        "    # Re-initialize with this version\n",
        "    init_ras_project(project_path, version_name)\n",
        "    \n",
        "    # Run the plan (this will take several minutes!)\n",
        "    print(f\"  Running Plan {new_plan} (may take 5-10 min)...\")\n",
        "    # NOTE: Using force_recompute=True for fresh cloned plans to ensure computation\n",
        "    # (Default behavior now checks if plan is current and skips if already computed)\n",
        "    #success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "    success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "    print(success, msgs)\n",
        "    if success:\n",
        "        # Extract results (limit to 20 timesteps for comparison)\n",
        "        df = RasControl.get_unsteady_results(new_plan)\n",
        "        \n",
        "        # Separate Max WS from timeseries\n",
        "        max_ws_data[version_name] = df[df['time_string'] == 'Max WS'].copy()\n",
        "        unsteady_results[version_name] = df[df['time_string'] != 'Max WS'].copy()\n",
        "        \n",
        "        # Save CSV\n",
        "        csv_path = Path(f\"working/unsteady_v{version_code}.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"  \u2713 Extracted {len(df)} rows -> {csv_path}\")\n",
        "    else:\n",
        "        print(f\"  \u2717 Failed\")\n",
        "    \n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:17:53.448669Z",
          "iopub.status.busy": "2025-11-17T19:17:53.448393Z",
          "iopub.status.idle": "2025-11-17T19:18:03.889215Z",
          "shell.execute_reply": "2025-11-17T19:18:03.888522Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot comparison at multiple cross sections (every 5th station)\n",
        "if unsteady_results:\n",
        "    # Gather all station IDs across versions\n",
        "    xs_set = set()\n",
        "    for df in unsteady_results.values():\n",
        "        try:\n",
        "            xs_set.update(df['node_id'].astype(float).unique().tolist())\n",
        "        except Exception:\n",
        "            xs_set.update(df['node_id'].unique().tolist())\n",
        "\n",
        "    all_xs = sorted(xs_set, reverse=True)  # upstream -> downstream\n",
        "    if not all_xs:\n",
        "        print(\"No cross section data found in unsteady_results\")\n",
        "    else:\n",
        "        # Select every 5th cross section for plotting (adjust step as needed)\n",
        "        step = 5\n",
        "        selected_xs = all_xs[::step] if len(all_xs) > step else all_xs\n",
        "        print(f\"Plotting {len(selected_xs)} stations (every {step}th of {len(all_xs)} total)\")\n",
        "\n",
        "        for xs_id in selected_xs:\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 6))\n",
        "\n",
        "            # Plot WSE time series for each version at this station\n",
        "            for version, df in unsteady_results.items():\n",
        "                # FIX: Convert node_id to float for comparison\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id].sort_values('time_index')\n",
        "                if len(xs_data):\n",
        "                    ax1.plot(xs_data['time_index'], xs_data['wsel'],\n",
        "                             marker='o', label=f'v{version}', alpha=0.8)\n",
        "\n",
        "            # Add Max WS reference lines (if available) for this station\n",
        "            for version, df in max_ws_data.items():\n",
        "                try:\n",
        "                    df_float = df.copy()\n",
        "                    df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                    max_row = df_float[df_float['node_id'] == xs_id]\n",
        "                    if len(max_row):\n",
        "                        max_wse = float(max_row['wsel'].iloc[0])\n",
        "                        ax1.axhline(max_wse, linestyle='--', alpha=0.5, label=f'MaxWS v{version}')\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "            ax1.set_xlabel('Time Index', fontsize=11)\n",
        "            ax1.set_ylabel('Water Surface Elevation (ft)', fontsize=11)\n",
        "            ax1.set_title(f'WSE Time Series at {xs_id} - Version Comparison',\n",
        "                          fontsize=13, fontweight='bold')\n",
        "            ax1.legend(fontsize=8)\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Plot Flow time series for each version at this station\n",
        "            for version, df in unsteady_results.items():\n",
        "                # FIX: Convert node_id to float for comparison\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id].sort_values('time_index')\n",
        "                if len(xs_data):\n",
        "                    ax2.plot(xs_data['time_index'], xs_data['flow'],\n",
        "                             marker='o', label=f'v{version}', alpha=0.8)\n",
        "\n",
        "            ax2.set_xlabel('Time Index', fontsize=11)\n",
        "            ax2.set_ylabel('Flow (cfs)', fontsize=11)\n",
        "            ax2.set_title(f'Flow Time Series at {xs_id} - Version Comparison',\n",
        "                          fontsize=13, fontweight='bold')\n",
        "            ax2.legend(fontsize=8)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Basic per-station stats\n",
        "            print(f\"\\nStation {xs_id}:\")\n",
        "            for version, df in unsteady_results.items():\n",
        "                df_float = df.copy()\n",
        "                df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                xs_data = df_float[df_float['node_id'] == xs_id]\n",
        "                if len(xs_data):\n",
        "                    print(f\"  v{version}: timesteps={len(xs_data)}, max_wse={xs_data['wsel'].max():.2f} ft\")\n",
        "                else:\n",
        "                    print(f\"  v{version}: no data\")\n",
        "\n",
        "        # Summary of Max WS across versions for the first selected station (if any)\n",
        "        if selected_xs:\n",
        "            summary_xs = selected_xs[0]\n",
        "            print(f\"\\nMax WSE by version at station {summary_xs}:\")\n",
        "            for version, df in max_ws_data.items():\n",
        "                try:\n",
        "                    df_float = df.copy()\n",
        "                    df_float['node_id'] = df_float['node_id'].astype(float)\n",
        "                    max_row = df_float[df_float['node_id'] == summary_xs]\n",
        "                    if len(max_row):\n",
        "                        max_wse = float(max_row['wsel'].iloc[0])\n",
        "                        print(f\"  v{version}: {max_wse:.2f} ft\")\n",
        "                    else:\n",
        "                        print(f\"  v{version}: N/A\")\n",
        "                except Exception:\n",
        "                    print(f\"  v{version}: N/A\")\n",
        "\n",
        "else:\n",
        "    print(\"Uncomment code above to run multi-version comparison\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T19:18:03.891945Z",
          "iopub.status.busy": "2025-11-17T19:18:03.891491Z",
          "iopub.status.idle": "2025-11-17T19:18:33.587488Z",
          "shell.execute_reply": "2025-11-17T19:18:33.586876Z"
        }
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Multi-version steady state comparison\n",
        "\n",
        "from ras_commander import RasPlan\n",
        "\n",
        "# Versions to test - all versions with actual COM interfaces\n",
        "test_versions = [\n",
        "  #  (\"4.1\", \"41\"),       # HEC-RAS 4.1     \u2192 RAS41.HECRASController\n",
        "  #  (\"5.0.1\", \"501\"),    # HEC-RAS 5.0.1   \u2192 RAS501.HECRASController\n",
        "  #  (\"5.0.3\", \"503\"),    # HEC-RAS 5.0.3   \u2192 RAS503.HECRASController\n",
        "    (\"5.0.4\", \"504\"),    # HEC-RAS 5.0.4   \u2192 RAS504.HECRASController\n",
        "    (\"5.0.6\", \"506\"),    # HEC-RAS 5.0.6   \u2192 RAS506.HECRASController\n",
        "    (\"6.3.1\", \"631\"),    # HEC-RAS 6.3.1   \u2192 RAS631.HECRASController\n",
        "    (\"6.6\", \"66\"),       # HEC-RAS 6.6     \u2192 RAS66.HECRASController\n",
        "]\n",
        "\n",
        "steady_results = {}\n",
        "\n",
        "print(\"=== MULTI-VERSION STEADY STATE COMPARISON ===\\n\")\n",
        "\n",
        "for version_name, version_code in test_versions:\n",
        "    print(f\"Processing HEC-RAS {version_name}...\")\n",
        "    \n",
        "    # Clone Plan 02 for this version\n",
        "    new_plan = RasPlan.clone_plan(\"02\",\n",
        "                      new_shortid=f\"Steady_{version_code}\",\n",
        "                      new_title=f\"Steady - v{version_name}\")\n",
        "    print(f\"  Cloned to Plan {new_plan}\")\n",
        "    \n",
        "    # Re-initialize with this version\n",
        "    init_ras_project(project_path, version_name)\n",
        "    \n",
        "    # Run the plan using ras-commander's compute_plan() instead of RasControl.run_plan\n",
        "    print(f\"  Running Plan {new_plan} with 2 cores...\")\n",
        "    try:\n",
        "        # Use direct command line execution, preferred over RasControl.run_plan\n",
        "        #RasCmdr.compute_plan(new_plan, clear_geompre=True, num_cores=2)\n",
        "        success, msgs = RasControl.run_plan(new_plan, force_recompute=True)\n",
        "        print(success, msgs)\n",
        "        # Extract results\n",
        "        df = RasControl.get_steady_results(new_plan)\n",
        "        steady_results[version_name] = df\n",
        "\n",
        "        # Save CSV\n",
        "        csv_path = Path(f\"working/steady_v{version_code}.csv\")\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"  \u2713 Extracted {len(df)} rows -> {csv_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  \u2717 Failed: {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# Plot comparison - first profile from each version\n",
        "if steady_results:\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    \n",
        "    for version, df in steady_results.items():\n",
        "        first_prof = df[df['profile'] == df['profile'].iloc[0]]\n",
        "        ax.plot(range(len(first_prof)), first_prof['wsel'], \n",
        "                marker='o', label=f'v{version}', alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Cross Section Index', fontsize=12)\n",
        "    ax.set_ylabel('Water Surface Elevation (ft)', fontsize=12)\n",
        "    ax.set_title('Steady State Profile - Multi-Version Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n\u2713 Compared {len(steady_results)} versions\")\n",
        "\n",
        "else:\n",
        "    print(\"Uncomment code above to run multi-version comparison\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\18_breach_results_extraction.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:16.358451Z",
          "iopub.status.busy": "2025-11-17T17:45:16.358126Z",
          "iopub.status.idle": "2025-11-17T17:45:18.126139Z",
          "shell.execute_reply": "2025-11-17T17:45:18.125568Z"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dam Breach Results Extraction and Sensitivity Analysis\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. **Extracting baseline breach results** from HDF files\n",
        "2. **Reading breach parameters** from plan files\n",
        "3. **Modifying parameters iteratively** (one parameter at a time)\n",
        "4. **Comparing results** across different scenarios\n",
        "5. **Visualizing sensitivity** to parameter changes\n",
        "\n",
        "**Project:** BaldEagleCrkMulti2D (HEC-RAS Example)  \n",
        "**Baseline Plan:** 02  \n",
        "**Version:** 6.6\n",
        "\n",
        "**Workflow:**\n",
        "- Extract baseline results\n",
        "- Clone plan and modify one parameter\n",
        "- Re-extract results and compare\n",
        "- Repeat for multiple parameters\n",
        "- Plot all scenarios together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.129879Z",
          "iopub.status.busy": "2025-11-17T17:45:18.129416Z",
          "iopub.status.idle": "2025-11-17T17:45:18.132725Z",
          "shell.execute_reply": "2025-11-17T17:45:18.132205Z"
        }
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.134875Z",
          "iopub.status.busy": "2025-11-17T17:45:18.134619Z",
          "iopub.status.idle": "2025-11-17T17:45:18.137708Z",
          "shell.execute_reply": "2025-11-17T17:45:18.137058Z"
        }
      },
      "outputs": [],
      "source": [
        "#! pip uninstall -y ras-commander"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.140385Z",
          "iopub.status.busy": "2025-11-17T17:45:18.140052Z",
          "iopub.status.idle": "2025-11-17T17:45:18.144723Z",
          "shell.execute_reply": "2025-11-17T17:45:18.144160Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.147113Z",
          "iopub.status.busy": "2025-11-17T17:45:18.146826Z",
          "iopub.status.idle": "2025-11-17T17:45:18.151896Z",
          "shell.execute_reply": "2025-11-17T17:45:18.151319Z"
        }
      },
      "outputs": [],
      "source": [
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "    \n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Now try to import again\n",
        "from ras_commander import *\n",
        "\n",
        "# Verify we're loading from the local copy\n",
        "import ras_commander\n",
        "local_path = Path(ras_commander.__file__).parent.parent\n",
        "print(f\"ras-commander loaded from: {local_path}\")\n",
        "print(f\"Expected local path: {rascmdr_directory}\")\n",
        "print(f\"Successfully using local copy: {local_path == rascmdr_directory}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Extract and Initialize Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.156737Z",
          "iopub.status.busy": "2025-11-17T17:45:18.155957Z",
          "iopub.status.idle": "2025-11-17T17:45:18.160513Z",
          "shell.execute_reply": "2025-11-17T17:45:18.159539Z"
        }
      },
      "outputs": [],
      "source": [
        "# Use existing folder if present, else extract\n",
        "from pathlib import Path\n",
        "example_project_folder = Path(\"c:/GH/ras-commander/examples/example_projects/BaldEagleCrkMulti2D\")\n",
        "if example_project_folder.exists():\n",
        "    project_path = example_project_folder\n",
        "    print(f\"Project folder already exists: {project_path}\")\n",
        "else:\n",
        "    project_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
        "    print(f\"Extracted project to: {project_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.168543Z",
          "iopub.status.busy": "2025-11-17T17:45:18.168236Z",
          "iopub.status.idle": "2025-11-17T17:45:18.259026Z",
          "shell.execute_reply": "2025-11-17T17:45:18.257370Z"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize the project\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "print(f\"\\nInitialized project: {ras.project_name}\")\n",
        "print(f\"\\nAvailable plans:\")\n",
        "ras.plan_df\n",
        "\n",
        "# This is the SA to 2D Dam Break Run\n",
        "template_plan = \"19\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RasResultsBreach - Breach Results (HDF Files)\n",
        "**Use for:** Extracting breach simulation RESULTS from HDF output files (.p##.hdf)\n",
        "\n",
        "```python\n",
        "from ras_commander import HdfResultsBreach\n",
        "\n",
        "# Extract complete time series (flow, stage, breach geometry evolution)\n",
        "timeseries = HdfResultsBreach.get_breach_timeseries(\"02\", \"Dam\")\n",
        "\n",
        "# Get summary statistics (peaks, timing, final geometry)\n",
        "summary = HdfResultsBreach.get_breach_summary(\"02\")\n",
        "\n",
        "# Get breach-specific variables (width, depth, slopes over time)\n",
        "breach_vars = HdfResultsBreach.get_breaching_variables(\"02\", \"Dam\")\n",
        "```\n",
        "\n",
        "**Key Points:**\n",
        "- \u2705 Extracts results AFTER HEC-RAS has run\n",
        "- \u2705 Works with plan numbers or HDF file paths\n",
        "- \u2705 Requires .p##.hdf file to exist (created by HEC-RAS)\n",
        "- \u26a0\ufe0f Structure names in HDF may include prefixes (e.g., \"BaldEagleCr Dam\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. BASELINE: Extract Existing Results from Plan 02\n",
        "\n",
        "First, extract and analyze the baseline breach behavior from the existing Plan 02 results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Important Note: HDF Results Files\n",
        "\n",
        "**This example project may not include pre-computed HDF results** (.p02.hdf files). These files are generated when HEC-RAS runs a simulation.\n",
        "\n",
        "**If you encounter \"HDF file not found\" errors:**\n",
        "1. Option A: Run HEC-RAS simulation for Plan 02 first\n",
        "2. Option B: Use the RasCmdr class to run simulation from Python (see cell below)\n",
        "3. Option C: Use a different project with existing results (e.g., Scott County)\n",
        "\n",
        "**The notebook will gracefully handle missing results and still demonstrate parameter modification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.262887Z",
          "iopub.status.busy": "2025-11-17T17:45:18.262559Z",
          "iopub.status.idle": "2025-11-17T17:45:18.277939Z",
          "shell.execute_reply": "2025-11-17T17:45:18.277356Z"
        }
      },
      "outputs": [],
      "source": [
        "# Initialize variables to None (prevents NameError in later cells)\n",
        "target_structure = None\n",
        "baseline_ts = pd.DataFrame()\n",
        "baseline_summary = pd.DataFrame()\n",
        "baseline_params = None\n",
        "baseline_geom = []\n",
        "scenarios = {}\n",
        "summaries = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Identify Breach Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.280814Z",
          "iopub.status.busy": "2025-11-17T17:45:18.280497Z",
          "iopub.status.idle": "2025-11-17T17:45:18.287087Z",
          "shell.execute_reply": "2025-11-17T17:45:18.286522Z"
        }
      },
      "outputs": [],
      "source": [
        "# List breach structures from PLAN FILE (for parameter operations)\n",
        "# This ensures structure names match between listing and read_breach_block()\n",
        "try:\n",
        "    breach_structures_list = RasBreach.list_breach_structures_plan(template_plan)\n",
        "    \n",
        "    print(\"Breach Structures in Plan File:\")\n",
        "    for struct in breach_structures_list:\n",
        "        if struct['structure']:  # Filter empty names\n",
        "            status = \"ACTIVE\" if struct['is_active'] else \"INACTIVE\"  \n",
        "            location = f\"{struct['river']}/{struct['reach']}/RS {struct['station']}\" if struct['river'] else \"No location\"\n",
        "            print(f\"  - {struct['structure']}: {status} ({location})\")\n",
        "    \n",
        "    # Get active structure names for parameter operations\n",
        "    breach_structures = [s['structure'] for s in breach_structures_list \n",
        "                        if s['structure'] and s['is_active']]\n",
        "    \n",
        "    if breach_structures:\n",
        "        target_structure = breach_structures[0]\n",
        "        print(f\"\\nTarget structure for analysis: {target_structure}\")\n",
        "        print(f\"  This name will work with RasBreach.read_breach_block()\")\n",
        "    else:\n",
        "        print(\"\\nWARNING: No active breach structures found!\")\n",
        "        target_structure = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error listing breach structures: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    target_structure = None\n",
        "    breach_structures = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if target_structure:\n",
        "    try:\n",
        "        # Extract complete breach time series from HDF results\n",
        "        baseline_ts = HdfResultsBreach.get_breach_timeseries(\"02\", target_structure)\n",
        "        \n",
        "        print(f\"Baseline Time Series Extracted: {baseline_ts.shape}\")\n",
        "        print(f\"\\nColumns: {list(baseline_ts.columns)}\")\n",
        "        print(f\"\\nFirst few timesteps:\")\n",
        "        print(baseline_ts.head())\n",
        "        \n",
        "        # Get summary statistics from HDF results\n",
        "        baseline_summary = HdfResultsBreach.get_breach_summary(\"02\", target_structure)\n",
        "        print(f\"\\nBaseline Summary Statistics:\")\n",
        "        print(baseline_summary.to_string(index=False))\n",
        "        \n",
        "        # Store baseline for later comparison\n",
        "        scenarios = {\n",
        "            'Baseline (Plan 02)': baseline_ts.copy()\n",
        "        }\n",
        "        summaries = {\n",
        "            'Baseline (Plan 02)': baseline_summary.copy()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Could not extract baseline time series: {e}\")\n",
        "        print(\"Continuing with parameter analysis only...\")\n",
        "        baseline_ts = pd.DataFrame()\n",
        "        baseline_summary = pd.DataFrame()\n",
        "        scenarios = {}\n",
        "        summaries = {}\n",
        "else:\n",
        "    print(\"Skipping baseline extraction - no breach structure available\")\n",
        "    scenarios = {}\n",
        "    summaries = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.290339Z",
          "iopub.status.busy": "2025-11-17T17:45:18.290075Z",
          "iopub.status.idle": "2025-11-17T17:45:18.296345Z",
          "shell.execute_reply": "2025-11-17T17:45:18.295805Z"
        }
      },
      "outputs": [],
      "source": [
        "template_plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.298966Z",
          "iopub.status.busy": "2025-11-17T17:45:18.298690Z",
          "iopub.status.idle": "2025-11-17T17:45:18.322474Z",
          "shell.execute_reply": "2025-11-17T17:45:18.321780Z"
        }
      },
      "outputs": [],
      "source": [
        "# Read current parameters\n",
        "params = RasBreach.read_breach_block(template_plan, \"Dam\")\n",
        "geom = [x.strip() for x in params['values']['Breach Geom'].split(',')]\n",
        "\n",
        "# Update Final Bottom Elevation (index 2)\n",
        "geom[2] = 605  # New elevation in feet\n",
        "\n",
        "# Write back\n",
        "RasBreach.update_breach_block(template_plan, \"Dam\", geom_values=geom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.325003Z",
          "iopub.status.busy": "2025-11-17T17:45:18.324748Z",
          "iopub.status.idle": "2025-11-17T17:45:18.334685Z",
          "shell.execute_reply": "2025-11-17T17:45:18.333910Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure:\n",
        "    try:\n",
        "        # Read breach parameters from plan file\n",
        "        baseline_params = RasBreach.read_breach_block(\"02\", target_structure)\n",
        "        \n",
        "        print(f\"Baseline Parameters for {target_structure}:\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nActivation: {baseline_params['is_active']}\")\n",
        "        print(f\"\\nKey Parameter Values:\")\n",
        "        for key in ['Breach Method', 'Breach Geom', 'Breach Start', 'Breach Progression']:\n",
        "            if key in baseline_params['values']:\n",
        "                print(f\"  {key}: {baseline_params['values'][key]}\")\n",
        "        \n",
        "        # Parse geometry values for modification\n",
        "        geom_str = baseline_params['values'].get('Breach Geom', '')\n",
        "        baseline_geom = [x.strip() for x in geom_str.split(',') if x.strip()]\n",
        "        print(f\"\\nBaseline Geometry (parsed): {baseline_geom}\")\n",
        "        \n",
        "        # Explain Breach Geom field structure\n",
        "        if len(baseline_geom) >= 10:\n",
        "            print(\"\\nBreach Geom Field Structure (CSV, 10 fields):\")\n",
        "            print(f\"  [0] Centerline/Station: {baseline_geom[0]} ft\")\n",
        "            print(f\"  [1] Initial Bottom Width: {baseline_geom[1]} ft\")\n",
        "            print(f\"  [2] Final Bottom Elevation: {baseline_geom[2]} ft  <-- KEY PARAMETER\")\n",
        "            print(f\"  [3] Left Side Slope: {baseline_geom[3]} (H:V)\")\n",
        "            print(f\"  [4] Right Side Slope: {baseline_geom[4]} (H:V)\")\n",
        "            print(f\"  [5] Active Flag: {baseline_geom[5]}\")\n",
        "            print(f\"  [6] Weir Coefficient: {baseline_geom[6]}\")\n",
        "            print(f\"  [7] Top Elevation: {baseline_geom[7]} ft\")\n",
        "            print(f\"  [8] Formation Method: {baseline_geom[8]} (1=Time, 2=Trigger)\")\n",
        "            print(f\"  [9] Formation Time/Threshold: {baseline_geom[9]} hrs or ft\")\n",
        "            \n",
        "            print(\"\\n--- Example: Update Final Bottom Elevation ---\")\n",
        "            print(f\"Current value: {baseline_geom[2]} ft\")\n",
        "            print(\"To change to 605 ft:\")\n",
        "            print(\"  new_geom = baseline_geom.copy()\")\n",
        "            print(\"  new_geom[2] = 605\")\n",
        "            print('  RasBreach.update_breach_block(\"template_plan\", \"Dam\", geom_values=new_geom)')\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Could not read baseline parameters: {e}\")\n",
        "        baseline_params = None\n",
        "        baseline_geom = []\n",
        "else:\n",
        "    print(\"Skipping parameter reading - no breach structure available\")\n",
        "    baseline_params = None\n",
        "    baseline_geom = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.337998Z",
          "iopub.status.busy": "2025-11-17T17:45:18.337735Z",
          "iopub.status.idle": "2025-11-17T17:45:18.345597Z",
          "shell.execute_reply": "2025-11-17T17:45:18.345107Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure:\n",
        "    try:\n",
        "        # Extract complete breach time series from HDF results\n",
        "        baseline_ts = HdfResultsBreach.get_breach_timeseries(template_plan, target_structure)\n",
        "        \n",
        "        print(f\"Baseline Time Series Extracted: {baseline_ts.shape}\")\n",
        "        print(f\"\\nColumns: {list(baseline_ts.columns)}\")\n",
        "        print(f\"\\nFirst few timesteps:\")\n",
        "        print(baseline_ts.head())\n",
        "        \n",
        "        # Get summary statistics from HDF results\n",
        "        baseline_summary = HdfResultsBreach.get_breach_summary(template_plan, target_structure)\n",
        "        print(f\"\\nBaseline Summary Statistics:\")\n",
        "        print(baseline_summary.to_string(index=False))\n",
        "        \n",
        "        # Store baseline for later comparison\n",
        "        scenarios = {\n",
        "            f'Baseline (Plan {template_plan})': baseline_ts.copy()\n",
        "        }\n",
        "        summaries = {\n",
        "            f'Baseline (Plan {template_plan})': baseline_summary.copy()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Could not extract baseline time series: {e}\")\n",
        "        print(\"Continuing with parameter analysis only...\")\n",
        "        baseline_ts = pd.DataFrame()\n",
        "        baseline_summary = pd.DataFrame()\n",
        "        scenarios = {}\n",
        "        summaries = {}\n",
        "else:\n",
        "    print(\"Skipping baseline extraction - no breach structure available\")\n",
        "    scenarios = {}\n",
        "    summaries = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.348026Z",
          "iopub.status.busy": "2025-11-17T17:45:18.347730Z",
          "iopub.status.idle": "2025-11-17T17:45:18.354849Z",
          "shell.execute_reply": "2025-11-17T17:45:18.354178Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure:\n",
        "    try:\n",
        "        # Extract complete breach time series\n",
        "        baseline_ts = HdfResultsBreach.get_breach_timeseries(template_plan, target_structure)\n",
        "        \n",
        "        print(f\"Baseline Time Series Extracted: {baseline_ts.shape}\")\n",
        "        print(f\"\\nColumns: {list(baseline_ts.columns)}\")\n",
        "        print(f\"\\nFirst few timesteps:\")\n",
        "        print(baseline_ts.head())\n",
        "        \n",
        "        # Get summary statistics\n",
        "        baseline_summary = HdfResultsBreach.get_breach_summary(template_plan, target_structure)\n",
        "        print(f\"\\nBaseline Summary Statistics:\")\n",
        "        print(baseline_summary.to_string(index=False))\n",
        "        \n",
        "        # Store baseline for later comparison\n",
        "        scenarios = {\n",
        "            f'Baseline (Plan {template_plan})': baseline_ts.copy()\n",
        "        }\n",
        "        summaries = {\n",
        "            f'Baseline (Plan {template_plan})': baseline_summary.copy()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Could not extract baseline time series: {e}\")\n",
        "        print(\"Continuing with parameter analysis only...\")\n",
        "        baseline_ts = pd.DataFrame()\n",
        "        baseline_summary = pd.DataFrame()\n",
        "        scenarios = {}\n",
        "        summaries = {}\n",
        "else:\n",
        "    print(\"Skipping baseline extraction - no breach structure available\")\n",
        "    scenarios = {}\n",
        "    summaries = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Read Baseline Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.357926Z",
          "iopub.status.busy": "2025-11-17T17:45:18.357649Z",
          "iopub.status.idle": "2025-11-17T17:45:18.363862Z",
          "shell.execute_reply": "2025-11-17T17:45:18.363259Z"
        }
      },
      "outputs": [],
      "source": [
        "# List breach structures from plan file (for parameter operations)\n",
        "try:\n",
        "    breach_structures_list = RasBreach.list_breach_structures_plan(template_plan)\n",
        "\n",
        "    print(\"Breach Structures in Plan File:\")\n",
        "    for struct in breach_structures_list:\n",
        "        if struct['structure']:  # Filter empty names\n",
        "            status = \"ACTIVE\" if struct['is_active'] else \"INACTIVE\"\n",
        "            print(f\"  - {struct['structure']}: {status}\")\n",
        "\n",
        "    # Get active structure names\n",
        "    breach_structures = [s['structure'] for s in breach_structures_list\n",
        "                        if s['structure'] and s['is_active']]\n",
        "\n",
        "    if breach_structures:\n",
        "        target_structure = breach_structures[0]\n",
        "        print(f\"\\nTarget structure for analysis: {target_structure}\")\n",
        "    else:\n",
        "        target_structure = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error listing breach structures: {e}\")\n",
        "    target_structure = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Easy Parameter Modification with set_breach_geom()\n",
        "\n",
        "**NEW FUNCTION:** `RasBreach.set_breach_geom()` provides a clean interface for modifying individual breach parameters without manually parsing/reconstructing the CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.367573Z",
          "iopub.status.busy": "2025-11-17T17:45:18.367159Z",
          "iopub.status.idle": "2025-11-17T17:45:18.372510Z",
          "shell.execute_reply": "2025-11-17T17:45:18.371822Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Update just Final Bottom Elevation (most common modification)\n",
        "if target_structure:\n",
        "    print(\"Example: Update Final Bottom Elevation to 605 ft\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nSimple approach using set_breach_geom():\")\n",
        "    print(\"  RasBreach.set_breach_geom('template_plan', 'Dam',\")\n",
        "    print(\"                            final_bottom_elev=605)\")\n",
        "    print(\"\\nThis automatically:\")\n",
        "    print(\"  1. Reads current Breach Geom values\")\n",
        "    print(\"  2. Updates ONLY the final_bottom_elev field (index 2)\")\n",
        "    print(\"  3. Preserves all other parameters\")\n",
        "    print(\"  4. Writes back to plan file with backup\")\n",
        "    \n",
        "    print(\"\\n\\nOther common modifications:\")\n",
        "    print(\"\\n# Increase breach width by 50%\")\n",
        "    print(\"  current_width = 200  # Read from baseline_params\")\n",
        "    print(\"  RasBreach.set_breach_geom('template_plan', 'Dam',\")\n",
        "    print(\"                            initial_width=current_width * 1.5)\")\n",
        "    \n",
        "    print(\"\\n# Change formation time\")\n",
        "    print(\"  RasBreach.set_breach_geom('template_plan', 'Dam',\")\n",
        "    print(\"                            formation_time=3.5)\")\n",
        "    \n",
        "    print(\"\\n# Update multiple parameters at once\")\n",
        "    print(\"  RasBreach.set_breach_geom('template_plan', 'Dam',\")\n",
        "    print(\"                            final_bottom_elev=605,\")\n",
        "    print(\"                            initial_width=250,\")\n",
        "    print(\"                            formation_time=3.0)\")\n",
        "else:\n",
        "    print(\"No target structure available for examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.375870Z",
          "iopub.status.busy": "2025-11-17T17:45:18.375429Z",
          "iopub.status.idle": "2025-11-17T17:45:18.381942Z",
          "shell.execute_reply": "2025-11-17T17:45:18.381335Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure:\n",
        "    try:\n",
        "        # Read breach parameters from plan file\n",
        "        baseline_params = RasBreach.read_breach_block(template_plan, target_structure)\n",
        "        \n",
        "        print(f\"Baseline Parameters for {target_structure}:\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nActivation: {baseline_params['is_active']}\")\n",
        "        print(f\"\\nKey Parameter Values:\")\n",
        "        for key in ['Breach Method', 'Breach Geom', 'Breach Start', 'Breach Progression']:\n",
        "            if key in baseline_params['values']:\n",
        "                print(f\"  {key}: {baseline_params['values'][key]}\")\n",
        "        \n",
        "        # Parse geometry values for modification\n",
        "        geom_str = baseline_params['values'].get('Breach Geom', '')\n",
        "        baseline_geom = [x.strip() for x in geom_str.split(',') if x.strip()]\n",
        "        print(f\"\\nBaseline Geometry (parsed): {baseline_geom}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read baseline parameters: {e}\")\n",
        "        baseline_params = None\n",
        "        baseline_geom = []\n",
        "else:\n",
        "    print(\"Skipping parameter reading - no breach structure available\")\n",
        "    baseline_params = None\n",
        "    baseline_geom = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SCENARIO ANALYSIS: Modify Parameters and Compare Results\n",
        "\n",
        "Now we'll create multiple scenarios by modifying breach parameters one at a time.\n",
        "\n",
        "**Workflow for each scenario:**\n",
        "1. Clone Plan 02 to a new plan number\n",
        "2. Modify ONE parameter in the cloned plan\n",
        "3. **[User must run HEC-RAS simulation]**\n",
        "4. Extract results from the new plan\n",
        "5. Compare with baseline\n",
        "\n",
        "**Note:** This notebook demonstrates steps 1-2 and 4-5. You must run HEC-RAS (step 3) separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 1: Increase Breach Width by 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.384718Z",
          "iopub.status.busy": "2025-11-17T17:45:18.384460Z",
          "iopub.status.idle": "2025-11-17T17:45:18.487782Z",
          "shell.execute_reply": "2025-11-17T17:45:18.487130Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure and baseline_geom and len(baseline_geom) >= 2:\n",
        "    # Clone plan\n",
        "    scenario_1_plan = RasPlan.clone_plan(template_plan, \"Scenario 1: +50% Width\")\n",
        "    \n",
        "    # Modify breach width (assuming index 1 is width)\n",
        "    try:\n",
        "        new_geom = baseline_geom.copy()\n",
        "        original_width = float(baseline_geom[1])\n",
        "        new_width = original_width * 1.5\n",
        "        new_geom[1] = new_width\n",
        "        \n",
        "        print(f\"\\nModifying breach width:\")\n",
        "        print(f\"  Original: {original_width} ft\")\n",
        "        print(f\"  New: {new_width} ft (+50%)\")\n",
        "        \n",
        "        # Update the plan\n",
        "        RasBreach.update_breach_block(\n",
        "            scenario_1_plan,\n",
        "            target_structure,\n",
        "            geom_values=new_geom\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n\u2713 Scenario 1 plan created: {scenario_1_plan}\")\n",
        "        print(f\"  Next step: Run HEC-RAS simulation for plan {scenario_1_plan}\")\n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(f\"Could not parse geometry values: {e}\")\n",
        "else:\n",
        "    print(\"Skipping Scenario 1 - insufficient baseline data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if target_structure:\n",
        "    # Scenario definitions\n",
        "    scenario_plans = {\n",
        "        'Scenario 1: +50% Width': '03',\n",
        "        'Scenario 2: -50% Formation Time': '04',\n",
        "        'Scenario 3: Different Method': '05'\n",
        "    }\n",
        "    \n",
        "    # Try to extract results for each scenario from HDF files\n",
        "    for scenario_name, plan_num in scenario_plans.items():\n",
        "        try:\n",
        "            # Extract breach results from HDF using HdfResultsBreach\n",
        "            ts = HdfResultsBreach.get_breach_timeseries(plan_num, target_structure)\n",
        "            summary = HdfResultsBreach.get_breach_summary(plan_num, target_structure)\n",
        "            \n",
        "            if not ts.empty:\n",
        "                scenarios[scenario_name] = ts\n",
        "                summaries[scenario_name] = summary\n",
        "                print(f\"\u2713 Extracted: {scenario_name}\")\n",
        "            else:\n",
        "                print(f\"\u26a0 No results for: {scenario_name} (run HEC-RAS first)\")\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"\u26a0 HDF not found for {scenario_name}: Plan {plan_num} (run HEC-RAS first)\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0 Could not extract {scenario_name}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal scenarios with results: {len(scenarios)}\")\n",
        "else:\n",
        "    print(\"Skipping scenario extraction - no breach structure available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Scenario 2: Decrease Breach Formation Time by 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.490868Z",
          "iopub.status.busy": "2025-11-17T17:45:18.490665Z",
          "iopub.status.idle": "2025-11-17T17:45:18.575282Z",
          "shell.execute_reply": "2025-11-17T17:45:18.574850Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure and baseline_geom and len(baseline_geom) >= 7:\n",
        "    # Clone plan\n",
        "    scenario_2_plan = RasPlan.clone_plan(template_plan, \"Scenario 2: -50% Formation Time\")\n",
        "    \n",
        "    # Modify formation time (assuming index 6 is formation time)\n",
        "    try:\n",
        "        new_geom = baseline_geom.copy()\n",
        "        original_time = float(baseline_geom[6])\n",
        "        new_time = original_time * 0.5\n",
        "        new_geom[6] = new_time\n",
        "        \n",
        "        print(f\"\\nModifying breach formation time:\")\n",
        "        print(f\"  Original: {original_time} hrs\")\n",
        "        print(f\"  New: {new_time} hrs (-50%)\")\n",
        "        \n",
        "        # Update the plan\n",
        "        RasBreach.update_breach_block(\n",
        "            scenario_2_plan,\n",
        "            target_structure,\n",
        "            geom_values=new_geom\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n\u2713 Scenario 2 plan created: {scenario_2_plan}\")\n",
        "        print(f\"  Next step: Run HEC-RAS simulation for plan {scenario_2_plan}\")\n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(f\"Could not parse geometry values: {e}\")\n",
        "else:\n",
        "    print(\"Skipping Scenario 2 - insufficient baseline data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:18.580395Z",
          "iopub.status.busy": "2025-11-17T17:45:18.580150Z",
          "iopub.status.idle": "2025-11-17T17:46:23.519281Z",
          "shell.execute_reply": "2025-11-17T17:46:23.518732Z"
        }
      },
      "outputs": [],
      "source": [
        "parallel_computed_folder = example_project_folder.parent / f\"{example_project_folder.name}_parallelcomputed\"\n",
        "RasCmdr.compute_parallel([template_plan, scenario_1_plan, scenario_2_plan], max_workers=4, num_cores=2, dest_folder=Path(parallel_computed_folder), overwrite_dest=True)\n",
        "# Re-initialize in new folder where results are present\n",
        "init_ras_project(parallel_computed_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.521307Z",
          "iopub.status.busy": "2025-11-17T17:46:23.521003Z",
          "iopub.status.idle": "2025-11-17T17:46:23.523792Z",
          "shell.execute_reply": "2025-11-17T17:46:23.523283Z"
        }
      },
      "outputs": [],
      "source": [
        "# Scenario definitions\n",
        "scenario_plans = {\n",
        "    'Scenario 1: +50% Width': scenario_1_plan,\n",
        "    'Scenario 2: -50% Formation Time': scenario_2_plan,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.525887Z",
          "iopub.status.busy": "2025-11-17T17:46:23.525728Z",
          "iopub.status.idle": "2025-11-17T17:46:23.642094Z",
          "shell.execute_reply": "2025-11-17T17:46:23.641636Z"
        }
      },
      "outputs": [],
      "source": [
        "# Try to extract results for each scenario from HDF files\n",
        "for scenario_name, plan_num in scenario_plans.items():\n",
        "    try:\n",
        "        # Extract breach results from HDF using HdfResultsBreach\n",
        "        ts = HdfResultsBreach.get_breach_timeseries(plan_num, target_structure)\n",
        "        summary = HdfResultsBreach.get_breach_summary(plan_num, target_structure)\n",
        "        \n",
        "        if not ts.empty:\n",
        "            scenarios[scenario_name] = ts\n",
        "            summaries[scenario_name] = summary\n",
        "            print(f\"\u2713 Extracted: {scenario_name}\")\n",
        "        else:\n",
        "            print(f\"\u26a0 No results for: {scenario_name} (run HEC-RAS first)\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"\u26a0 HDF not found for {scenario_name}: Plan {plan_num} (run HEC-RAS first)\")\n",
        "    except Exception as e:\n",
        "        print(f\"\u26a0 Could not extract {scenario_name}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal scenarios with results: {len(scenarios)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.643967Z",
          "iopub.status.busy": "2025-11-17T17:46:23.643790Z",
          "iopub.status.idle": "2025-11-17T17:46:23.654859Z",
          "shell.execute_reply": "2025-11-17T17:46:23.654360Z"
        }
      },
      "outputs": [],
      "source": [
        "ts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.656789Z",
          "iopub.status.busy": "2025-11-17T17:46:23.656427Z",
          "iopub.status.idle": "2025-11-17T17:46:23.663672Z",
          "shell.execute_reply": "2025-11-17T17:46:23.663158Z"
        }
      },
      "outputs": [],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Results from All Scenarios\n",
        "\n",
        "**\u26a0\ufe0f IMPORTANT:** You must run HEC-RAS simulations for plans 03, 04, and 05 before this section will work.\n",
        "\n",
        "This section attempts to extract results from all scenarios. If HDF files don't exist, it will skip gracefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.665685Z",
          "iopub.status.busy": "2025-11-17T17:46:23.665530Z",
          "iopub.status.idle": "2025-11-17T17:46:23.673536Z",
          "shell.execute_reply": "2025-11-17T17:46:23.672950Z"
        }
      },
      "outputs": [],
      "source": [
        "from ras_commander import get_logger\n",
        "import textwrap\n",
        "\n",
        "logger = get_logger(__name__)\n",
        "\n",
        "# Get the raw computation messages string from the results HDF for the scenario 1 plan\n",
        "comp_msgs = HdfResultsPlan.get_compute_messages(scenario_1_plan)\n",
        "\n",
        "def pretty_print_compute_messages(msg: str) -> None:\n",
        "    \"\"\"\n",
        "    Nicely format and print RAS compute messages. Strips unnecessary escapes,\n",
        "    ensures readable blocks, and optionally highlights warnings.\n",
        "    \"\"\"\n",
        "    if not msg:\n",
        "        print(\"No computation messages found.\")\n",
        "        return\n",
        "\n",
        "    # Replace carriage returns, unify newlines\n",
        "    msg = msg.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
        "    # Collapse excessive blank lines to at most 2\n",
        "    lines = msg.split('\\n')\n",
        "    pretty_lines = []\n",
        "    blank_count = 0\n",
        "    for line in lines:\n",
        "        if line.strip() == '':\n",
        "            blank_count += 1\n",
        "            if blank_count <= 2:\n",
        "                pretty_lines.append('')\n",
        "        else:\n",
        "            blank_count = 0\n",
        "            # Optionally add highlighting for warnings/errors\n",
        "            l_strip = line.lstrip()\n",
        "            if l_strip.lower().startswith(\"warning\") or \"error\" in l_strip.lower():\n",
        "                pretty_lines.append(\"\u26a0\ufe0f \" + line)\n",
        "            else:\n",
        "                pretty_lines.append(line)\n",
        "    # Optionally wrap long lines for readability\n",
        "    final_lines = []\n",
        "    for l in pretty_lines:\n",
        "        if len(l) > 120:\n",
        "            final_lines.extend(textwrap.wrap(l, width=120))\n",
        "        else:\n",
        "            final_lines.append(l)\n",
        "    # Print result\n",
        "    print('\\n'.join(final_lines))\n",
        "\n",
        "pretty_print_compute_messages(comp_msgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.675608Z",
          "iopub.status.busy": "2025-11-17T17:46:23.675427Z",
          "iopub.status.idle": "2025-11-17T17:46:23.695348Z",
          "shell.execute_reply": "2025-11-17T17:46:23.694955Z"
        }
      },
      "outputs": [],
      "source": [
        "# Try to list SA/2D connection structures in HDF results\n",
        "try:\n",
        "    hdf_structures = HdfStruc.list_sa2d_connections(template_plan)\n",
        "    print(\"SA/2D Connection Structures in HDF:\")\n",
        "    for struct in hdf_structures:\n",
        "        print(f\"  - {struct}\")\n",
        "\n",
        "    # Get breach capability information\n",
        "    breach_info = HdfStruc.get_sa2d_breach_info(template_plan)\n",
        "    print(\"\\nBreach Capability Information:\")\n",
        "    print(breach_info.to_string(index=False))\n",
        "\n",
        "    # Get list of structures with breach capability\n",
        "    breach_structures = breach_info[breach_info['has_breach']]['structure'].tolist()\n",
        "    print(f\"\\nStructures with breach capability: {breach_structures}\")\n",
        "\n",
        "    # Select first breach structure for analysis\n",
        "    if breach_structures:\n",
        "        target_structure = breach_structures[0]\n",
        "        print(f\"\\nTarget structure for analysis: {target_structure}\")\n",
        "    else:\n",
        "        print(\"\\nWARNING: No breach structures found! Cannot proceed with analysis.\")\n",
        "        target_structure = None\n",
        "        \n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n\u26a0\ufe0f HDF RESULTS FILE NOT FOUND\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(f\"\\nThis means HEC-RAS has not been run for Plan 02 yet.\")\n",
        "    print(f\"To generate results, either:\")\n",
        "    print(f\"  1. Uncomment and run the simulation cell above, OR\")\n",
        "    print(f\"  2. Open HEC-RAS and manually run Plan 02\")\n",
        "    print(f\"\\nThe notebook will continue to demonstrate parameter modification.\")\n",
        "    target_structure = None\n",
        "    breach_structures = []\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u26a0\ufe0f UNEXPECTED ERROR: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    target_structure = None\n",
        "    breach_structures = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.697289Z",
          "iopub.status.busy": "2025-11-17T17:46:23.697016Z",
          "iopub.status.idle": "2025-11-17T17:46:23.721684Z",
          "shell.execute_reply": "2025-11-17T17:46:23.721265Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get breach-specific variables (width, depth, slopes over time)\n",
        "breach_vars = HdfResultsBreach.get_breaching_variables(template_plan, \"Dam\")\n",
        "breach_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.723606Z",
          "iopub.status.busy": "2025-11-17T17:46:23.723369Z",
          "iopub.status.idle": "2025-11-17T17:46:23.735510Z",
          "shell.execute_reply": "2025-11-17T17:46:23.735109Z"
        }
      },
      "outputs": [],
      "source": [
        "# OPTIONAL: Also check HDF for breach capability (requires HDF file to exist)\n",
        "print(\"\\n--- HDF Breach Capability Check (optional) ---\")\n",
        "try:\n",
        "    hdf_structures = HdfStruc.list_sa2d_connections(template_plan)\n",
        "    print(f\"SA/2D Connections in HDF: {hdf_structures}\")\n",
        "    \n",
        "    breach_info = HdfStruc.get_sa2d_breach_info(template_plan)\n",
        "    print(f\"\\nBreach capability info:\")\n",
        "    print(breach_info[['structure', 'has_breach']].to_string(index=False))\n",
        "    \n",
        "    print(f\"\\nNOTE: HDF names may differ from plan file names!\")\n",
        "    print(f\"  Plan file: '{target_structure}'\")\n",
        "    print(f\"  HDF may show: 'AreaName {target_structure}'\")\n",
        "except FileNotFoundError:\n",
        "    print(\"HDF file not found (HEC-RAS not run yet)\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not read HDF: {e}\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Visualize Baseline Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "**\u2705 Baseline Analysis:**\n",
        "- Extracted existing breach results from Plan 02\n",
        "- Read baseline breach parameters\n",
        "- Visualized baseline behavior\n",
        "\n",
        "**\u2705 Scenario Creation:**\n",
        "- Cloned Plan 02 to create new scenarios\n",
        "- Modified breach parameters one at a time:\n",
        "  - Scenario 1: Increased breach width by 50%\n",
        "  - Scenario 2: Decreased formation time by 50%\n",
        "  - Scenario 3: Changed breach method\n",
        "\n",
        "**\u2705 Results Comparison:**\n",
        "- Extracted results from all scenarios (if HEC-RAS was run)\n",
        "- Compared flow hydrographs\n",
        "- Compared peak flows\n",
        "- Compared breach geometry evolution\n",
        "- Created comprehensive comparison dashboard\n",
        "\n",
        "**\u2705 Data Export:**\n",
        "- Exported time series for all scenarios\n",
        "- Exported comparison summary table\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Run HEC-RAS Simulations:**\n",
        "   - Open HEC-RAS\n",
        "   - Run plans 03, 04, and 05\n",
        "   - Re-run this notebook to extract and compare results\n",
        "\n",
        "2. **Additional Scenarios:**\n",
        "   - Create more scenarios by modifying other parameters\n",
        "   - Test combinations of parameters\n",
        "   - Explore full sensitivity range\n",
        "\n",
        "3. **Advanced Analysis:**\n",
        "   - Statistical analysis of parameter sensitivity\n",
        "   - Uncertainty quantification\n",
        "   - Flood impact assessment downstream\n",
        "\n",
        "### Key Functions Used:\n",
        "\n",
        "```python\n",
        "# HDF Results Extraction (use HdfResultsBreach and HdfStruc)\n",
        "HdfStruc.list_sa2d_connections(plan)           # List structures in HDF\n",
        "HdfStruc.get_sa2d_breach_info(plan)            # Get breach capability info\n",
        "HdfResultsBreach.get_breach_timeseries(plan, structure)  # Extract time series\n",
        "HdfResultsBreach.get_breach_summary(plan, structure)     # Extract summary stats\n",
        "\n",
        "# Plan File Parameter Management (use RasBreach)\n",
        "RasBreach.list_breach_structures_plan(plan)    # List structures in plan file\n",
        "RasBreach.read_breach_block(plan, structure)   # Read parameters\n",
        "RasBreach.update_breach_block(plan, structure, **params)  # Modify parameters\n",
        "```\n",
        "\n",
        "### Architectural Pattern:\n",
        "\n",
        "**ras-commander separates HDF and plain text operations:**\n",
        "- **RasBreach** \u2192 Breach PARAMETERS in plan files (.p##)\n",
        "- **HdfResultsBreach** \u2192 Breach RESULTS from HDF files (.p##.hdf)\n",
        "- **HdfStruc** \u2192 Structure listings and metadata from HDF\n",
        "\n",
        "Use plan file methods for parameter operations to ensure structure names match!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.737259Z",
          "iopub.status.busy": "2025-11-17T17:46:23.737124Z",
          "iopub.status.idle": "2025-11-17T17:46:23.840225Z",
          "shell.execute_reply": "2025-11-17T17:46:23.839751Z"
        }
      },
      "outputs": [],
      "source": [
        "if target_structure:\n",
        "    # Scenario definitions\n",
        "    scenario_plans = {\n",
        "        'Scenario 1: +50% Width': scenario_1_plan,\n",
        "        'Scenario 2: -50% Formation Time': scenario_2_plan,\n",
        "    }\n",
        "    \n",
        "    # Try to extract results for each scenario\n",
        "    for scenario_name, plan_num in scenario_plans.items():\n",
        "        try:\n",
        "            ts = HdfResultsBreach.get_breach_timeseries(plan_num, target_structure)\n",
        "            summary = HdfResultsBreach.get_breach_summary(plan_num, target_structure)\n",
        "            \n",
        "            if not ts.empty:\n",
        "                scenarios[scenario_name] = ts\n",
        "                summaries[scenario_name] = summary\n",
        "                print(f\"\u2713 Extracted: {scenario_name}\")\n",
        "            else:\n",
        "                print(f\"\u26a0 No results for: {scenario_name} (run HEC-RAS first)\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u26a0 Could not extract {scenario_name}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal scenarios with results: {len(scenarios)}\")\n",
        "else:\n",
        "    print(\"Skipping scenario extraction - no breach structure available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compare Results Across All Scenarios\n",
        "\n",
        "Visualize all scenarios together to understand parameter sensitivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Flow Hydrograph Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.842191Z",
          "iopub.status.busy": "2025-11-17T17:46:23.841892Z",
          "iopub.status.idle": "2025-11-17T17:46:23.990599Z",
          "shell.execute_reply": "2025-11-17T17:46:23.990022Z"
        }
      },
      "outputs": [],
      "source": [
        "if scenarios:\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    \n",
        "    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
        "    linestyles = ['-', '--', '-.', ':', '-']\n",
        "    \n",
        "    for idx, (scenario_name, ts_data) in enumerate(scenarios.items()):\n",
        "        color = colors[idx % len(colors)]\n",
        "        linestyle = linestyles[idx % len(linestyles)]\n",
        "        \n",
        "        ax.plot(ts_data['datetime'], ts_data['total_flow'],\n",
        "               label=scenario_name, color=color, linestyle=linestyle, linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('Time', fontsize=12)\n",
        "    ax.set_ylabel('Total Flow (cfs)', fontsize=12)\n",
        "    ax.set_title(f'{target_structure} - Flow Hydrograph Comparison', \n",
        "                fontsize=14, fontweight='bold')\n",
        "    ax.legend(loc='best', fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No scenario data available for comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Peak Flow Comparison (Bar Chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:23.992637Z",
          "iopub.status.busy": "2025-11-17T17:46:23.992366Z",
          "iopub.status.idle": "2025-11-17T17:46:24.078621Z",
          "shell.execute_reply": "2025-11-17T17:46:24.078072Z"
        }
      },
      "outputs": [],
      "source": [
        "if summaries:\n",
        "    # Extract peak flows\n",
        "    scenario_names = list(summaries.keys())\n",
        "    peak_flows = [summaries[name].iloc[0]['max_total_flow'] \n",
        "                 for name in scenario_names]\n",
        "    \n",
        "    # Create bar chart\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bars = ax.bar(range(len(scenario_names)), peak_flows, \n",
        "                  color=['blue', 'red', 'green', 'orange', 'purple'][:len(scenario_names)])\n",
        "    \n",
        "    ax.set_xticks(range(len(scenario_names)))\n",
        "    ax.set_xticklabels(scenario_names, rotation=45, ha='right')\n",
        "    ax.set_ylabel('Peak Flow (cfs)', fontsize=12)\n",
        "    ax.set_title(f'{target_structure} - Peak Flow Comparison', \n",
        "                fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, peak_flows):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "               f'{value:.0f}',\n",
        "               ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print percent differences from baseline\n",
        "    if len(peak_flows) > 1:\n",
        "        baseline_flow = peak_flows[0]\n",
        "        print(\"\\nPeak Flow Differences from Baseline:\")\n",
        "        print(\"=\" * 60)\n",
        "        for i, (name, flow) in enumerate(zip(scenario_names, peak_flows)):\n",
        "            if i == 0:\n",
        "                print(f\"{name}: {flow:.0f} cfs (baseline)\")\n",
        "            else:\n",
        "                diff_pct = ((flow - baseline_flow) / baseline_flow) * 100\n",
        "                print(f\"{name}: {flow:.0f} cfs ({diff_pct:+.1f}%)\")\n",
        "else:\n",
        "    print(\"No summary data available for comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Breach Width Evolution Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:24.080940Z",
          "iopub.status.busy": "2025-11-17T17:46:24.080762Z",
          "iopub.status.idle": "2025-11-17T17:46:24.206707Z",
          "shell.execute_reply": "2025-11-17T17:46:24.206056Z"
        }
      },
      "outputs": [],
      "source": [
        "if scenarios:\n",
        "    # Check if any scenario has breach width data\n",
        "    has_width_data = any(ts['bottom_width'].notna().any() for ts in scenarios.values())\n",
        "    \n",
        "    if has_width_data:\n",
        "        fig, ax = plt.subplots(figsize=(14, 6))\n",
        "        \n",
        "        for idx, (scenario_name, ts_data) in enumerate(scenarios.items()):\n",
        "            if ts_data['bottom_width'].notna().any():\n",
        "                color = colors[idx % len(colors)]\n",
        "                linestyle = linestyles[idx % len(linestyles)]\n",
        "                \n",
        "                ax.plot(ts_data['datetime'], ts_data['bottom_width'],\n",
        "                       label=scenario_name, color=color, linestyle=linestyle, \n",
        "                       linewidth=2, marker='o', markersize=4)\n",
        "        \n",
        "        ax.set_xlabel('Time', fontsize=12)\n",
        "        ax.set_ylabel('Breach Width (ft)', fontsize=12)\n",
        "        ax.set_title(f'{target_structure} - Breach Width Evolution Comparison', \n",
        "                    fontsize=14, fontweight='bold')\n",
        "        ax.legend(loc='best', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No breach width data available (breach may not have formed)\")\n",
        "else:\n",
        "    print(\"No scenario data available for comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Summary Table Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:24.208965Z",
          "iopub.status.busy": "2025-11-17T17:46:24.208784Z",
          "iopub.status.idle": "2025-11-17T17:46:24.219501Z",
          "shell.execute_reply": "2025-11-17T17:46:24.218896Z"
        }
      },
      "outputs": [],
      "source": [
        "if summaries:\n",
        "    # Combine all summaries into a comparison table\n",
        "    comparison_data = []\n",
        "    for scenario_name, summary_df in summaries.items():\n",
        "        row = summary_df.iloc[0].to_dict()\n",
        "        row['Scenario'] = scenario_name\n",
        "        comparison_data.append(row)\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    \n",
        "    # Select key columns for display\n",
        "    display_cols = ['Scenario', 'max_total_flow', 'max_breach_flow', \n",
        "                   'final_breach_width', 'final_breach_depth', \n",
        "                   'max_hw', 'max_tw']\n",
        "    \n",
        "    # Filter to available columns\n",
        "    display_cols = [col for col in display_cols if col in comparison_df.columns]\n",
        "    \n",
        "    print(\"\\nScenario Comparison Summary:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(comparison_df[display_cols].to_string(index=False))\n",
        "    \n",
        "    # Export to CSV\n",
        "    output_file = project_path / \"breach_scenario_comparison.csv\"\n",
        "    comparison_df.to_csv(output_file, index=False)\n",
        "    print(f\"\\nComparison table exported to: {output_file}\")\n",
        "else:\n",
        "    print(\"No summary data available for comparison table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Comprehensive Multi-Panel Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:24.221528Z",
          "iopub.status.busy": "2025-11-17T17:46:24.221370Z",
          "iopub.status.idle": "2025-11-17T17:46:24.628102Z",
          "shell.execute_reply": "2025-11-17T17:46:24.627569Z"
        }
      },
      "outputs": [],
      "source": [
        "if scenarios and len(scenarios) > 1:\n",
        "    # Create 2x2 subplot grid\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Plot 1: Flow comparison\n",
        "    for idx, (scenario_name, ts_data) in enumerate(scenarios.items()):\n",
        "        color = colors[idx % len(colors)]\n",
        "        axes[0, 0].plot(ts_data['datetime'], ts_data['total_flow'],\n",
        "                       label=scenario_name, color=color, linewidth=2)\n",
        "    axes[0, 0].set_ylabel('Total Flow (cfs)', fontsize=11)\n",
        "    axes[0, 0].set_title('Flow Hydrographs', fontsize=12, fontweight='bold')\n",
        "    axes[0, 0].legend(fontsize=8)\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Peak flows bar chart\n",
        "    scenario_names = list(summaries.keys())\n",
        "    peak_flows = [summaries[name].iloc[0]['max_total_flow'] for name in scenario_names]\n",
        "    bars = axes[0, 1].bar(range(len(scenario_names)), peak_flows,\n",
        "                          color=colors[:len(scenario_names)])\n",
        "    axes[0, 1].set_xticks(range(len(scenario_names)))\n",
        "    axes[0, 1].set_xticklabels(range(len(scenario_names)))\n",
        "    axes[0, 1].set_ylabel('Peak Flow (cfs)', fontsize=11)\n",
        "    axes[0, 1].set_title('Peak Flow Comparison', fontsize=12, fontweight='bold')\n",
        "    axes[0, 1].grid(True, axis='y', alpha=0.3)\n",
        "    \n",
        "    # Plot 3: HW/TW for baseline\n",
        "    baseline_ts = scenarios[list(scenarios.keys())[0]]\n",
        "    axes[1, 0].plot(baseline_ts['datetime'], baseline_ts['hw'], \n",
        "                   label='HW', color='blue', linewidth=2)\n",
        "    axes[1, 0].plot(baseline_ts['datetime'], baseline_ts['tw'], \n",
        "                   label='TW', color='red', linewidth=2)\n",
        "    axes[1, 0].set_xlabel('Time', fontsize=11)\n",
        "    axes[1, 0].set_ylabel('Elevation (ft)', fontsize=11)\n",
        "    axes[1, 0].set_title('Baseline Water Levels', fontsize=12, fontweight='bold')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Breach width comparison (if available)\n",
        "    has_width = False\n",
        "    for idx, (scenario_name, ts_data) in enumerate(scenarios.items()):\n",
        "        if ts_data['bottom_width'].notna().any():\n",
        "            color = colors[idx % len(colors)]\n",
        "            axes[1, 1].plot(ts_data['datetime'], ts_data['bottom_width'],\n",
        "                           label=scenario_name, color=color, linewidth=2, marker='o')\n",
        "            has_width = True\n",
        "    \n",
        "    if has_width:\n",
        "        axes[1, 1].set_xlabel('Time', fontsize=11)\n",
        "        axes[1, 1].set_ylabel('Breach Width (ft)', fontsize=11)\n",
        "        axes[1, 1].set_title('Breach Width Evolution', fontsize=12, fontweight='bold')\n",
        "        axes[1, 1].legend(fontsize=8)\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, 'No Breach Width Data',\n",
        "                       ha='center', va='center', fontsize=14,\n",
        "                       transform=axes[1, 1].transAxes)\n",
        "    \n",
        "    fig.suptitle(f'{target_structure} - Breach Scenario Analysis Dashboard',\n",
        "                fontsize=16, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Need at least 2 scenarios for comprehensive comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Export All Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:24.630278Z",
          "iopub.status.busy": "2025-11-17T17:46:24.630122Z",
          "iopub.status.idle": "2025-11-17T17:46:24.640652Z",
          "shell.execute_reply": "2025-11-17T17:46:24.640047Z"
        }
      },
      "outputs": [],
      "source": [
        "if scenarios:\n",
        "    # Export each scenario's time series\n",
        "    for scenario_name, ts_data in scenarios.items():\n",
        "        # Create safe filename\n",
        "        safe_name = scenario_name.replace(' ', '_').replace(':', '').replace('+', 'plus')\n",
        "        filename = project_path / f\"breach_{safe_name}.csv\"\n",
        "        ts_data.to_csv(filename, index=False)\n",
        "        print(f\"Exported: {filename.name}\")\n",
        "    \n",
        "    print(f\"\\nAll scenario data exported to: {project_path}\")\n",
        "else:\n",
        "    print(\"No scenario data to export\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "**\u2705 Baseline Analysis:**\n",
        "- Extracted existing breach results from HDF\n",
        "- Read baseline breach parameters from plan file\n",
        "- Visualized baseline behavior\n",
        "\n",
        "**\u2705 Scenario Creation:**\n",
        "- Cloned plans to create new scenarios\n",
        "- Modified breach parameters one at a time:\n",
        "  - Scenario 1: Increased breach width by 50%\n",
        "  - Scenario 2: Decreased formation time by 50%\n",
        "\n",
        "**\u2705 Results Comparison:**\n",
        "- Extracted results from all scenarios\n",
        "- Compared flow hydrographs\n",
        "- Compared peak flows\n",
        "- Compared breach geometry evolution\n",
        "- Created comprehensive comparison dashboard\n",
        "\n",
        "**\u2705 Data Export:**\n",
        "- Exported time series for all scenarios\n",
        "- Exported comparison summary table\n",
        "\n",
        "### Key Functions Used:\n",
        "\n",
        "```python\n",
        "# HDF Results Extraction (use HdfResultsBreach and HdfStruc)\n",
        "HdfStruc.list_sa2d_connections(plan)              # List structures in HDF\n",
        "HdfStruc.get_sa2d_breach_info(plan)               # Get breach capability info\n",
        "HdfResultsBreach.get_breach_timeseries(plan, structure)   # Extract time series\n",
        "HdfResultsBreach.get_breach_summary(plan, structure)      # Extract summary stats\n",
        "HdfResultsBreach.get_breaching_variables(plan, structure) # Breach geometry evolution\n",
        "HdfResultsBreach.get_structure_variables(plan, structure) # Structure flow variables\n",
        "\n",
        "# Plan File Parameter Management (use RasBreach)\n",
        "RasBreach.list_breach_structures_plan(plan)      # List structures in plan file\n",
        "RasBreach.read_breach_block(plan, structure)     # Read parameters\n",
        "RasBreach.update_breach_block(plan, structure, geom_values=[...])  # Modify parameters\n",
        "```\n",
        "\n",
        "### Architectural Pattern:\n",
        "\n",
        "**ras-commander separates HDF and plain text operations:**\n",
        "- **RasBreach** \u2192 Breach PARAMETERS in plan files (.p##)\n",
        "- **HdfResultsBreach** \u2192 Breach RESULTS from HDF files (.p##.hdf)\n",
        "- **HdfStruc** \u2192 Structure listings and metadata from HDF\n",
        "\n",
        "**Important:** Use plan file methods for parameter operations to ensure structure names match!\n",
        "\n",
        "### Breach Geom Field Structure:\n",
        "```python\n",
        "# Breach Geom CSV format (10 fields):\n",
        "[0] Centerline/Station     # ft\n",
        "[1] Initial Bottom Width   # ft\n",
        "[2] Final Bottom Elevation # ft  <-- Example: change this to 605\n",
        "[3] Left Side Slope        # H:V ratio\n",
        "[4] Right Side Slope       # H:V ratio\n",
        "[5] Active Flag            # True/False\n",
        "[6] Weir Coefficient       # dimensionless\n",
        "[7] Top Elevation          # ft\n",
        "[8] Formation Method       # 1=Time, 2=Trigger\n",
        "[9] Formation Time/Threshold # hrs or ft\n",
        "\n",
        "# Example: Update Final Bottom Elevation\n",
        "new_geom = baseline_geom.copy()\n",
        "new_geom[2] = 605  # Set to 605 ft\n",
        "RasBreach.update_breach_block(\"template_plan\", \"Dam\", geom_values=new_geom)\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\19_steady_flow_analysis.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HEC-RAS Steady State Flow Analysis\n",
        "\n",
        "This notebook demonstrates how to extract and analyze steady state flow results from HEC-RAS using the ras-commander library. It showcases the new steady state functionality in `HdfResultsPlan`.\n",
        "\n",
        "## New Steady State Methods\n",
        "\n",
        "The library now includes full support for steady state analysis:\n",
        "- `is_steady_plan()` - Check if HDF contains steady state results\n",
        "- `get_steady_profile_names()` - Extract steady state profile names\n",
        "- `get_steady_wse()` - Extract water surface elevations for profiles\n",
        "- `get_steady_info()` - Extract steady flow metadata and attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting Steady Flow Computation Messages\n",
        "\n",
        "For steady flow analyses, computation messages provide valuable information about:\n",
        "- Hydraulic computations and convergence\n",
        "- Warning messages for critical flow or other conditions\n",
        "- Computation timing and performance\n",
        "\n",
        "We can extract these using `HdfResultsPlan.get_compute_messages()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Extracting project 'Balde Eagle Creek'\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Project 'Balde Eagle Creek' already exists. Deleting existing folder...\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Existing folder for project 'Balde Eagle Creek' has been deleted.\n",
            "2025-12-02 21:07:36 - ras_commander.RasExamples - INFO - Successfully extracted project 'Balde Eagle Creek' to c:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n"
          ]
        }
      ],
      "source": [
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "plan_number = \"01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:07:36 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "data": {
            "text/plain": "['<ras_commander.RasPrj.RasPrj at 0x1f6cf0a1400>']"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init_ras_project(bald_eagle_path, \"6.6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>PS Cores</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '      <th>flow_type</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>5.00</td>\\n', '      <td>UnsteadyFlow</td>\\n', '      <td>18FEB1999,0000,24FEB1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>1HOUR</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>2</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Unsteady</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>NaN</td>\\n', '      <td>SteadyRun</td>\\n', '      <td>02/18/1999,0000,02/24/1999,0500</td>\\n', '      <td>2MIN</td>\\n', '      <td>NaN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>None</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>02</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>Steady</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  plan_number unsteady_number geometry_number                     Plan Title  \\\\\\n', '0          01              02              01  Unsteady with Bridges and Dam   \\n', '1          02            None              01                Steady Flow Run   \\n', '\\n', '  Program Version Short Identifier                  Simulation Date  \\\\\\n', '0            5.00     UnsteadyFlow    18FEB1999,0000,24FEB1999,0500   \\n', '1             NaN        SteadyRun  02/18/1999,0000,02/24/1999,0500   \\n', '\\n', '  Computation Interval Mapping Interval Run HTab  ... PS Cores DSS File  \\\\\\n', '0                 2MIN            1HOUR        1  ...     None      dss   \\n', '1                 2MIN              NaN        1  ...     None      dss   \\n', '\\n', '  Friction Slope Method HDF_Results_Path Geom File  \\\\\\n', '0                     2             None        01   \\n', '1                     1             None        01   \\n', '\\n', '                                           Geom Path  Flow File  \\\\\\n', '0  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...         02   \\n', '1  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...         02   \\n', '\\n', '                                           Flow Path  \\\\\\n', '0  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '1  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...   \\n', '\\n', '                                           full_path flow_type  \\n', '0  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  Unsteady  \\n', '1  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...    Steady  \\n', '\\n', '[2 rows x 27 columns]']"
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:07:36 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "2025-12-02 21:07:36 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 21:07:36 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p01\"\n",
            "2025-12-02 21:09:02 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-12-02 21:09:02 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 86.56 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": "['True']"
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RasCmdr.compute_plan(plan_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting Steady Flow Computation Messages\n",
        "\n",
        "For steady flow analyses, computation messages provide valuable information about:\n",
        "- Hydraulic computations and convergence\n",
        "- Warning messages for critical flow or other conditions\n",
        "- Computation timing and performance\n",
        "\n",
        "We can extract these using `HdfResultsPlan.get_compute_messages()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:02 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p01.hdf\n",
            "2025-12-02 21:09:02 - ras_commander.hdf.HdfResultsPlan - INFO - Reading computation messages from HDF: BaldEagle.p01.hdf\n",
            "2025-12-02 21:09:02 - ras_commander.hdf.HdfResultsPlan - INFO - Successfully extracted 1693 characters from HDF\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEADY FLOW COMPUTATION MESSAGES\n",
            "================================================================================\n",
            "\n",
            "Extracted 1693 characters\n",
            "\n",
            "Computation messages:\n",
            "--------------------------------------------------------------------------------\n",
            "Plan: 'Unsteady with Bridges and Dam' (BaldEagle.p01)\n",
            "Simulation started at: 02Dec2025 09:07:37 PM\n",
            "\n",
            "Writing Plan GIS Data...\n",
            "Completed Writing Plan GIS Data\n",
            "Writing Geometry...\n",
            "Computing Bank Lines\n",
            "Bank lines generated in 108 ms\n",
            "Computing Edge Lines\n",
            "Edge Lines generated in 46 ms\n",
            "Computing XS Interpolation Surface\n",
            "XS Interpolation Surface generated in 109 ms\n",
            "Completed Writing Geometry\n",
            "Writing Event Conditions ...\n",
            "Completed Writing Event Condition Data\n",
            "\n",
            "\t\n",
            "Geometric Preprocessor HEC-RAS 6.6 September 2024\n",
            " \n",
            "\n",
            "Finished Processing Geometry\n",
            "\n",
            "\n",
            "Performing Unsteady Flow Simulation  HEC-RAS 6.6 September 2024\n",
            " \n",
            "\t\n",
            "Unsteady Input Summary:\n",
            "     1D Unsteady Finite Difference Numerical Solution\n",
            "\n",
            "Overall Volume Accounting Error in Acre Feet:    -29.5468461514\n",
            "Overall Volume Accounting Error as percentage:           0.01407\n",
            "Please review \"Computational Log File\" output for volume accounting details\n",
            "\n",
            "Writing Results to DSS\n",
            "\n",
            "Finished Unsteady Flow Simulation\n",
            "\n",
            "Reading U\n",
            "\n",
            "... (truncated for display) ...\n",
            "\n",
            "================================================================================\n",
            "Checking for critical flow or warnings...\n",
            "================================================================================\n",
            "\u2713 No critical flow or warning messages found\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Extract computation messages for steady flow analysis\n",
        "from ras_commander import HdfResultsPlan\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"STEADY FLOW COMPUTATION MESSAGES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Extract messages (works with plan number or HDF path)\n",
        "steady_msgs = HdfResultsPlan.get_compute_messages(plan_number)\n",
        "\n",
        "if steady_msgs:\n",
        "    print(f\"\\nExtracted {len(steady_msgs)} characters\\n\")\n",
        "    \n",
        "    # Display messages\n",
        "    print(\"Computation messages:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(steady_msgs[:1000])  # First 1000 characters\n",
        "    \n",
        "    if len(steady_msgs) > 1000:\n",
        "        print(\"\\n... (truncated for display) ...\")\n",
        "    \n",
        "    # Look for critical information\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Checking for critical flow or warnings...\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    lines = steady_msgs.split('\\n')\n",
        "    critical = [l for l in lines if 'critical' in l.lower() or 'warning' in l.lower()]\n",
        "    \n",
        "    if critical:\n",
        "        print(f\"Found {len(critical)} lines with critical flow or warnings:\")\n",
        "        for line in critical[:10]:\n",
        "            print(f\"  - {line.strip()}\")\n",
        "    else:\n",
        "        print(\"\u2713 No critical flow or warning messages found\")\n",
        "else:\n",
        "    print(\"No computation messages available\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Installation and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ras-commander from pip (uncomment to install if needed)\n",
        "# !pip install --upgrade ras-commander\n",
        "\n",
        "# Set to False to disable plot generation for llm-friendly outputs\n",
        "generate_plots = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enable this cell for local development version of ras-commander\n",
        "import os\n",
        "import sys      \n",
        "from pathlib import Path\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "sys.path.append(str(rascmdr_directory))\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "\n",
        "# Import RAS-Commander modules\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "from ras_commander import *\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Bald Eagle Creek Example Project\n",
        "\n",
        "This project contains both unsteady (Plan 01) and **steady state** (Plan 02) flow analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:02 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bald Eagle Creek project already exists\n",
            "Initialized project: BaldEagle\n"
          ]
        }
      ],
      "source": [
        "# Extract and initialize the Bald Eagle Creek project\n",
        "current_dir = Path.cwd()\n",
        "bald_eagle_path = current_dir / \"example_projects\" / \"Balde Eagle Creek\"\n",
        "\n",
        "# Extract project if needed\n",
        "if not bald_eagle_path.exists():\n",
        "    RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "    print(\"Extracted Bald Eagle Creek project\")\n",
        "else:\n",
        "    print(\"Bald Eagle Creek project already exists\")\n",
        "\n",
        "# Initialize the project\n",
        "init_ras_project(bald_eagle_path, \"6.6\")\n",
        "print(f\"Initialized project: {ras.project_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plans in this project:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>Program Version</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>Unsteady with Bridges and Dam</td>\\n', '      <td>02</td>\\n', '      <td>5.00</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>02</td>\\n', '      <td>Steady Flow Run</td>\\n', '      <td>None</td>\\n', '      <td>NaN</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  plan_number                     Plan Title unsteady_number Program Version\\n', '0          01  Unsteady with Bridges and Dam              02            5.00\\n', '1          02                Steady Flow Run            None             NaN']"
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View all plans in the project\n",
        "print(\"Plans in this project:\")\n",
        "ras.plan_df[['plan_number', 'Plan Title', 'unsteady_number', 'Program Version']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Steady State Plan (Plan 02)\n",
        "\n",
        "Execute the steady state plan if results don't already exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:02 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\n",
            "2025-12-02 21:09:02 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-12-02 21:09:02 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Plan 02 (Steady State)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 02\n",
            "2025-12-02 21:09:06 - ras_commander.RasCmdr - INFO - Total run time for plan 02: 3.72 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan 02 executed successfully\n"
          ]
        }
      ],
      "source": [
        "# Define plan number\n",
        "plan_number = \"02\"\n",
        "\n",
        "# Check if results exist\n",
        "plan02_hdf = bald_eagle_path / \"BaldEagle.p02.hdf\"\n",
        "\n",
        "if not plan02_hdf.exists():\n",
        "    print(f\"Running Plan {plan_number} (Steady State)...\")\n",
        "    success = RasCmdr.compute_plan(plan_number)\n",
        "    if success:\n",
        "        print(f\"Plan {plan_number} executed successfully\")\n",
        "    else:\n",
        "        print(f\"Plan {plan_number} execution failed\")\n",
        "else:\n",
        "    print(f\"Plan {plan_number} results already exist\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check if Plan Contains Steady State Results\n",
        "\n",
        "Use `is_steady_plan()` to verify the HDF contains steady state results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Plan 02 a steady state plan? True\n"
          ]
        }
      ],
      "source": [
        "# Check if this is a steady state plan\n",
        "is_steady = HdfResultsPlan.is_steady_plan(plan_number)\n",
        "print(f\"Is Plan {plan_number} a steady state plan? {is_steady}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extract Steady State Profile Names\n",
        "\n",
        "Get the list of all steady state profiles (e.g., different return periods)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n",
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Found 8 steady state profiles: ['.5 year', '1 year', '2 year', '5 year', '10 year', '25 year', '50 year', '100 year']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8 steady state profiles:\n",
            "  1. .5 year\n",
            "  2. 1 year\n",
            "  3. 2 year\n",
            "  4. 5 year\n",
            "  5. 10 year\n",
            "  6. 25 year\n",
            "  7. 50 year\n",
            "  8. 100 year\n"
          ]
        }
      ],
      "source": [
        "# Get profile names\n",
        "profiles = HdfResultsPlan.get_steady_profile_names(plan_number)\n",
        "\n",
        "print(f\"Found {len(profiles)} steady state profiles:\")\n",
        "for i, profile in enumerate(profiles, 1):\n",
        "    print(f\"  {i}. {profile}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Water Surface Elevations (WSE)\n",
        "\n",
        "Extract WSE data for specific profiles or all profiles at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3a. Extract Single Profile by Name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n",
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Extracted WSE data for 1 profile(s), 178 cross sections\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WSE Data for 100-year profile:\n",
            "Shape: (178, 4)\n",
            "Columns: ['River', 'Reach', 'Station', 'WSE']\n",
            "\n",
            "First 5 cross sections:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>River</th>\\n', '      <th>Reach</th>\\n', '      <th>Station</th>\\n', '      <th>WSE</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>138154.4</td>\\n', '      <td>669.521484</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>137690.8</td>\\n', '      <td>669.346863</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>137327.0</td>\\n', '      <td>668.883057</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>136564.9</td>\\n', '      <td>666.177979</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>136202.3</td>\\n', '      <td>666.057739</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['        River    Reach   Station         WSE\\n', '0  Bald Eagle  Loc Hav  138154.4  669.521484\\n', '1  Bald Eagle  Loc Hav  137690.8  669.346863\\n', '2  Bald Eagle  Loc Hav  137327.0  668.883057\\n', '3  Bald Eagle  Loc Hav  136564.9  666.177979\\n', '4  Bald Eagle  Loc Hav  136202.3  666.057739']"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract WSE for 100-year profile\n",
        "wse_100yr = HdfResultsPlan.get_steady_wse(plan_number, profile_name='100 year')\n",
        "\n",
        "print(f\"WSE Data for 100-year profile:\")\n",
        "print(f\"Shape: {wse_100yr.shape}\")\n",
        "print(f\"Columns: {list(wse_100yr.columns)}\")\n",
        "print(\"\\nFirst 5 cross sections:\")\n",
        "wse_100yr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3b. Extract Single Profile by Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n",
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Extracted WSE data for 1 profile(s), 178 cross sections\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WSE Data for .5 year profile:\n",
            "Shape: (178, 4)\n",
            "\n",
            "Summary statistics:\n"
          ]
        },
        {
          "data": {
            "text/plain": "['count    178.000000\\n', 'mean     590.215864\\n', 'std       39.202902\\n', 'min      537.500000\\n', '25%      557.109406\\n', '50%      579.655151\\n', '75%      623.142242\\n', 'max      660.588928\\n', 'Name: WSE, dtype: float64']"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract WSE for first profile (0.5-year) using index\n",
        "wse_05yr = HdfResultsPlan.get_steady_wse(plan_number, profile_index=0)\n",
        "\n",
        "print(f\"WSE Data for {profiles[0]} profile:\")\n",
        "print(f\"Shape: {wse_05yr.shape}\")\n",
        "print(\"\\nSummary statistics:\")\n",
        "wse_05yr['WSE'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3c. Extract All Profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n",
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Extracted WSE data for 8 profile(s), 178 cross sections\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WSE Data for all 8 profiles:\n",
            "Shape: (1424, 5)\n",
            "Columns: ['River', 'Reach', 'Station', 'Profile', 'WSE']\n",
            "\n",
            "Profiles included: ['.5 year', '1 year', '2 year', '5 year', '10 year', '25 year', '50 year', '100 year']\n",
            "\n",
            "Sample data:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>River</th>\\n', '      <th>Reach</th>\\n', '      <th>Station</th>\\n', '      <th>Profile</th>\\n', '      <th>WSE</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>138154.4</td>\\n', '      <td>.5 year</td>\\n', '      <td>660.588928</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>137690.8</td>\\n', '      <td>.5 year</td>\\n', '      <td>659.914612</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>137327.0</td>\\n', '      <td>.5 year</td>\\n', '      <td>659.465759</td>\\n', '    </tr><tr>\\n', '      <th>3</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>136564.9</td>\\n', '      <td>.5 year</td>\\n', '      <td>658.126160</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>Bald Eagle</td>\\n', '      <td>Loc Hav</td>\\n', '      <td>136202.3</td>\\n', '      <td>.5 year</td>\\n', '      <td>657.173157</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['        River    Reach   Station  Profile         WSE\\n', '0  Bald Eagle  Loc Hav  138154.4  .5 year  660.588928\\n', '1  Bald Eagle  Loc Hav  137690.8  .5 year  659.914612\\n', '2  Bald Eagle  Loc Hav  137327.0  .5 year  659.465759\\n', '3  Bald Eagle  Loc Hav  136564.9  .5 year  658.126160\\n', '4  Bald Eagle  Loc Hav  136202.3  .5 year  657.173157\\n', '5  Bald Eagle  Loc Hav  135591.4  .5 year  656.520264\\n', '6  Bald Eagle  Loc Hav  135068.7  .5 year  655.880676\\n', '7  Bald Eagle  Loc Hav  134487.2  .5 year  654.593140\\n', '8  Bald Eagle  Loc Hav  133881.0  .5 year  653.786621\\n', '9  Bald Eagle  Loc Hav  133446.1  .5 year  653.006958']"
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract WSE for all profiles\n",
        "wse_all = HdfResultsPlan.get_steady_wse(plan_number)\n",
        "\n",
        "print(f\"WSE Data for all {len(profiles)} profiles:\")\n",
        "print(f\"Shape: {wse_all.shape}\")\n",
        "print(f\"Columns: {list(wse_all.columns)}\")\n",
        "print(f\"\\nProfiles included: {wse_all['Profile'].unique().tolist()}\")\n",
        "print(\"\\nSample data:\")\n",
        "wse_all.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Extract Steady Flow Metadata\n",
        "\n",
        "Get plan information, program version, solution status, and flow file details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Final validated file path: C:\\GH\\ras-commander\\examples\\example_projects\\Balde Eagle Creek\\BaldEagle.p02.hdf\n",
            "2025-12-02 21:09:06 - ras_commander.hdf.HdfResultsPlan - INFO - Extracted 8 steady state attributes\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steady Flow Information (8 attributes):\n",
            "\n",
            "Key attributes:\n",
            "  Program Version: HEC-RAS 6.6 September 2024\n",
            "  Solution: Steady Finished Successfully\n",
            "  Flow Title: Steady Flow Data\n",
            "  Flow Filename: BaldEagle.f02\n",
            "\n",
            "All attributes:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>0</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>Program Name</th>\\n', '      <td>HEC-RAS - River Analysis System</td>\\n', '    </tr><tr>\\n', '      <th>Program Version</th>\\n', '      <td>HEC-RAS 6.6 September 2024</td>\\n', '    </tr><tr>\\n', '      <th>Project File Name</th>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>Type of Run</th>\\n', '      <td>Steady Flow Analysis</td>\\n', '    </tr><tr>\\n', '      <th>Run Time Window</th>\\n', '      <td>02DEC2025 21:09:05 to 02DEC2025 21:09:06</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['                                                                   0\\n', 'Program Name                         HEC-RAS - River Analysis System\\n', 'Program Version                           HEC-RAS 6.6 September 2024\\n', 'Project File Name  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...\\n', 'Type of Run                                     Steady Flow Analysis\\n', 'Run Time Window             02DEC2025 21:09:05 to 02DEC2025 21:09:06\\n', 'Solution                                Steady Finished Successfully\\n', 'Flow Filename                                          BaldEagle.f02\\n', 'Flow Title                                          Steady Flow Data']"
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get steady flow information\n",
        "steady_info = HdfResultsPlan.get_steady_info(plan_number)\n",
        "\n",
        "print(f\"Steady Flow Information ({len(steady_info.columns)} attributes):\")\n",
        "print(\"\\nKey attributes:\")\n",
        "for col in ['Program Version', 'Solution', 'Flow Title', 'Flow Filename']:\n",
        "    if col in steady_info.columns:\n",
        "        print(f\"  {col}: {steady_info[col].values[0]}\")\n",
        "\n",
        "print(\"\\nAll attributes:\")\n",
        "steady_info.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Water Surface Profiles\n",
        "\n",
        "Plot WSE vs. station for different return periods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Profile Comparison (Maximum WSE):\n",
            "  .5 year   : 660.59 ft\n",
            "  1 year    : 661.43 ft\n",
            "  2 year    : 662.60 ft\n",
            "  5 year    : 664.67 ft\n",
            "  10 year   : 666.19 ft\n",
            "  25 year   : 667.46 ft\n",
            "  50 year   : 668.54 ft\n",
            "  100 year  : 669.52 ft\n"
          ]
        }
      ],
      "source": [
        "if generate_plots:\n",
        "    # Create a plot comparing all profiles\n",
        "    fig, ax = plt.subplots(figsize=(15, 8))\n",
        "    \n",
        "    # Plot each profile\n",
        "    for profile in profiles:\n",
        "        profile_data = wse_all[wse_all['Profile'] == profile]\n",
        "        # Convert station to numeric for plotting\n",
        "        stations = pd.to_numeric(profile_data['Station'], errors='coerce')\n",
        "        ax.plot(stations, profile_data['WSE'], label=profile, linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('River Station (ft)', fontsize=12)\n",
        "    ax.set_ylabel('Water Surface Elevation (ft)', fontsize=12)\n",
        "    ax.set_title('Steady State Water Surface Profiles\\nBald Eagle Creek', fontsize=14)\n",
        "    ax.legend(title='Return Period', loc='best', fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Invert X axis so upstream (higher stations) is on the left\n",
        "    ax.invert_xaxis()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print profile comparison stats\n",
        "    print(\"\\nProfile Comparison (Maximum WSE):\")\n",
        "    for profile in profiles:\n",
        "        max_wse = wse_all[wse_all['Profile'] == profile]['WSE'].max()\n",
        "        print(f\"  {profile:10s}: {max_wse:.2f} ft\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Analyze WSE Differences Between Profiles\n",
        "\n",
        "Compare water surface elevations between different return periods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Water Surface Elevations by Profile and Station:\n",
            "\n",
            "First 10 stations:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th>Profile</th>\\n', '      <th>.5 year</th>\\n', '      <th>1 year</th>\\n', '      <th>10 year</th>\\n', '      <th>100 year</th>\\n', '      <th>2 year</th>\\n', '      <th>25 year</th>\\n', '      <th>5 year</th>\\n', '      <th>50 year</th>\\n', '    </tr>\\n', '    <tr>\\n', '      <th>River</th>\\n', '      <th>Reach</th>\\n', '      <th>Station</th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '      <th></th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th rowspan=\"10\" valign=\"top\">Bald Eagle</th>\\n', '      <th rowspan=\"10\" valign=\"top\">Loc Hav</th>\\n', '      <th>100657.3</th>\\n', '      <td>620.031982</td>\\n', '      <td>657.029053</td>\\n', '      <td>660.006348</td>\\n', '      <td>662.170227</td>\\n', '      <td>657.916138</td>\\n', '      <td>660.793945</td>\\n', '      <td>659.094055</td>\\n', '      <td>661.508545</td>\\n', '    </tr><tr>\\n', '      <th>101440.3</th>\\n', '      <td>620.033875</td>\\n', '      <td>657.029053</td>\\n', '      <td>660.006470</td>\\n', '      <td>662.170593</td>\\n', '      <td>657.916138</td>\\n', '      <td>660.794067</td>\\n', '      <td>659.094116</td>\\n', '      <td>661.508850</td>\\n', '    </tr><tr>\\n', '      <th>10221.14</th>\\n', '      <td>540.174683</td>\\n', '      <td>541.939697</td>\\n', '      <td>556.019287</td>\\n', '      <td>563.945190</td>\\n', '      <td>544.468933</td>\\n', '      <td>559.538452</td>\\n', '      <td>550.165833</td>\\n', '      <td>561.924500</td>\\n', '    </tr><tr>\\n', '      <th>103122.3</th>\\n', '      <td>620.044861</td>\\n', '      <td>657.029053</td>\\n', '      <td>660.006836</td>\\n', '      <td>662.171753</td>\\n', '      <td>657.916138</td>\\n', '      <td>660.794678</td>\\n', '      <td>659.094299</td>\\n', '      <td>661.509705</td>\\n', '    </tr><tr>\\n', '      <th>103369.7</th>\\n', '      <td>620.055420</td>\\n', '      <td>657.029480</td>\\n', '      <td>660.012878</td>\\n', '      <td>662.186707</td>\\n', '      <td>657.917175</td>\\n', '      <td>660.803711</td>\\n', '      <td>659.097473</td>\\n', '      <td>661.521729</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['Profile                         .5 year      1 year     10 year    100 year  \\\\\\n', 'River      Reach   Station                                                    \\n', 'Bald Eagle Loc Hav 100657.3  620.031982  657.029053  660.006348  662.170227   \\n', '                   101440.3  620.033875  657.029053  660.006470  662.170593   \\n', '                   10221.14  540.174683  541.939697  556.019287  563.945190   \\n', '                   103122.3  620.044861  657.029053  660.006836  662.171753   \\n', '                   103369.7  620.055420  657.029480  660.012878  662.186707   \\n', '                   103854.0  620.059082  657.029480  660.012939  662.187012   \\n', '                   104195.0  620.059875  657.029480  660.012878  662.186829   \\n', '                   104647.2  620.066528  657.029480  660.013000  662.187378   \\n', '                   105178.6  620.075806  657.029480  660.013367  662.188599   \\n', '                   106466.0  620.093262  657.029419  660.013428  662.1887\n...\n[Output truncated, 2009 characters total]"
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a pivot table for easy comparison\n",
        "wse_pivot = wse_all.pivot_table(\n",
        "    index=['River', 'Reach', 'Station'],\n",
        "    columns='Profile',\n",
        "    values='WSE'\n",
        ")\n",
        "\n",
        "print(\"Water Surface Elevations by Profile and Station:\")\n",
        "print(\"\\nFirst 10 stations:\")\n",
        "wse_pivot.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Difference between 100-year and 0.5-year profiles:\n",
            "  Maximum difference: 42.14 ft\n",
            "  Minimum difference: 7.90 ft\n",
            "  Average difference: 21.62 ft\n",
            "\n",
            "Stations with largest differences:\n",
            "Profile                        100 year     .5 year  Diff_100yr_vs_05yr\n",
            "River      Reach   Station                                             \n",
            "Bald Eagle Loc Hav 96370.43  662.169006  620.027832           42.141174\n",
            "                   94560.01  662.168457  620.027466           42.140991\n",
            "                   93391.71  662.167664  620.027283           42.140381\n",
            "                   97607.35  662.168640  620.028320           42.140320\n",
            "                   98206.87  662.169983  620.029846           42.140137\n"
          ]
        }
      ],
      "source": [
        "# Calculate differences between profiles\n",
        "if '100 year' in wse_pivot.columns and '.5 year' in wse_pivot.columns:\n",
        "    wse_pivot['Diff_100yr_vs_05yr'] = wse_pivot['100 year'] - wse_pivot['.5 year']\n",
        "    \n",
        "    print(\"\\nDifference between 100-year and 0.5-year profiles:\")\n",
        "    print(f\"  Maximum difference: {wse_pivot['Diff_100yr_vs_05yr'].max():.2f} ft\")\n",
        "    print(f\"  Minimum difference: {wse_pivot['Diff_100yr_vs_05yr'].min():.2f} ft\")\n",
        "    print(f\"  Average difference: {wse_pivot['Diff_100yr_vs_05yr'].mean():.2f} ft\")\n",
        "    \n",
        "    print(\"\\nStations with largest differences:\")\n",
        "    top_diff = wse_pivot.nlargest(5, 'Diff_100yr_vs_05yr')[['100 year', '.5 year', 'Diff_100yr_vs_05yr']]\n",
        "    print(top_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated the new steady state functionality in ras-commander:\n",
        "\n",
        "1. \u2705 Checked if a plan contains steady state results\n",
        "2. \u2705 Extracted profile names for different return periods\n",
        "3. \u2705 Retrieved WSE data for individual and all profiles\n",
        "4. \u2705 Accessed steady flow metadata and attributes\n",
        "5. \u2705 Visualized water surface profiles\n",
        "6. \u2705 Analyzed differences between profiles\n",
        "\n",
        "These tools enable comprehensive steady state flow analysis and comparison of hydraulic conditions across different design storms or flow scenarios."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\20_plaintext_geometry_operations.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:15.924893Z",
          "iopub.status.busy": "2025-11-17T17:43:15.924374Z",
          "iopub.status.idle": "2025-11-17T17:43:18.494495Z",
          "shell.execute_reply": "2025-11-17T17:43:18.493987Z"
        }
      },
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Guide to HEC-RAS Geometry Operations\n",
        "\n",
        "This notebook demonstrates comprehensive geometry parsing and manipulation capabilities using the RasGeometry and HdfHydraulicTables classes. We'll explore how to extract, analyze, and modify various geometry types from HEC-RAS files.\n",
        "\n",
        "## Operations Covered\n",
        "\n",
        "1. **Cross Section Operations**: Extract and modify station/elevation data\n",
        "2. **Hydraulic Property Tables (HTAB)**: Generate rating curves from preprocessed geometry\n",
        "3. **Storage Areas**: Extract elevation-volume curves for reservoirs and detention basins\n",
        "4. **Lateral Structures**: Analyze overflow weirs and lateral connections\n",
        "5. **SA/2D Connections**: Extract dam breach connections, weir profiles, and gates\n",
        "6. **Batch Processing**: Automate operations across multiple geometry elements\n",
        "\n",
        "These capabilities enable:\n",
        "- Automated geometry modification for sensitivity studies\n",
        "- Rating curve generation without re-running HEC-RAS\n",
        "- Dam breach and detention basin analysis\n",
        "- Model setup validation and QA/QC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Package Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.497163Z",
          "iopub.status.busy": "2025-11-17T17:43:18.496747Z",
          "iopub.status.idle": "2025-11-17T17:43:18.501218Z",
          "shell.execute_reply": "2025-11-17T17:43:18.500710Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "# Add ras-commander to path (for local development)\n",
        "current_file = Path.cwd()\n",
        "ras_commander_root = current_file.parent\n",
        "sys.path.insert(0, str(ras_commander_root))\n",
        "\n",
        "# Import RAS Commander geometry modules\n",
        "from ras_commander import (\n",
        "    RasGeometry,\n",
        "    RasGeometryUtils,\n",
        "    HdfHydraulicTables,\n",
        "    RasExamples,\n",
        "    init_ras_project,\n",
        "    RasCmdr,\n",
        "    ras\n",
        ")\n",
        "\n",
        "print(\"\u2713 Packages loaded successfully!\")\n",
        "print(f\"Working directory: {Path.cwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Cross Section Operations\n",
        "\n",
        "Cross sections define the channel geometry in 1D models. We'll explore how to list cross sections, extract their station/elevation data, and modify them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.503421Z",
          "iopub.status.busy": "2025-11-17T17:43:18.503158Z",
          "iopub.status.idle": "2025-11-17T17:43:18.607554Z",
          "shell.execute_reply": "2025-11-17T17:43:18.606901Z"
        }
      },
      "outputs": [],
      "source": [
        "bald_eagle_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "print(bald_eagle_path)\n",
        "init_ras_project(bald_eagle_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.610230Z",
          "iopub.status.busy": "2025-11-17T17:43:18.609921Z",
          "iopub.status.idle": "2025-11-17T17:43:18.622596Z",
          "shell.execute_reply": "2025-11-17T17:43:18.622128Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.625332Z",
          "iopub.status.busy": "2025-11-17T17:43:18.625053Z",
          "iopub.status.idle": "2025-11-17T17:43:18.631811Z",
          "shell.execute_reply": "2025-11-17T17:43:18.631242Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Setup: Define Geometry File Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.634411Z",
          "iopub.status.busy": "2025-11-17T17:43:18.633914Z",
          "iopub.status.idle": "2025-11-17T17:43:18.638831Z",
          "shell.execute_reply": "2025-11-17T17:43:18.638391Z"
        }
      },
      "outputs": [],
      "source": [
        "# Lookup geometry file path and HDF path from ras.geom_df by geom_number\n",
        "geom_number = \"01\"\n",
        "geom_row = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number].iloc[0]\n",
        "\n",
        "geom_file = Path(geom_row[\"full_path\"])\n",
        "geom_hdf = Path(geom_row[\"hdf_path\"])\n",
        "\n",
        "print(f\"Geometry file: {geom_file}\")\n",
        "print(f\"File exists: {geom_file.exists()}\")\n",
        "if geom_file.exists():\n",
        "    print(f\"File size: {geom_file.stat().st_size / 1024:.1f} KB\")\n",
        "else:\n",
        "    print(\"Geometry file does not exist!\")\n",
        "print(f\"HDF file: {geom_hdf}\")\n",
        "print(f\"HDF exists: {geom_hdf.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 List All Cross Sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.641447Z",
          "iopub.status.busy": "2025-11-17T17:43:18.641092Z",
          "iopub.status.idle": "2025-11-17T17:43:18.669169Z",
          "shell.execute_reply": "2025-11-17T17:43:18.668693Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract all cross sections\n",
        "xs_df = RasGeometry.get_cross_sections(geom_file)\n",
        "\n",
        "print(f\"Total cross sections: {len(xs_df)}\")\n",
        "print(f\"Rivers: {xs_df['River'].unique().tolist()}\")\n",
        "print(f\"Reaches: {xs_df['Reach'].unique().tolist()}\")\n",
        "\n",
        "print(\"\\nFirst 10 cross sections:\")\n",
        "display.display(xs_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Extract Station/Elevation for a Cross Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.671323Z",
          "iopub.status.busy": "2025-11-17T17:43:18.671106Z",
          "iopub.status.idle": "2025-11-17T17:43:18.682170Z",
          "shell.execute_reply": "2025-11-17T17:43:18.681713Z"
        }
      },
      "outputs": [],
      "source": [
        "# Select first cross section\n",
        "first_xs = xs_df.iloc[0]\n",
        "river = first_xs['River']\n",
        "reach = first_xs['Reach']\n",
        "rs = first_xs['RS']\n",
        "\n",
        "print(f\"Selected cross section: {river} / {reach} / RS {rs}\")\n",
        "\n",
        "# Extract station/elevation data\n",
        "sta_elev = RasGeometry.get_station_elevation(geom_file, river, reach, rs)\n",
        "\n",
        "print(f\"\\nStation/Elevation Data:\")\n",
        "print(f\"  Points: {len(sta_elev)}\")\n",
        "print(f\"  Station range: {sta_elev['Station'].min():.2f} to {sta_elev['Station'].max():.2f} ft\")\n",
        "print(f\"  Elevation range: {sta_elev['Elevation'].min():.2f} to {sta_elev['Elevation'].max():.2f} ft\")\n",
        "print(f\"  Channel width: {sta_elev['Station'].max() - sta_elev['Station'].min():.2f} ft\")\n",
        "\n",
        "print(\"\\nFirst 10 points:\")\n",
        "display.display(sta_elev.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Visualize Cross Section Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.684431Z",
          "iopub.status.busy": "2025-11-17T17:43:18.684049Z",
          "iopub.status.idle": "2025-11-17T17:43:18.856972Z",
          "shell.execute_reply": "2025-11-17T17:43:18.856416Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot cross section profile\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "ax.plot(sta_elev['Station'], sta_elev['Elevation'], 'b-', linewidth=2, label='Cross Section')\n",
        "ax.fill_between(sta_elev['Station'], sta_elev['Elevation'],\n",
        "                 sta_elev['Elevation'].min() - 5,\n",
        "                 alpha=0.3)\n",
        "\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlabel('Station (ft)', fontsize=12)\n",
        "ax.set_ylabel('Elevation (ft)', fontsize=12)\n",
        "ax.set_title(f'Cross Section Profile: {river} / {reach} / RS {rs}',\n",
        "             fontsize=14, fontweight='bold')\n",
        "\n",
        "# Add statistics annotation\n",
        "stats_text = f'Points: {len(sta_elev)}\\n'\n",
        "stats_text += f'Width: {sta_elev[\"Station\"].max() - sta_elev[\"Station\"].min():.1f} ft\\n'\n",
        "stats_text += f'Elev Range: {sta_elev[\"Elevation\"].min():.1f} - {sta_elev[\"Elevation\"].max():.1f} ft'\n",
        "ax.text(0.02, 0.98, stats_text,\n",
        "        transform=ax.transAxes,\n",
        "        verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
        "        fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 Modify Cross Section Geometry (Round-Trip Example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.859568Z",
          "iopub.status.busy": "2025-11-17T17:43:18.859317Z",
          "iopub.status.idle": "2025-11-17T17:43:18.863036Z",
          "shell.execute_reply": "2025-11-17T17:43:18.862455Z"
        }
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell modifies the geometry file!\n",
        "# Uncomment to actually modify the file (backup is created automatically)\n",
        "\n",
        "# # Read original data\n",
        "# original_sta_elev = RasGeometry.get_station_elevation(geom_file, river, reach, rs)\n",
        "# print(f\"Original mean elevation: {original_sta_elev['Elevation'].mean():.3f} ft\")\n",
        "\n",
        "# # Modify elevations (raise by 1 foot)\n",
        "# modified_sta_elev = original_sta_elev.copy()\n",
        "# modified_sta_elev['Elevation'] += 1.0\n",
        "\n",
        "# # Write back to file (creates .bak backup automatically)\n",
        "# RasGeometry.set_station_elevation(geom_file, river, reach, rs, modified_sta_elev)\n",
        "# print(f\"\\n\u2713 Modified geometry written to file\")\n",
        "# print(f\"  Backup created: {geom_file}.bak\")\n",
        "\n",
        "# # Verify round-trip\n",
        "# readback_sta_elev = RasGeometry.get_station_elevation(geom_file, river, reach, rs)\n",
        "# print(f\"\\nReadback mean elevation: {readback_sta_elev['Elevation'].mean():.3f} ft\")\n",
        "# print(f\"Difference: {abs(modified_sta_elev['Elevation'].mean() - readback_sta_elev['Elevation'].mean()):.6f} ft\")\n",
        "\n",
        "# # Restore original (using backup)\n",
        "# import shutil\n",
        "# shutil.copy2(str(geom_file) + '.bak', geom_file)\n",
        "# print(f\"\\n\u2713 Original geometry restored from backup\")\n",
        "\n",
        "print(\"Modification example is commented out to protect geometry file.\")\n",
        "print(\"Uncomment the code above to test round-trip operations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Hydraulic Property Tables (HTAB)\n",
        "\n",
        "Property tables contain preprocessed hydraulic properties (area, conveyance, wetted perimeter, etc.) as functions of elevation. These enable hydraulic analysis without re-running HEC-RAS.\n",
        "\n",
        "**IMPORTANT:** Property tables only exist in preprocessed geometry HDF files. Run `RasCmdr.compute_plan()` to generate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Generate Preprocessed Geometry HDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:43:18.865449Z",
          "iopub.status.busy": "2025-11-17T17:43:18.865115Z",
          "iopub.status.idle": "2025-11-17T17:44:57.044563Z",
          "shell.execute_reply": "2025-11-17T17:44:57.043803Z"
        }
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell runs HEC-RAS and may take 1-2 minutes!\n",
        "# Uncomment to generate preprocessed HDF\n",
        "\n",
        "# Extract and initialize project\n",
        "project_path = RasExamples.extract_project(\"Balde Eagle Creek\")\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "# Compute plan to generate preprocessed geometry HDF\n",
        "print(\"Computing plan 01 to generate preprocessed geometry HDF...\")\n",
        "print(\"(This may take 1-2 minutes)\\n\")\n",
        "result = RasCmdr.compute_plan(\"01\")\n",
        "\n",
        "if result:\n",
        "    geom_hdf = ras.geom_df.iloc[0]['full_path'] + '.hdf'\n",
        "    print(f\"\\n\u2713 Preprocessed HDF created: {Path(geom_hdf).name}\")\n",
        "    print(f\"  Location: {geom_hdf}\")\n",
        "else:\n",
        "    print(\"ERROR: Plan computation failed\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Extract HTAB for a Cross Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:44:57.047143Z",
          "iopub.status.busy": "2025-11-17T17:44:57.046705Z",
          "iopub.status.idle": "2025-11-17T17:44:57.074674Z",
          "shell.execute_reply": "2025-11-17T17:44:57.073946Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract hydraulic property table\n",
        "river = \"Bald Eagle\"\n",
        "reach = \"Loc Hav\"\n",
        "rs = \"138154.4\"\n",
        "\n",
        "htab = HdfHydraulicTables.get_xs_htab(geom_hdf, river, reach, rs)\n",
        "\n",
        "print(f\"Hydraulic Property Table for {river} / {reach} / RS {rs}\")\n",
        "print(f\"\\nTable dimensions: {len(htab)} elevations \u00d7 {len(htab.columns)} properties\")\n",
        "print(f\"Elevation range: {htab['Elevation'].min():.2f} to {htab['Elevation'].max():.2f} ft\")\n",
        "\n",
        "print(\"\\nAvailable properties:\")\n",
        "for col in htab.columns:\n",
        "    print(f\"  - {col}\")\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display.display(htab.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Generate Rating Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:44:57.077186Z",
          "iopub.status.busy": "2025-11-17T17:44:57.076944Z",
          "iopub.status.idle": "2025-11-17T17:44:57.469189Z",
          "shell.execute_reply": "2025-11-17T17:44:57.468645Z"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate hydraulic radius\n",
        "htab['Hydraulic_Radius'] = htab['Area_Total'] / htab['Wetted_Perimeter_Total']\n",
        "htab['Hydraulic_Radius'] = htab['Hydraulic_Radius'].replace([np.inf, -np.inf], 0)\n",
        "\n",
        "# Create 4-panel rating curve plot\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Area vs Elevation\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(htab['Area_Total'], htab['Elevation'], 'b-', linewidth=2)\n",
        "ax1.fill_betweenx(htab['Elevation'], 0, htab['Area_Total'], alpha=0.3)\n",
        "ax1.set_xlabel('Flow Area (sq ft)', fontsize=11)\n",
        "ax1.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "ax1.set_title('Area-Elevation Curve', fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Conveyance vs Elevation\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(htab['Conveyance_Total'], htab['Elevation'], 'g-', linewidth=2)\n",
        "ax2.fill_betweenx(htab['Elevation'], 0, htab['Conveyance_Total'], alpha=0.3, color='green')\n",
        "ax2.set_xlabel('Conveyance (cfs)', fontsize=11)\n",
        "ax2.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "ax2.set_title('Conveyance-Elevation Curve', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Top Width vs Elevation\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(htab['Top_Width'], htab['Elevation'], 'r-', linewidth=2)\n",
        "ax3.fill_betweenx(htab['Elevation'], 0, htab['Top_Width'], alpha=0.3, color='red')\n",
        "ax3.set_xlabel('Top Width (ft)', fontsize=11)\n",
        "ax3.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "ax3.set_title('Top Width-Elevation Curve', fontsize=12, fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Hydraulic Radius vs Elevation\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(htab['Hydraulic_Radius'], htab['Elevation'], 'm-', linewidth=2)\n",
        "ax4.fill_betweenx(htab['Elevation'], 0, htab['Hydraulic_Radius'], alpha=0.3, color='purple')\n",
        "ax4.set_xlabel('Hydraulic Radius (ft)', fontsize=11)\n",
        "ax4.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "ax4.set_title('Hydraulic Radius-Elevation Curve', fontsize=12, fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "fig.suptitle(f'Hydraulic Property Curves: {river} / {reach} / RS {rs}',\n",
        "             fontsize=14, fontweight='bold', y=0.995)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nMaximum Hydraulic Properties:\")\n",
        "print(f\"  Max Area: {htab['Area_Total'].max():.1f} sq ft\")\n",
        "print(f\"  Max Conveyance: {htab['Conveyance_Total'].max():.1f} cfs\")\n",
        "print(f\"  Max Hydraulic Radius: {htab['Hydraulic_Radius'].max():.2f} ft\")\n",
        "print(f\"  Max Top Width: {htab['Top_Width'].max():.1f} ft\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Find Hydraulic Properties at Specific Elevation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:44:57.471161Z",
          "iopub.status.busy": "2025-11-17T17:44:57.470937Z",
          "iopub.status.idle": "2025-11-17T17:44:57.476034Z",
          "shell.execute_reply": "2025-11-17T17:44:57.475617Z"
        }
      },
      "outputs": [],
      "source": [
        "# Find properties at specific water surface elevation\n",
        "target_elev = 665.0\n",
        "\n",
        "# Find closest elevation in table\n",
        "idx = (htab['Elevation'] - target_elev).abs().idxmin()\n",
        "actual_elev = htab.loc[idx, 'Elevation']\n",
        "\n",
        "print(f\"Target elevation: {target_elev:.2f} ft\")\n",
        "print(f\"Closest table elevation: {actual_elev:.2f} ft\\n\")\n",
        "\n",
        "print(f\"Hydraulic properties at elevation {actual_elev:.2f} ft:\")\n",
        "print(f\"  Flow Area: {htab.loc[idx, 'Area_Total']:.1f} sq ft\")\n",
        "print(f\"  Conveyance: {htab.loc[idx, 'Conveyance_Total']:.1f} cfs\")\n",
        "print(f\"  Wetted Perimeter: {htab.loc[idx, 'Wetted_Perimeter_Total']:.1f} ft\")\n",
        "print(f\"  Top Width: {htab.loc[idx, 'Top_Width']:.1f} ft\")\n",
        "print(f\"  Hydraulic Radius: {htab.loc[idx, 'Hydraulic_Radius']:.2f} ft\")\n",
        "print(f\"  Velocity Coefficient (Alpha): {htab.loc[idx, 'Alpha']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Batch Extract HTABs for Multiple Cross Sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:44:57.478088Z",
          "iopub.status.busy": "2025-11-17T17:44:57.477901Z",
          "iopub.status.idle": "2025-11-17T17:44:58.072795Z",
          "shell.execute_reply": "2025-11-17T17:44:58.072089Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract HTABs for all cross sections\n",
        "print(\"Extracting property tables for all cross sections...\")\n",
        "print(\"(This may take a few seconds)\\n\")\n",
        "\n",
        "all_htabs = HdfHydraulicTables.get_all_xs_htabs(geom_hdf)\n",
        "\n",
        "print(f\"Total HTABs extracted: {len(all_htabs)}\")\n",
        "\n",
        "# Calculate statistics across all cross sections\n",
        "stats_list = []\n",
        "for (river, reach, rs), htab_df in list(all_htabs.items())[:10]:  # First 10 for demo\n",
        "    htab_df['Hydraulic_Radius'] = htab_df['Area_Total'] / htab_df['Wetted_Perimeter_Total']\n",
        "    htab_df['Hydraulic_Radius'] = htab_df['Hydraulic_Radius'].replace([np.inf, -np.inf], 0)\n",
        "\n",
        "    stats_list.append({\n",
        "        'RS': rs,\n",
        "        'Max_Area': htab_df['Area_Total'].max(),\n",
        "        'Max_Conveyance': htab_df['Conveyance_Total'].max(),\n",
        "        'Max_Hydraulic_Radius': htab_df['Hydraulic_Radius'].max(),\n",
        "        'Num_Elevations': len(htab_df)\n",
        "    })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_list)\n",
        "\n",
        "print(\"\\nStatistics for first 10 cross sections:\")\n",
        "display.display(stats_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Storage Area Operations\n",
        "\n",
        "Storage areas represent reservoirs, detention basins, or other storage volumes. We'll extract elevation-volume curves that define storage capacity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 List Storage Areas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change to Geometry 12 (SA to 2D Connection) of BaldEagleCrkMulti2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:44:58.075854Z",
          "iopub.status.busy": "2025-11-17T17:44:58.075606Z",
          "iopub.status.idle": "2025-11-17T17:45:00.300360Z",
          "shell.execute_reply": "2025-11-17T17:45:00.299942Z"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Set extraction path for storage area operations\n",
        "storageareasoperations_path = Path.cwd() / \"example_projects\" / \"StorageAreaOperations\"\n",
        "\n",
        "# Extract the example project to the designated folder\n",
        "bald_eagle2D_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\", output_path=storageareasoperations_path)\n",
        "print(bald_eagle2D_path)\n",
        "\n",
        "init_ras_project(bald_eagle2D_path)\n",
        "\n",
        "geom_number = \"12\"\n",
        "geom_row = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number].iloc[0]\n",
        "\n",
        "geom_file = Path(geom_row[\"full_path\"])\n",
        "geom_hdf = Path(geom_row[\"hdf_path\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.302501Z",
          "iopub.status.busy": "2025-11-17T17:45:00.302264Z",
          "iopub.status.idle": "2025-11-17T17:45:00.308795Z",
          "shell.execute_reply": "2025-11-17T17:45:00.308194Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.311039Z",
          "iopub.status.busy": "2025-11-17T17:45:00.310801Z",
          "iopub.status.idle": "2025-11-17T17:45:00.329838Z",
          "shell.execute_reply": "2025-11-17T17:45:00.329297Z"
        }
      },
      "outputs": [],
      "source": [
        "# Path to dam breach geometry with storage areas\n",
        "dam_geom_file = geom_file\n",
        "\n",
        "print(f\"Geometry file: {dam_geom_file.name}\")\n",
        "\n",
        "# Get storage areas (excluding 2D flow areas)\n",
        "storage_areas = RasGeometry.get_storage_areas(dam_geom_file, exclude_2d=True)\n",
        "\n",
        "print(f\"\\nTraditional storage areas found: {len(storage_areas)}\")\n",
        "for i, name in enumerate(storage_areas, 1):\n",
        "    print(f\"  {i}. {name}\")\n",
        "\n",
        "# Get all storage areas (including 2D)\n",
        "all_storage = RasGeometry.get_storage_areas(dam_geom_file, exclude_2d=False)\n",
        "\n",
        "print(f\"\\nAll storage areas (including 2D): {len(all_storage)}\")\n",
        "for i, name in enumerate(all_storage, 1):\n",
        "    print(f\"  {i}. {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Extract Elevation-Volume Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.332749Z",
          "iopub.status.busy": "2025-11-17T17:45:00.332462Z",
          "iopub.status.idle": "2025-11-17T17:45:00.345364Z",
          "shell.execute_reply": "2025-11-17T17:45:00.344746Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get elevation-volume curve for first storage area\n",
        "if len(storage_areas) > 0:\n",
        "    area_name = storage_areas[0]\n",
        "\n",
        "    print(f\"Extracting elevation-volume curve for: {area_name}\")\n",
        "\n",
        "    elev_vol = RasGeometry.get_storage_elevation_volume(dam_geom_file, area_name)\n",
        "\n",
        "    print(f\"\\nStorage Curve Data:\")\n",
        "    print(f\"  Points: {len(elev_vol)}\")\n",
        "    print(f\"  Elevation range: {elev_vol['Elevation'].min():.2f} to {elev_vol['Elevation'].max():.2f} ft\")\n",
        "    print(f\"  Volume range: {elev_vol['Volume'].min():.0f} to {elev_vol['Volume'].max():.0f} cu ft\")\n",
        "\n",
        "    print(\"\\nFirst 10 points:\")\n",
        "    display.display(elev_vol.head(10))\n",
        "else:\n",
        "    print(\"No traditional storage areas found in this geometry file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Visualize Storage Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.348637Z",
          "iopub.status.busy": "2025-11-17T17:45:00.348280Z",
          "iopub.status.idle": "2025-11-17T17:45:00.553415Z",
          "shell.execute_reply": "2025-11-17T17:45:00.552873Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(storage_areas) > 0:\n",
        "    # Plot elevation-volume curve\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot 1: Volume vs Elevation\n",
        "    ax1.plot(elev_vol['Volume'], elev_vol['Elevation'], 'b-', linewidth=2)\n",
        "    ax1.fill_betweenx(elev_vol['Elevation'], 0, elev_vol['Volume'], alpha=0.3)\n",
        "    ax1.set_xlabel('Storage Volume (cu ft)', fontsize=11)\n",
        "    ax1.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "    ax1.set_title(f'Storage Curve: {area_name}', fontsize=12, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Incremental Storage (dV/dZ)\n",
        "    elev_vol['dV'] = elev_vol['Volume'].diff()\n",
        "    elev_vol['dZ'] = elev_vol['Elevation'].diff()\n",
        "    elev_vol['Surface_Area'] = elev_vol['dV'] / elev_vol['dZ']\n",
        "\n",
        "    ax2.plot(elev_vol['Surface_Area'], elev_vol['Elevation'], 'r-', linewidth=2)\n",
        "    ax2.fill_betweenx(elev_vol['Elevation'], 0, elev_vol['Surface_Area'], alpha=0.3, color='red')\n",
        "    ax2.set_xlabel('Surface Area (sq ft)', fontsize=11)\n",
        "    ax2.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "    ax2.set_title('Surface Area vs Elevation (dV/dZ)', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nStorage Statistics:\")\n",
        "    print(f\"  Total storage capacity: {elev_vol['Volume'].max():.0f} cu ft\")\n",
        "    print(f\"  Elevation range: {elev_vol['Elevation'].max() - elev_vol['Elevation'].min():.1f} ft\")\n",
        "    print(f\"  Average surface area: {elev_vol['Surface_Area'].mean():.0f} sq ft\")\n",
        "else:\n",
        "    print(\"Skipping storage visualization - no traditional storage areas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Lateral Structure Operations\n",
        "\n",
        "Lateral structures are overflow weirs or connections along the side of a channel. Common in urban drainage and irrigation systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Geometry XX in project XX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.555560Z",
          "iopub.status.busy": "2025-11-17T17:45:00.555317Z",
          "iopub.status.idle": "2025-11-17T17:45:00.933267Z",
          "shell.execute_reply": "2025-11-17T17:45:00.932774Z"
        }
      },
      "outputs": [],
      "source": [
        "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
        "print(muncie_path)\n",
        "\n",
        "init_ras_project(muncie_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.935212Z",
          "iopub.status.busy": "2025-11-17T17:45:00.934987Z",
          "iopub.status.idle": "2025-11-17T17:45:00.945400Z",
          "shell.execute_reply": "2025-11-17T17:45:00.944945Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.947252Z",
          "iopub.status.busy": "2025-11-17T17:45:00.947034Z",
          "iopub.status.idle": "2025-11-17T17:45:00.952359Z",
          "shell.execute_reply": "2025-11-17T17:45:00.951938Z"
        }
      },
      "outputs": [],
      "source": [
        "ras.geom_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.954173Z",
          "iopub.status.busy": "2025-11-17T17:45:00.953822Z",
          "iopub.status.idle": "2025-11-17T17:45:00.957279Z",
          "shell.execute_reply": "2025-11-17T17:45:00.956815Z"
        }
      },
      "outputs": [],
      "source": [
        "geom_number = \"01\"\n",
        "geom_row = ras.geom_df.loc[ras.geom_df['geom_number'] == geom_number].iloc[0]\n",
        "\n",
        "geom_file = Path(geom_row[\"full_path\"])\n",
        "geom_hdf = Path(geom_row[\"hdf_path\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 List Lateral Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.959556Z",
          "iopub.status.busy": "2025-11-17T17:45:00.959196Z",
          "iopub.status.idle": "2025-11-17T17:45:00.962144Z",
          "shell.execute_reply": "2025-11-17T17:45:00.961688Z"
        }
      },
      "outputs": [],
      "source": [
        "# Path to geometry with lateral structures\n",
        "lateral_geom_file = geom_file\n",
        "\n",
        "print(f\"Geometry file: {lateral_geom_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.964025Z",
          "iopub.status.busy": "2025-11-17T17:45:00.963639Z",
          "iopub.status.idle": "2025-11-17T17:45:00.982759Z",
          "shell.execute_reply": "2025-11-17T17:45:00.982328Z"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Extract lateral structures\n",
        "lat_strucs = RasGeometry.get_lateral_structures(lateral_geom_file)\n",
        "\n",
        "print(f\"\\nLateral structures found: {len(lat_strucs)}\")\n",
        "\n",
        "if len(lat_strucs) > 0:\n",
        "    print(\"\\nLateral structure inventory:\")\n",
        "    display.display(lat_strucs[['River', 'Reach', 'RS', 'Position', 'Width', 'Coefficient', 'Distance', 'Description']])\n",
        "else:\n",
        "    print(\"No lateral structures found in this geometry file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Extract and Visualize Lateral Weir Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:00.984720Z",
          "iopub.status.busy": "2025-11-17T17:45:00.984454Z",
          "iopub.status.idle": "2025-11-17T17:45:01.080629Z",
          "shell.execute_reply": "2025-11-17T17:45:01.080015Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(lat_strucs) > 0:\n",
        "    # Get profile for first lateral structure\n",
        "    first_lat = lat_strucs.iloc[0]\n",
        "    river = first_lat['River']\n",
        "    reach = first_lat['Reach']\n",
        "    rs = first_lat['RS']\n",
        "    position = first_lat['Position']\n",
        "\n",
        "    print(f\"Extracting lateral weir profile:\")\n",
        "    print(f\"  Location: {river} / {reach} / RS {rs}\")\n",
        "    print(f\"  Position: {position}\")\n",
        "    print(f\"  Description: {first_lat['Description']}\")\n",
        "\n",
        "    profile = RasGeometry.get_lateral_weir_profile(lateral_geom_file, river, reach, rs, position)\n",
        "\n",
        "    print(f\"\\nWeir Profile:\")\n",
        "    print(f\"  Points: {len(profile)}\")\n",
        "    print(f\"  Station range: {profile['Station'].min():.1f} to {profile['Station'].max():.1f} ft\")\n",
        "    print(f\"  Elevation range: {profile['Elevation'].min():.2f} to {profile['Elevation'].max():.2f} ft\")\n",
        "\n",
        "    # Plot weir profile\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(profile['Station'], profile['Elevation'], 'go-', linewidth=2, markersize=6)\n",
        "    ax.fill_between(profile['Station'], profile['Elevation'],\n",
        "                     profile['Elevation'].min() - 2, alpha=0.3, color='green')\n",
        "    ax.set_xlabel('Station (ft)', fontsize=11)\n",
        "    ax.set_ylabel('Weir Crest Elevation (ft)', fontsize=11)\n",
        "    ax.set_title(f'Lateral Weir Crest Profile: RS {rs}, Position {position}',\n",
        "                 fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping lateral weir visualization - no laterals found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: SA/2D Connection Operations\n",
        "\n",
        "Connections link storage areas to 2D flow areas for dam breach modeling, levee overtopping, and floodplain connectivity. We'll analyze connections, weir profiles, and gate structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 List All Connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.083154Z",
          "iopub.status.busy": "2025-11-17T17:45:01.082861Z",
          "iopub.status.idle": "2025-11-17T17:45:01.094111Z",
          "shell.execute_reply": "2025-11-17T17:45:01.093586Z"
        }
      },
      "outputs": [],
      "source": [
        "# Extract all connections\n",
        "connections = RasGeometry.get_connections(dam_geom_file)\n",
        "\n",
        "print(f\"SA/2D Connections found: {len(connections)}\")\n",
        "\n",
        "if len(connections) > 0:\n",
        "    print(\"\\nConnection inventory:\")\n",
        "    display.display(connections[['Connection_Name', 'Upstream_Area', 'Downstream_Area',\n",
        "                                  'Weir_Width', 'Weir_Coefficient', 'SE_Count', 'Num_Gates']])\n",
        "\n",
        "    print(\"\\nConnection summary:\")\n",
        "    print(f\"  Total weir width: {connections['Weir_Width'].sum():.1f} ft\")\n",
        "    print(f\"  Total gates: {connections['Num_Gates'].sum():.0f}\")\n",
        "    print(f\"  Weir coefficient range: {connections['Weir_Coefficient'].min():.2f} to {connections['Weir_Coefficient'].max():.2f}\")\n",
        "else:\n",
        "    print(\"No connections found in this geometry file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Extract Dam Crest Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.096545Z",
          "iopub.status.busy": "2025-11-17T17:45:01.096140Z",
          "iopub.status.idle": "2025-11-17T17:45:01.105911Z",
          "shell.execute_reply": "2025-11-17T17:45:01.105330Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(connections) > 0:\n",
        "    # Get weir profile for first connection\n",
        "    conn_name = connections.iloc[0]['Connection_Name']\n",
        "\n",
        "    print(f\"Extracting weir profile for connection: {conn_name}\")\n",
        "    print(f\"  Upstream: {connections.iloc[0]['Upstream_Area']}\")\n",
        "    print(f\"  Downstream: {connections.iloc[0]['Downstream_Area']}\")\n",
        "\n",
        "    weir_profile = RasGeometry.get_connection_weir_profile(dam_geom_file, conn_name)\n",
        "\n",
        "    print(f\"\\nWeir/Dam Crest Profile:\")\n",
        "    print(f\"  Points: {len(weir_profile)}\")\n",
        "    print(f\"  Station range: {weir_profile['Station'].min():.1f} to {weir_profile['Station'].max():.1f} ft\")\n",
        "    print(f\"  Elevation range: {weir_profile['Elevation'].min():.2f} to {weir_profile['Elevation'].max():.2f} ft\")\n",
        "    print(f\"  Crest length: {weir_profile['Station'].max() - weir_profile['Station'].min():.1f} ft\")\n",
        "\n",
        "    print(\"\\nFirst 10 points:\")\n",
        "    display.display(weir_profile.head(10))\n",
        "else:\n",
        "    print(\"Skipping weir profile extraction - no connections found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Visualize Dam Crest Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.108118Z",
          "iopub.status.busy": "2025-11-17T17:45:01.107855Z",
          "iopub.status.idle": "2025-11-17T17:45:01.237014Z",
          "shell.execute_reply": "2025-11-17T17:45:01.236378Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(connections) > 0:\n",
        "    # Plot weir/dam crest profile\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    ax.plot(weir_profile['Station'], weir_profile['Elevation'],\n",
        "            'ro-', linewidth=2, markersize=6, label='Dam Crest')\n",
        "    ax.fill_between(weir_profile['Station'], weir_profile['Elevation'],\n",
        "                     weir_profile['Elevation'].min() - 10,\n",
        "                     alpha=0.3, color='brown')\n",
        "\n",
        "    ax.set_xlabel('Station Along Dam (ft)', fontsize=12)\n",
        "    ax.set_ylabel('Crest Elevation (ft)', fontsize=12)\n",
        "    ax.set_title(f'Dam Crest Profile: {conn_name}',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend(fontsize=10)\n",
        "\n",
        "    # Add statistics\n",
        "    stats_text = f'Points: {len(weir_profile)}\\n'\n",
        "    stats_text += f'Length: {weir_profile[\"Station\"].max() - weir_profile[\"Station\"].min():.1f} ft\\n'\n",
        "    stats_text += f'Elev Range: {weir_profile[\"Elevation\"].min():.1f} - {weir_profile[\"Elevation\"].max():.1f} ft\\n'\n",
        "    stats_text += f'Weir Coef: {connections.iloc[0][\"Weir_Coefficient\"]:.2f}'\n",
        "    ax.text(0.02, 0.98, stats_text,\n",
        "            transform=ax.transAxes,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
        "            fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping visualization - no connections\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Extract Gate Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.239262Z",
          "iopub.status.busy": "2025-11-17T17:45:01.239049Z",
          "iopub.status.idle": "2025-11-17T17:45:01.437455Z",
          "shell.execute_reply": "2025-11-17T17:45:01.436925Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(connections) > 0:\n",
        "    # Check which connections have gates\n",
        "    conn_with_gates = connections[connections['Num_Gates'] > 0]\n",
        "\n",
        "    if len(conn_with_gates) > 0:\n",
        "        # Get gates for first connection with gates\n",
        "        conn_name_with_gates = conn_with_gates.iloc[0]['Connection_Name']\n",
        "\n",
        "        print(f\"Extracting gates for connection: {conn_name_with_gates}\")\n",
        "\n",
        "        gates = RasGeometry.get_connection_gates(dam_geom_file, conn_name_with_gates)\n",
        "\n",
        "        print(f\"\\nGates found: {len(gates)}\")\n",
        "\n",
        "        if len(gates) > 0:\n",
        "            print(\"\\nGate parameters:\")\n",
        "            display.display(gates[['Gate_Name', 'Width', 'Height', 'Invert', 'Gate_Coefficient']])\n",
        "\n",
        "            # Visualize gate geometry\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "            for idx, gate in gates.iterrows():\n",
        "                # Draw gate as rectangle\n",
        "                width = gate['Width']\n",
        "                height = gate['Height']\n",
        "                invert = gate['Invert']\n",
        "\n",
        "                rect = plt.Rectangle((idx * 20, invert), width, height,\n",
        "                                      linewidth=2, edgecolor='blue',\n",
        "                                      facecolor='lightblue', alpha=0.5)\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                # Label gate\n",
        "                ax.text(idx * 20 + width/2, invert + height + 2,\n",
        "                        gate['Gate_Name'],\n",
        "                        ha='center', fontsize=10, fontweight='bold')\n",
        "                ax.text(idx * 20 + width/2, invert + height/2,\n",
        "                        f\"{width}' \u00d7 {height}'\\nInvert: {invert}'\",\n",
        "                        ha='center', va='center', fontsize=9)\n",
        "\n",
        "            ax.set_xlim(-5, len(gates) * 20 + 15)\n",
        "            ax.set_ylim(invert - 10, invert + height + 20)\n",
        "            ax.set_xlabel('Position', fontsize=11)\n",
        "            ax.set_ylabel('Elevation (ft)', fontsize=11)\n",
        "            ax.set_title(f'Gate Configuration: {conn_name_with_gates}',\n",
        "                         fontsize=12, fontweight='bold')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            ax.set_aspect('equal')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"No gates found in any connections\")\n",
        "else:\n",
        "    print(\"Skipping gate extraction - no connections\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Analyze All Connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.439845Z",
          "iopub.status.busy": "2025-11-17T17:45:01.439548Z",
          "iopub.status.idle": "2025-11-17T17:45:01.451004Z",
          "shell.execute_reply": "2025-11-17T17:45:01.450566Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(connections) > 0:\n",
        "    # Extract profiles for all connections\n",
        "    print(\"Processing all connections...\\n\")\n",
        "\n",
        "    for idx, conn in connections.iterrows():\n",
        "        conn_name = conn['Connection_Name']\n",
        "\n",
        "        try:\n",
        "            # Get weir profile\n",
        "            profile = RasGeometry.get_connection_weir_profile(dam_geom_file, conn_name)\n",
        "\n",
        "            # Get gates\n",
        "            gates = RasGeometry.get_connection_gates(dam_geom_file, conn_name)\n",
        "\n",
        "            print(f\"{idx+1}. {conn_name}:\")\n",
        "            print(f\"   {conn['Upstream_Area']} \u2192 {conn['Downstream_Area']}\")\n",
        "            print(f\"   Weir profile: {len(profile)} points, length={profile['Station'].max():.0f} ft\")\n",
        "            print(f\"   Gates: {len(gates)}\")\n",
        "            if len(gates) > 0:\n",
        "                gate = gates.iloc[0]\n",
        "                print(f\"     {gate['Gate_Name']}: {gate['Width']:.0f}' W \u00d7 {gate['Height']:.0f}' H, Invert={gate['Invert']:.0f}'\")\n",
        "            print()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"{idx+1}. {conn_name}: ERROR - {e}\\n\")\n",
        "else:\n",
        "    print(\"No connections to process\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Batch Processing Example\n",
        "\n",
        "Demonstrate how to automate operations across multiple geometry elements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Calculate Statistics for All Cross Sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.453506Z",
          "iopub.status.busy": "2025-11-17T17:45:01.453210Z",
          "iopub.status.idle": "2025-11-17T17:45:01.510796Z",
          "shell.execute_reply": "2025-11-17T17:45:01.510188Z"
        }
      },
      "outputs": [],
      "source": [
        "# Get all cross sections\n",
        "xs_df = RasGeometry.get_cross_sections(geom_file)\n",
        "\n",
        "print(f\"Processing {len(xs_df)} cross sections...\")\n",
        "\n",
        "# Calculate geometry statistics for first 10 XS (for speed)\n",
        "xs_stats = []\n",
        "for idx, xs in xs_df.head(10).iterrows():\n",
        "    try:\n",
        "        sta_elev = RasGeometry.get_station_elevation(geom_file, xs['River'], xs['Reach'], xs['RS'])\n",
        "\n",
        "        stats = {\n",
        "            'RS': xs['RS'],\n",
        "            'Points': len(sta_elev),\n",
        "            'Min_Elev': sta_elev['Elevation'].min(),\n",
        "            'Max_Elev': sta_elev['Elevation'].max(),\n",
        "            'Relief': sta_elev['Elevation'].max() - sta_elev['Elevation'].min(),\n",
        "            'Width': sta_elev['Station'].max() - sta_elev['Station'].min(),\n",
        "            'Channel_Length': xs['Length_Channel']\n",
        "        }\n",
        "        xs_stats.append(stats)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Warning: Could not process RS {xs['RS']}: {e}\")\n",
        "\n",
        "xs_stats_df = pd.DataFrame(xs_stats)\n",
        "\n",
        "print(f\"\\nStatistics for first 10 cross sections:\")\n",
        "display.display(xs_stats_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Visualize Cross Section Statistics Along Reach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.513364Z",
          "iopub.status.busy": "2025-11-17T17:45:01.513064Z",
          "iopub.status.idle": "2025-11-17T17:45:01.992322Z",
          "shell.execute_reply": "2025-11-17T17:45:01.991697Z"
        }
      },
      "outputs": [],
      "source": [
        "# Plot cross section properties along the reach\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Convert RS to numeric for plotting\n",
        "xs_stats_df['RS_num'] = pd.to_numeric(xs_stats_df['RS'], errors='coerce')\n",
        "\n",
        "# Plot 1: Channel width along reach\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(xs_stats_df['RS_num'], xs_stats_df['Width'], 'b-o', linewidth=2, markersize=5)\n",
        "ax1.set_xlabel('River Station', fontsize=11)\n",
        "ax1.set_ylabel('Channel Width (ft)', fontsize=11)\n",
        "ax1.set_title('Channel Width Along Reach', fontsize=12, fontweight='bold')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.invert_xaxis()  # Invert so upstream is on left\n",
        "\n",
        "# Plot 2: Relief (elevation change across XS)\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(xs_stats_df['RS_num'], xs_stats_df['Relief'], 'g-o', linewidth=2, markersize=5)\n",
        "ax2.set_xlabel('River Station', fontsize=11)\n",
        "ax2.set_ylabel('Relief (ft)', fontsize=11)\n",
        "ax2.set_title('Cross Section Relief Along Reach', fontsize=12, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.invert_xaxis()\n",
        "\n",
        "# Plot 3: Minimum elevation (thalweg)\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(xs_stats_df['RS_num'], xs_stats_df['Min_Elev'], 'r-o', linewidth=2, markersize=5)\n",
        "ax3.set_xlabel('River Station', fontsize=11)\n",
        "ax3.set_ylabel('Minimum Elevation (ft)', fontsize=11)\n",
        "ax3.set_title('Thalweg Profile', fontsize=12, fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.invert_xaxis()\n",
        "\n",
        "# Plot 4: Number of points per XS\n",
        "ax4 = axes[1, 1]\n",
        "ax4.bar(xs_stats_df['RS_num'], xs_stats_df['Points'], color='purple', alpha=0.6)\n",
        "ax4.set_xlabel('River Station', fontsize=11)\n",
        "ax4.set_ylabel('Number of Points', fontsize=11)\n",
        "ax4.set_title('Cross Section Detail Level', fontsize=12, fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "ax4.invert_xaxis()\n",
        "\n",
        "fig.suptitle('Cross Section Statistics Along Reach', fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Practical Applications\n",
        "\n",
        "Real-world use cases combining multiple geometry operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Application: Dam Breach Analysis Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:01.994932Z",
          "iopub.status.busy": "2025-11-17T17:45:01.994562Z",
          "iopub.status.idle": "2025-11-17T17:45:02.018238Z",
          "shell.execute_reply": "2025-11-17T17:45:02.017624Z"
        }
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"DAM BREACH ANALYSIS WORKFLOW\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Identify storage areas\n",
        "print(\"\\nStep 1: Storage Areas\")\n",
        "storage_areas = RasGeometry.get_storage_areas(dam_geom_file)\n",
        "print(f\"  Found {len(storage_areas)} storage area(s)\")\n",
        "for area in storage_areas:\n",
        "    print(f\"    - {area}\")\n",
        "\n",
        "# Step 2: Get storage capacity\n",
        "if len(storage_areas) > 0:\n",
        "    print(\"\\nStep 2: Storage Capacity\")\n",
        "    elev_vol = RasGeometry.get_storage_elevation_volume(dam_geom_file, storage_areas[0])\n",
        "    print(f\"  Maximum storage: {elev_vol['Volume'].max():.0f} cu ft\")\n",
        "    print(f\"  Pool elevation range: {elev_vol['Elevation'].min():.1f} to {elev_vol['Elevation'].max():.1f} ft\")\n",
        "\n",
        "# Step 3: Identify connections\n",
        "print(\"\\nStep 3: Connections\")\n",
        "connections = RasGeometry.get_connections(dam_geom_file)\n",
        "print(f\"  Found {len(connections)} connection(s)\")\n",
        "for idx, conn in connections.iterrows():\n",
        "    print(f\"    - {conn['Connection_Name']}: {conn['Upstream_Area']} \u2192 {conn['Downstream_Area']}\")\n",
        "\n",
        "# Step 4: Analyze dam crest\n",
        "if len(connections) > 0:\n",
        "    dam_connections = connections[connections['Connection_Name'].str.contains('Dam', case=False, na=False)]\n",
        "\n",
        "    if len(dam_connections) > 0:\n",
        "        print(\"\\nStep 4: Dam Crest Geometry\")\n",
        "        dam_name = dam_connections.iloc[0]['Connection_Name']\n",
        "        dam_profile = RasGeometry.get_connection_weir_profile(dam_geom_file, dam_name)\n",
        "\n",
        "        print(f\"  Dam: {dam_name}\")\n",
        "        print(f\"  Crest length: {dam_profile['Station'].max() - dam_profile['Station'].min():.0f} ft\")\n",
        "        print(f\"  Crest elevation range: {dam_profile['Elevation'].min():.1f} to {dam_profile['Elevation'].max():.1f} ft\")\n",
        "        print(f\"  Min crest elevation: {dam_profile['Elevation'].min():.1f} ft\")\n",
        "\n",
        "# Step 5: Check for gates\n",
        "if len(connections) > 0:\n",
        "    print(\"\\nStep 5: Gate Inventory\")\n",
        "    total_gates = connections['Num_Gates'].sum()\n",
        "    print(f\"  Total gates in model: {total_gates:.0f}\")\n",
        "\n",
        "    if total_gates > 0:\n",
        "        conn_with_gates = connections[connections['Num_Gates'] > 0]\n",
        "        for idx, conn in conn_with_gates.iterrows():\n",
        "            gates = RasGeometry.get_connection_gates(dam_geom_file, conn['Connection_Name'])\n",
        "            print(f\"  {conn['Connection_Name']}: {len(gates)} gate(s)\")\n",
        "            for _, gate in gates.iterrows():\n",
        "                print(f\"    \u2022 {gate['Gate_Name']}: {gate['Width']:.0f}' \u00d7 {gate['Height']:.0f}', Invert {gate['Invert']:.0f}'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Application: Sensitivity Study Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:02.020658Z",
          "iopub.status.busy": "2025-11-17T17:45:02.020352Z",
          "iopub.status.idle": "2025-11-17T17:45:02.025927Z",
          "shell.execute_reply": "2025-11-17T17:45:02.025120Z"
        }
      },
      "outputs": [],
      "source": [
        "# Example: Prepare geometry for Manning's n sensitivity study\n",
        "# (Conceptual - actual Manning's n methods not yet implemented)\n",
        "\n",
        "print(\"Sensitivity Study Example:\")\n",
        "print(\"\\nPreparing geometry for parameter sensitivity analysis...\")\n",
        "\n",
        "# Get cross sections for modification\n",
        "xs_subset = xs_df.head(5)\n",
        "\n",
        "print(f\"\\nSelected {len(xs_subset)} cross sections for study:\")\n",
        "for idx, xs in xs_subset.iterrows():\n",
        "    print(f\"  - RS {xs['RS']}\")\n",
        "\n",
        "print(\"\\nFor each cross section, you could:\")\n",
        "print(\"  1. Extract current geometry with get_station_elevation()\")\n",
        "print(\"  2. Extract current Manning's n (future: get_mannings_n())\")\n",
        "print(\"  3. Modify Manning's n values (e.g., \u00b110%, \u00b120%)\")\n",
        "print(\"  4. Write modified values (future: set_mannings_n())\")\n",
        "print(\"  5. Run RasCmdr.compute_plan() for each scenario\")\n",
        "print(\"  6. Compare results to assess sensitivity\")\n",
        "\n",
        "print(\"\\nThis workflow enables automated sensitivity studies!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8: Summary and Key Takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Methods Demonstrated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:45:02.028545Z",
          "iopub.status.busy": "2025-11-17T17:45:02.028173Z",
          "iopub.status.idle": "2025-11-17T17:45:02.032756Z",
          "shell.execute_reply": "2025-11-17T17:45:02.032278Z"
        }
      },
      "outputs": [],
      "source": [
        "print(\"GEOMETRY PARSING METHODS DEMONSTRATED:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n\ud83d\udcd0 Cross Section Operations (3 methods):\")\n",
        "print(\"  \u2713 RasGeometry.get_cross_sections()\")\n",
        "print(\"  \u2713 RasGeometry.get_station_elevation()\")\n",
        "print(\"  \u2713 RasGeometry.set_station_elevation()\")\n",
        "\n",
        "print(\"\\n\ud83d\udcca Hydraulic Property Tables - HTAB (2 methods):\")\n",
        "print(\"  \u2713 HdfHydraulicTables.get_xs_htab()\")\n",
        "print(\"  \u2713 HdfHydraulicTables.get_all_xs_htabs()\")\n",
        "\n",
        "print(\"\\n\ud83c\udfca Storage Area Operations (2 methods):\")\n",
        "print(\"  \u2713 RasGeometry.get_storage_areas()\")\n",
        "print(\"  \u2713 RasGeometry.get_storage_elevation_volume()\")\n",
        "\n",
        "print(\"\\n\ud83c\udf0a Lateral Structure Operations (2 methods):\")\n",
        "print(\"  \u2713 RasGeometry.get_lateral_structures()\")\n",
        "print(\"  \u2713 RasGeometry.get_lateral_weir_profile()\")\n",
        "\n",
        "print(\"\\n\ud83d\udea7 SA/2D Connection Operations (3 methods):\")\n",
        "print(\"  \u2713 RasGeometry.get_connections()\")\n",
        "print(\"  \u2713 RasGeometry.get_connection_weir_profile()\")\n",
        "print(\"  \u2713 RasGeometry.get_connection_gates()\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOTAL: 12 methods demonstrated\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Key Capabilities Enabled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook demonstrated how to:\n",
        "\n",
        "**1. Extract Geometry Data**\n",
        "- List and filter cross sections by river/reach\n",
        "- Extract station/elevation profiles\n",
        "- Get hydraulic property tables (HTAB)\n",
        "- List storage areas and connections\n",
        "- Extract weir profiles and gate configurations\n",
        "\n",
        "**2. Modify Geometry**\n",
        "- Change cross section elevations\n",
        "- Round-trip testing (read \u2192 modify \u2192 write \u2192 verify)\n",
        "- Automatic backup creation before modifications\n",
        "\n",
        "**3. Analyze Hydraulics**\n",
        "- Generate rating curves (area, conveyance, etc.)\n",
        "- Calculate hydraulic properties at specific stages\n",
        "- Find properties without re-running HEC-RAS\n",
        "\n",
        "**4. Visualize Results**\n",
        "- Cross section profiles\n",
        "- Rating curves (area, conveyance, WP, hydraulic radius)\n",
        "- Storage elevation-volume curves\n",
        "- Dam crest profiles\n",
        "- Gate configurations\n",
        "- Statistics along reach\n",
        "\n",
        "**5. Batch Processing**\n",
        "- Automate operations across multiple cross sections\n",
        "- Calculate reach-wide statistics\n",
        "- Process all connections in a model\n",
        "\n",
        "**Use Cases:**\n",
        "- \u2705 Automated geometry modification for sensitivity studies\n",
        "- \u2705 Rating curve generation without HEC-RAS computation\n",
        "- \u2705 Dam breach pre/post-processing\n",
        "- \u2705 Model QA/QC and validation\n",
        "- \u2705 GIS data extraction for visualization\n",
        "- \u2705 Batch processing for calibration studies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Important Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**HTAB Data Requirements:**\n",
        "- Property tables only exist in **preprocessed geometry HDF files**\n",
        "- Run `RasCmdr.compute_plan(\"XX\")` to generate preprocessed HDF\n",
        "- Geometry HDF location: Same as geometry file with `.hdf` extension\n",
        "\n",
        "**Data Formats:**\n",
        "- Plain text geometry files (.g##): Editable with RasGeometry methods\n",
        "- Geometry HDF files (.g##.hdf): Read-only, accessed with HdfHydraulicTables\n",
        "- Fixed-width format (8-char columns): Used for station/elevation, Manning's n, storage curves\n",
        "- CSV format: Used for gates and some metadata\n",
        "\n",
        "**Safety Features:**\n",
        "- Automatic .bak backup before any file modification\n",
        "- Round-trip validation ensures data integrity\n",
        "- Comprehensive error messages for debugging\n",
        "- Logging of all operations\n",
        "\n",
        "**Performance:**\n",
        "- Single cross section extraction: < 0.5 seconds\n",
        "- Batch HTAB extraction (178 XS): < 2 seconds\n",
        "- File modification: < 1 second\n",
        "\n",
        "**Next Steps:**\n",
        "- Explore additional geometry operations (Manning's n, bank stations, ineffective areas)\n",
        "- Implement 2D flow area operations (perimeter, mesh parameters)\n",
        "- Create automated workflows for calibration and sensitivity studies\n",
        "- Export geometry data to GIS formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "**Documentation:**\n",
        "- API Reference: `research/geometry file parsing/api-geom.md`\n",
        "- Geometry Inventory: `research/geometry file parsing/Example Geometries/GEOMETRY_INVENTORY.md`\n",
        "- Parsing Patterns: `research/geometry file parsing/geometry_docs/_PARSING_PATTERNS_REFERENCE.md`\n",
        "\n",
        "**Working Scripts:**\n",
        "- `research/geometry file parsing/working_scripts/01_extract_cross_sections.py`\n",
        "- `research/geometry file parsing/working_scripts/02_htab_rating_curves.py`\n",
        "\n",
        "**Test Files:**\n",
        "- `tests/test_ras_geometry_xs.py` - Cross section tests\n",
        "- `tests/test_hdf_hydraulic_tables.py` - HTAB tests\n",
        "- `tests/test_ras_geometry_storage.py` - Storage area tests\n",
        "- `tests/test_ras_geometry_lateral.py` - Lateral structure tests\n",
        "- `tests/test_ras_geometry_connections.py` - Connection tests\n",
        "\n",
        "**RAS Commander Documentation:**\n",
        "- Main API: `C:\\GH\\ras-commander\\api-ras.md`\n",
        "- Development Guide: `C:\\GH\\ras-commander\\CLAUDE.md`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\21_rasmap_raster_exports.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n"
          ]
        }
      ],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAS Commander: RASMapper Operations\n",
        "\n",
        "This notebook demonstrates how to work with RASMapper configuration files and raster outputs using the `ras-commander` library.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. **Initialize Project**: Set up the HEC-RAS project and explore the rasmap_df\n",
        "2. **Generate Stored Maps**: Use `RasMap.postprocess_stored_maps()` to create raster outputs\n",
        "3. **Locate Results**: Use `RasMap.get_results_folder()` and `RasMap.get_results_raster()` to find outputs\n",
        "4. **Visualize**: Load and display the generated raster files\n",
        "\n",
        "## Key Functions\n",
        "\n",
        "- `RasMap.parse_rasmap()` - Parse .rasmap XML configuration files\n",
        "- `RasMap.get_terrain_names()` - Extract available terrain layers\n",
        "- `RasMap.postprocess_stored_maps()` - Automate raster output generation\n",
        "- `RasMap.get_results_folder()` - Find the output folder for a plan\n",
        "- `RasMap.get_results_raster()` - Get the path to a specific VRT file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import additional libraries for visualization\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize Project and Explore RASMapper Configuration\n",
        "\n",
        "We'll use the Muncie example project, which is a 2D unsteady flow model. Let's initialize the project and examine the `rasmap_df` dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:28:19 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project initialized: Muncie\n",
            "Project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
            "RAS version: 6.6\n"
          ]
        }
      ],
      "source": [
        "# Extract Muncie project if it doesn't exist\n",
        "project_path = Path(\"./example_projects/Muncie\").resolve()\n",
        "\n",
        "if not os.path.exists(project_path):\n",
        "    project_path = RasExamples.extract_project(\"Muncie\")\n",
        "\n",
        "# Initialize the RAS project with version 6.6\n",
        "init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "print(f\"Project initialized: {ras.project_name}\")\n",
        "print(f\"Project folder: {ras.project_folder}\")\n",
        "print(f\"RAS version: {ras.ras_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:28:19 - ras_commander.RasCmdr - INFO - Using ras_object with project folder: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n",
            "2025-11-17 21:28:19 - ras_commander.RasUtils - INFO - Using provided plan file path: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01\n",
            "2025-11-17 21:28:19 - ras_commander.RasUtils - INFO - Successfully updated file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01\n",
            "2025-11-17 21:28:19 - ras_commander.RasCmdr - INFO - Set number of cores to 4 for plan: 01\n",
            "2025-11-17 21:28:19 - ras_commander.RasCmdr - INFO - Running HEC-RAS from the Command Line:\n",
            "2025-11-17 21:28:19 - ras_commander.RasCmdr - INFO - Running command: \"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\" -c \"C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.prj\" \"C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01\"\n",
            "2025-11-17 21:28:34 - ras_commander.RasCmdr - INFO - HEC-RAS execution completed for plan: 01\n",
            "2025-11-17 21:28:34 - ras_commander.RasCmdr - INFO - Total run time for plan 01: 14.86 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": "['True']"
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We'll select a plan to work with (using plan number \"01\")\n",
        "plan_number = \"01\"\n",
        "success = RasCmdr.compute_plan(plan_number, num_cores=4)\n",
        "success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the rasmap_df\n",
        "\n",
        "The `rasmap_df` dataframe is created during project initialization by parsing the `.rasmap` XML file. It contains all RASMapper configuration information:\n",
        "\n",
        "- **projection_path**: Coordinate system projection file\n",
        "- **profile_lines_path**: XS cut lines for extracting profiles\n",
        "- **soil_layer_path**: Hydrologic soil group layers\n",
        "- **infiltration_hdf_path**: Infiltration parameter layers\n",
        "- **landcover_hdf_path**: Land cover classification layers\n",
        "- **terrain_hdf_path**: Digital elevation model (DEM) layers\n",
        "- **current_settings**: Various RASMapper display and export settings\n",
        "\n",
        "This dataframe provides a programmatic way to access all the spatial data layers and configuration used in RASMapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RASMapper Configuration DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>projection_path</th>\\n', '      <th>profile_lines_path</th>\\n', '      <th>soil_layer_path</th>\\n', '      <th>infiltration_hdf_path</th>\\n', '      <th>landcover_hdf_path</th>\\n', '      <th>terrain_hdf_path</th>\\n', '      <th>current_settings</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>[C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects...</td>\\n', '      <td>[]</td>\\n', '      <td>[]</td>\\n', '      <td>[]</td>\\n', '      <td>[C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects...</td>\\n', \"      <td>{'RiverStationUnits': 'Feet', 'RiverStationDec...</td>\\n\", '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "                                     projection_path  \\\n",
              "0  C:\\GH\\ras-commander\\examples\\example_projects\\...   \n",
              "\n",
              "                                  profile_lines_path soil_layer_path  \\\n",
              "0  [C:\\GH\\ras-commander\\examples\\example_projects...              []   \n",
              "\n",
              "  infiltration_hdf_path landcover_hdf_path  \\\n",
              "0                    []                 []   \n",
              "\n",
              "                                    terrain_hdf_path  \\\n",
              "0  [C:\\GH\\ras-commander\\examples\\example_projects...   \n",
              "\n",
              "                                    current_settings  \n",
              "0  {'RiverStationUnits': 'Feet', 'RiverStationDec...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Column Details:\n",
            "============================================================\n",
            "\n",
            "projection_path:\n",
            "  C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\GIS_Data\\Muncie_IA_Clip.prj\n",
            "\n",
            "profile_lines_path:\n",
            "  - C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Features\\Profile Lines.shp\n",
            "\n",
            "soil_layer_path:\n",
            "  (empty list)\n",
            "\n",
            "infiltration_hdf_path:\n",
            "  (empty list)\n",
            "\n",
            "landcover_hdf_path:\n",
            "  (empty list)\n",
            "\n",
            "terrain_hdf_path:\n",
            "  - C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Terrain\\Terrain.hdf\n",
            "  - C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Terrain\\TerrainWithChannel.hdf\n",
            "\n",
            "current_settings:\n",
            "  RiverStationUnits: Feet\n",
            "  RiverStationDecimalPlaces: 0\n",
            "  HorizontalDecimalPlaces: 1\n",
            "  VerticalDecimalPlaces: 2\n",
            "  XSMaxPoints: 450\n",
            "  LSMaxPoints: 1000\n",
            "  ProfilePointMinCount: 0\n",
            "  ShowLegend: True\n",
            "  ShowNorthArrow: False\n",
            "  ShowScaleBar: True\n",
            "  ShowGreaterThanInLegend: False\n",
            "  TerrainDestinationFolder: .\\Terrain\n",
            "  AddDataFolder: .\\LandCover\n",
            "  LandCoverDestinationFolder: ..\\Muncie\n",
            "  TerrainSourceFolder: .\\Terrain\n"
          ]
        }
      ],
      "source": [
        "# Display the rasmap_df\n",
        "print(\"\\nRASMapper Configuration DataFrame:\")\n",
        "display(ras.rasmap_df)\n",
        "\n",
        "# Show what's in each column\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Column Details:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for col in ras.rasmap_df.columns:\n",
        "    value = ras.rasmap_df[col].iloc[0]\n",
        "    print(f\"\\n{col}:\")\n",
        "    if isinstance(value, list):\n",
        "        if len(value) > 0:\n",
        "            for item in value:\n",
        "                print(f\"  - {item}\")\n",
        "        else:\n",
        "            print(\"  (empty list)\")\n",
        "    elif isinstance(value, dict):\n",
        "        if len(value) > 0:\n",
        "            for key, val in value.items():\n",
        "                print(f\"  {key}: {val}\")\n",
        "        else:\n",
        "            print(\"  (empty dict)\")\n",
        "    else:\n",
        "        print(f\"  {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Available Terrains\n",
        "\n",
        "Before generating stored maps, we need to know which terrain layers are available. The `get_terrain_names()` function extracts this from the .rasmap file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Extracted terrain names: ['Terrain', 'TerrainWithChannel']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available terrains: ['Terrain', 'TerrainWithChannel']\n",
            "\n",
            "Using terrain: Terrain\n"
          ]
        }
      ],
      "source": [
        "# Get the rasmap file path\n",
        "rasmap_path = ras.project_folder / f\"{ras.project_name}.rasmap\"\n",
        "\n",
        "# Extract terrain names\n",
        "terrains = RasMap.get_terrain_names(rasmap_path)\n",
        "print(f\"Available terrains: {terrains}\")\n",
        "\n",
        "# Select the first terrain for our mapping\n",
        "target_terrain = None\n",
        "if terrains:\n",
        "    target_terrain = terrains[0]\n",
        "    print(f\"\\nUsing terrain: {target_terrain}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Check for Existing Results\n",
        "\n",
        "Let's examine what plans are available and whether they have been computed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>unsteady_number</th>\\n', '      <th>geometry_number</th>\\n', '      <th>Plan Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>Simulation Date</th>\\n', '      <th>Computation Interval</th>\\n', '      <th>Mapping Interval</th>\\n', '      <th>Run HTab</th>\\n', '      <th>...</th>\\n', '      <th>DSS File</th>\\n', '      <th>Friction Slope Method</th>\\n', '      <th>UNET D2 SolverType</th>\\n', '      <th>UNET D2 Name</th>\\n', '      <th>HDF_Results_Path</th>\\n', '      <th>Geom File</th>\\n', '      <th>Geom Path</th>\\n', '      <th>Flow File</th>\\n', '      <th>Flow Path</th>\\n', '      <th>full_path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>01</td>\\n', '      <td>Unsteady Multi  9-SA run</td>\\n', '      <td>5.00</td>\\n', '      <td>9-SAs</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>15SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>NaN</td>\\n', '      <td>NaN</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>01</td>\\n', '      <td>02</td>\\n', '      <td>Unsteady Run with 2D 50ft Grid</td>\\n', '      <td>5.10</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>-1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>02</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>01</td>\\n', '      <td>04</td>\\n', '      <td>Unsteady Run with 2D 50ft User n Value R</td>\\n', '      <td>5.10</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>02JAN1900,0000,02JAN1900,2400</td>\\n', '      <td>10SEC</td>\\n', '      <td>5MIN</td>\\n', '      <td>1</td>\\n', '      <td>...</td>\\n', '      <td>dss</td>\\n', '      <td>1</td>\\n', '      <td>Pardiso (Direct)</td>\\n', '      <td>2D Interior Area</td>\\n', '      <td>None</td>\\n', '      <td>04</td>\\n', '      <td>None</td>\\n', '      <td>01</td>\\n', '      <td>None</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  plan_number unsteady_number geometry_number  \\\\\\n', '0          01              01              01   \\n', '1          03              01              02   \\n', '2          04              01              04   \\n', '\\n', '                                 Plan Title Program Version  \\\\\\n', '0                  Unsteady Multi  9-SA run            5.00   \\n', '1            Unsteady Run with 2D 50ft Grid            5.10   \\n', '2  Unsteady Run with 2D 50ft User n Value R            5.10   \\n', '\\n', '      Short Identifier                Simulation Date Computation Interval  \\\\\\n', '0                9-SAs  02JAN1900,0000,02JAN1900,2400                15SEC   \\n', '1         2D 50ft Grid  02JAN1900,0000,02JAN1900,2400                10SEC   \\n', '2  50ft User n Regions  02JAN1900,0000,02JAN1900,2400                10SEC   \\n', '\\n', '  Mapping Interval Run HTab  ... DSS File Friction Slope Method  \\\\\\n', '0             5MIN        1  ...      dss                     1   \\n', '1           \n...\n[Output truncated, 2041 characters total]"
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ras.plan_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available plans and HDF results status:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>plan_number</th>\\n', '      <th>Short Identifier</th>\\n', '      <th>HDF_Results_Path</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>01</td>\\n', '      <td>9-SAs</td>\\n', '      <td>C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...</td>\\n', '    </tr><tr>\\n', '      <th>1</th>\\n', '      <td>03</td>\\n', '      <td>2D 50ft Grid</td>\\n', '      <td>None</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>04</td>\\n', '      <td>50ft User n Regions</td>\\n', '      <td>None</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['  plan_number     Short Identifier  \\\\\\n', '0          01                9-SAs   \\n', '1          03         2D 50ft Grid   \\n', '2          04  50ft User n Regions   \\n', '\\n', '                                    HDF_Results_Path  \\n', '0  C:\\\\GH\\\\ras-commander\\\\examples\\\\example_projects\\\\...  \\n', '1                                               None  \\n', '2                                               None  ']"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 2: Check for Existing Results and Display Status by Plan\n",
        "\n",
        "# Show which plans exist and which have results HDF files present.\n",
        "import pandas as pd\n",
        "\n",
        "# Choose relevant columns for clarity\n",
        "plan_results_cols = ['plan_number', 'Short Identifier', 'HDF_Results_Path']\n",
        "plan_results_df = ras.plan_df[plan_results_cols]\n",
        "\n",
        "print(\"Available plans and HDF results status:\")\n",
        "plan_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results for plan 01 are already present at:\n",
            "  C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.hdf\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Check for the computed HDF results file (outputs typically end with .pXX.hdf)\n",
        "plan_hdf_path = ras.project_folder / f\"{ras.project_name}.p{plan_number}.hdf\"\n",
        "\n",
        "if plan_hdf_path.exists():\n",
        "    print(f\"\\nResults for plan {plan_number} are already present at:\\n  {plan_hdf_path}\")\n",
        "else:\n",
        "    print(f\"\\nResults for plan {plan_number} not found. \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Stored Maps Using postprocess_stored_maps()\n",
        "\n",
        "The `postprocess_stored_maps()` function automates the process of creating raster outputs:\n",
        "\n",
        "1. Backs up the original plan and .rasmap files\n",
        "2. Modifies plan flags to only run floodplain mapping (not the full simulation)\n",
        "3. Adds stored map definitions to the .rasmap file\n",
        "4. Opens HEC-RAS for you to run the plan\n",
        "5. Restores original files after completion\n",
        "\n",
        "**Note:** HEC-RAS 6.x requires the GUI to be open for floodplain mapping. The function will open HEC-RAS and wait for you to close it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Backing up plan file C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01 to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.storedmap.bak\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Updating plan run flags for floodplain mapping for plan 01...\n",
            "2025-11-17 21:28:34 - ras_commander.RasPlan - INFO - Successfully updated run flags in plan file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01 (flags modified: 4)\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Backing up rasmap file C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap to C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap.storedmap.bak\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Added 'WSE' stored map to results layer for plan 01.\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Added 'Depth' stored map to results layer for plan 01.\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Added 'Velocity' stored map to results layer for plan 01.\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Filtered terrains, keeping only 'Terrain'.\n",
            "2025-11-17 21:28:34 - ras_commander.RasMap - INFO - Using GUI automation to run floodplain mapping...\n",
            "2025-11-17 21:28:34 - ras_commander.RasGuiAutomation - INFO - Setting current plan to 01 in project file...\n",
            "2025-11-17 21:28:34 - ras_commander.RasPrj - INFO - Set current plan to p01 in C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.prj\n",
            "2025-11-17 21:28:34 - ras_commander.RasGuiAutomation - INFO - Current plan set to 01 in C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.prj\n",
            "2025-11-17 21:28:34 - ras_commander.RasGuiAutomation - INFO - Opening HEC-RAS...\n",
            "2025-11-17 21:28:34 - ras_commander.RasGuiAutomation - INFO - HEC-RAS opened with Process ID: 428556\n",
            "2025-11-17 21:28:34 - ras_commander.RasGuiAutomation - INFO - Waiting for HEC-RAS main window...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating stored maps for WSE, Depth, and Velocity...\n",
            "\n",
            "HEC-RAS will open. Please:\n",
            "1. Click 'Compute' (or use Run > Unsteady Flow Analysis)\n",
            "2. Wait for the floodplain mapping to complete\n",
            "3. Close HEC-RAS when finished\n",
            "\n",
            "The script will continue automatically after you close HEC-RAS.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:28:47 - ras_commander.RasGuiAutomation - INFO - Found HEC-RAS main window: HEC-RAS 6.6\n",
            "2025-11-17 21:28:48 - ras_commander.RasGuiAutomation - INFO - Clicking 'Run > Unsteady Flow Analysis' menu...\n",
            "2025-11-17 21:28:49 - ras_commander.RasGuiAutomation - INFO - Clicked menu item ID: 47\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Looking for Unsteady Flow Analysis dialog...\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Found Unsteady Flow Analysis dialog\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Looking for Compute button...\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - WARNING - Could not find Compute button - user must click manually\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Trying keyboard shortcut as fallback...\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Sent Enter key to dialog\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Waiting for user to close HEC-RAS...\n",
            "2025-11-17 21:28:51 - ras_commander.RasGuiAutomation - INFO - Please monitor plan 01 execution and close HEC-RAS when complete\n",
            "2025-11-17 21:29:43 - ras_commander.RasGuiAutomation - INFO - HEC-RAS has been closed\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Floodplain mapping computation successful.\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Restoring original plan file from C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p01.storedmap.bak\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Restoring original rasmap file from C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.rasmap.storedmap.bak\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Successfully generated stored maps!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate stored maps for WSE, Depth, and Velocity\n",
        "print(\"Generating stored maps for WSE, Depth, and Velocity...\")\n",
        "print(\"\\nHEC-RAS will open. Please:\")\n",
        "print(\"1. Click 'Compute' (or use Run > Unsteady Flow Analysis)\")\n",
        "print(\"2. Wait for the floodplain mapping to complete\")\n",
        "print(\"3. Close HEC-RAS when finished\")\n",
        "print(\"\\nThe script will continue automatically after you close HEC-RAS.\")\n",
        "\n",
        "success = RasMap.postprocess_stored_maps(\n",
        "    plan_number=plan_number,\n",
        "    specify_terrain=target_terrain,\n",
        "    layers=['WSE', 'Depth', 'Velocity']  # Generate all three variables\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Successfully generated stored maps!\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"\\nFailed to generate stored maps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Locate Results Using get_results_folder() and get_results_raster()\n",
        "\n",
        "Now that we've generated the raster outputs, we can use the new functions to locate them programmatically.\n",
        "\n",
        "### Understanding the Output Folder Structure\n",
        "\n",
        "HEC-RAS creates output folders based on the plan's **Short Identifier**. Windows folder naming replaces special characters (like `/`, `\\`, `:`, `*`, `?`, `\"`, `<`, `>`, `|`, `+`, ` `) with underscores (`_`).\n",
        "\n",
        "The `get_results_folder()` function handles this normalization automatically and finds the correct folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results folder: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "\n",
            "Files in results folder:\n",
            "  - Depth (Max).Terrain.muncie_clip.tif\n",
            "  - Depth (Max).vrt\n",
            "  - PostProcessing.hdf\n",
            "  - Velocity (Max).Terrain.muncie_clip.tif\n",
            "  - Velocity (Max).vrt\n",
            "  - WSE (Max).Terrain.muncie_clip.tif\n",
            "  - WSE (Max).vrt\n"
          ]
        }
      ],
      "source": [
        "# Get the results folder for this plan\n",
        "results_folder = RasMap.get_results_folder(plan_number)\n",
        "print(f\"Results folder: {results_folder}\")\n",
        "\n",
        "# List all files in the results folder\n",
        "print(\"\\nFiles in results folder:\")\n",
        "for file in sorted(results_folder.iterdir()):\n",
        "    print(f\"  - {file.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Specific Raster Files\n",
        "\n",
        "The `get_results_raster()` function searches for VRT files matching a variable name. VRT (Virtual Raster) files are lightweight files that reference the underlying TIFF tiles.\n",
        "\n",
        "The function performs a **case-insensitive substring match**, so:\n",
        "- `\"WSE\"` will match `\"WSE (Max).vrt\"` or `\"WSE (10Pct).vrt\"`\n",
        "- `\"WSE (Max)\"` will match only `\"WSE (Max).vrt\"`\n",
        "\n",
        "If multiple files match, it will raise an error and show you all matching files so you can be more specific."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found matching VRT file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\\WSE (Max).vrt\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found matching VRT file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\\Depth (Max).vrt\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found matching VRT file: C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\\Velocity (Max).vrt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found raster files:\n",
            "  WSE:      WSE (Max).vrt\n",
            "  Depth:    Depth (Max).vrt\n",
            "  Velocity: Velocity (Max).vrt\n"
          ]
        }
      ],
      "source": [
        "# Get specific raster files\n",
        "wse_vrt = RasMap.get_results_raster(plan_number, \"WSE (Max)\")\n",
        "depth_vrt = RasMap.get_results_raster(plan_number, \"Depth (Max)\")\n",
        "velocity_vrt = RasMap.get_results_raster(plan_number, \"Velocity (Max)\")\n",
        "\n",
        "print(\"Found raster files:\")\n",
        "print(f\"  WSE:      {wse_vrt.name}\")\n",
        "print(f\"  Depth:    {depth_vrt.name}\")\n",
        "print(f\"  Velocity: {velocity_vrt.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demonstrating Flexible Plan Number Handling\n",
        "\n",
        "Both functions accept plan numbers in multiple formats for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n",
            "2025-11-17 21:29:43 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flexible plan number handling:\n",
            "  get_results_folder(1)     -> True\n",
            "  get_results_folder('01')  -> True\n",
            "  get_results_folder('001') -> True\n"
          ]
        }
      ],
      "source": [
        "# All of these work the same way:\n",
        "folder1 = RasMap.get_results_folder(1)          # Integer\n",
        "folder2 = RasMap.get_results_folder(\"01\")       # Two-digit string\n",
        "folder3 = RasMap.get_results_folder(\"001\")      # Three-digit string\n",
        "\n",
        "print(\"Flexible plan number handling:\")\n",
        "print(f\"  get_results_folder(1)     -> {folder1 == results_folder}\")\n",
        "print(f\"  get_results_folder('01')  -> {folder2 == results_folder}\")\n",
        "print(f\"  get_results_folder('001') -> {folder3 == results_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Visualize the Results\n",
        "\n",
        "Now let's load and visualize the raster files we've located."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "def get_valid_data_bounds(src) -> tuple:\n",
        "    \"\"\"\n",
        "    Returns the bounding box of valid (non-nodata) values in raster coordinates,\n",
        "    expanded by 10% on all sides and transformed to spatial coordinates.\n",
        "    \"\"\"\n",
        "    data = src.read(1, masked=True)\n",
        "    # Find where data is not nodata\n",
        "    valid_mask = np.ma.getmaskarray(data) == 0\n",
        "    rows, cols = np.where(valid_mask)\n",
        "    if rows.size == 0 or cols.size == 0:\n",
        "        # No data found, fallback to raster extents\n",
        "        bounds = src.bounds\n",
        "        return bounds.left, bounds.right, bounds.bottom, bounds.top\n",
        "\n",
        "    # Find min/max in pixel coordinates\n",
        "    row_min, row_max = rows.min(), rows.max()\n",
        "    col_min, col_max = cols.min(), cols.max()\n",
        "\n",
        "    # Transform corners to map coordinates\n",
        "    top_left = src.transform * (col_min, row_min)\n",
        "    bottom_right = src.transform * (col_max + 1, row_max + 1)  # +1 to include the edge\n",
        "\n",
        "    xmin = top_left[0]\n",
        "    ymax = top_left[1]\n",
        "    xmax = bottom_right[0]\n",
        "    ymin = bottom_right[1]\n",
        "\n",
        "    # Expand bounds by 10%\n",
        "    width = xmax - xmin\n",
        "    height = ymax - ymin\n",
        "    xpad = width * 0.10 / 2.0\n",
        "    ypad = height * 0.10 / 2.0\n",
        "\n",
        "    return (\n",
        "        xmin - xpad,\n",
        "        xmax + xpad,\n",
        "        ymin - ypad,\n",
        "        ymax + ypad\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_raster_with_valid_bounds(raster_path, cmap, title):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        valid_bounds = get_valid_data_bounds(src)\n",
        "        fig, ax = plt.subplots(figsize=(6, 6))\n",
        "        img = ax.imshow(\n",
        "            src.read(1, masked=True),\n",
        "            cmap=cmap,\n",
        "            extent=[src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top],\n",
        "            origin='upper'\n",
        "        )\n",
        "        ax.set_xlim(valid_bounds[0], valid_bounds[1])\n",
        "        ax.set_ylim(valid_bounds[2], valid_bounds[3])\n",
        "        ax.set_xlabel('Easting')\n",
        "        ax.set_ylabel('Northing')\n",
        "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Plot WSE individually (zoom to actual data mask)\n",
        "plot_raster_with_valid_bounds(\n",
        "    wse_vrt, cmap='terrain', title='Maximum Water Surface Elevation'\n",
        ")\n",
        "\n",
        "# Plot Depth individually (zoom to actual data mask)\n",
        "plot_raster_with_valid_bounds(\n",
        "    depth_vrt, cmap='Blues', title='Maximum Depth'\n",
        ")\n",
        "\n",
        "# Plot Velocity individually (zoom to actual data mask)\n",
        "plot_raster_with_valid_bounds(\n",
        "    velocity_vrt, cmap='YlOrRd', title='Maximum Velocity'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Raster Metadata\n",
        "\n",
        "We can use rasterio to examine the raster properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth Raster Metadata:\n",
            "  CRS:        PROJCS[\"NAD83 / Indiana East (ftUS)\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101004,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",37.5],PARAMETER[\"central_meridian\",-85.6666666666667],PARAMETER[\"scale_factor\",0.999966666666667],PARAMETER[\"false_easting\",328083.333333333],PARAMETER[\"false_northing\",820208.333333333],UNIT[\"US survey foot\",0.304800609601219,AUTHORITY[\"EPSG\",\"9003\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]\n",
            "  Dimensions: 7892 x 4538\n",
            "  Resolution: (5.0, 5.0)\n",
            "  Bounds:     BoundingBox(left=384977.84867792, bottom=1788863.5402636, right=424437.84867792, top=1811553.5402636)\n",
            "  NoData:     -9999.0\n",
            "  Data Type:  float32\n"
          ]
        }
      ],
      "source": [
        "# Examine depth raster properties\n",
        "with rasterio.open(depth_vrt) as src:\n",
        "    print(\"Depth Raster Metadata:\")\n",
        "    print(f\"  CRS:        {src.crs}\")\n",
        "    print(f\"  Dimensions: {src.width} x {src.height}\")\n",
        "    print(f\"  Resolution: {src.res}\")\n",
        "    print(f\"  Bounds:     {src.bounds}\")\n",
        "    print(f\"  NoData:     {src.nodata}\")\n",
        "    print(f\"  Data Type:  {src.dtypes[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Working with Multiple Plans\n",
        "\n",
        "The `get_results_folder()` and `get_results_raster()` functions make it easy to work with multiple plans programmatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 21:29:58 - ras_commander.RasMap - INFO - Found output folder (exact match): C:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\9-SAs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results folders for all plans:\n",
            "============================================================\n",
            "Plan 01 (9-SAs):\n",
            "  Folder: 9-SAs\n",
            "  VRT files: 3\n",
            "    - Depth (Max).vrt\n",
            "    - Velocity (Max).vrt\n",
            "    - WSE (Max).vrt\n",
            "\n",
            "Plan 03 (2D 50ft Grid): Not computed\n",
            "\n",
            "Plan 04 (50ft User n Regions): Not computed\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get results for all computed plans\n",
        "print(\"Results folders for all plans:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for idx, row in ras.plan_df.iterrows():\n",
        "    plan_num = row['plan_number']\n",
        "    short_id = row['Short Identifier']\n",
        "    \n",
        "    # Check if HDF results exist\n",
        "    hdf_path = ras.project_folder / f\"{ras.project_name}.p{plan_num}.hdf\"\n",
        "    if hdf_path.exists():\n",
        "        try:\n",
        "            folder = RasMap.get_results_folder(plan_num)\n",
        "            print(f\"Plan {plan_num} ({short_id}):\")\n",
        "            print(f\"  Folder: {folder.name}\")\n",
        "            \n",
        "            # Count VRT files\n",
        "            vrt_files = list(folder.glob(\"*.vrt\"))\n",
        "            print(f\"  VRT files: {len(vrt_files)}\")\n",
        "            for vrt in vrt_files:\n",
        "                print(f\"    - {vrt.name}\")\n",
        "            print()\n",
        "        except ValueError as e:\n",
        "            print(f\"Plan {plan_num} ({short_id}): No results folder (likely no stored maps)\")\n",
        "            print()\n",
        "    else:\n",
        "        print(f\"Plan {plan_num} ({short_id}): Not computed\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated the complete RASMapper workflow:\n",
        "\n",
        "1. **Project Initialization**: Loaded project and examined `rasmap_df` configuration\n",
        "2. **Terrain Discovery**: Used `get_terrain_names()` to find available DEMs\n",
        "3. **Stored Map Generation**: Used `postprocess_stored_maps()` to create WSE, Depth, and Velocity rasters\n",
        "4. **Results Location**: Used `get_results_folder()` and `get_results_raster()` to find outputs\n",
        "5. **Visualization**: Loaded and displayed raster files with rasterio\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- The `rasmap_df` provides programmatic access to all RASMapper configuration\n",
        "- `postprocess_stored_maps()` automates the tedious process of generating raster outputs\n",
        "- `get_results_folder()` handles Windows folder naming normalization automatically\n",
        "- `get_results_raster()` provides smart matching for finding specific variable outputs\n",
        "- Both functions accept flexible plan number formats (1, \"01\", \"001\")\n",
        "- VRT files are lightweight references to underlying TIFF tiles\n",
        "\n",
        "These functions significantly streamline workflows involving raster output generation and processing for multiple plans or scenarios."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\22_dss_boundary_extraction.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:38.035942Z",
          "iopub.status.busy": "2025-11-17T17:46:38.035768Z",
          "iopub.status.idle": "2025-11-17T17:46:39.238862Z",
          "shell.execute_reply": "2025-11-17T17:46:39.238068Z"
        }
      },
      "source": [
        "# Uncomment to install/upgrade ras-commander from pip\n",
        "#!pip install --upgrade ras-commander\n",
        "\n",
        "#Import the ras-commander package\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ras-commander from local dev copy\n"
          ]
        }
      ],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSS Boundary Condition Extraction\n",
        "\n",
        "This notebook demonstrates how to extract DSS (Data Storage System) boundary condition data from HEC-RAS projects using ras-commander.\n",
        "\n",
        "**Example Project**: BaldEagleCrkMulti2D, Plan 07\n",
        "\n",
        "## Features Demonstrated\n",
        "- Reading DSS file catalogs\n",
        "- Extracting individual time series\n",
        "- Automatic boundary condition extraction\n",
        "- Plotting DSS boundary data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:39.241141Z",
          "iopub.status.busy": "2025-11-17T17:46:39.240862Z",
          "iopub.status.idle": "2025-11-17T17:46:40.918172Z",
          "shell.execute_reply": "2025-11-17T17:46:40.917709Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyjnius in c:\\users\\billk_clb\\anaconda3\\envs\\rascmdr_local\\lib\\site-packages (1.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyjnius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:40.920260Z",
          "iopub.status.busy": "2025-11-17T17:46:40.920101Z",
          "iopub.status.idle": "2025-11-17T17:46:40.924671Z",
          "shell.execute_reply": "2025-11-17T17:46:40.924113Z"
        }
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flexible imports for development vs installed package\n",
        "try:\n",
        "    from ras_commander import init_ras_project, RasExamples\n",
        "    from ras_commander import RasDss\n",
        "except ImportError:\n",
        "    current_file = Path.cwd()\n",
        "    parent_directory = current_file.parent\n",
        "    sys.path.append(str(parent_directory))\n",
        "    from ras_commander import init_ras_project, RasExamples\n",
        "    from ras_commander.RasDss import RasDss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Extract Example Project\n",
        "\n",
        "Extract the Bald Eagle Creek Multi-2D example project which contains DSS boundary conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:40.926914Z",
          "iopub.status.busy": "2025-11-17T17:46:40.926567Z",
          "iopub.status.idle": "2025-11-17T17:46:42.397243Z",
          "shell.execute_reply": "2025-11-17T17:46:42.396709Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Found zip file: c:\\GH\\ras-commander\\examples\\Example_Projects_6_6.zip\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Loaded 68 projects from CSV.\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n",
            "2025-12-02 13:46:59 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n",
            "2025-12-02 13:47:00 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project extracted to: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"
          ]
        }
      ],
      "source": [
        "# Extract BaldEagleCrkMulti2D example project\n",
        "project_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
        "print(f\"Project extracted to: {project_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialize Project\n",
        "\n",
        "Initialize the HEC-RAS project to access boundary condition data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:42.399692Z",
          "iopub.status.busy": "2025-11-17T17:46:42.399166Z",
          "iopub.status.idle": "2025-11-17T17:46:42.514823Z",
          "shell.execute_reply": "2025-11-17T17:46:42.514207Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 13:47:00 - ras_commander.RasMap - INFO - Successfully parsed RASMapper file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.rasmap\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Project: BaldEagleDamBrk\n",
            "Plans: 11\n",
            "Boundaries: 51\n"
          ]
        }
      ],
      "source": [
        "# Initialize project\n",
        "ras = init_ras_project(project_path, \"6.6\")\n",
        "\n",
        "print(f\"\\nProject: {ras.project_name}\")\n",
        "print(f\"Plans: {len(ras.plan_df)}\")\n",
        "print(f\"Boundaries: {len(ras.boundaries_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Examine Boundary Conditions\n",
        "\n",
        "View boundary conditions and identify which are defined by DSS files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:42.517421Z",
          "iopub.status.busy": "2025-11-17T17:46:42.517189Z",
          "iopub.status.idle": "2025-11-17T17:46:42.523928Z",
          "shell.execute_reply": "2025-11-17T17:46:42.523454Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plan 07 has 10 boundary conditions\n",
            "\n",
            "DSS-defined boundaries: 0\n",
            "\n",
            "Empty DataFrame\n",
            "Columns: [boundary_condition_number, bc_type, Use DSS, DSS File, DSS Path]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Show boundaries for plan 07\n",
        "plan_07_boundaries = ras.boundaries_df[ras.boundaries_df['unsteady_number'] == '07'].copy()\n",
        "\n",
        "print(f\"Plan 07 has {len(plan_07_boundaries)} boundary conditions\\n\")\n",
        "\n",
        "# Show DSS-defined boundaries\n",
        "dss_boundaries = plan_07_boundaries[plan_07_boundaries['Use DSS'] == True]\n",
        "print(f\"DSS-defined boundaries: {len(dss_boundaries)}\\n\")\n",
        "\n",
        "# Display key columns\n",
        "display_cols = ['boundary_condition_number', 'bc_type', 'Use DSS', 'DSS File', 'DSS Path']\n",
        "print(dss_boundaries[display_cols].to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Inspect DSS File\n",
        "\n",
        "Examine what's in the DSS file before extracting data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:42.526425Z",
          "iopub.status.busy": "2025-11-17T17:46:42.526099Z",
          "iopub.status.idle": "2025-11-17T17:46:43.007655Z",
          "shell.execute_reply": "2025-11-17T17:46:43.007161Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuring Java VM for DSS operations...\n",
            "  Found Java: C:\\Program Files\\Java\\jre1.8.0_471\n",
            "[OK] Java VM configured\n",
            "DSS File: Bald_Eagle_Creek.dss\n",
            "Size: 29.27 MB\n",
            "Total paths: 1270\n",
            "\n",
            "First 10 paths:\n",
            "  1. //BALD EAGLE AT MILESBURG/FLOW/01SEP2004/15MIN/GAGE/\n",
            "  2. //FISHING CREEK/FLOW-BASE/01JUN1972/15MIN/RUN:1972 CALIBRATION EVENT/\n",
            "  3. //LOCAL DOWNSTREAM OF DAM/FLOW/01JUN1972/15MIN/RUN:1972 CALIBRATION EVENT/\n",
            "  4. //MARSH CREEK/INFILTRATION/01JAN1996/15MIN/RUN:1996 CALIBRATION EVENT/\n",
            "  5. //SAYERS - ELEVATION-STORAGE/ELEVATION-STORAGE///TABLE/\n",
            "  6. //MARSH CREEK GAGE/FLOW-OBSERVED/01JUN1972/15MIN/RUN:1972 CALIBRATION EVENT/\n",
            "  7. //BALD EAGLE AT MILESBURG/FLOW-OBSERVED/01JUN1972/15MIN/RUN:1972 CALIBRATION EVENT/\n",
            "  8. //MARSH CREEK/PRECIP-INC/01JAN2000/15MIN/DAA:1% EVENT>BALD EAGLE BL BEECH/\n",
            "  9. //BASIN TEMPERATURE/TEMPERATURE/01JUN1972/1HOUR/GAGE/\n",
            "  10. //BALD EAGLE HW/INFILTRATION/01JAN2000/15MIN/RUN:1% EVENT/\n"
          ]
        }
      ],
      "source": [
        "# Get DSS file path\n",
        "dss_file = project_path / \"Bald_Eagle_Creek.dss\"\n",
        "\n",
        "if dss_file.exists():\n",
        "    # Get file info\n",
        "    info = RasDss.get_info(dss_file)\n",
        "    \n",
        "    print(f\"DSS File: {info['filename']}\")\n",
        "    print(f\"Size: {info['file_size_mb']:.2f} MB\")\n",
        "    print(f\"Total paths: {info['total_paths']}\")\n",
        "    \n",
        "    print(f\"\\nFirst 10 paths:\")\n",
        "    catalog = RasDss.get_catalog(dss_file)\n",
        "    for i, path in enumerate(catalog[:10]):\n",
        "        print(f\"  {i+1}. {path}\")\n",
        "else:\n",
        "    print(f\"DSS file not found: {dss_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Extract Single Time Series\n",
        "\n",
        "Demonstrate extracting a single DSS time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:43.010199Z",
          "iopub.status.busy": "2025-11-17T17:46:43.009777Z",
          "iopub.status.idle": "2025-11-17T17:46:43.020258Z",
          "shell.execute_reply": "2025-11-17T17:46:43.019760Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>unsteady_number</th>\\n', '      <th>boundary_condition_number</th>\\n', '      <th>river_reach_name</th>\\n', '      <th>river_station</th>\\n', '      <th>storage_area_name</th>\\n', '      <th>pump_station_name</th>\\n', '      <th>bc_type</th>\\n', '      <th>hydrograph_type</th>\\n', '      <th>Interval</th>\\n', '      <th>DSS File</th>\\n', '      <th>...</th>\\n', '      <th>Flow Title</th>\\n', '      <th>Program Version</th>\\n', '      <th>Use Restart</th>\\n', '      <th>Precipitation Mode</th>\\n', '      <th>Wind Mode</th>\\n', '      <th>Met BC=Precipitation|Mode</th>\\n', '      <th>Met BC=Evapotranspiration|Mode</th>\\n', '      <th>Met BC=Precipitation|Expanded View</th>\\n', '      <th>Met BC=Precipitation|Constant Units</th>\\n', '      <th>Met BC=Precipitation|Gridded Source</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    \n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "['Empty DataFrame\\n', 'Columns: [unsteady_number, boundary_condition_number, river_reach_name, river_station, storage_area_name, pump_station_name, bc_type, hydrograph_type, Interval, DSS File, DSS Path, Use DSS, Use Fixed Start Time, Fixed Start Date/Time, Is Critical Boundary, Critical Boundary Flow, hydrograph_num_values, hydrograph_values, full_path, Flow Title, Program Version, Use Restart, Precipitation Mode, Wind Mode, Met BC=Precipitation|Mode, Met BC=Evapotranspiration|Mode, Met BC=Precipitation|Expanded View, Met BC=Precipitation|Constant Units, Met BC=Precipitation|Gridded Source]\\n', 'Index: []\\n', '\\n', '[0 rows x 29 columns]']"
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dss_boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:43.022529Z",
          "iopub.status.busy": "2025-11-17T17:46:43.022259Z",
          "iopub.status.idle": "2025-11-17T17:46:43.026791Z",
          "shell.execute_reply": "2025-11-17T17:46:43.026288Z"
        }
      },
      "outputs": [],
      "source": [
        "if len(dss_boundaries) > 0:\n",
        "    # Get first DSS boundary\n",
        "    first_dss = dss_boundaries.iloc[0]\n",
        "    \n",
        "    print(f\"Boundary Type: {first_dss['bc_type']}\")\n",
        "    print(f\"DSS Path: {first_dss['DSS Path']}\")\n",
        "    \n",
        "    # Extract time series\n",
        "    dss_file_path = project_path / first_dss['DSS File']\n",
        "    df_ts = RasDss.read_timeseries(dss_file_path, first_dss['DSS Path'])\n",
        "    \n",
        "    print(f\"\\nExtracted {len(df_ts)} data points\")\n",
        "    print(f\"Date range: {df_ts.index.min()} to {df_ts.index.max()}\")\n",
        "    print(f\"Value range: {df_ts['value'].min():.2f} to {df_ts['value'].max():.2f}\")\n",
        "    print(f\"Units: {df_ts.attrs.get('units', 'N/A')}\")\n",
        "    \n",
        "    # Display first/last rows\n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    display(df_ts.head())\n",
        "    \n",
        "    print(f\"\\nLast 5 rows:\")\n",
        "    display(df_ts.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Plot Time Series\n",
        "\n",
        "Visualize the extracted DSS boundary condition data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:43.029190Z",
          "iopub.status.busy": "2025-11-17T17:46:43.028925Z",
          "iopub.status.idle": "2025-11-17T17:46:43.159527Z",
          "shell.execute_reply": "2025-11-17T17:46:43.158990Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Found 7 DSS-defined boundaries\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 0: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 2: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 4: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 5: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 6: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 7: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Row 8: Extracted 673 points from Bald_Eagle_Creek.dss\n",
            "2025-12-02 13:47:01 - ras_commander.dss.RasDss - INFO - Extraction complete: 7 success, 0 failed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extraction complete!\n",
            "Total boundaries: 10\n",
            "DSS-defined: 7\n",
            "\n",
            "DSS Boundary Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Flow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //BALD EAGLE 40/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 719.78 to 193738.20 CFS\n",
            "\n",
            "Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //FISHING CREEK/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 345.89 to 28510.08 CFS\n",
            "\n",
            "Uniform Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //RESERVOIR LOCAL/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 209.15 to 75262.30 CFS\n",
            "\n",
            "Uniform Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //LOCAL DOWNSTREAM OF DAM/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 9.98 to 5568.15 CFS\n",
            "\n",
            "Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //MARSH CREEK/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 94.61 to 37820.33 CFS\n",
            "\n",
            "Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //BEECH CREEK FLOW/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 382.69 to 32872.19 CFS\n",
            "\n",
            "Uniform Lateral Inflow Hydrograph:\n",
            "  Location: Bald Eagle Cr. RS Lock Haven\n",
            "  DSS Path: //BALD EAGLE LOCAL/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  Points: 673\n",
            "  Date range: 1999-01-01 00:00:00 to 1999-01-08 00:00:00\n",
            "  Value range: 100.19 to 27428.17 CFS\n"
          ]
        }
      ],
      "source": [
        "# Extract all DSS boundary time series for plan 07\n",
        "enhanced_boundaries = RasDss.extract_boundary_timeseries(\n",
        "    plan_07_boundaries, \n",
        "    ras_object=ras\n",
        ")\n",
        "\n",
        "# Show results\n",
        "print(f\"\\nExtraction complete!\")\n",
        "print(f\"Total boundaries: {len(enhanced_boundaries)}\")\n",
        "\n",
        "# Count DSS-defined boundaries (handle string 'True')\n",
        "dss_count = ((enhanced_boundaries['Use DSS'] == True) | (enhanced_boundaries['Use DSS'] == 'True')).sum()\n",
        "print(f\"DSS-defined: {dss_count}\")\n",
        "\n",
        "# Show extracted data summary\n",
        "print(f\"\\nDSS Boundary Summary:\")\n",
        "print(\"-\" * 80)\n",
        "for idx, row in enhanced_boundaries.iterrows():\n",
        "    # Check if DSS boundary (handle string 'True')\n",
        "    is_dss = (row['Use DSS'] == True) or (row['Use DSS'] == 'True')\n",
        "    if is_dss and row['dss_timeseries'] is not None:\n",
        "        df = row['dss_timeseries']\n",
        "        print(f\"\\n{row['bc_type']}:\")\n",
        "        print(f\"  Location: {row['river_reach_name']} RS {row['river_station']}\")\n",
        "        print(f\"  DSS Path: {row['DSS Path']}\")\n",
        "        print(f\"  Points: {len(df)}\")\n",
        "        print(f\"  Date range: {df.index.min()} to {df.index.max()}\")\n",
        "        print(f\"  Value range: {df['value'].min():.2f} to {df['value'].max():.2f} {df.attrs.get('units', '')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Extract ALL Boundary DSS Data\n",
        "\n",
        "Use the `extract_boundary_timeseries()` function to automatically extract ALL DSS boundary data in one call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:43.161938Z",
          "iopub.status.busy": "2025-11-17T17:46:43.161649Z",
          "iopub.status.idle": "2025-11-17T17:46:43.169344Z",
          "shell.execute_reply": "2025-11-17T17:46:43.168886Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boundary Definition Summary:\n",
            "================================================================================\n",
            "\n",
            "Manual boundaries (defined in .u## file): 3\n",
            "  Types:\n",
            "    - Gate Opening: 1\n",
            "    - Lateral Inflow Hydrograph: 1\n",
            "    - Normal Depth: 1\n",
            "\n",
            "DSS boundaries (defined in DSS file): 7\n",
            "  Types:\n",
            "    - Lateral Inflow Hydrograph: 3\n",
            "    - Uniform Lateral Inflow Hydrograph: 3\n",
            "    - Flow Hydrograph: 1\n",
            "\n",
            "Total boundaries: 10\n"
          ]
        }
      ],
      "source": [
        "# Count boundary types\n",
        "print(\"Boundary Definition Summary:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Handle both string and boolean 'Use DSS' values\n",
        "manual_bc = enhanced_boundaries[\n",
        "    (enhanced_boundaries['Use DSS'] == False) | (enhanced_boundaries['Use DSS'] == 'False') | (enhanced_boundaries['Use DSS'].isna())\n",
        "]\n",
        "dss_bc = enhanced_boundaries[\n",
        "    (enhanced_boundaries['Use DSS'] == True) | (enhanced_boundaries['Use DSS'] == 'True')\n",
        "]\n",
        "\n",
        "print(f\"\\nManual boundaries (defined in .u## file): {len(manual_bc)}\")\n",
        "if len(manual_bc) > 0:\n",
        "    print(\"  Types:\")\n",
        "    for bc_type, count in manual_bc['bc_type'].value_counts().items():\n",
        "        print(f\"    - {bc_type}: {count}\")\n",
        "\n",
        "print(f\"\\nDSS boundaries (defined in DSS file): {len(dss_bc)}\")\n",
        "if len(dss_bc) > 0:\n",
        "    print(\"  Types:\")\n",
        "    for bc_type, count in dss_bc['bc_type'].value_counts().items():\n",
        "        print(f\"    - {bc_type}: {count}\")\n",
        "\n",
        "print(f\"\\nTotal boundaries: {len(enhanced_boundaries)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Compare Manual vs DSS Boundaries\n",
        "\n",
        "Show the difference between manually-defined and DSS-defined boundary conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:43.171887Z",
          "iopub.status.busy": "2025-11-17T17:46:43.171588Z",
          "iopub.status.idle": "2025-11-17T17:46:44.304607Z",
          "shell.execute_reply": "2025-11-17T17:46:44.304096Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x2800 with 7 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get all successfully extracted DSS boundaries\n",
        "successful_dss = enhanced_boundaries[\n",
        "    ((enhanced_boundaries['Use DSS'] == True) | (enhanced_boundaries['Use DSS'] == 'True')) & \n",
        "    (enhanced_boundaries['dss_timeseries'].notna())\n",
        "]\n",
        "\n",
        "if len(successful_dss) > 0:\n",
        "    # Create subplots\n",
        "    n_plots = len(successful_dss)\n",
        "    fig, axes = plt.subplots(n_plots, 1, figsize=(14, 4*n_plots))\n",
        "    \n",
        "    if n_plots == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for ax, (idx, row) in zip(axes, successful_dss.iterrows()):\n",
        "        df = row['dss_timeseries']\n",
        "        \n",
        "        # Plot\n",
        "        df['value'].plot(ax=ax, linewidth=1.5, color='steelblue')\n",
        "        \n",
        "        # Format\n",
        "        title = f\"{row['bc_type']} - {row['river_reach_name']} RS {row['river_station']}\"\n",
        "        ax.set_title(title, fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('Date/Time', fontsize=9)\n",
        "        ax.set_ylabel(f\"Flow ({df.attrs.get('units', '')})\", fontsize=9)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add DSS path as text\n",
        "        ax.text(0.02, 0.98, f\"DSS: {row['DSS Path']}\", \n",
        "                transform=ax.transAxes, fontsize=8, \n",
        "                verticalalignment='top', family='monospace',\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No successful DSS extractions to plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Plot Multiple DSS Boundaries\n",
        "\n",
        "Create a multi-panel plot showing all DSS boundary conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:44.308678Z",
          "iopub.status.busy": "2025-11-17T17:46:44.308375Z",
          "iopub.status.idle": "2025-11-17T17:46:44.326171Z",
          "shell.execute_reply": "2025-11-17T17:46:44.325708Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\boundaries_with_dss_summary.csv\n",
            "\n",
            "DSS Boundary Statistics:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>bc_type</th>\\n', '      <th>Use DSS</th>\\n', '      <th>dss_points</th>\\n', '      <th>dss_mean</th>\\n', '      <th>dss_max</th>\\n', '      <th>dss_min</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    <tr>\\n', '      <th>0</th>\\n', '      <td>Flow Hydrograph</td>\\n', '      <td>True</td>\\n', '      <td>673.0</td>\\n', '      <td>23749.776843</td>\\n', '      <td>193738.197396</td>\\n', '      <td>719.775321</td>\\n', '    </tr><tr>\\n', '      <th>2</th>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>True</td>\\n', '      <td>673.0</td>\\n', '      <td>7554.055251</td>\\n', '      <td>28510.083069</td>\\n', '      <td>345.889757</td>\\n', '    </tr><tr>\\n', '      <th>4</th>\\n', '      <td>Uniform Lateral Inflow Hydrograph</td>\\n', '      <td>True</td>\\n', '      <td>673.0</td>\\n', '      <td>6448.671063</td>\\n', '      <td>75262.300507</td>\\n', '      <td>209.150354</td>\\n', '    </tr><tr>\\n', '      <th>5</th>\\n', '      <td>Uniform Lateral Inflow Hydrograph</td>\\n', '      <td>True</td>\\n', '      <td>673.0</td>\\n', '      <td>539.962137</td>\\n', '      <td>5568.152787</td>\\n', '      <td>9.979876</td>\\n', '    </tr><tr>\\n', '      <th>6</th>\\n', '      <td>Lateral Inflow Hydrograph</td>\\n', '      <td>True</td>\\n', '      <td>673.0</td>\\n', '      <td>4343.093777</td>\\n', '      <td>37820.325998</td>\\n', '      <td>94.606990</td>\\n', '    </tr>\n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "                             bc_type Use DSS  dss_points      dss_mean  \\\n",
              "0                    Flow Hydrograph    True       673.0  23749.776843   \n",
              "2          Lateral Inflow Hydrograph    True       673.0   7554.055251   \n",
              "4  Uniform Lateral Inflow Hydrograph    True       673.0   6448.671063   \n",
              "5  Uniform Lateral Inflow Hydrograph    True       673.0    539.962137   \n",
              "6          Lateral Inflow Hydrograph    True       673.0   4343.093777   \n",
              "7          Lateral Inflow Hydrograph    True       673.0   6971.806773   \n",
              "8  Uniform Lateral Inflow Hydrograph    True       673.0   2710.452795   \n",
              "\n",
              "         dss_max     dss_min  \n",
              "0  193738.197396  719.775321  \n",
              "2   28510.083069  345.889757  \n",
              "4   75262.300507  209.150354  \n",
              "5    5568.152787    9.979876  \n",
              "6   37820.325998   94.606990  \n",
              "7   32872.193876  382.693009  \n",
              "8   27428.172923  100.189004  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Export to CSV (without the DataFrame column)\n",
        "export_df = enhanced_boundaries.drop(columns=['dss_timeseries']).copy()\n",
        "\n",
        "# Add summary statistics for DSS boundaries\n",
        "for idx, row in enhanced_boundaries.iterrows():\n",
        "    is_dss = (row['Use DSS'] == True) or (row['Use DSS'] == 'True')\n",
        "    if is_dss and row['dss_timeseries'] is not None:\n",
        "        df = row['dss_timeseries']\n",
        "        export_df.at[idx, 'dss_points'] = len(df)\n",
        "        export_df.at[idx, 'dss_mean'] = df['value'].mean()\n",
        "        export_df.at[idx, 'dss_max'] = df['value'].max()\n",
        "        export_df.at[idx, 'dss_min'] = df['value'].min()\n",
        "\n",
        "# Save\n",
        "output_file = project_path / \"boundaries_with_dss_summary.csv\"\n",
        "export_df.to_csv(output_file, index=False)\n",
        "print(f\"Exported to: {output_file}\")\n",
        "\n",
        "# Show summary\n",
        "dss_summary_cols = ['bc_type', 'Use DSS', 'dss_points', 'dss_mean', 'dss_max', 'dss_min']\n",
        "available_cols = [c for c in dss_summary_cols if c in export_df.columns]\n",
        "print(f\"\\nDSS Boundary Statistics:\")\n",
        "\n",
        "# Filter for DSS boundaries\n",
        "dss_summary = export_df[\n",
        "    (export_df['Use DSS'] == True) | (export_df['Use DSS'] == 'True')\n",
        "][available_cols]\n",
        "display(dss_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Export Boundary Data\n",
        "\n",
        "Save extracted boundary condition data for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:44.328268Z",
          "iopub.status.busy": "2025-11-17T17:46:44.328039Z",
          "iopub.status.idle": "2025-11-17T17:46:44.338104Z",
          "shell.execute_reply": "2025-11-17T17:46:44.337573Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\boundaries_with_dss_summary.csv\n",
            "\n",
            "DSS Boundary Statistics:\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\\n', '    .dataframe tbody tr th:only-of-type {\\n', '        vertical-align: middle;\\n', '    }\\n', '\\n', '    .dataframe tbody tr th {\\n', '        vertical-align: top;\\n', '    }\\n', '\\n', '    .dataframe thead th {\\n', '        text-align: right;\\n', '    }\\n', '</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\\n', '    <tr style=\"text-align: right;\">\\n', '      <th></th>\\n', '      <th>bc_type</th>\\n', '      <th>Use DSS</th>\\n', '    </tr>\\n', '  </thead>\n  <tbody>\n    \n    <tr><td colspan=\"100%\" style=\"text-align:center\">[... additional rows truncated ...]</td></tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [bc_type, Use DSS]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Export to CSV (without the DataFrame column)\n",
        "export_df = enhanced_boundaries.drop(columns=['dss_timeseries']).copy()\n",
        "\n",
        "# Add summary statistics for DSS boundaries\n",
        "for idx, row in enhanced_boundaries[enhanced_boundaries['Use DSS'] == True].iterrows():\n",
        "    if row['dss_timeseries'] is not None:\n",
        "        df = row['dss_timeseries']\n",
        "        export_df.at[idx, 'dss_points'] = len(df)\n",
        "        export_df.at[idx, 'dss_mean'] = df['value'].mean()\n",
        "        export_df.at[idx, 'dss_max'] = df['value'].max()\n",
        "        export_df.at[idx, 'dss_min'] = df['value'].min()\n",
        "\n",
        "# Save\n",
        "output_file = project_path / \"boundaries_with_dss_summary.csv\"\n",
        "export_df.to_csv(output_file, index=False)\n",
        "print(f\"Exported to: {output_file}\")\n",
        "\n",
        "# Show summary\n",
        "dss_summary_cols = ['bc_type', 'Use DSS', 'dss_points', 'dss_mean', 'dss_max', 'dss_min']\n",
        "available_cols = [c for c in dss_summary_cols if c in export_df.columns]\n",
        "print(f\"\\nDSS Boundary Statistics:\")\n",
        "display(export_df[export_df['Use DSS'] == True][available_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Access Individual DSS Time Series\n",
        "\n",
        "Access extracted data from the enhanced boundaries_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-17T17:46:44.340353Z",
          "iopub.status.busy": "2025-11-17T17:46:44.340113Z",
          "iopub.status.idle": "2025-11-17T17:46:44.347833Z",
          "shell.execute_reply": "2025-11-17T17:46:44.347307Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accessing DSS data for boundary 0:\n",
            "  Type: Flow Hydrograph\n",
            "  Data points: 673\n",
            "\n",
            "Data statistics:\n",
            "count       673.000000\n",
            "mean      23749.776843\n",
            "std       42452.303066\n",
            "min         719.775321\n",
            "25%        4332.272683\n",
            "50%        7792.191249\n",
            "75%       14070.993090\n",
            "max      193738.197396\n",
            "Name: value, dtype: float64\n",
            "\n",
            "Metadata:\n",
            "  pathname: //BALD EAGLE 40/FLOW/01JAN1999/15MIN/RUN:PMF-EVENT/\n",
            "  units: CFS\n",
            "  type: INST-VAL\n",
            "  interval: 15\n",
            "  dss_file: C:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\Bald_Eagle_Creek.dss\n"
          ]
        }
      ],
      "source": [
        "# Access specific boundary by index\n",
        "if len(successful_dss) > 0:\n",
        "    # Get first successful DSS boundary\n",
        "    idx = successful_dss.index[0]\n",
        "    boundary_data = enhanced_boundaries.loc[idx, 'dss_timeseries']\n",
        "    \n",
        "    print(f\"Accessing DSS data for boundary {idx}:\")\n",
        "    print(f\"  Type: {enhanced_boundaries.loc[idx, 'bc_type']}\")\n",
        "    print(f\"  Data points: {len(boundary_data)}\")\n",
        "    \n",
        "    # Show statistics\n",
        "    print(f\"\\nData statistics:\")\n",
        "    print(boundary_data['value'].describe())\n",
        "    \n",
        "    # Access metadata\n",
        "    print(f\"\\nMetadata:\")\n",
        "    for key, value in boundary_data.attrs.items():\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. \u2705 Reading DSS file catalogs\n",
        "2. \u2705 Extracting individual time series from DSS files\n",
        "3. \u2705 Automatic extraction of ALL DSS boundary data with `extract_boundary_timeseries()`\n",
        "4. \u2705 Plotting and analyzing DSS data\n",
        "5. \u2705 Exporting results\n",
        "\n",
        "### Key Features\n",
        "- **Unified API** - Same DataFrame structure for manual and DSS boundaries\n",
        "- **Automatic extraction** - One function call extracts all DSS data\n",
        "- **V6 and V7 support** - Works with both DSS formats\n",
        "- **Auto-download** - HEC Monolith libraries downloaded automatically on first use\n",
        "\n",
        "### Next Steps\n",
        "- Use extracted data for boundary condition analysis\n",
        "- Compare DSS vs manual boundary definitions\n",
        "- Modify DSS data and write back to files (future enhancement)\n",
        "- Integrate DSS data with HEC-RAS model workflows"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\23_remote_execution_psexec.ipynb
==================================================
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remote Execution with PsExec\n",
        "\n",
        "This notebook demonstrates how to execute HEC-RAS plans on remote Windows machines using PsExec.\n",
        "\n",
        "**Features:**\n",
        "- Distributed execution across multiple remote machines\n",
        "- Automatic project deployment via network shares\n",
        "- Parallel execution with configurable workers\n",
        "- Result collection and consolidation\n",
        "- **Automatic PsExec.exe download** (no manual setup required)\n",
        "\n",
        "**Requirements:**\n",
        "- Remote machine(s) configured per REMOTE_WORKER_SETUP_GUIDE.md (see feature_dev_notes/RasRemote/)\n",
        "- Network share accessible from control machine\n",
        "- HEC-RAS installed on remote machine(s)\n",
        "\n",
        "**Note:** PsExec.exe will be automatically downloaded to `C:\\Users\\{username}\\psexec\\` if not found.\n",
        "\n",
        "**Author:** William (Bill) Katzenmeyer, P.E., C.F.M.\n",
        "\n",
        "**Date:** 2025-11-24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Optional Code Cell For Development/Testing Mode (Local Copy)\n",
        "##### Uncomment and run this cell instead of the pip cell above\n",
        "\n",
        "# For Development Mode, add the parent directory to the Python path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "current_file = Path(os.getcwd()).resolve()\n",
        "rascmdr_directory = current_file.parent\n",
        "\n",
        "# Use insert(0) instead of append() to give highest priority to local version\n",
        "if str(rascmdr_directory) not in sys.path:\n",
        "    sys.path.insert(0, str(rascmdr_directory))\n",
        "\n",
        "print(\"Loading ras-commander from local dev copy\")\n",
        "from ras_commander import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Remote Workers\n",
        "\n",
        "Load worker configurations from `RemoteWorkers.json` file using `load_workers_from_json()`.\n",
        "\n",
        "**First time setup:**\n",
        "1. Copy `RemoteWorkers.json.template` to `RemoteWorkers.json`\n",
        "2. Edit `RemoteWorkers.json` with your remote machine details\n",
        "3. The JSON file is in `.gitignore` for security (credentials won't be committed)\n",
        "\n",
        "**JSON Format:**\n",
        "```json\n",
        "{\n",
        "  \"workers\": [\n",
        "    {\n",
        "      \"name\": \"Local Compute\",\n",
        "      \"worker_type\": \"local\",\n",
        "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
        "      \"process_priority\": \"low\",\n",
        "      \"queue_priority\": 0,\n",
        "      \"cores_total\": 4,\n",
        "      \"cores_per_plan\": 2,\n",
        "      \"enabled\": true\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Remote Workstation\",\n",
        "      \"worker_type\": \"psexec\",\n",
        "      \"hostname\": \"192.168.1.100\",\n",
        "      \"share_path\": \"\\\\\\\\192.168.1.100\\\\RasRemote\",\n",
        "      \"worker_folder\": \"C:\\\\RasRemote\",\n",
        "      \"username\": \"your_username\",\n",
        "      \"password\": \"your_password\",\n",
        "      \"session_id\": 2,\n",
        "      \"process_priority\": \"low\",\n",
        "      \"queue_priority\": 1,\n",
        "      \"cores_total\": 16,\n",
        "      \"cores_per_plan\": 4,\n",
        "      \"enabled\": true\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Key Changes (v0.85.0):**\n",
        "- `ras_exe_path` is no longer required - automatically obtained from the initialized RAS project\n",
        "- Use `load_workers_from_json()` to load all workers from a JSON file\n",
        "- `worker_type` field is now required in each worker configuration\n",
        "- `worker_folder` replaces `local_path` - specifies where temp folders are created\n",
        "\n",
        "**Configuration Fields:**\n",
        "- `worker_type`: Required - \"psexec\", \"local\", \"ssh\", etc.\n",
        "- `worker_folder`: Local path where temporary worker folders are created during execution\n",
        "- `share_path`: (psexec only) UNC path to network share that maps to worker_folder\n",
        "- `process_priority`: OS process priority for HEC-RAS execution\n",
        "  - Valid values: `\"low\"` (default, recommended), `\"below normal\"`, `\"normal\"`\n",
        "- `queue_priority`: Execution queue priority (0-9)\n",
        "  - Lower values execute first (0 = highest priority)\n",
        "- `cores_total`: Total CPU cores on the remote machine (enables parallel execution)\n",
        "- `cores_per_plan`: Cores allocated to each HEC-RAS plan\n",
        "- **Parallel plans**: cores_total / cores_per_plan (e.g., 16/4 = 4 plans in parallel)\n",
        "\n",
        "**Session ID:** Use `query user` on remote machine to find (typically 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load remote worker configurations using the new load_workers_from_json() function\n",
        "# Note: Workers are loaded AFTER init_ras_project() so ras_exe_path is obtained automatically\n",
        "\n",
        "config_file = Path(\"RemoteWorkers.json\")\n",
        "\n",
        "if not config_file.exists():\n",
        "    print(\"ERROR: RemoteWorkers.json not found!\")\n",
        "    print()\n",
        "    print(\"First time setup:\")\n",
        "    print(\"1. Copy RemoteWorkers.json.template to RemoteWorkers.json\")\n",
        "    print(\"2. Edit RemoteWorkers.json with your remote machine details\")\n",
        "    print(\"3. Run this cell again\")\n",
        "    print()\n",
        "    print(\"The RemoteWorkers.json file should be in the same folder as this notebook.\")\n",
        "    raise FileNotFoundError(\"RemoteWorkers.json not found. See instructions above.\")\n",
        "\n",
        "# Preview the JSON configuration (without loading workers yet)\n",
        "import json\n",
        "with open(config_file, 'r') as f:\n",
        "    worker_configs = json.load(f)\n",
        "\n",
        "# Get enabled workers for display\n",
        "enabled_configs = [w for w in worker_configs[\"workers\"] if w.get(\"enabled\", True)]\n",
        "\n",
        "print(f\"Found {len(enabled_configs)} enabled worker(s) in RemoteWorkers.json:\")\n",
        "for w in enabled_configs:\n",
        "    cores_total = w.get('cores_total', 'Not set')\n",
        "    cores_per_plan = w.get('cores_per_plan', 4)\n",
        "    process_priority = w.get('process_priority', 'low')\n",
        "    queue_priority = w.get('queue_priority', 0)\n",
        "    \n",
        "    if w.get('cores_total'):\n",
        "        max_parallel = w['cores_total'] // cores_per_plan\n",
        "        parallel_info = f\"{max_parallel} plans in parallel\"\n",
        "    else:\n",
        "        parallel_info = \"Sequential execution\"\n",
        "\n",
        "    print(f\"  - {w.get('name', 'unnamed')} ({w.get('hostname', 'localhost')})\")\n",
        "    print(f\"    Type: {w.get('worker_type', 'unknown')}\")\n",
        "    print(f\"    Cores: {cores_total} total, {cores_per_plan} per plan \u2192 {parallel_info}\")\n",
        "    print(f\"    Process Priority: {process_priority}, Queue Priority: {queue_priority}\")\n",
        "\n",
        "print()\n",
        "print(\"NOTE: Workers will be loaded after init_ras_project() to get ras_exe_path automatically\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Example 1: Execute Single Plan (Muncie)\n",
        "\n",
        "Simple example executing one plan from the Muncie example project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Muncie example project\n",
        "muncie_path = RasExamples.extract_project(\"Muncie\")\n",
        "print(f\"Project extracted to: {muncie_path}\")\n",
        "\n",
        "# Initialize project (updates global ras object)\n",
        "init_ras_project(muncie_path, \"6.6\")\n",
        "print(f\"Project initialized: {ras.project_name}\")\n",
        "print(f\"Available plans: {list(ras.plan_df.index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load workers from JSON - ras_exe_path is automatically obtained from the ras object\n",
        "# This must be called AFTER init_ras_project() so the RAS executable path is known\n",
        "\n",
        "workers = load_workers_from_json(\"RemoteWorkers.json\")\n",
        "\n",
        "print(f\"Loaded {len(workers)} worker(s):\")\n",
        "for w in workers:\n",
        "    print(f\"  - {w.worker_id} ({w.worker_type})\")\n",
        "    print(f\"    Hostname: {w.hostname}\")\n",
        "    print(f\"    RAS Exe: {w.ras_exe_path}\")\n",
        "    print(f\"    Session ID: {getattr(w, 'session_id', 'N/A')}\")\n",
        "    print(f\"    Process Priority: {getattr(w, 'process_priority', 'N/A')}\")\n",
        "    print(f\"    Queue Priority: {getattr(w, 'queue_priority', 'N/A')}\")\n",
        "    if hasattr(w, 'max_parallel_plans') and w.max_parallel_plans > 1:\n",
        "        print(f\"    Parallel Capacity: {w.max_parallel_plans} plans simultaneously\")\n",
        "    print()\n",
        "\n",
        "# Use first worker for single-plan examples\n",
        "if workers:\n",
        "    worker = workers[0]\n",
        "    print(f\"Using worker for examples: {worker.worker_id}\")\n",
        "else:\n",
        "    raise ValueError(\"No workers loaded from RemoteWorkers.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute Plan 01 remotely\n",
        "# autoclean=True (default) deletes worker folders after execution\n",
        "# Set autoclean=False for debugging to preserve worker folders on the remote machine\n",
        "\n",
        "print(\"Executing Plan 01 on remote machine...\")\n",
        "print(\"This will take ~30-60 seconds\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "results = compute_parallel_remote(\n",
        "    plan_numbers=\"01\",\n",
        "    workers=[worker],\n",
        "    num_cores=4,\n",
        "    autoclean=True  # Default is True - deletes temp folders after execution\n",
        ")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "\n",
        "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
        "print(f\"\\nResults:\")\n",
        "for plan_num, result in results.items():\n",
        "    if result.success:\n",
        "        print(f\"  Plan {plan_num}: SUCCESS\")\n",
        "        print(f\"    HDF Path: {result.hdf_path}\")\n",
        "        print(f\"    Execution Time: {result.execution_time:.1f}s\")\n",
        "    else:\n",
        "        print(f\"  Plan {plan_num}: FAILED - {result.error_message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify Muncie results using HDF analysis\n",
        "from ras_commander import HdfResultsPlan\n",
        "\n",
        "hdf_path = Path(muncie_path) / \"Muncie.p01.hdf\"\n",
        "\n",
        "if hdf_path.exists():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"MUNCIE PLAN 01 - RESULT VERIFICATION\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "    \n",
        "    # Get basic info\n",
        "    size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"HDF File: {hdf_path.name}\")\n",
        "    print(f\"Size: {size_mb:.2f} MB\")\n",
        "    print()\n",
        "    \n",
        "    # Get compute messages (static method)\n",
        "    msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
        "    \n",
        "    if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
        "        print(\"Compute Status: \u2705 Successful\")\n",
        "    else:\n",
        "        print(\"Compute Status: \u26a0\ufe0f Check messages\")\n",
        "    \n",
        "    # Show last part of compute messages\n",
        "    print(\"\\nCompute Messages (last 250 chars):\")\n",
        "    print(msgs[-250:])\n",
        "    print()\n",
        "    \n",
        "    # Get steady flow results\n",
        "    is_steady = HdfResultsPlan.is_steady_plan(hdf_path)\n",
        "    if is_steady:\n",
        "        profiles = HdfResultsPlan.get_steady_profile_names(hdf_path)\n",
        "        print(f\"Steady Flow Profiles: {profiles}\")\n",
        "        \n",
        "        # Get WSE for first profile\n",
        "        if profiles:\n",
        "            wse_df = HdfResultsPlan.get_steady_wse(hdf_path, profiles[0])\n",
        "            if wse_df is not None and len(wse_df) > 0:\n",
        "                print(f\"Cross Sections: {len(wse_df)}\")\n",
        "                print(f\"WSE Range: {wse_df['W.S. Elev'].min():.2f} to {wse_df['W.S. Elev'].max():.2f} ft\")\n",
        "    \n",
        "    # Get volume accounting\n",
        "    try:\n",
        "        vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
        "        if vol is not None:\n",
        "            print(f\"\\nVolume Accounting: Available ({len(vol)} entries)\")\n",
        "            print(vol)\n",
        "    except:\n",
        "        print(\"\\nVolume Accounting: Not available\")\n",
        "    \n",
        "    print()\n",
        "    print(\"\u2705 Remote execution verified - HDF results successfully collected!\")\n",
        "    print()\n",
        "else:\n",
        "    print(\"\u274c HDF file not found - execution may have failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract BaldEagleCrkMulti2D project\n",
        "baldeagle_path = RasExamples.extract_project(\"BaldEagleCrkMulti2D\")\n",
        "print(f\"Project extracted to: {baldeagle_path}\")\n",
        "\n",
        "# Initialize project (updates global ras object)\n",
        "init_ras_project(baldeagle_path, \"6.6\")\n",
        "print(f\"Project initialized: {ras.project_name}\")\n",
        "print(f\"Available plans: {list(ras.plan_df.index)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute expanded set of plans to test queue priority and parallel execution\n",
        "# Plans 03, 04, 06, 13, 15, 17, 18, 19 - 8 plans total\n",
        "# This tests the queue-aware scheduling with multiple sub-workers\n",
        "\n",
        "test_plans = [\"03\", \"04\", \"06\", \"13\", \"15\", \"17\", \"18\", \"19\"]\n",
        "print(f\"Executing {len(test_plans)} plans on remote machine: {test_plans}\")\n",
        "print(\"These are 2D unsteady models - may take 10-20 minutes total\")\n",
        "print(\"Watch the logs to observe queue priority and wave scheduling\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "results = compute_parallel_remote(\n",
        "    plan_numbers=test_plans,\n",
        "    workers=[worker],\n",
        "    num_cores=4,\n",
        "    autoclean=True  # Default is True - deletes temp folders after execution\n",
        ")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "\n",
        "print(f\"\\nExecution complete in {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
        "print(f\"\\nResults:\")\n",
        "success_count = 0\n",
        "for plan_num, result in results.items():\n",
        "    if result.success:\n",
        "        print(f\"  Plan {plan_num}: SUCCESS ({result.execution_time:.1f}s)\")\n",
        "        success_count += 1\n",
        "    else:\n",
        "        print(f\"  Plan {plan_num}: FAILED - {result.error_message}\")\n",
        "\n",
        "print(f\"\\nSummary: {success_count}/{len(results)} plans succeeded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify BaldEagle results using HDF analysis\n",
        "from ras_commander import HdfResultsPlan, HdfResultsMesh\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BALDEAGLE PLANS 06 & 19 - RESULT VERIFICATION\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "for plan_num in [\"06\", \"19\"]:\n",
        "    hdf_path = Path(baldeagle_path) / f\"BaldEagleDamBrk.p{plan_num}.hdf\"\n",
        "    \n",
        "    if hdf_path.exists():\n",
        "        print(f\"Plan {plan_num}:\")\n",
        "        size_mb = hdf_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  HDF Size: {size_mb:.2f} MB\")\n",
        "        \n",
        "        # Get compute messages (static method)\n",
        "        msgs = HdfResultsPlan.get_compute_messages(hdf_path)\n",
        "        if \"completed successfully\" in msgs.lower() or \"complete process\" in msgs.lower():\n",
        "            print(f\"  Status: \u2705 Computation successful\")\n",
        "        else:\n",
        "            print(f\"  Status: \u26a0\ufe0f Check compute messages\")\n",
        "        \n",
        "        # Get unsteady summary\n",
        "        try:\n",
        "            summary = HdfResultsPlan.get_unsteady_summary(hdf_path)\n",
        "            if summary is not None:\n",
        "                print(f\"  Unsteady Summary: Available\")\n",
        "        except:\n",
        "            print(f\"  Unsteady Summary: Not available\")\n",
        "        \n",
        "        # Get volume accounting\n",
        "        try:\n",
        "            vol = HdfResultsPlan.get_volume_accounting(hdf_path)\n",
        "            if vol is not None and len(vol) > 0:\n",
        "                print(f\"  Volume Accounting: {len(vol)} entries\")\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Get mesh timesteps for 2D\n",
        "        try:\n",
        "            mesh_times = HdfResultsMesh.get_output_times(hdf_path)\n",
        "            if mesh_times is not None:\n",
        "                print(f\"  Output Timesteps: {len(mesh_times)}\")\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        print()\n",
        "    else:\n",
        "        print(f\"Plan {plan_num}: \u274c HDF file not found\")\n",
        "        print()\n",
        "\n",
        "print(\"\u2705 Remote execution verified - 2D model results successfully collected!\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Example 3: Multiple Remote Workers (Parallel)\n",
        "\n",
        "Execute plans across multiple remote machines simultaneously.\n",
        "\n",
        "**Note:** This example uses ALL enabled workers from `RemoteWorkers.json`.\n",
        "To use multiple machines, add additional workers to the JSON file and set `enabled: true`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute multiple plans across all loaded workers\n",
        "# Plans will be distributed based on queue_priority (0 first, then 1, etc.)\n",
        "\n",
        "# Workers were already loaded in cell-7 using load_workers_from_json()\n",
        "if len(workers) > 1:\n",
        "    print(f\"Executing plans across {len(workers)} worker(s)...\")\n",
        "    for w in workers:\n",
        "        print(f\"  - {w.worker_id} ({w.hostname}) - Queue {getattr(w, 'queue_priority', 0)}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    results = compute_parallel_remote(\n",
        "        plan_numbers=[\"06\", \"19\"],\n",
        "        workers=workers,\n",
        "        num_cores=4,\n",
        "        clear_geompre=False,\n",
        "        autoclean=True  # Default is True - deletes temp folders after execution\n",
        "    )\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\nTotal execution time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
        "    print(f\"\\nResults:\")\n",
        "    for plan_num, result in results.items():\n",
        "        status = \"SUCCESS\" if result.success else f\"FAILED: {result.error_message}\"\n",
        "        print(f\"  Plan {plan_num}: {status}\")\n",
        "    \n",
        "    # Calculate speedup\n",
        "    successful = sum(1 for r in results.values() if r.success)\n",
        "    print(f\"\\nSummary: {successful}/{len(results)} plans succeeded\")\n",
        "else:\n",
        "    print(f\"Only 1 worker loaded - skipping multi-worker example\")\n",
        "    print(f\"To test parallel execution:\")\n",
        "    print(f\"  1. Add more workers to RemoteWorkers.json\")\n",
        "    print(f\"  2. Set enabled=true for each\")\n",
        "    print(f\"  3. Re-run the notebook from the beginning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Manually initialize a worker without JSON file\n",
        "# This demonstrates the init_ras_worker() function directly\n",
        "# Note: ras_exe_path is automatically obtained from the ras object\n",
        "\n",
        "manual_worker = init_ras_worker(\n",
        "    \"psexec\",\n",
        "    hostname=\"192.168.3.8\",  # Replace with your hostname\n",
        "    share_path=r\"\\\\192.168.3.8\\RasRemote\",  # Replace with your share path\n",
        "    worker_folder=r\"C:\\RasRemote\",  # Local path on remote machine corresponding to share_path\n",
        "    credentials={\n",
        "        \"username\": \".\\\\bill\",  # Replace with your username\n",
        "        \"password\": \"YourPassword\"  # Replace with your password\n",
        "    },\n",
        "    # ras_exe_path is NOT required - obtained from ras object automatically\n",
        "    session_id=2,\n",
        "    process_priority=\"low\",\n",
        "    queue_priority=0,\n",
        "    cores_total=8,\n",
        "    cores_per_plan=2\n",
        ")\n",
        "\n",
        "print(f\"Manual worker initialized:\")\n",
        "print(f\"  Worker ID: {manual_worker.worker_id}\")\n",
        "print(f\"  Hostname: {manual_worker.hostname}\")\n",
        "print(f\"  Worker Folder: {manual_worker.worker_folder}\")\n",
        "print(f\"  RAS Exe: {manual_worker.ras_exe_path}\")  # Automatically set from ras object\n",
        "print(f\"  Parallel Capacity: {manual_worker.max_parallel_plans} plans\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Results\n",
        "\n",
        "Check that HDF files were created and results collected properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List only .pXX.hdf files in results folder (plan result HDFs)\n",
        "import re\n",
        "\n",
        "results_path = Path(baldeagle_path).parent / \"multi_worker_results\" / \"BaldEagleDamBrk\"\n",
        "\n",
        "pattern = re.compile(r\"\\.p\\d{2}\\.hdf$\", re.IGNORECASE)\n",
        "\n",
        "if results_path.exists():\n",
        "    hdf_files = [hdf for hdf in results_path.glob(\"*.hdf\") if pattern.search(hdf.name)]\n",
        "    print(f\"Plan HDF files (.pXX.hdf) in results folder: {len(hdf_files)}\")\n",
        "    for hdf in hdf_files:\n",
        "        size_mb = hdf.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  {hdf.name}: {size_mb:.2f} MB\")\n",
        "else:\n",
        "    print(f\"Results folder not found: {results_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Advanced Configuration\n",
        "\n",
        "### Session ID Determination\n",
        "\n",
        "Find the active session ID on a remote machine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query active sessions on remote machine\n",
        "# Uses the first loaded worker to get psexec_path and credentials\n",
        "import subprocess\n",
        "\n",
        "if workers:\n",
        "    w = workers[0]\n",
        "    psexec = getattr(w, 'psexec_path', None)\n",
        "    \n",
        "    if psexec and hasattr(w, 'credentials') and w.credentials:\n",
        "        cmd = [\n",
        "            psexec,\n",
        "            f\"\\\\\\\\{w.hostname}\",\n",
        "            \"-u\", w.credentials.get(\"username\", \"\"),\n",
        "            \"-p\", w.credentials.get(\"password\", \"\"),\n",
        "            \"-accepteula\",\n",
        "            \"cmd\", \"/c\", \"query\", \"user\"\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)\n",
        "            print(\"Active sessions on remote machine:\")\n",
        "            print(result.stdout)\n",
        "            print(\"\\nLook for the ID column - typically 2 for workstations\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"Timeout querying sessions\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not query sessions: {e}\")\n",
        "    else:\n",
        "        print(\"Worker doesn't have psexec_path or credentials set\")\n",
        "        print(\"Try session_id=2 (most common for single-user workstations)\")\n",
        "else:\n",
        "    print(\"No workers loaded - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Process Priority Levels\n",
        "\n",
        "Control OS process priority for remote HEC-RAS execution:\n",
        "\n",
        "- `\"low\"` - Low priority (recommended for background work, minimal impact on remote user)\n",
        "- `\"below normal\"` - Below normal priority\n",
        "- `\"normal\"` - Normal priority (default Windows priority)\n",
        "\n",
        "**Note:** Higher priorities (above normal, high, realtime) are NOT supported to avoid impacting remote user operations.\n",
        "\n",
        "### Queue Priority\n",
        "\n",
        "Control execution order across workers:\n",
        "\n",
        "- `queue_priority` is an integer from 0-9 (lower = higher priority)\n",
        "- Workers at queue level 0 are filled before queue level 1, etc.\n",
        "- Within each queue level, wave scheduling applies (one plan per machine first, then additional)\n",
        "- Use for tiered bursting: local workers (queue 0) execute first, then remote (queue 1), then cloud (queue 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Viewing worker configuration with low process priority\n",
        "# Workers loaded from JSON already have these settings applied\n",
        "\n",
        "if workers:\n",
        "    w = workers[0]\n",
        "    print(f\"Worker: {w.worker_id}\")\n",
        "    print(f\"  Process Priority: {getattr(w, 'process_priority', 'N/A')}\")\n",
        "    print(f\"  Queue Priority: {getattr(w, 'queue_priority', 'N/A')}\")\n",
        "    print(f\"  RAS Exe Path: {w.ras_exe_path}\")\n",
        "    print()\n",
        "    print(\"To change settings, edit RemoteWorkers.json and reload workers:\")\n",
        "    print(\"  workers = load_workers_from_json('RemoteWorkers.json')\")\n",
        "else:\n",
        "    print(\"No workers loaded - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Troubleshooting (Optional)\n",
        "\n",
        "### Test Remote Connections using psexec\n",
        "\n",
        "Change the cell below to a code cell, enter your username and password for use in testing. \n",
        "\n",
        "Don't leave your passwords here, it can get synced back to git.  Use RemoteWorkers.json, it is already in the .gitignore for this repo.  \n",
        "Use the code cell below for testing only, not as a design pattern for production usage: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build REMOTE_CONFIG from the first psexec worker in workers list\n",
        "# This uses the credentials already loaded from RemoteWorkers.json\n",
        "\n",
        "REMOTE_CONFIG = None\n",
        "\n",
        "if workers:\n",
        "    # Find first psexec worker\n",
        "    for w in workers:\n",
        "        if w.worker_type == \"psexec\":\n",
        "            REMOTE_CONFIG = {\n",
        "                \"hostname\": w.hostname,\n",
        "                \"share_path\": w.share_path,\n",
        "                \"username\": w.credentials.get(\"username\", \"\") if hasattr(w, 'credentials') and w.credentials else \"\",\n",
        "                \"password\": w.credentials.get(\"password\", \"\") if hasattr(w, 'credentials') and w.credentials else \"\",\n",
        "                \"ras_exe_path\": w.ras_exe_path,\n",
        "                \"session_id\": getattr(w, 'session_id', 2)\n",
        "            }\n",
        "            print(f\"REMOTE_CONFIG built from worker: {w.worker_id}\")\n",
        "            print(f\"  Hostname: {REMOTE_CONFIG['hostname']}\")\n",
        "            print(f\"  Share Path: {REMOTE_CONFIG['share_path']}\")\n",
        "            print(f\"  Session ID: {REMOTE_CONFIG['session_id']}\")\n",
        "            break\n",
        "\n",
        "if REMOTE_CONFIG is None:\n",
        "    print(\"WARNING: No psexec workers found in workers list.\")\n",
        "    print(\"Define REMOTE_CONFIG manually or add psexec workers to RemoteWorkers.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test basic PsExec connectivity\n",
        "import subprocess\n",
        "\n",
        "if REMOTE_CONFIG is None:\n",
        "    print(\"REMOTE_CONFIG not set - run the cell above first\")\n",
        "else:\n",
        "    # Get psexec path from the initialized worker\n",
        "    try:\n",
        "        temp_worker = init_ras_worker(\n",
        "            \"psexec\",\n",
        "            hostname=REMOTE_CONFIG[\"hostname\"],\n",
        "            share_path=REMOTE_CONFIG[\"share_path\"],\n",
        "            credentials={\n",
        "                \"username\": REMOTE_CONFIG[\"username\"],\n",
        "                \"password\": REMOTE_CONFIG[\"password\"]\n",
        "            },\n",
        "            session_id=REMOTE_CONFIG[\"session_id\"]\n",
        "        )\n",
        "        psexec_path = temp_worker.psexec_path\n",
        "\n",
        "        test_cmd = [\n",
        "            psexec_path,\n",
        "            f\"\\\\\\\\{REMOTE_CONFIG['hostname']}\",\n",
        "            \"-u\", REMOTE_CONFIG[\"username\"],\n",
        "            \"-p\", REMOTE_CONFIG[\"password\"],\n",
        "            \"-i\", str(REMOTE_CONFIG[\"session_id\"]),\n",
        "            \"-accepteula\",\n",
        "            \"cmd\", \"/c\", \"echo\", \"SUCCESS\"\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(test_cmd, capture_output=True, text=True, timeout=30)\n",
        "        if \"SUCCESS\" in result.stdout:\n",
        "            print(\"[OK] PsExec connection successful!\")\n",
        "        else:\n",
        "            print(\"[WARNING] Unexpected output:\")\n",
        "            print(result.stdout)\n",
        "            print(result.stderr)\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"[FAIL] Connection timeout - check firewall and services\")\n",
        "    except Exception as e:\n",
        "        print(f\"[FAIL] Connection error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Share Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test if share is accessible\n",
        "from pathlib import WindowsPath\n",
        "\n",
        "if REMOTE_CONFIG is None:\n",
        "    print(\"REMOTE_CONFIG not set - run the 'Build REMOTE_CONFIG' cell first\")\n",
        "else:\n",
        "    share_path = Path(REMOTE_CONFIG[\"share_path\"])\n",
        "\n",
        "    try:\n",
        "        # This may fail without authenticated session - that's OK\n",
        "        if share_path.exists():\n",
        "            print(f\"[OK] Share accessible: {share_path}\")\n",
        "            files = list(share_path.iterdir())[:5]\n",
        "            print(f\"     Contents: {len(list(share_path.iterdir()))} items\")\n",
        "        else:\n",
        "            print(f\"[INFO] Share not accessible via Path.exists() (authentication may be required)\")\n",
        "            print(f\"      This is normal - share will be accessed during execution with credentials\")\n",
        "    except Exception as e:\n",
        "        print(f\"[INFO] Cannot test share access: {e}\")\n",
        "        print(f\"      This is normal - share will be accessed during execution with credentials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Notes and Best Practices\n",
        "\n",
        "### Remote Worker Configuration:\n",
        "- Credentials stored in `RemoteWorkers.json` (not committed to git)\n",
        "- See **REMOTE_WORKERS_README.md** for JSON format and setup\n",
        "- Template provided: `RemoteWorkers.json.template`\n",
        "\n",
        "### Remote Worker Requirements:\n",
        "1. \u2705 Network share created and accessible\n",
        "2. \u2705 User in local Administrators group\n",
        "3. \u2705 Group Policy: User added to network access, local logon, batch job policies\n",
        "4. \u2705 Registry: LocalAccountTokenFilterPolicy = 1\n",
        "5. \u2705 Remote Registry service running\n",
        "6. \u2705 Windows Firewall configured\n",
        "7. \u2705 Machine rebooted after changes\n",
        "\n",
        "### Session ID:\n",
        "- Session ID 2 is typical for single-user workstations\n",
        "- Use `query user` on remote machine to verify\n",
        "- User must be logged in for session to be active\n",
        "- Session ID can change if user logs off/on\n",
        "\n",
        "### HEC-RAS Considerations:\n",
        "- HEC-RAS is a GUI application\n",
        "- MUST use session-based execution (`system_account=False`)\n",
        "- NEVER use SYSTEM account (`system_account=True`) for HEC-RAS\n",
        "- HEC-RAS window will start on the desktop of the remote desktop\n",
        "- Ensure HEC-RAS version matches on all workers, and TOS has been accepted.\n",
        "\n",
        "### Performance:\n",
        "- Network share speed affects file transfer\n",
        "- Use Gigabit Ethernet for best performance\n",
        "- 2-4 workers per machine optimal (depends on cores/RAM)\n",
        "- Plans execute sequentially on each worker\n",
        "- Multiple workers enable true parallel execution\n",
        "\n",
        "### Security:\n",
        "- Credentials in `RemoteWorkers.json` (in .gitignore)\n",
        "- Never commit credentials to git\n",
        "- See setup instructions for required group policy and registry changes\n",
        "\n",
        "### Debugging:\n",
        "- Check logs in ras_commander.log\n",
        "- Inspect compute messages: `project.p##.computeMsgs.txt`\n",
        "- Verify temp folders on remote share\n",
        "- Test PsExec manually with provided batch files\n",
        "\n",
        "---\n",
        "\n",
        "**For complete setup instructions, see:**\n",
        "- `feature_dev_notes/RasRemote/REMOTE_WORKER_SETUP_GUIDE.md` - Remote machine setup\n",
        "- `REMOTE_WORKERS_README.md` - JSON credential file format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Cleanup Remote Worker Folders\n",
        "\n",
        "The `autoclean=True` parameter (default) automatically deletes worker folders after execution.\n",
        "However, if you used `autoclean=False` for debugging or if executions were interrupted,\n",
        "you may have leftover folders on the remote shares.\n",
        "\n",
        "**All files in the RasRemote share are considered temporary** and can be safely deleted\n",
        "to preserve disk space on the remote machines.\n",
        "\n",
        "Run the cells below to manually clean up any remaining worker folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List and optionally clean up worker folders on remote machines\n",
        "# This cleans ALL files in the RasRemote share - all contents are temporary\n",
        "\n",
        "def cleanup_remote_shares(workers, dry_run=True):\n",
        "    \"\"\"\n",
        "    Clean up worker folders from remote shares.\n",
        "    \n",
        "    Args:\n",
        "        workers: List of worker objects with share_path attribute\n",
        "        dry_run: If True, only list folders without deleting (default True for safety)\n",
        "    \n",
        "    Returns:\n",
        "        dict: {hostname: {\"folders\": count, \"size_mb\": total_size}}\n",
        "    \"\"\"\n",
        "    import shutil\n",
        "    \n",
        "    results = {}\n",
        "    seen_shares = set()\n",
        "    \n",
        "    for w in workers:\n",
        "        if not hasattr(w, 'share_path') or not w.share_path:\n",
        "            continue\n",
        "            \n",
        "        share_path = Path(w.share_path)\n",
        "        share_key = str(share_path)\n",
        "        \n",
        "        # Skip if we've already processed this share\n",
        "        if share_key in seen_shares:\n",
        "            continue\n",
        "        seen_shares.add(share_key)\n",
        "        \n",
        "        hostname = getattr(w, 'hostname', 'unknown')\n",
        "        \n",
        "        try:\n",
        "            if not share_path.exists():\n",
        "                print(f\"Share not accessible: {share_path}\")\n",
        "                continue\n",
        "                \n",
        "            folders = [f for f in share_path.iterdir() if f.is_dir()]\n",
        "            total_size = 0\n",
        "            \n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Share: {share_path} ({hostname})\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            if not folders:\n",
        "                print(\"  No folders found - share is clean\")\n",
        "                results[hostname] = {\"folders\": 0, \"size_mb\": 0}\n",
        "                continue\n",
        "                \n",
        "            for folder in folders:\n",
        "                # Calculate folder size\n",
        "                folder_size = sum(f.stat().st_size for f in folder.rglob('*') if f.is_file())\n",
        "                folder_size_mb = folder_size / (1024 * 1024)\n",
        "                total_size += folder_size_mb\n",
        "                \n",
        "                if dry_run:\n",
        "                    print(f\"  [WOULD DELETE] {folder.name} ({folder_size_mb:.1f} MB)\")\n",
        "                else:\n",
        "                    print(f\"  [DELETING] {folder.name} ({folder_size_mb:.1f} MB)\")\n",
        "                    shutil.rmtree(folder, ignore_errors=True)\n",
        "            \n",
        "            results[hostname] = {\"folders\": len(folders), \"size_mb\": total_size}\n",
        "            \n",
        "            if dry_run:\n",
        "                print(f\"\\n  Summary: {len(folders)} folders, {total_size:.1f} MB total\")\n",
        "                print(f\"  Set dry_run=False to delete these folders\")\n",
        "            else:\n",
        "                print(f\"\\n  Deleted: {len(folders)} folders, {total_size:.1f} MB freed\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing {share_path}: {e}\")\n",
        "            \n",
        "    return results\n",
        "\n",
        "# DRY RUN - List folders without deleting\n",
        "print(\"=\" * 70)\n",
        "print(\"CLEANUP PREVIEW (dry_run=True)\")\n",
        "print(\"=\" * 70)\n",
        "cleanup_results = cleanup_remote_shares(workers, dry_run=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ACTUALLY DELETE - Uncomment and run to delete all worker folders\n",
        "# WARNING: This permanently deletes all folders in the RasRemote shares!\n",
        "\n",
        "# print(\"=\" * 70)\n",
        "# print(\"CLEANUP EXECUTION (dry_run=False)\")\n",
        "# print(\"=\" * 70)\n",
        "# cleanup_results = cleanup_remote_shares(workers, dry_run=False)\n",
        "# print(\"\\nCleanup complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rascmdr_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
==================================================

File: C:\GH\ras-commander\examples\AGENTS.md
==================================================
**Agent Guide: Examples Notebooks**

Purpose: Help an agent navigate each notebook quickly and extract only the logic needed to build scripts. Treat notebooks as reference; prefer cleaned copies (no images/outputs) when available.

How agents should use notebooks
- Read code cells, ignore long outputs and images.
- Understand the intent and data flow; note any environment-specific paths.
- Extract relevant cells into a script, replacing Jupyter-only commands (e.g., `!pip install`) with `uv pip install` run in the terminal.
- Execute scripts via `uv run ...` with inputs/outputs in a writable folder (e.g., `working/`).

00_Using_RasExamples.ipynb
- Focus: Download/list/extract official example projects.
- Functions: [RasExamples.get_example_projects](../ras_commander/RasExamples.py), [RasExamples.list_categories](../ras_commander/RasExamples.py), [RasExamples.list_projects](../ras_commander/RasExamples.py), [RasExamples.extract_project](../ras_commander/RasExamples.py), [RasExamples.is_project_extracted](../ras_commander/RasExamples.py), [RasExamples.clean_projects_directory](../ras_commander/RasExamples.py).
- Pattern: Extract to a writable workspace folder (not inside repo) to avoid committing large assets.

01_project_initialization.ipynb
- Focus: Initialize a project and inspect metadata.
- Functions: [init_ras_project](../ras_commander/RasPrj.py), [RasPrj](../ras_commander/RasPrj.py), [get_ras_exe](../ras_commander/RasPrj.py); ras dataframes: `plan_df`, `geom_df`, `flow_df`, `unsteady_df`, `boundaries_df`, [get_hdf_entries](../ras_commander/RasPrj.py).
- Pattern: Use global `ras` for single-project workflows; prefer separate `RasPrj` instances for multi-project work.

02_plan_and_geometry_operations.ipynb
- Focus: Clone/retarget plans, geometry, and intervals.
- Functions: [RasPlan.clone_plan](../ras_commander/RasPlan.py), [RasPlan.clone_geom](../ras_commander/RasPlan.py), [RasPlan.clone_unsteady](../ras_commander/RasPlan.py), [RasPlan.clone_steady](../ras_commander/RasPlan.py), [RasPlan.set_geom](../ras_commander/RasPlan.py), [RasPlan.set_steady](../ras_commander/RasPlan.py), [RasPlan.set_unsteady](../ras_commander/RasPlan.py), [RasPlan.set_geom_preprocessor](../ras_commander/RasPlan.py), [RasPlan.set_num_cores](../ras_commander/RasPlan.py), [RasPlan.update_run_flags](../ras_commander/RasPlan.py), [RasPlan.update_plan_intervals](../ras_commander/RasPlan.py), [RasPlan.update_simulation_date](../ras_commander/RasPlan.py), [RasPlan.update_plan_description](../ras_commander/RasPlan.py), [RasPlan.get_shortid](../ras_commander/RasPlan.py)/[set_shortid](../ras_commander/RasPlan.py).
- Pattern: Two-digit plan numbers; clear geompre when geometry changes.

03_unsteady_flow_operations.ipynb
- Focus: Inspect/modify unsteady (.uXX) files and BC tables.
- Functions: [RasUnsteady.update_flow_title](../ras_commander/RasUnsteady.py), [RasUnsteady.update_restart_settings](../ras_commander/RasUnsteady.py), [RasUnsteady.extract_boundary_and_tables](../ras_commander/RasUnsteady.py), [RasUnsteady.identify_tables](../ras_commander/RasUnsteady.py), [RasUnsteady.write_table_to_file](../ras_commander/RasUnsteady.py).
- Pattern: Clone unsteady first, then edit; reassign plan to updated unsteady.

04_multiple_project_operations.ipynb
- Focus: Work with several projects at once.
- Functions: `RasPrj` per project; [RasCmdr.compute_plan](../ras_commander/RasCmdr.py)/[compute_parallel](../ras_commander/RasCmdr.py) with `ras_object`.
- Pattern: Isolate compute folders per project; do not mix global `ras` and custom `RasPrj` instances.

05_single_plan_execution.ipynb
- Focus: Run a single plan with options.
- Functions: [RasCmdr.compute_plan](../ras_commander/RasCmdr.py); [RasGeo.clear_geompre_files](../ras_commander/RasGeo.py); [RasPlan.set_num_cores](../ras_commander/RasPlan.py).
- Pattern: Use `dest_folder` and `overwrite_dest` to keep originals clean.

06_executing_plan_sets.ipynb
- Focus: Specify and execute sets of plans.
- Functions: [RasCmdr.compute_plan](../ras_commander/RasCmdr.py) (loop), [RasCmdr.compute_parallel](../ras_commander/RasCmdr.py), [RasCmdr.compute_test_mode](../ras_commander/RasCmdr.py).
- Pattern: Use lists for plan selection; choose sequential vs parallel based on dependencies.

07_sequential_plan_execution.ipynb
- Focus: Ordered runs with isolation.
- Functions: [RasCmdr.compute_test_mode](../ras_commander/RasCmdr.py) (with `plan_number`, `dest_folder_suffix`, `num_cores`, `clear_geompre`).
- Pattern: Good for dependent plans or reproducible test folders.

08_parallel_execution.ipynb
- Focus: Throughput with multiple workers.
- Functions: [RasCmdr.compute_parallel](../ras_commander/RasCmdr.py) (`max_workers`, `num_cores`, `dest_folder`, `overwrite_dest`).
- Pattern: Balance `max_workers * num_cores` to available cores/RAM.

09_plan_parameter_operations.ipynb
- Focus: Edit plan-level parameters.
- Functions: [RasPlan.get_plan_value](../ras_commander/RasPlan.py), [RasPlan.update_run_flags](../ras_commander/RasPlan.py), [RasPlan.update_plan_intervals](../ras_commander/RasPlan.py), [RasPlan.update_simulation_date](../ras_commander/RasPlan.py), [RasPlan.update_plan_description](../ras_commander/RasPlan.py), [RasPlan.get_plan_title](../ras_commander/RasPlan.py)/[set_plan_title](../ras_commander/RasPlan.py).
- Pattern: Verify changes via ras.plan_df and file reads.

10_1d_hdf_data_extraction.ipynb
- Focus: 1D geometry/results and timeseries queries.
- Functions: [HdfXsec.get_cross_sections](../ras_commander/HdfXsec.py), [HdfResultsXsec.get_xsec_timeseries](../ras_commander/HdfResultsXsec.py), [HdfResultsXsec.get_ref_lines_timeseries](../ras_commander/HdfResultsXsec.py), [HdfResultsXsec.get_ref_points_timeseries](../ras_commander/HdfResultsXsec.py); [HdfResultsPlan.get_runtime_data](../ras_commander/HdfResultsPlan.py).
- Notable cells: locate and print `HDF_Results_Path` and geometry HDF; demonstrate use of decorators to accept plan numbers or paths; optional GeoPandas plots for xsec lines.

11_2d_hdf_data_extraction.ipynb
- Focus: 2D mesh geometry/results basics with spatial plotting.
- Functions: [HdfMesh.get_mesh_area_names](../ras_commander/HdfMesh.py), [HdfMesh.get_mesh_areas](../ras_commander/HdfMesh.py), [HdfMesh.get_mesh_cell_polygons](../ras_commander/HdfMesh.py), [HdfMesh.get_mesh_cell_points](../ras_commander/HdfMesh.py), [HdfMesh.get_mesh_cell_faces](../ras_commander/HdfMesh.py), [HdfBndry.get_breaklines](../ras_commander/HdfBndry.py), [HdfBndry.get_bc_lines](../ras_commander/HdfBndry.py), [HdfResultsMesh.get_mesh_max_ws](../ras_commander/HdfResultsMesh.py)/[get_mesh_min_ws](../ras_commander/HdfResultsMesh.py)/[get_mesh_max_face_v](../ras_commander/HdfResultsMesh.py)/[get_mesh_max_ws_err](../ras_commander/HdfResultsMesh.py), [HdfResultsMesh.get_mesh_timeseries](../ras_commander/HdfResultsMesh.py).
- Notable cells: parse `.rasmap`, list plans, derive run windows; join result attributes back to geometry; toggle `generate_plots` to minimize output size.

12_2d_hdf_data_extraction pipes and pumps.ipynb
- Focus: New 6.6+ pipe networks: conduits, nodes, pumps, timeseries.
- Functions: [HdfPipe.get_pipe_conduits](../ras_commander/HdfPipe.py), [HdfPipe.get_pipe_nodes](../ras_commander/HdfPipe.py), [HdfPipe.get_pipe_network_timeseries](../ras_commander/HdfPipe.py), [HdfPipe.get_pipe_conduit_timeseries](../ras_commander/HdfPipe.py), [HdfPump.get_pump_stations](../ras_commander/HdfPump.py), [HdfPump.get_pump_groups](../ras_commander/HdfPump.py), [HdfPump.get_pump_station_timeseries](../ras_commander/HdfPump.py).
- Notable cells: build network GeoDataFrames, summarize pump groups, plot selected elements; record plan run and extract pump/conduit curves.

13_2d_detail_face_data_extraction.ipynb
- Focus: Face-level analytics along profile lines; unique notebook-only helpers.
- Functions: [HdfMesh.get_mesh_face_property_tables](../ras_commander/HdfMesh.py), [HdfMesh.get_mesh_cell_property_tables](../ras_commander/HdfMesh.py); [HdfResultsMesh.get_mesh_faces_timeseries](../ras_commander/HdfResultsMesh.py).
- Notable cells:
  - Extract `mesh_cell_faces` GeoDataFrame and preview attributes.
  - Unique function `find_nearest_cell_face(point, cell_faces_df)`; returns `(face_id, distance)` and supports plotting the nearest face vs all faces.
  - Profile-line selection along perpendicular faces; compute discharge-weighted velocity; enforce positive flow direction before aggregation.

14_fluvial_pluvial_delineation.ipynb
- Focus: Classify flooding mechanism by timing.
- Functions: [HdfResultsMesh.get_mesh_max_ws](../ras_commander/HdfResultsMesh.py), plus HdfMesh/HdfBndry for polygons/lines.
- Notable cells: compare timing in adjacent cells; map and export boundaries (GeoJSON) after smoothing/filtering short segments.

15_stored_map_generation.ipynb
- Focus: Automate stored map outputs.
- Functions: [RasMap.parse_rasmap](../ras_commander/RasMap.py), [RasMap.postprocess_stored_maps](../ras_commander/RasMap.py).
- Notable cells: backup/modify `.rasmap` and plan flags, launch RAS to bake maps, restore originals after generation.

16_automating_ras_with_win32com.ipynb
- Focus: Open HEC‑RAS/RAS Mapper to refresh stored-map configs.
- Functions: [RasMap.parse_rasmap](../ras_commander/RasMap.py); external `subprocess` to `Ras.exe`.
- Notable cells: manual steps to update mapper, then resume automation.

17_extracting_profiles_with_hecrascontroller.ipynb
- Focus: Extract steady AND unsteady results from legacy HEC-RAS versions (3.x-4.x) using RasControl.
- Functions: [RasControl.run_plan](../ras_commander/RasControl.py), [RasControl.get_steady_results](../ras_commander/RasControl.py), [RasControl.get_unsteady_results](../ras_commander/RasControl.py), [RasControl.get_output_times](../ras_commander/RasControl.py), [RasControl.set_current_plan](../ras_commander/RasControl.py).
- Pattern: ras-commander style API - use plan numbers ("02") not file paths. Open-operate-close pattern. Integrates with init_ras_project().
- Notable cells: Steady workflow (Plan 02), unsteady workflow (Plan 01), time series visualization, DataFrame exports.
- Supported versions: 3.1, 4.1, 5.0.x (501, 503, 505, 506), 6.0, 6.3, 6.6.
- Key: Must specify version in init_ras_project(path, "4.1") for RasControl to work.

101_Core_Sensitivity(.ipynb, _aircooled)
- Focus: Runtime vs core count experiments.
- Functions: [RasCmdr.compute_plan](../ras_commander/RasCmdr.py); [RasPlan.set_num_cores](../ras_commander/RasPlan.py).
- Notable cells: sweep cores, record walltime, plot scaling; choose efficient settings.

102_benchmarking_versions_6.1_to_6.6.ipynb
- Focus: Cross-version performance comparison.
- Functions: [init_ras_project](../ras_commander/RasPrj.py) (vary Ras.exe), [RasCmdr.compute_plan](../ras_commander/RasCmdr.py), [HdfResultsPlan.get_runtime_data](../ras_commander/HdfResultsPlan.py).
- Notable cells: control versioned runs, tabulate walltimes per version; keep outputs isolated per version.

103_Running_AEP_Events_from_Atlas_14.ipynb
- Focus: Generate hyetographs from NOAA Atlas 14 and batch scenarios.
- Functions: [RasPlan.clone_plan](../ras_commander/RasPlan.py)/[set_unsteady](../ras_commander/RasPlan.py), [RasUnsteady.*](../ras_commander/RasUnsteady.py), [RasCmdr.compute_parallel](../ras_commander/RasCmdr.py), [HdfResultsMesh](../ras_commander/HdfResultsMesh.py)/[HdfResultsPlan](../ras_commander/HdfResultsPlan.py).
- Notable cells:
  - Read precipitation frequency from Atlas 14 CSVs in `examples/data` and generate balanced storm hyetographs via Alternating Block Method.
  - Parameterize AEP events, clone plans, write unsteady settings, and compute in parallel.
  - Aggregate key metrics from mesh/plan results; optional plots (disable to keep outputs light).

Notebook‑only utilities and unique logic
- `find_nearest_cell_face(...)` (13_2d_detail_face_data_extraction): nearest face selection and plotting; not part of the library API.
- Hyetograph generation for Atlas 14 AEP events (103_*): end‑to‑end pattern from CSV → plan clones → batch compute.
- Profile‑based face aggregation (13_*): discharge‑weighted velocity and flow‑direction normalization.

---

## Notebook Import Cell Management

All example notebooks follow a standardized 2-cell import pattern:

**Cell 0 (Code - ACTIVE by default):**
```python
# Uncomment to install/upgrade ras-commander from pip
#!pip install --upgrade ras-commander

#Import the ras-commander package
from ras_commander import *
```

**Cell 1 (Markdown - INACTIVE by default):**
Contains development mode instructions with code block for local copy usage.

**Cell 2 (Code - When needed):**
Notebook-specific imports (numpy, pandas, matplotlib, etc.)

### Toggling Between Pip and Dev Modes

**For pip-installed package testing (default state):**
- Cell 0 remains as code (active)
- Cell 1 remains as markdown (inactive)
- Run notebooks as-is

**For local development copy testing:**
1. Convert Cell 1 from markdown to code
2. Convert Cell 0 from code to markdown
3. Run the modified notebooks
4. **IMPORTANT:** Restore to default state before committing

**Warning:** Never have both Cell 0 and Cell 1 as code cells simultaneously. This will cause import conflicts.

---

## Running Notebook Tests

### Prerequisites
- Install test dependencies: `uv pip install notebook jupyter ipykernel`
- Ensure HEC-RAS is installed and in PATH
- Verify sufficient disk space for example projects (~5 GB)

### Testing All Notebooks with Subagents

**For pip-installed package:**
```python
# Launch subagent to run all notebooks and review results
# Default state (Cell 0=code, Cell 1=markdown) is correct
task_prompt = """
Run all example notebooks in C:\\GH\\ras-commander\\examples\\ and verify:
1. No import errors
2. No unhandled exceptions
3. Warnings are reviewed and acceptable
4. Long-running cells complete successfully
5. Results match expected patterns

Report any failures, unexpected warnings, or behavioral changes.
"""
```

**For local development copy:**
```python
# First toggle cells, then test
task_prompt = """
1. For each notebook in C:\\GH\\ras-commander\\examples\\:
   - Convert Cell 0 (pip mode) from code to markdown
   - Convert Cell 1 (dev mode) from markdown to code
2. Run all notebooks and verify functionality
3. After testing, restore default state:
   - Convert Cell 0 back to code
   - Convert Cell 1 back to markdown
4. Report results and any issues
"""
```

### Expected Execution Times
- **Quick notebooks** (<30 seconds): 00, 01, 02, 03, 09
- **Medium notebooks** (1-5 minutes): 10, 11, 13, 14
- **Long-running notebooks** (5-30 minutes): 04, 05, 06, 07, 08, 12, 15, 101, 102, 103
- **Manual intervention required:** 16 (GUI automation)

### Reviewing Results

Check for:
- **Import errors:** Indicates missing dependencies or broken imports
- **HEC-RAS errors:** Check HDF files exist and compute messages are clean
- **Warnings:** Review pandas/numpy/geopandas deprecation warnings
- **Data quality:** Spot-check DataFrames, plots, and extracted values
- **Performance:** Note if runtimes significantly increase/decrease

---

## Pre-Commit Checklist for Notebooks

Before committing modified notebooks:

1. **Verify Import Cell State:**
   - [ ] Cell 0 is code (pip mode active)
   - [ ] Cell 1 is markdown (dev mode inactive)
   - [ ] Notebook-specific imports in Cell 2 (if applicable)

2. **Clear All Outputs:**
   ```python
   # Run this to clear outputs from all notebooks
   python -c "import json; from pathlib import Path; import glob;
   notebooks = glob.glob(r'C:\GH\ras-commander\examples\*.ipynb');
   [json.dump((lambda nb: (nb.update({'cells': [dict(cell, outputs=[], execution_count=None)
   if cell['cell_type'] == 'code' else cell for cell in nb['cells']]}) or nb))
   (json.load(open(nb, encoding='utf-8'))), open(nb, 'w', encoding='utf-8'),
   indent=1, ensure_ascii=False) for nb in notebooks]"
   ```

3. **Verify Notebook-Specific Imports Preserved:**
   - Check notebooks 03, 04-09, 12, 16, 101, 102, 105 retain their special imports
   - Ensure imports are consolidated in Cell 2, not scattered

4. **Git Diff Review:**
   - Verify only intended cells were modified
   - Check no accidental deletions of content cells
   - Ensure no large binary outputs were committed

---

General Tips
- Use two-digit plan numbers (e.g., "01").
- Keep original projects immutable; use `dest_folder`/suffixes.
- Plotting: GeoPandas for spatial layers; xarray/pandas for timeseries.
- Logging: library functions are decorated; prefer `get_logger(__name__)` for extra context.


==================================================

File: C:\GH\ras-commander\examples\flood_polygons.geojson
==================================================
{
"type": "FeatureCollection",
"name": "flood_polygons",
"crs": { "type": "name", "properties": { "name": "urn:ogc:def:crs:EPSG::2271" } },
"features": [
{ "type": "Feature", "properties": { "classification": "ambiguous", "mesh_name": "BaldEagleCr", "cell_id": 10, "area_acres": 795.65021094283441 }, "geometry": { "type": "MultiPolygon", "coordinates": [ [ [ [ 1967375.0, 291375.0 ], [ 1967375.0, 291625.0 ], [ 1967625.0, 291625.0 ], [ 1967625.0, 291375.0 ], [ 1967375.0, 291375.0 ] ] ], [ [ [ 1969875.0, 292875.0 ], [ 1970125.0, 292875.0 ], [ 1970125.0, 293125.0 ], [ 1969875.0, 293125.0 ], [ 1969875.0, 293375.0 ], [ 1970125.0, 293375.0 ], [ 1970375.0, 293375.0 ], [ 1970375.0, 293125.0 ], [ 1970625.0, 293125.0 ], [ 1970625.0, 292875.0 ], [ 1970875.0, 292875.0 ], [ 1970875.0, 292625.0 ], [ 1971125.0, 292625.0 ], [ 1971125.0, 292375.0 ], [ 1971125.0, 292125.0 ], [ 1971268.222361444029957, 291981.777638555911835 ], [ 1971194.582610715879127, 291875.0 ], [ 1971159.15496135991998, 291823.629908433998935 ], [ 1970971.95266490872018, 291528.047335091221612 ], [ 1970778.075113887898624, 291221.924886112101376 ], [ 1970716.689352683257312, 291125.0 ], [ 1970524.232588320039213, 290821.120898374996614 ], [ 1970483.27829177165404, 290766.721708228287753 ], [ 1970268.528428039280698, 290481.47157196077751 ], [ 1970188.37156687467359, 290375.0 ], [ 1969946.40363244060427, 290053.59636755939573 ], [ 1969731.653768708230928, 289768.346231291885488 ], [ 1969625.0, 289875.0 ], [ 1969625.0, 290125.0 ], [ 1969625.0, 290375.0 ], [ 1969625.0, 290625.0 ], [ 1969375.0, 290625.0 ], [ 1969375.0, 290875.0 ], [ 1969625.0, 290875.0 ], [ 1969875.0, 290875.0 ], [ 1969875.0, 291125.0 ], [ 1969875.0, 291375.0 ], [ 1969875.0, 291625.0 ], [ 1969875.0, 291875.0 ], [ 1969875.0, 292125.0 ], [ 1969625.0, 292125.0 ], [ 1969625.0, 292375.0 ], [ 1969625.0, 292625.0 ], [ 1969875.0, 292625.0 ], [ 1969875.0, 292875.0 ] ] ], [ [ [ 1967125.0, 291625.0 ], [ 1967125.0, 291875.0 ], [ 1967375.0, 291875.0 ], [ 1967375.0, 291625.0 ], [ 1967125.0, 291625.0 ] ] ], [ [ [ 1966875.0, 291875.0 ], [ 1966875.0, 292125.0 ], [ 1967125.0, 292125.0 ], [ 1967125.0, 291875.0 ], [ 1966875.0, 291875.0 ] ] ], [ [ [ 1968375.0, 291875.0 ], [ 1968125.0, 291875.0 ], [ 1967875.0, 291875.0 ], [ 1967875.0, 292125.0 ], [ 1968125.0, 292125.0 ], [ 1968375.0, 292125.0 ], [ 1968375.0, 291875.0 ] ] ], [ [ [ 1973875.0, 293125.0 ], [ 1974125.0, 293125.0 ], [ 1974125.0, 292730.211061998503283 ], [ 1974033.059430368477479, 292716.940569631522521 ], [ 1973632.010519499890506, 292659.054083483002614 ], [ 1973625.0, 292659.573381223715842 ], [ 1973191.671768725616857, 292691.671768725675065 ], [ 1973375.0, 292875.0 ], [ 1973625.0, 292875.0 ], [ 1973625.0, 293125.0 ], [ 1973875.0, 293125.0 ] ] ], [ [ [ 1974625.0, 293125.0 ], [ 1974875.0, 293125.0 ], [ 1974875.0, 292838.464353392249905 ], [ 1974625.0, 292802.379922927648295 ], [ 1974625.0, 293125.0 ] ] ], [ [ [ 1975125.0, 292874.548783856793307 ], [ 1975125.0, 293125.0 ], [ 1975375.0, 293125.0 ], [ 1975375.0, 292910.633214321394917 ], [ 1975125.0, 292874.548783856793307 ] ] ], [ [ [ 1967955.15116493916139, 294294.848835060896818 ], [ 1968005.056607259437442, 294375.0 ], [ 1968185.044898180058226, 294664.072103601007257 ], [ 1968239.674949259730056, 294760.325050740211736 ], [ 1968375.0, 294625.0 ], [ 1968375.0, 294375.0 ], [ 1968375.0, 294125.0 ], [ 1968375.0, 293875.0 ], [ 1968375.0, 293625.0 ], [ 1968375.0, 293375.0 ], [ 1968125.0, 293375.0 ], [ 1967875.0, 293375.0 ], [ 1967625.0, 293375.0 ], [ 1967625.0, 293125.0 ], [ 1967625.0, 292875.0 ], [ 1967375.0, 292875.0 ], [ 1967375.0, 292625.0 ], [ 1967125.0, 292625.0 ], [ 1967125.0, 292375.0 ], [ 1966875.0, 292375.0 ], [ 1966875.0, 292720.762558158952743 ], [ 1966959.246386470505968, 292790.75361352955224 ], [ 1967060.651538825361058, 292875.0 ], [ 1967082.284987119957805, 292892.972852497012354 ], [ 1967283.639537033857778, 293216.360462966142222 ], [ 1967475.500002149725333, 293524.499997850391082 ], [ 1967538.075475185876712, 293625.0 ], [ 1967763.290699823293835, 293986.709300176706165 ], [ 1967955.15116493916139, 294294.848835060896818 ] ] ], [ [ [ 1971125.0, 293625.0 ], [ 1971125.0, 293875.0 ], [ 1971375.0, 293875.0 ], [ 1971375.0, 293625.0 ], [ 1971125.0, 293625.0 ] ] ], [ [ [ 1970125.0, 295625.0 ], [ 1970375.0, 295625.0 ], [ 1970375.0, 295375.0 ], [ 1970125.0, 295375.0 ], [ 1970125.0, 295625.0 ] ] ], [ [ [ 1969875.0, 295625.0 ], [ 1969875.0, 295875.0 ], [ 1970125.0, 295875.0 ], [ 1970125.0, 295625.0 ], [ 1969875.0, 295625.0 ] ] ], [ [ [ 1980375.0, 296375.0 ], [ 1980375.0, 296625.0 ], [ 1980625.0, 296625.0 ], [ 1980764.261157453991473, 296485.738842546066735 ], [ 1980480.477373670320958, 296269.522626329620834 ], [ 1980375.0, 296375.0 ] ] ], [ [ [ 1982375.0, 300875.0 ], [ 1982125.0, 300875.0 ], [ 1982125.0, 301125.0 ], [ 1982375.0, 301125.0 ], [ 1982375.0, 300875.0 ] ] ], [ [ [ 1982875.0, 301875.0 ], [ 1982625.0, 301875.0 ], [ 1982625.0, 302125.0 ], [ 1982875.0, 302125.0 ], [ 1983125.0, 302125.0 ], [ 1983125.0, 301875.0 ], [ 1982875.0, 301875.0 ] ] ], [ [ [ 1983625.0, 302125.0 ], [ 1983375.0, 302125.0 ], [ 1983375.0, 302375.0 ], [ 1983625.0, 302375.0 ], [ 1983625.0, 302125.0 ] ] ], [ [ [ 1981875.0, 302125.0 ], [ 1981625.0, 302125.0 ], [ 1981625.0, 302375.0 ], [ 1981875.0, 302375.0 ], [ 1981875.0, 302625.0 ], [ 1982125.0, 302625.0 ], [ 1982125.0, 302375.0 ], [ 1982125.0, 302125.0 ], [ 1981875.0, 302125.0 ] ] ], [ [ [ 1982375.0, 303375.0 ], [ 1982235.022394865285605, 303514.977605134656187 ], [ 1982464.530591586604714, 303785.469408413337078 ], [ 1982625.0, 303625.0 ], [ 1982625.0, 303375.0 ], [ 1982375.0, 303375.0 ] ] ], [ [ [ 1984625.0, 305375.0 ], [ 1984625.0, 305625.0 ], [ 1984875.0, 305625.0 ], [ 1984875.0, 305375.0 ], [ 1984625.0, 305375.0 ] ] ], [ [ [ 1985875.0, 306625.0 ], [ 1985875.0, 306875.0 ], [ 1986125.0, 306875.0 ], [ 1986125.0, 306625.0 ], [ 1985875.0, 306625.0 ] ] ], [ [ [ 1993875.0, 307375.0 ], [ 1994125.0, 307375.0 ], [ 1994286.050033164443448, 307213.949966835556552 ], [ 1994011.275258389534429, 306988.724741610349156 ], [ 1993875.0, 307125.0 ], [ 1993875.0, 307375.0 ] ] ], [ [ [ 1988375.0, 307125.0 ], [ 1988375.0, 307375.0 ], [ 1988625.0, 307375.0 ], [ 1988625.0, 307125.0 ], [ 1988375.0, 307125.0 ] ] ], [ [ [ 1994625.0, 307875.0 ], [ 1994875.0, 307875.0 ], [ 1994875.0, 308125.0 ], [ 1995125.0, 308125.0 ], [ 1995247.761744876159355, 308002.238255123840645 ], [ 1994972.986970101250336, 307777.013029898633249 ], [ 1994698.212195326574147, 307551.787804673425853 ], [ 1994625.0, 307625.0 ], [ 1994625.0, 307875.0 ] ] ], [ [ [ 1987625.0, 308125.0 ], [ 1987375.0, 308125.0 ], [ 1987375.0, 308375.0 ], [ 1987625.0, 308375.0 ], [ 1987625.0, 308125.0 ] ] ], [ [ [ 1995375.0, 308875.0 ], [ 1995375.0, 309125.0 ], [ 1995625.0, 309125.0 ], [ 1995625.0, 308875.0 ], [ 1995375.0, 308875.0 ] ] ], [ [ [ 1996221.519480956485495, 309028.480519043572713 ], [ 1996027.641929935663939, 308722.358070064452477 ], [ 1995875.0, 308875.0 ], [ 1995875.0, 309125.0 ], [ 1996125.0, 309125.0 ], [ 1996125.0, 309375.0 ], [ 1996440.981818896485493, 309375.0 ], [ 1996221.519480956485495, 309028.480519043572713 ] ] ], [ [ [ 1995875.0, 309375.0 ], [ 1995875.0, 309125.0 ], [ 1995625.0, 309125.0 ], [ 1995625.0, 309375.0 ], [ 1995875.0, 309375.0 ] ] ], [ [ [ 1987523.19201434077695, 309476.80798565922305 ], [ 1987760.996892389841378, 309739.003107610158622 ], [ 1987875.0, 309625.0 ], [ 1987875.0, 309375.0 ], [ 1987625.0, 309375.0 ], [ 1987523.19201434077695, 309476.80798565922305 ] ] ], [ [ [ 1989022.23288223403506, 311227.767117765906733 ], [ 1989125.0, 311125.0 ], [ 1989125.0, 310875.0 ], [ 1988875.0, 310875.0 ], [ 1988797.23288223426789, 310952.767117765673902 ], [ 1989022.23288223403506, 311227.767117765906733 ] ] ], [ [ [ 1991875.0, 313875.0 ], [ 1991875.0, 313625.0 ], [ 1991625.0, 313625.0 ], [ 1991363.417010633274913, 313625.0 ], [ 1991523.286694810492918, 313976.713305189507082 ], [ 1991625.0, 313875.0 ], [ 1991875.0, 313875.0 ] ] ], [ [ [ 1993125.0, 314625.0 ], [ 1992875.0, 314625.0 ], [ 1992875.0, 314848.133553712745197 ], [ 1993125.0, 314854.383553712745197 ], [ 1993125.0, 314625.0 ] ] ], [ [ [ 1998375.0, 315375.0 ], [ 1998125.0, 315375.0 ], [ 1998125.0, 315625.0 ], [ 1998125.0, 315875.0 ], [ 1998375.0, 315875.0 ], [ 1998375.0, 315625.0 ], [ 1998375.0, 315375.0 ] ] ], [ [ [ 1995125.0, 316875.0 ], [ 1995375.0, 316875.0 ], [ 1995375.0, 316625.0 ], [ 1995125.0, 316625.0 ], [ 1995125.0, 316875.0 ] ] ], [ [ [ 1995875.0, 317574.561949152790476 ], [ 1995875.0, 317375.0 ], [ 1995625.0, 317375.0 ], [ 1995445.872684899717569, 317554.127315100340638 ], [ 1995875.0, 317574.561949152790476 ] ] ], [ [ [ 2000375.0, 317375.0 ], [ 2000375.0, 317625.0 ], [ 2000375.0, 317875.0 ], [ 2000625.0, 317875.0 ], [ 2000625.0, 318125.0 ], [ 2000875.0, 318125.0 ], [ 2000875.0, 317875.0 ], [ 2001125.0, 317875.0 ], [ 2001125.0, 318125.0 ], [ 2001375.0, 318125.0 ], [ 2001375.0, 317875.0 ], [ 2001375.0, 317625.0 ], [ 2001375.0, 317375.0 ], [ 2001125.0, 317375.0 ], [ 2000875.0, 317375.0 ], [ 2000625.0, 317375.0 ], [ 2000375.0, 317375.0 ] ] ], [ [ [ 2001375.0, 318625.0 ], [ 2001625.0, 318625.0 ], [ 2001625.0, 318375.0 ], [ 2001375.0, 318375.0 ], [ 2001375.0, 318625.0 ] ] ], [ [ [ 2004625.0, 321125.0 ], [ 2004625.0, 321375.0 ], [ 2004875.0, 321375.0 ], [ 2004875.0, 321125.0 ], [ 2004625.0, 321125.0 ] ] ], [ [ [ 2005125.0, 321375.0 ], [ 2004875.0, 321375.0 ], [ 2004875.0, 321625.0 ], [ 2005125.0, 321625.0 ], [ 2005125.0, 321375.0 ] ] ], [ [ [ 2000719.88580773328431, 322280.11419226671569 ], [ 2000990.663948226952925, 322509.336051772930659 ], [ 2001125.0, 322375.0 ], [ 2001125.0, 322125.0 ], [ 2000875.0, 322125.0 ], [ 2000719.88580773328431, 322280.11419226671569 ] ] ], [ [ [ 2001261.442088720854372, 322738.557911279203836 ], [ 2001532.220229214522988, 322967.779770785477012 ], [ 2001625.0, 322875.0 ], [ 2001625.0, 322625.0 ], [ 2001375.0, 322625.0 ], [ 2001261.442088720854372, 322738.557911279203836 ] ] ], [ [ [ 2005125.0, 323380.201065170695074 ], [ 2005344.927198968362063, 323344.927198968245648 ], [ 2005352.183974175946787, 323250.94473008584464 ], [ 2005265.429, 323086.270599999988917 ], [ 2005156.825999999884516, 323118.102399999974295 ], [ 2004965.835, 323153.6791 ], [ 2005108.617624151753262, 323367.808860811113846 ], [ 2005125.0, 323380.201065170695074 ] ] ], [ [ [ 2002375.0, 323363.963568864972331 ], [ 2002640.221391269238666, 323263.745681104890537 ], [ 2002613.391619356349111, 323125.0 ], [ 2002375.0, 323125.0 ], [ 2002375.0, 323363.963568864972331 ] ] ], [ [ [ 2007375.0, 323875.0 ], [ 2007375.0, 323625.0 ], [ 2007125.0, 323625.0 ], [ 2007125.0, 323875.0 ], [ 2007375.0, 323875.0 ] ] ], [ [ [ 2006125.0, 326375.0 ], [ 2006125.0, 326625.0 ], [ 2006375.0, 326625.0 ], [ 2006375.0, 326375.0 ], [ 2006125.0, 326375.0 ] ] ], [ [ [ 2002875.0, 326875.0 ], [ 2002720.589737881906331, 326720.589737881789915 ], [ 2002625.0, 326774.443111336440779 ], [ 2002297.006994920084253, 326959.227902930986602 ], [ 2002235.943278753664345, 326985.943278753547929 ], [ 2002375.0, 327125.0 ], [ 2002625.0, 327125.0 ], [ 2002875.0, 327125.0 ], [ 2002875.0, 326875.0 ] ] ], [ [ [ 2007375.0, 327125.0 ], [ 2007125.0, 327125.0 ], [ 2007125.0, 326875.0 ], [ 2006875.0, 326875.0 ], [ 2006625.0, 326875.0 ], [ 2006625.0, 327198.01929838018259 ], [ 2006875.0, 327230.486830847687088 ], [ 2006948.066138840047643, 327239.975939787982497 ], [ 2006986.789839697536081, 327263.210160302405711 ], [ 2007375.0, 327496.136256483208854 ], [ 2007375.0, 327125.0 ] ] ], [ [ [ 2004625.0, 327375.0 ], [ 2004769.156847949139774, 327519.156847949197982 ], [ 2004875.0, 327413.313695900083985 ], [ 2004875.0, 327125.0 ], [ 2004625.0, 327125.0 ], [ 2004625.0, 327375.0 ] ] ], [ [ [ 2007875.0, 327375.0 ], [ 2007625.0, 327375.0 ], [ 2007455.539839698001742, 327544.46016030194005 ], [ 2007768.039839698467404, 327731.960160301590804 ], [ 2007875.0, 327625.0 ], [ 2007875.0, 327375.0 ] ] ], [ [ [ 2002125.0, 328375.0 ], [ 2002375.0, 328375.0 ], [ 2002375.0, 328125.0 ], [ 2002125.0, 328125.0 ], [ 2002125.0, 328375.0 ] ] ], [ [ [ 2001375.0, 328625.0 ], [ 2001375.0, 328875.0 ], [ 2001625.0, 328875.0 ], [ 2001625.0, 328625.0 ], [ 2001375.0, 328625.0 ] ] ], [ [ [ 2003947.537490927381441, 328875.0 ], [ 2003625.0, 328875.0 ], [ 2003625.0, 329232.355279027775396 ], [ 2003766.255054469918832, 329177.137394098972436 ], [ 2003947.537490927381441, 328875.0 ] ] ], [ [ [ 2004875.0, 337375.0 ], [ 2004875.0, 337777.385589807992801 ], [ 2005125.0, 337777.385589807992801 ], [ 2005272.936185600003228, 337777.385589807992801 ], [ 2005375.0, 337727.439467867545318 ], [ 2005375.0, 337375.0 ], [ 2005125.0, 337375.0 ], [ 2004875.0, 337375.0 ] ] ], [ [ [ 2010375.0, 322375.0 ], [ 2010518.892821161542088, 322231.107178838399705 ], [ 2010254.688275706255808, 321995.311724293627776 ], [ 2010125.0, 322125.0 ], [ 2010125.0, 322375.0 ], [ 2010375.0, 322375.0 ] ] ], [ [ [ 2011125.0, 323125.0 ], [ 2011375.0, 323125.0 ], [ 2011625.0, 323125.0 ], [ 2011720.56660290970467, 323029.433397090237122 ], [ 2011375.0, 322815.650668170070276 ], [ 2011257.21581757068634, 322742.784182429371867 ], [ 2011125.0, 322875.0 ], [ 2011125.0, 323125.0 ] ] ], [ [ [ 2008625.0, 323375.0 ], [ 2008625.0, 323125.0 ], [ 2008375.0, 323125.0 ], [ 2008375.0, 322875.0 ], [ 2008125.0, 322875.0 ], [ 2008125.0, 323125.0 ], [ 2008125.0, 323375.0 ], [ 2008375.0, 323375.0 ], [ 2008375.0, 323625.0 ], [ 2008625.0, 323625.0 ], [ 2008625.0, 323375.0 ] ] ], [ [ [ 2010875.0, 323125.0 ], [ 2010875.0, 323375.0 ], [ 2011125.0, 323375.0 ], [ 2011125.0, 323125.0 ], [ 2010875.0, 323125.0 ] ] ], [ [ [ 2012125.0, 323625.0 ], [ 2011875.0, 323625.0 ], [ 2011875.0, 323875.0 ], [ 2012125.0, 323875.0 ], [ 2012125.0, 323625.0 ] ] ], [ [ [ 2013875.0, 323875.0 ], [ 2013875.0, 324125.0 ], [ 2014125.0, 324125.0 ], [ 2014125.0, 323875.0 ], [ 2014298.791663677198812, 323701.20833632274298 ], [ 2013966.767060260055587, 323626.672200862027239 ], [ 2013875.0, 323614.831289860594552 ], [ 2013875.0, 323875.0 ] ] ], [ [ [ 2007625.0, 324125.0 ], [ 2007625.0, 324375.0 ], [ 2007875.0, 324375.0 ], [ 2007875.0, 324125.0 ], [ 2007625.0, 324125.0 ] ] ], [ [ [ 2015287.130086361663416, 324212.869913638220169 ], [ 2014966.770804925588891, 324033.229195074411109 ], [ 2014625.0, 323841.582014740735758 ], [ 2014425.322187130106613, 323729.613147709984332 ], [ 2014375.0, 323718.316330191039015 ], [ 2014375.0, 324125.0 ], [ 2014625.0, 324125.0 ], [ 2014875.0, 324125.0 ], [ 2014875.0, 324375.0 ], [ 2015125.0, 324375.0 ], [ 2015125.0, 324625.0 ], [ 2015375.0, 324625.0 ], [ 2015625.0, 324625.0 ], [ 2015625.0, 324875.0 ], [ 2015875.0, 324875.0 ], [ 2015875.0, 324569.132067444443237 ], [ 2015755.173654922051355, 324494.826345077890437 ], [ 2015426.656851910054684, 324291.109221422986593 ], [ 2015375.0, 324262.1427624077769 ], [ 2015287.130086361663416, 324212.869913638220169 ] ] ], [ [ [ 2014125.0, 324375.0 ], [ 2014125.0, 324625.0 ], [ 2014375.0, 324625.0 ], [ 2014375.0, 324375.0 ], [ 2014125.0, 324375.0 ] ] ], [ [ [ 2008375.0, 326375.0 ], [ 2008375.0, 326625.0 ], [ 2008625.0, 326625.0 ], [ 2008625.0, 326375.0 ], [ 2008375.0, 326375.0 ] ] ], [ [ [ 2009125.0, 326375.0 ], [ 2009125.0, 326625.0 ], [ 2009375.0, 326625.0 ], [ 2009375.0, 326375.0 ], [ 2009125.0, 326375.0 ] ] ], [ [ [ 2010125.0, 326625.0 ], [ 2010125.0, 326875.0 ], [ 2010375.0, 326875.0 ], [ 2010375.0, 326625.0 ], [ 2010375.0, 326375.0 ], [ 2010125.0, 326375.0 ], [ 2010125.0, 326625.0 ] ] ], [ [ [ 2008125.0, 327125.0 ], [ 2008125.0, 326875.0 ], [ 2008125.0, 326625.0 ], [ 2007875.0, 326625.0 ], [ 2007875.0, 326875.0 ], [ 2007875.0, 327125.0 ], [ 2008125.0, 327125.0 ] ] ], [ [ [ 2011375.0, 326625.0 ], [ 2011125.0, 326625.0 ], [ 2011125.0, 326875.0 ], [ 2011125.0, 327125.0 ], [ 2011375.0, 327125.0 ], [ 2011375.0, 326875.0 ], [ 2011375.0, 326625.0 ] ] ], [ [ [ 2010625.0, 327125.0 ], [ 2010875.0, 327125.0 ], [ 2010875.0, 326875.0 ], [ 2010625.0, 326875.0 ], [ 2010625.0, 327125.0 ] ] ], [ [ [ 2010875.0, 327125.0 ], [ 2010875.0, 327375.0 ], [ 2011125.0, 327375.0 ], [ 2011125.0, 327125.0 ], [ 2010875.0, 327125.0 ] ] ], [ [ [ 2009875.0, 327375.0 ], [ 2009625.0, 327375.0 ], [ 2009625.0, 327625.0 ], [ 2009875.0, 327625.0 ], [ 2009875.0, 327375.0 ] ] ], [ [ [ 2012375.0, 327625.0 ], [ 2012125.0, 327625.0 ], [ 2012125.0, 327875.0 ], [ 2012375.0, 327875.0 ], [ 2012375.0, 327625.0 ] ] ], [ [ [ 2012625.0, 328125.0 ], [ 2012875.0, 328125.0 ], [ 2013125.0, 328125.0 ], [ 2013125.0, 327875.0 ], [ 2013375.0, 327875.0 ], [ 2013625.0, 327875.0 ], [ 2013625.0, 327625.0 ], [ 2013375.0, 327625.0 ], [ 2013125.0, 327625.0 ], [ 2012875.0, 327625.0 ], [ 2012875.0, 327875.0 ], [ 2012625.0, 327875.0 ], [ 2012625.0, 328125.0 ] ] ], [ [ [ 2010625.0, 328375.0 ], [ 2010625.0, 328625.0 ], [ 2010875.0, 328625.0 ], [ 2010875.0, 328375.0 ], [ 2010625.0, 328375.0 ] ] ], [ [ [ 2009625.0, 328375.0 ], [ 2009625.0, 328625.0 ], [ 2009875.0, 328625.0 ], [ 2009875.0, 328375.0 ], [ 2009625.0, 328375.0 ] ] ], [ [ [ 2013875.0, 328875.0 ], [ 2014125.0, 328875.0 ], [ 2014125.0, 328625.0 ], [ 2013875.0, 328625.0 ], [ 2013875.0, 328875.0 ] ] ], [ [ [ 2012375.0, 329375.0 ], [ 2012625.0, 329375.0 ], [ 2012625.0, 329125.0 ], [ 2012375.0, 329125.0 ], [ 2012125.0, 329125.0 ], [ 2012125.0, 329375.0 ], [ 2012375.0, 329375.0 ] ] ], [ [ [ 2010375.0, 329125.0 ], [ 2010125.0, 329125.0 ], [ 2010125.0, 329375.0 ], [ 2010375.0, 329375.0 ], [ 2010375.0, 329125.0 ] ] ], [ [ [ 2012625.0, 329375.0 ], [ 2012625.0, 329625.0 ], [ 2012875.0, 329625.0 ], [ 2012875.0, 329375.0 ], [ 2012625.0, 329375.0 ] ] ], [ [ [ 2015625.0, 329375.0 ], [ 2015625.0, 329625.0 ], [ 2015875.0, 329625.0 ], [ 2015875.0, 329375.0 ], [ 2015625.0, 329375.0 ] ] ], [ [ [ 2010875.0, 329875.0 ], [ 2010875.0, 330125.0 ], [ 2011125.0, 330125.0 ], [ 2011125.0, 329875.0 ], [ 2010875.0, 329875.0 ] ] ], [ [ [ 2010125.0, 329875.0 ], [ 2010125.0, 330125.0 ], [ 2010375.0, 330125.0 ], [ 2010375.0, 329875.0 ], [ 2010125.0, 329875.0 ] ] ], [ [ [ 2013625.0, 330125.0 ], [ 2013625.0, 329875.0 ], [ 2013375.0, 329875.0 ], [ 2013375.0, 330125.0 ], [ 2013375.0, 330375.0 ], [ 2013625.0, 330375.0 ], [ 2013625.0, 330125.0 ] ] ], [ [ [ 2016375.0, 330375.0 ], [ 2016625.0, 330375.0 ], [ 2016625.0, 330125.0 ], [ 2016625.0, 329875.0 ], [ 2016375.0, 329875.0 ], [ 2016375.0, 330125.0 ], [ 2016375.0, 330375.0 ] ] ], [ [ [ 2012375.0, 330125.0 ], [ 2012375.0, 330375.0 ], [ 2012625.0, 330375.0 ], [ 2012875.0, 330375.0 ], [ 2013125.0, 330375.0 ], [ 2013125.0, 330125.0 ], [ 2012875.0, 330125.0 ], [ 2012625.0, 330125.0 ], [ 2012375.0, 330125.0 ] ] ], [ [ [ 2012375.0, 330375.0 ], [ 2012125.0, 330375.0 ], [ 2012125.0, 330625.0 ], [ 2012375.0, 330625.0 ], [ 2012375.0, 330375.0 ] ] ], [ [ [ 2014625.0, 330375.0 ], [ 2014375.0, 330375.0 ], [ 2014375.0, 330625.0 ], [ 2014625.0, 330625.0 ], [ 2014625.0, 330375.0 ] ] ], [ [ [ 2018375.0, 330625.0 ], [ 2018375.0, 330375.0 ], [ 2018125.0, 330375.0 ], [ 2018125.0, 330625.0 ], [ 2018125.0, 330875.0 ], [ 2018375.0, 330875.0 ], [ 2018375.0, 330625.0 ] ] ], [ [ [ 2009625.0, 330625.0 ], [ 2009555.910272921202704, 330555.910272921260912 ], [ 2009530.948077919892967, 330599.594114172970876 ], [ 2009303.612880811095238, 330803.61288081103703 ], [ 2009040.099367298651487, 331040.099367298651487 ], [ 2009125.0, 331125.0 ], [ 2009375.0, 331125.0 ], [ 2009375.0, 330875.0 ], [ 2009625.0, 330875.0 ], [ 2009625.0, 330625.0 ] ] ], [ [ [ 2012625.0, 330625.0 ], [ 2012375.0, 330625.0 ], [ 2012375.0, 330875.0 ], [ 2012375.0, 331125.0 ], [ 2012625.0, 331125.0 ], [ 2012625.0, 330875.0 ], [ 2012625.0, 330625.0 ] ] ], [ [ [ 2013125.0, 331125.0 ], [ 2013375.0, 331125.0 ], [ 2013375.0, 330875.0 ], [ 2013125.0, 330875.0 ], [ 2012875.0, 330875.0 ], [ 2012875.0, 331125.0 ], [ 2013125.0, 331125.0 ] ] ], [ [ [ 2017875.0, 331125.0 ], [ 2017875.0, 331375.0 ], [ 2018125.0, 331375.0 ], [ 2018125.0, 331125.0 ], [ 2017875.0, 331125.0 ] ] ], [ [ [ 2009375.0, 331625.0 ], [ 2009375.0, 331875.0 ], [ 2009625.0, 331875.0 ], [ 2009625.0, 331625.0 ], [ 2009375.0, 331625.0 ] ] ], [ [ [ 2012875.0, 332125.0 ], [ 2012625.0, 332125.0 ], [ 2012625.0, 332375.0 ], [ 2012875.0, 332375.0 ], [ 2012875.0, 332125.0 ] ] ], [ [ [ 2014875.0, 332125.0 ], [ 2014875.0, 332375.0 ], [ 2015125.0, 332375.0 ], [ 2015125.0, 332125.0 ], [ 2014875.0, 332125.0 ] ] ], [ [ [ 2008625.0, 332625.0 ], [ 2008875.0, 332625.0 ], [ 2008875.0, 332375.0 ], [ 2008625.0, 332375.0 ], [ 2008625.0, 332625.0 ] ] ], [ [ [ 2008375.0, 332625.0 ], [ 2008375.0, 332875.0 ], [ 2008625.0, 332875.0 ], [ 2008625.0, 332625.0 ], [ 2008375.0, 332625.0 ] ] ], [ [ [ 2019875.0, 332875.0 ], [ 2020125.0, 332875.0 ], [ 2020125.0, 332625.0 ], [ 2019875.0, 332625.0 ], [ 2019625.0, 332625.0 ], [ 2019375.0, 332625.0 ], [ 2019375.0, 332875.0 ], [ 2019625.0, 332875.0 ], [ 2019875.0, 332875.0 ] ] ], [ [ [ 2012125.0, 333375.0 ], [ 2011875.0, 333375.0 ], [ 2011875.0, 333625.0 ], [ 2011875.0, 333986.382859602512326 ], [ 2012020.247338050045073, 333903.062681186012924 ], [ 2012162.843584816204384, 333625.0 ], [ 2012207.412695959908888, 333538.09023327199975 ], [ 2012241.619971779873595, 333491.61997177999001 ], [ 2012125.0, 333375.0 ] ] ], [ [ [ 2008125.0, 333625.0 ], [ 2008125.0, 333875.0 ], [ 2008375.0, 333875.0 ], [ 2008375.0, 333625.0 ], [ 2008125.0, 333625.0 ] ] ], [ [ [ 2010375.0, 334125.0 ], [ 2010375.0, 333875.0 ], [ 2010125.0, 333875.0 ], [ 2009875.0, 333875.0 ], [ 2009875.0, 334125.0 ], [ 2009875.0, 334375.0 ], [ 2010125.0, 334375.0 ], [ 2010125.0, 334125.0 ], [ 2010375.0, 334125.0 ] ] ], [ [ [ 2008125.0, 334375.0 ], [ 2008375.0, 334375.0 ], [ 2008375.0, 334125.0 ], [ 2008125.0, 334125.0 ], [ 2008125.0, 334375.0 ] ] ], [ [ [ 2009625.0, 335125.0 ], [ 2009625.0, 335478.111655970860738 ], [ 2009971.047671458451077, 335221.047671458509285 ], [ 2009875.0, 335125.0 ], [ 2009625.0, 335125.0 ] ] ], [ [ [ 2020625.0, 336375.0 ], [ 2020541.324557156302035, 336458.67544284381438 ], [ 2020875.0, 336685.791474982397631 ], [ 2020875.0, 336375.0 ], [ 2020625.0, 336375.0 ] ] ], [ [ [ 2021731.340660215821117, 337268.659339784178883 ], [ 2021875.0, 337125.0 ], [ 2021875.0, 336875.0 ], [ 2021625.0, 336875.0 ], [ 2021375.0, 336875.0 ], [ 2021285.084621568443254, 336964.915378431556746 ], [ 2021625.0, 337196.278619772638194 ], [ 2021731.340660215821117, 337268.659339784178883 ] ] ], [ [ [ 2022286.267219109926373, 337646.369839275022969 ], [ 2022375.0, 337703.769679732096847 ], [ 2022478.972284559160471, 337771.027715440897737 ], [ 2022625.0, 337625.0 ], [ 2022625.0, 337375.0 ], [ 2022375.0, 337375.0 ], [ 2022125.0, 337375.0 ], [ 2022028.844685980817303, 337471.155314019299112 ], [ 2022286.267219109926373, 337646.369839275022969 ] ] ], [ [ [ 2023125.0, 329875.0 ], [ 2023209.070283957989886, 329790.929716042068321 ], [ 2022875.0, 329554.443120293261018 ], [ 2022875.0, 329875.0 ], [ 2023125.0, 329875.0 ] ] ], [ [ [ 2024975.861002979800105, 331024.138997020141687 ], [ 2024625.0, 330786.995789472362958 ], [ 2024528.337418074253947, 330721.662581925687846 ], [ 2024375.0, 330875.0 ], [ 2024375.0, 331125.0 ], [ 2024625.0, 331125.0 ], [ 2024875.0, 331125.0 ], [ 2024975.861002979800105, 331024.138997020141687 ] ] ], [ [ [ 2023625.0, 331375.0 ], [ 2023375.0, 331375.0 ], [ 2023375.0, 331625.0 ], [ 2023625.0, 331625.0 ], [ 2023625.0, 331375.0 ] ] ], [ [ [ 2023875.0, 331375.0 ], [ 2023875.0, 331625.0 ], [ 2024125.0, 331625.0 ], [ 2024125.0, 331375.0 ], [ 2023875.0, 331375.0 ] ] ], [ [ [ 2025375.0, 332125.0 ], [ 2025375.0, 332375.0 ], [ 2025625.0, 332375.0 ], [ 2025625.0, 332125.0 ], [ 2025625.0, 331875.0 ], [ 2025875.0, 331875.0 ], [ 2026020.082701092818752, 331729.917298907181248 ], [ 2025721.733644489198923, 331528.266355510859285 ], [ 2025375.0, 331293.912785520078614 ], [ 2025375.0, 331625.0 ], [ 2025375.0, 331875.0 ], [ 2025125.0, 331875.0 ], [ 2025125.0, 332125.0 ], [ 2025375.0, 332125.0 ] ] ], [ [ [ 2026375.0, 332375.0 ], [ 2026625.0, 332375.0 ], [ 2026765.955342601984739, 332234.044657397898845 ], [ 2026467.60628599836491, 332032.39371400163509 ], [ 2026375.0, 332125.0 ], [ 2026375.0, 332375.0 ] ] ], [ [ [ 2024625.0, 333125.0 ], [ 2024625.0, 333375.0 ], [ 2024875.0, 333375.0 ], [ 2024875.0, 333125.0 ], [ 2024625.0, 333125.0 ] ] ], [ [ [ 2026125.0, 333625.0 ], [ 2026375.0, 333625.0 ], [ 2026375.0, 333375.0 ], [ 2026125.0, 333375.0 ], [ 2026125.0, 333625.0 ] ] ], [ [ [ 2023625.0, 334875.0 ], [ 2023375.0, 334875.0 ], [ 2023375.0, 335125.0 ], [ 2023625.0, 335125.0 ], [ 2023625.0, 334875.0 ] ] ], [ [ [ 2024625.0, 335375.0 ], [ 2024375.0, 335375.0 ], [ 2024375.0, 335625.0 ], [ 2024625.0, 335625.0 ], [ 2024875.0, 335625.0 ], [ 2025125.0, 335625.0 ], [ 2025125.0, 335375.0 ], [ 2024875.0, 335375.0 ], [ 2024875.0, 335125.0 ], [ 2024625.0, 335125.0 ], [ 2024625.0, 335375.0 ] ] ], [ [ [ 2025625.0, 335875.0 ], [ 2025375.0, 335875.0 ], [ 2025375.0, 336125.0 ], [ 2025625.0, 336125.0 ], [ 2025625.0, 335875.0 ] ] ], [ [ [ 2026875.0, 335875.0 ], [ 2026625.0, 335875.0 ], [ 2026625.0, 336125.0 ], [ 2026875.0, 336125.0 ], [ 2026875.0, 335875.0 ] ] ], [ [ [ 2025375.0, 336625.0 ], [ 2025375.0, 336875.0 ], [ 2025625.0, 336875.0 ], [ 2025625.0, 336625.0 ], [ 2025375.0, 336625.0 ] ] ], [ [ [ 2026875.0, 337125.0 ], [ 2026625.0, 337125.0 ], [ 2026625.0, 336875.0 ], [ 2026375.0, 336875.0 ], [ 2026375.0, 336625.0 ], [ 2026125.0, 336625.0 ], [ 2025875.0, 336625.0 ], [ 2025875.0, 336875.0 ], [ 2026125.0, 336875.0 ], [ 2026125.0, 337125.0 ], [ 2026375.0, 337125.0 ], [ 2026375.0, 337375.0 ], [ 2026625.0, 337375.0 ], [ 2026875.0, 337375.0 ], [ 2026875.0, 337625.0 ], [ 2027125.0, 337625.0 ], [ 2027375.0, 337625.0 ], [ 2027375.0, 337375.0 ], [ 2027375.0, 337125.0 ], [ 2027125.0, 337125.0 ], [ 2026875.0, 337125.0 ] ] ], [ [ [ 2028125.0, 337125.0 ], [ 2027875.0, 337125.0 ], [ 2027875.0, 337375.0 ], [ 2028125.0, 337375.0 ], [ 2028125.0, 337125.0 ] ] ], [ [ [ 2025875.0, 337375.0 ], [ 2025875.0, 337625.0 ], [ 2026125.0, 337625.0 ], [ 2026125.0, 337375.0 ], [ 2025875.0, 337375.0 ] ] ], [ [ [ 2027375.0, 337625.0 ], [ 2027375.0, 337875.0 ], [ 2027625.0, 337875.0 ], [ 2027625.0, 337625.0 ], [ 2027375.0, 337625.0 ] ] ], [ [ [ 2029875.0, 337875.0 ], [ 2030125.0, 337875.0 ], [ 2030125.0, 337625.0 ], [ 2029875.0, 337625.0 ], [ 2029875.0, 337875.0 ] ] ], [ [ [ 2023875.0, 338125.0 ], [ 2024125.0, 338125.0 ], [ 2024125.0, 337875.0 ], [ 2023875.0, 337875.0 ], [ 2023875.0, 338125.0 ] ] ], [ [ [ 2027875.0, 337875.0 ], [ 2027875.0, 338125.0 ], [ 2028125.0, 338125.0 ], [ 2028125.0, 337875.0 ], [ 2027875.0, 337875.0 ] ] ], [ [ [ 2030125.0, 337875.0 ], [ 2030125.0, 338125.0 ], [ 2030375.0, 338125.0 ], [ 2030625.0, 338125.0 ], [ 2030625.0, 337875.0 ], [ 2030375.0, 337875.0 ], [ 2030125.0, 337875.0 ] ] ], [ [ [ 2023625.0, 337875.0 ], [ 2023625.0, 337625.0 ], [ 2023375.0, 337625.0 ], [ 2023375.0, 337875.0 ], [ 2023375.0, 338125.0 ], [ 2023237.981293568154797, 338262.018706431786995 ], [ 2023541.584897171938792, 338458.415102828177623 ], [ 2023875.0, 338674.096089227299672 ], [ 2023996.990302577381954, 338753.009697422676254 ], [ 2024300.593906180933118, 338949.406093819066882 ], [ 2024375.0, 338875.0 ], [ 2024375.0, 338625.0 ], [ 2024375.0, 338375.0 ], [ 2024375.0, 338125.0 ], [ 2024125.0, 338125.0 ], [ 2024125.0, 338375.0 ], [ 2023875.0, 338375.0 ], [ 2023625.0, 338375.0 ], [ 2023625.0, 338125.0 ], [ 2023625.0, 337875.0 ] ] ], [ [ [ 2025875.0, 338875.0 ], [ 2025625.0, 338875.0 ], [ 2025625.0, 339125.0 ], [ 2025875.0, 339125.0 ], [ 2025875.0, 338875.0 ] ] ], [ [ [ 2025625.0, 339625.0 ], [ 2025875.0, 339625.0 ], [ 2025875.0, 339375.0 ], [ 2025625.0, 339375.0 ], [ 2025625.0, 339625.0 ] ] ], [ [ [ 2031375.0, 339875.0 ], [ 2031625.0, 339875.0 ], [ 2031625.0, 339625.0 ], [ 2031375.0, 339625.0 ], [ 2031375.0, 339875.0 ] ] ], [ [ [ 2027375.0, 339875.0 ], [ 2027375.0, 340125.0 ], [ 2027625.0, 340125.0 ], [ 2027625.0, 339875.0 ], [ 2027375.0, 339875.0 ] ] ], [ [ [ 2026625.0, 340125.0 ], [ 2026875.0, 340125.0 ], [ 2026875.0, 339875.0 ], [ 2026625.0, 339875.0 ], [ 2026625.0, 340125.0 ] ] ], [ [ [ 2027375.0, 340375.0 ], [ 2027375.0, 340125.0 ], [ 2027125.0, 340125.0 ], [ 2026875.0, 340125.0 ], [ 2026875.0, 340375.0 ], [ 2027125.0, 340375.0 ], [ 2027375.0, 340375.0 ] ] ], [ [ [ 2033625.0, 340375.0 ], [ 2033625.0, 340125.0 ], [ 2033375.0, 340125.0 ], [ 2033125.0, 340125.0 ], [ 2033125.0, 340375.0 ], [ 2033375.0, 340375.0 ], [ 2033625.0, 340375.0 ] ] ], [ [ [ 2026231.005073083331808, 340768.994926916609984 ], [ 2026375.0, 340625.0 ], [ 2026375.0, 340375.0 ], [ 2026125.0, 340375.0 ], [ 2026125.0, 340749.467676611733623 ], [ 2026231.005073083331808, 340768.994926916609984 ] ] ], [ [ [ 2032375.0, 340625.0 ], [ 2032125.0, 340625.0 ], [ 2032125.0, 340875.0 ], [ 2032375.0, 340875.0 ], [ 2032625.0, 340875.0 ], [ 2032625.0, 340625.0 ], [ 2032375.0, 340625.0 ] ] ], [ [ [ 2034375.0, 340875.0 ], [ 2034375.0, 340625.0 ], [ 2034125.0, 340625.0 ], [ 2034125.0, 340875.0 ], [ 2034125.0, 341125.0 ], [ 2034375.0, 341125.0 ], [ 2034375.0, 340875.0 ] ] ], [ [ [ 2027212.347141260746866, 341287.652858739311341 ], [ 2027375.0, 341125.0 ], [ 2027375.0, 340875.0 ], [ 2027375.0, 340625.0 ], [ 2027125.0, 340625.0 ], [ 2027125.0, 340875.0 ], [ 2026875.0, 340875.0 ], [ 2026751.611554779810831, 340998.388445220189169 ], [ 2027125.0, 341232.81355322280433 ], [ 2027212.347141260746866, 341287.652858739311341 ] ] ], [ [ [ 2032875.0, 340875.0 ], [ 2032875.0, 341125.0 ], [ 2032875.0, 341375.0 ], [ 2032875.0, 341625.0 ], [ 2033125.0, 341625.0 ], [ 2033125.0, 341375.0 ], [ 2033125.0, 341125.0 ], [ 2033125.0, 340875.0 ], [ 2032875.0, 340875.0 ] ] ], [ [ [ 2030125.0, 342125.0 ], [ 2029875.0, 342125.0 ], [ 2029875.0, 342375.0 ], [ 2029875.0, 342625.0 ], [ 2030125.0, 342625.0 ], [ 2030125.0, 342375.0 ], [ 2030125.0, 342125.0 ] ] ], [ [ [ 2034625.0, 342625.0 ], [ 2034875.0, 342625.0 ], [ 2034875.0, 342375.0 ], [ 2034625.0, 342375.0 ], [ 2034625.0, 342625.0 ] ] ], [ [ [ 2035375.0, 342875.0 ], [ 2035625.0, 342875.0 ], [ 2035625.0, 342625.0 ], [ 2035375.0, 342625.0 ], [ 2035125.0, 342625.0 ], [ 2035125.0, 342875.0 ], [ 2035375.0, 342875.0 ] ] ], [ [ [ 2033875.0, 342875.0 ], [ 2033875.0, 343125.0 ], [ 2034125.0, 343125.0 ], [ 2034125.0, 342875.0 ], [ 2033875.0, 342875.0 ] ] ], [ [ [ 2030006.838232669979334, 343092.881754293979611 ], [ 2030033.358234973857179, 343216.641765026201028 ], [ 2030125.0, 343125.0 ], [ 2030125.0, 342875.0 ], [ 2029875.0, 342875.0 ], [ 2029801.630637013586238, 342948.36936298647197 ], [ 2030006.838232669979334, 343092.881754293979611 ] ] ], [ [ [ 2034375.0, 343125.0 ], [ 2034125.0, 343125.0 ], [ 2034125.0, 343375.0 ], [ 2034375.0, 343375.0 ], [ 2034375.0, 343125.0 ] ] ], [ [ [ 2033375.0, 343125.0 ], [ 2033125.0, 343125.0 ], [ 2033125.0, 343375.0 ], [ 2033125.0, 343625.0 ], [ 2033375.0, 343625.0 ], [ 2033625.0, 343625.0 ], [ 2033625.0, 343375.0 ], [ 2033625.0, 343125.0 ], [ 2033375.0, 343125.0 ] ] ], [ [ [ 2031875.0, 343875.0 ], [ 2032125.0, 343875.0 ], [ 2032125.0, 343625.0 ], [ 2031875.0, 343625.0 ], [ 2031875.0, 343875.0 ] ] ], [ [ [ 2035375.0, 343625.0 ], [ 2035375.0, 343875.0 ], [ 2035625.0, 343875.0 ], [ 2035625.0, 343625.0 ], [ 2035375.0, 343625.0 ] ] ], [ [ [ 2029875.0, 344567.421952598670032 ], [ 2029922.613821610109881, 344552.771545948984567 ], [ 2030109.779179519973695, 344618.279421215003822 ], [ 2030125.0, 344628.064234380959533 ], [ 2030125.0, 344375.0 ], [ 2029875.0, 344375.0 ], [ 2029625.0, 344375.0 ], [ 2029625.0, 344644.489058320061304 ], [ 2029679.29885634011589, 344627.637689110997599 ], [ 2029875.0, 344567.421952598670032 ] ] ], [ [ [ 2031733.288588577648625, 344266.711411422467791 ], [ 2032021.718340643448755, 344478.28165935643483 ], [ 2032310.148092709481716, 344689.851907290460076 ], [ 2032625.0, 344920.803449601109605 ], [ 2032625.0, 344625.0 ], [ 2032375.0, 344625.0 ], [ 2032375.0, 344375.0 ], [ 2032625.0, 344375.0 ], [ 2032625.0, 344125.0 ], [ 2032375.0, 344125.0 ], [ 2032125.0, 344125.0 ], [ 2031875.0, 344125.0 ], [ 2031733.288588577648625, 344266.711411422467791 ] ] ], [ [ [ 2035625.0, 346625.0 ], [ 2035875.0, 346625.0 ], [ 2035875.0, 346375.0 ], [ 2035625.0, 346375.0 ], [ 2035625.0, 346625.0 ] ] ], [ [ [ 2035875.0, 347125.0 ], [ 2035875.0, 347375.0 ], [ 2036125.0, 347375.0 ], [ 2036125.0, 347125.0 ], [ 2036125.0, 346875.0 ], [ 2036125.0, 346625.0 ], [ 2035875.0, 346625.0 ], [ 2035875.0, 346875.0 ], [ 2035875.0, 347125.0 ] ] ], [ [ [ 2035625.0, 347625.0 ], [ 2035625.0, 347375.0 ], [ 2035625.0, 347125.0 ], [ 2035625.0, 346875.0 ], [ 2035625.0, 346625.0 ], [ 2035375.0, 346625.0 ], [ 2035375.0, 346875.0 ], [ 2035375.0, 347125.0 ], [ 2035375.0, 347375.0 ], [ 2035375.0, 347625.0 ], [ 2035625.0, 347625.0 ] ] ], [ [ [ 2034984.327424573944882, 347765.672575426171534 ], [ 2035057.212374291615561, 347875.0 ], [ 2035125.810771360062063, 347977.897595599992201 ], [ 2035264.198325752746314, 348235.801674247137271 ], [ 2035375.0, 348125.0 ], [ 2035375.0, 347875.0 ], [ 2035375.0, 347625.0 ], [ 2035125.0, 347625.0 ], [ 2034984.327424573944882, 347765.672575426171534 ] ] ], [ [ [ 2036375.0, 349125.0 ], [ 2036625.0, 349125.0 ], [ 2036625.0, 348875.0 ], [ 2036375.0, 348875.0 ], [ 2036375.0, 349125.0 ] ] ], [ [ [ 2035719.413591908058152, 349280.586408092058264 ], [ 2035723.044883902417496, 349375.0 ], [ 2036125.0, 349375.0 ], [ 2036125.0, 349125.0 ], [ 2035875.0, 349125.0 ], [ 2035719.413591908058152, 349280.586408092058264 ] ] ], [ [ [ 2035454.028788686497137, 350375.0 ], [ 2035490.783219269942492, 350551.421266785997432 ], [ 2035536.331958879483864, 350625.0 ], [ 2035612.440701910061762, 350747.944892585976049 ], [ 2035780.889524020021781, 350850.88583943300182 ], [ 2035949.338346139993519, 350860.244107328995597 ], [ 2035998.097667711554095, 350748.09766771143768 ], [ 2036042.921025089919567, 350645.003945738018956 ], [ 2036125.0, 350576.604799978144001 ], [ 2036125.0, 350375.0 ], [ 2035875.0, 350375.0 ], [ 2035875.0, 350093.678138779476285 ], [ 2035855.755667180055752, 350120.940943606023211 ], [ 2035621.798969799885526, 350242.598426243988797 ], [ 2035443.991879790090024, 350326.822837301006075 ], [ 2035454.028788686497137, 350375.0 ] ] ], [ [ [ 2044811.618042910005897, 329138.691991147992667 ], [ 2044758.410026984056458, 329258.410026984114666 ], [ 2044875.0, 329375.0 ], [ 2045125.0, 329375.0 ], [ 2045375.0, 329375.0 ], [ 2045625.0, 329375.0 ], [ 2045625.0, 329125.0 ], [ 2045625.0, 328875.0 ], [ 2045375.0, 328875.0 ], [ 2045245.162522831233218, 328745.162522831233218 ], [ 2045021.478312307735905, 329021.478312307677697 ], [ 2045017.49993660999462, 329026.392776404973119 ], [ 2044811.618042910005897, 329138.691991147992667 ] ] ], [ [ [ 2043875.0, 329874.822982012876309 ], [ 2043875.0, 330125.0 ], [ 2044125.0, 330125.0 ], [ 2044125.0, 329891.489648679620586 ], [ 2043875.0, 329874.822982012876309 ] ] ], [ [ [ 2038875.0, 330875.0 ], [ 2038875.0, 330625.0 ], [ 2038875.0, 330375.0 ], [ 2039125.0, 330375.0 ], [ 2039375.0, 330375.0 ], [ 2039548.440754137234762, 330201.559245862823445 ], [ 2039140.507698409957811, 330121.31012014602311 ], [ 2039125.0, 330126.949283204041421 ], [ 2038831.684857859974727, 330233.609334888984449 ], [ 2038791.728163316845894, 330291.728163316787686 ], [ 2038625.802964169997722, 330533.073907535988837 ], [ 2038608.566821833373979, 330625.0 ], [ 2038569.653356800088659, 330832.538480182993226 ], [ 2038595.783522840589285, 330875.0 ], [ 2038875.0, 330875.0 ] ] ], [ [ [ 2041375.0, 331375.0 ], [ 2041480.59065587236546, 331269.409344127692748 ], [ 2041218.043171149911359, 331057.136909668974113 ], [ 2041204.391320103546605, 331045.608679896511603 ], [ 2041125.0, 331125.0 ], [ 2041125.0, 331375.0 ], [ 2041375.0, 331375.0 ] ] ], [ [ [ 2042625.0, 330625.0 ], [ 2042375.0, 330625.0 ], [ 2042375.0, 330875.0 ], [ 2042375.0, 331125.0 ], [ 2042375.0, 331375.0 ], [ 2042375.0, 331625.0 ], [ 2042375.0, 331875.0 ], [ 2042375.0, 332125.0 ], [ 2042625.0, 332125.0 ], [ 2042625.0, 332375.0 ], [ 2042875.0, 332375.0 ], [ 2042875.0, 332125.0 ], [ 2042875.0, 331875.0 ], [ 2042875.0, 331625.0 ], [ 2042625.0, 331625.0 ], [ 2042625.0, 331375.0 ], [ 2042625.0, 331125.0 ], [ 2042625.0, 330875.0 ], [ 2042625.0, 330625.0 ] ] ], [ [ [ 2041125.0, 332375.0 ], [ 2041375.0, 332375.0 ], [ 2041375.0, 332625.0 ], [ 2041625.0, 332625.0 ], [ 2041875.0, 332625.0 ], [ 2042125.0, 332625.0 ], [ 2042125.0, 332375.0 ], [ 2042125.0, 332125.0 ], [ 2041875.0, 332125.0 ], [ 2041875.0, 331875.0 ], [ 2041625.0, 331875.0 ], [ 2041375.0, 331875.0 ], [ 2041375.0, 331625.0 ], [ 2041125.0, 331625.0 ], [ 2040875.0, 331625.0 ], [ 2040875.0, 331375.0 ], [ 2040625.0, 331375.0 ], [ 2040625.0, 331125.0 ], [ 2040375.0, 331125.0 ], [ 2040125.0, 331125.0 ], [ 2040125.0, 330875.0 ], [ 2039875.0, 330875.0 ], [ 2039875.0, 330625.0 ], [ 2039625.0, 330625.0 ], [ 2039625.0, 330875.0 ], [ 2039625.0, 331125.0 ], [ 2039625.0, 331375.0 ], [ 2039479.618512869346887, 331520.381487130653113 ], [ 2039627.13762895995751, 331571.841643906023819 ], [ 2039802.535532959736884, 331697.464467040321324 ], [ 2040125.0, 331928.418747487070505 ], [ 2040239.543406976154074, 332010.456593023729511 ], [ 2040319.649453209945932, 332067.829842353006825 ], [ 2040538.916008312953636, 332211.083991687046364 ], [ 2040875.0, 332430.65886625595158 ], [ 2040992.545040570897982, 332507.454959429043811 ], [ 2041125.0, 332375.0 ] ] ], [ [ [ 2042375.0, 332375.0 ], [ 2042375.0, 332625.0 ], [ 2042625.0, 332625.0 ], [ 2042625.0, 332375.0 ], [ 2042375.0, 332375.0 ] ] ], [ [ [ 2043847.716449700063094, 333087.881042931985576 ], [ 2043800.409551271703094, 332875.0 ], [ 2043791.566842329921201, 332835.20780976099195 ], [ 2043854.061056044185534, 332625.0 ], [ 2043894.507789179915562, 332488.951897637976799 ], [ 2043921.177382243564352, 332375.0 ], [ 2043979.688020539935678, 332125.0 ], [ 2043625.0, 332125.0 ], [ 2043625.0, 332375.0 ], [ 2043625.0, 332625.0 ], [ 2043625.0, 332875.0 ], [ 2043625.0, 333125.0 ], [ 2043907.106781009119004, 333125.0 ], [ 2043847.716449700063094, 333087.881042931985576 ] ] ], [ [ [ 2042125.0, 332625.0 ], [ 2042125.0, 332875.0 ], [ 2042375.0, 332875.0 ], [ 2042375.0, 332625.0 ], [ 2042125.0, 332625.0 ] ] ], [ [ [ 2041161.893563769990578, 333144.030650303000584 ], [ 2041208.471752394689247, 333291.528247605252545 ], [ 2041375.0, 333125.0 ], [ 2041375.0, 332875.0 ], [ 2041156.04507137532346, 332875.0 ], [ 2041161.893563769990578, 333144.030650303000584 ] ] ], [ [ [ 2045625.0, 333549.322385145525914 ], [ 2045625.0, 333875.0 ], [ 2045875.0, 333875.0 ], [ 2046125.0, 333875.0 ], [ 2046228.662012284621596, 333771.337987715494819 ], [ 2046168.566887720022351, 333714.884991911996622 ], [ 2045875.0, 333547.132484641566407 ], [ 2045841.027511389926076, 333527.71963400702225 ], [ 2045625.0, 333549.322385145525914 ] ] ], [ [ [ 2045125.0, 333875.0 ], [ 2045125.0, 334125.0 ], [ 2045375.0, 334125.0 ], [ 2045625.0, 334125.0 ], [ 2045625.0, 333875.0 ], [ 2045375.0, 333875.0 ], [ 2045125.0, 333875.0 ] ] ], [ [ [ 2042375.0, 334125.0 ], [ 2042125.0, 334125.0 ], [ 2041974.989066767739132, 334275.01093323220266 ], [ 2042235.703352481825277, 334514.29664751823293 ], [ 2042375.0, 334375.0 ], [ 2042375.0, 334125.0 ] ] ], [ [ [ 2046625.0, 334875.0 ], [ 2046625.0, 335125.0 ], [ 2046875.0, 335125.0 ], [ 2046875.0, 334875.0 ], [ 2046875.0, 334625.0 ], [ 2046625.0, 334625.0 ], [ 2046625.0, 334875.0 ] ] ], [ [ [ 2046125.0, 335125.0 ], [ 2046375.0, 335125.0 ], [ 2046375.0, 334875.0 ], [ 2046125.0, 334875.0 ], [ 2046125.0, 335125.0 ] ] ], [ [ [ 2042875.0, 335375.0 ], [ 2042875.0, 335625.0 ], [ 2042722.73240717779845, 335777.267592822259758 ], [ 2042724.724302279995754, 335783.0621967560146 ], [ 2042750.086454898351803, 335875.0 ], [ 2043125.0, 335875.0 ], [ 2043125.0, 335625.0 ], [ 2043125.0, 335375.0 ], [ 2042875.0, 335375.0 ] ] ], [ [ [ 2045897.17711876006797, 336475.574021001986694 ], [ 2045892.986534549389035, 336375.0 ], [ 2045625.0, 336375.0 ], [ 2045625.0, 336625.0 ], [ 2045375.0, 336625.0 ], [ 2045375.0, 336942.511958842398599 ], [ 2045644.503885590005666, 336803.113397334993351 ], [ 2045733.138612741837278, 336733.138612741895486 ], [ 2045822.310975600033998, 336662.739378907019272 ], [ 2045897.17711876006797, 336475.574021001986694 ] ] ], [ [ [ 2042930.689328896580264, 339680.689328896638472 ], [ 2043070.980214399984106, 339526.369354845024645 ], [ 2043202.605740349041298, 339375.0 ], [ 2043258.145572300069034, 339311.129193254979327 ], [ 2043289.167104511754587, 339125.0 ], [ 2043301.428946725092828, 339051.428946725151036 ], [ 2043125.0, 338875.0 ], [ 2043125.0, 338625.0 ], [ 2043125.0, 338375.0 ], [ 2042875.0, 338375.0 ], [ 2042875.0, 338125.0 ], [ 2042875.0, 337875.0 ], [ 2042875.0, 337625.0 ], [ 2042754.983489477075636, 337504.983489477017429 ], [ 2042715.366034379927441, 337504.983489477017429 ], [ 2042603.066819640109316, 337476.908685791015159 ], [ 2042397.184925939887762, 337411.400810524006374 ], [ 2042294.243979099905118, 337411.400810524006374 ], [ 2042219.377835940103978, 337476.908685791015159 ], [ 2042210.019568040035665, 337542.416561056976207 ], [ 2042378.468390149995685, 337664.074043695 ], [ 2042443.97626541997306, 337767.014990543015301 ], [ 2042541.676988262683153, 337875.0 ], [ 2042621.783355430001393, 337963.538616342004389 ], [ 2042659.216427010018378, 338057.121295295015443 ], [ 2042659.216427010018378, 338125.0 ], [ 2042659.216427010018378, 338150.70397424697876 ], [ 2042549.454542066901922, 338375.0 ], [ 2042492.133763959165663, 338492.13376395922387 ], [ 2042443.97626541997306, 338590.542565322015435 ], [ 2042350.393586470047012, 338749.633119540987536 ], [ 2042329.144962663995102, 338875.0 ], [ 2042286.772081308998168, 339125.0 ], [ 2042263.326852134196088, 339263.32685213413788 ], [ 2042256.810907519888133, 339301.770925358985551 ], [ 2042228.736103829927742, 339414.070140102005098 ], [ 2042081.724383295048028, 339625.0 ], [ 2042013.495942240115255, 339722.892980644013733 ], [ 2041987.657693951623514, 339737.657693951681722 ], [ 2041875.0, 339802.03351906692842 ], [ 2041816.972316439962015, 339835.192195386975072 ], [ 2041539.783753642113879, 340039.783753642172087 ], [ 2041625.0, 340125.0 ], [ 2041875.0, 340125.0 ], [ 2042125.0, 340125.0 ], [ 2042125.0, 339875.0 ], [ 2042375.0, 339875.0 ], [ 2042375.0, 340125.0 ], [ 2042689.136431750608608, 340125.0 ], [ 2042737.204595950897783, 339987.204595950955991 ], [ 2042790.232177539961413, 339835.192195386975072 ], [ 2042930.689328896580264, 339680.689328896638472 ] ] ], [ [ [ 2037125.0, 339125.0 ], [ 2037265.488501320593059, 338984.511498679406941 ], [ 2036965.113031983841211, 338784.886968016100582 ], [ 2036875.0, 338875.0 ], [ 2036875.0, 339125.0 ], [ 2036875.0, 339375.0 ], [ 2037125.0, 339375.0 ], [ 2037125.0, 339125.0 ] ] ], [ [ [ 2038125.0, 339875.0 ], [ 2038375.0, 339875.0 ], [ 2038466.990378667600453, 339783.009621332399547 ], [ 2038125.0, 339555.728515509690624 ], [ 2038125.0, 339875.0 ] ] ], [ [ [ 2037125.0, 339875.0 ], [ 2037375.0, 339875.0 ], [ 2037625.0, 339875.0 ], [ 2037625.0, 339625.0 ], [ 2037375.0, 339625.0 ], [ 2037125.0, 339625.0 ], [ 2037125.0, 339875.0 ] ] ], [ [ [ 2040125.0, 341375.0 ], [ 2040375.0, 341375.0 ], [ 2040375.0, 341125.0 ], [ 2040125.0, 341125.0 ], [ 2039875.0, 341125.0 ], [ 2039875.0, 341375.0 ], [ 2040125.0, 341375.0 ] ] ], [ [ [ 2041875.0, 341875.0 ], [ 2042125.0, 341875.0 ], [ 2042375.0, 341875.0 ], [ 2042625.0, 341875.0 ], [ 2042625.0, 342125.0 ], [ 2042875.0, 342125.0 ], [ 2042934.929263087222353, 342065.070736912835855 ], [ 2042743.440838069887832, 341903.369400230993051 ], [ 2042676.474764458369464, 341823.525235541630536 ], [ 2042500.125872790114954, 341613.263095478992909 ], [ 2042485.427302830619738, 341514.57269716943847 ], [ 2042464.639879849739373, 341375.0 ], [ 2042434.617997529916465, 341173.424504404014442 ], [ 2042443.538300971966237, 341125.0 ], [ 2042489.590932546183467, 340875.0 ], [ 2042500.125872790114954, 340817.810324385005515 ], [ 2042514.009862861363217, 340764.00986286130501 ], [ 2042375.0, 340625.0 ], [ 2042125.0, 340625.0 ], [ 2042125.0, 340875.0 ], [ 2042125.0, 341125.0 ], [ 2041875.0, 341125.0 ], [ 2041625.0, 341125.0 ], [ 2041375.0, 341125.0 ], [ 2041375.0, 341375.0 ], [ 2041375.0, 341625.0 ], [ 2041125.0, 341625.0 ], [ 2041125.0, 341875.0 ], [ 2041125.0, 342125.0 ], [ 2041125.0, 342375.0 ], [ 2041375.0, 342375.0 ], [ 2041375.0, 342125.0 ], [ 2041375.0, 341875.0 ], [ 2041625.0, 341875.0 ], [ 2041625.0, 342125.0 ], [ 2041875.0, 342125.0 ], [ 2041875.0, 341875.0 ] ] ], [ [ [ 2039875.0, 341875.0 ], [ 2039625.0, 341875.0 ], [ 2039625.0, 341625.0 ], [ 2039625.0, 341375.0 ], [ 2039375.0, 341375.0 ], [ 2039375.0, 341625.0 ], [ 2039125.0, 341625.0 ], [ 2038875.0, 341625.0 ], [ 2038625.0, 341625.0 ], [ 2038375.0, 341625.0 ], [ 2038125.0, 341625.0 ], [ 2037875.0, 341625.0 ], [ 2037875.0, 341875.0 ], [ 2038125.0, 341875.0 ], [ 2038375.0, 341875.0 ], [ 2038625.0, 341875.0 ], [ 2038875.0, 341875.0 ], [ 2039125.0, 341875.0 ], [ 2039375.0, 341875.0 ], [ 2039375.0, 342125.0 ], [ 2039375.0, 342375.0 ], [ 2039625.0, 342375.0 ], [ 2039875.0, 342375.0 ], [ 2040125.0, 342375.0 ], [ 2040125.0, 342125.0 ], [ 2039875.0, 342125.0 ], [ 2039875.0, 341875.0 ] ] ], [ [ [ 2041625.0, 342375.0 ], [ 2041375.0, 342375.0 ], [ 2041375.0, 342625.0 ], [ 2041625.0, 342625.0 ], [ 2041625.0, 342375.0 ] ] ], [ [ [ 2043125.0, 343625.0 ], [ 2043125.0, 343375.0 ], [ 2043125.0, 343125.0 ], [ 2043125.0, 342875.0 ], [ 2043125.0, 342625.0 ], [ 2043375.0, 342625.0 ], [ 2043477.097937785089016, 342522.902062214910984 ], [ 2043206.013600436039269, 342293.986399563902523 ], [ 2043125.0, 342375.0 ], [ 2042875.0, 342375.0 ], [ 2042625.0, 342375.0 ], [ 2042375.0, 342375.0 ], [ 2042375.0, 342125.0 ], [ 2042125.0, 342125.0 ], [ 2042125.0, 342375.0 ], [ 2042125.0, 342625.0 ], [ 2042125.0, 342875.0 ], [ 2042375.0, 342875.0 ], [ 2042375.0, 343125.0 ], [ 2042625.0, 343125.0 ], [ 2042625.0, 343375.0 ], [ 2042875.0, 343375.0 ], [ 2042875.0, 343625.0 ], [ 2042875.0, 343875.0 ], [ 2043125.0, 343875.0 ], [ 2043375.0, 343875.0 ], [ 2043375.0, 343625.0 ], [ 2043125.0, 343625.0 ] ] ], [ [ [ 2041875.0, 343875.0 ], [ 2041875.0, 343625.0 ], [ 2041875.0, 343375.0 ], [ 2041875.0, 343125.0 ], [ 2041875.0, 342875.0 ], [ 2041875.0, 342625.0 ], [ 2041625.0, 342625.0 ], [ 2041625.0, 342875.0 ], [ 2041625.0, 343125.0 ], [ 2041625.0, 343375.0 ], [ 2041625.0, 343625.0 ], [ 2041625.0, 343875.0 ], [ 2041875.0, 343875.0 ] ] ], [ [ [ 2040375.0, 343625.0 ], [ 2040125.0, 343625.0 ], [ 2040125.0, 343875.0 ], [ 2039875.0, 343875.0 ], [ 2039875.0, 344125.0 ], [ 2040125.0, 344125.0 ], [ 2040375.0, 344125.0 ], [ 2040375.0, 343875.0 ], [ 2040625.0, 343875.0 ], [ 2040875.0, 343875.0 ], [ 2040875.0, 343625.0 ], [ 2040875.0, 343375.0 ], [ 2040625.0, 343375.0 ], [ 2040625.0, 343625.0 ], [ 2040375.0, 343625.0 ] ] ], [ [ [ 2044125.0, 344375.0 ], [ 2044375.0, 344375.0 ], [ 2044375.0, 344625.0 ], [ 2044125.0, 344625.0 ], [ 2043875.0, 344625.0 ], [ 2043625.0, 344625.0 ], [ 2043625.0, 344875.0 ], [ 2043625.0, 345125.0 ], [ 2043875.0, 345125.0 ], [ 2043875.0, 344875.0 ], [ 2044125.0, 344875.0 ], [ 2044375.0, 344875.0 ], [ 2044375.0, 345125.0 ], [ 2044625.0, 345125.0 ], [ 2044625.0, 344875.0 ], [ 2044625.0, 344625.0 ], [ 2044875.0, 344625.0 ], [ 2045125.0, 344625.0 ], [ 2045125.0, 344375.0 ], [ 2045375.0, 344375.0 ], [ 2045375.0, 344625.0 ], [ 2045625.0, 344625.0 ], [ 2045625.0, 344375.0 ], [ 2045625.0, 344125.0 ], [ 2045708.068354367977008, 344041.931645632139407 ], [ 2045375.0, 343832.113254995492753 ], [ 2045247.933219232363626, 343752.066780767578166 ], [ 2044875.0, 343517.13528142782161 ], [ 2044787.798084096983075, 343462.201915903075133 ], [ 2044481.041327339829877, 343268.958672660053708 ], [ 2044125.0, 343044.668321076314896 ], [ 2044020.906192204449326, 342979.093807795550674 ], [ 2044006.807003919966519, 342970.211940285982564 ], [ 2043748.182275134138763, 342751.817724865977652 ], [ 2043625.0, 342875.0 ], [ 2043625.0, 343125.0 ], [ 2043375.0, 343125.0 ], [ 2043375.0, 343375.0 ], [ 2043625.0, 343375.0 ], [ 2043625.0, 343625.0 ], [ 2043625.0, 343875.0 ], [ 2043625.0, 344125.0 ], [ 2043375.0, 344125.0 ], [ 2043125.0, 344125.0 ], [ 2043125.0, 344375.0 ], [ 2043375.0, 344375.0 ], [ 2043625.0, 344375.0 ], [ 2043875.0, 344375.0 ], [ 2044125.0, 344375.0 ] ] ], [ [ [ 2038875.0, 344625.0 ], [ 2038875.0, 344375.0 ], [ 2038875.0, 344125.0 ], [ 2039125.0, 344125.0 ], [ 2039125.0, 343875.0 ], [ 2038875.0, 343875.0 ], [ 2038875.0, 343625.0 ], [ 2038625.0, 343625.0 ], [ 2038375.0, 343625.0 ], [ 2038125.0, 343625.0 ], [ 2038125.0, 343875.0 ], [ 2038125.0, 344125.0 ], [ 2038375.0, 344125.0 ], [ 2038375.0, 344375.0 ], [ 2038125.0, 344375.0 ], [ 2038125.0, 344625.0 ], [ 2038375.0, 344625.0 ], [ 2038375.0, 344875.0 ], [ 2038375.0, 345125.0 ], [ 2038625.0, 345125.0 ], [ 2038875.0, 345125.0 ], [ 2038875.0, 344875.0 ], [ 2038875.0, 344625.0 ] ] ], [ [ [ 2041875.0, 344625.0 ], [ 2041875.0, 344375.0 ], [ 2042125.0, 344375.0 ], [ 2042375.0, 344375.0 ], [ 2042625.0, 344375.0 ], [ 2042625.0, 344125.0 ], [ 2042375.0, 344125.0 ], [ 2042125.0, 344125.0 ], [ 2041875.0, 344125.0 ], [ 2041625.0, 344125.0 ], [ 2041375.0, 344125.0 ], [ 2041375.0, 343875.0 ], [ 2041125.0, 343875.0 ], [ 2041125.0, 344125.0 ], [ 2041125.0, 344375.0 ], [ 2041125.0, 344625.0 ], [ 2041125.0, 344875.0 ], [ 2041125.0, 345125.0 ], [ 2041375.0, 345125.0 ], [ 2041625.0, 345125.0 ], [ 2041875.0, 345125.0 ], [ 2042125.0, 345125.0 ], [ 2042125.0, 344875.0 ], [ 2042125.0, 344625.0 ], [ 2041875.0, 344625.0 ] ] ], [ [ [ 2042875.0, 344625.0 ], [ 2042625.0, 344625.0 ], [ 2042625.0, 344875.0 ], [ 2042875.0, 344875.0 ], [ 2042875.0, 344625.0 ] ] ], [ [ [ 2043375.0, 344625.0 ], [ 2043125.0, 344625.0 ], [ 2043125.0, 344875.0 ], [ 2043375.0, 344875.0 ], [ 2043375.0, 344625.0 ] ] ], [ [ [ 2039875.0, 345125.0 ], [ 2040125.0, 345125.0 ], [ 2040375.0, 345125.0 ], [ 2040375.0, 344875.0 ], [ 2040125.0, 344875.0 ], [ 2039875.0, 344875.0 ], [ 2039625.0, 344875.0 ], [ 2039625.0, 345125.0 ], [ 2039625.0, 345375.0 ], [ 2039875.0, 345375.0 ], [ 2039875.0, 345125.0 ] ] ], [ [ [ 2037875.0, 345375.0 ], [ 2037875.0, 345625.0 ], [ 2038125.0, 345625.0 ], [ 2038125.0, 345375.0 ], [ 2037875.0, 345375.0 ] ] ], [ [ [ 2044375.0, 345375.0 ], [ 2044125.0, 345375.0 ], [ 2044125.0, 345625.0 ], [ 2044375.0, 345625.0 ], [ 2044375.0, 345375.0 ] ] ], [ [ [ 2042625.0, 345625.0 ], [ 2042625.0, 345375.0 ], [ 2042375.0, 345375.0 ], [ 2042375.0, 345625.0 ], [ 2042625.0, 345625.0 ] ] ], [ [ [ 2042375.0, 345625.0 ], [ 2042125.0, 345625.0 ], [ 2042125.0, 345875.0 ], [ 2042375.0, 345875.0 ], [ 2042375.0, 345625.0 ] ] ], [ [ [ 2043375.0, 345625.0 ], [ 2043375.0, 345875.0 ], [ 2043625.0, 345875.0 ], [ 2043625.0, 345625.0 ], [ 2043375.0, 345625.0 ] ] ], [ [ [ 2046125.0, 348875.0 ], [ 2045875.0, 348875.0 ], [ 2045875.0, 349125.0 ], [ 2046125.0, 349125.0 ], [ 2046125.0, 348875.0 ] ] ], [ [ [ 2038875.0, 349625.0 ], [ 2038875.0, 349875.0 ], [ 2039125.0, 349875.0 ], [ 2039125.0, 349625.0 ], [ 2038875.0, 349625.0 ] ] ], [ [ [ 2036875.0, 350125.0 ], [ 2036875.0, 350492.031781814410351 ], [ 2036913.239939339924604, 350485.913391519978177 ], [ 2036980.972776822280139, 350519.027223177661654 ], [ 2037125.0, 350375.0 ], [ 2037125.0, 350125.0 ], [ 2037375.0, 350125.0 ], [ 2037375.0, 349875.0 ], [ 2037375.0, 349625.0 ], [ 2037125.0, 349625.0 ], [ 2036875.0, 349625.0 ], [ 2036625.0, 349625.0 ], [ 2036625.0, 349875.0 ], [ 2036875.0, 349875.0 ], [ 2036875.0, 350125.0 ] ] ], [ [ [ 2043625.0, 350125.0 ], [ 2043625.0, 350375.0 ], [ 2043875.0, 350375.0 ], [ 2043875.0, 350125.0 ], [ 2043625.0, 350125.0 ] ] ], [ [ [ 2038125.0, 350125.0 ], [ 2037875.0, 350125.0 ], [ 2037875.0, 350375.0 ], [ 2038125.0, 350375.0 ], [ 2038125.0, 350125.0 ] ] ], [ [ [ 2036375.0, 350375.0 ], [ 2036625.0, 350375.0 ], [ 2036625.0, 350125.0 ], [ 2036375.0, 350125.0 ], [ 2036375.0, 350375.0 ] ] ], [ [ [ 2045875.0, 350625.0 ], [ 2045875.0, 350875.0 ], [ 2046125.0, 350875.0 ], [ 2046125.0, 350625.0 ], [ 2045875.0, 350625.0 ] ] ], [ [ [ 2037463.693344051716849, 350786.306655948341358 ], [ 2037577.676959899952635, 350869.602375223999843 ], [ 2037579.476168158696964, 350875.0 ], [ 2037671.259638859890401, 351150.350412080006208 ], [ 2037875.0, 351252.220592652447522 ], [ 2038008.157283080043271, 351318.799234193982556 ], [ 2038125.0, 351292.092327469727024 ], [ 2038125.0, 350875.0 ], [ 2038125.0, 350625.0 ], [ 2037875.0, 350625.0 ], [ 2037625.0, 350625.0 ], [ 2037625.0, 350375.0 ], [ 2037375.0, 350375.0 ], [ 2037375.0, 350721.492289139947388 ], [ 2037463.693344051716849, 350786.306655948341358 ] ] ], [ [ [ 2039625.0, 350875.0 ], [ 2039375.0, 350875.0 ], [ 2039375.0, 350625.0 ], [ 2039125.0, 350625.0 ], [ 2039125.0, 350875.0 ], [ 2039125.0, 351164.751396803359967 ], [ 2039375.0, 351162.414948205288965 ], [ 2039625.0, 351160.078499607217964 ], [ 2039664.570700539974496, 351159.708679975999985 ], [ 2039875.0, 351248.169404589687474 ], [ 2039964.293289145454764, 351285.706710854603443 ], [ 2040125.0, 351125.0 ], [ 2040125.0, 350875.0 ], [ 2040125.0, 350625.0 ], [ 2039875.0, 350625.0 ], [ 2039875.0, 350875.0 ], [ 2039625.0, 350875.0 ] ] ], [ [ [ 2040492.320194975240156, 351507.679805024818052 ], [ 2040875.0, 351668.551570194249507 ], [ 2040875.0, 351375.0 ], [ 2040625.0, 351375.0 ], [ 2040492.320194975240156, 351507.679805024818052 ] ] ], [ [ [ 2042750.898281793342903, 352499.101718206715304 ], [ 2042790.232177539961413, 352516.65752478298964 ], [ 2043125.0, 352672.693374234077055 ], [ 2043262.989490407053381, 352737.010509593063034 ], [ 2043625.0, 352905.744221690867562 ], [ 2043875.0, 353022.269645419204608 ], [ 2043894.507789179915562, 353031.362259019981138 ], [ 2044125.0, 353047.258273558982182 ], [ 2044165.897558140102774, 353050.078794809989631 ], [ 2044534.408276748144999, 352784.408276748086791 ], [ 2044568.303077640011907, 352759.97249005897902 ], [ 2044625.0, 352740.272711950703524 ], [ 2044875.0, 352653.408305170363747 ], [ 2044875.0, 352375.0 ], [ 2045125.0, 352375.0 ], [ 2045125.0, 352125.0 ], [ 2044875.0, 352125.0 ], [ 2044875.0, 351875.0 ], [ 2045125.0, 351875.0 ], [ 2045375.0, 351875.0 ], [ 2045625.0, 351875.0 ], [ 2045625.0, 351625.0 ], [ 2045375.0, 351625.0 ], [ 2045125.0, 351625.0 ], [ 2045125.0, 351375.0 ], [ 2044875.0, 351375.0 ], [ 2044625.0, 351375.0 ], [ 2044375.0, 351375.0 ], [ 2044375.0, 351125.0 ], [ 2044375.0, 350875.0 ], [ 2044125.0, 350875.0 ], [ 2044125.0, 350625.0 ], [ 2043875.0, 350625.0 ], [ 2043625.0, 350625.0 ], [ 2043375.0, 350625.0 ], [ 2043125.0, 350625.0 ], [ 2042875.0, 350625.0 ], [ 2042625.0, 350625.0 ], [ 2042375.0, 350625.0 ], [ 2042125.0, 350625.0 ], [ 2042125.0, 350375.0 ], [ 2041875.0, 350375.0 ], [ 2041875.0, 350625.0 ], [ 2041875.0, 350875.0 ], [ 2041625.0, 350875.0 ], [ 2041375.0, 350875.0 ], [ 2041375.0, 351125.0 ], [ 2041125.0, 351125.0 ], [ 2041125.0, 351375.0 ], [ 2041375.0, 351375.0 ], [ 2041625.0, 351375.0 ], [ 2041625.0, 351625.0 ], [ 2041625.0, 351996.582146105298307 ], [ 2041713.788906794274226, 352036.211093205667567 ], [ 2042125.0, 352219.745987913920544 ], [ 2042232.343594293808565, 352267.656405706191435 ], [ 2042625.0, 352442.909829722542781 ], [ 2042750.898281793342903, 352499.101718206715304 ] ] ], [ [ [ 2041125.0, 351625.0 ], [ 2041020.347100805025548, 351729.65289919503266 ], [ 2041133.818760090041906, 351777.354361060017254 ], [ 2041375.0, 351885.000225200958084 ], [ 2041375.0, 351625.0 ], [ 2041125.0, 351625.0 ] ] ], [ [ [ 2045589.400186964077875, 358875.0 ], [ 2045524.329313099151477, 359024.329313099267893 ], [ 2045371.52309199119918, 359375.0 ], [ 2045262.584544504759833, 359625.0 ], [ 2045220.827367573278025, 359720.827367573219817 ], [ 2045044.707449531881139, 360125.0 ], [ 2044993.20090842875652, 360243.200908428698312 ], [ 2044826.830354559002444, 360625.0 ], [ 2044765.574449284235016, 360765.574449284176808 ], [ 2044689.960560269886628, 360939.098630482971203 ], [ 2044595.073402913520113, 361125.0 ], [ 2044520.703770205378532, 361270.70377020543674 ], [ 2044339.865069583524019, 361625.0 ], [ 2044267.255494345445186, 361767.255494345503394 ], [ 2044231.40543341008015, 361837.492348423984367 ], [ 2044147.549035033443943, 362125.0 ], [ 2044074.632368366699666, 362375.0 ], [ 2044034.881807609926909, 362511.287636880006175 ], [ 2044375.0, 362642.102326260879636 ], [ 2044625.0, 362738.256172414810862 ], [ 2044643.169220800045878, 362745.244334260991309 ], [ 2044875.0, 362766.809988140070345 ], [ 2045125.0, 362790.065802093537059 ], [ 2045202.705755531555042, 362797.294244468561374 ], [ 2045625.0, 362836.577430000528693 ], [ 2045875.0, 362859.833243953995407 ], [ 2046125.0, 362883.08905790746212 ], [ 2046125.0, 362625.0 ], [ 2045875.0, 362625.0 ], [ 2045875.0, 362375.0 ], [ 2045625.0, 362375.0 ], [ 2045375.0, 362375.0 ], [ 2045125.0, 362375.0 ], [ 2045125.0, 362125.0 ], [ 2045375.0, 362125.0 ], [ 2045375.0, 361875.0 ], [ 2045625.0, 361875.0 ], [ 2045625.0, 361625.0 ], [ 2045625.0, 361375.0 ], [ 2045625.0, 361125.0 ], [ 2045875.0, 361125.0 ], [ 2045875.0, 360875.0 ], [ 2045875.0, 360625.0 ], [ 2045875.0, 360375.0 ], [ 2046125.0, 360375.0 ], [ 2046375.0, 360375.0 ], [ 2046375.0, 360125.0 ], [ 2046375.0, 359875.0 ], [ 2046625.0, 359875.0 ], [ 2046625.0, 359625.0 ], [ 2046625.0, 359375.0 ], [ 2046875.0, 359375.0 ], [ 2046875.0, 359125.0 ], [ 2047125.0, 359125.0 ], [ 2047125.0, 358875.0 ], [ 2047375.0, 358875.0 ], [ 2047375.0, 358625.0 ], [ 2047375.0, 358375.0 ], [ 2047625.0, 358375.0 ], [ 2047625.0, 358125.0 ], [ 2047875.0, 358125.0 ], [ 2047875.0, 357875.0 ], [ 2048125.0, 357875.0 ], [ 2048125.0, 357625.0 ], [ 2048125.0, 357375.0 ], [ 2048125.0, 357125.0 ], [ 2047875.0, 357125.0 ], [ 2047625.0, 357125.0 ], [ 2047625.0, 356875.0 ], [ 2047625.0, 356625.0 ], [ 2047875.0, 356625.0 ], [ 2047875.0, 356375.0 ], [ 2047924.015269186114892, 356325.984730813885108 ], [ 2048040.994343778584152, 356290.994343778467737 ], [ 2048056.414309432962909, 356241.334207701147534 ], [ 2048059.782211526064202, 356095.699855783430394 ], [ 2047899.410151296760887, 355996.421776332135778 ], [ 2047895.280881618382409, 355895.280881618324202 ], [ 2047875.0, 355875.0 ], [ 2047625.0, 355875.0 ], [ 2047375.0, 355875.0 ], [ 2047125.0, 355875.0 ], [ 2046875.0, 355875.0 ], [ 2046875.0, 356125.0 ], [ 2046625.0, 356125.0 ], [ 2046625.0, 356375.0 ], [ 2046875.0, 356375.0 ], [ 2046875.0, 356625.0 ], [ 2046625.0, 356625.0 ], [ 2046625.0, 356875.0 ], [ 2046375.0, 356875.0 ], [ 2046375.0, 356625.0 ], [ 2046125.0, 356625.0 ], [ 2045875.0, 356625.0 ], [ 2045875.0, 356375.0 ], [ 2045625.0, 356375.0 ], [ 2045625.0, 356125.0 ], [ 2045625.0, 355875.0 ], [ 2045375.0, 355875.0 ], [ 2045375.0, 355521.513473123952281 ], [ 2045232.740098200039938, 355558.094590729975607 ], [ 2045077.972340184263885, 355875.0 ], [ 2045036.216472399886698, 355960.500110224995296 ], [ 2045224.312295054318383, 356275.687704945623409 ], [ 2045283.57930984441191, 356375.0 ], [ 2045382.47238452010788, 356540.71271972800605 ], [ 2045549.680005601840094, 356700.319994398159906 ], [ 2045805.49395908927545, 356944.50604091072455 ], [ 2046000.118065600050613, 357130.28359712701058 ], [ 2046029.557656314224005, 357220.44234368565958 ], [ 2046080.025462459772825, 357375.0 ], [ 2046149.850351929897442, 357588.83872399298707 ], [ 2046134.092924396041781, 357625.0 ], [ 2046025.154376909602433, 357875.0 ], [ 2045979.582231388427317, 357979.582231388310902 ], [ 2045807.277281936723739, 358375.0 ], [ 2045751.955772243672982, 358501.955772243789397 ], [ 2045589.400186964077875, 358875.0 ] ] ], [ [ [ 2048010.392948073800653, 327625.0 ], [ 2047625.0, 327625.0 ], [ 2047375.0, 327625.0 ], [ 2047375.0, 327875.0 ], [ 2047375.0, 328125.0 ], [ 2047375.0, 328375.0 ], [ 2047625.0, 328375.0 ], [ 2047625.0, 328125.0 ], [ 2047875.0, 328125.0 ], [ 2047875.0, 327875.0 ], [ 2048033.314358457922935, 327716.685641542135272 ], [ 2048010.392948073800653, 327625.0 ] ] ], [ [ [ 2047625.0, 333875.0 ], [ 2047875.0, 333875.0 ], [ 2048125.0, 333875.0 ], [ 2048125.0, 333491.750577958940994 ], [ 2047875.0, 333506.750577958882786 ], [ 2047625.0, 333521.750577958824579 ], [ 2047525.515732530038804, 333527.71963400702225 ], [ 2047218.655123849865049, 333718.655123849981464 ], [ 2047375.0, 333875.0 ], [ 2047625.0, 333875.0 ] ] ], [ [ [ 2049125.0, 334878.986807471257634 ], [ 2049312.944900509901345, 334959.534621976024937 ], [ 2049375.0, 334933.333579969126731 ], [ 2049767.578298415988684, 334767.578298415930476 ], [ 2049875.0, 334722.222468858293723 ], [ 2050125.0, 334616.666913302848116 ], [ 2050155.189011079957709, 334603.92044195800554 ], [ 2050504.849866310367361, 334504.849866310425568 ], [ 2050625.0, 334470.807328432041686 ], [ 2050716.685084800003096, 334444.829887738975231 ], [ 2050973.939559718128294, 334125.0 ], [ 2051062.940996919991449, 334014.34956455900101 ], [ 2050988.074853759957477, 333808.467670864018146 ], [ 2050772.407563124084845, 333727.59243687603157 ], [ 2050688.610281110042706, 333696.168456120998599 ], [ 2050375.0, 333576.06239101360552 ], [ 2050248.771690039895475, 333527.71963400702225 ], [ 2050125.0, 333526.633917427738197 ], [ 2049875.0, 333524.440934971673414 ], [ 2049625.0, 333522.247952515608631 ], [ 2049375.0, 333520.054970059543848 ], [ 2049181.929149979958311, 333518.361366112018004 ], [ 2049125.0, 333514.664668061363045 ], [ 2048875.0, 333498.430901827581692 ], [ 2048625.0, 333482.19713559380034 ], [ 2048461.342522050021216, 333471.570026636007242 ], [ 2048375.0, 333476.750577958999202 ], [ 2048375.0, 333875.0 ], [ 2048375.0, 334125.0 ], [ 2048375.0, 334375.0 ], [ 2048500.0, 334500.0 ], [ 2048500.0, 334532.85154322150629 ], [ 2048545.56693310989067, 334529.054298795992509 ], [ 2048751.448826800100505, 334716.219656699977349 ], [ 2048773.901268813991919, 334726.098731186124496 ], [ 2048985.405524180037901, 334819.16060354799265 ], [ 2049125.0, 334878.986807471257634 ] ] ], [ [ [ 2047125.0, 345125.0 ], [ 2047125.0, 345375.0 ], [ 2047375.0, 345375.0 ], [ 2047375.0, 345125.0 ], [ 2047125.0, 345125.0 ] ] ], [ [ [ 2047875.0, 345625.0 ], [ 2048125.0, 345625.0 ], [ 2048125.0, 345875.0 ], [ 2048375.0, 345875.0 ], [ 2048625.0, 345875.0 ], [ 2048625.0, 345524.746649439970497 ], [ 2048592.35827257996425, 345515.660807786975056 ], [ 2048514.520994080230594, 345485.479005919652991 ], [ 2048125.0, 345334.440253112465143 ], [ 2047875.0, 345237.50147760193795 ], [ 2047875.0, 345625.0 ] ] ], [ [ [ 2049875.0, 346125.0 ], [ 2050125.0, 346125.0 ], [ 2050267.940121002029628, 345982.05987899802858 ], [ 2049875.0, 345872.684793770487886 ], [ 2049875.0, 346125.0 ] ] ], [ [ [ 2052525.807856808882207, 346474.192143191059586 ], [ 2052125.0, 346388.429763349995483 ], [ 2051875.0, 346334.9363135684398 ], [ 2051625.0, 346281.442863786884118 ], [ 2051625.0, 346625.0 ], [ 2051875.0, 346625.0 ], [ 2052125.0, 346625.0 ], [ 2052375.0, 346625.0 ], [ 2052525.807856808882207, 346474.192143191059586 ] ] ], [ [ [ 2054125.0, 347625.0 ], [ 2053875.0, 347625.0 ], [ 2053875.0, 347875.0 ], [ 2054125.0, 347875.0 ], [ 2054125.0, 347625.0 ] ] ], [ [ [ 2055526.476974438643083, 347723.523025561473332 ], [ 2055221.476974438177422, 347528.523025561822578 ], [ 2055125.0, 347625.0 ], [ 2054875.0, 347625.0 ], [ 2054875.0, 347875.0 ], [ 2054875.0, 348125.0 ], [ 2055125.0, 348125.0 ], [ 2055375.0, 348125.0 ], [ 2055375.0, 347875.0 ], [ 2055526.476974438643083, 347723.523025561473332 ] ] ], [ [ [ 2049625.0, 347875.0 ], [ 2049625.0, 348125.0 ], [ 2049625.0, 348375.0 ], [ 2049875.0, 348375.0 ], [ 2049875.0, 348125.0 ], [ 2049875.0, 347875.0 ], [ 2049875.0, 347625.0 ], [ 2049625.0, 347625.0 ], [ 2049625.0, 347875.0 ] ] ], [ [ [ 2054375.0, 347875.0 ], [ 2054375.0, 348125.0 ], [ 2054625.0, 348125.0 ], [ 2054625.0, 347875.0 ], [ 2054375.0, 347875.0 ] ] ], [ [ [ 2056625.0, 348375.0 ], [ 2056875.0, 348375.0 ], [ 2056986.184095392236486, 348263.815904607879929 ], [ 2056818.275752479908988, 348107.90101476298878 ], [ 2056625.0, 348121.706425654585473 ], [ 2056625.0, 348375.0 ] ] ], [ [ [ 2055875.0, 348875.0 ], [ 2056125.0, 348875.0 ], [ 2056125.0, 348625.0 ], [ 2055875.0, 348625.0 ], [ 2055875.0, 348875.0 ] ] ], [ [ [ 2057125.0, 348875.0 ], [ 2057125.0, 349125.0 ], [ 2057375.0, 349125.0 ], [ 2057375.0, 348875.0 ], [ 2057125.0, 348875.0 ] ] ], [ [ [ 2059625.0, 349625.0 ], [ 2059759.905580135295168, 349490.094419864646625 ], [ 2059375.0, 349380.41702337434981 ], [ 2059125.0, 349309.180464234494139 ], [ 2059125.0, 349625.0 ], [ 2059375.0, 349625.0 ], [ 2059625.0, 349625.0 ] ] ], [ [ [ 2056625.0, 349125.0 ], [ 2056625.0, 349375.0 ], [ 2056625.0, 349625.0 ], [ 2056625.0, 349875.0 ], [ 2056875.0, 349875.0 ], [ 2056875.0, 349625.0 ], [ 2056875.0, 349375.0 ], [ 2056875.0, 349125.0 ], [ 2056625.0, 349125.0 ] ] ], [ [ [ 2056375.0, 349625.0 ], [ 2056375.0, 349375.0 ], [ 2056125.0, 349375.0 ], [ 2056125.0, 349625.0 ], [ 2056375.0, 349625.0 ] ] ], [ [ [ 2058875.0, 349875.0 ], [ 2058875.0, 349625.0 ], [ 2058625.0, 349625.0 ], [ 2058625.0, 349875.0 ], [ 2058875.0, 349875.0 ] ] ], [ [ [ 2048375.0, 350125.0 ], [ 2048375.0, 349875.0 ], [ 2048125.0, 349875.0 ], [ 2047875.0, 349875.0 ], [ 2047875.0, 350125.0 ], [ 2048125.0, 350125.0 ], [ 2048375.0, 350125.0 ] ] ], [ [ [ 2049375.0, 350875.0 ], [ 2049375.0, 350625.0 ], [ 2049625.0, 350625.0 ], [ 2049625.0, 350375.0 ], [ 2049625.0, 350125.0 ], [ 2049375.0, 350125.0 ], [ 2049375.0, 350375.0 ], [ 2049125.0, 350375.0 ], [ 2049125.0, 350625.0 ], [ 2049125.0, 350875.0 ], [ 2049375.0, 350875.0 ] ] ], [ [ [ 2047875.0, 350625.0 ], [ 2047625.0, 350625.0 ], [ 2047625.0, 350875.0 ], [ 2047875.0, 350875.0 ], [ 2047875.0, 351125.0 ], [ 2048125.0, 351125.0 ], [ 2048125.0, 350875.0 ], [ 2048125.0, 350625.0 ], [ 2047875.0, 350625.0 ] ] ], [ [ [ 2050125.0, 350875.0 ], [ 2050125.0, 351125.0 ], [ 2050375.0, 351125.0 ], [ 2050375.0, 350875.0 ], [ 2050125.0, 350875.0 ] ] ], [ [ [ 2047625.0, 350875.0 ], [ 2047375.0, 350875.0 ], [ 2047375.0, 351125.0 ], [ 2047375.0, 351375.0 ], [ 2047375.0, 351625.0 ], [ 2047625.0, 351625.0 ], [ 2047625.0, 351375.0 ], [ 2047625.0, 351125.0 ], [ 2047625.0, 350875.0 ] ] ], [ [ [ 2049125.0, 351125.0 ], [ 2049125.0, 351375.0 ], [ 2049375.0, 351375.0 ], [ 2049375.0, 351125.0 ], [ 2049125.0, 351125.0 ] ] ], [ [ [ 2048375.0, 351375.0 ], [ 2048375.0, 351625.0 ], [ 2048625.0, 351625.0 ], [ 2048625.0, 351375.0 ], [ 2048375.0, 351375.0 ] ] ], [ [ [ 2050125.0, 351875.0 ], [ 2050125.0, 351625.0 ], [ 2050125.0, 351375.0 ], [ 2049875.0, 351375.0 ], [ 2049875.0, 351625.0 ], [ 2049875.0, 351875.0 ], [ 2050125.0, 351875.0 ] ] ], [ [ [ 2047125.0, 351625.0 ], [ 2047125.0, 351875.0 ], [ 2047375.0, 351875.0 ], [ 2047375.0, 351625.0 ], [ 2047125.0, 351625.0 ] ] ], [ [ [ 2048125.0, 351625.0 ], [ 2048125.0, 351875.0 ], [ 2048375.0, 351875.0 ], [ 2048375.0, 351625.0 ], [ 2048125.0, 351625.0 ] ] ], [ [ [ 2049375.0, 352375.0 ], [ 2049375.0, 352125.0 ], [ 2049625.0, 352125.0 ], [ 2049625.0, 351875.0 ], [ 2049375.0, 351875.0 ], [ 2049375.0, 351625.0 ], [ 2049125.0, 351625.0 ], [ 2049125.0, 351875.0 ], [ 2048875.0, 351875.0 ], [ 2048875.0, 352125.0 ], [ 2048875.0, 352375.0 ], [ 2049125.0, 352375.0 ], [ 2049125.0, 352625.0 ], [ 2049125.0, 352875.0 ], [ 2049125.0, 353125.0 ], [ 2049375.0, 353125.0 ], [ 2049625.0, 353125.0 ], [ 2049625.0, 352875.0 ], [ 2049625.0, 352625.0 ], [ 2049625.0, 352375.0 ], [ 2049375.0, 352375.0 ] ] ], [ [ [ 2056625.0, 352375.0 ], [ 2056375.0, 352375.0 ], [ 2056125.0, 352375.0 ], [ 2055875.0, 352375.0 ], [ 2055875.0, 352625.0 ], [ 2056125.0, 352625.0 ], [ 2056375.0, 352625.0 ], [ 2056625.0, 352625.0 ], [ 2056625.0, 352375.0 ] ] ], [ [ [ 2057625.0, 353375.0 ], [ 2057375.0, 353375.0 ], [ 2057375.0, 353625.0 ], [ 2057625.0, 353625.0 ], [ 2057625.0, 353375.0 ] ] ], [ [ [ 2049125.0, 353625.0 ], [ 2049125.0, 353375.0 ], [ 2048875.0, 353375.0 ], [ 2048625.0, 353375.0 ], [ 2048500.0, 353500.0 ], [ 2048625.0, 353625.0 ], [ 2048875.0, 353625.0 ], [ 2048875.0, 353875.0 ], [ 2048875.0, 354125.0 ], [ 2049125.0, 354125.0 ], [ 2049125.0, 353875.0 ], [ 2049125.0, 353625.0 ] ] ], [ [ [ 2047875.0, 354625.0 ], [ 2047875.0, 354375.0 ], [ 2047727.399179421830922, 354227.39917942188913 ], [ 2047625.0, 354213.435654955392238 ], [ 2047375.0, 354179.344745864684228 ], [ 2047375.0, 354625.0 ], [ 2047125.0, 354625.0 ], [ 2047125.0, 354875.0 ], [ 2046875.0, 354875.0 ], [ 2046875.0, 355125.0 ], [ 2047125.0, 355125.0 ], [ 2047125.0, 355375.0 ], [ 2047375.0, 355375.0 ], [ 2047375.0, 355125.0 ], [ 2047625.0, 355125.0 ], [ 2047875.0, 355125.0 ], [ 2048125.0, 355125.0 ], [ 2048375.0, 355125.0 ], [ 2048375.0, 354875.0 ], [ 2048125.0, 354875.0 ], [ 2048125.0, 354625.0 ], [ 2047875.0, 354625.0 ] ] ], [ [ [ 2056375.0, 355125.0 ], [ 2056125.0, 355125.0 ], [ 2056125.0, 355375.0 ], [ 2056375.0, 355375.0 ], [ 2056375.0, 355125.0 ] ] ], [ [ [ 2046625.0, 355375.0 ], [ 2046625.0, 355625.0 ], [ 2046875.0, 355625.0 ], [ 2046875.0, 355375.0 ], [ 2046625.0, 355375.0 ] ] ], [ [ [ 2055875.0, 355744.162986650306266 ], [ 2055875.0, 355375.0 ], [ 2055625.0, 355375.0 ], [ 2055625.0, 355645.153085660480428 ], [ 2055875.0, 355744.162986650306266 ] ] ], [ [ [ 2057375.0, 355875.0 ], [ 2057375.0, 355625.0 ], [ 2057375.0, 355375.0 ], [ 2057125.0, 355375.0 ], [ 2056875.0, 355375.0 ], [ 2056875.0, 355625.0 ], [ 2056625.0, 355625.0 ], [ 2056625.0, 355375.0 ], [ 2056375.0, 355375.0 ], [ 2056375.0, 355625.0 ], [ 2056125.0, 355625.0 ], [ 2055968.720130129950121, 355781.279869870049879 ], [ 2056350.362357720034197, 355932.425306538993027 ], [ 2056375.0, 355955.766230804147199 ], [ 2056461.903827425092459, 356038.096172574907541 ], [ 2056718.660584182245657, 356281.339415817637928 ], [ 2056817.524534153053537, 356375.0 ], [ 2057125.0, 356375.0 ], [ 2057125.0, 356125.0 ], [ 2057375.0, 356125.0 ], [ 2057375.0, 355875.0 ] ] ], [ [ [ 2059375.0, 356125.0 ], [ 2059125.0, 356125.0 ], [ 2059125.0, 356375.0 ], [ 2059125.0, 356625.0 ], [ 2059375.0, 356625.0 ], [ 2059375.0, 356375.0 ], [ 2059375.0, 356125.0 ] ] ], [ [ [ 2050375.0, 356625.0 ], [ 2050375.0, 356375.0 ], [ 2050125.0, 356375.0 ], [ 2050125.0, 356625.0 ], [ 2050375.0, 356625.0 ] ] ], [ [ [ 2051895.8268395899795, 356886.968631852010731 ], [ 2052326.307162770070136, 356765.311149213986937 ], [ 2052311.916275671450421, 356625.0 ], [ 2051875.0, 356625.0 ], [ 2051875.0, 356375.0 ], [ 2051875.0, 356125.0 ], [ 2051625.0, 356125.0 ], [ 2051625.0, 356375.0 ], [ 2051554.664228707784787, 356445.335771292157006 ], [ 2051699.30321379005909, 356596.862327100010589 ], [ 2051781.620976123027503, 356718.379023877030704 ], [ 2051895.8268395899795, 356886.968631852010731 ] ] ], [ [ [ 2049875.0, 356625.0 ], [ 2049625.0, 356625.0 ], [ 2049625.0, 356875.0 ], [ 2049875.0, 356875.0 ], [ 2049875.0, 356625.0 ] ] ], [ [ [ 2051268.822890609968454, 356858.893828166008461 ], [ 2051385.769804697716609, 356625.0 ], [ 2051125.0, 356625.0 ], [ 2051125.0, 356977.336208671040367 ], [ 2051268.822890609968454, 356858.893828166008461 ] ] ], [ [ [ 2050125.0, 357375.0 ], [ 2050125.0, 357625.0 ], [ 2050125.0, 357875.0 ], [ 2050375.0, 357875.0 ], [ 2050375.0, 357625.0 ], [ 2050648.724023817339912, 357625.0 ], [ 2050679.252013219986111, 357495.256045041023754 ], [ 2050706.992838188074529, 357456.992838188132737 ], [ 2050947.687645873054862, 357125.0 ], [ 2050625.0, 357125.0 ], [ 2050375.0, 357125.0 ], [ 2050125.0, 357125.0 ], [ 2050125.0, 357375.0 ] ] ], [ [ [ 2057250.0, 357750.0 ], [ 2057375.0, 357625.0 ], [ 2057375.0, 357375.0 ], [ 2057125.0, 357375.0 ], [ 2057125.0, 357625.0 ], [ 2057250.0, 357750.0 ] ] ], [ [ [ 2056041.53951718006283, 358103.543458229978569 ], [ 2056269.222136728698388, 358230.777863271418028 ], [ 2056359.72062562010251, 358281.350548240006901 ], [ 2056625.0, 358360.369936354050878 ], [ 2056799.55921669001691, 358412.366298772976734 ], [ 2056943.242366073187441, 358125.0 ], [ 2056968.00803879997693, 358075.468654545024037 ], [ 2056999.206282081548125, 357999.206282081606332 ], [ 2056875.0, 357875.0 ], [ 2056875.0, 357625.0 ], [ 2056625.0, 357625.0 ], [ 2056511.712746385484934, 357511.712746385543142 ], [ 2056261.712746385252103, 357761.712746385193896 ], [ 2056153.838731920113787, 357869.586760849982966 ], [ 2056041.53951718006283, 358103.543458229978569 ] ] ], [ [ [ 2048125.0, 358125.0 ], [ 2048125.0, 358375.0 ], [ 2048375.0, 358375.0 ], [ 2048375.0, 358125.0 ], [ 2048375.0, 357875.0 ], [ 2048125.0, 357875.0 ], [ 2048125.0, 358125.0 ] ] ], [ [ [ 2057992.250846266048029, 357875.0 ], [ 2057625.0, 357875.0 ], [ 2057298.930689605418593, 357875.0 ], [ 2057520.495808988809586, 358229.504191011190414 ], [ 2057712.803501297254115, 358537.196498702745885 ], [ 2057767.680689608445391, 358625.0 ], [ 2057903.83482832997106, 358842.846621953009162 ], [ 2058081.641918339999393, 358880.279693534015678 ], [ 2058254.291882123332471, 358754.291882123390678 ], [ 2058427.897830459987745, 358627.606460363022052 ], [ 2058250.090740449959412, 358393.649762981978711 ], [ 2058194.191655781352893, 358305.8083442185889 ], [ 2057999.747211334994063, 358000.252788664889522 ], [ 2057988.059239380061626, 357981.885975593002513 ], [ 2057992.250846266048029, 357875.0 ] ] ], [ [ [ 2049375.0, 359875.0 ], [ 2049490.703500043135136, 359990.703500043193344 ], [ 2049750.101996283745393, 359750.101996283803601 ], [ 2050009.50049252435565, 359509.50049252435565 ], [ 2050052.248064239975065, 359469.850570933020208 ], [ 2050125.0, 359455.300183781015221 ], [ 2050286.20476161991246, 359423.059231457009446 ], [ 2050300.61904099280946, 359449.380959007306956 ], [ 2050477.542117915814742, 359772.45788208412705 ], [ 2050501.444923209957778, 359816.106483055977151 ], [ 2050534.572526490082964, 359875.0 ], [ 2050669.893745319917798, 360115.571055702981539 ], [ 2050903.850442700088024, 360096.854519912973046 ], [ 2050934.987919178325683, 359875.0 ], [ 2050970.075638475595042, 359625.0 ], [ 2050978.716585859889165, 359563.433249884983525 ], [ 2051028.77643278427422, 359528.776432784216013 ], [ 2051100.374068500008434, 359479.208838828024454 ], [ 2051228.358788205077872, 359228.358788205194287 ], [ 2051334.33076587994583, 359020.653711961989757 ], [ 2051275.166686237091199, 358724.833313762908801 ], [ 2051268.822890609968454, 358693.114335628983099 ], [ 2050903.850442700088024, 358655.681264049024321 ], [ 2050875.0, 358652.866586712363642 ], [ 2050625.0, 358628.476342809619382 ], [ 2050520.161459, 358618.248192468017805 ], [ 2050481.406756587559357, 358518.593243412440643 ], [ 2050454.653583730105311, 358449.79937035398325 ], [ 2050472.253435578430071, 358375.0 ], [ 2050531.076964991400018, 358125.0 ], [ 2050125.0, 358125.0 ], [ 2049875.0, 358125.0 ], [ 2049875.0, 357875.0 ], [ 2049625.0, 357875.0 ], [ 2049625.0, 358125.0 ], [ 2049375.0, 358125.0 ], [ 2049125.0, 358125.0 ], [ 2049125.0, 358375.0 ], [ 2048875.0, 358375.0 ], [ 2048875.0, 358625.0 ], [ 2049125.0, 358625.0 ], [ 2049375.0, 358625.0 ], [ 2049625.0, 358625.0 ], [ 2049875.0, 358625.0 ], [ 2049875.0, 358875.0 ], [ 2049875.0, 359125.0 ], [ 2049875.0, 359375.0 ], [ 2049625.0, 359375.0 ], [ 2049625.0, 359625.0 ], [ 2049375.0, 359625.0 ], [ 2049375.0, 359875.0 ] ] ], [ [ [ 2047125.0, 359625.0 ], [ 2047375.0, 359625.0 ], [ 2047375.0, 359375.0 ], [ 2047125.0, 359375.0 ], [ 2047125.0, 359625.0 ] ] ], [ [ [ 2047375.0, 360125.0 ], [ 2047625.0, 360125.0 ], [ 2047625.0, 359875.0 ], [ 2047375.0, 359875.0 ], [ 2047375.0, 360125.0 ] ] ], [ [ [ 2047375.0, 360625.0 ], [ 2047375.0, 360875.0 ], [ 2047625.0, 360875.0 ], [ 2047625.0, 360625.0 ], [ 2047375.0, 360625.0 ] ] ], [ [ [ 2047375.0, 361375.0 ], [ 2047625.0, 361375.0 ], [ 2047625.0, 361125.0 ], [ 2047375.0, 361125.0 ], [ 2047375.0, 361375.0 ] ] ], [ [ [ 2062875.0, 351375.0 ], [ 2063125.0, 351375.0 ], [ 2063125.0, 351030.452113917737734 ], [ 2063028.14763583149761, 350971.852364168618806 ], [ 2062875.0, 351125.0 ], [ 2062875.0, 351375.0 ] ] ], [ [ [ 2065034.834964490029961, 352197.464084975013975 ], [ 2064875.0, 352110.745114879333414 ], [ 2064875.0, 352375.0 ], [ 2065125.0, 352375.0 ], [ 2065220.994820896303281, 352279.005179103580303 ], [ 2065034.834964490029961, 352197.464084975013975 ] ] ], [ [ [ 2058125.0, 353625.0 ], [ 2058375.0, 353625.0 ], [ 2058375.0, 353375.0 ], [ 2058625.0, 353375.0 ], [ 2058625.0, 353125.0 ], [ 2058875.0, 353125.0 ], [ 2058875.0, 352875.0 ], [ 2058625.0, 352875.0 ], [ 2058625.0, 352625.0 ], [ 2058875.0, 352625.0 ], [ 2059125.0, 352625.0 ], [ 2059375.0, 352625.0 ], [ 2059625.0, 352625.0 ], [ 2059625.0, 352875.0 ], [ 2059625.0, 353125.0 ], [ 2059375.0, 353125.0 ], [ 2059375.0, 353375.0 ], [ 2059375.0, 353625.0 ], [ 2059625.0, 353625.0 ], [ 2059875.0, 353625.0 ], [ 2060125.0, 353625.0 ], [ 2060125.0, 353375.0 ], [ 2060125.0, 353125.0 ], [ 2060163.097459559794515, 353067.355153968965169 ], [ 2060319.55769241345115, 353000.673875383858103 ], [ 2060295.89290426322259, 352753.722286372852977 ], [ 2060594.955344538670033, 352883.180850168806501 ], [ 2060615.875600476050749, 352875.0 ], [ 2060875.0, 352875.0 ], [ 2060875.0, 352625.0 ], [ 2061125.0, 352625.0 ], [ 2061125.0, 352375.0 ], [ 2061125.0, 352125.0 ], [ 2061125.0, 351950.060636591981165 ], [ 2061172.273600102867931, 351856.060891543340404 ], [ 2061065.446651025675237, 351772.888735701038968 ], [ 2061083.122, 351764.558200000028592 ], [ 2061063.703, 351664.178100000019185 ], [ 2061061.849, 351663.458700000017416 ], [ 2061054.935050831874833, 351651.875175932247657 ], [ 2061048.719, 351641.4609 ], [ 2061044.033, 351635.098400000017136 ], [ 2061027.602, 351627.59519999998156 ], [ 2060991.953694114694372, 351624.893341886578128 ], [ 2060964.719821736216545, 351696.371154662920162 ], [ 2060857.700888885883614, 351615.397245519154239 ], [ 2060854.733, 351615.192800000018906 ], [ 2060751.325999999884516, 351607.555799999972805 ], [ 2060650.648, 351601.70150000002468 ], [ 2060635.897513984469697, 351600.890607873327099 ], [ 2060639.944290086627007, 351387.894145780184772 ], [ 2060625.0, 351374.847991493297741 ], [ 2060436.516043751034886, 351387.744993808853906 ], [ 2060375.0, 351327.830256019020453 ], [ 2060183.066451482241973, 351375.142003979417495 ], [ 2060170.242608245229349, 351571.859622314281296 ], [ 2060247.435, 351577.7048 ], [ 2060347.54, 351583.63890000001993 ], [ 2060375.690805861959234, 351585.1759505996597 ], [ 2060407.137546690180898, 351713.740684832155239 ], [ 2060386.95, 351771.946799999976065 ], [ 2060330.204857724253088, 351819.724748992884997 ], [ 2060158.335058291675523, 351754.521282917354256 ], [ 2060123.591380463680252, 351785.751374438928906 ], [ 2059919.377369914203882, 351654.814204456051812 ], [ 2059875.0, 351772.684193356079049 ], [ 2059673.995058369124308, 351652.305168879975099 ], [ 2059625.0, 351758.932045619178098 ], [ 2059427.903657301561907, 351650.729735348955728 ], [ 2059375.0, 351746.357840756012592 ], [ 2059375.0, 351875.0 ], [ 2059125.0, 351875.0 ], [ 2058875.0, 351875.0 ], [ 2058625.0, 351875.0 ], [ 2058625.0, 352125.0 ], [ 2058375.0, 352125.0 ], [ 2058375.0, 352375.0 ], [ 2058125.0, 352375.0 ], [ 2058125.0, 352625.0 ], [ 2058125.0, 352875.0 ], [ 2057875.0, 352875.0 ], [ 2057875.0, 353125.0 ], [ 2057875.0, 353375.0 ], [ 2057875.0, 353625.0 ], [ 2058125.0, 353625.0 ] ] ], [ [ [ 2062625.0, 352625.0 ], [ 2062875.0, 352625.0 ], [ 2062875.0, 352375.0 ], [ 2062625.0, 352375.0 ], [ 2062625.0, 352625.0 ] ] ], [ [ [ 2061625.0, 352875.0 ], [ 2061875.0, 352875.0 ], [ 2061875.0, 352625.0 ], [ 2062125.0, 352625.0 ], [ 2062125.0, 352375.0 ], [ 2061875.0, 352375.0 ], [ 2061625.0, 352375.0 ], [ 2061625.0, 352625.0 ], [ 2061625.0, 352875.0 ] ] ], [ [ [ 2067496.059420929988846, 353348.531036088010296 ], [ 2067375.0, 353288.853856756235473 ], [ 2067375.0, 353625.0 ], [ 2067625.0, 353625.0 ], [ 2067875.0, 353625.0 ], [ 2067988.448316165013239, 353511.551683835103177 ], [ 2067625.0, 353391.220822401810437 ], [ 2067496.059420929988846, 353348.531036088010296 ] ] ], [ [ [ 2062625.0, 353875.0 ], [ 2062625.0, 354125.0 ], [ 2062875.0, 354125.0 ], [ 2062875.0, 353875.0 ], [ 2062625.0, 353875.0 ] ] ], [ [ [ 2070375.0, 354372.352028578228783 ], [ 2070375.0, 354625.0 ], [ 2070625.0, 354625.0 ], [ 2070739.666175345424563, 354510.333824654691853 ], [ 2070375.0, 354372.352028578228783 ] ] ], [ [ [ 2061375.0, 354875.0 ], [ 2061625.0, 354875.0 ], [ 2061625.0, 354625.0 ], [ 2061375.0, 354625.0 ], [ 2061375.0, 354875.0 ] ] ], [ [ [ 2070125.0, 355125.0 ], [ 2070375.0, 355125.0 ], [ 2070375.0, 354875.0 ], [ 2070125.0, 354875.0 ], [ 2070125.0, 355125.0 ] ] ], [ [ [ 2059625.0, 355875.0 ], [ 2059625.0, 355625.0 ], [ 2059375.0, 355625.0 ], [ 2059375.0, 355875.0 ], [ 2059625.0, 355875.0 ] ] ], [ [ [ 2066625.0, 356125.0 ], [ 2066625.0, 356375.0 ], [ 2066875.0, 356375.0 ], [ 2066875.0, 356125.0 ], [ 2066625.0, 356125.0 ] ] ], [ [ [ 2068375.0, 356375.0 ], [ 2068125.0, 356375.0 ], [ 2068125.0, 356625.0 ], [ 2068375.0, 356625.0 ], [ 2068375.0, 356375.0 ] ] ], [ [ [ 2059375.0, 356625.0 ], [ 2059375.0, 356875.0 ], [ 2059625.0, 356875.0 ], [ 2059625.0, 356625.0 ], [ 2059375.0, 356625.0 ] ] ], [ [ [ 2060625.0, 357125.0 ], [ 2060625.0, 356875.0 ], [ 2060375.0, 356875.0 ], [ 2060375.0, 357125.0 ], [ 2060375.0, 357536.061457500502001 ], [ 2060451.632580644218251, 357548.367419355723541 ], [ 2060625.0, 357375.0 ], [ 2060875.0, 357375.0 ], [ 2060875.0, 357125.0 ], [ 2060625.0, 357125.0 ] ] ], [ [ [ 2066125.0, 357375.0 ], [ 2066125.0, 357125.0 ], [ 2065875.0, 357125.0 ], [ 2065875.0, 357375.0 ], [ 2065875.0, 357625.0 ], [ 2066125.0, 357625.0 ], [ 2066125.0, 357375.0 ] ] ], [ [ [ 2066125.0, 357875.0 ], [ 2066125.0, 358125.0 ], [ 2066375.0, 358125.0 ], [ 2066375.0, 357875.0 ], [ 2066375.0, 357625.0 ], [ 2066125.0, 357625.0 ], [ 2066125.0, 357875.0 ] ] ], [ [ [ 2072625.0, 358125.0 ], [ 2072375.0, 358125.0 ], [ 2072375.0, 358375.0 ], [ 2072625.0, 358375.0 ], [ 2072875.0, 358375.0 ], [ 2072875.0, 358125.0 ], [ 2072875.0, 357875.0 ], [ 2072625.0, 357875.0 ], [ 2072625.0, 358125.0 ] ] ], [ [ [ 2064625.0, 358375.0 ], [ 2064625.0, 358125.0 ], [ 2064375.0, 358125.0 ], [ 2064375.0, 358375.0 ], [ 2064265.642357896314934, 358484.357642103568651 ], [ 2064625.0, 358670.232284570811316 ], [ 2064625.0, 358375.0 ] ] ], [ [ [ 2065875.0, 358875.0 ], [ 2065875.0, 358625.0 ], [ 2065625.0, 358625.0 ], [ 2065375.0, 358625.0 ], [ 2065375.0, 358375.0 ], [ 2065125.0, 358375.0 ], [ 2065125.0, 358625.0 ], [ 2064875.0, 358625.0 ], [ 2064759.960539714666083, 358740.039460285275709 ], [ 2065125.0, 358928.852974225825164 ], [ 2065254.278721533017233, 358995.721278466982767 ], [ 2065625.0, 359187.473663880780805 ], [ 2065736.705056630074978, 359245.252141448028851 ], [ 2065748.449899390572682, 359251.550100609427318 ], [ 2066125.0, 359453.468270501471125 ], [ 2066236.657446560449898, 359513.342553439608309 ], [ 2066375.0, 359375.0 ], [ 2066375.0, 359125.0 ], [ 2066125.0, 359125.0 ], [ 2066125.0, 358875.0 ], [ 2065875.0, 358875.0 ] ] ], [ [ [ 2072375.0, 359375.0 ], [ 2072375.0, 359625.0 ], [ 2072625.0, 359625.0 ], [ 2072625.0, 359375.0 ], [ 2072375.0, 359375.0 ] ] ], [ [ [ 2066625.0, 359375.0 ], [ 2066625.0, 359625.0 ], [ 2066489.289956248365343, 359760.710043751518242 ], [ 2066494.724756140029058, 359769.315143580024596 ], [ 2066501.330059669679031, 359875.0 ], [ 2066875.0, 359875.0 ], [ 2066875.0, 359625.0 ], [ 2066875.0, 359375.0 ], [ 2066625.0, 359375.0 ] ] ], [ [ [ 2069125.0, 359875.0 ], [ 2069125.0, 360125.0 ], [ 2069375.0, 360125.0 ], [ 2069625.0, 360125.0 ], [ 2069875.0, 360125.0 ], [ 2070125.0, 360125.0 ], [ 2070375.0, 360125.0 ], [ 2070375.0, 359875.0 ], [ 2070125.0, 359875.0 ], [ 2070125.0, 359625.0 ], [ 2069875.0, 359625.0 ], [ 2069625.0, 359625.0 ], [ 2069375.0, 359625.0 ], [ 2069375.0, 359875.0 ], [ 2069125.0, 359875.0 ] ] ], [ [ [ 2067625.0, 360125.0 ], [ 2067875.0, 360125.0 ], [ 2067875.0, 359875.0 ], [ 2067625.0, 359875.0 ], [ 2067375.0, 359875.0 ], [ 2067375.0, 360125.0 ], [ 2067625.0, 360125.0 ] ] ], [ [ [ 2072375.0, 360125.0 ], [ 2072375.0, 360375.0 ], [ 2072625.0, 360375.0 ], [ 2072625.0, 360125.0 ], [ 2072375.0, 360125.0 ] ] ], [ [ [ 2072375.0, 360875.0 ], [ 2072375.0, 361125.0 ], [ 2072625.0, 361125.0 ], [ 2072625.0, 360875.0 ], [ 2072375.0, 360875.0 ] ] ], [ [ [ 2069875.0, 361375.0 ], [ 2069625.0, 361375.0 ], [ 2069375.0, 361375.0 ], [ 2069375.0, 361625.0 ], [ 2069375.0, 361875.0 ], [ 2069625.0, 361875.0 ], [ 2069625.0, 362125.0 ], [ 2069875.0, 362125.0 ], [ 2069875.0, 361875.0 ], [ 2070125.0, 361875.0 ], [ 2070125.0, 361625.0 ], [ 2070125.0, 361375.0 ], [ 2069875.0, 361375.0 ] ] ], [ [ [ 2068125.0, 362125.0 ], [ 2068125.0, 362375.0 ], [ 2068375.0, 362375.0 ], [ 2068625.0, 362375.0 ], [ 2068875.0, 362375.0 ], [ 2069125.0, 362375.0 ], [ 2069125.0, 362125.0 ], [ 2068875.0, 362125.0 ], [ 2068625.0, 362125.0 ], [ 2068375.0, 362125.0 ], [ 2068125.0, 362125.0 ] ] ], [ [ [ 2067625.0, 362284.505883899983019 ], [ 2067625.0, 362625.0 ], [ 2067875.0, 362625.0 ], [ 2067875.0, 362375.0 ], [ 2067719.184426684165373, 362219.184426684165373 ], [ 2067625.0, 362284.505883899983019 ] ] ], [ [ [ 2070625.0, 362875.0 ], [ 2070875.0, 362875.0 ], [ 2070875.0, 362625.0 ], [ 2070625.0, 362625.0 ], [ 2070625.0, 362375.0 ], [ 2070375.0, 362375.0 ], [ 2070375.0, 362625.0 ], [ 2070375.0, 362875.0 ], [ 2070125.0, 362875.0 ], [ 2070125.0, 363125.0 ], [ 2070375.0, 363125.0 ], [ 2070375.0, 363375.0 ], [ 2070625.0, 363375.0 ], [ 2070625.0, 363125.0 ], [ 2070625.0, 362875.0 ] ] ], [ [ [ 2068125.0, 363375.0 ], [ 2068375.0, 363375.0 ], [ 2068375.0, 363125.0 ], [ 2068125.0, 363125.0 ], [ 2068125.0, 363375.0 ] ] ], [ [ [ 2066625.0, 363375.0 ], [ 2066625.0, 363125.0 ], [ 2066375.0, 363125.0 ], [ 2066125.0, 363125.0 ], [ 2066125.0, 363375.0 ], [ 2066375.0, 363375.0 ], [ 2066625.0, 363375.0 ] ] ], [ [ [ 2067625.0, 363125.0 ], [ 2067375.0, 363125.0 ], [ 2067125.0, 363125.0 ], [ 2067125.0, 363375.0 ], [ 2067375.0, 363375.0 ], [ 2067625.0, 363375.0 ], [ 2067875.0, 363375.0 ], [ 2067875.0, 363125.0 ], [ 2067625.0, 363125.0 ] ] ], [ [ [ 2065875.0, 363625.0 ], [ 2065875.0, 363875.0 ], [ 2066125.0, 363875.0 ], [ 2066125.0, 363625.0 ], [ 2065875.0, 363625.0 ] ] ], [ [ [ 2067875.0, 363625.0 ], [ 2067875.0, 363875.0 ], [ 2068125.0, 363875.0 ], [ 2068125.0, 363625.0 ], [ 2067875.0, 363625.0 ] ] ], [ [ [ 2072625.0, 363625.0 ], [ 2072375.0, 363625.0 ], [ 2072375.0, 363875.0 ], [ 2072625.0, 363875.0 ], [ 2072625.0, 363625.0 ] ] ], [ [ [ 2066625.0, 364125.0 ], [ 2066875.0, 364125.0 ], [ 2066875.0, 363875.0 ], [ 2066625.0, 363875.0 ], [ 2066625.0, 364125.0 ] ] ], [ [ [ 2070625.0, 364375.0 ], [ 2070875.0, 364375.0 ], [ 2070875.0, 364625.0 ], [ 2070875.0, 364875.0 ], [ 2071125.0, 364875.0 ], [ 2071125.0, 364625.0 ], [ 2071375.0, 364625.0 ], [ 2071625.0, 364625.0 ], [ 2071875.0, 364625.0 ], [ 2071875.0, 364875.0 ], [ 2072125.0, 364875.0 ], [ 2072125.0, 364625.0 ], [ 2072125.0, 364375.0 ], [ 2072125.0, 364125.0 ], [ 2071875.0, 364125.0 ], [ 2071875.0, 363875.0 ], [ 2071875.0, 363625.0 ], [ 2071625.0, 363625.0 ], [ 2071625.0, 363375.0 ], [ 2071375.0, 363375.0 ], [ 2071375.0, 363625.0 ], [ 2071375.0, 363875.0 ], [ 2071125.0, 363875.0 ], [ 2071125.0, 363625.0 ], [ 2070875.0, 363625.0 ], [ 2070625.0, 363625.0 ], [ 2070625.0, 363875.0 ], [ 2070375.0, 363875.0 ], [ 2070375.0, 363625.0 ], [ 2070125.0, 363625.0 ], [ 2070125.0, 363875.0 ], [ 2069875.0, 363875.0 ], [ 2069875.0, 363625.0 ], [ 2069625.0, 363625.0 ], [ 2069625.0, 363375.0 ], [ 2069375.0, 363375.0 ], [ 2069125.0, 363375.0 ], [ 2068875.0, 363375.0 ], [ 2068625.0, 363375.0 ], [ 2068625.0, 363625.0 ], [ 2068875.0, 363625.0 ], [ 2068875.0, 363875.0 ], [ 2069125.0, 363875.0 ], [ 2069375.0, 363875.0 ], [ 2069625.0, 363875.0 ], [ 2069625.0, 364125.0 ], [ 2069875.0, 364125.0 ], [ 2070125.0, 364125.0 ], [ 2070125.0, 364375.0 ], [ 2070375.0, 364375.0 ], [ 2070625.0, 364375.0 ] ] ], [ [ [ 2067875.0, 364375.0 ], [ 2068125.0, 364375.0 ], [ 2068125.0, 364125.0 ], [ 2067875.0, 364125.0 ], [ 2067875.0, 364375.0 ] ] ], [ [ [ 2068625.0, 364625.0 ], [ 2068625.0, 364875.0 ], [ 2068875.0, 364875.0 ], [ 2068875.0, 364625.0 ], [ 2069125.0, 364625.0 ], [ 2069125.0, 364875.0 ], [ 2069375.0, 364875.0 ], [ 2069375.0, 364625.0 ], [ 2069375.0, 364375.0 ], [ 2069125.0, 364375.0 ], [ 2068875.0, 364375.0 ], [ 2068625.0, 364375.0 ], [ 2068625.0, 364625.0 ] ] ], [ [ [ 2066520.182177630718797, 364729.817822369164787 ], [ 2066875.0, 364864.40389292355394 ], [ 2066875.0, 364625.0 ], [ 2066625.0, 364625.0 ], [ 2066520.182177630718797, 364729.817822369164787 ] ] ], [ [ [ 2067625.0, 364875.0 ], [ 2067453.413004581583664, 365046.586995418299921 ], [ 2067875.0, 365134.984268651111051 ], [ 2067875.0, 364875.0 ], [ 2067625.0, 364875.0 ] ] ], [ [ [ 2070625.0, 365125.0 ], [ 2070625.0, 365375.0 ], [ 2070875.0, 365375.0 ], [ 2070875.0, 365125.0 ], [ 2070625.0, 365125.0 ] ] ], [ [ [ 2072375.0, 365875.0 ], [ 2072375.0, 365625.0 ], [ 2072125.0, 365625.0 ], [ 2072125.0, 365875.0 ], [ 2072375.0, 365875.0 ] ] ], [ [ [ 2071125.0, 366125.0 ], [ 2071375.0, 366125.0 ], [ 2071375.0, 365875.0 ], [ 2071125.0, 365875.0 ], [ 2071125.0, 366125.0 ] ] ], [ [ [ 2071125.0, 366375.0 ], [ 2071125.0, 366125.0 ], [ 2070875.0, 366125.0 ], [ 2070875.0, 366375.0 ], [ 2071125.0, 366375.0 ] ] ], [ [ [ 2071375.0, 366625.0 ], [ 2071375.0, 366875.0 ], [ 2071625.0, 366875.0 ], [ 2071625.0, 366625.0 ], [ 2071375.0, 366625.0 ] ] ], [ [ [ 2070875.0, 367375.0 ], [ 2070875.0, 367125.0 ], [ 2070625.0, 367125.0 ], [ 2070625.0, 366875.0 ], [ 2070625.0, 366625.0 ], [ 2070375.0, 366625.0 ], [ 2070375.0, 366875.0 ], [ 2070295.117965420009568, 366954.882034580048639 ], [ 2070504.795384774450213, 367245.204615225607995 ], [ 2070593.64609425002709, 367368.228674500016496 ], [ 2070594.4274010383524, 367375.0 ], [ 2070875.0, 367375.0 ] ] ], [ [ [ 2071125.0, 367875.0 ], [ 2070875.0, 367875.0 ], [ 2070648.246363546932116, 367875.0 ], [ 2070629.015594316646457, 368125.0 ], [ 2070875.0, 368125.0 ], [ 2071125.0, 368125.0 ], [ 2071125.0, 367875.0 ] ] ], [ [ [ 2071125.0, 368375.0 ], [ 2071125.0, 368625.0 ], [ 2071375.0, 368625.0 ], [ 2071375.0, 368375.0 ], [ 2071125.0, 368375.0 ] ] ], [ [ [ 2071875.0, 369158.764727400324773 ], [ 2071875.0, 368875.0 ], [ 2071625.0, 368875.0 ], [ 2071625.0, 368625.0 ], [ 2071375.0, 368625.0 ], [ 2071375.0, 368947.085895284602884 ], [ 2071499.996063312981278, 369000.003936686960515 ], [ 2071875.0, 369158.764727400324773 ] ] ], [ [ [ 2072625.0, 369491.622143981629051 ], [ 2072625.0, 369125.0 ], [ 2072375.0, 369125.0 ], [ 2072202.560165878152475, 369297.439834121789318 ], [ 2072530.807548559969291, 369436.405879343976267 ], [ 2072625.0, 369491.622143981629051 ] ] ], [ [ [ 2074375.0, 356875.0 ], [ 2074125.0, 356875.0 ], [ 2074125.0, 357125.0 ], [ 2074375.0, 357125.0 ], [ 2074625.0, 357125.0 ], [ 2074625.0, 357375.0 ], [ 2074375.0, 357375.0 ], [ 2074375.0, 357625.0 ], [ 2074625.0, 357625.0 ], [ 2074875.0, 357625.0 ], [ 2075125.0, 357625.0 ], [ 2075125.0, 357375.0 ], [ 2075375.0, 357375.0 ], [ 2075625.0, 357375.0 ], [ 2075875.0, 357375.0 ], [ 2076125.0, 357375.0 ], [ 2076125.0, 357037.964313182164915 ], [ 2075875.0, 356990.955766173545271 ], [ 2075777.396945019485429, 356972.603054980572779 ], [ 2075375.0, 356896.938672156305984 ], [ 2075366.362720810109749, 356895.314568376983516 ], [ 2075263.560928629944101, 356736.439071370055899 ], [ 2075191.453294214559719, 356625.0 ], [ 2074968.918071488384157, 356281.081928511557635 ], [ 2074772.489500060677528, 355977.510499939206056 ], [ 2074748.717039729934186, 355940.77124306402402 ], [ 2074375.0, 355807.89407338242745 ], [ 2074240.078142586629838, 355759.921857413311955 ], [ 2073875.0, 355630.116295604908373 ], [ 2073625.0, 355541.227406716148835 ], [ 2073502.373224553652108, 355497.626775446347892 ], [ 2073375.0, 355625.0 ], [ 2073125.0, 355625.0 ], [ 2073125.0, 355875.0 ], [ 2073125.0, 356125.0 ], [ 2073125.0, 356375.0 ], [ 2073375.0, 356375.0 ], [ 2073375.0, 356125.0 ], [ 2073625.0, 356125.0 ], [ 2073625.0, 356375.0 ], [ 2073875.0, 356375.0 ], [ 2073875.0, 356625.0 ], [ 2074125.0, 356625.0 ], [ 2074375.0, 356625.0 ], [ 2074625.0, 356625.0 ], [ 2074625.0, 356875.0 ], [ 2074375.0, 356875.0 ] ] ], [ [ [ 2072875.0, 357125.0 ], [ 2072625.0, 357125.0 ], [ 2072625.0, 357375.0 ], [ 2072875.0, 357375.0 ], [ 2073125.0, 357375.0 ], [ 2073125.0, 357125.0 ], [ 2072875.0, 357125.0 ] ] ], [ [ [ 2073625.0, 357625.0 ], [ 2073875.0, 357625.0 ], [ 2074125.0, 357625.0 ], [ 2074125.0, 357375.0 ], [ 2073875.0, 357375.0 ], [ 2073875.0, 357125.0 ], [ 2073625.0, 357125.0 ], [ 2073625.0, 357375.0 ], [ 2073625.0, 357625.0 ] ] ], [ [ [ 2076125.0, 358125.0 ], [ 2076375.0, 358125.0 ], [ 2076375.0, 357875.0 ], [ 2076125.0, 357875.0 ], [ 2076125.0, 357625.0 ], [ 2075875.0, 357625.0 ], [ 2075625.0, 357625.0 ], [ 2075625.0, 357875.0 ], [ 2075875.0, 357875.0 ], [ 2075875.0, 358125.0 ], [ 2076125.0, 358125.0 ] ] ], [ [ [ 2074875.0, 359375.0 ], [ 2075125.0, 359375.0 ], [ 2075375.0, 359375.0 ], [ 2075625.0, 359375.0 ], [ 2075625.0, 359125.0 ], [ 2075875.0, 359125.0 ], [ 2076125.0, 359125.0 ], [ 2076125.0, 359375.0 ], [ 2076375.0, 359375.0 ], [ 2076375.0, 359625.0 ], [ 2076625.0, 359625.0 ], [ 2076625.0, 359875.0 ], [ 2076875.0, 359875.0 ], [ 2077125.0, 359875.0 ], [ 2077125.0, 360125.0 ], [ 2077375.0, 360125.0 ], [ 2077375.0, 359875.0 ], [ 2077375.0, 359625.0 ], [ 2077375.0, 359375.0 ], [ 2077625.0, 359375.0 ], [ 2077625.0, 359625.0 ], [ 2077875.0, 359625.0 ], [ 2077875.0, 359375.0 ], [ 2078125.0, 359375.0 ], [ 2078375.0, 359375.0 ], [ 2078375.0, 359625.0 ], [ 2078625.0, 359625.0 ], [ 2078625.0, 359875.0 ], [ 2078875.0, 359875.0 ], [ 2078875.0, 360125.0 ], [ 2078875.0, 360375.0 ], [ 2079125.0, 360375.0 ], [ 2079375.0, 360375.0 ], [ 2079375.0, 360625.0 ], [ 2079125.0, 360625.0 ], [ 2078875.0, 360625.0 ], [ 2078875.0, 360875.0 ], [ 2079125.0, 360875.0 ], [ 2079375.0, 360875.0 ], [ 2079375.0, 361125.0 ], [ 2079625.0, 361125.0 ], [ 2079625.0, 361375.0 ], [ 2079875.0, 361375.0 ], [ 2079875.0, 361625.0 ], [ 2079625.0, 361625.0 ], [ 2079625.0, 361875.0 ], [ 2079875.0, 361875.0 ], [ 2079875.0, 362125.0 ], [ 2080125.0, 362125.0 ], [ 2080125.0, 361875.0 ], [ 2080125.0, 361625.0 ], [ 2080125.0, 361375.0 ], [ 2080375.0, 361375.0 ], [ 2080754.836753551848233, 361375.0 ], [ 2080686.3720232618507, 361125.0 ], [ 2080606.992742140078917, 360835.145352264982648 ], [ 2080505.02776063256897, 360744.972239367372822 ], [ 2080239.684800343587995, 360510.315199656412005 ], [ 2079974.341840054607019, 360275.658159945451189 ], [ 2079708.998879765626043, 360041.001120234432165 ], [ 2079443.655919476412237, 359806.344080523471348 ], [ 2079231.327361539937556, 359618.57052588602528 ], [ 2079184.910161321749911, 359565.089838678191882 ], [ 2078952.58692899858579, 359297.413071001356002 ], [ 2078720.26369667542167, 359029.736303324520122 ], [ 2078487.94046435225755, 358762.059535647684243 ], [ 2078255.617232029093429, 358494.382767970848363 ], [ 2078023.293999705929309, 358226.706000294012483 ], [ 2077790.970767382765189, 357959.029232617176604 ], [ 2077718.039735300000757, 357875.0 ], [ 2077509.406068820040673, 357634.617732099024579 ], [ 2077375.0, 357566.214643503539264 ], [ 2077248.277869393816218, 357501.722130606183782 ], [ 2077125.0, 357625.0 ], [ 2077125.0, 357875.0 ], [ 2077125.0, 358125.0 ], [ 2077125.0, 358375.0 ], [ 2077125.0, 358625.0 ], [ 2077375.0, 358625.0 ], [ 2077625.0, 358625.0 ], [ 2077625.0, 358875.0 ], [ 2077625.0, 359125.0 ], [ 2077375.0, 359125.0 ], [ 2077375.0, 358875.0 ], [ 2077125.0, 358875.0 ], [ 2077125.0, 359125.0 ], [ 2076875.0, 359125.0 ], [ 2076875.0, 359375.0 ], [ 2076625.0, 359375.0 ], [ 2076625.0, 359125.0 ], [ 2076625.0, 358875.0 ], [ 2076625.0, 358625.0 ], [ 2076625.0, 358375.0 ], [ 2076375.0, 358375.0 ], [ 2076375.0, 358625.0 ], [ 2076125.0, 358625.0 ], [ 2076125.0, 358875.0 ], [ 2075875.0, 358875.0 ], [ 2075875.0, 358625.0 ], [ 2075625.0, 358625.0 ], [ 2075625.0, 358875.0 ], [ 2075375.0, 358875.0 ], [ 2075375.0, 358625.0 ], [ 2075125.0, 358625.0 ], [ 2074875.0, 358625.0 ], [ 2074875.0, 358375.0 ], [ 2074875.0, 358125.0 ], [ 2074625.0, 358125.0 ], [ 2074625.0, 358375.0 ], [ 2074625.0, 358625.0 ], [ 2074625.0, 358875.0 ], [ 2074375.0, 358875.0 ], [ 2074375.0, 358625.0 ], [ 2074125.0, 358625.0 ], [ 2074125.0, 358875.0 ], [ 2074125.0, 359125.0 ], [ 2073875.0, 359125.0 ], [ 2073625.0, 359125.0 ], [ 2073625.0, 359375.0 ], [ 2073625.0, 359625.0 ], [ 2073875.0, 359625.0 ], [ 2073875.0, 359875.0 ], [ 2073875.0, 360125.0 ], [ 2074125.0, 360125.0 ], [ 2074375.0, 360125.0 ], [ 2074375.0, 359875.0 ], [ 2074625.0, 359875.0 ], [ 2074625.0, 359625.0 ], [ 2074875.0, 359625.0 ], [ 2074875.0, 359375.0 ] ] ], [ [ [ 2076125.0, 360375.0 ], [ 2075875.0, 360375.0 ], [ 2075875.0, 360625.0 ], [ 2076125.0, 360625.0 ], [ 2076125.0, 360375.0 ] ] ], [ [ [ 2077375.0, 360375.0 ], [ 2077375.0, 360625.0 ], [ 2077625.0, 360625.0 ], [ 2077625.0, 360375.0 ], [ 2077375.0, 360375.0 ] ] ], [ [ [ 2078125.0, 361375.0 ], [ 2078375.0, 361375.0 ], [ 2078375.0, 361125.0 ], [ 2078125.0, 361125.0 ], [ 2078125.0, 361375.0 ] ] ], [ [ [ 2074375.0, 361125.0 ], [ 2074625.0, 361125.0 ], [ 2074875.0, 361125.0 ], [ 2075125.0, 361125.0 ], [ 2075375.0, 361125.0 ], [ 2075375.0, 360875.0 ], [ 2075375.0, 360625.0 ], [ 2075125.0, 360625.0 ], [ 2074875.0, 360625.0 ], [ 2074625.0, 360625.0 ], [ 2074625.0, 360875.0 ], [ 2074375.0, 360875.0 ], [ 2074125.0, 360875.0 ], [ 2074125.0, 361125.0 ], [ 2074125.0, 361375.0 ], [ 2073875.0, 361375.0 ], [ 2073625.0, 361375.0 ], [ 2073625.0, 361625.0 ], [ 2073875.0, 361625.0 ], [ 2073875.0, 361875.0 ], [ 2073875.0, 362125.0 ], [ 2074125.0, 362125.0 ], [ 2074125.0, 361875.0 ], [ 2074375.0, 361875.0 ], [ 2074375.0, 361625.0 ], [ 2074375.0, 361375.0 ], [ 2074375.0, 361125.0 ] ] ], [ [ [ 2078125.0, 361375.0 ], [ 2077875.0, 361375.0 ], [ 2077875.0, 361625.0 ], [ 2078125.0, 361625.0 ], [ 2078125.0, 361375.0 ] ] ], [ [ [ 2080625.0, 361875.0 ], [ 2080625.0, 362125.0 ], [ 2080625.0, 362375.0 ], [ 2081028.695674711605534, 362375.0 ], [ 2080960.230944421608001, 362125.0 ], [ 2080891.766214131610468, 361875.0 ], [ 2080780.669894482009113, 361469.330105518107302 ], [ 2080625.0, 361625.0 ], [ 2080625.0, 361875.0 ] ] ], [ [ [ 2077625.0, 362125.0 ], [ 2077625.0, 361875.0 ], [ 2077375.0, 361875.0 ], [ 2077125.0, 361875.0 ], [ 2077125.0, 362125.0 ], [ 2077375.0, 362125.0 ], [ 2077625.0, 362125.0 ] ] ], [ [ [ 2074875.0, 362125.0 ], [ 2074875.0, 362375.0 ], [ 2075125.0, 362375.0 ], [ 2075125.0, 362125.0 ], [ 2074875.0, 362125.0 ] ] ], [ [ [ 2074625.0, 362875.0 ], [ 2074875.0, 362875.0 ], [ 2074875.0, 362625.0 ], [ 2074625.0, 362625.0 ], [ 2074625.0, 362875.0 ] ] ], [ [ [ 2080875.0, 362875.0 ], [ 2080875.0, 363125.0 ], [ 2081125.0, 363125.0 ], [ 2081210.637321189278737, 363039.362678810663056 ], [ 2081165.625135291367769, 362875.0 ], [ 2081049.399536174023524, 362450.600463825976476 ], [ 2080875.0, 362625.0 ], [ 2080875.0, 362875.0 ] ] ], [ [ [ 2079625.0, 362625.0 ], [ 2079625.0, 362375.0 ], [ 2079375.0, 362375.0 ], [ 2079375.0, 362625.0 ], [ 2079125.0, 362625.0 ], [ 2078875.0, 362625.0 ], [ 2078875.0, 362875.0 ], [ 2079125.0, 362875.0 ], [ 2079375.0, 362875.0 ], [ 2079375.0, 363125.0 ], [ 2079375.0, 363375.0 ], [ 2079625.0, 363375.0 ], [ 2079875.0, 363375.0 ], [ 2079875.0, 363125.0 ], [ 2079875.0, 362875.0 ], [ 2079875.0, 362625.0 ], [ 2079625.0, 362625.0 ] ] ], [ [ [ 2077625.0, 363875.0 ], [ 2077625.0, 364125.0 ], [ 2077875.0, 364125.0 ], [ 2077875.0, 363875.0 ], [ 2078125.0, 363875.0 ], [ 2078125.0, 363625.0 ], [ 2078375.0, 363625.0 ], [ 2078375.0, 363375.0 ], [ 2078125.0, 363375.0 ], [ 2077875.0, 363375.0 ], [ 2077625.0, 363375.0 ], [ 2077625.0, 363125.0 ], [ 2077625.0, 362875.0 ], [ 2077375.0, 362875.0 ], [ 2077125.0, 362875.0 ], [ 2077125.0, 362625.0 ], [ 2077375.0, 362625.0 ], [ 2077375.0, 362375.0 ], [ 2077125.0, 362375.0 ], [ 2077125.0, 362125.0 ], [ 2076875.0, 362125.0 ], [ 2076875.0, 362375.0 ], [ 2076875.0, 362625.0 ], [ 2076625.0, 362625.0 ], [ 2076375.0, 362625.0 ], [ 2076125.0, 362625.0 ], [ 2076125.0, 362875.0 ], [ 2075875.0, 362875.0 ], [ 2075875.0, 363125.0 ], [ 2076125.0, 363125.0 ], [ 2076375.0, 363125.0 ], [ 2076375.0, 363375.0 ], [ 2076625.0, 363375.0 ], [ 2076875.0, 363375.0 ], [ 2076875.0, 363625.0 ], [ 2077125.0, 363625.0 ], [ 2077125.0, 363875.0 ], [ 2077375.0, 363875.0 ], [ 2077625.0, 363875.0 ] ] ], [ [ [ 2080375.0, 363375.0 ], [ 2080125.0, 363375.0 ], [ 2080125.0, 363625.0 ], [ 2080375.0, 363625.0 ], [ 2080375.0, 363375.0 ] ] ], [ [ [ 2075875.0, 363875.0 ], [ 2075625.0, 363875.0 ], [ 2075625.0, 364125.0 ], [ 2075625.0, 364375.0 ], [ 2075875.0, 364375.0 ], [ 2075875.0, 364125.0 ], [ 2075875.0, 363875.0 ] ] ], [ [ [ 2081625.0, 364625.0 ], [ 2081875.0, 364625.0 ], [ 2081875.0, 364375.0 ], [ 2081625.0, 364375.0 ], [ 2081625.0, 364625.0 ] ] ], [ [ [ 2081625.0, 364875.0 ], [ 2081625.0, 364625.0 ], [ 2081375.0, 364625.0 ], [ 2081375.0, 364875.0 ], [ 2081375.0, 365125.0 ], [ 2081625.0, 365125.0 ], [ 2081625.0, 364875.0 ] ] ], [ [ [ 2073625.0, 364875.0 ], [ 2073375.0, 364875.0 ], [ 2073375.0, 365125.0 ], [ 2073625.0, 365125.0 ], [ 2073625.0, 364875.0 ] ] ], [ [ [ 2083875.0, 365375.0 ], [ 2084125.0, 365375.0 ], [ 2084237.027790324995294, 365262.972209675121121 ], [ 2083947.204781475709751, 365052.795218524290249 ], [ 2083625.0, 364819.135262491530739 ], [ 2083625.0, 365125.0 ], [ 2083625.0, 365375.0 ], [ 2083875.0, 365375.0 ] ] ], [ [ [ 2073875.0, 365125.0 ], [ 2073625.0, 365125.0 ], [ 2073625.0, 365375.0 ], [ 2073875.0, 365375.0 ], [ 2073875.0, 365125.0 ] ] ], [ [ [ 2080375.0, 365625.0 ], [ 2080625.0, 365625.0 ], [ 2080625.0, 365375.0 ], [ 2080375.0, 365375.0 ], [ 2080375.0, 365625.0 ] ] ], [ [ [ 2081125.0, 365625.0 ], [ 2081125.0, 365875.0 ], [ 2081375.0, 365875.0 ], [ 2081375.0, 365625.0 ], [ 2081125.0, 365625.0 ] ] ], [ [ [ 2077625.0, 366125.0 ], [ 2077625.0, 365875.0 ], [ 2077375.0, 365875.0 ], [ 2077125.0, 365875.0 ], [ 2077125.0, 366125.0 ], [ 2077375.0, 366125.0 ], [ 2077625.0, 366125.0 ] ] ], [ [ [ 2074625.0, 365875.0 ], [ 2074375.0, 365875.0 ], [ 2074375.0, 366125.0 ], [ 2074625.0, 366125.0 ], [ 2074625.0, 365875.0 ] ] ], [ [ [ 2080875.0, 365875.0 ], [ 2080875.0, 366125.0 ], [ 2081125.0, 366125.0 ], [ 2081125.0, 365875.0 ], [ 2080875.0, 365875.0 ] ] ], [ [ [ 2073875.0, 366125.0 ], [ 2073625.0, 366125.0 ], [ 2073625.0, 366375.0 ], [ 2073625.0, 366625.0 ], [ 2073875.0, 366625.0 ], [ 2074125.0, 366625.0 ], [ 2074125.0, 366375.0 ], [ 2074125.0, 366125.0 ], [ 2073875.0, 366125.0 ] ] ], [ [ [ 2082625.0, 366875.0 ], [ 2082875.0, 366875.0 ], [ 2082875.0, 366625.0 ], [ 2082625.0, 366625.0 ], [ 2082625.0, 366875.0 ] ] ], [ [ [ 2075125.0, 367125.0 ], [ 2075125.0, 367375.0 ], [ 2075375.0, 367375.0 ], [ 2075375.0, 367125.0 ], [ 2075625.0, 367125.0 ], [ 2075625.0, 366875.0 ], [ 2075375.0, 366875.0 ], [ 2075125.0, 366875.0 ], [ 2074875.0, 366875.0 ], [ 2074875.0, 367125.0 ], [ 2075125.0, 367125.0 ] ] ], [ [ [ 2075375.0, 367375.0 ], [ 2075375.0, 367625.0 ], [ 2075625.0, 367625.0 ], [ 2075625.0, 367375.0 ], [ 2075375.0, 367375.0 ] ] ], [ [ [ 2083625.0, 367375.0 ], [ 2083375.0, 367375.0 ], [ 2083375.0, 367625.0 ], [ 2083625.0, 367625.0 ], [ 2083625.0, 367875.0 ], [ 2083875.0, 367875.0 ], [ 2083875.0, 368125.0 ], [ 2084125.0, 368125.0 ], [ 2084125.0, 367875.0 ], [ 2084348.716473254840821, 367875.0 ], [ 2084355.473230011295527, 367625.0 ], [ 2084362.229986767983064, 367375.0 ], [ 2084368.98674352443777, 367125.0 ], [ 2084125.0, 367125.0 ], [ 2083875.0, 367125.0 ], [ 2083875.0, 367375.0 ], [ 2083625.0, 367375.0 ] ] ], [ [ [ 2075875.0, 367625.0 ], [ 2075625.0, 367625.0 ], [ 2075625.0, 367875.0 ], [ 2075875.0, 367875.0 ], [ 2075875.0, 367625.0 ] ] ], [ [ [ 2076125.0, 367375.0 ], [ 2076125.0, 367625.0 ], [ 2076125.0, 367875.0 ], [ 2076125.0, 368125.0 ], [ 2076375.0, 368125.0 ], [ 2076375.0, 367875.0 ], [ 2076375.0, 367625.0 ], [ 2076375.0, 367375.0 ], [ 2076125.0, 367375.0 ] ] ], [ [ [ 2073125.0, 367375.0 ], [ 2073125.0, 367625.0 ], [ 2073125.0, 367875.0 ], [ 2073125.0, 368125.0 ], [ 2073375.0, 368125.0 ], [ 2073375.0, 368375.0 ], [ 2073625.0, 368375.0 ], [ 2073625.0, 368125.0 ], [ 2073625.0, 367875.0 ], [ 2073625.0, 367625.0 ], [ 2073875.0, 367625.0 ], [ 2073875.0, 367375.0 ], [ 2073625.0, 367375.0 ], [ 2073375.0, 367375.0 ], [ 2073125.0, 367375.0 ] ] ], [ [ [ 2074375.0, 368375.0 ], [ 2074375.0, 368125.0 ], [ 2074125.0, 368125.0 ], [ 2074125.0, 368375.0 ], [ 2074375.0, 368375.0 ] ] ], [ [ [ 2077125.0, 368375.0 ], [ 2076875.0, 368375.0 ], [ 2076875.0, 368625.0 ], [ 2077125.0, 368625.0 ], [ 2077125.0, 368375.0 ] ] ], [ [ [ 2083875.0, 368625.0 ], [ 2084125.0, 368625.0 ], [ 2084125.0, 368375.0 ], [ 2083875.0, 368375.0 ], [ 2083875.0, 368625.0 ] ] ], [ [ [ 2079125.0, 368625.0 ], [ 2079125.0, 368375.0 ], [ 2078875.0, 368375.0 ], [ 2078875.0, 368625.0 ], [ 2078875.0, 368875.0 ], [ 2079125.0, 368875.0 ], [ 2079125.0, 368625.0 ] ] ], [ [ [ 2083375.0, 368875.0 ], [ 2083625.0, 368875.0 ], [ 2083625.0, 368625.0 ], [ 2083375.0, 368625.0 ], [ 2083125.0, 368625.0 ], [ 2083125.0, 368375.0 ], [ 2083125.0, 368125.0 ], [ 2083125.0, 367875.0 ], [ 2082875.0, 367875.0 ], [ 2082625.0, 367875.0 ], [ 2082625.0, 368125.0 ], [ 2082375.0, 368125.0 ], [ 2082375.0, 367875.0 ], [ 2082125.0, 367875.0 ], [ 2082125.0, 368125.0 ], [ 2082125.0, 368375.0 ], [ 2082125.0, 368625.0 ], [ 2082375.0, 368625.0 ], [ 2082625.0, 368625.0 ], [ 2082625.0, 368875.0 ], [ 2082625.0, 369125.0 ], [ 2082875.0, 369125.0 ], [ 2082875.0, 369375.0 ], [ 2083125.0, 369375.0 ], [ 2083125.0, 369125.0 ], [ 2083125.0, 368875.0 ], [ 2083375.0, 368875.0 ] ] ], [ [ [ 2084125.0, 368875.0 ], [ 2084375.0, 368875.0 ], [ 2084498.74964591441676, 368751.250354085525032 ], [ 2084464.899913297733292, 368625.0 ], [ 2084125.0, 368625.0 ], [ 2084125.0, 368875.0 ] ] ], [ [ [ 2076375.0, 369125.0 ], [ 2076375.0, 369375.0 ], [ 2076625.0, 369375.0 ], [ 2076625.0, 369125.0 ], [ 2076625.0, 368875.0 ], [ 2076375.0, 368875.0 ], [ 2076375.0, 369125.0 ] ] ], [ [ [ 2081125.0, 369375.0 ], [ 2080875.0, 369375.0 ], [ 2080875.0, 369625.0 ], [ 2080875.0, 369875.0 ], [ 2081125.0, 369875.0 ], [ 2081125.0, 369625.0 ], [ 2081125.0, 369375.0 ] ] ], [ [ [ 2080288.811633700039238, 370324.428998021001462 ], [ 2080625.0, 370457.010325575945899 ], [ 2080625.0, 370125.0 ], [ 2080625.0, 369875.0 ], [ 2080375.0, 369875.0 ], [ 2080375.0, 370125.0 ], [ 2080228.359867894090712, 370271.640132105909288 ], [ 2080288.811633700039238, 370324.428998021001462 ] ] ], [ [ [ 2084375.0, 370375.0 ], [ 2084375.0, 370625.0 ], [ 2084744.536088891560212, 370625.0 ], [ 2084790.138491299934685, 370474.161284343979787 ], [ 2084780.131389210000634, 370375.0 ], [ 2084375.0, 370375.0 ] ] ], [ [ [ 2081625.0, 370375.0 ], [ 2081625.0, 370653.635633661004249 ], [ 2081875.0, 370678.635633661004249 ], [ 2081875.0, 370375.0 ], [ 2081625.0, 370375.0 ] ] ], [ [ [ 2082375.0, 370728.635633660946041 ], [ 2082375.0, 370375.0 ], [ 2082125.0, 370375.0 ], [ 2082125.0, 370703.635633661004249 ], [ 2082375.0, 370728.635633660946041 ] ] ] ] } },
{ "type": "Feature", "properties": { "classification": "fluvial", "mesh_name": "BaldEagleCr", "cell_id": 63, "area_acres": 99601.164563350947 }, "geometry": { "type": "MultiPolygon", "coordinates": [ [ [ [ 1981875.0, 300125.0 ], [ 1981875.0, 300375.0 ], [ 1982125.0, 300375.0 ], [ 1982125.0, 300625.0 ], [ 1982375.0, 300625.0 ], [ 1982375.0, 300875.0 ], [ 1982625.0, 300875.0 ], [ 1982625.0, 301125.0 ], [ 1982625.0, 301375.0 ], [ 1982875.0, 301375.0 ], [ 1983125.0, 301375.0 ], [ 1983125.0, 301625.0 ], [ 1983375.0, 301625.0 ], [ 1983375.0, 301875.0 ], [ 1983625.0, 301875.0 ], [ 1983625.0, 302125.0 ], [ 1983875.0, 302125.0 ], [ 1983875.0, 302375.0 ], [ 1983875.0, 302625.0 ], [ 1984125.0, 302625.0 ], [ 1984375.0, 302625.0 ], [ 1984375.0, 302875.0 ], [ 1984625.0, 302875.0 ], [ 1984625.0, 303125.0 ], [ 1984375.0, 303125.0 ], [ 1984125.0, 303125.0 ], [ 1983875.0, 303125.0 ], [ 1983875.0, 302875.0 ], [ 1983625.0, 302875.0 ], [ 1983375.0, 302875.0 ], [ 1983375.0, 302625.0 ], [ 1983125.0, 302625.0 ], [ 1983125.0, 302375.0 ], [ 1982875.0, 302375.0 ], [ 1982625.0, 302375.0 ], [ 1982375.0, 302375.0 ], [ 1982375.0, 302625.0 ], [ 1982625.0, 302625.0 ], [ 1982625.0, 302875.0 ], [ 1982875.0, 302875.0 ], [ 1982875.0, 303125.0 ], [ 1983125.0, 303125.0 ], [ 1983375.0, 303125.0 ], [ 1983375.0, 303375.0 ], [ 1983625.0, 303375.0 ], [ 1983625.0, 303625.0 ], [ 1983875.0, 303625.0 ], [ 1983875.0, 303875.0 ], [ 1983875.0, 304125.0 ], [ 1983875.0, 304375.0 ], [ 1984125.0, 304375.0 ], [ 1984125.0, 304625.0 ], [ 1984375.0, 304625.0 ], [ 1984375.0, 304875.0 ], [ 1984625.0, 304875.0 ], [ 1984625.0, 305125.0 ], [ 1984875.0, 305125.0 ], [ 1985125.0, 305125.0 ], [ 1985375.0, 305125.0 ], [ 1985375.0, 305375.0 ], [ 1985125.0, 305375.0 ], [ 1985125.0, 305625.0 ], [ 1984875.0, 305625.0 ], [ 1984875.0, 305875.0 ], [ 1984875.0, 306125.0 ], [ 1985125.0, 306125.0 ], [ 1985375.0, 306125.0 ], [ 1985375.0, 305875.0 ], [ 1985625.0, 305875.0 ], [ 1985875.0, 305875.0 ], [ 1986125.0, 305875.0 ], [ 1986125.0, 306125.0 ], [ 1986125.0, 306375.0 ], [ 1986375.0, 306375.0 ], [ 1986375.0, 306625.0 ], [ 1986625.0, 306625.0 ], [ 1986625.0, 306875.0 ], [ 1986875.0, 306875.0 ], [ 1986875.0, 306625.0 ], [ 1986875.0, 306375.0 ], [ 1986625.0, 306375.0 ], [ 1986625.0, 306125.0 ], [ 1986875.0, 306125.0 ], [ 1987125.0, 306125.0 ], [ 1987125.0, 305875.0 ], [ 1987375.0, 305875.0 ], [ 1987375.0, 305625.0 ], [ 1987375.0, 305375.0 ], [ 1987625.0, 305375.0 ], [ 1987625.0, 305625.0 ], [ 1987875.0, 305625.0 ], [ 1987875.0, 305875.0 ], [ 1988125.0, 305875.0 ], [ 1988125.0, 306125.0 ], [ 1988125.0, 306375.0 ], [ 1987875.0, 306375.0 ], [ 1987875.0, 306625.0 ], [ 1987875.0, 306875.0 ], [ 1987625.0, 306875.0 ], [ 1987625.0, 307125.0 ], [ 1987875.0, 307125.0 ], [ 1988125.0, 307125.0 ], [ 1988375.0, 307125.0 ], [ 1988375.0, 306875.0 ], [ 1988625.0, 306875.0 ], [ 1988875.0, 306875.0 ], [ 1988875.0, 307125.0 ], [ 1989125.0, 307125.0 ], [ 1989125.0, 307375.0 ], [ 1989375.0, 307375.0 ], [ 1989375.0, 307625.0 ], [ 1989625.0, 307625.0 ], [ 1989625.0, 307875.0 ], [ 1989375.0, 307875.0 ], [ 1989125.0, 307875.0 ], [ 1988875.0, 307875.0 ], [ 1988625.0, 307875.0 ], [ 1988375.0, 307875.0 ], [ 1988125.0, 307875.0 ], [ 1987875.0, 307875.0 ], [ 1987875.0, 308125.0 ], [ 1987875.0, 308375.0 ], [ 1987875.0, 308625.0 ], [ 1988125.0, 308625.0 ], [ 1988125.0, 308875.0 ], [ 1987875.0, 308875.0 ], [ 1987875.0, 309125.0 ], [ 1988125.0, 309125.0 ], [ 1988375.0, 309125.0 ], [ 1988375.0, 309375.0 ], [ 1988625.0, 309375.0 ], [ 1988875.0, 309375.0 ], [ 1989125.0, 309375.0 ], [ 1989125.0, 309625.0 ], [ 1989125.0, 309875.0 ], [ 1989375.0, 309875.0 ], [ 1989375.0, 310125.0 ], [ 1989625.0, 310125.0 ], [ 1989625.0, 310375.0 ], [ 1989875.0, 310375.0 ], [ 1989875.0, 310625.0 ], [ 1989875.0, 310875.0 ], [ 1990125.0, 310875.0 ], [ 1990125.0, 311125.0 ], [ 1990375.0, 311125.0 ], [ 1990375.0, 311375.0 ], [ 1990125.0, 311375.0 ], [ 1990125.0, 311625.0 ], [ 1989875.0, 311625.0 ], [ 1989625.0, 311625.0 ], [ 1989472.232882233802229, 311777.767117766314186 ], [ 1989551.787058606510982, 311875.0 ], [ 1989809.732882233336568, 312190.267117766605224 ], [ 1990034.732882233103737, 312465.267117766779847 ], [ 1990259.732882233103737, 312740.267117767012678 ], [ 1990307.077053480083123, 312798.132215957972221 ], [ 1990545.596453194972128, 312954.40354680508608 ], [ 1990875.0, 313170.219663676631171 ], [ 1990998.721453195437789, 313251.278546804445796 ], [ 1991276.169096539961174, 313433.054588995000813 ], [ 1991288.911694810260087, 313461.088305189681705 ], [ 1991363.417010633274913, 313625.0 ], [ 1991625.0, 313625.0 ], [ 1991875.0, 313625.0 ], [ 1991875.0, 313875.0 ], [ 1991625.0, 313875.0 ], [ 1991523.286694810492918, 313976.713305189507082 ], [ 1991590.68973790621385, 314125.0 ], [ 1991757.661694810725749, 314492.338305189332459 ], [ 1991777.423601570073515, 314535.814500059990678 ], [ 1992125.0, 314700.455951947369613 ], [ 1992243.440604035742581, 314756.559395964199211 ], [ 1992375.0, 314625.0 ], [ 1992625.0, 314625.0 ], [ 1992625.0, 314375.0 ], [ 1992625.0, 314125.0 ], [ 1992875.0, 314125.0 ], [ 1993125.0, 314125.0 ], [ 1993125.0, 313875.0 ], [ 1993375.0, 313875.0 ], [ 1993375.0, 314125.0 ], [ 1993625.0, 314125.0 ], [ 1993625.0, 314375.0 ], [ 1993625.0, 314625.0 ], [ 1993875.0, 314625.0 ], [ 1993875.0, 314375.0 ], [ 1994125.0, 314375.0 ], [ 1994125.0, 314625.0 ], [ 1994125.0, 314875.0 ], [ 1994375.0, 314875.0 ], [ 1994375.0, 315125.0 ], [ 1994625.0, 315125.0 ], [ 1994875.0, 315125.0 ], [ 1994875.0, 315375.0 ], [ 1994875.0, 315625.0 ], [ 1994875.0, 315875.0 ], [ 1995125.0, 315875.0 ], [ 1995375.0, 315875.0 ], [ 1995625.0, 315875.0 ], [ 1995625.0, 316125.0 ], [ 1995875.0, 316125.0 ], [ 1995875.0, 316375.0 ], [ 1995875.0, 316625.0 ], [ 1995875.0, 316875.0 ], [ 1996125.0, 316875.0 ], [ 1996375.0, 316875.0 ], [ 1996625.0, 316875.0 ], [ 1996875.0, 316875.0 ], [ 1996875.0, 317125.0 ], [ 1997125.0, 317125.0 ], [ 1997375.0, 317125.0 ], [ 1997375.0, 316875.0 ], [ 1997625.0, 316875.0 ], [ 1997625.0, 317125.0 ], [ 1997875.0, 317125.0 ], [ 1997875.0, 317375.0 ], [ 1997625.0, 317375.0 ], [ 1997625.0, 317625.0 ], [ 1997625.0, 317875.0 ], [ 1997375.0, 317875.0 ], [ 1997375.0, 318125.0 ], [ 1997375.0, 318375.0 ], [ 1997625.0, 318375.0 ], [ 1997875.0, 318375.0 ], [ 1997875.0, 318625.0 ], [ 1997875.0, 318875.0 ], [ 1998125.0, 318875.0 ], [ 1998125.0, 319125.0 ], [ 1998375.0, 319125.0 ], [ 1998375.0, 319375.0 ], [ 1998125.0, 319375.0 ], [ 1998125.0, 319625.0 ], [ 1998125.0, 319875.0 ], [ 1998375.0, 319875.0 ], [ 1998625.0, 319875.0 ], [ 1998875.0, 319875.0 ], [ 1998875.0, 320125.0 ], [ 1999125.0, 320125.0 ], [ 1999375.0, 320125.0 ], [ 1999375.0, 320375.0 ], [ 1999125.0, 320375.0 ], [ 1998875.0, 320375.0 ], [ 1998625.0, 320375.0 ], [ 1998625.0, 320625.0 ], [ 1998480.176777553744614, 320769.823222446255386 ], [ 1998494.233968959888443, 320784.787329427024815 ], [ 1998787.831081654177979, 320962.168918345822021 ], [ 1999125.0, 321165.875139845709782 ], [ 1999255.363549187313765, 321244.636450812686235 ], [ 1999625.0, 321467.958473177917767 ], [ 1999722.896016720449552, 321527.103983279608656 ], [ 2000034.584328409051523, 321715.415671590832062 ], [ 2000098.248385060112923, 321753.879372483992483 ], [ 2000313.718596992781386, 321936.28140300733503 ], [ 2000625.0, 322199.790495347464457 ], [ 2000719.88580773328431, 322280.11419226671569 ], [ 2000875.0, 322125.0 ], [ 2001125.0, 322125.0 ], [ 2001375.0, 322125.0 ], [ 2001375.0, 322375.0 ], [ 2001625.0, 322375.0 ], [ 2001875.0, 322375.0 ], [ 2001875.0, 322625.0 ], [ 2002125.0, 322625.0 ], [ 2002125.0, 322875.0 ], [ 2002375.0, 322875.0 ], [ 2002625.0, 322875.0 ], [ 2002625.0, 323109.507223077933304 ], [ 2002853.736919600982219, 323091.999806937295943 ], [ 2002947.325, 323247.302000000025146 ], [ 2002991.896173857152462, 323380.988579147902783 ], [ 2003125.0, 323449.735253088292666 ], [ 2003125.0, 323625.0 ], [ 2003375.0, 323625.0 ], [ 2003625.0, 323625.0 ], [ 2003875.0, 323625.0 ], [ 2004125.0, 323625.0 ], [ 2004125.0, 323875.0 ], [ 2004375.0, 323875.0 ], [ 2004375.0, 324125.0 ], [ 2004625.0, 324125.0 ], [ 2004875.0, 324125.0 ], [ 2005125.0, 324125.0 ], [ 2005125.0, 324375.0 ], [ 2005125.0, 324625.0 ], [ 2005125.0, 324875.0 ], [ 2004875.0, 324875.0 ], [ 2004875.0, 325125.0 ], [ 2004625.0, 325125.0 ], [ 2004625.0, 325375.0 ], [ 2004875.0, 325375.0 ], [ 2004875.0, 325625.0 ], [ 2004875.0, 325875.0 ], [ 2005125.0, 325875.0 ], [ 2005125.0, 326125.0 ], [ 2005125.0, 326375.0 ], [ 2005375.0, 326375.0 ], [ 2005625.0, 326375.0 ], [ 2005625.0, 326125.0 ], [ 2005875.0, 326125.0 ], [ 2006125.0, 326125.0 ], [ 2006375.0, 326125.0 ], [ 2006625.0, 326125.0 ], [ 2006625.0, 326375.0 ], [ 2006875.0, 326375.0 ], [ 2007125.0, 326375.0 ], [ 2007375.0, 326375.0 ], [ 2007625.0, 326375.0 ], [ 2007875.0, 326375.0 ], [ 2008125.0, 326375.0 ], [ 2008375.0, 326375.0 ], [ 2008375.0, 326125.0 ], [ 2008625.0, 326125.0 ], [ 2008875.0, 326125.0 ], [ 2008875.0, 325875.0 ], [ 2009125.0, 325875.0 ], [ 2009375.0, 325875.0 ], [ 2009625.0, 325875.0 ], [ 2009625.0, 326125.0 ], [ 2009875.0, 326125.0 ], [ 2010125.0, 326125.0 ], [ 2010125.0, 325875.0 ], [ 2010375.0, 325875.0 ], [ 2010375.0, 326125.0 ], [ 2010625.0, 326125.0 ], [ 2010875.0, 326125.0 ], [ 2011125.0, 326125.0 ], [ 2011125.0, 326375.0 ], [ 2011375.0, 326375.0 ], [ 2011375.0, 326625.0 ], [ 2011625.0, 326625.0 ], [ 2011875.0, 326625.0 ], [ 2011875.0, 326875.0 ], [ 2012125.0, 326875.0 ], [ 2012125.0, 327125.0 ], [ 2012375.0, 327125.0 ], [ 2012375.0, 327375.0 ], [ 2012625.0, 327375.0 ], [ 2012875.0, 327375.0 ], [ 2013125.0, 327375.0 ], [ 2013375.0, 327375.0 ], [ 2013625.0, 327375.0 ], [ 2013875.0, 327375.0 ], [ 2014125.0, 327375.0 ], [ 2014125.0, 327125.0 ], [ 2014375.0, 327125.0 ], [ 2014625.0, 327125.0 ], [ 2014625.0, 326875.0 ], [ 2014875.0, 326875.0 ], [ 2015125.0, 326875.0 ], [ 2015375.0, 326875.0 ], [ 2015625.0, 326875.0 ], [ 2015625.0, 326625.0 ], [ 2015875.0, 326625.0 ], [ 2015875.0, 326375.0 ], [ 2016125.0, 326375.0 ], [ 2016375.0, 326375.0 ], [ 2016625.0, 326375.0 ], [ 2016875.0, 326375.0 ], [ 2016875.0, 326625.0 ], [ 2016625.0, 326625.0 ], [ 2016625.0, 326875.0 ], [ 2016375.0, 326875.0 ], [ 2016125.0, 326875.0 ], [ 2015875.0, 326875.0 ], [ 2015875.0, 327125.0 ], [ 2015875.0, 327375.0 ], [ 2015875.0, 327625.0 ], [ 2015625.0, 327625.0 ], [ 2015625.0, 327875.0 ], [ 2015875.0, 327875.0 ], [ 2016125.0, 327875.0 ], [ 2016375.0, 327875.0 ], [ 2016375.0, 328125.0 ], [ 2016375.0, 328375.0 ], [ 2016125.0, 328375.0 ], [ 2016125.0, 328125.0 ], [ 2015875.0, 328125.0 ], [ 2015625.0, 328125.0 ], [ 2015375.0, 328125.0 ], [ 2015125.0, 328125.0 ], [ 2015125.0, 328375.0 ], [ 2015375.0, 328375.0 ], [ 2015375.0, 328625.0 ], [ 2015625.0, 328625.0 ], [ 2015875.0, 328625.0 ], [ 2015875.0, 328875.0 ], [ 2016125.0, 328875.0 ], [ 2016125.0, 329125.0 ], [ 2016125.0, 329375.0 ], [ 2016125.0, 329625.0 ], [ 2016375.0, 329625.0 ], [ 2016625.0, 329625.0 ], [ 2016625.0, 329375.0 ], [ 2016875.0, 329375.0 ], [ 2017125.0, 329375.0 ], [ 2017125.0, 329125.0 ], [ 2017375.0, 329125.0 ], [ 2017625.0, 329125.0 ], [ 2017625.0, 328875.0 ], [ 2017875.0, 328875.0 ], [ 2017875.0, 328625.0 ], [ 2017875.0, 328375.0 ], [ 2018125.0, 328375.0 ], [ 2018125.0, 328125.0 ], [ 2018375.0, 328125.0 ], [ 2018375.0, 328375.0 ], [ 2018375.0, 328625.0 ], [ 2018125.0, 328625.0 ], [ 2018125.0, 328875.0 ], [ 2018375.0, 328875.0 ], [ 2018375.0, 329125.0 ], [ 2018375.0, 329375.0 ], [ 2018375.0, 329625.0 ], [ 2018625.0, 329625.0 ], [ 2018625.0, 329875.0 ], [ 2018875.0, 329875.0 ], [ 2018875.0, 330125.0 ], [ 2018875.0, 330375.0 ], [ 2019125.0, 330375.0 ], [ 2019125.0, 330625.0 ], [ 2019375.0, 330625.0 ], [ 2019375.0, 330875.0 ], [ 2019375.0, 331125.0 ], [ 2019625.0, 331125.0 ], [ 2019875.0, 331125.0 ], [ 2019875.0, 331375.0 ], [ 2019875.0, 331625.0 ], [ 2019875.0, 331875.0 ], [ 2020125.0, 331875.0 ], [ 2020375.0, 331875.0 ], [ 2020375.0, 332125.0 ], [ 2020625.0, 332125.0 ], [ 2020625.0, 332375.0 ], [ 2020875.0, 332375.0 ], [ 2020875.0, 332625.0 ], [ 2021125.0, 332625.0 ], [ 2021125.0, 332875.0 ], [ 2021375.0, 332875.0 ], [ 2021625.0, 332875.0 ], [ 2021625.0, 333125.0 ], [ 2021875.0, 333125.0 ], [ 2021875.0, 333375.0 ], [ 2022125.0, 333375.0 ], [ 2022375.0, 333375.0 ], [ 2022375.0, 333625.0 ], [ 2022625.0, 333625.0 ], [ 2022625.0, 333875.0 ], [ 2022875.0, 333875.0 ], [ 2022875.0, 334125.0 ], [ 2023125.0, 334125.0 ], [ 2023125.0, 334375.0 ], [ 2023375.0, 334375.0 ], [ 2023625.0, 334375.0 ], [ 2023625.0, 334625.0 ], [ 2023625.0, 334875.0 ], [ 2023875.0, 334875.0 ], [ 2024125.0, 334875.0 ], [ 2024125.0, 334625.0 ], [ 2024375.0, 334625.0 ], [ 2024625.0, 334625.0 ], [ 2024875.0, 334625.0 ], [ 2024875.0, 334875.0 ], [ 2025125.0, 334875.0 ], [ 2025125.0, 335125.0 ], [ 2025375.0, 335125.0 ], [ 2025625.0, 335125.0 ], [ 2025625.0, 335375.0 ], [ 2025875.0, 335375.0 ], [ 2026125.0, 335375.0 ], [ 2026125.0, 335625.0 ], [ 2026375.0, 335625.0 ], [ 2026625.0, 335625.0 ], [ 2026875.0, 335625.0 ], [ 2026875.0, 335875.0 ], [ 2027125.0, 335875.0 ], [ 2027125.0, 336125.0 ], [ 2027375.0, 336125.0 ], [ 2027625.0, 336125.0 ], [ 2027625.0, 336375.0 ], [ 2027625.0, 336625.0 ], [ 2027875.0, 336625.0 ], [ 2027875.0, 336375.0 ], [ 2028125.0, 336375.0 ], [ 2028375.0, 336375.0 ], [ 2028375.0, 336625.0 ], [ 2028625.0, 336625.0 ], [ 2028875.0, 336625.0 ], [ 2028875.0, 336875.0 ], [ 2029125.0, 336875.0 ], [ 2029375.0, 336875.0 ], [ 2029375.0, 337125.0 ], [ 2029625.0, 337125.0 ], [ 2029625.0, 337375.0 ], [ 2029875.0, 337375.0 ], [ 2030125.0, 337375.0 ], [ 2030125.0, 337625.0 ], [ 2030125.0, 337875.0 ], [ 2030375.0, 337875.0 ], [ 2030625.0, 337875.0 ], [ 2030625.0, 338125.0 ], [ 2030625.0, 338375.0 ], [ 2030625.0, 338625.0 ], [ 2030875.0, 338625.0 ], [ 2031125.0, 338625.0 ], [ 2031125.0, 338375.0 ], [ 2031125.0, 338125.0 ], [ 2031375.0, 338125.0 ], [ 2031375.0, 338375.0 ], [ 2031625.0, 338375.0 ], [ 2031875.0, 338375.0 ], [ 2031875.0, 338625.0 ], [ 2031625.0, 338625.0 ], [ 2031625.0, 338875.0 ], [ 2031875.0, 338875.0 ], [ 2031875.0, 339125.0 ], [ 2032125.0, 339125.0 ], [ 2032125.0, 338875.0 ], [ 2032125.0, 338625.0 ], [ 2032375.0, 338625.0 ], [ 2032375.0, 338875.0 ], [ 2032625.0, 338875.0 ], [ 2032875.0, 338875.0 ], [ 2033125.0, 338875.0 ], [ 2033125.0, 339125.0 ], [ 2033375.0, 339125.0 ], [ 2033375.0, 339375.0 ], [ 2033625.0, 339375.0 ], [ 2033625.0, 339625.0 ], [ 2033875.0, 339625.0 ], [ 2033875.0, 339875.0 ], [ 2034125.0, 339875.0 ], [ 2034125.0, 340125.0 ], [ 2034375.0, 340125.0 ], [ 2034375.0, 340375.0 ], [ 2034625.0, 340375.0 ], [ 2034625.0, 340625.0 ], [ 2034625.0, 340875.0 ], [ 2034875.0, 340875.0 ], [ 2034875.0, 341125.0 ], [ 2034875.0, 341375.0 ], [ 2035125.0, 341375.0 ], [ 2035125.0, 341625.0 ], [ 2035375.0, 341625.0 ], [ 2035375.0, 341875.0 ], [ 2035625.0, 341875.0 ], [ 2035625.0, 342125.0 ], [ 2035625.0, 342375.0 ], [ 2035875.0, 342375.0 ], [ 2035875.0, 342625.0 ], [ 2035875.0, 342875.0 ], [ 2035875.0, 343125.0 ], [ 2035875.0, 343375.0 ], [ 2036125.0, 343375.0 ], [ 2036125.0, 343625.0 ], [ 2036125.0, 343875.0 ], [ 2036125.0, 344125.0 ], [ 2036125.0, 344375.0 ], [ 2036125.0, 344625.0 ], [ 2036125.0, 344875.0 ], [ 2035875.0, 344875.0 ], [ 2035875.0, 345125.0 ], [ 2036125.0, 345125.0 ], [ 2036125.0, 345375.0 ], [ 2036125.0, 345625.0 ], [ 2036375.0, 345625.0 ], [ 2036375.0, 345875.0 ], [ 2036625.0, 345875.0 ], [ 2036625.0, 346125.0 ], [ 2036375.0, 346125.0 ], [ 2036375.0, 346375.0 ], [ 2036375.0, 346625.0 ], [ 2036375.0, 346875.0 ], [ 2036625.0, 346875.0 ], [ 2036625.0, 347125.0 ], [ 2036375.0, 347125.0 ], [ 2036375.0, 347375.0 ], [ 2036375.0, 347625.0 ], [ 2036625.0, 347625.0 ], [ 2036625.0, 347875.0 ], [ 2036625.0, 348125.0 ], [ 2036625.0, 348375.0 ], [ 2036625.0, 348625.0 ], [ 2036625.0, 348875.0 ], [ 2036875.0, 348875.0 ], [ 2037125.0, 348875.0 ], [ 2037375.0, 348875.0 ], [ 2037625.0, 348875.0 ], [ 2037625.0, 348625.0 ], [ 2037875.0, 348625.0 ], [ 2038125.0, 348625.0 ], [ 2038125.0, 348875.0 ], [ 2038375.0, 348875.0 ], [ 2038375.0, 349125.0 ], [ 2038625.0, 349125.0 ], [ 2038875.0, 349125.0 ], [ 2038875.0, 349375.0 ], [ 2039125.0, 349375.0 ], [ 2039375.0, 349375.0 ], [ 2039375.0, 349625.0 ], [ 2039625.0, 349625.0 ], [ 2039875.0, 349625.0 ], [ 2040125.0, 349625.0 ], [ 2040375.0, 349625.0 ], [ 2040625.0, 349625.0 ], [ 2040875.0, 349625.0 ], [ 2040875.0, 349875.0 ], [ 2041125.0, 349875.0 ], [ 2041375.0, 349875.0 ], [ 2041625.0, 349875.0 ], [ 2041625.0, 349625.0 ], [ 2041875.0, 349625.0 ], [ 2041875.0, 349875.0 ], [ 2042125.0, 349875.0 ], [ 2042375.0, 349875.0 ], [ 2042625.0, 349875.0 ], [ 2042875.0, 349875.0 ], [ 2043125.0, 349875.0 ], [ 2043375.0, 349875.0 ], [ 2043625.0, 349875.0 ], [ 2043625.0, 349625.0 ], [ 2043875.0, 349625.0 ], [ 2043875.0, 349375.0 ], [ 2044125.0, 349375.0 ], [ 2044125.0, 349125.0 ], [ 2044125.0, 348875.0 ], [ 2044375.0, 348875.0 ], [ 2044375.0, 348625.0 ], [ 2044625.0, 348625.0 ], [ 2044625.0, 348375.0 ], [ 2044875.0, 348375.0 ], [ 2044875.0, 348125.0 ], [ 2045125.0, 348125.0 ], [ 2045375.0, 348125.0 ], [ 2045392.826774591812864, 348142.826774591754656 ], [ 2045556.744589085225016, 348117.718749680614565 ], [ 2045704.146632959367707, 348188.635653424018528 ], [ 2045703.53, 348189.957 ], [ 2045683.655, 348230.872199999983422 ], [ 2045638.91, 348320.3714 ], [ 2045601.113818968413398, 348404.300741842540447 ], [ 2045875.0, 348438.28639834333444 ], [ 2045875.0, 348625.0 ], [ 2046125.0, 348625.0 ], [ 2046375.0, 348625.0 ], [ 2046625.0, 348625.0 ], [ 2046875.0, 348625.0 ], [ 2047125.0, 348625.0 ], [ 2047375.0, 348625.0 ], [ 2047625.0, 348625.0 ], [ 2047625.0, 348875.0 ], [ 2047875.0, 348875.0 ], [ 2047875.0, 349125.0 ], [ 2048125.0, 349125.0 ], [ 2048375.0, 349125.0 ], [ 2048375.0, 349375.0 ], [ 2048625.0, 349375.0 ], [ 2048625.0, 349625.0 ], [ 2048875.0, 349625.0 ], [ 2048875.0, 349375.0 ], [ 2048875.0, 349125.0 ], [ 2048625.0, 349125.0 ], [ 2048625.0, 348875.0 ], [ 2048375.0, 348875.0 ], [ 2048375.0, 348625.0 ], [ 2048125.0, 348625.0 ], [ 2048125.0, 348375.0 ], [ 2047875.0, 348375.0 ], [ 2047625.0, 348375.0 ], [ 2047625.0, 348125.0 ], [ 2047375.0, 348125.0 ], [ 2047125.0, 348125.0 ], [ 2046875.0, 348125.0 ], [ 2046625.0, 348125.0 ], [ 2046375.0, 348125.0 ], [ 2046125.0, 348125.0 ], [ 2046089.87689806940034, 348089.876898069458548 ], [ 2046133.482221366371959, 347904.488804459862877 ], [ 2045958.136711895698681, 347764.27390489471145 ], [ 2046003.847, 347713.34529999998631 ], [ 2046072.674000000115484, 347635.247199999983422 ], [ 2046075.053, 347630.305500000016764 ], [ 2046122.245087900198996, 347577.973078029346652 ], [ 2046139.892, 347558.403999999980442 ], [ 2046207.156999999890104, 347483.392400000011548 ], [ 2046274.705, 347407.8383 ], [ 2046287.932678144657984, 347392.772025281796232 ], [ 2046341.25, 347332.043799999984913 ], [ 2046411.049000000115484, 347255.744200000015553 ], [ 2046457.673041422618553, 347211.46309378487058 ], [ 2046485.556, 347184.981299999984913 ], [ 2046565.708000000100583, 347123.543899999989662 ], [ 2046651.968000000109896, 347068.3297 ], [ 2046660.080679264385253, 347063.249455272394698 ], [ 2046738.525, 347014.126800000027288 ], [ 2046825.058, 346961.364500000025146 ], [ 2046869.245368028059602, 346934.381285698153079 ], [ 2046911.172, 346908.778600000019651 ], [ 2046998.466, 346858.839700000011362 ], [ 2047074.832631461787969, 346796.353584631113335 ], [ 2047077.102, 346794.496700000017881 ], [ 2047131.55, 346710.1251 ], [ 2047135.395, 346703.76510000001872 ], [ 2047135.838, 346703.745500000019092 ], [ 2047138.368, 346696.5062 ], [ 2047154.071, 346669.8028 ], [ 2047159.066000000108033, 346664.3712 ], [ 2047206.933, 346605.079900000011548 ], [ 2047221.362432709662244, 346597.393960972491186 ], [ 2047376.290053668897599, 346783.877958185737953 ], [ 2047375.0, 346884.71753743494628 ], [ 2047625.0, 346875.0 ], [ 2047625.0, 347125.0 ], [ 2047875.0, 347125.0 ], [ 2048125.0, 347125.0 ], [ 2048125.0, 346875.0 ], [ 2048125.0, 346674.451247457182035 ], [ 2048169.136621022131294, 346466.638890414615162 ], [ 2048255.281999999890104, 346487.695499999972526 ], [ 2048354.399, 346511.208600000012666 ], [ 2048410.55518839834258, 346525.293504228000529 ], [ 2048451.509, 346535.565400000021327 ], [ 2048548.051, 346568.491900000022724 ], [ 2048643.018, 346606.93 ], [ 2048644.829203597269952, 346607.831182389636524 ], [ 2048734.287, 346652.3418 ], [ 2048824.444, 346701.8885 ], [ 2048862.720127717126161, 346726.940490917710122 ], [ 2048908.692, 346757.0294 ], [ 2048988.824, 346817.044600000022911 ], [ 2049059.556004673242569, 346878.25982995639788 ], [ 2049067.213, 346884.886600000027101 ], [ 2049143.874, 346950.678699999989476 ], [ 2049164.018, 346969.060999999986961 ], [ 2049246.389999999897555, 347028.6629 ], [ 2049253.963706719689071, 347032.600758539338131 ], [ 2049335.862, 347075.1828 ], [ 2049429.828, 347112.933499999984633 ], [ 2049481.395841051125899, 347132.290066618821584 ], [ 2049525.551, 347148.864200000010896 ], [ 2049620.142, 347187.714800000016112 ], [ 2049711.574092950439081, 347225.890785001625773 ], [ 2049713.02, 347226.494499999971595 ], [ 2049806.409, 347264.1264 ], [ 2049812.534, 347266.604899999976624 ], [ 2049899.589, 347301.8296 ], [ 2049942.999113350640982, 347316.274769303330686 ], [ 2049996.120000000111759, 347333.951300000015181 ], [ 2050093.68, 347358.6692 ], [ 2050184.511057119816542, 347373.972390304203145 ], [ 2050194.082, 347375.584900000016205 ], [ 2050295.031, 347380.165700000012293 ], [ 2050395.870000000111759, 347379.972400000027847 ], [ 2050432.790745197795331, 347381.637759556586388 ], [ 2050606.428, 347389.469900000025518 ], [ 2050680.816848023561761, 347396.403189528442454 ], [ 2050693.102999999886379, 347397.548300000024028 ], [ 2050792.656, 347418.07909999997355 ], [ 2050891.608, 347444.3001 ], [ 2050921.034117232076824, 347452.326108012755867 ], [ 2050955.508, 347461.728899999987334 ], [ 2050989.633, 347471.4816 ], [ 2051088.202, 347496.375 ], [ 2051162.892246897798032, 347517.011693853070028 ], [ 2051185.308, 347523.205100000021048 ], [ 2051252.842, 347541.0538 ], [ 2051284.082, 347549.719700000016019 ], [ 2051381.33, 347575.379000000015367 ], [ 2051403.036967576947063, 347581.186219056078698 ], [ 2051479.602, 347601.669500000018161 ], [ 2051577.727, 347627.338800000026822 ], [ 2051642.329075674060732, 347647.870469470217358 ], [ 2051674.817, 347658.195699999982025 ], [ 2051764.92, 347702.402 ], [ 2051855.0, 347751.324499999987893 ], [ 2051864.872799330158159, 347757.811560854723211 ], [ 2051781.506151334848255, 347891.426020058279391 ], [ 2051625.0, 347935.163654816860799 ], [ 2051625.0, 348125.0 ], [ 2051625.0, 348375.0 ], [ 2051375.0, 348375.0 ], [ 2051125.0, 348375.0 ], [ 2051125.0, 348625.0 ], [ 2051125.0, 348875.0 ], [ 2051125.0, 349125.0 ], [ 2051125.0, 349375.0 ], [ 2051375.0, 349375.0 ], [ 2051625.0, 349375.0 ], [ 2051875.0, 349375.0 ], [ 2052125.0, 349375.0 ], [ 2052125.0, 349625.0 ], [ 2052375.0, 349625.0 ], [ 2052375.0, 349875.0 ], [ 2052375.0, 350125.0 ], [ 2052375.0, 350375.0 ], [ 2052125.0, 350375.0 ], [ 2051875.0, 350375.0 ], [ 2051625.0, 350375.0 ], [ 2051375.0, 350375.0 ], [ 2051125.0, 350375.0 ], [ 2051125.0, 350625.0 ], [ 2051125.0, 350875.0 ], [ 2050875.0, 350875.0 ], [ 2050875.0, 351125.0 ], [ 2050875.0, 351375.0 ], [ 2051125.0, 351375.0 ], [ 2051125.0, 351625.0 ], [ 2051125.0, 351875.0 ], [ 2051125.0, 352125.0 ], [ 2051375.0, 352125.0 ], [ 2051625.0, 352125.0 ], [ 2051625.0, 352375.0 ], [ 2051875.0, 352375.0 ], [ 2052125.0, 352375.0 ], [ 2052375.0, 352375.0 ], [ 2052625.0, 352375.0 ], [ 2052875.0, 352375.0 ], [ 2053125.0, 352375.0 ], [ 2053125.0, 352125.0 ], [ 2053375.0, 352125.0 ], [ 2053375.0, 352375.0 ], [ 2053375.0, 352625.0 ], [ 2053625.0, 352625.0 ], [ 2053875.0, 352625.0 ], [ 2054125.0, 352625.0 ], [ 2054375.0, 352625.0 ], [ 2054625.0, 352625.0 ], [ 2054625.0, 352375.0 ], [ 2054625.0, 352125.0 ], [ 2054625.0, 351875.0 ], [ 2054625.0, 351625.0 ], [ 2054625.0, 351375.0 ], [ 2054375.0, 351375.0 ], [ 2054375.0, 351125.0 ], [ 2054625.0, 351125.0 ], [ 2054625.0, 350875.0 ], [ 2054875.0, 350875.0 ], [ 2054875.0, 351125.0 ], [ 2054875.0, 351375.0 ], [ 2054875.0, 351625.0 ], [ 2055125.0, 351625.0 ], [ 2055375.0, 351625.0 ], [ 2055625.0, 351625.0 ], [ 2055875.0, 351625.0 ], [ 2056125.0, 351625.0 ], [ 2056125.0, 351375.0 ], [ 2056350.599363238317892, 351375.0 ], [ 2056298.700922008370981, 351060.282652019988745 ], [ 2056325.352999999886379, 351070.809300000022631 ], [ 2056420.75, 351103.553599999984726 ], [ 2056519.756, 351131.548799999989569 ], [ 2056531.340559467673302, 351135.295387445541564 ], [ 2056615.531, 351162.523600000014994 ], [ 2056713.584, 351191.837999999988824 ], [ 2056765.632664176868275, 351207.582327997835819 ], [ 2056792.118906509829685, 351118.623203010298312 ], [ 2056875.0, 351003.812603708007373 ], [ 2056875.0, 350875.0 ], [ 2057125.0, 350875.0 ], [ 2057375.0, 350875.0 ], [ 2057625.0, 350875.0 ], [ 2057875.0, 350875.0 ], [ 2058125.0, 350875.0 ], [ 2058375.0, 350875.0 ], [ 2058625.0, 350875.0 ], [ 2058875.0, 350875.0 ], [ 2059125.0, 350875.0 ], [ 2059125.0, 351125.0 ], [ 2059375.0, 351125.0 ], [ 2059375.0, 350875.0 ], [ 2059625.0, 350875.0 ], [ 2059875.0, 350875.0 ], [ 2060125.0, 350875.0 ], [ 2060375.0, 350875.0 ], [ 2060625.0, 350875.0 ], [ 2060875.0, 350875.0 ], [ 2061125.0, 350875.0 ], [ 2061375.0, 350875.0 ], [ 2061625.0, 350875.0 ], [ 2061625.0, 351125.0 ], [ 2061875.0, 351125.0 ], [ 2061875.0, 351375.0 ], [ 2062125.0, 351375.0 ], [ 2062125.0, 351625.0 ], [ 2062375.0, 351625.0 ], [ 2062375.0, 351875.0 ], [ 2062625.0, 351875.0 ], [ 2062625.0, 352125.0 ], [ 2062875.0, 352125.0 ], [ 2062875.0, 352375.0 ], [ 2062875.0, 352625.0 ], [ 2062625.0, 352625.0 ], [ 2062625.0, 352875.0 ], [ 2062375.0, 352875.0 ], [ 2062125.0, 352875.0 ], [ 2061875.0, 352875.0 ], [ 2061625.0, 352875.0 ], [ 2061625.0, 352625.0 ], [ 2061375.0, 352625.0 ], [ 2061125.0, 352625.0 ], [ 2060875.0, 352625.0 ], [ 2060875.0, 352875.0 ], [ 2061125.0, 352875.0 ], [ 2061125.0, 353125.0 ], [ 2061125.0, 353375.0 ], [ 2060936.052242371952161, 353375.0 ], [ 2060859.709153409814462, 353594.106941066042054 ], [ 2060721.401, 353583.945469315221999 ], [ 2060721.401, 353603.5735 ], [ 2060689.642, 353702.8212 ], [ 2060634.063, 353788.174300000013318 ], [ 2060619.980225313687697, 353803.537643563351594 ], [ 2060612.229, 353811.9937 ], [ 2060518.936, 353873.527300000016112 ], [ 2060405.793, 353909.256500000017695 ], [ 2060400.958919165888801, 353910.302681645960547 ], [ 2060464.563876286381856, 354093.325358352158219 ], [ 2060375.0, 354183.159451701270882 ], [ 2060229.512232922716066, 354139.291739791049622 ], [ 2060086.491612219018862, 354299.844311335938983 ], [ 2059948.375940116588026, 354084.718807010853197 ], [ 2059867.871, 354141.4962 ], [ 2059770.608, 354210.969600000011269 ], [ 2059748.387329578632489, 354227.130101456714328 ], [ 2059683.27, 354274.488200000021607 ], [ 2059591.962, 354324.112000000022817 ], [ 2059531.247434145305306, 354340.55549108015839 ], [ 2059479.528306855354458, 354115.575721094384789 ], [ 2059375.0, 354072.547782423382159 ], [ 2059302.939927732106298, 354127.833226935239509 ], [ 2059125.0, 354064.438373746932484 ], [ 2059067.533013119595125, 354118.25090581382392 ], [ 2058875.0, 354043.578457493975293 ], [ 2058821.234719607280567, 354106.711431483156048 ], [ 2058625.0, 354019.287746681598946 ], [ 2058573.495666530216113, 354099.253049300634302 ], [ 2058343.532893176889047, 353971.947776140645146 ], [ 2058333.412036124849692, 353916.587963875208516 ], [ 2058125.0, 353895.644056870019995 ], [ 2057875.0, 353864.916898941854015 ], [ 2057632.892756410408765, 353845.583374651672784 ], [ 2057625.0, 353832.339210560137872 ], [ 2057389.012500252341852, 353821.701727379695512 ], [ 2057375.0, 353785.807741610682569 ], [ 2057139.27351446961984, 353807.841307688562665 ], [ 2057114.510077364509925, 353625.0 ], [ 2056916.989277934422716, 353646.347393477743026 ], [ 2056875.0, 353603.90383220568765 ], [ 2056658.175532867899165, 353622.710814676713198 ], [ 2056625.0, 353581.976500147837214 ], [ 2056402.627314012264833, 353604.969436102895997 ], [ 2056375.0, 353565.189082252269145 ], [ 2056146.247539822710678, 353594.238262819766533 ], [ 2056125.0, 353559.748845178051852 ], [ 2055875.0, 353574.024443101196084 ], [ 2055625.0, 353585.932005941634998 ], [ 2055375.0, 353601.183635311434045 ], [ 2055125.0, 353616.0711170466966 ], [ 2054875.0, 353631.366473019646946 ], [ 2054649.23748409259133, 353649.237484092533123 ], [ 2054640.49694138020277, 353726.582696879399009 ], [ 2054405.525373977608979, 353829.287263249338139 ], [ 2054375.0, 353761.103910181613173 ], [ 2054157.475470915203914, 353836.179934816900641 ], [ 2054125.0, 353783.61728427791968 ], [ 2053910.105774469673634, 353847.911656951182522 ], [ 2053875.0, 353803.9519838662236 ], [ 2053663.131689874920994, 353861.772455535479821 ], [ 2053625.0, 353823.244815596495755 ], [ 2053406.365308852866292, 353879.118521186290309 ], [ 2053375.0, 353853.129190048901364 ], [ 2053146.790609032381326, 353896.790609032323118 ], [ 2053148.391622352646664, 353994.126779674785212 ], [ 2052904.208318482618779, 354094.469294218695723 ], [ 2052875.0, 354069.359012868138961 ], [ 2052673.265417135553434, 354143.942089368880261 ], [ 2052613.944667972391471, 354125.0 ], [ 2052534.696291639702395, 354454.267284148954786 ], [ 2052463.99, 354472.983599999977741 ], [ 2052296.063303152332082, 354506.857195468794089 ], [ 2052054.392753534484655, 354555.606147173035424 ], [ 2052001.495000000111759, 354566.276499999978114 ], [ 2051813.08432263857685, 354606.194154093100224 ], [ 2051767.271, 354615.900399999984074 ], [ 2051600.534, 354653.614500000025146 ], [ 2051572.818477610126138, 354661.120849128928967 ], [ 2051505.257, 354679.418899999989662 ], [ 2051431.813, 354703.238399999972899 ], [ 2051339.851474932162091, 354741.190803439472802 ], [ 2051306.761, 354754.847200000018347 ], [ 2051211.483, 354798.516200000012759 ], [ 2051119.563230130355805, 354846.244091359432787 ], [ 2051108.266, 354852.10999999998603 ], [ 2050977.259, 354939.447999999974854 ], [ 2050910.884441662346944, 354980.747683905356098 ], [ 2050887.936, 354995.026699999987613 ], [ 2050836.327, 355024.800999999977648 ], [ 2050747.004, 355060.530199999979232 ], [ 2050723.183999999891967, 355066.4851 ], [ 2050686.458111064741388, 355073.265250973519869 ], [ 2050625.0, 355382.912428987619933 ], [ 2050875.0, 355375.0 ], [ 2050875.0, 355625.0 ], [ 2050875.0, 355875.0 ], [ 2051125.0, 355875.0 ], [ 2051375.0, 355875.0 ], [ 2051625.0, 355875.0 ], [ 2051625.0, 355625.0 ], [ 2051875.0, 355625.0 ], [ 2052125.0, 355625.0 ], [ 2052375.0, 355625.0 ], [ 2052375.0, 355375.0 ], [ 2052625.0, 355375.0 ], [ 2052790.338085040450096, 355540.338085040508304 ], [ 2052875.0, 355487.659560176252853 ], [ 2052875.0, 355125.0 ], [ 2053125.0, 355125.0 ], [ 2053375.0, 355125.0 ], [ 2053625.0, 355125.0 ], [ 2053875.0, 355125.0 ], [ 2053875.0, 354875.0 ], [ 2054125.0, 354875.0 ], [ 2054375.0, 354875.0 ], [ 2054625.0, 354875.0 ], [ 2054875.0, 354875.0 ], [ 2054875.0, 354625.0 ], [ 2055125.0, 354625.0 ], [ 2055375.0, 354625.0 ], [ 2055625.0, 354625.0 ], [ 2055625.0, 354875.0 ], [ 2055875.0, 354875.0 ], [ 2056125.0, 354875.0 ], [ 2056375.0, 354875.0 ], [ 2056625.0, 354875.0 ], [ 2056875.0, 354875.0 ], [ 2057125.0, 354875.0 ], [ 2057375.0, 354875.0 ], [ 2057625.0, 354875.0 ], [ 2057875.0, 354875.0 ], [ 2058125.0, 354875.0 ], [ 2058125.0, 355125.0 ], [ 2058375.0, 355125.0 ], [ 2058625.0, 355125.0 ], [ 2058875.0, 355125.0 ], [ 2059125.0, 355125.0 ], [ 2059125.0, 355375.0 ], [ 2059375.0, 355375.0 ], [ 2059625.0, 355375.0 ], [ 2059875.0, 355375.0 ], [ 2059875.0, 355625.0 ], [ 2060125.0, 355625.0 ], [ 2060375.0, 355625.0 ], [ 2060375.0, 355875.0 ], [ 2060375.0, 356125.0 ], [ 2060625.0, 356125.0 ], [ 2060625.0, 356375.0 ], [ 2060625.0, 356625.0 ], [ 2060875.0, 356625.0 ], [ 2060875.0, 356875.0 ], [ 2061125.0, 356875.0 ], [ 2061125.0, 357125.0 ], [ 2061375.0, 357125.0 ], [ 2061375.0, 357375.0 ], [ 2061625.0, 357375.0 ], [ 2061875.0, 357375.0 ], [ 2062125.0, 357375.0 ], [ 2062375.0, 357375.0 ], [ 2062625.0, 357375.0 ], [ 2062625.0, 357125.0 ], [ 2062875.0, 357125.0 ], [ 2063125.0, 357125.0 ], [ 2063375.0, 357125.0 ], [ 2063375.0, 356875.0 ], [ 2063625.0, 356875.0 ], [ 2063875.0, 356875.0 ], [ 2064125.0, 356875.0 ], [ 2064375.0, 356875.0 ], [ 2064625.0, 356875.0 ], [ 2064875.0, 356875.0 ], [ 2065125.0, 356875.0 ], [ 2065125.0, 356625.0 ], [ 2065375.0, 356625.0 ], [ 2065625.0, 356625.0 ], [ 2065625.0, 356375.0 ], [ 2065875.0, 356375.0 ], [ 2065875.0, 356125.0 ], [ 2066125.0, 356125.0 ], [ 2066125.0, 356375.0 ], [ 2066125.0, 356625.0 ], [ 2065875.0, 356625.0 ], [ 2065875.0, 356875.0 ], [ 2065875.0, 357125.0 ], [ 2066125.0, 357125.0 ], [ 2066125.0, 357375.0 ], [ 2066125.0, 357625.0 ], [ 2066375.0, 357625.0 ], [ 2066375.0, 357875.0 ], [ 2066375.0, 358125.0 ], [ 2066625.0, 358125.0 ], [ 2066625.0, 358375.0 ], [ 2066625.0, 358625.0 ], [ 2066875.0, 358625.0 ], [ 2066875.0, 358875.0 ], [ 2066875.0, 359125.0 ], [ 2067125.0, 359125.0 ], [ 2067125.0, 359375.0 ], [ 2067375.0, 359375.0 ], [ 2067625.0, 359375.0 ], [ 2067625.0, 359625.0 ], [ 2067625.0, 359875.0 ], [ 2067875.0, 359875.0 ], [ 2067875.0, 360125.0 ], [ 2068125.0, 360125.0 ], [ 2068375.0, 360125.0 ], [ 2068375.0, 360375.0 ], [ 2068625.0, 360375.0 ], [ 2068625.0, 360125.0 ], [ 2068875.0, 360125.0 ], [ 2069125.0, 360125.0 ], [ 2069125.0, 359875.0 ], [ 2069375.0, 359875.0 ], [ 2069375.0, 359625.0 ], [ 2069625.0, 359625.0 ], [ 2069875.0, 359625.0 ], [ 2070125.0, 359625.0 ], [ 2070125.0, 359875.0 ], [ 2070375.0, 359875.0 ], [ 2070625.0, 359875.0 ], [ 2070625.0, 360125.0 ], [ 2070625.0, 360375.0 ], [ 2070625.0, 360625.0 ], [ 2070625.0, 360875.0 ], [ 2070875.0, 360875.0 ], [ 2070875.0, 361125.0 ], [ 2070875.0, 361375.0 ], [ 2070875.0, 361625.0 ], [ 2071125.0, 361625.0 ], [ 2071125.0, 361875.0 ], [ 2071125.0, 362125.0 ], [ 2071375.0, 362125.0 ], [ 2071375.0, 362375.0 ], [ 2071625.0, 362375.0 ], [ 2071625.0, 362625.0 ], [ 2071625.0, 362875.0 ], [ 2071875.0, 362875.0 ], [ 2071875.0, 363125.0 ], [ 2072125.0, 363125.0 ], [ 2072375.0, 363125.0 ], [ 2072375.0, 363375.0 ], [ 2072375.0, 363625.0 ], [ 2072625.0, 363625.0 ], [ 2072625.0, 363875.0 ], [ 2072625.0, 364125.0 ], [ 2072625.0, 364375.0 ], [ 2072625.0, 364625.0 ], [ 2072875.0, 364625.0 ], [ 2072875.0, 364875.0 ], [ 2073125.0, 364875.0 ], [ 2073375.0, 364875.0 ], [ 2073625.0, 364875.0 ], [ 2073625.0, 365125.0 ], [ 2073875.0, 365125.0 ], [ 2073875.0, 365375.0 ], [ 2073875.0, 365625.0 ], [ 2074125.0, 365625.0 ], [ 2074125.0, 365875.0 ], [ 2074375.0, 365875.0 ], [ 2074625.0, 365875.0 ], [ 2074875.0, 365875.0 ], [ 2075125.0, 365875.0 ], [ 2075125.0, 366125.0 ], [ 2075375.0, 366125.0 ], [ 2075375.0, 366375.0 ], [ 2075625.0, 366375.0 ], [ 2075625.0, 366625.0 ], [ 2075875.0, 366625.0 ], [ 2075875.0, 366875.0 ], [ 2076125.0, 366875.0 ], [ 2076125.0, 367125.0 ], [ 2076375.0, 367125.0 ], [ 2076375.0, 367375.0 ], [ 2076625.0, 367375.0 ], [ 2076625.0, 367625.0 ], [ 2076875.0, 367625.0 ], [ 2077125.0, 367625.0 ], [ 2077375.0, 367625.0 ], [ 2077375.0, 367875.0 ], [ 2077625.0, 367875.0 ], [ 2077875.0, 367875.0 ], [ 2078125.0, 367875.0 ], [ 2078125.0, 368125.0 ], [ 2078375.0, 368125.0 ], [ 2078625.0, 368125.0 ], [ 2078875.0, 368125.0 ], [ 2079125.0, 368125.0 ], [ 2079375.0, 368125.0 ], [ 2079625.0, 368125.0 ], [ 2079875.0, 368125.0 ], [ 2080125.0, 368125.0 ], [ 2080375.0, 368125.0 ], [ 2080625.0, 368125.0 ], [ 2080625.0, 367875.0 ], [ 2080875.0, 367875.0 ], [ 2081125.0, 367875.0 ], [ 2081125.0, 367625.0 ], [ 2081375.0, 367625.0 ], [ 2081625.0, 367625.0 ], [ 2081625.0, 367375.0 ], [ 2081875.0, 367375.0 ], [ 2081875.0, 367125.0 ], [ 2081875.0, 366875.0 ], [ 2082125.0, 366875.0 ], [ 2082375.0, 366875.0 ], [ 2082375.0, 366625.0 ], [ 2082375.0, 366375.0 ], [ 2082375.0, 366125.0 ], [ 2082625.0, 366125.0 ], [ 2082625.0, 365875.0 ], [ 2082625.0, 365625.0 ], [ 2082875.0, 365625.0 ], [ 2082875.0, 365375.0 ], [ 2082875.0, 365125.0 ], [ 2082875.0, 364875.0 ], [ 2083125.0, 364875.0 ], [ 2083125.0, 364625.0 ], [ 2083222.647259352728724, 364527.352740647213068 ], [ 2083189.874681219924241, 364503.586367191979662 ], [ 2082875.0, 364379.293729868950322 ], [ 2082625.0, 364280.609519343124703 ], [ 2082513.430910659488291, 364236.569089340511709 ], [ 2082125.0, 364083.241098291473463 ], [ 2081875.0, 363984.556887765647843 ], [ 2081875.0, 364375.0 ], [ 2081875.0, 364625.0 ], [ 2081625.0, 364625.0 ], [ 2081625.0, 364375.0 ], [ 2081375.0, 364375.0 ], [ 2081125.0, 364375.0 ], [ 2080875.0, 364375.0 ], [ 2080625.0, 364375.0 ], [ 2080375.0, 364375.0 ], [ 2080125.0, 364375.0 ], [ 2079875.0, 364375.0 ], [ 2079875.0, 364625.0 ], [ 2079625.0, 364625.0 ], [ 2079375.0, 364625.0 ], [ 2079125.0, 364625.0 ], [ 2078875.0, 364625.0 ], [ 2078875.0, 364875.0 ], [ 2078625.0, 364875.0 ], [ 2078375.0, 364875.0 ], [ 2078125.0, 364875.0 ], [ 2077875.0, 364875.0 ], [ 2077625.0, 364875.0 ], [ 2077375.0, 364875.0 ], [ 2077125.0, 364875.0 ], [ 2077125.0, 365125.0 ], [ 2077125.0, 365375.0 ], [ 2077125.0, 365625.0 ], [ 2077125.0, 365875.0 ], [ 2077375.0, 365875.0 ], [ 2077625.0, 365875.0 ], [ 2077625.0, 366125.0 ], [ 2077375.0, 366125.0 ], [ 2077125.0, 366125.0 ], [ 2076875.0, 366125.0 ], [ 2076625.0, 366125.0 ], [ 2076625.0, 365875.0 ], [ 2076375.0, 365875.0 ], [ 2076375.0, 365625.0 ], [ 2076125.0, 365625.0 ], [ 2076125.0, 365375.0 ], [ 2075875.0, 365375.0 ], [ 2075875.0, 365125.0 ], [ 2075875.0, 364875.0 ], [ 2075625.0, 364875.0 ], [ 2075375.0, 364875.0 ], [ 2075375.0, 364625.0 ], [ 2075125.0, 364625.0 ], [ 2075125.0, 364375.0 ], [ 2075125.0, 364125.0 ], [ 2074875.0, 364125.0 ], [ 2074875.0, 363875.0 ], [ 2074875.0, 363625.0 ], [ 2074625.0, 363625.0 ], [ 2074625.0, 363375.0 ], [ 2074375.0, 363375.0 ], [ 2074125.0, 363375.0 ], [ 2074125.0, 363125.0 ], [ 2074125.0, 362875.0 ], [ 2073875.0, 362875.0 ], [ 2073875.0, 362625.0 ], [ 2073625.0, 362625.0 ], [ 2073625.0, 362375.0 ], [ 2073375.0, 362375.0 ], [ 2073375.0, 362125.0 ], [ 2073125.0, 362125.0 ], [ 2073125.0, 361875.0 ], [ 2072875.0, 361875.0 ], [ 2072875.0, 361625.0 ], [ 2072625.0, 361625.0 ], [ 2072375.0, 361625.0 ], [ 2072375.0, 361375.0 ], [ 2072125.0, 361375.0 ], [ 2072125.0, 361125.0 ], [ 2072125.0, 360875.0 ], [ 2071875.0, 360875.0 ], [ 2071875.0, 360625.0 ], [ 2071875.0, 360375.0 ], [ 2071875.0, 360125.0 ], [ 2071625.0, 360125.0 ], [ 2071625.0, 359875.0 ], [ 2071625.0, 359625.0 ], [ 2071875.0, 359625.0 ], [ 2071875.0, 359375.0 ], [ 2071625.0, 359375.0 ], [ 2071625.0, 359125.0 ], [ 2071375.0, 359125.0 ], [ 2071375.0, 358875.0 ], [ 2071625.0, 358875.0 ], [ 2071625.0, 358625.0 ], [ 2071625.0, 358375.0 ], [ 2071625.0, 358125.0 ], [ 2071625.0, 357875.0 ], [ 2071875.0, 357875.0 ], [ 2072125.0, 357875.0 ], [ 2072375.0, 357875.0 ], [ 2072375.0, 358125.0 ], [ 2072625.0, 358125.0 ], [ 2072625.0, 357875.0 ], [ 2072875.0, 357875.0 ], [ 2072875.0, 357625.0 ], [ 2072625.0, 357625.0 ], [ 2072625.0, 357375.0 ], [ 2072375.0, 357375.0 ], [ 2072375.0, 357625.0 ], [ 2072125.0, 357625.0 ], [ 2071875.0, 357625.0 ], [ 2071625.0, 357625.0 ], [ 2071375.0, 357625.0 ], [ 2071375.0, 357375.0 ], [ 2071375.0, 357125.0 ], [ 2071375.0, 356875.0 ], [ 2071375.0, 356625.0 ], [ 2071125.0, 356625.0 ], [ 2071125.0, 356375.0 ], [ 2071125.0, 356125.0 ], [ 2070875.0, 356125.0 ], [ 2070875.0, 355875.0 ], [ 2070625.0, 355875.0 ], [ 2070625.0, 355625.0 ], [ 2070375.0, 355625.0 ], [ 2070375.0, 355375.0 ], [ 2070125.0, 355375.0 ], [ 2069875.0, 355375.0 ], [ 2069875.0, 355125.0 ], [ 2069625.0, 355125.0 ], [ 2069625.0, 354875.0 ], [ 2069375.0, 354875.0 ], [ 2069125.0, 354875.0 ], [ 2069125.0, 354625.0 ], [ 2068875.0, 354625.0 ], [ 2068625.0, 354625.0 ], [ 2068625.0, 354375.0 ], [ 2068375.0, 354375.0 ], [ 2068375.0, 354125.0 ], [ 2068125.0, 354125.0 ], [ 2067875.0, 354125.0 ], [ 2067625.0, 354125.0 ], [ 2067625.0, 353875.0 ], [ 2067375.0, 353875.0 ], [ 2067125.0, 353875.0 ], [ 2066875.0, 353875.0 ], [ 2066875.0, 353625.0 ], [ 2066625.0, 353625.0 ], [ 2066375.0, 353625.0 ], [ 2066125.0, 353625.0 ], [ 2066125.0, 353375.0 ], [ 2065875.0, 353375.0 ], [ 2065625.0, 353375.0 ], [ 2065625.0, 353125.0 ], [ 2065375.0, 353125.0 ], [ 2065375.0, 352875.0 ], [ 2065125.0, 352875.0 ], [ 2064875.0, 352875.0 ], [ 2064875.0, 352625.0 ], [ 2064625.0, 352625.0 ], [ 2064375.0, 352625.0 ], [ 2064375.0, 352375.0 ], [ 2064125.0, 352375.0 ], [ 2063875.0, 352375.0 ], [ 2063875.0, 352125.0 ], [ 2063625.0, 352125.0 ], [ 2063625.0, 351875.0 ], [ 2063375.0, 351875.0 ], [ 2063375.0, 351625.0 ], [ 2063125.0, 351625.0 ], [ 2062875.0, 351625.0 ], [ 2062875.0, 351375.0 ], [ 2062875.0, 351125.0 ], [ 2063028.14763583149761, 350971.852364168618806 ], [ 2062716.62931122421287, 350783.37068877578713 ], [ 2062375.0, 350576.670601312071085 ], [ 2062249.351824313402176, 350500.648175686539616 ], [ 2062115.055381180020049, 350419.393184882996138 ], [ 2061875.0, 350295.319617082946934 ], [ 2061762.715215404285118, 350237.284784595656674 ], [ 2061375.0, 350036.89265079254983 ], [ 2061282.16953850002028, 349988.912861703021917 ], [ 2061266.453567439690232, 349983.546432560426183 ], [ 2060875.0, 349849.879360751598142 ], [ 2060625.0, 349764.513507093011867 ], [ 2060520.999021985335276, 349729.000978014722932 ], [ 2060375.0, 349875.0 ], [ 2060125.0, 349875.0 ], [ 2059875.0, 349875.0 ], [ 2059625.0, 349875.0 ], [ 2059375.0, 349875.0 ], [ 2059125.0, 349875.0 ], [ 2058875.0, 349875.0 ], [ 2058875.0, 350125.0 ], [ 2058625.0, 350125.0 ], [ 2058375.0, 350125.0 ], [ 2058375.0, 349875.0 ], [ 2058125.0, 349875.0 ], [ 2057875.0, 349875.0 ], [ 2057875.0, 350125.0 ], [ 2057625.0, 350125.0 ], [ 2057375.0, 350125.0 ], [ 2057375.0, 350375.0 ], [ 2057125.0, 350375.0 ], [ 2056875.0, 350375.0 ], [ 2056625.0, 350375.0 ], [ 2056625.0, 350125.0 ], [ 2056375.0, 350125.0 ], [ 2056125.0, 350125.0 ], [ 2056125.0, 349875.0 ], [ 2056125.0, 349625.0 ], [ 2055875.0, 349625.0 ], [ 2055875.0, 349375.0 ], [ 2055625.0, 349375.0 ], [ 2055625.0, 349125.0 ], [ 2055375.0, 349125.0 ], [ 2055375.0, 348875.0 ], [ 2055125.0, 348875.0 ], [ 2054875.0, 348875.0 ], [ 2054875.0, 348625.0 ], [ 2054625.0, 348625.0 ], [ 2054625.0, 348375.0 ], [ 2054375.0, 348375.0 ], [ 2054375.0, 348125.0 ], [ 2054125.0, 348125.0 ], [ 2053875.0, 348125.0 ], [ 2053625.0, 348125.0 ], [ 2053375.0, 348125.0 ], [ 2053125.0, 348125.0 ], [ 2052875.0, 348125.0 ], [ 2052875.0, 347875.0 ], [ 2052875.0, 347625.0 ], [ 2052625.0, 347625.0 ], [ 2052375.0, 347625.0 ], [ 2052153.325309976236895, 347625.0 ], [ 2052125.0, 347599.571051757840905 ], [ 2052125.0, 347375.0 ], [ 2052125.0, 347125.0 ], [ 2051875.0, 347125.0 ], [ 2051625.0, 347125.0 ], [ 2051375.0, 347125.0 ], [ 2051125.0, 347125.0 ], [ 2051125.0, 346875.0 ], [ 2050875.0, 346875.0 ], [ 2050625.0, 346875.0 ], [ 2050375.0, 346875.0 ], [ 2050375.0, 346625.0 ], [ 2050125.0, 346625.0 ], [ 2049875.0, 346625.0 ], [ 2049625.0, 346625.0 ], [ 2049625.0, 346375.0 ], [ 2049375.0, 346375.0 ], [ 2049125.0, 346375.0 ], [ 2049125.0, 346125.0 ], [ 2048875.0, 346125.0 ], [ 2048625.0, 346125.0 ], [ 2048375.0, 346125.0 ], [ 2048125.0, 346125.0 ], [ 2048125.0, 345875.0 ], [ 2047875.0, 345875.0 ], [ 2047625.0, 345875.0 ], [ 2047375.0, 345875.0 ], [ 2047125.0, 345875.0 ], [ 2046875.0, 345875.0 ], [ 2046875.0, 346125.0 ], [ 2046625.0, 346125.0 ], [ 2046375.0, 346125.0 ], [ 2046125.0, 346125.0 ], [ 2045875.0, 346125.0 ], [ 2045875.0, 346375.0 ], [ 2045625.0, 346375.0 ], [ 2045625.0, 346125.0 ], [ 2045375.0, 346125.0 ], [ 2045125.0, 346125.0 ], [ 2044875.0, 346125.0 ], [ 2044625.0, 346125.0 ], [ 2044625.0, 346375.0 ], [ 2044375.0, 346375.0 ], [ 2044375.0, 346625.0 ], [ 2044125.0, 346625.0 ], [ 2043875.0, 346625.0 ], [ 2043875.0, 346875.0 ], [ 2043625.0, 346875.0 ], [ 2043375.0, 346875.0 ], [ 2043375.0, 347125.0 ], [ 2043375.0, 347375.0 ], [ 2043125.0, 347375.0 ], [ 2043125.0, 347625.0 ], [ 2042875.0, 347625.0 ], [ 2042625.0, 347625.0 ], [ 2042375.0, 347625.0 ], [ 2042375.0, 347375.0 ], [ 2042625.0, 347375.0 ], [ 2042625.0, 347125.0 ], [ 2042625.0, 346875.0 ], [ 2042375.0, 346875.0 ], [ 2042125.0, 346875.0 ], [ 2041875.0, 346875.0 ], [ 2041625.0, 346875.0 ], [ 2041625.0, 346625.0 ], [ 2041625.0, 346375.0 ], [ 2041625.0, 346125.0 ], [ 2041375.0, 346125.0 ], [ 2041375.0, 345875.0 ], [ 2041125.0, 345875.0 ], [ 2040875.0, 345875.0 ], [ 2040875.0, 346125.0 ], [ 2040625.0, 346125.0 ], [ 2040625.0, 345875.0 ], [ 2040625.0, 345625.0 ], [ 2040375.0, 345625.0 ], [ 2040375.0, 345875.0 ], [ 2040125.0, 345875.0 ], [ 2040125.0, 346125.0 ], [ 2040125.0, 346375.0 ], [ 2039875.0, 346375.0 ], [ 2039625.0, 346375.0 ], [ 2039625.0, 346125.0 ], [ 2039375.0, 346125.0 ], [ 2039125.0, 346125.0 ], [ 2038875.0, 346125.0 ], [ 2038625.0, 346125.0 ], [ 2038375.0, 346125.0 ], [ 2038125.0, 346125.0 ], [ 2037875.0, 346125.0 ], [ 2037875.0, 345875.0 ], [ 2037875.0, 345625.0 ], [ 2037625.0, 345625.0 ], [ 2037625.0, 345375.0 ], [ 2037375.0, 345375.0 ], [ 2037375.0, 345125.0 ], [ 2037375.0, 344875.0 ], [ 2037375.0, 344625.0 ], [ 2037375.0, 344375.0 ], [ 2037125.0, 344375.0 ], [ 2037125.0, 344125.0 ], [ 2037125.0, 343875.0 ], [ 2037375.0, 343875.0 ], [ 2037375.0, 343625.0 ], [ 2037375.0, 343375.0 ], [ 2037625.0, 343375.0 ], [ 2037625.0, 343125.0 ], [ 2037625.0, 342875.0 ], [ 2037625.0, 342625.0 ], [ 2037625.0, 342375.0 ], [ 2037625.0, 342125.0 ], [ 2037625.0, 341875.0 ], [ 2037625.0, 341625.0 ], [ 2037625.0, 341375.0 ], [ 2037625.0, 341125.0 ], [ 2037625.0, 340875.0 ], [ 2037375.0, 340875.0 ], [ 2037375.0, 340625.0 ], [ 2037375.0, 340375.0 ], [ 2037125.0, 340375.0 ], [ 2037125.0, 340125.0 ], [ 2037125.0, 339875.0 ], [ 2036875.0, 339875.0 ], [ 2036875.0, 339625.0 ], [ 2036625.0, 339625.0 ], [ 2036625.0, 339375.0 ], [ 2036375.0, 339375.0 ], [ 2036125.0, 339375.0 ], [ 2036125.0, 339125.0 ], [ 2035875.0, 339125.0 ], [ 2035875.0, 338875.0 ], [ 2035625.0, 338875.0 ], [ 2035625.0, 338625.0 ], [ 2035375.0, 338625.0 ], [ 2035375.0, 338375.0 ], [ 2035125.0, 338375.0 ], [ 2035125.0, 338125.0 ], [ 2034875.0, 338125.0 ], [ 2034875.0, 337875.0 ], [ 2034625.0, 337875.0 ], [ 2034375.0, 337875.0 ], [ 2034375.0, 337625.0 ], [ 2034125.0, 337625.0 ], [ 2033875.0, 337625.0 ], [ 2033875.0, 337375.0 ], [ 2033625.0, 337375.0 ], [ 2033625.0, 337125.0 ], [ 2033375.0, 337125.0 ], [ 2033375.0, 336875.0 ], [ 2033125.0, 336875.0 ], [ 2032875.0, 336875.0 ], [ 2032875.0, 336625.0 ], [ 2032625.0, 336625.0 ], [ 2032625.0, 336375.0 ], [ 2032375.0, 336375.0 ], [ 2032375.0, 336125.0 ], [ 2032125.0, 336125.0 ], [ 2032125.0, 335875.0 ], [ 2031875.0, 335875.0 ], [ 2031625.0, 335875.0 ], [ 2031625.0, 335625.0 ], [ 2031375.0, 335625.0 ], [ 2031125.0, 335625.0 ], [ 2031125.0, 335375.0 ], [ 2030875.0, 335375.0 ], [ 2030625.0, 335375.0 ], [ 2030625.0, 335125.0 ], [ 2030375.0, 335125.0 ], [ 2030375.0, 334875.0 ], [ 2030125.0, 334875.0 ], [ 2030125.0, 334625.0 ], [ 2029875.0, 334625.0 ], [ 2029625.0, 334625.0 ], [ 2029625.0, 334375.0 ], [ 2029375.0, 334375.0 ], [ 2029125.0, 334375.0 ], [ 2028875.0, 334375.0 ], [ 2028875.0, 334125.0 ], [ 2028625.0, 334125.0 ], [ 2028375.0, 334125.0 ], [ 2028375.0, 333875.0 ], [ 2028125.0, 333875.0 ], [ 2027875.0, 333875.0 ], [ 2027625.0, 333875.0 ], [ 2027625.0, 333625.0 ], [ 2027375.0, 333625.0 ], [ 2027125.0, 333625.0 ], [ 2026875.0, 333625.0 ], [ 2026625.0, 333625.0 ], [ 2026375.0, 333625.0 ], [ 2026375.0, 333875.0 ], [ 2026125.0, 333875.0 ], [ 2025875.0, 333875.0 ], [ 2025625.0, 333875.0 ], [ 2025375.0, 333875.0 ], [ 2025375.0, 333625.0 ], [ 2025125.0, 333625.0 ], [ 2024875.0, 333625.0 ], [ 2024625.0, 333625.0 ], [ 2024375.0, 333625.0 ], [ 2024375.0, 333375.0 ], [ 2024125.0, 333375.0 ], [ 2024125.0, 333125.0 ], [ 2023875.0, 333125.0 ], [ 2023875.0, 332875.0 ], [ 2023625.0, 332875.0 ], [ 2023625.0, 332625.0 ], [ 2023375.0, 332625.0 ], [ 2023375.0, 332375.0 ], [ 2023125.0, 332375.0 ], [ 2023125.0, 332125.0 ], [ 2022875.0, 332125.0 ], [ 2022875.0, 331875.0 ], [ 2022625.0, 331875.0 ], [ 2022625.0, 331625.0 ], [ 2022625.0, 331375.0 ], [ 2022625.0, 331125.0 ], [ 2022375.0, 331125.0 ], [ 2022375.0, 330875.0 ], [ 2022125.0, 330875.0 ], [ 2022125.0, 330625.0 ], [ 2021875.0, 330625.0 ], [ 2021875.0, 330375.0 ], [ 2021625.0, 330375.0 ], [ 2021625.0, 330125.0 ], [ 2021625.0, 329875.0 ], [ 2021375.0, 329875.0 ], [ 2021375.0, 329625.0 ], [ 2021125.0, 329625.0 ], [ 2021125.0, 329375.0 ], [ 2020875.0, 329375.0 ], [ 2020875.0, 329125.0 ], [ 2020875.0, 328875.0 ], [ 2020625.0, 328875.0 ], [ 2020625.0, 328625.0 ], [ 2020375.0, 328625.0 ], [ 2020375.0, 328375.0 ], [ 2020375.0, 328125.0 ], [ 2020125.0, 328125.0 ], [ 2020125.0, 327875.0 ], [ 2019875.0, 327875.0 ], [ 2019875.0, 327625.0 ], [ 2019625.0, 327625.0 ], [ 2019375.0, 327625.0 ], [ 2019375.0, 327375.0 ], [ 2019125.0, 327375.0 ], [ 2019125.0, 327125.0 ], [ 2018875.0, 327125.0 ], [ 2018625.0, 327125.0 ], [ 2018625.0, 326875.0 ], [ 2018375.0, 326875.0 ], [ 2018375.0, 326625.0 ], [ 2018125.0, 326625.0 ], [ 2018125.0, 326375.0 ], [ 2017875.0, 326375.0 ], [ 2017875.0, 326125.0 ], [ 2017625.0, 326125.0 ], [ 2017625.0, 325875.0 ], [ 2017375.0, 325875.0 ], [ 2017375.0, 325545.715381716901902 ], [ 2017279.628278370480984, 325470.371721629460808 ], [ 2017125.0, 325625.0 ], [ 2016875.0, 325625.0 ], [ 2016875.0, 325375.0 ], [ 2016625.0, 325375.0 ], [ 2016375.0, 325375.0 ], [ 2016375.0, 325125.0 ], [ 2016125.0, 325125.0 ], [ 2015875.0, 325125.0 ], [ 2015625.0, 325125.0 ], [ 2015375.0, 325125.0 ], [ 2015125.0, 325125.0 ], [ 2015125.0, 325375.0 ], [ 2014875.0, 325375.0 ], [ 2014625.0, 325375.0 ], [ 2014375.0, 325375.0 ], [ 2014375.0, 325125.0 ], [ 2014125.0, 325125.0 ], [ 2014125.0, 325375.0 ], [ 2013875.0, 325375.0 ], [ 2013625.0, 325375.0 ], [ 2013375.0, 325375.0 ], [ 2013125.0, 325375.0 ], [ 2013125.0, 325625.0 ], [ 2012875.0, 325625.0 ], [ 2012875.0, 325375.0 ], [ 2012625.0, 325375.0 ], [ 2012375.0, 325375.0 ], [ 2012125.0, 325375.0 ], [ 2011875.0, 325375.0 ], [ 2011625.0, 325375.0 ], [ 2011625.0, 325125.0 ], [ 2011375.0, 325125.0 ], [ 2011375.0, 324875.0 ], [ 2011125.0, 324875.0 ], [ 2011125.0, 324625.0 ], [ 2011125.0, 324375.0 ], [ 2011125.0, 324125.0 ], [ 2011125.0, 323875.0 ], [ 2010875.0, 323875.0 ], [ 2010875.0, 323625.0 ], [ 2010625.0, 323625.0 ], [ 2010625.0, 323375.0 ], [ 2010625.0, 323125.0 ], [ 2010375.0, 323125.0 ], [ 2010375.0, 322875.0 ], [ 2010375.0, 322625.0 ], [ 2010125.0, 322625.0 ], [ 2009875.0, 322625.0 ], [ 2009875.0, 322375.0 ], [ 2009625.0, 322375.0 ], [ 2009625.0, 322125.0 ], [ 2009375.0, 322125.0 ], [ 2009125.0, 322125.0 ], [ 2009125.0, 322375.0 ], [ 2008875.0, 322375.0 ], [ 2008875.0, 322125.0 ], [ 2008625.0, 322125.0 ], [ 2008625.0, 321875.0 ], [ 2008875.0, 321875.0 ], [ 2009125.0, 321875.0 ], [ 2009125.0, 321625.0 ], [ 2009125.0, 321375.0 ], [ 2008875.0, 321375.0 ], [ 2008875.0, 321125.0 ], [ 2008625.0, 321125.0 ], [ 2008625.0, 320875.0 ], [ 2008375.0, 320875.0 ], [ 2008125.0, 320866.190288251324091 ], [ 2008125.0, 321125.0 ], [ 2007839.446900221286342, 321125.0 ], [ 2007771.765017242636532, 321271.765017242520116 ], [ 2007568.955295509891585, 321529.296566680888645 ], [ 2007325.133, 321253.133900000015274 ], [ 2007631.921911379788071, 320935.452957197616342 ], [ 2007802.646582176443189, 320758.666990148311015 ], [ 2007973.371252968208864, 320581.881023104069754 ], [ 2008143.762959928717464, 320405.439841219747905 ], [ 2008274.469, 320270.0933 ], [ 2008186.308506580768153, 320111.32622177497251 ], [ 2008125.0, 320081.342086733086035 ], [ 2008125.0, 319875.0 ], [ 2007875.0, 319875.0 ], [ 2007875.0, 319625.0 ], [ 2007625.0, 319625.0 ], [ 2007625.0, 319375.0 ], [ 2007375.0, 319375.0 ], [ 2007375.0, 319125.0 ], [ 2007125.0, 319125.0 ], [ 2007125.0, 318875.0 ], [ 2006875.0, 318875.0 ], [ 2006875.0, 318625.0 ], [ 2006625.0, 318625.0 ], [ 2006625.0, 318375.0 ], [ 2006375.0, 318375.0 ], [ 2006375.0, 318034.667274101113435 ], [ 2006291.591722484445199, 317958.408277515554801 ], [ 2006030.397692633559927, 317719.60230736649828 ], [ 2005769.203662782674655, 317480.79633721744176 ], [ 2005545.214006379945204, 317276.005794221011456 ], [ 2005506.366842415882275, 317243.633157584175933 ], [ 2005233.639569688821211, 317016.360430311178789 ], [ 2004960.912296961760148, 316789.087703038239852 ], [ 2004688.185024234699085, 316561.814975765242707 ], [ 2004375.0, 316300.827455569116864 ], [ 2004279.094115144107491, 316220.905884855776094 ], [ 2004141.701392299961299, 316106.411949152010493 ], [ 2004028.590898402268067, 315971.409101597848348 ], [ 2003947.815705170854926, 315875.0 ], [ 2003686.67913369461894, 315563.320866305439267 ], [ 2003458.737957222852856, 315291.262042777147144 ], [ 2003230.796780751086771, 315019.203219248913229 ], [ 2003105.77541523007676, 314869.984170079987962 ], [ 2003022.843322667758912, 314727.156677332357503 ], [ 2002963.526542281731963, 314625.0 ], [ 2002747.333118587499484, 314252.6668814123841 ], [ 2002673.203961639199406, 314125.0 ], [ 2002504.27000920008868, 313834.058193019009195 ], [ 2002460.105908090481535, 313789.894091909460258 ], [ 2002210.105908090481535, 313539.894091909634881 ], [ 2001960.105908090248704, 313289.894091909809504 ], [ 2001710.105908090015873, 313039.894091909925919 ], [ 2001460.105908090015873, 312789.894091910100542 ], [ 2001210.105908089783043, 312539.894091910216957 ], [ 2000960.105908089550212, 312289.89409191039158 ], [ 2000833.421659100102261, 312163.209842921001837 ], [ 2000708.416651226580143, 312041.583348773478065 ], [ 2000454.991993692470714, 311795.00800630741287 ], [ 2000201.567336158594117, 311548.432663841405883 ], [ 1999948.142678624717519, 311301.857321375340689 ], [ 1999694.71802109060809, 311055.281978909275495 ], [ 1999596.993880030000582, 310960.199030850024428 ], [ 1999375.0, 310836.228422521555331 ], [ 1999239.461762215243652, 310760.538237784639932 ], [ 1998875.0, 310557.007643300748896 ], [ 1998758.211762215243652, 310491.788237784639932 ], [ 1998375.0, 310277.786864079942461 ], [ 1998276.961762215476483, 310223.038237784639932 ], [ 1997875.0, 309998.566084859136026 ], [ 1997795.711762215476483, 309954.288237784581725 ], [ 1997474.878428881987929, 309775.121571117895655 ], [ 1997125.0, 309579.734916027926374 ], [ 1997023.887420879909769, 309523.26944976602681 ], [ 1996875.0, 309533.904265543096699 ], [ 1996625.0, 309551.761408400139771 ], [ 1996556.049882849911228, 309556.686416768003255 ], [ 1996512.335807487834245, 309487.664192512223963 ], [ 1996440.981818896485493, 309375.0 ], [ 1996125.0, 309375.0 ], [ 1996125.0, 309125.0 ], [ 1995875.0, 309125.0 ], [ 1995875.0, 309375.0 ], [ 1995625.0, 309375.0 ], [ 1995375.0, 309375.0 ], [ 1995125.0, 309375.0 ], [ 1994875.0, 309375.0 ], [ 1994875.0, 309625.0 ], [ 1994625.0, 309625.0 ], [ 1994375.0, 309625.0 ], [ 1994125.0, 309625.0 ], [ 1993875.0, 309625.0 ], [ 1993875.0, 309375.0 ], [ 1993625.0, 309375.0 ], [ 1993375.0, 309375.0 ], [ 1993375.0, 309125.0 ], [ 1993375.0, 308875.0 ], [ 1993375.0, 308625.0 ], [ 1993375.0, 308375.0 ], [ 1993375.0, 308125.0 ], [ 1993125.0, 308125.0 ], [ 1993125.0, 307875.0 ], [ 1993125.0, 307625.0 ], [ 1993125.0, 307375.0 ], [ 1993125.0, 307125.0 ], [ 1993125.0, 306875.0 ], [ 1992875.0, 306875.0 ], [ 1992875.0, 306625.0 ], [ 1992625.0, 306625.0 ], [ 1992625.0, 306375.0 ], [ 1992625.0, 306125.0 ], [ 1992375.0, 306125.0 ], [ 1992125.0, 306125.0 ], [ 1992125.0, 305875.0 ], [ 1992125.0, 305625.0 ], [ 1991875.0, 305625.0 ], [ 1991875.0, 305375.0 ], [ 1991625.0, 305375.0 ], [ 1991375.0, 305375.0 ], [ 1991375.0, 305125.0 ], [ 1991125.0, 305125.0 ], [ 1991125.0, 304875.0 ], [ 1990875.0, 304875.0 ], [ 1990875.0, 304625.0 ], [ 1990625.0, 304625.0 ], [ 1990625.0, 304375.0 ], [ 1990375.0, 304375.0 ], [ 1990125.0, 304375.0 ], [ 1990125.0, 304125.0 ], [ 1989875.0, 304125.0 ], [ 1989875.0, 303875.0 ], [ 1989625.0, 303875.0 ], [ 1989625.0, 303625.0 ], [ 1989375.0, 303625.0 ], [ 1989125.0, 303625.0 ], [ 1989125.0, 303375.0 ], [ 1988875.0, 303375.0 ], [ 1988875.0, 303125.0 ], [ 1988625.0, 303125.0 ], [ 1988375.0, 303125.0 ], [ 1988375.0, 302875.0 ], [ 1988125.0, 302875.0 ], [ 1988125.0, 302625.0 ], [ 1987875.0, 302625.0 ], [ 1987875.0, 302375.0 ], [ 1987625.0, 302375.0 ], [ 1987375.0, 302375.0 ], [ 1987375.0, 302125.0 ], [ 1987125.0, 302125.0 ], [ 1987125.0, 301875.0 ], [ 1986875.0, 301875.0 ], [ 1986875.0, 301625.0 ], [ 1986625.0, 301625.0 ], [ 1986625.0, 301375.0 ], [ 1986375.0, 301375.0 ], [ 1986125.0, 301375.0 ], [ 1986125.0, 301125.0 ], [ 1985875.0, 301125.0 ], [ 1985875.0, 300875.0 ], [ 1985625.0, 300875.0 ], [ 1985625.0, 300625.0 ], [ 1985375.0, 300625.0 ], [ 1985375.0, 300375.0 ], [ 1985125.0, 300375.0 ], [ 1984875.0, 300375.0 ], [ 1984875.0, 300125.0 ], [ 1984625.0, 300125.0 ], [ 1984625.0, 299875.0 ], [ 1984375.0, 299875.0 ], [ 1984375.0, 299625.0 ], [ 1984125.0, 299625.0 ], [ 1984125.0, 299375.0 ], [ 1983875.0, 299375.0 ], [ 1983875.0, 299125.0 ], [ 1983625.0, 299125.0 ], [ 1983625.0, 298875.0 ], [ 1983375.0, 298875.0 ], [ 1983375.0, 298625.0 ], [ 1983125.0, 298625.0 ], [ 1982875.0, 298625.0 ], [ 1982625.0, 298625.0 ], [ 1982625.0, 298375.0 ], [ 1982625.0, 298125.0 ], [ 1982375.0, 298125.0 ], [ 1982375.0, 297875.0 ], [ 1982125.0, 297875.0 ], [ 1981875.0, 297875.0 ], [ 1981875.0, 298125.0 ], [ 1981625.0, 298125.0 ], [ 1981625.0, 297875.0 ], [ 1981375.0, 297875.0 ], [ 1981125.0, 297875.0 ], [ 1981125.0, 297625.0 ], [ 1980875.0, 297625.0 ], [ 1980875.0, 297375.0 ], [ 1980625.0, 297375.0 ], [ 1980625.0, 297125.0 ], [ 1980625.0, 296875.0 ], [ 1980375.0, 296875.0 ], [ 1980375.0, 296625.0 ], [ 1980125.0, 296625.0 ], [ 1979875.0, 296625.0 ], [ 1979875.0, 296375.0 ], [ 1979625.0, 296375.0 ], [ 1979625.0, 296125.0 ], [ 1979375.0, 296125.0 ], [ 1979375.0, 295875.0 ], [ 1979125.0, 295875.0 ], [ 1979125.0, 295625.0 ], [ 1979125.0, 295375.0 ], [ 1978875.0, 295375.0 ], [ 1978625.0, 295375.0 ], [ 1978625.0, 295125.0 ], [ 1978375.0, 295125.0 ], [ 1978375.0, 294875.0 ], [ 1978125.0, 294875.0 ], [ 1978125.0, 294625.0 ], [ 1977875.0, 294625.0 ], [ 1977875.0, 294375.0 ], [ 1977875.0, 294125.0 ], [ 1977625.0, 294125.0 ], [ 1977375.0, 294125.0 ], [ 1977125.0, 294125.0 ], [ 1977125.0, 293875.0 ], [ 1976875.0, 293875.0 ], [ 1976625.0, 293875.0 ], [ 1976375.0, 293875.0 ], [ 1976125.0, 293875.0 ], [ 1975875.0, 293875.0 ], [ 1975875.0, 293625.0 ], [ 1975625.0, 293625.0 ], [ 1975375.0, 293625.0 ], [ 1975125.0, 293625.0 ], [ 1974875.0, 293625.0 ], [ 1974625.0, 293625.0 ], [ 1974375.0, 293625.0 ], [ 1974125.0, 293625.0 ], [ 1973875.0, 293625.0 ], [ 1973625.0, 293625.0 ], [ 1973625.0, 293375.0 ], [ 1973375.0, 293375.0 ], [ 1973125.0, 293375.0 ], [ 1973125.0, 293625.0 ], [ 1972875.0, 293625.0 ], [ 1972625.0, 293625.0 ], [ 1972375.0, 293625.0 ], [ 1972125.0, 293625.0 ], [ 1971875.0, 293625.0 ], [ 1971875.0, 293875.0 ], [ 1971625.0, 293875.0 ], [ 1971625.0, 294125.0 ], [ 1971375.0, 294125.0 ], [ 1971125.0, 294125.0 ], [ 1970875.0, 294125.0 ], [ 1970875.0, 294375.0 ], [ 1970625.0, 294375.0 ], [ 1970625.0, 294625.0 ], [ 1970375.0, 294625.0 ], [ 1970375.0, 294875.0 ], [ 1970375.0, 295125.0 ], [ 1970125.0, 295125.0 ], [ 1970125.0, 294875.0 ], [ 1969875.0, 294875.0 ], [ 1969875.0, 295125.0 ], [ 1969625.0, 295125.0 ], [ 1969375.0, 295125.0 ], [ 1969375.0, 294875.0 ], [ 1969375.0, 294625.0 ], [ 1969125.0, 294625.0 ], [ 1969125.0, 294375.0 ], [ 1968875.0, 294375.0 ], [ 1968875.0, 294125.0 ], [ 1968625.0, 294125.0 ], [ 1968625.0, 293875.0 ], [ 1968375.0, 293875.0 ], [ 1968375.0, 294125.0 ], [ 1968375.0, 294375.0 ], [ 1968375.0, 294625.0 ], [ 1968239.674949259730056, 294760.325050740211736 ], [ 1968304.760731272865087, 294875.0 ], [ 1968511.22667340002954, 295238.773326600086875 ], [ 1968588.544515060260892, 295375.0 ], [ 1968782.778397540096194, 295717.221602459903806 ], [ 1968886.801205229945481, 295900.49988267297158 ], [ 1969125.0, 295940.872559752839152 ], [ 1969375.0, 295983.245441108942032 ], [ 1969625.0, 296025.618322465044912 ], [ 1969709.978535863105208, 296040.021464136836585 ], [ 1970125.0, 296110.364085177250672 ], [ 1970125.0, 295875.0 ], [ 1969875.0, 295875.0 ], [ 1969875.0, 295625.0 ], [ 1970125.0, 295625.0 ], [ 1970125.0, 295375.0 ], [ 1970375.0, 295375.0 ], [ 1970625.0, 295375.0 ], [ 1970875.0, 295375.0 ], [ 1971125.0, 295375.0 ], [ 1971375.0, 295375.0 ], [ 1971375.0, 295625.0 ], [ 1971625.0, 295625.0 ], [ 1971875.0, 295625.0 ], [ 1971875.0, 295875.0 ], [ 1972125.0, 295875.0 ], [ 1972375.0, 295875.0 ], [ 1972375.0, 296125.0 ], [ 1972625.0, 296125.0 ], [ 1972875.0, 296125.0 ], [ 1973125.0, 296125.0 ], [ 1973125.0, 296375.0 ], [ 1973375.0, 296375.0 ], [ 1973625.0, 296375.0 ], [ 1973625.0, 296625.0 ], [ 1973875.0, 296625.0 ], [ 1973875.0, 296375.0 ], [ 1974125.0, 296375.0 ], [ 1974375.0, 296375.0 ], [ 1974625.0, 296375.0 ], [ 1974625.0, 296125.0 ], [ 1974875.0, 296125.0 ], [ 1975125.0, 296125.0 ], [ 1975375.0, 296125.0 ], [ 1975625.0, 296125.0 ], [ 1975625.0, 295875.0 ], [ 1975875.0, 295875.0 ], [ 1976125.0, 295875.0 ], [ 1976125.0, 295625.0 ], [ 1975875.0, 295625.0 ], [ 1975875.0, 295375.0 ], [ 1975875.0, 295125.0 ], [ 1976125.0, 295125.0 ], [ 1976375.0, 295125.0 ], [ 1976375.0, 295375.0 ], [ 1976625.0, 295375.0 ], [ 1976625.0, 295625.0 ], [ 1976875.0, 295625.0 ], [ 1976875.0, 295875.0 ], [ 1976875.0, 296125.0 ], [ 1977125.0, 296125.0 ], [ 1977125.0, 296375.0 ], [ 1977375.0, 296375.0 ], [ 1977625.0, 296375.0 ], [ 1977625.0, 296625.0 ], [ 1977875.0, 296625.0 ], [ 1977875.0, 296875.0 ], [ 1978125.0, 296875.0 ], [ 1978125.0, 297125.0 ], [ 1977875.0, 297125.0 ], [ 1977875.0, 297375.0 ], [ 1977875.0, 297625.0 ], [ 1977875.0, 297875.0 ], [ 1978125.0, 297875.0 ], [ 1978375.0, 297875.0 ], [ 1978375.0, 297625.0 ], [ 1978625.0, 297625.0 ], [ 1978875.0, 297625.0 ], [ 1979125.0, 297625.0 ], [ 1979125.0, 297875.0 ], [ 1979125.0, 298125.0 ], [ 1979375.0, 298125.0 ], [ 1979375.0, 298375.0 ], [ 1979625.0, 298375.0 ], [ 1979875.0, 298375.0 ], [ 1979875.0, 298625.0 ], [ 1979875.0, 298875.0 ], [ 1980125.0, 298875.0 ], [ 1980125.0, 299125.0 ], [ 1979875.0, 299125.0 ], [ 1979625.0, 299125.0 ], [ 1979375.0, 299125.0 ], [ 1979375.0, 299375.0 ], [ 1979125.0, 299375.0 ], [ 1978875.0, 299375.0 ], [ 1978875.0, 299625.0 ], [ 1978625.0, 299625.0 ], [ 1978375.0, 299625.0 ], [ 1978214.142584908287972, 299785.857415091595612 ], [ 1978234.099880037130788, 299875.0 ], [ 1978290.070029290858656, 300125.0 ], [ 1978625.0, 300125.0 ], [ 1978875.0, 300125.0 ], [ 1979125.0, 300125.0 ], [ 1979375.0, 300125.0 ], [ 1979375.0, 300375.0 ], [ 1979625.0, 300375.0 ], [ 1979875.0, 300375.0 ], [ 1980125.0, 300375.0 ], [ 1980375.0, 300375.0 ], [ 1980375.0, 300625.0 ], [ 1980625.0, 300625.0 ], [ 1980625.0, 300875.0 ], [ 1980625.0, 301125.0 ], [ 1980875.0, 301125.0 ], [ 1980875.0, 301375.0 ], [ 1981125.0, 301375.0 ], [ 1981125.0, 301625.0 ], [ 1981125.0, 301875.0 ], [ 1981375.0, 301875.0 ], [ 1981625.0, 301875.0 ], [ 1981875.0, 301875.0 ], [ 1982125.0, 301875.0 ], [ 1982125.0, 301625.0 ], [ 1982125.0, 301375.0 ], [ 1981875.0, 301375.0 ], [ 1981625.0, 301375.0 ], [ 1981625.0, 301125.0 ], [ 1981625.0, 300875.0 ], [ 1981375.0, 300875.0 ], [ 1981375.0, 300625.0 ], [ 1981375.0, 300375.0 ], [ 1981375.0, 300125.0 ], [ 1981625.0, 300125.0 ], [ 1981875.0, 300125.0 ] ], [ [ 2081625.0, 364875.0 ], [ 2081625.0, 365125.0 ], [ 2081375.0, 365125.0 ], [ 2081375.0, 364875.0 ], [ 2081375.0, 364625.0 ], [ 2081625.0, 364625.0 ], [ 2081625.0, 364875.0 ] ], [ [ 2068125.0, 356375.0 ], [ 2068375.0, 356375.0 ], [ 2068375.0, 356625.0 ], [ 2068125.0, 356625.0 ], [ 2068125.0, 356375.0 ] ], [ [ 2081125.0, 365875.0 ], [ 2081125.0, 365625.0 ], [ 2081375.0, 365625.0 ], [ 2081375.0, 365875.0 ], [ 2081125.0, 365875.0 ] ], [ [ 2081125.0, 366125.0 ], [ 2080875.0, 366125.0 ], [ 2080875.0, 365875.0 ], [ 2081125.0, 365875.0 ], [ 2081125.0, 366125.0 ] ], [ [ 2080375.0, 365375.0 ], [ 2080625.0, 365375.0 ], [ 2080625.0, 365625.0 ], [ 2080375.0, 365625.0 ], [ 2080375.0, 365375.0 ] ], [ [ 2000375.0, 317875.0 ], [ 2000125.0, 317875.0 ], [ 2000125.0, 317625.0 ], [ 1999875.0, 317625.0 ], [ 1999875.0, 317375.0 ], [ 1999875.0, 317125.0 ], [ 1999625.0, 317125.0 ], [ 1999375.0, 317125.0 ], [ 1999375.0, 316875.0 ], [ 1999125.0, 316875.0 ], [ 1998875.0, 316875.0 ], [ 1998875.0, 316625.0 ], [ 1998625.0, 316625.0 ], [ 1998625.0, 316375.0 ], [ 1998625.0, 316125.0 ], [ 1998625.0, 315875.0 ], [ 1998875.0, 315875.0 ], [ 1998875.0, 315625.0 ], [ 1998625.0, 315625.0 ], [ 1998625.0, 315375.0 ], [ 1998375.0, 315375.0 ], [ 1998375.0, 315625.0 ], [ 1998375.0, 315875.0 ], [ 1998375.0, 316125.0 ], [ 1998375.0, 316375.0 ], [ 1998125.0, 316375.0 ], [ 1997875.0, 316375.0 ], [ 1997875.0, 316125.0 ], [ 1997875.0, 315875.0 ], [ 1997625.0, 315875.0 ], [ 1997625.0, 315625.0 ], [ 1997625.0, 315375.0 ], [ 1997375.0, 315375.0 ], [ 1997375.0, 315125.0 ], [ 1997375.0, 314875.0 ], [ 1997375.0, 314625.0 ], [ 1997125.0, 314625.0 ], [ 1996875.0, 314625.0 ], [ 1996875.0, 314375.0 ], [ 1997125.0, 314375.0 ], [ 1997375.0, 314375.0 ], [ 1997625.0, 314375.0 ], [ 1997875.0, 314375.0 ], [ 1998125.0, 314375.0 ], [ 1998375.0, 314375.0 ], [ 1998625.0, 314375.0 ], [ 1998875.0, 314375.0 ], [ 1998875.0, 314625.0 ], [ 1999125.0, 314625.0 ], [ 1999125.0, 314875.0 ], [ 1999375.0, 314875.0 ], [ 1999375.0, 315125.0 ], [ 1999625.0, 315125.0 ], [ 1999625.0, 315375.0 ], [ 1999875.0, 315375.0 ], [ 1999875.0, 315625.0 ], [ 2000125.0, 315625.0 ], [ 2000125.0, 315875.0 ], [ 2000125.0, 316125.0 ], [ 2000375.0, 316125.0 ], [ 2000375.0, 316375.0 ], [ 2000625.0, 316375.0 ], [ 2000625.0, 316625.0 ], [ 2000875.0, 316625.0 ], [ 2000875.0, 316875.0 ], [ 2001125.0, 316875.0 ], [ 2001125.0, 317125.0 ], [ 2001375.0, 317125.0 ], [ 2001375.0, 317375.0 ], [ 2001375.0, 317625.0 ], [ 2001375.0, 317875.0 ], [ 2001375.0, 318125.0 ], [ 2001125.0, 318125.0 ], [ 2001125.0, 317875.0 ], [ 2000875.0, 317875.0 ], [ 2000875.0, 318125.0 ], [ 2000625.0, 318125.0 ], [ 2000625.0, 317875.0 ], [ 2000375.0, 317875.0 ] ], [ [ 2001375.0, 318625.0 ], [ 2001375.0, 318375.0 ], [ 2001625.0, 318375.0 ], [ 2001625.0, 318625.0 ], [ 2001375.0, 318625.0 ] ], [ [ 2005125.0, 321375.0 ], [ 2005375.0, 321375.0 ], [ 2005375.0, 321625.0 ], [ 2005625.0, 321625.0 ], [ 2005625.0, 321875.0 ], [ 2005875.0, 321875.0 ], [ 2005875.0, 322125.0 ], [ 2005875.0, 322361.554269636981189 ], [ 2005951.030115525936708, 322384.202294588496443 ], [ 2006132.449795989319682, 322221.120999313541688 ], [ 2006220.382, 322395.3335 ], [ 2006411.373, 322194.9804 ], [ 2006583.639, 322015.2244 ], [ 2006777.156816202681512, 321818.271713803464081 ], [ 2006900.085, 321693.1616 ], [ 2006975.777212957851589, 321614.801813868223689 ], [ 2007148.71354650054127, 321435.770793618052267 ], [ 2007289.698470945237204, 321629.262140740000177 ], [ 2007375.0, 321686.510160959267523 ], [ 2007375.0, 321875.0 ], [ 2007625.0, 321875.0 ], [ 2007625.0, 322125.0 ], [ 2007875.0, 322125.0 ], [ 2007875.0, 322375.0 ], [ 2008125.0, 322375.0 ], [ 2008375.0, 322375.0 ], [ 2008625.0, 322375.0 ], [ 2008625.0, 322625.0 ], [ 2008625.0, 322875.0 ], [ 2008875.0, 322875.0 ], [ 2008875.0, 323125.0 ], [ 2009125.0, 323125.0 ], [ 2009125.0, 323375.0 ], [ 2009125.0, 323625.0 ], [ 2009375.0, 323625.0 ], [ 2009375.0, 323875.0 ], [ 2009375.0, 324125.0 ], [ 2009125.0, 324125.0 ], [ 2009125.0, 324375.0 ], [ 2009125.0, 324625.0 ], [ 2008875.0, 324625.0 ], [ 2008875.0, 324875.0 ], [ 2008625.0, 324875.0 ], [ 2008625.0, 325125.0 ], [ 2008375.0, 325125.0 ], [ 2008125.0, 325125.0 ], [ 2008125.0, 324875.0 ], [ 2007875.0, 324875.0 ], [ 2007625.0, 324875.0 ], [ 2007625.0, 324625.0 ], [ 2007375.0, 324625.0 ], [ 2007375.0, 324375.0 ], [ 2007125.0, 324375.0 ], [ 2006875.0, 324375.0 ], [ 2006625.0, 324375.0 ], [ 2006625.0, 324125.0 ], [ 2006625.0, 323875.0 ], [ 2006375.0, 323875.0 ], [ 2006375.0, 323625.0 ], [ 2006375.0, 323375.0 ], [ 2006125.0, 323375.0 ], [ 2006125.0, 323125.0 ], [ 2006125.0, 322874.713643411407247 ], [ 2006060.660845221951604, 322854.279157310607843 ], [ 2005890.83, 322726.7586 ], [ 2005823.255498570390046, 322591.415552785329055 ], [ 2005853.200009249150753, 322375.0 ], [ 2005625.0, 322375.0 ], [ 2005625.0, 322125.0 ], [ 2005375.0, 322125.0 ], [ 2005125.0, 322125.0 ], [ 2005125.0, 321875.0 ], [ 2004875.0, 321875.0 ], [ 2004625.0, 321875.0 ], [ 2004625.0, 321625.0 ], [ 2004375.0, 321625.0 ], [ 2004375.0, 321375.0 ], [ 2004125.0, 321375.0 ], [ 2004125.0, 321125.0 ], [ 2003875.0, 321125.0 ], [ 2003875.0, 320875.0 ], [ 2003625.0, 320875.0 ], [ 2003625.0, 320625.0 ], [ 2003375.0, 320625.0 ], [ 2003375.0, 320375.0 ], [ 2003125.0, 320375.0 ], [ 2003125.0, 320125.0 ], [ 2003375.0, 320125.0 ], [ 2003625.0, 320125.0 ], [ 2003875.0, 320125.0 ], [ 2003875.0, 320375.0 ], [ 2004125.0, 320375.0 ], [ 2004125.0, 320625.0 ], [ 2004375.0, 320625.0 ], [ 2004375.0, 320875.0 ], [ 2004625.0, 320875.0 ], [ 2004875.0, 320875.0 ], [ 2004875.0, 321125.0 ], [ 2004875.0, 321375.0 ], [ 2005125.0, 321375.0 ] ], [ [ 2005156.825999999884516, 323118.102399999974295 ], [ 2005265.429, 323086.270599999988917 ], [ 2005352.183974175946787, 323250.94473008584464 ], [ 2005344.927198968362063, 323344.927198968245648 ], [ 2005125.0, 323380.201065170695074 ], [ 2005108.617624151753262, 323367.808860811113846 ], [ 2004965.835, 323153.6791 ], [ 2005156.825999999884516, 323118.102399999974295 ] ], [ [ 2061125.0, 355125.0 ], [ 2060875.0, 355125.0 ], [ 2060875.0, 354875.0 ], [ 2060875.0, 354625.0 ], [ 2060875.0, 354375.0 ], [ 2061125.0, 354375.0 ], [ 2061125.0, 354125.0 ], [ 2061125.0, 353875.0 ], [ 2061375.0, 353875.0 ], [ 2061375.0, 353625.0 ], [ 2061625.0, 353625.0 ], [ 2061875.0, 353625.0 ], [ 2062125.0, 353625.0 ], [ 2062375.0, 353625.0 ], [ 2062625.0, 353625.0 ], [ 2062875.0, 353625.0 ], [ 2062875.0, 353875.0 ], [ 2063125.0, 353875.0 ], [ 2063375.0, 353875.0 ], [ 2063625.0, 353875.0 ], [ 2063875.0, 353875.0 ], [ 2064125.0, 353875.0 ], [ 2064375.0, 353875.0 ], [ 2064625.0, 353875.0 ], [ 2064625.0, 353625.0 ], [ 2064875.0, 353625.0 ], [ 2065125.0, 353625.0 ], [ 2065125.0, 353875.0 ], [ 2065375.0, 353875.0 ], [ 2065625.0, 353875.0 ], [ 2065625.0, 354125.0 ], [ 2065875.0, 354125.0 ], [ 2065875.0, 354375.0 ], [ 2065625.0, 354375.0 ], [ 2065625.0, 354625.0 ], [ 2065625.0, 354875.0 ], [ 2065625.0, 355125.0 ], [ 2065625.0, 355375.0 ], [ 2065375.0, 355375.0 ], [ 2065375.0, 355625.0 ], [ 2065125.0, 355625.0 ], [ 2065125.0, 355875.0 ], [ 2064875.0, 355875.0 ], [ 2064875.0, 356125.0 ], [ 2064625.0, 356125.0 ], [ 2064375.0, 356125.0 ], [ 2064125.0, 356125.0 ], [ 2063875.0, 356125.0 ], [ 2063875.0, 355875.0 ], [ 2064125.0, 355875.0 ], [ 2064125.0, 355625.0 ], [ 2064375.0, 355625.0 ], [ 2064625.0, 355625.0 ], [ 2064625.0, 355375.0 ], [ 2064875.0, 355375.0 ], [ 2064875.0, 355125.0 ], [ 2065125.0, 355125.0 ], [ 2065125.0, 354875.0 ], [ 2064875.0, 354875.0 ], [ 2064625.0, 354875.0 ], [ 2064375.0, 354875.0 ], [ 2064125.0, 354875.0 ], [ 2063875.0, 354875.0 ], [ 2063625.0, 354875.0 ], [ 2063625.0, 354625.0 ], [ 2063375.0, 354625.0 ], [ 2063125.0, 354625.0 ], [ 2062875.0, 354625.0 ], [ 2062625.0, 354625.0 ], [ 2062625.0, 354875.0 ], [ 2062375.0, 354875.0 ], [ 2062375.0, 355125.0 ], [ 2062375.0, 355375.0 ], [ 2062375.0, 355625.0 ], [ 2062375.0, 355875.0 ], [ 2062375.0, 356125.0 ], [ 2062375.0, 356375.0 ], [ 2062375.0, 356625.0 ], [ 2062125.0, 356625.0 ], [ 2061875.0, 356625.0 ], [ 2061875.0, 356375.0 ], [ 2061625.0, 356375.0 ], [ 2061375.0, 356375.0 ], [ 2061375.0, 356125.0 ], [ 2061375.0, 355875.0 ], [ 2061125.0, 355875.0 ], [ 2061125.0, 355625.0 ], [ 2061125.0, 355375.0 ], [ 2061125.0, 355125.0 ] ], [ [ 2066875.0, 356375.0 ], [ 2066625.0, 356375.0 ], [ 2066625.0, 356125.0 ], [ 2066875.0, 356125.0 ], [ 2066875.0, 356375.0 ] ] ], [ [ [ 2008625.0, 333125.0 ], [ 2008625.0, 332875.0 ], [ 2008375.0, 332875.0 ], [ 2008375.0, 333125.0 ], [ 2008375.0, 333375.0 ], [ 2008625.0, 333375.0 ], [ 2008625.0, 333125.0 ] ] ], [ [ [ 2009625.0, 333625.0 ], [ 2009625.0, 333375.0 ], [ 2009375.0, 333375.0 ], [ 2009375.0, 333125.0 ], [ 2009375.0, 332875.0 ], [ 2009125.0, 332875.0 ], [ 2009125.0, 333125.0 ], [ 2009125.0, 333375.0 ], [ 2009125.0, 333625.0 ], [ 2009375.0, 333625.0 ], [ 2009625.0, 333625.0 ] ] ], [ [ [ 2004375.0, 336375.0 ], [ 2004625.0, 336375.0 ], [ 2004875.0, 336375.0 ], [ 2004875.0, 336125.0 ], [ 2004625.0, 336125.0 ], [ 2004455.95006786310114, 335955.950067863217555 ], [ 2004375.0, 335992.955813172273338 ], [ 2004375.0, 336375.0 ] ] ], [ [ [ 2003246.088069938356057, 337753.911930061702151 ], [ 2003625.0, 337902.992033692600671 ], [ 2003625.0, 337625.0 ], [ 2003625.0, 337375.0 ], [ 2003375.0, 337375.0 ], [ 2003375.0, 337625.0 ], [ 2003246.088069938356057, 337753.911930061702151 ] ] ], [ [ [ 2048125.0, 333491.750577958940994 ], [ 2048125.0, 333875.0 ], [ 2048375.0, 333875.0 ], [ 2048375.0, 333476.750577958999202 ], [ 2048125.0, 333491.750577958940994 ] ] ], [ [ [ 2046252.791298779891804, 335736.270857280003838 ], [ 2046259.751744923647493, 335740.248255076410715 ], [ 2046375.0, 335625.0 ], [ 2046375.0, 335375.0 ], [ 2046625.0, 335375.0 ], [ 2046625.0, 335625.0 ], [ 2046875.0, 335625.0 ], [ 2046875.0, 335875.0 ], [ 2047125.0, 335875.0 ], [ 2047375.0, 335875.0 ], [ 2047737.973404365358874, 335875.0 ], [ 2047722.039358329959214, 335829.853536232025363 ], [ 2047534.874000420095399, 335652.04644622298656 ], [ 2047506.799196739913896, 335521.030695690016728 ], [ 2047513.270180029096082, 335500.0 ], [ 2047581.665339899947867, 335277.715730414027348 ], [ 2047681.691049345536157, 335181.691049345594365 ], [ 2047815.622037279885262, 335053.117300927988254 ], [ 2047945.164908360224217, 334945.164908360282425 ], [ 2048217.892181086586788, 334717.892181086703204 ], [ 2048433.267718360060826, 334538.412566690996755 ], [ 2048500.0, 334532.85154322150629 ], [ 2048500.0, 334500.0 ], [ 2048375.0, 334375.0 ], [ 2048125.0, 334375.0 ], [ 2048125.0, 334625.0 ], [ 2047875.0, 334625.0 ], [ 2047625.0, 334625.0 ], [ 2047625.0, 334375.0 ], [ 2047375.0, 334375.0 ], [ 2047375.0, 334625.0 ], [ 2047375.0, 334875.0 ], [ 2047125.0, 334875.0 ], [ 2047125.0, 334625.0 ], [ 2046875.0, 334625.0 ], [ 2046875.0, 334375.0 ], [ 2047125.0, 334375.0 ], [ 2047125.0, 334125.0 ], [ 2047125.0, 333776.929423133609816 ], [ 2047104.393677240004763, 333789.751135073020123 ], [ 2046754.47435533371754, 334004.474355333659332 ], [ 2046692.629889850039035, 334042.424368244013749 ], [ 2046625.0, 334030.662648270372301 ], [ 2046492.398484806297347, 334007.601515193702653 ], [ 2046477.389728259993717, 334004.991296663996764 ], [ 2046228.662012284621596, 333771.337987715494819 ], [ 2046125.0, 333875.0 ], [ 2045875.0, 333875.0 ], [ 2045625.0, 333875.0 ], [ 2045625.0, 333549.322385145525914 ], [ 2045375.0, 333574.322385145002045 ], [ 2045373.114116620039567, 333574.510973482974805 ], [ 2045125.0, 333582.14525399467675 ], [ 2044875.0, 333589.837561687338166 ], [ 2044764.826703439932317, 333593.227509273972828 ], [ 2044625.0, 333544.825958084082231 ], [ 2044625.0, 333875.0 ], [ 2044625.0, 334125.0 ], [ 2044875.0, 334125.0 ], [ 2044875.0, 334375.0 ], [ 2045125.0, 334375.0 ], [ 2045375.0, 334375.0 ], [ 2045375.0, 334625.0 ], [ 2045625.0, 334625.0 ], [ 2045625.0, 334875.0 ], [ 2045875.0, 334875.0 ], [ 2045875.0, 335125.0 ], [ 2045875.0, 335375.0 ], [ 2046125.0, 335375.0 ], [ 2046125.0, 335625.0 ], [ 2046239.942066502058879, 335739.942066502058879 ], [ 2046252.791298779891804, 335736.270857280003838 ] ], [ [ 2046875.0, 334875.0 ], [ 2046875.0, 335125.0 ], [ 2046625.0, 335125.0 ], [ 2046625.0, 334875.0 ], [ 2046625.0, 334625.0 ], [ 2046875.0, 334625.0 ], [ 2046875.0, 334875.0 ] ], [ [ 2045625.0, 334125.0 ], [ 2045375.0, 334125.0 ], [ 2045125.0, 334125.0 ], [ 2045125.0, 333875.0 ], [ 2045375.0, 333875.0 ], [ 2045625.0, 333875.0 ], [ 2045625.0, 334125.0 ] ], [ [ 2046125.0, 335125.0 ], [ 2046125.0, 334875.0 ], [ 2046375.0, 334875.0 ], [ 2046375.0, 335125.0 ], [ 2046125.0, 335125.0 ] ] ], [ [ [ 2044025.523539710091427, 338758.991387435991783 ], [ 2044222.047165510011837, 338749.633119540987536 ], [ 2044278.1967728799209, 338646.692172694019973 ], [ 2044193.972361830063164, 338515.676422160991933 ], [ 2043838.358181810006499, 338412.735475312976632 ], [ 2043625.0, 338306.056384409370366 ], [ 2043625.0, 338665.145386123040225 ], [ 2043744.775502860080451, 338712.200047959981021 ], [ 2044025.523539710091427, 338758.991387435991783 ] ] ], [ [ [ 2024597.759389230050147, 340856.255727335985284 ], [ 2024532.251513970084488, 341005.988013660011347 ], [ 2024575.095829048892483, 341125.0 ], [ 2024616.475925019942224, 341239.94471104000695 ], [ 2024784.924747139913961, 341417.751801048987545 ], [ 2024875.0, 341459.324994679889642 ], [ 2024906.582229770021513, 341473.901408420992084 ], [ 2025018.881444520084187, 341427.110068944981322 ], [ 2025224.763338210061193, 341258.661246831004974 ], [ 2025242.967770617455244, 341242.967770617571659 ], [ 2025125.0, 341125.0 ], [ 2025125.0, 340875.0 ], [ 2024973.459618293214589, 340723.459618293156382 ], [ 2024875.0, 340770.720235074171796 ], [ 2024794.283015029970556, 340809.464387859974522 ], [ 2024597.759389230050147, 340856.255727335985284 ] ] ], [ [ [ 2039875.0, 344125.0 ], [ 2039875.0, 344375.0 ], [ 2040125.0, 344375.0 ], [ 2040125.0, 344125.0 ], [ 2039875.0, 344125.0 ] ] ], [ [ [ 2029031.68183714337647, 344375.0 ], [ 2029005.503567880019546, 344412.397527520020958 ], [ 2029033.578371569979936, 344590.204617529991083 ], [ 2029164.59412209992297, 344739.936903853027616 ], [ 2029248.818533160025254, 344796.086511224973947 ], [ 2029375.0, 344729.284558192535769 ], [ 2029407.909087379928678, 344711.862100168014877 ], [ 2029625.0, 344644.489058320061304 ], [ 2029625.0, 344375.0 ], [ 2029375.0, 344375.0 ], [ 2029375.0, 344125.0 ], [ 2029292.459090777207166, 344042.459090777207166 ], [ 2029286.251604740042239, 344047.425079606997315 ], [ 2029136.51931840996258, 344225.232169615977909 ], [ 2029031.68183714337647, 344375.0 ] ] ], [ [ [ 2047375.0, 358375.0 ], [ 2047375.0, 358625.0 ], [ 2047375.0, 358875.0 ], [ 2047125.0, 358875.0 ], [ 2047125.0, 359125.0 ], [ 2047125.0, 359375.0 ], [ 2047375.0, 359375.0 ], [ 2047375.0, 359625.0 ], [ 2047375.0, 359875.0 ], [ 2047625.0, 359875.0 ], [ 2047625.0, 360125.0 ], [ 2047625.0, 360375.0 ], [ 2047875.0, 360375.0 ], [ 2047875.0, 360625.0 ], [ 2047875.0, 360875.0 ], [ 2047875.0, 361125.0 ], [ 2047625.0, 361125.0 ], [ 2047625.0, 361375.0 ], [ 2047375.0, 361375.0 ], [ 2047375.0, 361125.0 ], [ 2047125.0, 361125.0 ], [ 2046875.0, 361125.0 ], [ 2046875.0, 361375.0 ], [ 2046625.0, 361375.0 ], [ 2046625.0, 361625.0 ], [ 2046625.0, 361875.0 ], [ 2046625.0, 362125.0 ], [ 2046625.0, 362375.0 ], [ 2046625.0, 362625.0 ], [ 2046375.0, 362625.0 ], [ 2046375.0, 362906.344871860928833 ], [ 2046625.0, 362929.600685814453755 ], [ 2046875.0, 362952.856499767920468 ], [ 2047125.0, 362976.112313721387181 ], [ 2047375.0, 362999.368127674912103 ], [ 2047460.007857260061428, 363007.275835326989181 ], [ 2047680.179382668575272, 362625.0 ], [ 2047751.378885387675837, 362501.378885387792252 ], [ 2047968.154066211078316, 362125.0 ], [ 2048025.475270928815007, 362025.475270928873215 ], [ 2048208.206194622907788, 361708.206194622965995 ], [ 2048311.610235719941556, 361528.669507881975733 ], [ 2048426.862366632325575, 361375.0 ], [ 2048511.778495218837634, 361261.778495218895841 ], [ 2048726.064209505682811, 360976.064209505624603 ], [ 2048940.349923792295158, 360690.349923792295158 ], [ 2049176.862366638379171, 360375.0 ], [ 2049261.778495222330093, 360261.778495222388301 ], [ 2049406.527579470071942, 360068.779716227028985 ], [ 2049490.703500043135136, 359990.703500043193344 ], [ 2049375.0, 359875.0 ], [ 2049375.0, 359625.0 ], [ 2049625.0, 359625.0 ], [ 2049625.0, 359375.0 ], [ 2049875.0, 359375.0 ], [ 2049875.0, 359125.0 ], [ 2049875.0, 358875.0 ], [ 2049875.0, 358625.0 ], [ 2049625.0, 358625.0 ], [ 2049375.0, 358625.0 ], [ 2049125.0, 358625.0 ], [ 2048875.0, 358625.0 ], [ 2048875.0, 358375.0 ], [ 2048875.0, 358125.0 ], [ 2048625.0, 358125.0 ], [ 2048625.0, 357875.0 ], [ 2048375.0, 357875.0 ], [ 2048375.0, 358125.0 ], [ 2048375.0, 358375.0 ], [ 2048125.0, 358375.0 ], [ 2048125.0, 358125.0 ], [ 2048125.0, 357875.0 ], [ 2047875.0, 357875.0 ], [ 2047875.0, 358125.0 ], [ 2047625.0, 358125.0 ], [ 2047625.0, 358375.0 ], [ 2047375.0, 358375.0 ] ] ], [ [ [ 2071375.0, 368947.085895284602884 ], [ 2071375.0, 368625.0 ], [ 2071125.0, 368625.0 ], [ 2071038.647045284276828, 368711.352954715664964 ], [ 2071248.724846909986809, 368893.626341421972029 ], [ 2071375.0, 368947.085895284602884 ] ] ] ] } },
{ "type": "Feature", "properties": { "classification": "pluvial", "mesh_name": "BaldEagleCr", "cell_id": 63, "area_acres": 65.757417196410884 }, "geometry": { "type": "MultiPolygon", "coordinates": [ [ [ [ 1969731.653768708230928, 289768.346231291885488 ], [ 1969588.437905200058594, 289578.114005430019461 ], [ 1969282.045979656279087, 289782.045979656279087 ], [ 1968981.852391151245683, 289981.852391151245683 ], [ 1968875.0, 290052.972473834874108 ], [ 1968531.562008393695578, 290281.562008393579163 ], [ 1968231.368419888429344, 290481.368419888545759 ], [ 1968125.0, 290552.166375235130545 ], [ 1967781.078037130879238, 290781.078037130879238 ], [ 1967480.884448625845835, 290980.884448625845835 ], [ 1967375.0, 291051.360276635328773 ], [ 1967030.594065868295729, 291280.594065868179314 ], [ 1966730.400477363029495, 291480.40047736314591 ], [ 1966625.0, 291550.55417803558521 ], [ 1966280.110094605479389, 291780.110094605479389 ], [ 1965981.774563469924033, 291978.679798224009573 ], [ 1966276.481022683903575, 292223.518977316096425 ], [ 1966549.587168198544532, 292450.412831801455468 ], [ 1966875.0, 292720.762558158952743 ], [ 1966875.0, 292375.0 ], [ 1967125.0, 292375.0 ], [ 1967125.0, 292625.0 ], [ 1967375.0, 292625.0 ], [ 1967375.0, 292875.0 ], [ 1967625.0, 292875.0 ], [ 1967625.0, 293125.0 ], [ 1967625.0, 293375.0 ], [ 1967875.0, 293375.0 ], [ 1968125.0, 293375.0 ], [ 1968375.0, 293375.0 ], [ 1968375.0, 293625.0 ], [ 1968375.0, 293875.0 ], [ 1968625.0, 293875.0 ], [ 1968625.0, 294125.0 ], [ 1968875.0, 294125.0 ], [ 1968875.0, 294375.0 ], [ 1969125.0, 294375.0 ], [ 1969125.0, 294625.0 ], [ 1969375.0, 294625.0 ], [ 1969375.0, 294875.0 ], [ 1969375.0, 295125.0 ], [ 1969625.0, 295125.0 ], [ 1969875.0, 295125.0 ], [ 1969875.0, 294875.0 ], [ 1970125.0, 294875.0 ], [ 1970125.0, 295125.0 ], [ 1970375.0, 295125.0 ], [ 1970375.0, 294875.0 ], [ 1970375.0, 294625.0 ], [ 1970625.0, 294625.0 ], [ 1970625.0, 294375.0 ], [ 1970875.0, 294375.0 ], [ 1970875.0, 294125.0 ], [ 1971125.0, 294125.0 ], [ 1971375.0, 294125.0 ], [ 1971625.0, 294125.0 ], [ 1971625.0, 293875.0 ], [ 1971875.0, 293875.0 ], [ 1971875.0, 293625.0 ], [ 1972125.0, 293625.0 ], [ 1972375.0, 293625.0 ], [ 1972625.0, 293625.0 ], [ 1972875.0, 293625.0 ], [ 1973125.0, 293625.0 ], [ 1973125.0, 293375.0 ], [ 1973375.0, 293375.0 ], [ 1973625.0, 293375.0 ], [ 1973625.0, 293625.0 ], [ 1973875.0, 293625.0 ], [ 1974125.0, 293625.0 ], [ 1974375.0, 293625.0 ], [ 1974625.0, 293625.0 ], [ 1974875.0, 293625.0 ], [ 1975125.0, 293625.0 ], [ 1975375.0, 293625.0 ], [ 1975625.0, 293625.0 ], [ 1975875.0, 293625.0 ], [ 1975875.0, 293875.0 ], [ 1976125.0, 293875.0 ], [ 1976375.0, 293875.0 ], [ 1976625.0, 293875.0 ], [ 1976875.0, 293875.0 ], [ 1977125.0, 293875.0 ], [ 1977125.0, 294125.0 ], [ 1977375.0, 294125.0 ], [ 1977625.0, 294125.0 ], [ 1977875.0, 294125.0 ], [ 1977875.0, 294375.0 ], [ 1977875.0, 294625.0 ], [ 1978125.0, 294625.0 ], [ 1978125.0, 294875.0 ], [ 1978375.0, 294875.0 ], [ 1978375.0, 295125.0 ], [ 1978625.0, 295125.0 ], [ 1978625.0, 295375.0 ], [ 1978875.0, 295375.0 ], [ 1979125.0, 295375.0 ], [ 1979125.0, 295625.0 ], [ 1979125.0, 295875.0 ], [ 1979375.0, 295875.0 ], [ 1979375.0, 296125.0 ], [ 1979625.0, 296125.0 ], [ 1979625.0, 296375.0 ], [ 1979875.0, 296375.0 ], [ 1979875.0, 296625.0 ], [ 1980125.0, 296625.0 ], [ 1980375.0, 296625.0 ], [ 1980375.0, 296375.0 ], [ 1980480.477373670320958, 296269.522626329620834 ], [ 1980196.693589886883274, 296053.306410113233142 ], [ 1979981.234249880071729, 295889.146912964992225 ], [ 1979875.0, 295790.239163076970726 ], [ 1979789.429719120729715, 295710.570280879270285 ], [ 1979530.501147691626102, 295469.498852308257483 ], [ 1979271.572576262755319, 295228.427423737244681 ], [ 1979012.644004833884537, 294987.355995166231878 ], [ 1979012.142206819960847, 294986.888803911977448 ], [ 1978745.992334429407492, 294754.0076655705343 ], [ 1978479.325667762663215, 294520.674332237278577 ], [ 1978212.659001095918939, 294287.340998904081061 ], [ 1977945.992334429174662, 294054.007665570825338 ], [ 1977675.463526739971712, 293817.294958842976484 ], [ 1977625.0, 293795.785914658743422 ], [ 1977505.253554089926183, 293744.746445910132024 ], [ 1977125.0, 293582.671160560392309 ], [ 1976979.39148512436077, 293520.608514875697438 ], [ 1976625.0, 293369.556406462041195 ], [ 1976375.0, 293262.999029412865639 ], [ 1976278.242059836862609, 293221.757940163079184 ], [ 1975875.0, 293049.884275314572733 ], [ 1975752.379990871297196, 292997.620009128586389 ], [ 1975637.02853962010704, 292948.45381679199636 ], [ 1975375.0, 292910.633214321394917 ], [ 1975375.0, 293125.0 ], [ 1975125.0, 293125.0 ], [ 1975125.0, 292874.548783856793307 ], [ 1974875.0, 292838.464353392249905 ], [ 1974875.0, 293125.0 ], [ 1974625.0, 293125.0 ], [ 1974625.0, 292802.379922927648295 ], [ 1974375.0, 292766.295492463046685 ], [ 1974125.0, 292730.211061998503283 ], [ 1974125.0, 293125.0 ], [ 1973875.0, 293125.0 ], [ 1973625.0, 293125.0 ], [ 1973625.0, 292875.0 ], [ 1973375.0, 292875.0 ], [ 1973191.671768725616857, 292691.671768725675065 ], [ 1973125.0, 292696.610418260970619 ], [ 1972875.0, 292715.128936779568903 ], [ 1972625.0, 292733.647455298167188 ], [ 1972375.0, 292752.165973816765472 ], [ 1972125.0, 292770.684492335363757 ], [ 1971875.0, 292789.203010853962041 ], [ 1971827.494301399914548, 292792.721951491024811 ], [ 1971778.426443077158183, 292721.573556922958232 ], [ 1971711.823990026721731, 292625.0 ], [ 1971472.303994097281247, 292277.696005902718753 ], [ 1971268.222361444029957, 291981.777638555911835 ], [ 1971125.0, 292125.0 ], [ 1971125.0, 292375.0 ], [ 1971125.0, 292625.0 ], [ 1970875.0, 292625.0 ], [ 1970875.0, 292875.0 ], [ 1970625.0, 292875.0 ], [ 1970625.0, 293125.0 ], [ 1970375.0, 293125.0 ], [ 1970375.0, 293375.0 ], [ 1970125.0, 293375.0 ], [ 1969875.0, 293375.0 ], [ 1969875.0, 293125.0 ], [ 1970125.0, 293125.0 ], [ 1970125.0, 292875.0 ], [ 1969875.0, 292875.0 ], [ 1969875.0, 292625.0 ], [ 1969625.0, 292625.0 ], [ 1969625.0, 292375.0 ], [ 1969625.0, 292125.0 ], [ 1969875.0, 292125.0 ], [ 1969875.0, 291875.0 ], [ 1969875.0, 291625.0 ], [ 1969875.0, 291375.0 ], [ 1969875.0, 291125.0 ], [ 1969875.0, 290875.0 ], [ 1969625.0, 290875.0 ], [ 1969375.0, 290875.0 ], [ 1969375.0, 290625.0 ], [ 1969625.0, 290625.0 ], [ 1969625.0, 290375.0 ], [ 1969625.0, 290125.0 ], [ 1969625.0, 289875.0 ], [ 1969731.653768708230928, 289768.346231291885488 ] ], [ [ 1968125.0, 292125.0 ], [ 1967875.0, 292125.0 ], [ 1967875.0, 291875.0 ], [ 1968125.0, 291875.0 ], [ 1968375.0, 291875.0 ], [ 1968375.0, 292125.0 ], [ 1968125.0, 292125.0 ] ], [ [ 1967625.0, 291625.0 ], [ 1967375.0, 291625.0 ], [ 1967375.0, 291375.0 ], [ 1967625.0, 291375.0 ], [ 1967625.0, 291625.0 ] ], [ [ 1967375.0, 291875.0 ], [ 1967125.0, 291875.0 ], [ 1967125.0, 291625.0 ], [ 1967375.0, 291625.0 ], [ 1967375.0, 291875.0 ] ], [ [ 1967125.0, 292125.0 ], [ 1966875.0, 292125.0 ], [ 1966875.0, 291875.0 ], [ 1967125.0, 291875.0 ], [ 1967125.0, 292125.0 ] ], [ [ 1971125.0, 293875.0 ], [ 1971125.0, 293625.0 ], [ 1971375.0, 293625.0 ], [ 1971375.0, 293875.0 ], [ 1971125.0, 293875.0 ] ] ], [ [ [ 1973875.0, 296625.0 ], [ 1973625.0, 296625.0 ], [ 1973625.0, 296375.0 ], [ 1973375.0, 296375.0 ], [ 1973125.0, 296375.0 ], [ 1973125.0, 296125.0 ], [ 1972875.0, 296125.0 ], [ 1972625.0, 296125.0 ], [ 1972375.0, 296125.0 ], [ 1972375.0, 295875.0 ], [ 1972125.0, 295875.0 ], [ 1971875.0, 295875.0 ], [ 1971875.0, 295625.0 ], [ 1971625.0, 295625.0 ], [ 1971375.0, 295625.0 ], [ 1971375.0, 295375.0 ], [ 1971125.0, 295375.0 ], [ 1970875.0, 295375.0 ], [ 1970625.0, 295375.0 ], [ 1970375.0, 295375.0 ], [ 1970375.0, 295625.0 ], [ 1970125.0, 295625.0 ], [ 1970125.0, 295875.0 ], [ 1970125.0, 296110.364085177250672 ], [ 1970375.0, 296152.736966533353552 ], [ 1970625.0, 296195.109847889456432 ], [ 1970858.402258340036497, 296234.669552693027072 ], [ 1970875.0, 296241.829362820833921 ], [ 1970968.037020494928584, 296281.962979504955001 ], [ 1971375.0, 296457.515637330594473 ], [ 1971492.009623234858736, 296507.990376765199471 ], [ 1971875.0, 296673.201911840413231 ], [ 1972015.982225974556059, 296734.017774025443941 ], [ 1972375.0, 296888.888186350173783 ], [ 1972562.667575439903885, 296969.842826735985 ], [ 1972625.0, 296995.635554140084423 ], [ 1972716.50168121792376, 297033.498318781959824 ], [ 1973125.0, 297202.532105863792822 ], [ 1973246.989486096426845, 297253.010513903573155 ], [ 1973531.759618500014767, 297370.846430759993382 ], [ 1973757.81749333976768, 297257.817493339825887 ], [ 1973875.0, 297199.226240009593312 ], [ 1974257.817493339534849, 297007.817493339476641 ], [ 1974375.0, 296949.226240009069443 ], [ 1974400.600760550005361, 296936.425859734008554 ], [ 1974625.0, 296976.70264630188467 ], [ 1974875.0, 297021.574441173637751 ], [ 1974962.686886831186712, 297037.313113168929704 ], [ 1975375.0, 297111.318030917085707 ], [ 1975625.0, 297156.189825788780581 ], [ 1975703.862473630113527, 297170.344628748018295 ], [ 1976019.423931503202766, 297019.423931503144559 ], [ 1976125.0, 296968.931029178202152 ], [ 1976472.452714669983834, 296802.757991725986358 ], [ 1976500.0, 296806.201402392238379 ], [ 1976875.0, 296853.076402392413002 ], [ 1977007.124186699977145, 296869.591925729997456 ], [ 1977024.736170638352633, 296975.26382936158916 ], [ 1977049.692199077922851, 297125.0 ], [ 1977091.358865744201466, 297375.0 ], [ 1977133.025532410480082, 297625.0 ], [ 1977203.307599208550528, 298046.692400791565888 ], [ 1977207.625988709973171, 298072.602737800974865 ], [ 1977486.949448623461649, 298263.050551376480144 ], [ 1977784.246745922137052, 298465.753254077921156 ], [ 1977942.799262759974226, 298573.85724282998126 ], [ 1977985.48404832277447, 298764.515951677167322 ], [ 1978010.219283021986485, 298875.0 ], [ 1978066.189432275714353, 299125.0 ], [ 1978122.159581529675052, 299375.0 ], [ 1978214.142584908287972, 299785.857415091595612 ], [ 1978375.0, 299625.0 ], [ 1978625.0, 299625.0 ], [ 1978875.0, 299625.0 ], [ 1978875.0, 299375.0 ], [ 1979125.0, 299375.0 ], [ 1979375.0, 299375.0 ], [ 1979375.0, 299125.0 ], [ 1979625.0, 299125.0 ], [ 1979875.0, 299125.0 ], [ 1980125.0, 299125.0 ], [ 1980125.0, 298875.0 ], [ 1979875.0, 298875.0 ], [ 1979875.0, 298625.0 ], [ 1979875.0, 298375.0 ], [ 1979625.0, 298375.0 ], [ 1979375.0, 298375.0 ], [ 1979375.0, 298125.0 ], [ 1979125.0, 298125.0 ], [ 1979125.0, 297875.0 ], [ 1979125.0, 297625.0 ], [ 1978875.0, 297625.0 ], [ 1978625.0, 297625.0 ], [ 1978375.0, 297625.0 ], [ 1978375.0, 297875.0 ], [ 1978125.0, 297875.0 ], [ 1977875.0, 297875.0 ], [ 1977875.0, 297625.0 ], [ 1977875.0, 297375.0 ], [ 1977875.0, 297125.0 ], [ 1978125.0, 297125.0 ], [ 1978125.0, 296875.0 ], [ 1977875.0, 296875.0 ], [ 1977875.0, 296625.0 ], [ 1977625.0, 296625.0 ], [ 1977625.0, 296375.0 ], [ 1977375.0, 296375.0 ], [ 1977125.0, 296375.0 ], [ 1977125.0, 296125.0 ], [ 1976875.0, 296125.0 ], [ 1976875.0, 295875.0 ], [ 1976875.0, 295625.0 ], [ 1976625.0, 295625.0 ], [ 1976625.0, 295375.0 ], [ 1976375.0, 295375.0 ], [ 1976375.0, 295125.0 ], [ 1976125.0, 295125.0 ], [ 1975875.0, 295125.0 ], [ 1975875.0, 295375.0 ], [ 1975875.0, 295625.0 ], [ 1976125.0, 295625.0 ], [ 1976125.0, 295875.0 ], [ 1975875.0, 295875.0 ], [ 1975625.0, 295875.0 ], [ 1975625.0, 296125.0 ], [ 1975375.0, 296125.0 ], [ 1975125.0, 296125.0 ], [ 1974875.0, 296125.0 ], [ 1974625.0, 296125.0 ], [ 1974625.0, 296375.0 ], [ 1974375.0, 296375.0 ], [ 1974125.0, 296375.0 ], [ 1973875.0, 296375.0 ], [ 1973875.0, 296625.0 ] ] ], [ [ [ 1981625.0, 301375.0 ], [ 1981875.0, 301375.0 ], [ 1982125.0, 301375.0 ], [ 1982125.0, 301625.0 ], [ 1982125.0, 301875.0 ], [ 1981875.0, 301875.0 ], [ 1981625.0, 301875.0 ], [ 1981375.0, 301875.0 ], [ 1981125.0, 301875.0 ], [ 1981125.0, 301625.0 ], [ 1981125.0, 301375.0 ], [ 1980875.0, 301375.0 ], [ 1980875.0, 301125.0 ], [ 1980625.0, 301125.0 ], [ 1980625.0, 300875.0 ], [ 1980625.0, 300625.0 ], [ 1980375.0, 300625.0 ], [ 1980375.0, 300375.0 ], [ 1980125.0, 300375.0 ], [ 1979875.0, 300375.0 ], [ 1979625.0, 300375.0 ], [ 1979375.0, 300375.0 ], [ 1979375.0, 300125.0 ], [ 1979125.0, 300125.0 ], [ 1978875.0, 300125.0 ], [ 1978625.0, 300125.0 ], [ 1978290.070029290858656, 300125.0 ], [ 1978346.040178544819355, 300375.0 ], [ 1978402.010327798547223, 300625.0 ], [ 1978444.053767790086567, 300812.794031961995643 ], [ 1978625.0, 300890.3424171951483 ], [ 1978875.0, 300997.485274338396266 ], [ 1978964.260307963006198, 301035.739692036993802 ], [ 1979375.0, 301211.770988624950405 ], [ 1979379.728843840071931, 301213.797635985014495 ], [ 1979470.505592635832727, 301279.494407364283688 ], [ 1979760.576234282227233, 301489.423765717714559 ], [ 1980050.64687592885457, 301699.35312407114543 ], [ 1980375.0, 301934.093333661789075 ], [ 1980485.752838398562744, 302014.24716160132084 ], [ 1980775.823480045190081, 302224.176519954751711 ], [ 1981125.0, 302476.881869141827337 ], [ 1981210.929442515131086, 302539.070557484927122 ], [ 1981501.000084161525592, 302748.9999158384162 ], [ 1981718.916533980052918, 302906.709983377018943 ], [ 1981776.006001422647387, 302973.993998577294406 ], [ 1982005.514198143966496, 303244.485801855975296 ], [ 1982235.022394865285605, 303514.977605134656187 ], [ 1982375.0, 303375.0 ], [ 1982625.0, 303375.0 ], [ 1982625.0, 303625.0 ], [ 1982464.530591586604714, 303785.469408413337078 ], [ 1982540.495942023815587, 303875.0 ], [ 1982808.792886668583378, 304191.207113331358414 ], [ 1983038.301083389902487, 304461.698916610039305 ], [ 1983267.809280111221597, 304732.190719888720196 ], [ 1983497.317476832540706, 305002.682523167401087 ], [ 1983726.825673553859815, 305273.174326446081977 ], [ 1983956.333870275178924, 305543.666129724762868 ], [ 1984025.344426872441545, 305625.0 ], [ 1984300.596165357157588, 305949.403834642784204 ], [ 1984530.104362078476697, 306219.895637921465095 ], [ 1984759.612558799795806, 306490.387441200145986 ], [ 1984989.120755521114916, 306760.879244478826877 ], [ 1985218.628952242434025, 307031.371047757507768 ], [ 1985298.071699599735439, 307125.0 ], [ 1985461.61683820001781, 307317.749627635988872 ], [ 1985570.665596464881673, 307429.334403535176534 ], [ 1985817.792033246019855, 307682.207966753921937 ], [ 1986064.918470027390867, 307935.08152997266734 ], [ 1986312.044906808529049, 308187.955093191354536 ], [ 1986559.171343589900061, 308440.828656410099939 ], [ 1986806.297780371038243, 308693.702219628845342 ], [ 1986898.546419280115515, 308788.096175722021144 ], [ 1987047.582258242648095, 308952.417741757293697 ], [ 1987285.387136291712523, 309214.612863708287477 ], [ 1987523.19201434077695, 309476.80798565922305 ], [ 1987625.0, 309375.0 ], [ 1987875.0, 309375.0 ], [ 1987875.0, 309625.0 ], [ 1987760.996892389841378, 309739.003107610158622 ], [ 1987998.801770438905805, 310001.198229561152402 ], [ 1988201.80813235999085, 310225.025756807008293 ], [ 1988234.732882234733552, 310265.267117765208241 ], [ 1988459.732882234500721, 310540.267117765382864 ], [ 1988529.059785881079733, 310625.0 ], [ 1988797.23288223426789, 310952.767117765673902 ], [ 1988875.0, 310875.0 ], [ 1989125.0, 310875.0 ], [ 1989125.0, 311125.0 ], [ 1989022.23288223403506, 311227.767117765906733 ], [ 1989247.232882233802229, 311502.767117766081356 ], [ 1989472.232882233802229, 311777.767117766314186 ], [ 1989625.0, 311625.0 ], [ 1989875.0, 311625.0 ], [ 1990125.0, 311625.0 ], [ 1990125.0, 311375.0 ], [ 1990375.0, 311375.0 ], [ 1990375.0, 311125.0 ], [ 1990125.0, 311125.0 ], [ 1990125.0, 310875.0 ], [ 1989875.0, 310875.0 ], [ 1989875.0, 310625.0 ], [ 1989875.0, 310375.0 ], [ 1989625.0, 310375.0 ], [ 1989625.0, 310125.0 ], [ 1989375.0, 310125.0 ], [ 1989375.0, 309875.0 ], [ 1989125.0, 309875.0 ], [ 1989125.0, 309625.0 ], [ 1989125.0, 309375.0 ], [ 1988875.0, 309375.0 ], [ 1988625.0, 309375.0 ], [ 1988375.0, 309375.0 ], [ 1988375.0, 309125.0 ], [ 1988125.0, 309125.0 ], [ 1987875.0, 309125.0 ], [ 1987875.0, 308875.0 ], [ 1988125.0, 308875.0 ], [ 1988125.0, 308625.0 ], [ 1987875.0, 308625.0 ], [ 1987875.0, 308375.0 ], [ 1987875.0, 308125.0 ], [ 1987875.0, 307875.0 ], [ 1988125.0, 307875.0 ], [ 1988375.0, 307875.0 ], [ 1988625.0, 307875.0 ], [ 1988875.0, 307875.0 ], [ 1989125.0, 307875.0 ], [ 1989375.0, 307875.0 ], [ 1989625.0, 307875.0 ], [ 1989625.0, 307625.0 ], [ 1989375.0, 307625.0 ], [ 1989375.0, 307375.0 ], [ 1989125.0, 307375.0 ], [ 1989125.0, 307125.0 ], [ 1988875.0, 307125.0 ], [ 1988875.0, 306875.0 ], [ 1988625.0, 306875.0 ], [ 1988375.0, 306875.0 ], [ 1988375.0, 307125.0 ], [ 1988125.0, 307125.0 ], [ 1987875.0, 307125.0 ], [ 1987625.0, 307125.0 ], [ 1987625.0, 306875.0 ], [ 1987875.0, 306875.0 ], [ 1987875.0, 306625.0 ], [ 1987875.0, 306375.0 ], [ 1988125.0, 306375.0 ], [ 1988125.0, 306125.0 ], [ 1988125.0, 305875.0 ], [ 1987875.0, 305875.0 ], [ 1987875.0, 305625.0 ], [ 1987625.0, 305625.0 ], [ 1987625.0, 305375.0 ], [ 1987375.0, 305375.0 ], [ 1987375.0, 305625.0 ], [ 1987375.0, 305875.0 ], [ 1987125.0, 305875.0 ], [ 1987125.0, 306125.0 ], [ 1986875.0, 306125.0 ], [ 1986625.0, 306125.0 ], [ 1986625.0, 306375.0 ], [ 1986875.0, 306375.0 ], [ 1986875.0, 306625.0 ], [ 1986875.0, 306875.0 ], [ 1986625.0, 306875.0 ], [ 1986625.0, 306625.0 ], [ 1986375.0, 306625.0 ], [ 1986375.0, 306375.0 ], [ 1986125.0, 306375.0 ], [ 1986125.0, 306125.0 ], [ 1986125.0, 305875.0 ], [ 1985875.0, 305875.0 ], [ 1985625.0, 305875.0 ], [ 1985375.0, 305875.0 ], [ 1985375.0, 306125.0 ], [ 1985125.0, 306125.0 ], [ 1984875.0, 306125.0 ], [ 1984875.0, 305875.0 ], [ 1984875.0, 305625.0 ], [ 1985125.0, 305625.0 ], [ 1985125.0, 305375.0 ], [ 1985375.0, 305375.0 ], [ 1985375.0, 305125.0 ], [ 1985125.0, 305125.0 ], [ 1984875.0, 305125.0 ], [ 1984625.0, 305125.0 ], [ 1984625.0, 304875.0 ], [ 1984375.0, 304875.0 ], [ 1984375.0, 304625.0 ], [ 1984125.0, 304625.0 ], [ 1984125.0, 304375.0 ], [ 1983875.0, 304375.0 ], [ 1983875.0, 304125.0 ], [ 1983875.0, 303875.0 ], [ 1983875.0, 303625.0 ], [ 1983625.0, 303625.0 ], [ 1983625.0, 303375.0 ], [ 1983375.0, 303375.0 ], [ 1983375.0, 303125.0 ], [ 1983125.0, 303125.0 ], [ 1982875.0, 303125.0 ], [ 1982875.0, 302875.0 ], [ 1982625.0, 302875.0 ], [ 1982625.0, 302625.0 ], [ 1982375.0, 302625.0 ], [ 1982375.0, 302375.0 ], [ 1982625.0, 302375.0 ], [ 1982875.0, 302375.0 ], [ 1983125.0, 302375.0 ], [ 1983125.0, 302625.0 ], [ 1983375.0, 302625.0 ], [ 1983375.0, 302875.0 ], [ 1983625.0, 302875.0 ], [ 1983875.0, 302875.0 ], [ 1983875.0, 303125.0 ], [ 1984125.0, 303125.0 ], [ 1984375.0, 303125.0 ], [ 1984625.0, 303125.0 ], [ 1984625.0, 302875.0 ], [ 1984375.0, 302875.0 ], [ 1984375.0, 302625.0 ], [ 1984125.0, 302625.0 ], [ 1983875.0, 302625.0 ], [ 1983875.0, 302375.0 ], [ 1983875.0, 302125.0 ], [ 1983625.0, 302125.0 ], [ 1983625.0, 301875.0 ], [ 1983375.0, 301875.0 ], [ 1983375.0, 301625.0 ], [ 1983125.0, 301625.0 ], [ 1983125.0, 301375.0 ], [ 1982875.0, 301375.0 ], [ 1982625.0, 301375.0 ], [ 1982625.0, 301125.0 ], [ 1982625.0, 300875.0 ], [ 1982375.0, 300875.0 ], [ 1982375.0, 300625.0 ], [ 1982125.0, 300625.0 ], [ 1982125.0, 300375.0 ], [ 1981875.0, 300375.0 ], [ 1981875.0, 300125.0 ], [ 1981625.0, 300125.0 ], [ 1981375.0, 300125.0 ], [ 1981375.0, 300375.0 ], [ 1981375.0, 300625.0 ], [ 1981375.0, 300875.0 ], [ 1981625.0, 300875.0 ], [ 1981625.0, 301125.0 ], [ 1981625.0, 301375.0 ] ], [ [ 1988625.0, 307125.0 ], [ 1988625.0, 307375.0 ], [ 1988375.0, 307375.0 ], [ 1988375.0, 307125.0 ], [ 1988625.0, 307125.0 ] ], [ [ 1984625.0, 305625.0 ], [ 1984625.0, 305375.0 ], [ 1984875.0, 305375.0 ], [ 1984875.0, 305625.0 ], [ 1984625.0, 305625.0 ] ], [ [ 1983625.0, 302375.0 ], [ 1983375.0, 302375.0 ], [ 1983375.0, 302125.0 ], [ 1983625.0, 302125.0 ], [ 1983625.0, 302375.0 ] ], [ [ 1982375.0, 301125.0 ], [ 1982125.0, 301125.0 ], [ 1982125.0, 300875.0 ], [ 1982375.0, 300875.0 ], [ 1982375.0, 301125.0 ] ], [ [ 1981625.0, 302375.0 ], [ 1981625.0, 302125.0 ], [ 1981875.0, 302125.0 ], [ 1982125.0, 302125.0 ], [ 1982125.0, 302375.0 ], [ 1982125.0, 302625.0 ], [ 1981875.0, 302625.0 ], [ 1981875.0, 302375.0 ], [ 1981625.0, 302375.0 ] ], [ [ 1983125.0, 302125.0 ], [ 1982875.0, 302125.0 ], [ 1982625.0, 302125.0 ], [ 1982625.0, 301875.0 ], [ 1982875.0, 301875.0 ], [ 1983125.0, 301875.0 ], [ 1983125.0, 302125.0 ] ], [ [ 1985875.0, 306625.0 ], [ 1986125.0, 306625.0 ], [ 1986125.0, 306875.0 ], [ 1985875.0, 306875.0 ], [ 1985875.0, 306625.0 ] ], [ [ 1987625.0, 308125.0 ], [ 1987625.0, 308375.0 ], [ 1987375.0, 308375.0 ], [ 1987375.0, 308125.0 ], [ 1987625.0, 308125.0 ] ] ], [ [ [ 1982625.0, 298125.0 ], [ 1982625.0, 298375.0 ], [ 1982625.0, 298625.0 ], [ 1982875.0, 298625.0 ], [ 1983125.0, 298625.0 ], [ 1983375.0, 298625.0 ], [ 1983375.0, 298875.0 ], [ 1983625.0, 298875.0 ], [ 1983625.0, 299125.0 ], [ 1983875.0, 299125.0 ], [ 1983875.0, 299375.0 ], [ 1984125.0, 299375.0 ], [ 1984125.0, 299625.0 ], [ 1984375.0, 299625.0 ], [ 1984375.0, 299875.0 ], [ 1984625.0, 299875.0 ], [ 1984625.0, 300125.0 ], [ 1984875.0, 300125.0 ], [ 1984875.0, 300375.0 ], [ 1985125.0, 300375.0 ], [ 1985375.0, 300375.0 ], [ 1985375.0, 300625.0 ], [ 1985625.0, 300625.0 ], [ 1985625.0, 300875.0 ], [ 1985875.0, 300875.0 ], [ 1985875.0, 301125.0 ], [ 1986125.0, 301125.0 ], [ 1986125.0, 301375.0 ], [ 1986375.0, 301375.0 ], [ 1986625.0, 301375.0 ], [ 1986625.0, 301625.0 ], [ 1986875.0, 301625.0 ], [ 1986875.0, 301875.0 ], [ 1987125.0, 301875.0 ], [ 1987125.0, 302125.0 ], [ 1987375.0, 302125.0 ], [ 1987375.0, 302375.0 ], [ 1987625.0, 302375.0 ], [ 1987875.0, 302375.0 ], [ 1987875.0, 302625.0 ], [ 1988125.0, 302625.0 ], [ 1988125.0, 302875.0 ], [ 1988375.0, 302875.0 ], [ 1988375.0, 303125.0 ], [ 1988625.0, 303125.0 ], [ 1988875.0, 303125.0 ], [ 1988875.0, 303375.0 ], [ 1989125.0, 303375.0 ], [ 1989125.0, 303625.0 ], [ 1989375.0, 303625.0 ], [ 1989625.0, 303625.0 ], [ 1989625.0, 303875.0 ], [ 1989875.0, 303875.0 ], [ 1989875.0, 304125.0 ], [ 1990125.0, 304125.0 ], [ 1990125.0, 304375.0 ], [ 1990375.0, 304375.0 ], [ 1990625.0, 304375.0 ], [ 1990625.0, 304625.0 ], [ 1990875.0, 304625.0 ], [ 1990875.0, 304875.0 ], [ 1991125.0, 304875.0 ], [ 1991125.0, 305125.0 ], [ 1991375.0, 305125.0 ], [ 1991375.0, 305375.0 ], [ 1991625.0, 305375.0 ], [ 1991875.0, 305375.0 ], [ 1991875.0, 305625.0 ], [ 1992125.0, 305625.0 ], [ 1992125.0, 305875.0 ], [ 1992125.0, 306125.0 ], [ 1992375.0, 306125.0 ], [ 1992625.0, 306125.0 ], [ 1992625.0, 306375.0 ], [ 1992625.0, 306625.0 ], [ 1992875.0, 306625.0 ], [ 1992875.0, 306875.0 ], [ 1993125.0, 306875.0 ], [ 1993125.0, 307125.0 ], [ 1993125.0, 307375.0 ], [ 1993125.0, 307625.0 ], [ 1993125.0, 307875.0 ], [ 1993125.0, 308125.0 ], [ 1993375.0, 308125.0 ], [ 1993375.0, 308375.0 ], [ 1993375.0, 308625.0 ], [ 1993375.0, 308875.0 ], [ 1993375.0, 309125.0 ], [ 1993375.0, 309375.0 ], [ 1993625.0, 309375.0 ], [ 1993875.0, 309375.0 ], [ 1993875.0, 309625.0 ], [ 1994125.0, 309625.0 ], [ 1994375.0, 309625.0 ], [ 1994625.0, 309625.0 ], [ 1994875.0, 309625.0 ], [ 1994875.0, 309375.0 ], [ 1995125.0, 309375.0 ], [ 1995375.0, 309375.0 ], [ 1995625.0, 309375.0 ], [ 1995625.0, 309125.0 ], [ 1995875.0, 309125.0 ], [ 1995875.0, 308875.0 ], [ 1996027.641929935663939, 308722.358070064452477 ], [ 1995965.981818894622847, 308625.0 ], [ 1995921.12750981003046, 308554.177406709000934 ], [ 1995625.0, 308311.449939651589375 ], [ 1995522.536519650835544, 308227.463480349106248 ], [ 1995247.761744876159355, 308002.238255123840645 ], [ 1995125.0, 308125.0 ], [ 1994875.0, 308125.0 ], [ 1994875.0, 307875.0 ], [ 1994625.0, 307875.0 ], [ 1994625.0, 307625.0 ], [ 1994698.212195326574147, 307551.787804673425853 ], [ 1994375.0, 307286.859775717195589 ], [ 1994286.050033164443448, 307213.949966835556552 ], [ 1994125.0, 307375.0 ], [ 1993875.0, 307375.0 ], [ 1993875.0, 307125.0 ], [ 1994011.275258389534429, 306988.724741610349156 ], [ 1993736.50048361485824, 306763.49951638514176 ], [ 1993461.725708840182051, 306538.274291159934364 ], [ 1993186.950934065273032, 306313.049065934668761 ], [ 1992875.0, 306057.351578995934688 ], [ 1992774.788771903142333, 305975.211228096857667 ], [ 1992500.013997128466144, 305749.986002871650271 ], [ 1992225.239222353557125, 305524.760777646384668 ], [ 1991950.464447578880936, 305299.535552421177272 ], [ 1991625.0, 305032.761415061540902 ], [ 1991538.302285416750237, 304961.697714583366178 ], [ 1991263.527510641841218, 304736.472489358158782 ], [ 1990988.752735867165029, 304511.247264132893179 ], [ 1990713.97796109225601, 304286.022038907685783 ], [ 1990439.203186317579821, 304060.796813682478387 ], [ 1990125.0, 303803.253218340221792 ], [ 1990027.041024155449122, 303722.958975844609085 ], [ 1989805.822548449970782, 303541.632356413989328 ], [ 1989751.42911317711696, 303498.570886822941247 ], [ 1989472.359345735283569, 303277.640654264832847 ], [ 1989193.289578293217346, 303056.710421706666239 ], [ 1988875.0, 302804.731172224448528 ], [ 1988774.684927130583674, 302725.315072869474534 ], [ 1988495.615159688750282, 302504.384840311307926 ], [ 1988216.54539224668406, 302283.454607753199525 ], [ 1987937.475624804850668, 302062.524375195091125 ], [ 1987625.0, 301815.147838891192805 ], [ 1987518.870973642216995, 301731.129026357841212 ], [ 1987239.801206200150773, 301510.198793799732812 ], [ 1986960.731438758317381, 301289.268561241624411 ], [ 1986625.0, 301023.481172224564943 ], [ 1986542.126787595683709, 300957.873212404374499 ], [ 1986263.057020153850317, 300736.942979846266098 ], [ 1985983.987252711784095, 300516.012747288157698 ], [ 1985704.917485269950703, 300295.08251472999109 ], [ 1985375.0, 300033.897838891251013 ], [ 1985286.31283410731703, 299963.687165892799385 ], [ 1985007.243066665250808, 299742.756933334690984 ], [ 1984728.173299223417416, 299521.826700776524376 ], [ 1984449.103531781584024, 299300.896468218415976 ], [ 1984191.772092120023444, 299097.175745152984746 ], [ 1984125.0, 299046.301770204328932 ], [ 1984027.774670965271071, 298972.225329034787137 ], [ 1983743.990887181600556, 298756.009112818399444 ], [ 1983460.207103397930041, 298539.792896602011751 ], [ 1983125.0, 298284.397008298314176 ], [ 1983034.531427722657099, 298215.468572277342901 ], [ 1982750.747643938986585, 297999.252356060955208 ], [ 1982466.9638601555489, 297783.036139844509307 ], [ 1982125.0, 297522.492246392357629 ], [ 1982041.288184480043128, 297458.711815519898664 ], [ 1981757.504400696605444, 297242.495599303510971 ], [ 1981473.720616912934929, 297026.279383087065071 ], [ 1981189.936833129264414, 296810.063166870677378 ], [ 1980875.0, 296570.111294009839185 ], [ 1980764.261157453991473, 296485.738842546066735 ], [ 1980625.0, 296625.0 ], [ 1980375.0, 296625.0 ], [ 1980375.0, 296875.0 ], [ 1980625.0, 296875.0 ], [ 1980625.0, 297125.0 ], [ 1980625.0, 297375.0 ], [ 1980875.0, 297375.0 ], [ 1980875.0, 297625.0 ], [ 1981125.0, 297625.0 ], [ 1981125.0, 297875.0 ], [ 1981375.0, 297875.0 ], [ 1981625.0, 297875.0 ], [ 1981625.0, 298125.0 ], [ 1981875.0, 298125.0 ], [ 1981875.0, 297875.0 ], [ 1982125.0, 297875.0 ], [ 1982375.0, 297875.0 ], [ 1982375.0, 298125.0 ], [ 1982625.0, 298125.0 ] ], [ [ 1995375.0, 309125.0 ], [ 1995375.0, 308875.0 ], [ 1995625.0, 308875.0 ], [ 1995625.0, 309125.0 ], [ 1995375.0, 309125.0 ] ] ], [ [ [ 1997625.0, 315375.0 ], [ 1997625.0, 315625.0 ], [ 1997625.0, 315875.0 ], [ 1997875.0, 315875.0 ], [ 1997875.0, 316125.0 ], [ 1997875.0, 316375.0 ], [ 1998125.0, 316375.0 ], [ 1998375.0, 316375.0 ], [ 1998375.0, 316125.0 ], [ 1998375.0, 315875.0 ], [ 1998125.0, 315875.0 ], [ 1998125.0, 315625.0 ], [ 1998125.0, 315375.0 ], [ 1998375.0, 315375.0 ], [ 1998625.0, 315375.0 ], [ 1998625.0, 315625.0 ], [ 1998875.0, 315625.0 ], [ 1998875.0, 315875.0 ], [ 1998625.0, 315875.0 ], [ 1998625.0, 316125.0 ], [ 1998625.0, 316375.0 ], [ 1998625.0, 316625.0 ], [ 1998875.0, 316625.0 ], [ 1998875.0, 316875.0 ], [ 1999125.0, 316875.0 ], [ 1999375.0, 316875.0 ], [ 1999375.0, 317125.0 ], [ 1999625.0, 317125.0 ], [ 1999875.0, 317125.0 ], [ 1999875.0, 317375.0 ], [ 1999875.0, 317625.0 ], [ 2000125.0, 317625.0 ], [ 2000125.0, 317875.0 ], [ 2000375.0, 317875.0 ], [ 2000375.0, 317625.0 ], [ 2000375.0, 317375.0 ], [ 2000625.0, 317375.0 ], [ 2000875.0, 317375.0 ], [ 2001125.0, 317375.0 ], [ 2001375.0, 317375.0 ], [ 2001375.0, 317125.0 ], [ 2001125.0, 317125.0 ], [ 2001125.0, 316875.0 ], [ 2000875.0, 316875.0 ], [ 2000875.0, 316625.0 ], [ 2000625.0, 316625.0 ], [ 2000625.0, 316375.0 ], [ 2000375.0, 316375.0 ], [ 2000375.0, 316125.0 ], [ 2000125.0, 316125.0 ], [ 2000125.0, 315875.0 ], [ 2000125.0, 315625.0 ], [ 1999875.0, 315625.0 ], [ 1999875.0, 315375.0 ], [ 1999625.0, 315375.0 ], [ 1999625.0, 315125.0 ], [ 1999375.0, 315125.0 ], [ 1999375.0, 314875.0 ], [ 1999125.0, 314875.0 ], [ 1999125.0, 314625.0 ], [ 1998875.0, 314625.0 ], [ 1998875.0, 314375.0 ], [ 1998625.0, 314375.0 ], [ 1998375.0, 314375.0 ], [ 1998125.0, 314375.0 ], [ 1997875.0, 314375.0 ], [ 1997625.0, 314375.0 ], [ 1997375.0, 314375.0 ], [ 1997125.0, 314375.0 ], [ 1996875.0, 314375.0 ], [ 1996875.0, 314625.0 ], [ 1997125.0, 314625.0 ], [ 1997375.0, 314625.0 ], [ 1997375.0, 314875.0 ], [ 1997375.0, 315125.0 ], [ 1997375.0, 315375.0 ], [ 1997625.0, 315375.0 ] ] ], [ [ [ 1995375.0, 317550.752425343205687 ], [ 1995445.872684899717569, 317554.127315100340638 ], [ 1995625.0, 317375.0 ], [ 1995875.0, 317375.0 ], [ 1995875.0, 317574.561949152790476 ], [ 1995921.12750981003046, 317576.758497238974087 ], [ 1996027.524240780156106, 317722.475759219843894 ], [ 1996238.533415092155337, 318011.46658490790287 ], [ 1996321.430829286342487, 318125.0 ], [ 1996555.047176559921354, 318444.952823439962231 ], [ 1996766.056350871920586, 318733.943649128021207 ], [ 1996977.065525183919817, 319022.934474816080183 ], [ 1997051.589559445157647, 319125.0 ], [ 1997293.579286651918665, 319456.420713348197751 ], [ 1997458.307991900015622, 319682.027418361976743 ], [ 1997511.426777554443106, 319738.573222445673309 ], [ 1997753.614277554210275, 319996.385722445789725 ], [ 1997995.801777553977445, 320254.198222445964348 ], [ 1998237.989277553977445, 320512.010722446138971 ], [ 1998480.176777553744614, 320769.823222446255386 ], [ 1998625.0, 320625.0 ], [ 1998625.0, 320375.0 ], [ 1998875.0, 320375.0 ], [ 1999125.0, 320375.0 ], [ 1999375.0, 320375.0 ], [ 1999375.0, 320125.0 ], [ 1999125.0, 320125.0 ], [ 1998875.0, 320125.0 ], [ 1998875.0, 319875.0 ], [ 1998625.0, 319875.0 ], [ 1998375.0, 319875.0 ], [ 1998125.0, 319875.0 ], [ 1998125.0, 319625.0 ], [ 1998125.0, 319375.0 ], [ 1998375.0, 319375.0 ], [ 1998375.0, 319125.0 ], [ 1998125.0, 319125.0 ], [ 1998125.0, 318875.0 ], [ 1997875.0, 318875.0 ], [ 1997875.0, 318625.0 ], [ 1997875.0, 318375.0 ], [ 1997625.0, 318375.0 ], [ 1997375.0, 318375.0 ], [ 1997375.0, 318125.0 ], [ 1997375.0, 317875.0 ], [ 1997625.0, 317875.0 ], [ 1997625.0, 317625.0 ], [ 1997625.0, 317375.0 ], [ 1997875.0, 317375.0 ], [ 1997875.0, 317125.0 ], [ 1997625.0, 317125.0 ], [ 1997625.0, 316875.0 ], [ 1997375.0, 316875.0 ], [ 1997375.0, 317125.0 ], [ 1997125.0, 317125.0 ], [ 1996875.0, 317125.0 ], [ 1996875.0, 316875.0 ], [ 1996625.0, 316875.0 ], [ 1996375.0, 316875.0 ], [ 1996125.0, 316875.0 ], [ 1995875.0, 316875.0 ], [ 1995875.0, 316625.0 ], [ 1995875.0, 316375.0 ], [ 1995875.0, 316125.0 ], [ 1995625.0, 316125.0 ], [ 1995625.0, 315875.0 ], [ 1995375.0, 315875.0 ], [ 1995125.0, 315875.0 ], [ 1994875.0, 315875.0 ], [ 1994875.0, 315625.0 ], [ 1994875.0, 315375.0 ], [ 1994875.0, 315125.0 ], [ 1994625.0, 315125.0 ], [ 1994375.0, 315125.0 ], [ 1994375.0, 314875.0 ], [ 1994125.0, 314875.0 ], [ 1994125.0, 314625.0 ], [ 1994125.0, 314375.0 ], [ 1993875.0, 314375.0 ], [ 1993875.0, 314625.0 ], [ 1993625.0, 314625.0 ], [ 1993625.0, 314375.0 ], [ 1993625.0, 314125.0 ], [ 1993375.0, 314125.0 ], [ 1993375.0, 313875.0 ], [ 1993125.0, 313875.0 ], [ 1993125.0, 314125.0 ], [ 1992875.0, 314125.0 ], [ 1992625.0, 314125.0 ], [ 1992625.0, 314375.0 ], [ 1992625.0, 314625.0 ], [ 1992375.0, 314625.0 ], [ 1992243.440604035742581, 314756.559395964199211 ], [ 1992412.345974609954283, 314836.567203078011516 ], [ 1992625.0, 314841.883553712745197 ], [ 1992875.0, 314848.133553712745197 ], [ 1992875.0, 314625.0 ], [ 1993125.0, 314625.0 ], [ 1993125.0, 314854.383553712745197 ], [ 1993375.0, 314860.633553712745197 ], [ 1993625.0, 314866.883553712745197 ], [ 1993749.024654689943418, 314869.984170079987962 ], [ 1993795.505394287640229, 314954.494605712417979 ], [ 1993972.924749125726521, 315277.075250874215271 ], [ 1994026.783361144829541, 315375.0 ], [ 1994239.053781383205205, 315760.94621861691121 ], [ 1994301.783361143665388, 315875.0 ], [ 1994505.182813640451059, 316244.817186359548941 ], [ 1994576.783361142268404, 316375.0 ], [ 1994771.311845897696912, 316728.68815410224488 ], [ 1994851.783361141104251, 316875.0 ], [ 1995037.440878155175596, 317212.559121844940819 ], [ 1995219.371202769922093, 317543.341530236997642 ], [ 1995375.0, 317550.752425343205687 ] ], [ [ 1995125.0, 316875.0 ], [ 1995125.0, 316625.0 ], [ 1995375.0, 316625.0 ], [ 1995375.0, 316875.0 ], [ 1995125.0, 316875.0 ] ] ], [ [ [ 2005125.0, 321875.0 ], [ 2005125.0, 322125.0 ], [ 2005375.0, 322125.0 ], [ 2005625.0, 322125.0 ], [ 2005625.0, 322375.0 ], [ 2005853.200009249150753, 322375.0 ], [ 2005823.255498570390046, 322591.415552785329055 ], [ 2005890.83, 322726.7586 ], [ 2006060.660845221951604, 322854.279157310607843 ], [ 2006125.0, 322874.713643411407247 ], [ 2006125.0, 323125.0 ], [ 2006125.0, 323375.0 ], [ 2006375.0, 323375.0 ], [ 2006375.0, 323625.0 ], [ 2006375.0, 323875.0 ], [ 2006625.0, 323875.0 ], [ 2006625.0, 324125.0 ], [ 2006625.0, 324375.0 ], [ 2006875.0, 324375.0 ], [ 2007125.0, 324375.0 ], [ 2007375.0, 324375.0 ], [ 2007375.0, 324625.0 ], [ 2007625.0, 324625.0 ], [ 2007625.0, 324875.0 ], [ 2007875.0, 324875.0 ], [ 2008125.0, 324875.0 ], [ 2008125.0, 325125.0 ], [ 2008375.0, 325125.0 ], [ 2008625.0, 325125.0 ], [ 2008625.0, 324875.0 ], [ 2008875.0, 324875.0 ], [ 2008875.0, 324625.0 ], [ 2009125.0, 324625.0 ], [ 2009125.0, 324375.0 ], [ 2009125.0, 324125.0 ], [ 2009375.0, 324125.0 ], [ 2009375.0, 323875.0 ], [ 2009375.0, 323625.0 ], [ 2009125.0, 323625.0 ], [ 2009125.0, 323375.0 ], [ 2009125.0, 323125.0 ], [ 2008875.0, 323125.0 ], [ 2008875.0, 322875.0 ], [ 2008625.0, 322875.0 ], [ 2008625.0, 322625.0 ], [ 2008625.0, 322375.0 ], [ 2008375.0, 322375.0 ], [ 2008125.0, 322375.0 ], [ 2007875.0, 322375.0 ], [ 2007875.0, 322125.0 ], [ 2007625.0, 322125.0 ], [ 2007625.0, 321875.0 ], [ 2007375.0, 321875.0 ], [ 2007375.0, 321686.510160959267523 ], [ 2007289.698470945237204, 321629.262140740000177 ], [ 2007148.71354650054127, 321435.770793618052267 ], [ 2006975.777212957851589, 321614.801813868223689 ], [ 2006900.085, 321693.1616 ], [ 2006777.156816202681512, 321818.271713803464081 ], [ 2006583.639, 322015.2244 ], [ 2006411.373, 322194.9804 ], [ 2006220.382, 322395.3335 ], [ 2006132.449795989319682, 322221.120999313541688 ], [ 2005951.030115525936708, 322384.202294588496443 ], [ 2005875.0, 322361.554269636981189 ], [ 2005875.0, 322125.0 ], [ 2005875.0, 321875.0 ], [ 2005625.0, 321875.0 ], [ 2005625.0, 321625.0 ], [ 2005375.0, 321625.0 ], [ 2005375.0, 321375.0 ], [ 2005125.0, 321375.0 ], [ 2005125.0, 321625.0 ], [ 2004875.0, 321625.0 ], [ 2004875.0, 321375.0 ], [ 2004625.0, 321375.0 ], [ 2004625.0, 321125.0 ], [ 2004875.0, 321125.0 ], [ 2004875.0, 320875.0 ], [ 2004625.0, 320875.0 ], [ 2004375.0, 320875.0 ], [ 2004375.0, 320625.0 ], [ 2004125.0, 320625.0 ], [ 2004125.0, 320375.0 ], [ 2003875.0, 320375.0 ], [ 2003875.0, 320125.0 ], [ 2003625.0, 320125.0 ], [ 2003375.0, 320125.0 ], [ 2003125.0, 320125.0 ], [ 2003125.0, 320375.0 ], [ 2003375.0, 320375.0 ], [ 2003375.0, 320625.0 ], [ 2003625.0, 320625.0 ], [ 2003625.0, 320875.0 ], [ 2003875.0, 320875.0 ], [ 2003875.0, 321125.0 ], [ 2004125.0, 321125.0 ], [ 2004125.0, 321375.0 ], [ 2004375.0, 321375.0 ], [ 2004375.0, 321625.0 ], [ 2004625.0, 321625.0 ], [ 2004625.0, 321875.0 ], [ 2004875.0, 321875.0 ], [ 2005125.0, 321875.0 ] ], [ [ 2007375.0, 323625.0 ], [ 2007375.0, 323875.0 ], [ 2007125.0, 323875.0 ], [ 2007125.0, 323625.0 ], [ 2007375.0, 323625.0 ] ], [ [ 2008125.0, 322875.0 ], [ 2008375.0, 322875.0 ], [ 2008375.0, 323125.0 ], [ 2008625.0, 323125.0 ], [ 2008625.0, 323375.0 ], [ 2008625.0, 323625.0 ], [ 2008375.0, 323625.0 ], [ 2008375.0, 323375.0 ], [ 2008125.0, 323375.0 ], [ 2008125.0, 323125.0 ], [ 2008125.0, 322875.0 ] ], [ [ 2007875.0, 324125.0 ], [ 2007875.0, 324375.0 ], [ 2007625.0, 324375.0 ], [ 2007625.0, 324125.0 ], [ 2007875.0, 324125.0 ] ] ], [ [ [ 2003260.908588130027056, 326425.80663290398661 ], [ 2003205.3318010433577, 326455.3318010433577 ], [ 2003125.0, 326498.008070347073954 ], [ 2002961.444015480112284, 326584.89718712202739 ], [ 2002720.589737881906331, 326720.589737881789915 ], [ 2002875.0, 326875.0 ], [ 2002875.0, 327125.0 ], [ 2002625.0, 327125.0 ], [ 2002375.0, 327125.0 ], [ 2002235.943278753664345, 326985.943278753547929 ], [ 2002125.0, 327034.480963207723107 ], [ 2001714.204148316988721, 327214.204148317105137 ], [ 2001698.07784962002188, 327221.259403996984474 ], [ 2001529.62902751006186, 327361.633422426006291 ], [ 2001463.792912004282698, 327463.792912004340906 ], [ 2001267.846966058947146, 327767.846966059005354 ], [ 2001037.681677520507947, 328125.0 ], [ 2000986.849489589920267, 328203.877532996004447 ], [ 2000974.910712822573259, 328375.0 ], [ 2000957.468852357938886, 328625.0 ], [ 2000952.09044894319959, 328702.090448943316005 ], [ 2000930.699882220011204, 329008.688571984996088 ], [ 2000933.026110779028386, 329125.0 ], [ 2000940.0581501100678, 329476.601966745976824 ], [ 2000944.225144267082214, 329555.774855732859578 ], [ 2000947.868572912644595, 329625.0 ], [ 2000958.774685899959877, 329832.216146763996221 ], [ 2000987.757296156603843, 329875.0 ], [ 2001155.298311700113118, 330122.322451515996363 ], [ 2001375.0, 330259.636006701330189 ], [ 2001379.896741189993918, 330262.69646994501818 ], [ 2001625.0, 330296.503815988078713 ], [ 2001651.286510149948299, 330300.129541526024695 ], [ 2001875.0, 330223.427773576579057 ], [ 2001978.825886480044574, 330187.830326783005148 ], [ 2002125.0, 330140.538701820769347 ], [ 2002297.006994920084253, 330084.889379934989847 ], [ 2002430.972065173555166, 329930.972065173671581 ], [ 2002663.64533249870874, 329663.645332498825155 ], [ 2002736.845585989998654, 329579.542913593002595 ], [ 2002983.229285574285313, 329483.229285574343521 ], [ 2003125.0, 329427.809824481024407 ], [ 2003522.444971849909052, 329272.444971849850845 ], [ 2003625.0, 329232.355279027775396 ], [ 2003625.0, 328875.0 ], [ 2003947.537490927381441, 328875.0 ], [ 2004014.085931829176843, 328764.085931829176843 ], [ 2004131.227502380032092, 328568.849980909028091 ], [ 2004241.455922896508127, 328375.0 ], [ 2004289.865650846390054, 328289.865650846331846 ], [ 2004471.115650845691562, 327971.115650845749769 ], [ 2004667.926511129597202, 327625.0 ], [ 2004674.007040299940854, 327614.306655596999917 ], [ 2004769.156847949139774, 327519.156847949197982 ], [ 2004625.0, 327375.0 ], [ 2004625.0, 327125.0 ], [ 2004875.0, 327125.0 ], [ 2004875.0, 327413.313695900083985 ], [ 2004936.038541370071471, 327352.275154531002045 ], [ 2005265.730908230412751, 327265.730908230296336 ], [ 2005375.0, 327237.047771640762221 ], [ 2005625.0, 327171.422771640878636 ], [ 2005684.699972989968956, 327155.751528731023427 ], [ 2005875.0, 327152.470493782660924 ], [ 2006125.0, 327148.160148955124896 ], [ 2006227.479510910110548, 327146.393260836019181 ], [ 2006375.0, 327165.551765912619885 ], [ 2006625.0, 327198.01929838018259 ], [ 2006625.0, 326875.0 ], [ 2006875.0, 326875.0 ], [ 2007125.0, 326875.0 ], [ 2007125.0, 327125.0 ], [ 2007375.0, 327125.0 ], [ 2007375.0, 327496.136256483208854 ], [ 2007455.539839698001742, 327544.46016030194005 ], [ 2007625.0, 327375.0 ], [ 2007875.0, 327375.0 ], [ 2007875.0, 327625.0 ], [ 2007768.039839698467404, 327731.960160301590804 ], [ 2008071.05828626989387, 327913.771228244004305 ], [ 2008125.0, 327961.209331098711118 ], [ 2008212.148997415555641, 328037.851002584444359 ], [ 2008478.186733264941722, 328271.81326673500007 ], [ 2008744.224469114560634, 328505.775530885555781 ], [ 2009010.262204963946715, 328739.737795036053285 ], [ 2009276.299940813332796, 328973.700059186608996 ], [ 2009390.574059499893337, 329074.196447251015343 ], [ 2009509.054002849152312, 329240.945997150847688 ], [ 2009604.302899609785527, 329375.0 ], [ 2009643.247292669955641, 329429.81062727002427 ], [ 2009738.123310459312052, 329761.876689540746156 ], [ 2009770.444256304064766, 329875.0 ], [ 2009774.263043199898675, 329888.36575413600076 ], [ 2009791.791505856206641, 330125.0 ], [ 2009792.979578990023583, 330141.038987306994386 ], [ 2009737.728454741183668, 330237.728454741125461 ], [ 2009555.910272921202704, 330555.910272921260912 ], [ 2009625.0, 330625.0 ], [ 2009625.0, 330875.0 ], [ 2009375.0, 330875.0 ], [ 2009375.0, 331125.0 ], [ 2009125.0, 331125.0 ], [ 2009040.099367298651487, 331040.099367298651487 ], [ 2008801.003182099899277, 331254.672866837994661 ], [ 2008779.566767575684935, 331279.566767575684935 ], [ 2008548.223483992973343, 331548.22348399303155 ], [ 2008316.88020041026175, 331816.880200410319958 ], [ 2008051.554817429045215, 332125.0 ], [ 2007969.865275036310777, 332219.865275036310777 ], [ 2007930.684267840115353, 332265.365799522027373 ], [ 2007771.11454053921625, 332521.114540539099835 ], [ 2007550.314211132237688, 332875.0 ], [ 2007482.956645802594721, 332982.956645802536514 ], [ 2007290.851382644847035, 333290.851382644847035 ], [ 2007247.530711489962414, 333360.283143263019156 ], [ 2007064.971143612172455, 333564.971143612230662 ], [ 2006938.707870949991047, 333706.539055385976098 ], [ 2006846.326062612701207, 333875.0 ], [ 2006779.617316730087623, 333996.64536013797624 ], [ 2006769.210183766670525, 334125.0 ], [ 2006758.394419982563704, 334258.394419982505497 ], [ 2006751.542513039894402, 334342.901272260991391 ], [ 2006657.959834089968354, 334530.06663016602397 ], [ 2006557.940748014487326, 334625.0 ], [ 2006464.084190337220207, 334714.084190337278415 ], [ 2006207.562451206380501, 334957.562451206322294 ], [ 2006125.0, 335035.926811672979966 ], [ 2006105.822028269991279, 335054.129632298019715 ], [ 2005815.71572351991199, 335297.444597574009094 ], [ 2005803.438300265232101, 335303.438300265290309 ], [ 2005467.459464286686853, 335467.459464286803268 ], [ 2005375.0, 335512.597155513591133 ], [ 2004963.49121031910181, 335713.49121031910181 ], [ 2004875.0, 335756.691643703321461 ], [ 2004627.215700830100104, 335877.657207078009378 ], [ 2004455.95006786310114, 335955.950067863217555 ], [ 2004625.0, 336125.0 ], [ 2004875.0, 336125.0 ], [ 2004875.0, 336375.0 ], [ 2004625.0, 336375.0 ], [ 2004375.0, 336375.0 ], [ 2004375.0, 335992.955813172273338 ], [ 2004299.67632450000383, 336027.389493400987703 ], [ 2004125.0, 336112.786807600059547 ], [ 2003878.554269209969789, 336233.271387096028775 ], [ 2003798.266360673354939, 336298.266360673296731 ], [ 2003521.950571199413389, 336521.950571199529804 ], [ 2003485.507017609896138, 336551.452495533972979 ], [ 2003258.463113754056394, 336758.463113754056394 ], [ 2003167.32590917008929, 336841.55880028597312 ], [ 2003091.741589248180389, 337125.0 ], [ 2003055.026694430038333, 337262.680855571001302 ], [ 2003076.086534011177719, 337375.0 ], [ 2003139.251105489907786, 337711.877714540984016 ], [ 2003246.088069938356057, 337753.911930061702151 ], [ 2003375.0, 337625.0 ], [ 2003375.0, 337375.0 ], [ 2003625.0, 337375.0 ], [ 2003625.0, 337625.0 ], [ 2003625.0, 337902.992033692600671 ], [ 2003710.105447100009769, 337936.476144027023111 ], [ 2003875.0, 337948.468475147208665 ], [ 2004125.0, 337966.650293329323176 ], [ 2004224.810181329958141, 337973.909215607971419 ], [ 2004375.0, 337901.089909587753937 ], [ 2004533.633021879941225, 337824.176929284003563 ], [ 2004702.081843989901245, 337777.385589807992801 ], [ 2004777.385589807992801, 337777.385589807992801 ], [ 2004875.0, 337777.385589807992801 ], [ 2004875.0, 337375.0 ], [ 2005125.0, 337375.0 ], [ 2005375.0, 337375.0 ], [ 2005375.0, 337727.439467867545318 ], [ 2005779.495071282377467, 337529.495071282435674 ], [ 2005875.0, 337482.758616803621408 ], [ 2006152.613367750076577, 337346.90526662801858 ], [ 2006284.5399657539092, 337284.539965753792785 ], [ 2006375.0, 337241.777040473942179 ], [ 2006625.0, 337123.595222292642575 ], [ 2006667.318101990036666, 337103.590301351970993 ], [ 2007040.623179794289172, 337040.623179794405587 ], [ 2007125.0, 337026.390945060877129 ], [ 2007375.0, 336984.222270361962728 ], [ 2007444.054337290115654, 336972.574550819001161 ], [ 2007779.622726832749322, 336779.622726832691114 ], [ 2007875.0, 336724.780794761667494 ], [ 2008192.715768910013139, 336542.09422763902694 ], [ 2008249.736196049489081, 336499.736196049605496 ], [ 2008536.621441951021552, 336286.62144195107976 ], [ 2008625.0, 336220.968798828951549 ], [ 2008966.949310803320259, 335966.949310803320259 ], [ 2009253.83455670485273, 335753.834556704794522 ], [ 2009540.719802606385201, 335540.719802606268786 ], [ 2009625.0, 335478.111655970860738 ], [ 2009625.0, 335125.0 ], [ 2009875.0, 335125.0 ], [ 2009971.047671458451077, 335221.047671458509285 ], [ 2010257.932917359983549, 335007.932917359983549 ], [ 2010375.0, 334920.968798827321734 ], [ 2010688.260786212282255, 334688.260786212224048 ], [ 2010813.03077957010828, 334595.574505431985017 ], [ 2010992.578270388534293, 334492.5782703885925 ], [ 2011125.0, 334416.615417743101716 ], [ 2011469.179255609866232, 334219.179255609866232 ], [ 2011786.913245757343248, 334036.913245757343248 ], [ 2011875.0, 333986.382859602512326 ], [ 2011875.0, 333625.0 ], [ 2011875.0, 333375.0 ], [ 2012125.0, 333375.0 ], [ 2012241.619971779873595, 333491.61997177999001 ], [ 2012453.61997177824378, 333203.619971778301988 ], [ 2012695.520784334046766, 332875.0 ], [ 2012703.400894399965182, 332864.294944815977942 ], [ 2012771.978686381364241, 332771.978686381364241 ], [ 2012946.71585967997089, 332536.755568484019022 ], [ 2013005.758291682694107, 332505.7582916826359 ], [ 2013125.0, 332443.156394816120155 ], [ 2013321.046575489919633, 332340.231942683982197 ], [ 2013375.0, 332335.857340696733445 ], [ 2013801.293040144955739, 332301.293040144839324 ], [ 2013875.0, 332295.316800156666432 ], [ 2013961.714070417685434, 332288.285929582372773 ], [ 2014013.558399739908054, 332284.082335313025396 ], [ 2014375.0, 332352.463178606063593 ], [ 2014625.0, 332399.760475903749466 ], [ 2014706.070223979884759, 332415.098085845995229 ], [ 2014778.094239746453241, 332471.905760253488552 ], [ 2015057.621798801701516, 332692.378201198414899 ], [ 2015370.50724453991279, 332939.161087977990974 ], [ 2015375.0, 332942.219079854083247 ], [ 2015483.756119152763858, 333016.243880847119726 ], [ 2015781.260144917760044, 333218.739855082239956 ], [ 2016125.0, 333452.706224644323811 ], [ 2016227.516183565137908, 333522.483816434862092 ], [ 2016525.020209329901263, 333724.979790669982322 ], [ 2016875.0, 333963.193369434506167 ], [ 2016971.276247977279127, 334028.723752022604458 ], [ 2017268.780273742275313, 334231.219726257724687 ], [ 2017625.0, 334473.68051422474673 ], [ 2017715.036312389653176, 334534.963687610405032 ], [ 2018012.540338154416531, 334737.459661845467053 ], [ 2018375.0, 334984.167659014987294 ], [ 2018458.796376801794395, 335041.203623198147397 ], [ 2018756.300402566790581, 335243.699597433209419 ], [ 2019053.804428331786767, 335446.195571668329649 ], [ 2019375.0, 335664.817185401916504 ], [ 2019500.0604669789318, 335749.939533020951785 ], [ 2019797.564492743927985, 335952.435507256072015 ], [ 2020125.0, 336175.304330192157067 ], [ 2020243.820531391305849, 336256.179468608694151 ], [ 2020541.324557156302035, 336458.67544284381438 ], [ 2020625.0, 336375.0 ], [ 2020875.0, 336375.0 ], [ 2020875.0, 336685.791474982397631 ], [ 2020987.580595803447068, 336762.419404196436517 ], [ 2021285.084621568443254, 336964.915378431556746 ], [ 2021375.0, 336875.0 ], [ 2021625.0, 336875.0 ], [ 2021875.0, 336875.0 ], [ 2021875.0, 337125.0 ], [ 2021731.340660215821117, 337268.659339784178883 ], [ 2022028.844685980817303, 337471.155314019299112 ], [ 2022125.0, 337375.0 ], [ 2022375.0, 337375.0 ], [ 2022625.0, 337375.0 ], [ 2022625.0, 337625.0 ], [ 2022478.972284559160471, 337771.027715440897737 ], [ 2022782.575888162711635, 337967.424111837288365 ], [ 2023125.0, 338188.932884479698259 ], [ 2023237.981293568154797, 338262.018706431786995 ], [ 2023375.0, 338125.0 ], [ 2023375.0, 337875.0 ], [ 2023375.0, 337625.0 ], [ 2023625.0, 337625.0 ], [ 2023625.0, 337875.0 ], [ 2023625.0, 338125.0 ], [ 2023625.0, 338375.0 ], [ 2023875.0, 338375.0 ], [ 2024125.0, 338375.0 ], [ 2024125.0, 338125.0 ], [ 2024375.0, 338125.0 ], [ 2024375.0, 338375.0 ], [ 2024375.0, 338625.0 ], [ 2024375.0, 338875.0 ], [ 2024300.593906180933118, 338949.406093819066882 ], [ 2024625.0, 339159.259293974901084 ], [ 2024755.99931158637628, 339244.000688413565513 ], [ 2025125.0, 339482.701430473360233 ], [ 2025211.404716991819441, 339538.595283008122351 ], [ 2025440.003499800106511, 339686.47224043298047 ], [ 2025485.883939142571762, 339764.116060857428238 ], [ 2025551.406266818754375, 339875.0 ], [ 2025561.660982439992949, 339892.354134128021542 ], [ 2025552.302714539924636, 340088.87775992800016 ], [ 2025535.445669173495844, 340125.0 ], [ 2025484.394774437416345, 340234.39477443729993 ], [ 2025421.286964009981602, 340369.625796784996055 ], [ 2025271.55467768991366, 340509.999815213028342 ], [ 2025265.023668463807553, 340515.023668463807553 ], [ 2025028.239712409907952, 340697.165173117013182 ], [ 2024973.459618293214589, 340723.459618293156382 ], [ 2025125.0, 340875.0 ], [ 2025125.0, 341125.0 ], [ 2025242.967770617455244, 341242.967770617571659 ], [ 2025496.153107170015574, 341024.70454945001984 ], [ 2025513.204662976320833, 341013.204662976204418 ], [ 2025625.0, 340937.807807775272522 ], [ 2025898.558626669924706, 340753.314780489017721 ], [ 2025998.553137133130804, 340748.553137133247219 ], [ 2026095.082252470077947, 340743.956512593023945 ], [ 2026125.0, 340749.467676611733623 ], [ 2026125.0, 340375.0 ], [ 2026375.0, 340375.0 ], [ 2026375.0, 340625.0 ], [ 2026231.005073083331808, 340768.994926916609984 ], [ 2026450.696432489901781, 340809.464387859974522 ], [ 2026625.0, 340918.897695617226418 ], [ 2026751.611554779810831, 340998.388445220189169 ], [ 2026875.0, 340875.0 ], [ 2027125.0, 340875.0 ], [ 2027125.0, 340625.0 ], [ 2027375.0, 340625.0 ], [ 2027375.0, 340875.0 ], [ 2027375.0, 341125.0 ], [ 2027212.347141260746866, 341287.652858739311341 ], [ 2027519.504198914626613, 341480.495801085373387 ], [ 2027875.0, 341703.687339631142095 ], [ 2027980.239785395562649, 341769.760214604495559 ], [ 2028287.396843049442396, 341962.603156950557604 ], [ 2028625.0, 342174.561126039479859 ], [ 2028748.132429530378431, 342251.867570469621569 ], [ 2029125.0, 342488.476983645057771 ], [ 2029208.868016011314467, 342541.131983988743741 ], [ 2029342.401212109951302, 342624.968359532998875 ], [ 2029508.24220726150088, 342741.757792738440912 ], [ 2029801.630637013586238, 342948.36936298647197 ], [ 2029875.0, 342875.0 ], [ 2030125.0, 342875.0 ], [ 2030125.0, 343125.0 ], [ 2030033.358234973857179, 343216.641765026201028 ], [ 2030034.913036359939724, 343223.897504827007651 ], [ 2030019.094194850884378, 343269.09419485082617 ], [ 2029969.405161089962348, 343411.062862731982023 ], [ 2029821.294835292035714, 343625.0 ], [ 2029800.956338980002329, 343654.377828006981872 ], [ 2029714.733685465529561, 343714.733685465645976 ], [ 2029625.0, 343777.547265290108044 ], [ 2029613.790981069905683, 343785.393578540999442 ], [ 2029292.459090777207166, 344042.459090777207166 ], [ 2029375.0, 344125.0 ], [ 2029375.0, 344375.0 ], [ 2029625.0, 344375.0 ], [ 2029875.0, 344375.0 ], [ 2030125.0, 344375.0 ], [ 2030125.0, 344628.064234380959533 ], [ 2030240.794930049916729, 344702.5038322720211 ], [ 2030334.377609, 344702.5038322720211 ], [ 2030390.527216369984671, 344562.129813843988813 ], [ 2030437.31855585006997, 344393.680991730012465 ], [ 2030448.096051078988239, 344375.0 ], [ 2030512.817008001729846, 344262.817008001788054 ], [ 2030577.692574280081317, 344150.366026454023086 ], [ 2030700.308486106572673, 343950.308486106514465 ], [ 2030755.499664290109649, 343860.259721702022944 ], [ 2030875.0, 343834.281387852039188 ], [ 2030970.739825879922137, 343813.468382226012181 ], [ 2031125.0, 343856.661230980011169 ], [ 2031204.696523260092363, 343878.976257493020967 ], [ 2031300.643960478482768, 343949.356039521517232 ], [ 2031625.0, 344187.279094299650751 ], [ 2031733.288588577648625, 344266.711411422467791 ], [ 2031875.0, 344125.0 ], [ 2032125.0, 344125.0 ], [ 2032375.0, 344125.0 ], [ 2032625.0, 344125.0 ], [ 2032625.0, 344375.0 ], [ 2032375.0, 344375.0 ], [ 2032375.0, 344625.0 ], [ 2032625.0, 344625.0 ], [ 2032625.0, 344920.803449601109605 ], [ 2032742.792720808647573, 345007.207279191410635 ], [ 2033031.222472874680534, 345218.777527125377674 ], [ 2033375.0, 345470.94671607716009 ], [ 2033463.86710097361356, 345536.13289902638644 ], [ 2033752.296853039646521, 345747.703146960353479 ], [ 2034040.726605105679482, 345959.273394894320518 ], [ 2034375.0, 346204.471071378618944 ], [ 2034470.732018690090626, 346274.692838669987395 ], [ 2034472.124453406548128, 346277.875546593335457 ], [ 2034514.616401774343103, 346375.0 ], [ 2034536.239893960068002, 346424.425124993023928 ], [ 2034573.672965540084988, 346611.590482897998299 ], [ 2034567.362604551017284, 346625.0 ], [ 2034505.806571095483378, 346755.806571095483378 ], [ 2034498.806822380051017, 346770.681037115980871 ], [ 2034339.716268159914762, 346985.921198707015719 ], [ 2034294.147701082052663, 347044.147701082110871 ], [ 2034171.267446039943025, 347201.16136029700283 ], [ 2034068.326499199960381, 347313.460575038974639 ], [ 2034012.941016733646393, 347375.0 ], [ 2033984.102088140090927, 347407.043253991985694 ], [ 2034021.535159720107913, 347538.059004525013734 ], [ 2034105.759570779977366, 347622.283415581972804 ], [ 2034199.342249729903415, 347631.64168347697705 ], [ 2034358.43280395003967, 347547.41727242001798 ], [ 2034508.165090270107612, 347528.700736629019957 ], [ 2034531.267692423891276, 347531.267692423949484 ], [ 2034625.0, 347541.682393265888095 ], [ 2034699.985846060561016, 347550.014153939438984 ], [ 2034760.838323439937085, 347556.775540315022226 ], [ 2034919.92887766007334, 347669.074755057983566 ], [ 2034984.327424573944882, 347765.672575426171534 ], [ 2035125.0, 347625.0 ], [ 2035375.0, 347625.0 ], [ 2035375.0, 347875.0 ], [ 2035375.0, 348125.0 ], [ 2035264.198325752746314, 348235.801674247137271 ], [ 2035331.692665050039068, 348361.586579304013867 ], [ 2035340.076052985154092, 348375.0 ], [ 2035545.816032607574016, 348704.183967392367776 ], [ 2035612.440701910061762, 348810.783438274986111 ], [ 2035630.553065473912284, 348875.0 ], [ 2035715.381648760056123, 349175.755886188999284 ], [ 2035719.413591908058152, 349280.586408092058264 ], [ 2035875.0, 349125.0 ], [ 2036125.0, 349125.0 ], [ 2036125.0, 349375.0 ], [ 2035723.044883902417496, 349375.0 ], [ 2035724.739916650112718, 349419.070851463999134 ], [ 2035865.113935079891235, 349596.877941474027466 ], [ 2035992.176342483609915, 349757.823657516506501 ], [ 2036005.487953509902582, 349774.685031483008061 ], [ 2035985.424959806958213, 349875.0 ], [ 2035968.054881929885596, 349961.850389386992902 ], [ 2035965.487505705095828, 349965.487505705154035 ], [ 2035875.0, 350093.678138779476285 ], [ 2035875.0, 350375.0 ], [ 2036125.0, 350375.0 ], [ 2036125.0, 350576.604799978144001 ], [ 2036155.220239829970524, 350551.421266785997432 ], [ 2036239.444650890072808, 350570.137802576995455 ], [ 2036375.0, 350575.35146985045867 ], [ 2036482.759616160066798, 350579.496070471999701 ], [ 2036679.283241959987208, 350523.346463100984693 ], [ 2036760.372225702274591, 350510.372225702158175 ], [ 2036875.0, 350492.031781814410351 ], [ 2036875.0, 350125.0 ], [ 2036875.0, 349875.0 ], [ 2036625.0, 349875.0 ], [ 2036625.0, 349625.0 ], [ 2036875.0, 349625.0 ], [ 2037125.0, 349625.0 ], [ 2037375.0, 349625.0 ], [ 2037375.0, 349875.0 ], [ 2037375.0, 350125.0 ], [ 2037125.0, 350125.0 ], [ 2037125.0, 350375.0 ], [ 2036980.972776822280139, 350519.027223177661654 ], [ 2037334.361994629958645, 350691.795285215019248 ], [ 2037375.0, 350721.492289139947388 ], [ 2037375.0, 350375.0 ], [ 2037625.0, 350375.0 ], [ 2037625.0, 350625.0 ], [ 2037875.0, 350625.0 ], [ 2038125.0, 350625.0 ], [ 2038125.0, 350875.0 ], [ 2038125.0, 351292.092327469727024 ], [ 2038375.0, 351234.949470327468589 ], [ 2038625.0, 351177.806613185210153 ], [ 2038663.236035750014707, 351169.066947871004231 ], [ 2038875.0, 351167.087845401430968 ], [ 2039125.0, 351164.751396803359967 ], [ 2039125.0, 350875.0 ], [ 2039125.0, 350625.0 ], [ 2039375.0, 350625.0 ], [ 2039375.0, 350875.0 ], [ 2039625.0, 350875.0 ], [ 2039875.0, 350875.0 ], [ 2039875.0, 350625.0 ], [ 2040125.0, 350625.0 ], [ 2040125.0, 350875.0 ], [ 2040125.0, 351125.0 ], [ 2039964.293289145454764, 351285.706710854603443 ], [ 2040375.0, 351458.360487391939387 ], [ 2040492.320194975240156, 351507.679805024818052 ], [ 2040625.0, 351375.0 ], [ 2040875.0, 351375.0 ], [ 2040875.0, 351668.551570194249507 ], [ 2041020.347100805025548, 351729.65289919503266 ], [ 2041125.0, 351625.0 ], [ 2041375.0, 351625.0 ], [ 2041375.0, 351885.000225200958084 ], [ 2041625.0, 351996.582146105298307 ], [ 2041625.0, 351625.0 ], [ 2041625.0, 351375.0 ], [ 2041375.0, 351375.0 ], [ 2041125.0, 351375.0 ], [ 2041125.0, 351125.0 ], [ 2041375.0, 351125.0 ], [ 2041375.0, 350875.0 ], [ 2041625.0, 350875.0 ], [ 2041875.0, 350875.0 ], [ 2041875.0, 350625.0 ], [ 2041875.0, 350375.0 ], [ 2042125.0, 350375.0 ], [ 2042125.0, 350625.0 ], [ 2042375.0, 350625.0 ], [ 2042625.0, 350625.0 ], [ 2042875.0, 350625.0 ], [ 2043125.0, 350625.0 ], [ 2043375.0, 350625.0 ], [ 2043625.0, 350625.0 ], [ 2043875.0, 350625.0 ], [ 2044125.0, 350625.0 ], [ 2044125.0, 350875.0 ], [ 2044375.0, 350875.0 ], [ 2044375.0, 351125.0 ], [ 2044375.0, 351375.0 ], [ 2044625.0, 351375.0 ], [ 2044875.0, 351375.0 ], [ 2045125.0, 351375.0 ], [ 2045125.0, 351625.0 ], [ 2045375.0, 351625.0 ], [ 2045625.0, 351625.0 ], [ 2045625.0, 351875.0 ], [ 2045375.0, 351875.0 ], [ 2045125.0, 351875.0 ], [ 2044875.0, 351875.0 ], [ 2044875.0, 352125.0 ], [ 2045125.0, 352125.0 ], [ 2045125.0, 352375.0 ], [ 2044875.0, 352375.0 ], [ 2044875.0, 352653.408305170363747 ], [ 2045267.152075534453616, 352517.152075534453616 ], [ 2045375.0, 352479.679491609684192 ], [ 2045625.0, 352392.815084829286207 ], [ 2045672.578689269954339, 352376.283506354026031 ], [ 2045875.0, 352446.413724244979676 ], [ 2046007.634251584066078, 352492.365748415933922 ], [ 2046375.0, 352619.642070702218916 ], [ 2046625.0, 352706.256243930838536 ], [ 2046750.324310062918812, 352749.67568993702298 ], [ 2046861.078711959999055, 352788.047293743991759 ], [ 2047125.0, 352871.509581414051354 ], [ 2047375.0, 352950.569410473166499 ], [ 2047507.521941394079477, 352992.478058605978731 ], [ 2047875.0, 353108.689068591454998 ], [ 2047955.996055709896609, 353134.303205867006909 ], [ 2048125.0, 353217.148276598658413 ], [ 2048230.92681438731961, 353269.073185612796806 ], [ 2048433.267718360060826, 353368.259903247992042 ], [ 2048452.087732181418687, 353500.0 ], [ 2048470.700789940077811, 353630.291404313989915 ], [ 2048330.326771510066465, 353873.606369589979295 ], [ 2048329.118958488106728, 353875.0 ], [ 2048234.34944204846397, 353984.34944204846397 ], [ 2048125.0, 354110.521875184436794 ], [ 2048087.011806240072474, 354154.35440644697519 ], [ 2047740.755894120084122, 354229.220549607998691 ], [ 2047727.399179421830922, 354227.39917942188913 ], [ 2047875.0, 354375.0 ], [ 2047875.0, 354625.0 ], [ 2048125.0, 354625.0 ], [ 2048125.0, 354875.0 ], [ 2048375.0, 354875.0 ], [ 2048375.0, 355125.0 ], [ 2048125.0, 355125.0 ], [ 2047875.0, 355125.0 ], [ 2047625.0, 355125.0 ], [ 2047375.0, 355125.0 ], [ 2047375.0, 355375.0 ], [ 2047125.0, 355375.0 ], [ 2047125.0, 355125.0 ], [ 2046875.0, 355125.0 ], [ 2046875.0, 354875.0 ], [ 2047125.0, 354875.0 ], [ 2047125.0, 354625.0 ], [ 2047375.0, 354625.0 ], [ 2047375.0, 354179.344745864684228 ], [ 2047328.992106729885563, 354173.070942236983683 ], [ 2047125.0, 354243.193228925112635 ], [ 2047029.527534079970792, 354276.011889084998984 ], [ 2046768.949744597775862, 354625.0 ], [ 2046707.413975914940238, 354707.41397591488203 ], [ 2046505.464531949954107, 354977.881981225975323 ], [ 2046487.374677254352719, 354987.374677254352719 ], [ 2046375.0, 355046.343567298550624 ], [ 2045995.491560370894149, 355245.491560370835941 ], [ 2045875.0, 355308.719804921769537 ], [ 2045560.279474529903382, 355473.870179673016537 ], [ 2045491.544808166567236, 355491.544808166567236 ], [ 2045375.0, 355521.513473123952281 ], [ 2045375.0, 355875.0 ], [ 2045625.0, 355875.0 ], [ 2045625.0, 356125.0 ], [ 2045625.0, 356375.0 ], [ 2045875.0, 356375.0 ], [ 2045875.0, 356625.0 ], [ 2046125.0, 356625.0 ], [ 2046375.0, 356625.0 ], [ 2046375.0, 356875.0 ], [ 2046625.0, 356875.0 ], [ 2046625.0, 356625.0 ], [ 2046875.0, 356625.0 ], [ 2046875.0, 356375.0 ], [ 2046625.0, 356375.0 ], [ 2046625.0, 356125.0 ], [ 2046875.0, 356125.0 ], [ 2046875.0, 355875.0 ], [ 2047125.0, 355875.0 ], [ 2047375.0, 355875.0 ], [ 2047625.0, 355875.0 ], [ 2047875.0, 355875.0 ], [ 2047895.280881618382409, 355895.280881618324202 ], [ 2047899.410151296760887, 355996.421776332135778 ], [ 2048059.782211526064202, 356095.699855783430394 ], [ 2048056.414309432962909, 356241.334207701147534 ], [ 2048040.994343778584152, 356290.994343778467737 ], [ 2047924.015269186114892, 356325.984730813885108 ], [ 2047875.0, 356375.0 ], [ 2047875.0, 356625.0 ], [ 2047625.0, 356625.0 ], [ 2047625.0, 356875.0 ], [ 2047625.0, 357125.0 ], [ 2047875.0, 357125.0 ], [ 2048125.0, 357125.0 ], [ 2048125.0, 357375.0 ], [ 2048125.0, 357625.0 ], [ 2048125.0, 357875.0 ], [ 2048375.0, 357875.0 ], [ 2048625.0, 357875.0 ], [ 2048625.0, 358125.0 ], [ 2048875.0, 358125.0 ], [ 2048875.0, 358375.0 ], [ 2049125.0, 358375.0 ], [ 2049125.0, 358125.0 ], [ 2049375.0, 358125.0 ], [ 2049625.0, 358125.0 ], [ 2049625.0, 357875.0 ], [ 2049875.0, 357875.0 ], [ 2049875.0, 358125.0 ], [ 2050125.0, 358125.0 ], [ 2050531.076964991400018, 358125.0 ], [ 2050548.967066898010671, 358048.967066898068879 ], [ 2050648.724023817339912, 357625.0 ], [ 2050375.0, 357625.0 ], [ 2050375.0, 357875.0 ], [ 2050125.0, 357875.0 ], [ 2050125.0, 357625.0 ], [ 2050125.0, 357375.0 ], [ 2050125.0, 357125.0 ], [ 2050375.0, 357125.0 ], [ 2050625.0, 357125.0 ], [ 2050947.687645873054862, 357125.0 ], [ 2050950.641782179940492, 357120.925329232006334 ], [ 2051044.023082175292075, 357044.023082175292075 ], [ 2051125.0, 356977.336208671040367 ], [ 2051125.0, 356625.0 ], [ 2051385.769804697716609, 356625.0 ], [ 2051465.513203134061769, 356465.513203133945353 ], [ 2051502.779588, 356390.980433405027725 ], [ 2051554.664228707784787, 356445.335771292157006 ], [ 2051625.0, 356375.0 ], [ 2051625.0, 356125.0 ], [ 2051875.0, 356125.0 ], [ 2051875.0, 356375.0 ], [ 2051875.0, 356625.0 ], [ 2052311.916275671450421, 356625.0 ], [ 2052288.87409119005315, 356400.338701299973764 ], [ 2052291.964176714653149, 356375.0 ], [ 2052300.989809681195766, 356300.989809681137558 ], [ 2052335.665430669905618, 356016.649717596010305 ], [ 2052406.490289468783885, 355875.0 ], [ 2052476.039449099916965, 355735.901680739014409 ], [ 2052482.118906959658489, 355732.118906959600281 ], [ 2052790.338085040450096, 355540.338085040508304 ], [ 2052625.0, 355375.0 ], [ 2052375.0, 355375.0 ], [ 2052375.0, 355625.0 ], [ 2052125.0, 355625.0 ], [ 2051875.0, 355625.0 ], [ 2051625.0, 355625.0 ], [ 2051625.0, 355875.0 ], [ 2051375.0, 355875.0 ], [ 2051125.0, 355875.0 ], [ 2050875.0, 355875.0 ], [ 2050875.0, 355625.0 ], [ 2050875.0, 355375.0 ], [ 2050625.0, 355382.912428987619933 ], [ 2050686.458111064741388, 355073.265250973519869 ], [ 2050723.183999999891967, 355066.4851 ], [ 2050747.004, 355060.530199999979232 ], [ 2050836.327, 355024.800999999977648 ], [ 2050887.936, 354995.026699999987613 ], [ 2050910.884441662346944, 354980.747683905356098 ], [ 2050977.259, 354939.447999999974854 ], [ 2051108.266, 354852.10999999998603 ], [ 2051119.563230130355805, 354846.244091359432787 ], [ 2051211.483, 354798.516200000012759 ], [ 2051306.761, 354754.847200000018347 ], [ 2051339.851474932162091, 354741.190803439472802 ], [ 2051431.813, 354703.238399999972899 ], [ 2051505.257, 354679.418899999989662 ], [ 2051572.818477610126138, 354661.120849128928967 ], [ 2051600.534, 354653.614500000025146 ], [ 2051767.271, 354615.900399999984074 ], [ 2051813.08432263857685, 354606.194154093100224 ], [ 2052001.495000000111759, 354566.276499999978114 ], [ 2052054.392753534484655, 354555.606147173035424 ], [ 2052296.063303152332082, 354506.857195468794089 ], [ 2052463.99, 354472.983599999977741 ], [ 2052534.696291639702395, 354454.267284148954786 ], [ 2052613.944667972391471, 354125.0 ], [ 2052673.265417135553434, 354143.942089368880261 ], [ 2052875.0, 354069.359012868138961 ], [ 2052904.208318482618779, 354094.469294218695723 ], [ 2053148.391622352646664, 353994.126779674785212 ], [ 2053146.790609032381326, 353896.790609032323118 ], [ 2053375.0, 353853.129190048901364 ], [ 2053406.365308852866292, 353879.118521186290309 ], [ 2053625.0, 353823.244815596495755 ], [ 2053663.131689874920994, 353861.772455535479821 ], [ 2053875.0, 353803.9519838662236 ], [ 2053910.105774469673634, 353847.911656951182522 ], [ 2054125.0, 353783.61728427791968 ], [ 2054157.475470915203914, 353836.179934816900641 ], [ 2054375.0, 353761.103910181613173 ], [ 2054405.525373977608979, 353829.287263249338139 ], [ 2054640.49694138020277, 353726.582696879399009 ], [ 2054649.23748409259133, 353649.237484092533123 ], [ 2054875.0, 353631.366473019646946 ], [ 2055125.0, 353616.0711170466966 ], [ 2055375.0, 353601.183635311434045 ], [ 2055625.0, 353585.932005941634998 ], [ 2055875.0, 353574.024443101196084 ], [ 2056125.0, 353559.748845178051852 ], [ 2056146.247539822710678, 353594.238262819766533 ], [ 2056375.0, 353565.189082252269145 ], [ 2056402.627314012264833, 353604.969436102895997 ], [ 2056625.0, 353581.976500147837214 ], [ 2056658.175532867899165, 353622.710814676713198 ], [ 2056875.0, 353603.90383220568765 ], [ 2056916.989277934422716, 353646.347393477743026 ], [ 2057114.510077364509925, 353625.0 ], [ 2057139.27351446961984, 353807.841307688562665 ], [ 2057375.0, 353785.807741610682569 ], [ 2057389.012500252341852, 353821.701727379695512 ], [ 2057625.0, 353832.339210560137872 ], [ 2057632.892756410408765, 353845.583374651672784 ], [ 2057875.0, 353864.916898941854015 ], [ 2058125.0, 353895.644056870019995 ], [ 2058333.412036124849692, 353916.587963875208516 ], [ 2058343.532893176889047, 353971.947776140645146 ], [ 2058573.495666530216113, 354099.253049300634302 ], [ 2058625.0, 354019.287746681598946 ], [ 2058821.234719607280567, 354106.711431483156048 ], [ 2058875.0, 354043.578457493975293 ], [ 2059067.533013119595125, 354118.25090581382392 ], [ 2059125.0, 354064.438373746932484 ], [ 2059302.939927732106298, 354127.833226935239509 ], [ 2059375.0, 354072.547782423382159 ], [ 2059479.528306855354458, 354115.575721094384789 ], [ 2059531.247434145305306, 354340.55549108015839 ], [ 2059591.962, 354324.112000000022817 ], [ 2059683.27, 354274.488200000021607 ], [ 2059748.387329578632489, 354227.130101456714328 ], [ 2059770.608, 354210.969600000011269 ], [ 2059867.871, 354141.4962 ], [ 2059948.375940116588026, 354084.718807010853197 ], [ 2060086.491612219018862, 354299.844311335938983 ], [ 2060229.512232922716066, 354139.291739791049622 ], [ 2060375.0, 354183.159451701270882 ], [ 2060464.563876286381856, 354093.325358352158219 ], [ 2060400.958919165888801, 353910.302681645960547 ], [ 2060405.793, 353909.256500000017695 ], [ 2060518.936, 353873.527300000016112 ], [ 2060612.229, 353811.9937 ], [ 2060619.980225313687697, 353803.537643563351594 ], [ 2060634.063, 353788.174300000013318 ], [ 2060689.642, 353702.8212 ], [ 2060721.401, 353603.5735 ], [ 2060721.401, 353583.945469315221999 ], [ 2060859.709153409814462, 353594.106941066042054 ], [ 2060936.052242371952161, 353375.0 ], [ 2061125.0, 353375.0 ], [ 2061125.0, 353125.0 ], [ 2061125.0, 352875.0 ], [ 2060875.0, 352875.0 ], [ 2060615.875600476050749, 352875.0 ], [ 2060594.955344538670033, 352883.180850168806501 ], [ 2060295.89290426322259, 352753.722286372852977 ], [ 2060319.55769241345115, 353000.673875383858103 ], [ 2060163.097459559794515, 353067.355153968965169 ], [ 2060125.0, 353125.0 ], [ 2060125.0, 353375.0 ], [ 2060125.0, 353625.0 ], [ 2059875.0, 353625.0 ], [ 2059625.0, 353625.0 ], [ 2059375.0, 353625.0 ], [ 2059375.0, 353375.0 ], [ 2059375.0, 353125.0 ], [ 2059625.0, 353125.0 ], [ 2059625.0, 352875.0 ], [ 2059625.0, 352625.0 ], [ 2059375.0, 352625.0 ], [ 2059125.0, 352625.0 ], [ 2058875.0, 352625.0 ], [ 2058625.0, 352625.0 ], [ 2058625.0, 352875.0 ], [ 2058875.0, 352875.0 ], [ 2058875.0, 353125.0 ], [ 2058625.0, 353125.0 ], [ 2058625.0, 353375.0 ], [ 2058375.0, 353375.0 ], [ 2058375.0, 353625.0 ], [ 2058125.0, 353625.0 ], [ 2057875.0, 353625.0 ], [ 2057875.0, 353375.0 ], [ 2057875.0, 353125.0 ], [ 2057875.0, 352875.0 ], [ 2058125.0, 352875.0 ], [ 2058125.0, 352625.0 ], [ 2058125.0, 352375.0 ], [ 2058375.0, 352375.0 ], [ 2058375.0, 352125.0 ], [ 2058625.0, 352125.0 ], [ 2058625.0, 351875.0 ], [ 2058875.0, 351875.0 ], [ 2059125.0, 351875.0 ], [ 2059375.0, 351875.0 ], [ 2059375.0, 351746.357840756012592 ], [ 2059427.903657301561907, 351650.729735348955728 ], [ 2059625.0, 351758.932045619178098 ], [ 2059673.995058369124308, 351652.305168879975099 ], [ 2059875.0, 351772.684193356079049 ], [ 2059919.377369914203882, 351654.814204456051812 ], [ 2060123.591380463680252, 351785.751374438928906 ], [ 2060158.335058291675523, 351754.521282917354256 ], [ 2060330.204857724253088, 351819.724748992884997 ], [ 2060386.95, 351771.946799999976065 ], [ 2060407.137546690180898, 351713.740684832155239 ], [ 2060375.690805861959234, 351585.1759505996597 ], [ 2060347.54, 351583.63890000001993 ], [ 2060247.435, 351577.7048 ], [ 2060170.242608245229349, 351571.859622314281296 ], [ 2060183.066451482241973, 351375.142003979417495 ], [ 2060375.0, 351327.830256019020453 ], [ 2060436.516043751034886, 351387.744993808853906 ], [ 2060625.0, 351374.847991493297741 ], [ 2060639.944290086627007, 351387.894145780184772 ], [ 2060635.897513984469697, 351600.890607873327099 ], [ 2060650.648, 351601.70150000002468 ], [ 2060751.325999999884516, 351607.555799999972805 ], [ 2060854.733, 351615.192800000018906 ], [ 2060857.700888885883614, 351615.397245519154239 ], [ 2060964.719821736216545, 351696.371154662920162 ], [ 2060991.953694114694372, 351624.893341886578128 ], [ 2061027.602, 351627.59519999998156 ], [ 2061044.033, 351635.098400000017136 ], [ 2061048.719, 351641.4609 ], [ 2061054.935050831874833, 351651.875175932247657 ], [ 2061061.849, 351663.458700000017416 ], [ 2061063.703, 351664.178100000019185 ], [ 2061083.122, 351764.558200000028592 ], [ 2061065.446651025675237, 351772.888735701038968 ], [ 2061172.273600102867931, 351856.060891543340404 ], [ 2061125.0, 351950.060636591981165 ], [ 2061125.0, 352125.0 ], [ 2061125.0, 352375.0 ], [ 2061125.0, 352625.0 ], [ 2061375.0, 352625.0 ], [ 2061625.0, 352625.0 ], [ 2061625.0, 352375.0 ], [ 2061875.0, 352375.0 ], [ 2062125.0, 352375.0 ], [ 2062125.0, 352625.0 ], [ 2061875.0, 352625.0 ], [ 2061875.0, 352875.0 ], [ 2062125.0, 352875.0 ], [ 2062375.0, 352875.0 ], [ 2062625.0, 352875.0 ], [ 2062625.0, 352625.0 ], [ 2062625.0, 352375.0 ], [ 2062875.0, 352375.0 ], [ 2062875.0, 352125.0 ], [ 2062625.0, 352125.0 ], [ 2062625.0, 351875.0 ], [ 2062375.0, 351875.0 ], [ 2062375.0, 351625.0 ], [ 2062125.0, 351625.0 ], [ 2062125.0, 351375.0 ], [ 2061875.0, 351375.0 ], [ 2061875.0, 351125.0 ], [ 2061625.0, 351125.0 ], [ 2061625.0, 350875.0 ], [ 2061375.0, 350875.0 ], [ 2061125.0, 350875.0 ], [ 2060875.0, 350875.0 ], [ 2060625.0, 350875.0 ], [ 2060375.0, 350875.0 ], [ 2060125.0, 350875.0 ], [ 2059875.0, 350875.0 ], [ 2059625.0, 350875.0 ], [ 2059375.0, 350875.0 ], [ 2059375.0, 351125.0 ], [ 2059125.0, 351125.0 ], [ 2059125.0, 350875.0 ], [ 2058875.0, 350875.0 ], [ 2058625.0, 350875.0 ], [ 2058375.0, 350875.0 ], [ 2058125.0, 350875.0 ], [ 2057875.0, 350875.0 ], [ 2057625.0, 350875.0 ], [ 2057375.0, 350875.0 ], [ 2057125.0, 350875.0 ], [ 2056875.0, 350875.0 ], [ 2056875.0, 351003.812603708007373 ], [ 2056792.118906509829685, 351118.623203010298312 ], [ 2056765.632664176868275, 351207.582327997835819 ], [ 2056713.584, 351191.837999999988824 ], [ 2056615.531, 351162.523600000014994 ], [ 2056531.340559467673302, 351135.295387445541564 ], [ 2056519.756, 351131.548799999989569 ], [ 2056420.75, 351103.553599999984726 ], [ 2056325.352999999886379, 351070.809300000022631 ], [ 2056298.700922008370981, 351060.282652019988745 ], [ 2056350.599363238317892, 351375.0 ], [ 2056125.0, 351375.0 ], [ 2056125.0, 351625.0 ], [ 2055875.0, 351625.0 ], [ 2055625.0, 351625.0 ], [ 2055375.0, 351625.0 ], [ 2055125.0, 351625.0 ], [ 2054875.0, 351625.0 ], [ 2054875.0, 351375.0 ], [ 2054875.0, 351125.0 ], [ 2054875.0, 350875.0 ], [ 2054625.0, 350875.0 ], [ 2054625.0, 351125.0 ], [ 2054375.0, 351125.0 ], [ 2054375.0, 351375.0 ], [ 2054625.0, 351375.0 ], [ 2054625.0, 351625.0 ], [ 2054625.0, 351875.0 ], [ 2054625.0, 352125.0 ], [ 2054625.0, 352375.0 ], [ 2054625.0, 352625.0 ], [ 2054375.0, 352625.0 ], [ 2054125.0, 352625.0 ], [ 2053875.0, 352625.0 ], [ 2053625.0, 352625.0 ], [ 2053375.0, 352625.0 ], [ 2053375.0, 352375.0 ], [ 2053375.0, 352125.0 ], [ 2053125.0, 352125.0 ], [ 2053125.0, 352375.0 ], [ 2052875.0, 352375.0 ], [ 2052625.0, 352375.0 ], [ 2052375.0, 352375.0 ], [ 2052125.0, 352375.0 ], [ 2051875.0, 352375.0 ], [ 2051625.0, 352375.0 ], [ 2051625.0, 352125.0 ], [ 2051375.0, 352125.0 ], [ 2051125.0, 352125.0 ], [ 2051125.0, 351875.0 ], [ 2051125.0, 351625.0 ], [ 2051125.0, 351375.0 ], [ 2050875.0, 351375.0 ], [ 2050875.0, 351125.0 ], [ 2050875.0, 350875.0 ], [ 2051125.0, 350875.0 ], [ 2051125.0, 350625.0 ], [ 2051125.0, 350375.0 ], [ 2051375.0, 350375.0 ], [ 2051625.0, 350375.0 ], [ 2051875.0, 350375.0 ], [ 2052125.0, 350375.0 ], [ 2052375.0, 350375.0 ], [ 2052375.0, 350125.0 ], [ 2052375.0, 349875.0 ], [ 2052375.0, 349625.0 ], [ 2052125.0, 349625.0 ], [ 2052125.0, 349375.0 ], [ 2051875.0, 349375.0 ], [ 2051625.0, 349375.0 ], [ 2051375.0, 349375.0 ], [ 2051125.0, 349375.0 ], [ 2051125.0, 349125.0 ], [ 2051125.0, 348875.0 ], [ 2051125.0, 348625.0 ], [ 2051125.0, 348375.0 ], [ 2051375.0, 348375.0 ], [ 2051625.0, 348375.0 ], [ 2051625.0, 348125.0 ], [ 2051625.0, 347935.163654816860799 ], [ 2051781.506151334848255, 347891.426020058279391 ], [ 2051864.872799330158159, 347757.811560854723211 ], [ 2051855.0, 347751.324499999987893 ], [ 2051764.92, 347702.402 ], [ 2051674.817, 347658.195699999982025 ], [ 2051642.329075674060732, 347647.870469470217358 ], [ 2051577.727, 347627.338800000026822 ], [ 2051479.602, 347601.669500000018161 ], [ 2051403.036967576947063, 347581.186219056078698 ], [ 2051381.33, 347575.379000000015367 ], [ 2051284.082, 347549.719700000016019 ], [ 2051252.842, 347541.0538 ], [ 2051185.308, 347523.205100000021048 ], [ 2051162.892246897798032, 347517.011693853070028 ], [ 2051088.202, 347496.375 ], [ 2050989.633, 347471.4816 ], [ 2050955.508, 347461.728899999987334 ], [ 2050921.034117232076824, 347452.326108012755867 ], [ 2050891.608, 347444.3001 ], [ 2050792.656, 347418.07909999997355 ], [ 2050693.102999999886379, 347397.548300000024028 ], [ 2050680.816848023561761, 347396.403189528442454 ], [ 2050606.428, 347389.469900000025518 ], [ 2050432.790745197795331, 347381.637759556586388 ], [ 2050395.870000000111759, 347379.972400000027847 ], [ 2050295.031, 347380.165700000012293 ], [ 2050194.082, 347375.584900000016205 ], [ 2050184.511057119816542, 347373.972390304203145 ], [ 2050093.68, 347358.6692 ], [ 2049996.120000000111759, 347333.951300000015181 ], [ 2049942.999113350640982, 347316.274769303330686 ], [ 2049899.589, 347301.8296 ], [ 2049812.534, 347266.604899999976624 ], [ 2049806.409, 347264.1264 ], [ 2049713.02, 347226.494499999971595 ], [ 2049711.574092950439081, 347225.890785001625773 ], [ 2049620.142, 347187.714800000016112 ], [ 2049525.551, 347148.864200000010896 ], [ 2049481.395841051125899, 347132.290066618821584 ], [ 2049429.828, 347112.933499999984633 ], [ 2049335.862, 347075.1828 ], [ 2049253.963706719689071, 347032.600758539338131 ], [ 2049246.389999999897555, 347028.6629 ], [ 2049164.018, 346969.060999999986961 ], [ 2049143.874, 346950.678699999989476 ], [ 2049067.213, 346884.886600000027101 ], [ 2049059.556004673242569, 346878.25982995639788 ], [ 2048988.824, 346817.044600000022911 ], [ 2048908.692, 346757.0294 ], [ 2048862.720127717126161, 346726.940490917710122 ], [ 2048824.444, 346701.8885 ], [ 2048734.287, 346652.3418 ], [ 2048644.829203597269952, 346607.831182389636524 ], [ 2048643.018, 346606.93 ], [ 2048548.051, 346568.491900000022724 ], [ 2048451.509, 346535.565400000021327 ], [ 2048410.55518839834258, 346525.293504228000529 ], [ 2048354.399, 346511.208600000012666 ], [ 2048255.281999999890104, 346487.695499999972526 ], [ 2048169.136621022131294, 346466.638890414615162 ], [ 2048125.0, 346674.451247457182035 ], [ 2048125.0, 346875.0 ], [ 2048125.0, 347125.0 ], [ 2047875.0, 347125.0 ], [ 2047625.0, 347125.0 ], [ 2047625.0, 346875.0 ], [ 2047375.0, 346884.71753743494628 ], [ 2047376.290053668897599, 346783.877958185737953 ], [ 2047221.362432709662244, 346597.393960972491186 ], [ 2047206.933, 346605.079900000011548 ], [ 2047159.066000000108033, 346664.3712 ], [ 2047154.071, 346669.8028 ], [ 2047138.368, 346696.5062 ], [ 2047135.838, 346703.745500000019092 ], [ 2047135.395, 346703.76510000001872 ], [ 2047131.55, 346710.1251 ], [ 2047077.102, 346794.496700000017881 ], [ 2047074.832631461787969, 346796.353584631113335 ], [ 2046998.466, 346858.839700000011362 ], [ 2046911.172, 346908.778600000019651 ], [ 2046869.245368028059602, 346934.381285698153079 ], [ 2046825.058, 346961.364500000025146 ], [ 2046738.525, 347014.126800000027288 ], [ 2046660.080679264385253, 347063.249455272394698 ], [ 2046651.968000000109896, 347068.3297 ], [ 2046565.708000000100583, 347123.543899999989662 ], [ 2046485.556, 347184.981299999984913 ], [ 2046457.673041422618553, 347211.46309378487058 ], [ 2046411.049000000115484, 347255.744200000015553 ], [ 2046341.25, 347332.043799999984913 ], [ 2046287.932678144657984, 347392.772025281796232 ], [ 2046274.705, 347407.8383 ], [ 2046207.156999999890104, 347483.392400000011548 ], [ 2046139.892, 347558.403999999980442 ], [ 2046122.245087900198996, 347577.973078029346652 ], [ 2046075.053, 347630.305500000016764 ], [ 2046072.674000000115484, 347635.247199999983422 ], [ 2046003.847, 347713.34529999998631 ], [ 2045958.136711895698681, 347764.27390489471145 ], [ 2046133.482221366371959, 347904.488804459862877 ], [ 2046089.87689806940034, 348089.876898069458548 ], [ 2046125.0, 348125.0 ], [ 2046375.0, 348125.0 ], [ 2046625.0, 348125.0 ], [ 2046875.0, 348125.0 ], [ 2047125.0, 348125.0 ], [ 2047375.0, 348125.0 ], [ 2047625.0, 348125.0 ], [ 2047625.0, 348375.0 ], [ 2047875.0, 348375.0 ], [ 2048125.0, 348375.0 ], [ 2048125.0, 348625.0 ], [ 2048375.0, 348625.0 ], [ 2048375.0, 348875.0 ], [ 2048625.0, 348875.0 ], [ 2048625.0, 349125.0 ], [ 2048875.0, 349125.0 ], [ 2048875.0, 349375.0 ], [ 2048875.0, 349625.0 ], [ 2048625.0, 349625.0 ], [ 2048625.0, 349375.0 ], [ 2048375.0, 349375.0 ], [ 2048375.0, 349125.0 ], [ 2048125.0, 349125.0 ], [ 2047875.0, 349125.0 ], [ 2047875.0, 348875.0 ], [ 2047625.0, 348875.0 ], [ 2047625.0, 348625.0 ], [ 2047375.0, 348625.0 ], [ 2047125.0, 348625.0 ], [ 2046875.0, 348625.0 ], [ 2046625.0, 348625.0 ], [ 2046375.0, 348625.0 ], [ 2046125.0, 348625.0 ], [ 2045875.0, 348625.0 ], [ 2045875.0, 348438.28639834333444 ], [ 2045601.113818968413398, 348404.300741842540447 ], [ 2045638.91, 348320.3714 ], [ 2045683.655, 348230.872199999983422 ], [ 2045703.53, 348189.957 ], [ 2045704.146632959367707, 348188.635653424018528 ], [ 2045556.744589085225016, 348117.718749680614565 ], [ 2045392.826774591812864, 348142.826774591754656 ], [ 2045375.0, 348125.0 ], [ 2045125.0, 348125.0 ], [ 2044875.0, 348125.0 ], [ 2044875.0, 348375.0 ], [ 2044625.0, 348375.0 ], [ 2044625.0, 348625.0 ], [ 2044375.0, 348625.0 ], [ 2044375.0, 348875.0 ], [ 2044125.0, 348875.0 ], [ 2044125.0, 349125.0 ], [ 2044125.0, 349375.0 ], [ 2043875.0, 349375.0 ], [ 2043875.0, 349625.0 ], [ 2043625.0, 349625.0 ], [ 2043625.0, 349875.0 ], [ 2043375.0, 349875.0 ], [ 2043125.0, 349875.0 ], [ 2042875.0, 349875.0 ], [ 2042625.0, 349875.0 ], [ 2042375.0, 349875.0 ], [ 2042125.0, 349875.0 ], [ 2041875.0, 349875.0 ], [ 2041875.0, 349625.0 ], [ 2041625.0, 349625.0 ], [ 2041625.0, 349875.0 ], [ 2041375.0, 349875.0 ], [ 2041125.0, 349875.0 ], [ 2040875.0, 349875.0 ], [ 2040875.0, 349625.0 ], [ 2040625.0, 349625.0 ], [ 2040375.0, 349625.0 ], [ 2040125.0, 349625.0 ], [ 2039875.0, 349625.0 ], [ 2039625.0, 349625.0 ], [ 2039375.0, 349625.0 ], [ 2039375.0, 349375.0 ], [ 2039125.0, 349375.0 ], [ 2038875.0, 349375.0 ], [ 2038875.0, 349125.0 ], [ 2038625.0, 349125.0 ], [ 2038375.0, 349125.0 ], [ 2038375.0, 348875.0 ], [ 2038125.0, 348875.0 ], [ 2038125.0, 348625.0 ], [ 2037875.0, 348625.0 ], [ 2037625.0, 348625.0 ], [ 2037625.0, 348875.0 ], [ 2037375.0, 348875.0 ], [ 2037125.0, 348875.0 ], [ 2036875.0, 348875.0 ], [ 2036625.0, 348875.0 ], [ 2036625.0, 348625.0 ], [ 2036625.0, 348375.0 ], [ 2036625.0, 348125.0 ], [ 2036625.0, 347875.0 ], [ 2036625.0, 347625.0 ], [ 2036375.0, 347625.0 ], [ 2036375.0, 347375.0 ], [ 2036375.0, 347125.0 ], [ 2036625.0, 347125.0 ], [ 2036625.0, 346875.0 ], [ 2036375.0, 346875.0 ], [ 2036375.0, 346625.0 ], [ 2036375.0, 346375.0 ], [ 2036375.0, 346125.0 ], [ 2036625.0, 346125.0 ], [ 2036625.0, 345875.0 ], [ 2036375.0, 345875.0 ], [ 2036375.0, 345625.0 ], [ 2036125.0, 345625.0 ], [ 2036125.0, 345375.0 ], [ 2036125.0, 345125.0 ], [ 2035875.0, 345125.0 ], [ 2035875.0, 344875.0 ], [ 2036125.0, 344875.0 ], [ 2036125.0, 344625.0 ], [ 2036125.0, 344375.0 ], [ 2036125.0, 344125.0 ], [ 2036125.0, 343875.0 ], [ 2036125.0, 343625.0 ], [ 2036125.0, 343375.0 ], [ 2035875.0, 343375.0 ], [ 2035875.0, 343125.0 ], [ 2035875.0, 342875.0 ], [ 2035875.0, 342625.0 ], [ 2035875.0, 342375.0 ], [ 2035625.0, 342375.0 ], [ 2035625.0, 342125.0 ], [ 2035625.0, 341875.0 ], [ 2035375.0, 341875.0 ], [ 2035375.0, 341625.0 ], [ 2035125.0, 341625.0 ], [ 2035125.0, 341375.0 ], [ 2034875.0, 341375.0 ], [ 2034875.0, 341125.0 ], [ 2034875.0, 340875.0 ], [ 2034625.0, 340875.0 ], [ 2034625.0, 340625.0 ], [ 2034625.0, 340375.0 ], [ 2034375.0, 340375.0 ], [ 2034375.0, 340125.0 ], [ 2034125.0, 340125.0 ], [ 2034125.0, 339875.0 ], [ 2033875.0, 339875.0 ], [ 2033875.0, 339625.0 ], [ 2033625.0, 339625.0 ], [ 2033625.0, 339375.0 ], [ 2033375.0, 339375.0 ], [ 2033375.0, 339125.0 ], [ 2033125.0, 339125.0 ], [ 2033125.0, 338875.0 ], [ 2032875.0, 338875.0 ], [ 2032625.0, 338875.0 ], [ 2032375.0, 338875.0 ], [ 2032375.0, 338625.0 ], [ 2032125.0, 338625.0 ], [ 2032125.0, 338875.0 ], [ 2032125.0, 339125.0 ], [ 2031875.0, 339125.0 ], [ 2031875.0, 338875.0 ], [ 2031625.0, 338875.0 ], [ 2031625.0, 338625.0 ], [ 2031875.0, 338625.0 ], [ 2031875.0, 338375.0 ], [ 2031625.0, 338375.0 ], [ 2031375.0, 338375.0 ], [ 2031375.0, 338125.0 ], [ 2031125.0, 338125.0 ], [ 2031125.0, 338375.0 ], [ 2031125.0, 338625.0 ], [ 2030875.0, 338625.0 ], [ 2030625.0, 338625.0 ], [ 2030625.0, 338375.0 ], [ 2030625.0, 338125.0 ], [ 2030375.0, 338125.0 ], [ 2030125.0, 338125.0 ], [ 2030125.0, 337875.0 ], [ 2029875.0, 337875.0 ], [ 2029875.0, 337625.0 ], [ 2030125.0, 337625.0 ], [ 2030125.0, 337375.0 ], [ 2029875.0, 337375.0 ], [ 2029625.0, 337375.0 ], [ 2029625.0, 337125.0 ], [ 2029375.0, 337125.0 ], [ 2029375.0, 336875.0 ], [ 2029125.0, 336875.0 ], [ 2028875.0, 336875.0 ], [ 2028875.0, 336625.0 ], [ 2028625.0, 336625.0 ], [ 2028375.0, 336625.0 ], [ 2028375.0, 336375.0 ], [ 2028125.0, 336375.0 ], [ 2027875.0, 336375.0 ], [ 2027875.0, 336625.0 ], [ 2027625.0, 336625.0 ], [ 2027625.0, 336375.0 ], [ 2027625.0, 336125.0 ], [ 2027375.0, 336125.0 ], [ 2027125.0, 336125.0 ], [ 2027125.0, 335875.0 ], [ 2026875.0, 335875.0 ], [ 2026875.0, 335625.0 ], [ 2026625.0, 335625.0 ], [ 2026375.0, 335625.0 ], [ 2026125.0, 335625.0 ], [ 2026125.0, 335375.0 ], [ 2025875.0, 335375.0 ], [ 2025625.0, 335375.0 ], [ 2025625.0, 335125.0 ], [ 2025375.0, 335125.0 ], [ 2025125.0, 335125.0 ], [ 2025125.0, 334875.0 ], [ 2024875.0, 334875.0 ], [ 2024875.0, 334625.0 ], [ 2024625.0, 334625.0 ], [ 2024375.0, 334625.0 ], [ 2024125.0, 334625.0 ], [ 2024125.0, 334875.0 ], [ 2023875.0, 334875.0 ], [ 2023625.0, 334875.0 ], [ 2023625.0, 334625.0 ], [ 2023625.0, 334375.0 ], [ 2023375.0, 334375.0 ], [ 2023125.0, 334375.0 ], [ 2023125.0, 334125.0 ], [ 2022875.0, 334125.0 ], [ 2022875.0, 333875.0 ], [ 2022625.0, 333875.0 ], [ 2022625.0, 333625.0 ], [ 2022375.0, 333625.0 ], [ 2022375.0, 333375.0 ], [ 2022125.0, 333375.0 ], [ 2021875.0, 333375.0 ], [ 2021875.0, 333125.0 ], [ 2021625.0, 333125.0 ], [ 2021625.0, 332875.0 ], [ 2021375.0, 332875.0 ], [ 2021125.0, 332875.0 ], [ 2021125.0, 332625.0 ], [ 2020875.0, 332625.0 ], [ 2020875.0, 332375.0 ], [ 2020625.0, 332375.0 ], [ 2020625.0, 332125.0 ], [ 2020375.0, 332125.0 ], [ 2020375.0, 331875.0 ], [ 2020125.0, 331875.0 ], [ 2019875.0, 331875.0 ], [ 2019875.0, 331625.0 ], [ 2019875.0, 331375.0 ], [ 2019875.0, 331125.0 ], [ 2019625.0, 331125.0 ], [ 2019375.0, 331125.0 ], [ 2019375.0, 330875.0 ], [ 2019375.0, 330625.0 ], [ 2019125.0, 330625.0 ], [ 2019125.0, 330375.0 ], [ 2018875.0, 330375.0 ], [ 2018875.0, 330125.0 ], [ 2018875.0, 329875.0 ], [ 2018625.0, 329875.0 ], [ 2018625.0, 329625.0 ], [ 2018375.0, 329625.0 ], [ 2018375.0, 329375.0 ], [ 2018375.0, 329125.0 ], [ 2018375.0, 328875.0 ], [ 2018125.0, 328875.0 ], [ 2018125.0, 328625.0 ], [ 2018375.0, 328625.0 ], [ 2018375.0, 328375.0 ], [ 2018375.0, 328125.0 ], [ 2018125.0, 328125.0 ], [ 2018125.0, 328375.0 ], [ 2017875.0, 328375.0 ], [ 2017875.0, 328625.0 ], [ 2017875.0, 328875.0 ], [ 2017625.0, 328875.0 ], [ 2017625.0, 329125.0 ], [ 2017375.0, 329125.0 ], [ 2017125.0, 329125.0 ], [ 2017125.0, 329375.0 ], [ 2016875.0, 329375.0 ], [ 2016625.0, 329375.0 ], [ 2016625.0, 329625.0 ], [ 2016375.0, 329625.0 ], [ 2016125.0, 329625.0 ], [ 2016125.0, 329375.0 ], [ 2016125.0, 329125.0 ], [ 2016125.0, 328875.0 ], [ 2015875.0, 328875.0 ], [ 2015875.0, 328625.0 ], [ 2015625.0, 328625.0 ], [ 2015375.0, 328625.0 ], [ 2015375.0, 328375.0 ], [ 2015125.0, 328375.0 ], [ 2015125.0, 328125.0 ], [ 2015375.0, 328125.0 ], [ 2015625.0, 328125.0 ], [ 2015875.0, 328125.0 ], [ 2016125.0, 328125.0 ], [ 2016125.0, 328375.0 ], [ 2016375.0, 328375.0 ], [ 2016375.0, 328125.0 ], [ 2016375.0, 327875.0 ], [ 2016125.0, 327875.0 ], [ 2015875.0, 327875.0 ], [ 2015625.0, 327875.0 ], [ 2015625.0, 327625.0 ], [ 2015875.0, 327625.0 ], [ 2015875.0, 327375.0 ], [ 2015875.0, 327125.0 ], [ 2015875.0, 326875.0 ], [ 2016125.0, 326875.0 ], [ 2016375.0, 326875.0 ], [ 2016625.0, 326875.0 ], [ 2016625.0, 326625.0 ], [ 2016875.0, 326625.0 ], [ 2016875.0, 326375.0 ], [ 2016625.0, 326375.0 ], [ 2016375.0, 326375.0 ], [ 2016125.0, 326375.0 ], [ 2015875.0, 326375.0 ], [ 2015875.0, 326625.0 ], [ 2015625.0, 326625.0 ], [ 2015625.0, 326875.0 ], [ 2015375.0, 326875.0 ], [ 2015125.0, 326875.0 ], [ 2014875.0, 326875.0 ], [ 2014625.0, 326875.0 ], [ 2014625.0, 327125.0 ], [ 2014375.0, 327125.0 ], [ 2014125.0, 327125.0 ], [ 2014125.0, 327375.0 ], [ 2013875.0, 327375.0 ], [ 2013625.0, 327375.0 ], [ 2013375.0, 327375.0 ], [ 2013125.0, 327375.0 ], [ 2012875.0, 327375.0 ], [ 2012625.0, 327375.0 ], [ 2012375.0, 327375.0 ], [ 2012375.0, 327125.0 ], [ 2012125.0, 327125.0 ], [ 2012125.0, 326875.0 ], [ 2011875.0, 326875.0 ], [ 2011875.0, 326625.0 ], [ 2011625.0, 326625.0 ], [ 2011375.0, 326625.0 ], [ 2011375.0, 326375.0 ], [ 2011125.0, 326375.0 ], [ 2011125.0, 326125.0 ], [ 2010875.0, 326125.0 ], [ 2010625.0, 326125.0 ], [ 2010375.0, 326125.0 ], [ 2010375.0, 325875.0 ], [ 2010125.0, 325875.0 ], [ 2010125.0, 326125.0 ], [ 2009875.0, 326125.0 ], [ 2009625.0, 326125.0 ], [ 2009625.0, 325875.0 ], [ 2009375.0, 325875.0 ], [ 2009125.0, 325875.0 ], [ 2008875.0, 325875.0 ], [ 2008875.0, 326125.0 ], [ 2008625.0, 326125.0 ], [ 2008375.0, 326125.0 ], [ 2008375.0, 326375.0 ], [ 2008125.0, 326375.0 ], [ 2007875.0, 326375.0 ], [ 2007625.0, 326375.0 ], [ 2007375.0, 326375.0 ], [ 2007125.0, 326375.0 ], [ 2006875.0, 326375.0 ], [ 2006625.0, 326375.0 ], [ 2006625.0, 326125.0 ], [ 2006375.0, 326125.0 ], [ 2006125.0, 326125.0 ], [ 2005875.0, 326125.0 ], [ 2005625.0, 326125.0 ], [ 2005625.0, 326375.0 ], [ 2005375.0, 326375.0 ], [ 2005125.0, 326375.0 ], [ 2005125.0, 326125.0 ], [ 2005125.0, 325875.0 ], [ 2004875.0, 325875.0 ], [ 2004875.0, 325625.0 ], [ 2004875.0, 325375.0 ], [ 2004625.0, 325375.0 ], [ 2004625.0, 325125.0 ], [ 2004875.0, 325125.0 ], [ 2004875.0, 324875.0 ], [ 2005125.0, 324875.0 ], [ 2005125.0, 324625.0 ], [ 2005125.0, 324375.0 ], [ 2005125.0, 324125.0 ], [ 2004875.0, 324125.0 ], [ 2004625.0, 324125.0 ], [ 2004375.0, 324125.0 ], [ 2004375.0, 323875.0 ], [ 2004125.0, 323875.0 ], [ 2004125.0, 323625.0 ], [ 2003875.0, 323625.0 ], [ 2003625.0, 323625.0 ], [ 2003375.0, 323625.0 ], [ 2003125.0, 323625.0 ], [ 2003125.0, 323449.735253088292666 ], [ 2002991.896173857152462, 323380.988579147902783 ], [ 2002947.325, 323247.302000000025146 ], [ 2002853.736919600982219, 323091.999806937295943 ], [ 2002625.0, 323109.507223077933304 ], [ 2002625.0, 322875.0 ], [ 2002375.0, 322875.0 ], [ 2002125.0, 322875.0 ], [ 2002125.0, 322625.0 ], [ 2001875.0, 322625.0 ], [ 2001875.0, 322375.0 ], [ 2001625.0, 322375.0 ], [ 2001375.0, 322375.0 ], [ 2001375.0, 322125.0 ], [ 2001125.0, 322125.0 ], [ 2001125.0, 322375.0 ], [ 2000990.663948226952925, 322509.336051772930659 ], [ 2001261.442088720854372, 322738.557911279203836 ], [ 2001375.0, 322625.0 ], [ 2001625.0, 322625.0 ], [ 2001625.0, 322875.0 ], [ 2001532.220229214522988, 322967.779770785477012 ], [ 2001802.998369708191603, 323197.001630291750189 ], [ 2002122.076081019360572, 323467.110532658640295 ], [ 2002382.353472185786813, 323687.443191276630387 ], [ 2002615.857058472698554, 323885.111016871524043 ], [ 2002647.081654819892719, 323911.543579056975432 ], [ 2002747.629449365194887, 324002.370550634746905 ], [ 2003010.32812323491089, 324239.671876765030902 ], [ 2003026.951890740077943, 324254.688481212011538 ], [ 2003296.335206218762323, 324453.664793781237677 ], [ 2003625.0, 324696.428561914828606 ], [ 2003727.707755238516256, 324772.292244761425536 ], [ 2003850.479465520009398, 324862.975894401024561 ], [ 2003855.823512454051524, 324875.0 ], [ 2003887.912537110038102, 324947.200305458973162 ], [ 2003836.054292866028845, 325125.0 ], [ 2003822.404661840060726, 325171.798734944022726 ], [ 2003752.335260098101571, 325375.0 ], [ 2003728.821982889901847, 325443.188503905024845 ], [ 2003724.133367233676836, 325474.133367233676836 ], [ 2003682.030643410049379, 325752.01134444802301 ], [ 2003629.321219603298232, 325875.0 ], [ 2003522.178362462902442, 326125.0 ], [ 2003513.581821300089359, 326145.058596046990715 ], [ 2003457.439240917097777, 326207.439240917214192 ], [ 2003260.908588130027056, 326425.80663290398661 ] ], [ [ 2023875.0, 338125.0 ], [ 2023875.0, 337875.0 ], [ 2024125.0, 337875.0 ], [ 2024125.0, 338125.0 ], [ 2023875.0, 338125.0 ] ], [ [ 2035375.0, 347375.0 ], [ 2035375.0, 347125.0 ], [ 2035375.0, 346875.0 ], [ 2035375.0, 346625.0 ], [ 2035625.0, 346625.0 ], [ 2035625.0, 346875.0 ], [ 2035625.0, 347125.0 ], [ 2035625.0, 347375.0 ], [ 2035625.0, 347625.0 ], [ 2035375.0, 347625.0 ], [ 2035375.0, 347375.0 ] ], [ [ 2035625.0, 346375.0 ], [ 2035875.0, 346375.0 ], [ 2035875.0, 346625.0 ], [ 2035625.0, 346625.0 ], [ 2035625.0, 346375.0 ] ], [ [ 2036125.0, 346625.0 ], [ 2036125.0, 346875.0 ], [ 2036125.0, 347125.0 ], [ 2036125.0, 347375.0 ], [ 2035875.0, 347375.0 ], [ 2035875.0, 347125.0 ], [ 2035875.0, 346875.0 ], [ 2035875.0, 346625.0 ], [ 2036125.0, 346625.0 ] ], [ [ 2036625.0, 349125.0 ], [ 2036375.0, 349125.0 ], [ 2036375.0, 348875.0 ], [ 2036625.0, 348875.0 ], [ 2036625.0, 349125.0 ] ], [ [ 2026875.0, 336125.0 ], [ 2026625.0, 336125.0 ], [ 2026625.0, 335875.0 ], [ 2026875.0, 335875.0 ], [ 2026875.0, 336125.0 ] ], [ [ 2023625.0, 335125.0 ], [ 2023375.0, 335125.0 ], [ 2023375.0, 334875.0 ], [ 2023625.0, 334875.0 ], [ 2023625.0, 335125.0 ] ], [ [ 2011375.0, 326875.0 ], [ 2011375.0, 327125.0 ], [ 2011125.0, 327125.0 ], [ 2011125.0, 326875.0 ], [ 2011125.0, 326625.0 ], [ 2011375.0, 326625.0 ], [ 2011375.0, 326875.0 ] ], [ [ 2011125.0, 327375.0 ], [ 2010875.0, 327375.0 ], [ 2010875.0, 327125.0 ], [ 2011125.0, 327125.0 ], [ 2011125.0, 327375.0 ] ], [ [ 2010625.0, 327125.0 ], [ 2010625.0, 326875.0 ], [ 2010875.0, 326875.0 ], [ 2010875.0, 327125.0 ], [ 2010625.0, 327125.0 ] ], [ [ 2008625.0, 326375.0 ], [ 2008625.0, 326625.0 ], [ 2008375.0, 326625.0 ], [ 2008375.0, 326375.0 ], [ 2008625.0, 326375.0 ] ], [ [ 2008375.0, 332875.0 ], [ 2008375.0, 332625.0 ], [ 2008625.0, 332625.0 ], [ 2008625.0, 332875.0 ], [ 2008625.0, 333125.0 ], [ 2008625.0, 333375.0 ], [ 2008375.0, 333375.0 ], [ 2008375.0, 333125.0 ], [ 2008375.0, 332875.0 ] ], [ [ 2008625.0, 332375.0 ], [ 2008875.0, 332375.0 ], [ 2008875.0, 332625.0 ], [ 2008625.0, 332625.0 ], [ 2008625.0, 332375.0 ] ], [ [ 2009375.0, 332875.0 ], [ 2009375.0, 333125.0 ], [ 2009375.0, 333375.0 ], [ 2009625.0, 333375.0 ], [ 2009625.0, 333625.0 ], [ 2009375.0, 333625.0 ], [ 2009125.0, 333625.0 ], [ 2009125.0, 333375.0 ], [ 2009125.0, 333125.0 ], [ 2009125.0, 332875.0 ], [ 2009375.0, 332875.0 ] ], [ [ 2009375.0, 326625.0 ], [ 2009125.0, 326625.0 ], [ 2009125.0, 326375.0 ], [ 2009375.0, 326375.0 ], [ 2009375.0, 326625.0 ] ], [ [ 2009625.0, 331625.0 ], [ 2009625.0, 331875.0 ], [ 2009375.0, 331875.0 ], [ 2009375.0, 331625.0 ], [ 2009625.0, 331625.0 ] ], [ [ 2010125.0, 334125.0 ], [ 2010125.0, 334375.0 ], [ 2009875.0, 334375.0 ], [ 2009875.0, 334125.0 ], [ 2009875.0, 333875.0 ], [ 2010125.0, 333875.0 ], [ 2010375.0, 333875.0 ], [ 2010375.0, 334125.0 ], [ 2010125.0, 334125.0 ] ], [ [ 2008125.0, 333875.0 ], [ 2008125.0, 333625.0 ], [ 2008375.0, 333625.0 ], [ 2008375.0, 333875.0 ], [ 2008125.0, 333875.0 ] ], [ [ 2008125.0, 334125.0 ], [ 2008375.0, 334125.0 ], [ 2008375.0, 334375.0 ], [ 2008125.0, 334375.0 ], [ 2008125.0, 334125.0 ] ], [ [ 2014875.0, 332125.0 ], [ 2015125.0, 332125.0 ], [ 2015125.0, 332375.0 ], [ 2014875.0, 332375.0 ], [ 2014875.0, 332125.0 ] ], [ [ 2026125.0, 336625.0 ], [ 2026375.0, 336625.0 ], [ 2026375.0, 336875.0 ], [ 2026625.0, 336875.0 ], [ 2026625.0, 337125.0 ], [ 2026875.0, 337125.0 ], [ 2027125.0, 337125.0 ], [ 2027375.0, 337125.0 ], [ 2027375.0, 337375.0 ], [ 2027375.0, 337625.0 ], [ 2027125.0, 337625.0 ], [ 2026875.0, 337625.0 ], [ 2026875.0, 337375.0 ], [ 2026625.0, 337375.0 ], [ 2026375.0, 337375.0 ], [ 2026375.0, 337125.0 ], [ 2026125.0, 337125.0 ], [ 2026125.0, 336875.0 ], [ 2025875.0, 336875.0 ], [ 2025875.0, 336625.0 ], [ 2026125.0, 336625.0 ] ], [ [ 2027625.0, 337625.0 ], [ 2027625.0, 337875.0 ], [ 2027375.0, 337875.0 ], [ 2027375.0, 337625.0 ], [ 2027625.0, 337625.0 ] ], [ [ 2026875.0, 340125.0 ], [ 2026625.0, 340125.0 ], [ 2026625.0, 339875.0 ], [ 2026875.0, 339875.0 ], [ 2026875.0, 340125.0 ] ], [ [ 2027125.0, 340125.0 ], [ 2027375.0, 340125.0 ], [ 2027375.0, 340375.0 ], [ 2027125.0, 340375.0 ], [ 2026875.0, 340375.0 ], [ 2026875.0, 340125.0 ], [ 2027125.0, 340125.0 ] ], [ [ 2027375.0, 339875.0 ], [ 2027625.0, 339875.0 ], [ 2027625.0, 340125.0 ], [ 2027375.0, 340125.0 ], [ 2027375.0, 339875.0 ] ], [ [ 2025625.0, 339375.0 ], [ 2025875.0, 339375.0 ], [ 2025875.0, 339625.0 ], [ 2025625.0, 339625.0 ], [ 2025625.0, 339375.0 ] ], [ [ 2025625.0, 338875.0 ], [ 2025875.0, 338875.0 ], [ 2025875.0, 339125.0 ], [ 2025625.0, 339125.0 ], [ 2025625.0, 338875.0 ] ], [ [ 2038875.0, 349875.0 ], [ 2038875.0, 349625.0 ], [ 2039125.0, 349625.0 ], [ 2039125.0, 349875.0 ], [ 2038875.0, 349875.0 ] ], [ [ 2012625.0, 331125.0 ], [ 2012375.0, 331125.0 ], [ 2012375.0, 330875.0 ], [ 2012375.0, 330625.0 ], [ 2012625.0, 330625.0 ], [ 2012625.0, 330875.0 ], [ 2012625.0, 331125.0 ] ], [ [ 2012125.0, 330625.0 ], [ 2012125.0, 330375.0 ], [ 2012375.0, 330375.0 ], [ 2012375.0, 330625.0 ], [ 2012125.0, 330625.0 ] ], [ [ 2012375.0, 330125.0 ], [ 2012625.0, 330125.0 ], [ 2012875.0, 330125.0 ], [ 2013125.0, 330125.0 ], [ 2013125.0, 330375.0 ], [ 2012875.0, 330375.0 ], [ 2012625.0, 330375.0 ], [ 2012375.0, 330375.0 ], [ 2012375.0, 330125.0 ] ], [ [ 2013125.0, 331125.0 ], [ 2012875.0, 331125.0 ], [ 2012875.0, 330875.0 ], [ 2013125.0, 330875.0 ], [ 2013375.0, 330875.0 ], [ 2013375.0, 331125.0 ], [ 2013125.0, 331125.0 ] ], [ [ 2013875.0, 328625.0 ], [ 2014125.0, 328625.0 ], [ 2014125.0, 328875.0 ], [ 2013875.0, 328875.0 ], [ 2013875.0, 328625.0 ] ], [ [ 2002640.221391269238666, 323263.745681104890537 ], [ 2002375.0, 323363.963568864972331 ], [ 2002375.0, 323125.0 ], [ 2002613.391619356349111, 323125.0 ], [ 2002640.221391269238666, 323263.745681104890537 ] ], [ [ 2001375.0, 328625.0 ], [ 2001625.0, 328625.0 ], [ 2001625.0, 328875.0 ], [ 2001375.0, 328875.0 ], [ 2001375.0, 328625.0 ] ], [ [ 2002125.0, 328375.0 ], [ 2002125.0, 328125.0 ], [ 2002375.0, 328125.0 ], [ 2002375.0, 328375.0 ], [ 2002125.0, 328375.0 ] ], [ [ 2006375.0, 326625.0 ], [ 2006125.0, 326625.0 ], [ 2006125.0, 326375.0 ], [ 2006375.0, 326375.0 ], [ 2006375.0, 326625.0 ] ], [ [ 2008125.0, 326875.0 ], [ 2008125.0, 327125.0 ], [ 2007875.0, 327125.0 ], [ 2007875.0, 326875.0 ], [ 2007875.0, 326625.0 ], [ 2008125.0, 326625.0 ], [ 2008125.0, 326875.0 ] ], [ [ 2010875.0, 330125.0 ], [ 2010875.0, 329875.0 ], [ 2011125.0, 329875.0 ], [ 2011125.0, 330125.0 ], [ 2010875.0, 330125.0 ] ], [ [ 2009875.0, 327625.0 ], [ 2009625.0, 327625.0 ], [ 2009625.0, 327375.0 ], [ 2009875.0, 327375.0 ], [ 2009875.0, 327625.0 ] ], [ [ 2010125.0, 326875.0 ], [ 2010125.0, 326625.0 ], [ 2010125.0, 326375.0 ], [ 2010375.0, 326375.0 ], [ 2010375.0, 326625.0 ], [ 2010375.0, 326875.0 ], [ 2010125.0, 326875.0 ] ], [ [ 2009625.0, 328375.0 ], [ 2009875.0, 328375.0 ], [ 2009875.0, 328625.0 ], [ 2009625.0, 328625.0 ], [ 2009625.0, 328375.0 ] ], [ [ 2010625.0, 328375.0 ], [ 2010875.0, 328375.0 ], [ 2010875.0, 328625.0 ], [ 2010625.0, 328625.0 ], [ 2010625.0, 328375.0 ] ], [ [ 2010375.0, 329375.0 ], [ 2010125.0, 329375.0 ], [ 2010125.0, 329125.0 ], [ 2010375.0, 329125.0 ], [ 2010375.0, 329375.0 ] ], [ [ 2010375.0, 329875.0 ], [ 2010375.0, 330125.0 ], [ 2010125.0, 330125.0 ], [ 2010125.0, 329875.0 ], [ 2010375.0, 329875.0 ] ], [ [ 2012375.0, 329375.0 ], [ 2012125.0, 329375.0 ], [ 2012125.0, 329125.0 ], [ 2012375.0, 329125.0 ], [ 2012625.0, 329125.0 ], [ 2012625.0, 329375.0 ], [ 2012375.0, 329375.0 ] ], [ [ 2012875.0, 329375.0 ], [ 2012875.0, 329625.0 ], [ 2012625.0, 329625.0 ], [ 2012625.0, 329375.0 ], [ 2012875.0, 329375.0 ] ], [ [ 2013125.0, 327625.0 ], [ 2013375.0, 327625.0 ], [ 2013625.0, 327625.0 ], [ 2013625.0, 327875.0 ], [ 2013375.0, 327875.0 ], [ 2013125.0, 327875.0 ], [ 2013125.0, 328125.0 ], [ 2012875.0, 328125.0 ], [ 2012625.0, 328125.0 ], [ 2012625.0, 327875.0 ], [ 2012875.0, 327875.0 ], [ 2012875.0, 327625.0 ], [ 2013125.0, 327625.0 ] ], [ [ 2012375.0, 327625.0 ], [ 2012375.0, 327875.0 ], [ 2012125.0, 327875.0 ], [ 2012125.0, 327625.0 ], [ 2012375.0, 327625.0 ] ], [ [ 2013375.0, 330125.0 ], [ 2013375.0, 329875.0 ], [ 2013625.0, 329875.0 ], [ 2013625.0, 330125.0 ], [ 2013625.0, 330375.0 ], [ 2013375.0, 330375.0 ], [ 2013375.0, 330125.0 ] ], [ [ 2028125.0, 338125.0 ], [ 2027875.0, 338125.0 ], [ 2027875.0, 337875.0 ], [ 2028125.0, 337875.0 ], [ 2028125.0, 338125.0 ] ], [ [ 2012625.0, 332125.0 ], [ 2012875.0, 332125.0 ], [ 2012875.0, 332375.0 ], [ 2012625.0, 332375.0 ], [ 2012625.0, 332125.0 ] ], [ [ 2016625.0, 330375.0 ], [ 2016375.0, 330375.0 ], [ 2016375.0, 330125.0 ], [ 2016375.0, 329875.0 ], [ 2016625.0, 329875.0 ], [ 2016625.0, 330125.0 ], [ 2016625.0, 330375.0 ] ], [ [ 2015875.0, 329375.0 ], [ 2015875.0, 329625.0 ], [ 2015625.0, 329625.0 ], [ 2015625.0, 329375.0 ], [ 2015875.0, 329375.0 ] ], [ [ 2014375.0, 330625.0 ], [ 2014375.0, 330375.0 ], [ 2014625.0, 330375.0 ], [ 2014625.0, 330625.0 ], [ 2014375.0, 330625.0 ] ], [ [ 2018125.0, 331375.0 ], [ 2017875.0, 331375.0 ], [ 2017875.0, 331125.0 ], [ 2018125.0, 331125.0 ], [ 2018125.0, 331375.0 ] ], [ [ 2019875.0, 332625.0 ], [ 2020125.0, 332625.0 ], [ 2020125.0, 332875.0 ], [ 2019875.0, 332875.0 ], [ 2019625.0, 332875.0 ], [ 2019375.0, 332875.0 ], [ 2019375.0, 332625.0 ], [ 2019625.0, 332625.0 ], [ 2019875.0, 332625.0 ] ], [ [ 2018375.0, 330875.0 ], [ 2018125.0, 330875.0 ], [ 2018125.0, 330625.0 ], [ 2018125.0, 330375.0 ], [ 2018375.0, 330375.0 ], [ 2018375.0, 330625.0 ], [ 2018375.0, 330875.0 ] ], [ [ 2025125.0, 335625.0 ], [ 2024875.0, 335625.0 ], [ 2024625.0, 335625.0 ], [ 2024375.0, 335625.0 ], [ 2024375.0, 335375.0 ], [ 2024625.0, 335375.0 ], [ 2024625.0, 335125.0 ], [ 2024875.0, 335125.0 ], [ 2024875.0, 335375.0 ], [ 2025125.0, 335375.0 ], [ 2025125.0, 335625.0 ] ], [ [ 2025625.0, 336125.0 ], [ 2025375.0, 336125.0 ], [ 2025375.0, 335875.0 ], [ 2025625.0, 335875.0 ], [ 2025625.0, 336125.0 ] ], [ [ 2025375.0, 336625.0 ], [ 2025625.0, 336625.0 ], [ 2025625.0, 336875.0 ], [ 2025375.0, 336875.0 ], [ 2025375.0, 336625.0 ] ], [ [ 2028125.0, 337125.0 ], [ 2028125.0, 337375.0 ], [ 2027875.0, 337375.0 ], [ 2027875.0, 337125.0 ], [ 2028125.0, 337125.0 ] ], [ [ 2025875.0, 337375.0 ], [ 2026125.0, 337375.0 ], [ 2026125.0, 337625.0 ], [ 2025875.0, 337625.0 ], [ 2025875.0, 337375.0 ] ], [ [ 2033625.0, 343625.0 ], [ 2033375.0, 343625.0 ], [ 2033125.0, 343625.0 ], [ 2033125.0, 343375.0 ], [ 2033125.0, 343125.0 ], [ 2033375.0, 343125.0 ], [ 2033625.0, 343125.0 ], [ 2033625.0, 343375.0 ], [ 2033625.0, 343625.0 ] ], [ [ 2033875.0, 342875.0 ], [ 2034125.0, 342875.0 ], [ 2034125.0, 343125.0 ], [ 2033875.0, 343125.0 ], [ 2033875.0, 342875.0 ] ], [ [ 2034375.0, 343125.0 ], [ 2034375.0, 343375.0 ], [ 2034125.0, 343375.0 ], [ 2034125.0, 343125.0 ], [ 2034375.0, 343125.0 ] ], [ [ 2035625.0, 343875.0 ], [ 2035375.0, 343875.0 ], [ 2035375.0, 343625.0 ], [ 2035625.0, 343625.0 ], [ 2035625.0, 343875.0 ] ], [ [ 2035125.0, 342875.0 ], [ 2035125.0, 342625.0 ], [ 2035375.0, 342625.0 ], [ 2035625.0, 342625.0 ], [ 2035625.0, 342875.0 ], [ 2035375.0, 342875.0 ], [ 2035125.0, 342875.0 ] ], [ [ 2032125.0, 340625.0 ], [ 2032375.0, 340625.0 ], [ 2032625.0, 340625.0 ], [ 2032625.0, 340875.0 ], [ 2032375.0, 340875.0 ], [ 2032125.0, 340875.0 ], [ 2032125.0, 340625.0 ] ], [ [ 2031625.0, 339875.0 ], [ 2031375.0, 339875.0 ], [ 2031375.0, 339625.0 ], [ 2031625.0, 339625.0 ], [ 2031625.0, 339875.0 ] ], [ [ 2030125.0, 342125.0 ], [ 2030125.0, 342375.0 ], [ 2030125.0, 342625.0 ], [ 2029875.0, 342625.0 ], [ 2029875.0, 342375.0 ], [ 2029875.0, 342125.0 ], [ 2030125.0, 342125.0 ] ], [ [ 2031875.0, 343625.0 ], [ 2032125.0, 343625.0 ], [ 2032125.0, 343875.0 ], [ 2031875.0, 343875.0 ], [ 2031875.0, 343625.0 ] ], [ [ 2032875.0, 341625.0 ], [ 2032875.0, 341375.0 ], [ 2032875.0, 341125.0 ], [ 2032875.0, 340875.0 ], [ 2033125.0, 340875.0 ], [ 2033125.0, 341125.0 ], [ 2033125.0, 341375.0 ], [ 2033125.0, 341625.0 ], [ 2032875.0, 341625.0 ] ], [ [ 2033375.0, 340375.0 ], [ 2033125.0, 340375.0 ], [ 2033125.0, 340125.0 ], [ 2033375.0, 340125.0 ], [ 2033625.0, 340125.0 ], [ 2033625.0, 340375.0 ], [ 2033375.0, 340375.0 ] ], [ [ 2034125.0, 340875.0 ], [ 2034125.0, 340625.0 ], [ 2034375.0, 340625.0 ], [ 2034375.0, 340875.0 ], [ 2034375.0, 341125.0 ], [ 2034125.0, 341125.0 ], [ 2034125.0, 340875.0 ] ], [ [ 2034625.0, 342375.0 ], [ 2034875.0, 342375.0 ], [ 2034875.0, 342625.0 ], [ 2034625.0, 342625.0 ], [ 2034625.0, 342375.0 ] ], [ [ 2036625.0, 350125.0 ], [ 2036625.0, 350375.0 ], [ 2036375.0, 350375.0 ], [ 2036375.0, 350125.0 ], [ 2036625.0, 350125.0 ] ], [ [ 2038125.0, 350125.0 ], [ 2038125.0, 350375.0 ], [ 2037875.0, 350375.0 ], [ 2037875.0, 350125.0 ], [ 2038125.0, 350125.0 ] ], [ [ 2047375.0, 351875.0 ], [ 2047125.0, 351875.0 ], [ 2047125.0, 351625.0 ], [ 2047375.0, 351625.0 ], [ 2047375.0, 351875.0 ] ], [ [ 2047375.0, 351375.0 ], [ 2047375.0, 351125.0 ], [ 2047375.0, 350875.0 ], [ 2047625.0, 350875.0 ], [ 2047625.0, 351125.0 ], [ 2047625.0, 351375.0 ], [ 2047625.0, 351625.0 ], [ 2047375.0, 351625.0 ], [ 2047375.0, 351375.0 ] ], [ [ 2047625.0, 350625.0 ], [ 2047875.0, 350625.0 ], [ 2048125.0, 350625.0 ], [ 2048125.0, 350875.0 ], [ 2048125.0, 351125.0 ], [ 2047875.0, 351125.0 ], [ 2047875.0, 350875.0 ], [ 2047625.0, 350875.0 ], [ 2047625.0, 350625.0 ] ], [ [ 2043625.0, 350375.0 ], [ 2043625.0, 350125.0 ], [ 2043875.0, 350125.0 ], [ 2043875.0, 350375.0 ], [ 2043625.0, 350375.0 ] ], [ [ 2046125.0, 350625.0 ], [ 2046125.0, 350875.0 ], [ 2045875.0, 350875.0 ], [ 2045875.0, 350625.0 ], [ 2046125.0, 350625.0 ] ], [ [ 2046125.0, 348875.0 ], [ 2046125.0, 349125.0 ], [ 2045875.0, 349125.0 ], [ 2045875.0, 348875.0 ], [ 2046125.0, 348875.0 ] ], [ [ 2046875.0, 355375.0 ], [ 2046875.0, 355625.0 ], [ 2046625.0, 355625.0 ], [ 2046625.0, 355375.0 ], [ 2046875.0, 355375.0 ] ], [ [ 2048875.0, 353875.0 ], [ 2048875.0, 353625.0 ], [ 2048625.0, 353625.0 ], [ 2048500.0, 353500.0 ], [ 2048625.0, 353375.0 ], [ 2048875.0, 353375.0 ], [ 2049125.0, 353375.0 ], [ 2049125.0, 353625.0 ], [ 2049125.0, 353875.0 ], [ 2049125.0, 354125.0 ], [ 2048875.0, 354125.0 ], [ 2048875.0, 353875.0 ] ], [ [ 2049375.0, 352125.0 ], [ 2049375.0, 352375.0 ], [ 2049625.0, 352375.0 ], [ 2049625.0, 352625.0 ], [ 2049625.0, 352875.0 ], [ 2049625.0, 353125.0 ], [ 2049375.0, 353125.0 ], [ 2049125.0, 353125.0 ], [ 2049125.0, 352875.0 ], [ 2049125.0, 352625.0 ], [ 2049125.0, 352375.0 ], [ 2048875.0, 352375.0 ], [ 2048875.0, 352125.0 ], [ 2048875.0, 351875.0 ], [ 2049125.0, 351875.0 ], [ 2049125.0, 351625.0 ], [ 2049375.0, 351625.0 ], [ 2049375.0, 351875.0 ], [ 2049625.0, 351875.0 ], [ 2049625.0, 352125.0 ], [ 2049375.0, 352125.0 ] ], [ [ 2049125.0, 351125.0 ], [ 2049375.0, 351125.0 ], [ 2049375.0, 351375.0 ], [ 2049125.0, 351375.0 ], [ 2049125.0, 351125.0 ] ], [ [ 2049375.0, 350375.0 ], [ 2049375.0, 350125.0 ], [ 2049625.0, 350125.0 ], [ 2049625.0, 350375.0 ], [ 2049625.0, 350625.0 ], [ 2049375.0, 350625.0 ], [ 2049375.0, 350875.0 ], [ 2049125.0, 350875.0 ], [ 2049125.0, 350625.0 ], [ 2049125.0, 350375.0 ], [ 2049375.0, 350375.0 ] ], [ [ 2048375.0, 351875.0 ], [ 2048125.0, 351875.0 ], [ 2048125.0, 351625.0 ], [ 2048375.0, 351625.0 ], [ 2048375.0, 351875.0 ] ], [ [ 2048375.0, 351375.0 ], [ 2048625.0, 351375.0 ], [ 2048625.0, 351625.0 ], [ 2048375.0, 351625.0 ], [ 2048375.0, 351375.0 ] ], [ [ 2047875.0, 349875.0 ], [ 2048125.0, 349875.0 ], [ 2048375.0, 349875.0 ], [ 2048375.0, 350125.0 ], [ 2048125.0, 350125.0 ], [ 2047875.0, 350125.0 ], [ 2047875.0, 349875.0 ] ], [ [ 2049625.0, 348375.0 ], [ 2049625.0, 348125.0 ], [ 2049625.0, 347875.0 ], [ 2049625.0, 347625.0 ], [ 2049875.0, 347625.0 ], [ 2049875.0, 347875.0 ], [ 2049875.0, 348125.0 ], [ 2049875.0, 348375.0 ], [ 2049625.0, 348375.0 ] ], [ [ 2050125.0, 351125.0 ], [ 2050125.0, 350875.0 ], [ 2050375.0, 350875.0 ], [ 2050375.0, 351125.0 ], [ 2050125.0, 351125.0 ] ], [ [ 2049875.0, 351375.0 ], [ 2050125.0, 351375.0 ], [ 2050125.0, 351625.0 ], [ 2050125.0, 351875.0 ], [ 2049875.0, 351875.0 ], [ 2049875.0, 351625.0 ], [ 2049875.0, 351375.0 ] ], [ [ 2049625.0, 356875.0 ], [ 2049625.0, 356625.0 ], [ 2049875.0, 356625.0 ], [ 2049875.0, 356875.0 ], [ 2049625.0, 356875.0 ] ], [ [ 2050125.0, 356625.0 ], [ 2050125.0, 356375.0 ], [ 2050375.0, 356375.0 ], [ 2050375.0, 356625.0 ], [ 2050125.0, 356625.0 ] ], [ [ 2055875.0, 352375.0 ], [ 2056125.0, 352375.0 ], [ 2056375.0, 352375.0 ], [ 2056625.0, 352375.0 ], [ 2056625.0, 352625.0 ], [ 2056375.0, 352625.0 ], [ 2056125.0, 352625.0 ], [ 2055875.0, 352625.0 ], [ 2055875.0, 352375.0 ] ], [ [ 2057625.0, 353375.0 ], [ 2057625.0, 353625.0 ], [ 2057375.0, 353625.0 ], [ 2057375.0, 353375.0 ], [ 2057625.0, 353375.0 ] ] ], [ [ [ 2007973.371252968208864, 320581.881023104069754 ], [ 2007802.646582176443189, 320758.666990148311015 ], [ 2007631.921911379788071, 320935.452957197616342 ], [ 2007325.133, 321253.133900000015274 ], [ 2007568.955295509891585, 321529.296566680888645 ], [ 2007771.765017242636532, 321271.765017242520116 ], [ 2007839.446900221286342, 321125.0 ], [ 2008125.0, 321125.0 ], [ 2008125.0, 320866.190288251324091 ], [ 2008375.0, 320875.0 ], [ 2008625.0, 320875.0 ], [ 2008625.0, 321125.0 ], [ 2008875.0, 321125.0 ], [ 2008875.0, 321375.0 ], [ 2009125.0, 321375.0 ], [ 2009125.0, 321625.0 ], [ 2009125.0, 321875.0 ], [ 2008875.0, 321875.0 ], [ 2008625.0, 321875.0 ], [ 2008625.0, 322125.0 ], [ 2008875.0, 322125.0 ], [ 2008875.0, 322375.0 ], [ 2009125.0, 322375.0 ], [ 2009125.0, 322125.0 ], [ 2009375.0, 322125.0 ], [ 2009625.0, 322125.0 ], [ 2009625.0, 322375.0 ], [ 2009875.0, 322375.0 ], [ 2009875.0, 322625.0 ], [ 2010125.0, 322625.0 ], [ 2010375.0, 322625.0 ], [ 2010375.0, 322875.0 ], [ 2010375.0, 323125.0 ], [ 2010625.0, 323125.0 ], [ 2010625.0, 323375.0 ], [ 2010625.0, 323625.0 ], [ 2010875.0, 323625.0 ], [ 2010875.0, 323875.0 ], [ 2011125.0, 323875.0 ], [ 2011125.0, 324125.0 ], [ 2011125.0, 324375.0 ], [ 2011125.0, 324625.0 ], [ 2011125.0, 324875.0 ], [ 2011375.0, 324875.0 ], [ 2011375.0, 325125.0 ], [ 2011625.0, 325125.0 ], [ 2011625.0, 325375.0 ], [ 2011875.0, 325375.0 ], [ 2012125.0, 325375.0 ], [ 2012375.0, 325375.0 ], [ 2012625.0, 325375.0 ], [ 2012875.0, 325375.0 ], [ 2012875.0, 325625.0 ], [ 2013125.0, 325625.0 ], [ 2013125.0, 325375.0 ], [ 2013375.0, 325375.0 ], [ 2013625.0, 325375.0 ], [ 2013875.0, 325375.0 ], [ 2014125.0, 325375.0 ], [ 2014125.0, 325125.0 ], [ 2014375.0, 325125.0 ], [ 2014375.0, 325375.0 ], [ 2014625.0, 325375.0 ], [ 2014875.0, 325375.0 ], [ 2015125.0, 325375.0 ], [ 2015125.0, 325125.0 ], [ 2015375.0, 325125.0 ], [ 2015625.0, 325125.0 ], [ 2015875.0, 325125.0 ], [ 2016125.0, 325125.0 ], [ 2016375.0, 325125.0 ], [ 2016375.0, 325375.0 ], [ 2016625.0, 325375.0 ], [ 2016875.0, 325375.0 ], [ 2016875.0, 325625.0 ], [ 2017125.0, 325625.0 ], [ 2017279.628278370480984, 325470.371721629460808 ], [ 2017101.786805160110816, 325329.876957793021575 ], [ 2016989.656413544202223, 325260.343586455914192 ], [ 2016625.0, 325034.215866325830575 ], [ 2016526.725379060953856, 324973.27462093916256 ], [ 2016218.104689405299723, 324781.895310594642069 ], [ 2015875.0, 324569.132067444443237 ], [ 2015875.0, 324875.0 ], [ 2015625.0, 324875.0 ], [ 2015625.0, 324625.0 ], [ 2015375.0, 324625.0 ], [ 2015125.0, 324625.0 ], [ 2015125.0, 324375.0 ], [ 2014875.0, 324375.0 ], [ 2014875.0, 324125.0 ], [ 2014625.0, 324125.0 ], [ 2014375.0, 324125.0 ], [ 2014375.0, 323718.316330191039015 ], [ 2014298.791663677198812, 323701.20833632274298 ], [ 2014125.0, 323875.0 ], [ 2014125.0, 324125.0 ], [ 2013875.0, 324125.0 ], [ 2013875.0, 323875.0 ], [ 2013875.0, 323614.831289860594552 ], [ 2013625.0, 323582.573225344181992 ], [ 2013386.554450759897009, 323551.806057700014208 ], [ 2013375.0, 323549.165040383464657 ], [ 2013125.0, 323492.022183241206221 ], [ 2013029.749385733623058, 323470.250614266318735 ], [ 2012731.475698089925572, 323402.073771376977675 ], [ 2012625.0, 323365.850080274394713 ], [ 2012375.0, 323280.798533883062191 ], [ 2012258.750324717955664, 323241.249675282160752 ], [ 2011875.0, 323110.695441100455355 ], [ 2011823.723712249891832, 323093.250930835027248 ], [ 2011720.56660290970467, 323029.433397090237122 ], [ 2011625.0, 323125.0 ], [ 2011375.0, 323125.0 ], [ 2011125.0, 323125.0 ], [ 2011125.0, 322875.0 ], [ 2011257.21581757068634, 322742.784182429371867 ], [ 2010875.0, 322506.328634269651957 ], [ 2010793.86503223143518, 322456.134967768448405 ], [ 2010719.4481006199494, 322410.097374483011663 ], [ 2010518.892821161542088, 322231.107178838399705 ], [ 2010375.0, 322375.0 ], [ 2010125.0, 322375.0 ], [ 2010125.0, 322125.0 ], [ 2010254.688275706255808, 321995.311724293627776 ], [ 2009990.48373025120236, 321759.516269748855848 ], [ 2009849.129186359932646, 321633.361139180022292 ], [ 2009728.139323069481179, 321521.860676930402406 ], [ 2009467.93524143868126, 321282.064758561202325 ], [ 2009371.85752371000126, 321193.522548103996087 ], [ 2009315.707916330080479, 321138.385272103012539 ], [ 2009224.726615462685004, 321025.273384537256788 ], [ 2009001.835049198707566, 320748.164950801176019 ], [ 2008969.452004210092127, 320707.904948922980111 ], [ 2008774.527210074011236, 320475.472789926046971 ], [ 2008705.315881839953363, 320392.943840646999888 ], [ 2008550.574199959635735, 320208.544073916855268 ], [ 2008342.490567919565365, 319960.578737477771938 ], [ 2008204.207694399869069, 319795.792305600130931 ], [ 2007976.070316154975444, 319523.929683844966348 ], [ 2007884.40169651992619, 319414.691682345990557 ], [ 2007728.158886664547026, 319271.841113335511182 ], [ 2007466.964856813661754, 319033.035143186454661 ], [ 2007205.770826962543651, 318794.229173037339933 ], [ 2006944.576797111658379, 318555.423202888283413 ], [ 2006683.382767260773107, 318316.617232739168685 ], [ 2006375.0, 318034.667274101113435 ], [ 2006375.0, 318375.0 ], [ 2006625.0, 318375.0 ], [ 2006625.0, 318625.0 ], [ 2006875.0, 318625.0 ], [ 2006875.0, 318875.0 ], [ 2007125.0, 318875.0 ], [ 2007125.0, 319125.0 ], [ 2007375.0, 319125.0 ], [ 2007375.0, 319375.0 ], [ 2007625.0, 319375.0 ], [ 2007625.0, 319625.0 ], [ 2007875.0, 319625.0 ], [ 2007875.0, 319875.0 ], [ 2008125.0, 319875.0 ], [ 2008125.0, 320081.342086733086035 ], [ 2008186.308506580768153, 320111.32622177497251 ], [ 2008274.469, 320270.0933 ], [ 2008143.762959928717464, 320405.439841219747905 ], [ 2007973.371252968208864, 320581.881023104069754 ] ], [ [ 2011125.0, 323375.0 ], [ 2010875.0, 323375.0 ], [ 2010875.0, 323125.0 ], [ 2011125.0, 323125.0 ], [ 2011125.0, 323375.0 ] ], [ [ 2014375.0, 324375.0 ], [ 2014375.0, 324625.0 ], [ 2014125.0, 324625.0 ], [ 2014125.0, 324375.0 ], [ 2014375.0, 324375.0 ] ], [ [ 2011875.0, 323625.0 ], [ 2012125.0, 323625.0 ], [ 2012125.0, 323875.0 ], [ 2011875.0, 323875.0 ], [ 2011875.0, 323625.0 ] ] ], [ [ [ 2018625.0, 327125.0 ], [ 2018875.0, 327125.0 ], [ 2019125.0, 327125.0 ], [ 2019125.0, 327375.0 ], [ 2019375.0, 327375.0 ], [ 2019375.0, 327625.0 ], [ 2019625.0, 327625.0 ], [ 2019875.0, 327625.0 ], [ 2019875.0, 327875.0 ], [ 2020125.0, 327875.0 ], [ 2020125.0, 328125.0 ], [ 2020375.0, 328125.0 ], [ 2020375.0, 328375.0 ], [ 2020375.0, 328625.0 ], [ 2020625.0, 328625.0 ], [ 2020625.0, 328875.0 ], [ 2020875.0, 328875.0 ], [ 2020875.0, 329125.0 ], [ 2020875.0, 329375.0 ], [ 2021125.0, 329375.0 ], [ 2021125.0, 329625.0 ], [ 2021375.0, 329625.0 ], [ 2021375.0, 329875.0 ], [ 2021625.0, 329875.0 ], [ 2021625.0, 330125.0 ], [ 2021625.0, 330375.0 ], [ 2021875.0, 330375.0 ], [ 2021875.0, 330625.0 ], [ 2022125.0, 330625.0 ], [ 2022125.0, 330875.0 ], [ 2022375.0, 330875.0 ], [ 2022375.0, 331125.0 ], [ 2022625.0, 331125.0 ], [ 2022625.0, 331375.0 ], [ 2022625.0, 331625.0 ], [ 2022625.0, 331875.0 ], [ 2022875.0, 331875.0 ], [ 2022875.0, 332125.0 ], [ 2023125.0, 332125.0 ], [ 2023125.0, 332375.0 ], [ 2023375.0, 332375.0 ], [ 2023375.0, 332625.0 ], [ 2023625.0, 332625.0 ], [ 2023625.0, 332875.0 ], [ 2023875.0, 332875.0 ], [ 2023875.0, 333125.0 ], [ 2024125.0, 333125.0 ], [ 2024125.0, 333375.0 ], [ 2024375.0, 333375.0 ], [ 2024375.0, 333625.0 ], [ 2024625.0, 333625.0 ], [ 2024875.0, 333625.0 ], [ 2025125.0, 333625.0 ], [ 2025375.0, 333625.0 ], [ 2025375.0, 333875.0 ], [ 2025625.0, 333875.0 ], [ 2025875.0, 333875.0 ], [ 2026125.0, 333875.0 ], [ 2026375.0, 333875.0 ], [ 2026375.0, 333625.0 ], [ 2026625.0, 333625.0 ], [ 2026875.0, 333625.0 ], [ 2027125.0, 333625.0 ], [ 2027375.0, 333625.0 ], [ 2027625.0, 333625.0 ], [ 2027625.0, 333875.0 ], [ 2027875.0, 333875.0 ], [ 2028125.0, 333875.0 ], [ 2028375.0, 333875.0 ], [ 2028375.0, 334125.0 ], [ 2028625.0, 334125.0 ], [ 2028875.0, 334125.0 ], [ 2028875.0, 334375.0 ], [ 2029125.0, 334375.0 ], [ 2029375.0, 334375.0 ], [ 2029625.0, 334375.0 ], [ 2029625.0, 334625.0 ], [ 2029875.0, 334625.0 ], [ 2030125.0, 334625.0 ], [ 2030125.0, 334875.0 ], [ 2030375.0, 334875.0 ], [ 2030375.0, 335125.0 ], [ 2030625.0, 335125.0 ], [ 2030625.0, 335375.0 ], [ 2030875.0, 335375.0 ], [ 2031125.0, 335375.0 ], [ 2031125.0, 335625.0 ], [ 2031375.0, 335625.0 ], [ 2031625.0, 335625.0 ], [ 2031625.0, 335875.0 ], [ 2031875.0, 335875.0 ], [ 2032125.0, 335875.0 ], [ 2032125.0, 336125.0 ], [ 2032375.0, 336125.0 ], [ 2032375.0, 336375.0 ], [ 2032625.0, 336375.0 ], [ 2032625.0, 336625.0 ], [ 2032875.0, 336625.0 ], [ 2032875.0, 336875.0 ], [ 2033125.0, 336875.0 ], [ 2033375.0, 336875.0 ], [ 2033375.0, 337125.0 ], [ 2033625.0, 337125.0 ], [ 2033625.0, 337375.0 ], [ 2033875.0, 337375.0 ], [ 2033875.0, 337625.0 ], [ 2034125.0, 337625.0 ], [ 2034375.0, 337625.0 ], [ 2034375.0, 337875.0 ], [ 2034625.0, 337875.0 ], [ 2034875.0, 337875.0 ], [ 2034875.0, 338125.0 ], [ 2035125.0, 338125.0 ], [ 2035125.0, 338375.0 ], [ 2035375.0, 338375.0 ], [ 2035375.0, 338625.0 ], [ 2035625.0, 338625.0 ], [ 2035625.0, 338875.0 ], [ 2035875.0, 338875.0 ], [ 2035875.0, 339125.0 ], [ 2036125.0, 339125.0 ], [ 2036125.0, 339375.0 ], [ 2036375.0, 339375.0 ], [ 2036625.0, 339375.0 ], [ 2036625.0, 339625.0 ], [ 2036875.0, 339625.0 ], [ 2036875.0, 339875.0 ], [ 2037125.0, 339875.0 ], [ 2037125.0, 340125.0 ], [ 2037125.0, 340375.0 ], [ 2037375.0, 340375.0 ], [ 2037375.0, 340625.0 ], [ 2037375.0, 340875.0 ], [ 2037625.0, 340875.0 ], [ 2037625.0, 341125.0 ], [ 2037625.0, 341375.0 ], [ 2037625.0, 341625.0 ], [ 2037625.0, 341875.0 ], [ 2037625.0, 342125.0 ], [ 2037625.0, 342375.0 ], [ 2037625.0, 342625.0 ], [ 2037625.0, 342875.0 ], [ 2037625.0, 343125.0 ], [ 2037625.0, 343375.0 ], [ 2037375.0, 343375.0 ], [ 2037375.0, 343625.0 ], [ 2037375.0, 343875.0 ], [ 2037125.0, 343875.0 ], [ 2037125.0, 344125.0 ], [ 2037125.0, 344375.0 ], [ 2037375.0, 344375.0 ], [ 2037375.0, 344625.0 ], [ 2037375.0, 344875.0 ], [ 2037375.0, 345125.0 ], [ 2037375.0, 345375.0 ], [ 2037625.0, 345375.0 ], [ 2037625.0, 345625.0 ], [ 2037875.0, 345625.0 ], [ 2037875.0, 345875.0 ], [ 2037875.0, 346125.0 ], [ 2038125.0, 346125.0 ], [ 2038375.0, 346125.0 ], [ 2038625.0, 346125.0 ], [ 2038875.0, 346125.0 ], [ 2039125.0, 346125.0 ], [ 2039375.0, 346125.0 ], [ 2039625.0, 346125.0 ], [ 2039625.0, 346375.0 ], [ 2039875.0, 346375.0 ], [ 2040125.0, 346375.0 ], [ 2040125.0, 346125.0 ], [ 2040125.0, 345875.0 ], [ 2040375.0, 345875.0 ], [ 2040375.0, 345625.0 ], [ 2040625.0, 345625.0 ], [ 2040625.0, 345875.0 ], [ 2040625.0, 346125.0 ], [ 2040875.0, 346125.0 ], [ 2040875.0, 345875.0 ], [ 2041125.0, 345875.0 ], [ 2041375.0, 345875.0 ], [ 2041375.0, 346125.0 ], [ 2041625.0, 346125.0 ], [ 2041625.0, 346375.0 ], [ 2041625.0, 346625.0 ], [ 2041625.0, 346875.0 ], [ 2041875.0, 346875.0 ], [ 2042125.0, 346875.0 ], [ 2042375.0, 346875.0 ], [ 2042625.0, 346875.0 ], [ 2042625.0, 347125.0 ], [ 2042625.0, 347375.0 ], [ 2042375.0, 347375.0 ], [ 2042375.0, 347625.0 ], [ 2042625.0, 347625.0 ], [ 2042875.0, 347625.0 ], [ 2043125.0, 347625.0 ], [ 2043125.0, 347375.0 ], [ 2043375.0, 347375.0 ], [ 2043375.0, 347125.0 ], [ 2043375.0, 346875.0 ], [ 2043625.0, 346875.0 ], [ 2043875.0, 346875.0 ], [ 2043875.0, 346625.0 ], [ 2044125.0, 346625.0 ], [ 2044375.0, 346625.0 ], [ 2044375.0, 346375.0 ], [ 2044625.0, 346375.0 ], [ 2044625.0, 346125.0 ], [ 2044875.0, 346125.0 ], [ 2045125.0, 346125.0 ], [ 2045375.0, 346125.0 ], [ 2045625.0, 346125.0 ], [ 2045625.0, 346375.0 ], [ 2045875.0, 346375.0 ], [ 2045875.0, 346125.0 ], [ 2046125.0, 346125.0 ], [ 2046375.0, 346125.0 ], [ 2046625.0, 346125.0 ], [ 2046875.0, 346125.0 ], [ 2046875.0, 345875.0 ], [ 2047125.0, 345875.0 ], [ 2047375.0, 345875.0 ], [ 2047625.0, 345875.0 ], [ 2047875.0, 345875.0 ], [ 2048125.0, 345875.0 ], [ 2048125.0, 345625.0 ], [ 2047875.0, 345625.0 ], [ 2047875.0, 345237.50147760193795 ], [ 2047793.932758786948398, 345206.067241213051602 ], [ 2047675.248018850106746, 345160.046627768024337 ], [ 2047459.140141147188842, 345040.859858852927573 ], [ 2047125.0, 344856.576508280762937 ], [ 2046975.741703647188842, 344774.258296352811158 ], [ 2046625.0, 344580.818932522961404 ], [ 2046492.343266147421673, 344507.656733852694742 ], [ 2046131.133816140005365, 344308.444249303021934 ], [ 2046125.0, 344304.580215346999466 ], [ 2046014.825111124897376, 344235.174888875102624 ], [ 2045708.068354367977008, 344041.931645632139407 ], [ 2045625.0, 344125.0 ], [ 2045625.0, 344375.0 ], [ 2045625.0, 344625.0 ], [ 2045375.0, 344625.0 ], [ 2045375.0, 344375.0 ], [ 2045125.0, 344375.0 ], [ 2045125.0, 344625.0 ], [ 2044875.0, 344625.0 ], [ 2044625.0, 344625.0 ], [ 2044625.0, 344875.0 ], [ 2044625.0, 345125.0 ], [ 2044375.0, 345125.0 ], [ 2044375.0, 344875.0 ], [ 2044125.0, 344875.0 ], [ 2043875.0, 344875.0 ], [ 2043875.0, 345125.0 ], [ 2043625.0, 345125.0 ], [ 2043625.0, 344875.0 ], [ 2043625.0, 344625.0 ], [ 2043875.0, 344625.0 ], [ 2044125.0, 344625.0 ], [ 2044375.0, 344625.0 ], [ 2044375.0, 344375.0 ], [ 2044125.0, 344375.0 ], [ 2043875.0, 344375.0 ], [ 2043625.0, 344375.0 ], [ 2043375.0, 344375.0 ], [ 2043125.0, 344375.0 ], [ 2043125.0, 344125.0 ], [ 2043375.0, 344125.0 ], [ 2043625.0, 344125.0 ], [ 2043625.0, 343875.0 ], [ 2043625.0, 343625.0 ], [ 2043625.0, 343375.0 ], [ 2043375.0, 343375.0 ], [ 2043375.0, 343125.0 ], [ 2043625.0, 343125.0 ], [ 2043625.0, 342875.0 ], [ 2043748.182275134138763, 342751.817724865977652 ], [ 2043477.097937785089016, 342522.902062214910984 ], [ 2043375.0, 342625.0 ], [ 2043125.0, 342625.0 ], [ 2043125.0, 342875.0 ], [ 2043125.0, 343125.0 ], [ 2043125.0, 343375.0 ], [ 2043125.0, 343625.0 ], [ 2043375.0, 343625.0 ], [ 2043375.0, 343875.0 ], [ 2043125.0, 343875.0 ], [ 2042875.0, 343875.0 ], [ 2042875.0, 343625.0 ], [ 2042875.0, 343375.0 ], [ 2042625.0, 343375.0 ], [ 2042625.0, 343125.0 ], [ 2042375.0, 343125.0 ], [ 2042375.0, 342875.0 ], [ 2042125.0, 342875.0 ], [ 2042125.0, 342625.0 ], [ 2042125.0, 342375.0 ], [ 2042125.0, 342125.0 ], [ 2042375.0, 342125.0 ], [ 2042375.0, 342375.0 ], [ 2042625.0, 342375.0 ], [ 2042875.0, 342375.0 ], [ 2043125.0, 342375.0 ], [ 2043206.013600436039269, 342293.986399563902523 ], [ 2042934.929263087222353, 342065.070736912835855 ], [ 2042875.0, 342125.0 ], [ 2042625.0, 342125.0 ], [ 2042625.0, 341875.0 ], [ 2042375.0, 341875.0 ], [ 2042125.0, 341875.0 ], [ 2041875.0, 341875.0 ], [ 2041875.0, 342125.0 ], [ 2041625.0, 342125.0 ], [ 2041625.0, 341875.0 ], [ 2041375.0, 341875.0 ], [ 2041375.0, 342125.0 ], [ 2041375.0, 342375.0 ], [ 2041125.0, 342375.0 ], [ 2041125.0, 342125.0 ], [ 2041125.0, 341875.0 ], [ 2041125.0, 341625.0 ], [ 2041375.0, 341625.0 ], [ 2041375.0, 341375.0 ], [ 2041375.0, 341125.0 ], [ 2041625.0, 341125.0 ], [ 2041875.0, 341125.0 ], [ 2042125.0, 341125.0 ], [ 2042125.0, 340875.0 ], [ 2042125.0, 340625.0 ], [ 2042375.0, 340625.0 ], [ 2042514.009862861363217, 340764.00986286130501 ], [ 2042614.399504894157872, 340375.0 ], [ 2042649.858159119961783, 340237.597714881005231 ], [ 2042689.136431750608608, 340125.0 ], [ 2042375.0, 340125.0 ], [ 2042375.0, 339875.0 ], [ 2042125.0, 339875.0 ], [ 2042125.0, 340125.0 ], [ 2041875.0, 340125.0 ], [ 2041625.0, 340125.0 ], [ 2041539.783753642113879, 340039.783753642172087 ], [ 2041423.925064839888364, 340125.298500138975214 ], [ 2041220.156350103206933, 340220.156350103148725 ], [ 2041125.0, 340264.453271703154314 ], [ 2040881.145526919979602, 340377.971733310027048 ], [ 2040875.0, 340380.206470371806063 ], [ 2040512.151411605300382, 340512.151411605242174 ], [ 2040375.0, 340562.024652188585605 ], [ 2040366.440792680019513, 340565.137091214011889 ], [ 2040125.0, 340565.137091214011889 ], [ 2040010.826612659962848, 340565.137091214011889 ], [ 2039875.0, 340508.542669272166677 ], [ 2039780.734586396254599, 340469.265413603803609 ], [ 2039449.330538949929178, 340331.180393834016286 ], [ 2039375.0, 340293.491669859387912 ], [ 2039263.197116261580959, 340236.802883738419041 ], [ 2038875.0, 340039.970543098519556 ], [ 2038784.893518389901146, 339994.282749606005382 ], [ 2038767.365848004352301, 339982.634151995647699 ], [ 2038466.990378667600453, 339783.009621332399547 ], [ 2038375.0, 339875.0 ], [ 2038125.0, 339875.0 ], [ 2038125.0, 339555.728515509690624 ], [ 2038016.42717466247268, 339483.57282533752732 ], [ 2037716.051705325720832, 339283.948294674279168 ], [ 2037375.0, 339057.291015509981662 ], [ 2037265.488501320593059, 338984.511498679406941 ], [ 2037125.0, 339125.0 ], [ 2037125.0, 339375.0 ], [ 2036875.0, 339375.0 ], [ 2036875.0, 339125.0 ], [ 2036875.0, 338875.0 ], [ 2036965.113031983841211, 338784.886968016100582 ], [ 2036625.0, 338558.853515510330908 ], [ 2036514.549827978713438, 338485.450172021228354 ], [ 2036214.174358641961589, 338285.825641357980203 ], [ 2035875.0, 338060.416015510680154 ], [ 2035763.611154636833817, 337986.388845363107976 ], [ 2035463.235685300081968, 337786.764314699859824 ], [ 2035125.0, 337561.978515510971192 ], [ 2035012.672481294954196, 337487.327518704987597 ], [ 2034712.297011958202347, 337287.702988041739445 ], [ 2034375.0, 337063.541015511320438 ], [ 2034292.924928680062294, 337008.995291029976215 ], [ 2034261.388202633941546, 336988.611797366000246 ], [ 2033957.684498930349946, 336792.315501069650054 ], [ 2033625.0, 336577.287715175421908 ], [ 2033502.128943375078961, 336497.871056625037454 ], [ 2033198.425239671487361, 336301.574760328629054 ], [ 2032875.0, 336092.531617614033166 ], [ 2032742.869684115983546, 336007.130315884016454 ], [ 2032375.0, 335769.360885906440672 ], [ 2032287.31412856047973, 335712.685871439403854 ], [ 2031983.61042485688813, 335516.389575143053662 ], [ 2031625.0, 335284.604788345051929 ], [ 2031528.054869301617146, 335221.945130698441062 ], [ 2031224.351165598025545, 335025.648834402032662 ], [ 2031223.41305904998444, 335025.042497242975514 ], [ 2030875.0, 334800.846267940942198 ], [ 2030768.003593581030145, 334731.996406419028062 ], [ 2030463.770789348287508, 334536.229210651712492 ], [ 2030147.212251099990681, 334332.530672996013891 ], [ 2030125.0, 334321.741865318908822 ], [ 2029992.577590650646016, 334257.422409349353984 ], [ 2029625.0, 334078.884722462389618 ], [ 2029487.769898342434317, 334012.230101657449268 ], [ 2029164.59412209992297, 333855.259010340028908 ], [ 2029125.0, 333828.497765758656897 ], [ 2029003.573267129948363, 333746.426732870109845 ], [ 2028705.224210526095703, 333544.775789473787881 ], [ 2028375.0, 333321.58076971094124 ], [ 2028257.700625620549545, 333242.299374379392248 ], [ 2027959.351569016929716, 333040.648430983070284 ], [ 2027625.0, 332814.663773663225584 ], [ 2027511.827984111383557, 332738.172015888616443 ], [ 2027213.478927507763728, 332536.521072492352687 ], [ 2026875.0, 332307.746777615509927 ], [ 2026765.955342601984739, 332234.044657397898845 ], [ 2026625.0, 332375.0 ], [ 2026375.0, 332375.0 ], [ 2026375.0, 332125.0 ], [ 2026467.60628599836491, 332032.39371400163509 ], [ 2026125.0, 331800.829781567794271 ], [ 2026020.082701092818752, 331729.917298907181248 ], [ 2025875.0, 331875.0 ], [ 2025625.0, 331875.0 ], [ 2025625.0, 332125.0 ], [ 2025625.0, 332375.0 ], [ 2025375.0, 332375.0 ], [ 2025375.0, 332125.0 ], [ 2025125.0, 332125.0 ], [ 2025125.0, 331875.0 ], [ 2025375.0, 331875.0 ], [ 2025375.0, 331625.0 ], [ 2025375.0, 331293.912785520078614 ], [ 2025274.210059583652765, 331225.789940416463651 ], [ 2024975.861002979800105, 331024.138997020141687 ], [ 2024875.0, 331125.0 ], [ 2024625.0, 331125.0 ], [ 2024375.0, 331125.0 ], [ 2024375.0, 330875.0 ], [ 2024528.337418074253947, 330721.662581925687846 ], [ 2024429.310567120090127, 330654.731390174012631 ], [ 2024233.723596747498959, 330516.276403252559248 ], [ 2023875.0, 330262.337857134349179 ], [ 2023794.586462694685906, 330205.413537305197679 ], [ 2023501.828373326454312, 329998.171626673662104 ], [ 2023209.070283957989886, 329790.929716042068321 ], [ 2023125.0, 329875.0 ], [ 2022875.0, 329875.0 ], [ 2022875.0, 329554.443120293261018 ], [ 2022769.933149905176833, 329480.066850094764959 ], [ 2022477.175060536712408, 329272.824939463171177 ], [ 2022125.0, 329023.522067662503105 ], [ 2022038.037926484132186, 328961.962073515867814 ], [ 2021745.27983711566776, 328754.720162884274032 ], [ 2021452.521747747203335, 328547.478252252738457 ], [ 2021125.0, 328315.627330821473151 ], [ 2021013.384613694623113, 328236.615386305376887 ], [ 2020873.168766930000857, 328137.357326359022409 ], [ 2020722.521045047324151, 328027.478954952734057 ], [ 2020375.0, 327774.006509554979857 ], [ 2020288.83783894055523, 327711.16216105944477 ], [ 2019999.715701536042616, 327500.284298463899177 ], [ 2019710.593564131530002, 327289.406435868411791 ], [ 2019375.0, 327044.633572260674555 ], [ 2019276.910358024761081, 326973.089641975122504 ], [ 2018987.788220620481297, 326762.211779379635118 ], [ 2018698.666083215968683, 326551.333916784089524 ], [ 2018375.0, 326315.260634966369253 ], [ 2018264.982877109199762, 326235.017122890800238 ], [ 2018037.613594680093229, 326069.18012151500443 ], [ 2017977.952300716424361, 326022.047699283633847 ], [ 2017698.622691778000444, 325801.377308221941348 ], [ 2017375.0, 325545.715381716901902 ], [ 2017375.0, 325875.0 ], [ 2017625.0, 325875.0 ], [ 2017625.0, 326125.0 ], [ 2017875.0, 326125.0 ], [ 2017875.0, 326375.0 ], [ 2018125.0, 326375.0 ], [ 2018125.0, 326625.0 ], [ 2018375.0, 326625.0 ], [ 2018375.0, 326875.0 ], [ 2018625.0, 326875.0 ], [ 2018625.0, 327125.0 ] ], [ [ 2026125.0, 333625.0 ], [ 2026125.0, 333375.0 ], [ 2026375.0, 333375.0 ], [ 2026375.0, 333625.0 ], [ 2026125.0, 333625.0 ] ], [ [ 2037125.0, 339625.0 ], [ 2037375.0, 339625.0 ], [ 2037625.0, 339625.0 ], [ 2037625.0, 339875.0 ], [ 2037375.0, 339875.0 ], [ 2037125.0, 339875.0 ], [ 2037125.0, 339625.0 ] ], [ [ 2037875.0, 345375.0 ], [ 2038125.0, 345375.0 ], [ 2038125.0, 345625.0 ], [ 2037875.0, 345625.0 ], [ 2037875.0, 345375.0 ] ], [ [ 2041625.0, 342375.0 ], [ 2041625.0, 342625.0 ], [ 2041375.0, 342625.0 ], [ 2041375.0, 342375.0 ], [ 2041625.0, 342375.0 ] ], [ [ 2041875.0, 342625.0 ], [ 2041875.0, 342875.0 ], [ 2041875.0, 343125.0 ], [ 2041875.0, 343375.0 ], [ 2041875.0, 343625.0 ], [ 2041875.0, 343875.0 ], [ 2041625.0, 343875.0 ], [ 2041625.0, 343625.0 ], [ 2041625.0, 343375.0 ], [ 2041625.0, 343125.0 ], [ 2041625.0, 342875.0 ], [ 2041625.0, 342625.0 ], [ 2041875.0, 342625.0 ] ], [ [ 2038375.0, 344125.0 ], [ 2038125.0, 344125.0 ], [ 2038125.0, 343875.0 ], [ 2038125.0, 343625.0 ], [ 2038375.0, 343625.0 ], [ 2038625.0, 343625.0 ], [ 2038875.0, 343625.0 ], [ 2038875.0, 343875.0 ], [ 2039125.0, 343875.0 ], [ 2039125.0, 344125.0 ], [ 2038875.0, 344125.0 ], [ 2038875.0, 344375.0 ], [ 2038875.0, 344625.0 ], [ 2038875.0, 344875.0 ], [ 2038875.0, 345125.0 ], [ 2038625.0, 345125.0 ], [ 2038375.0, 345125.0 ], [ 2038375.0, 344875.0 ], [ 2038375.0, 344625.0 ], [ 2038125.0, 344625.0 ], [ 2038125.0, 344375.0 ], [ 2038375.0, 344375.0 ], [ 2038375.0, 344125.0 ] ], [ [ 2040625.0, 343625.0 ], [ 2040625.0, 343375.0 ], [ 2040875.0, 343375.0 ], [ 2040875.0, 343625.0 ], [ 2040875.0, 343875.0 ], [ 2040625.0, 343875.0 ], [ 2040375.0, 343875.0 ], [ 2040375.0, 344125.0 ], [ 2040125.0, 344125.0 ], [ 2040125.0, 344375.0 ], [ 2039875.0, 344375.0 ], [ 2039875.0, 344125.0 ], [ 2039875.0, 343875.0 ], [ 2040125.0, 343875.0 ], [ 2040125.0, 343625.0 ], [ 2040375.0, 343625.0 ], [ 2040625.0, 343625.0 ] ], [ [ 2040375.0, 345125.0 ], [ 2040125.0, 345125.0 ], [ 2039875.0, 345125.0 ], [ 2039875.0, 345375.0 ], [ 2039625.0, 345375.0 ], [ 2039625.0, 345125.0 ], [ 2039625.0, 344875.0 ], [ 2039875.0, 344875.0 ], [ 2040125.0, 344875.0 ], [ 2040375.0, 344875.0 ], [ 2040375.0, 345125.0 ] ], [ [ 2024875.0, 333125.0 ], [ 2024875.0, 333375.0 ], [ 2024625.0, 333375.0 ], [ 2024625.0, 333125.0 ], [ 2024875.0, 333125.0 ] ], [ [ 2023375.0, 331625.0 ], [ 2023375.0, 331375.0 ], [ 2023625.0, 331375.0 ], [ 2023625.0, 331625.0 ], [ 2023375.0, 331625.0 ] ], [ [ 2023875.0, 331625.0 ], [ 2023875.0, 331375.0 ], [ 2024125.0, 331375.0 ], [ 2024125.0, 331625.0 ], [ 2023875.0, 331625.0 ] ], [ [ 2039375.0, 341625.0 ], [ 2039375.0, 341375.0 ], [ 2039625.0, 341375.0 ], [ 2039625.0, 341625.0 ], [ 2039625.0, 341875.0 ], [ 2039875.0, 341875.0 ], [ 2039875.0, 342125.0 ], [ 2040125.0, 342125.0 ], [ 2040125.0, 342375.0 ], [ 2039875.0, 342375.0 ], [ 2039625.0, 342375.0 ], [ 2039375.0, 342375.0 ], [ 2039375.0, 342125.0 ], [ 2039375.0, 341875.0 ], [ 2039125.0, 341875.0 ], [ 2038875.0, 341875.0 ], [ 2038625.0, 341875.0 ], [ 2038375.0, 341875.0 ], [ 2038125.0, 341875.0 ], [ 2037875.0, 341875.0 ], [ 2037875.0, 341625.0 ], [ 2038125.0, 341625.0 ], [ 2038375.0, 341625.0 ], [ 2038625.0, 341625.0 ], [ 2038875.0, 341625.0 ], [ 2039125.0, 341625.0 ], [ 2039375.0, 341625.0 ] ], [ [ 2040125.0, 341375.0 ], [ 2039875.0, 341375.0 ], [ 2039875.0, 341125.0 ], [ 2040125.0, 341125.0 ], [ 2040375.0, 341125.0 ], [ 2040375.0, 341375.0 ], [ 2040125.0, 341375.0 ] ], [ [ 2041875.0, 344125.0 ], [ 2042125.0, 344125.0 ], [ 2042375.0, 344125.0 ], [ 2042625.0, 344125.0 ], [ 2042625.0, 344375.0 ], [ 2042375.0, 344375.0 ], [ 2042125.0, 344375.0 ], [ 2041875.0, 344375.0 ], [ 2041875.0, 344625.0 ], [ 2042125.0, 344625.0 ], [ 2042125.0, 344875.0 ], [ 2042125.0, 345125.0 ], [ 2041875.0, 345125.0 ], [ 2041625.0, 345125.0 ], [ 2041375.0, 345125.0 ], [ 2041125.0, 345125.0 ], [ 2041125.0, 344875.0 ], [ 2041125.0, 344625.0 ], [ 2041125.0, 344375.0 ], [ 2041125.0, 344125.0 ], [ 2041125.0, 343875.0 ], [ 2041375.0, 343875.0 ], [ 2041375.0, 344125.0 ], [ 2041625.0, 344125.0 ], [ 2041875.0, 344125.0 ] ], [ [ 2042375.0, 345625.0 ], [ 2042375.0, 345875.0 ], [ 2042125.0, 345875.0 ], [ 2042125.0, 345625.0 ], [ 2042375.0, 345625.0 ] ], [ [ 2042375.0, 345375.0 ], [ 2042625.0, 345375.0 ], [ 2042625.0, 345625.0 ], [ 2042375.0, 345625.0 ], [ 2042375.0, 345375.0 ] ], [ [ 2043625.0, 345875.0 ], [ 2043375.0, 345875.0 ], [ 2043375.0, 345625.0 ], [ 2043625.0, 345625.0 ], [ 2043625.0, 345875.0 ] ], [ [ 2042875.0, 344625.0 ], [ 2042875.0, 344875.0 ], [ 2042625.0, 344875.0 ], [ 2042625.0, 344625.0 ], [ 2042875.0, 344625.0 ] ], [ [ 2043125.0, 344625.0 ], [ 2043375.0, 344625.0 ], [ 2043375.0, 344875.0 ], [ 2043125.0, 344875.0 ], [ 2043125.0, 344625.0 ] ], [ [ 2047125.0, 345375.0 ], [ 2047125.0, 345125.0 ], [ 2047375.0, 345125.0 ], [ 2047375.0, 345375.0 ], [ 2047125.0, 345375.0 ] ], [ [ 2044125.0, 345375.0 ], [ 2044375.0, 345375.0 ], [ 2044375.0, 345625.0 ], [ 2044125.0, 345625.0 ], [ 2044125.0, 345375.0 ] ] ], [ [ [ 2047944.085763221839443, 328375.0 ], [ 2047993.426009615883231, 328243.426009615825024 ], [ 2048096.370074129896238, 327968.908504244987853 ], [ 2048033.314358457922935, 327716.685641542135272 ], [ 2047875.0, 327875.0 ], [ 2047875.0, 328125.0 ], [ 2047625.0, 328125.0 ], [ 2047625.0, 328375.0 ], [ 2047375.0, 328375.0 ], [ 2047375.0, 328125.0 ], [ 2047375.0, 327875.0 ], [ 2047375.0, 327625.0 ], [ 2047625.0, 327625.0 ], [ 2048010.392948073800653, 327625.0 ], [ 2047955.996055709896609, 327407.412430531985592 ], [ 2047772.418572968337685, 327227.5814270315459 ], [ 2047497.440928840078413, 326958.215571561013348 ], [ 2047375.0, 326955.115801210689824 ], [ 2047125.0, 326948.786687286745291 ], [ 2046875.0, 326942.457573362858966 ], [ 2046758.137765120016411, 326939.499035771004856 ], [ 2046625.0, 326974.420416785869747 ], [ 2046375.0, 327039.994187277217861 ], [ 2046187.283423509914428, 327089.231322093983181 ], [ 2045982.021927803521976, 327232.021927803463768 ], [ 2045972.043261920101941, 327238.963608418009244 ], [ 2045809.501623356016353, 327625.0 ], [ 2045754.834475693991408, 327754.834475694107823 ], [ 2045747.44483242998831, 327772.384878445998766 ], [ 2045653.862153480062261, 328090.565986883011647 ], [ 2045633.676697514718398, 328125.0 ], [ 2045538.078787563135847, 328288.078787563194055 ], [ 2045340.573249236680567, 328625.0 ], [ 2045335.681045040022582, 328633.345524806005415 ], [ 2045245.162522831233218, 328745.162522831233218 ], [ 2045375.0, 328875.0 ], [ 2045625.0, 328875.0 ], [ 2045625.0, 329125.0 ], [ 2045625.0, 329375.0 ], [ 2045375.0, 329375.0 ], [ 2045125.0, 329375.0 ], [ 2044875.0, 329375.0 ], [ 2044758.410026984056458, 329258.410026984114666 ], [ 2044624.45268500992097, 329559.814046433020849 ], [ 2044606.470352991949767, 329625.0 ], [ 2044556.422709102509543, 329806.422709102567751 ], [ 2044549.586541849886999, 329831.203815394022968 ], [ 2044437.287327100057155, 329887.353422766027506 ], [ 2044375.0, 329889.844915849971585 ], [ 2044203.330629719886929, 329896.711690660973545 ], [ 2044125.0, 329891.489648679620586 ], [ 2044125.0, 330125.0 ], [ 2043875.0, 330125.0 ], [ 2043875.0, 329874.822982012876309 ], [ 2043625.0, 329858.156315346132033 ], [ 2043375.0, 329841.489648679387756 ], [ 2043220.712500720052049, 329831.203815394022968 ], [ 2043125.0, 329807.275690214126371 ], [ 2042875.0, 329744.775690214417409 ], [ 2042808.948713330086321, 329728.262868546997197 ], [ 2042625.0, 329792.89349755551666 ], [ 2042462.692801210097969, 329849.920351185020991 ], [ 2042266.169175409944728, 329924.786494346975815 ], [ 2042227.847405931679532, 329977.847405931563117 ], [ 2042144.511692770058289, 330093.23531646101037 ], [ 2042089.724115420831367, 330375.0 ], [ 2042079.003817510092631, 330430.132960689021274 ], [ 2042072.284264430403709, 330625.0 ], [ 2042063.663574775448069, 330875.0 ], [ 2042060.287281719967723, 330972.912498612015042 ], [ 2042052.868379213381559, 331125.0 ], [ 2042041.570745930075645, 331356.601482315978501 ], [ 2042029.305067472159863, 331375.0 ], [ 2041985.421138549922034, 331440.825893372995779 ], [ 2041953.567391995340586, 331453.56739199522417 ], [ 2041891.838459599995986, 331478.258964954002295 ], [ 2041875.0, 331478.258964954002295 ], [ 2041771.741035046055913, 331478.258964954002295 ], [ 2041751.464441169984639, 331478.258964954002295 ], [ 2041657.88176222005859, 331412.75108968699351 ], [ 2041480.59065587236546, 331269.409344127692748 ], [ 2041375.0, 331375.0 ], [ 2041125.0, 331375.0 ], [ 2041125.0, 331125.0 ], [ 2041204.391320103546605, 331045.608679896511603 ], [ 2040875.0, 330767.456009589717723 ], [ 2040797.764814077410847, 330702.235185922472738 ], [ 2040796.921115860110149, 330701.522729650023393 ], [ 2040375.0, 330533.910231568617746 ], [ 2040261.270128387259319, 330488.729871612857096 ], [ 2040113.767559509957209, 330430.132960689021274 ], [ 2039875.0, 330313.525547903496772 ], [ 2039711.362040020059794, 330233.609334888984449 ], [ 2039625.0, 330216.62008111452451 ], [ 2039548.440754137234762, 330201.559245862823445 ], [ 2039375.0, 330375.0 ], [ 2039125.0, 330375.0 ], [ 2038875.0, 330375.0 ], [ 2038875.0, 330625.0 ], [ 2038875.0, 330875.0 ], [ 2038595.783522840589285, 330875.0 ], [ 2038719.38564311992377, 331075.853445458982605 ], [ 2038875.0, 331185.359844745253213 ], [ 2038986.310525910230353, 331263.689474089711439 ], [ 2039224.732109460048378, 331431.467625477002002 ], [ 2039375.0, 331483.886657060240395 ], [ 2039479.618512869346887, 331520.381487130653113 ], [ 2039625.0, 331375.0 ], [ 2039625.0, 331125.0 ], [ 2039625.0, 330875.0 ], [ 2039625.0, 330625.0 ], [ 2039875.0, 330625.0 ], [ 2039875.0, 330875.0 ], [ 2040125.0, 330875.0 ], [ 2040125.0, 331125.0 ], [ 2040375.0, 331125.0 ], [ 2040625.0, 331125.0 ], [ 2040625.0, 331375.0 ], [ 2040875.0, 331375.0 ], [ 2040875.0, 331625.0 ], [ 2041125.0, 331625.0 ], [ 2041375.0, 331625.0 ], [ 2041375.0, 331875.0 ], [ 2041625.0, 331875.0 ], [ 2041875.0, 331875.0 ], [ 2041875.0, 332125.0 ], [ 2042125.0, 332125.0 ], [ 2042125.0, 332375.0 ], [ 2042125.0, 332625.0 ], [ 2041875.0, 332625.0 ], [ 2041625.0, 332625.0 ], [ 2041375.0, 332625.0 ], [ 2041375.0, 332375.0 ], [ 2041125.0, 332375.0 ], [ 2040992.545040570897982, 332507.454959429043811 ], [ 2041021.519545349990949, 332526.384969217993785 ], [ 2041090.550066895550117, 332625.0 ], [ 2041152.535295879933983, 332713.550327123026364 ], [ 2041156.04507137532346, 332875.0 ], [ 2041375.0, 332875.0 ], [ 2041375.0, 333125.0 ], [ 2041208.471752394689247, 333291.528247605252545 ], [ 2041234.831253152573481, 333375.0 ], [ 2041274.192778520053253, 333499.644830322009511 ], [ 2041482.171753969043493, 333767.828246030898299 ], [ 2041629.806958540109918, 333958.199957186996471 ], [ 2041714.274781053652987, 334035.725218946230598 ], [ 2041974.989066767739132, 334275.01093323220266 ], [ 2042125.0, 334125.0 ], [ 2042375.0, 334125.0 ], [ 2042375.0, 334375.0 ], [ 2042235.703352481825277, 334514.29664751823293 ], [ 2042312.960514890030026, 334585.203906167007517 ], [ 2042326.640422145137563, 334625.0 ], [ 2042466.918453689431772, 335033.081546310626436 ], [ 2042498.515422145137563, 335125.0 ], [ 2042584.452922145137563, 335375.0 ], [ 2042722.73240717779845, 335777.267592822259758 ], [ 2042875.0, 335625.0 ], [ 2042875.0, 335375.0 ], [ 2043125.0, 335375.0 ], [ 2043125.0, 335625.0 ], [ 2043125.0, 335875.0 ], [ 2042750.086454898351803, 335875.0 ], [ 2042819.051972138229758, 336125.0 ], [ 2042874.456588600063697, 336325.841734679008368 ], [ 2042875.502509138779715, 336375.0 ], [ 2042880.821658074855804, 336625.0 ], [ 2042886.140807010699064, 336875.0 ], [ 2042891.459955946775153, 337125.0 ], [ 2042893.173124389955774, 337205.51891682902351 ], [ 2042873.617614797316492, 337375.0 ], [ 2042865.098320710007101, 337448.83388210501289 ], [ 2042790.232177539961413, 337504.983489477017429 ], [ 2042754.983489477075636, 337504.983489477017429 ], [ 2042875.0, 337625.0 ], [ 2042875.0, 337875.0 ], [ 2042875.0, 338125.0 ], [ 2042875.0, 338375.0 ], [ 2043125.0, 338375.0 ], [ 2043125.0, 338625.0 ], [ 2043125.0, 338875.0 ], [ 2043301.428946725092828, 339051.428946725151036 ], [ 2043304.936911779921502, 339030.381156397983432 ], [ 2043407.877858629915863, 338712.200047959981021 ], [ 2043430.750359400175512, 338680.750359400233719 ], [ 2043482.744001789949834, 338609.259101113013458 ], [ 2043625.0, 338665.145386123040225 ], [ 2043625.0, 338306.056384409370366 ], [ 2043538.893609160091728, 338263.003188989998307 ], [ 2043524.739936937578022, 338225.260063062421978 ], [ 2043487.142413290217519, 338125.0 ], [ 2043482.744001789949834, 338113.270902665972244 ], [ 2043471.121030928567052, 337875.0 ], [ 2043464.027466, 337729.581918962008785 ], [ 2043497.493680067127571, 337625.0 ], [ 2043528.404303080402315, 337528.40430308051873 ], [ 2043538.893609160091728, 337495.625221581023652 ], [ 2043651.192823899909854, 337373.967738943989389 ], [ 2043787.333049761131406, 337287.333049761131406 ], [ 2043857.074717599898577, 337242.951988409971818 ], [ 2043875.0, 337239.590997960011009 ], [ 2044125.0, 337192.715997960825916 ], [ 2044156.539290250046179, 337186.802381039015017 ], [ 2044375.0, 337122.073281853401568 ], [ 2044409.212523420108482, 337111.936237877001986 ], [ 2044774.568503508344293, 337024.568503508344293 ], [ 2044839.692846599966288, 337008.995291029976215 ], [ 2044875.0, 337007.272990864061285 ], [ 2045125.0, 336995.077868912369013 ], [ 2045223.381830299971625, 336990.278755238978192 ], [ 2045373.114116620039567, 336943.487415763025638 ], [ 2045375.0, 336942.511958842398599 ], [ 2045375.0, 336625.0 ], [ 2045625.0, 336625.0 ], [ 2045625.0, 336375.0 ], [ 2045892.986534549389035, 336375.0 ], [ 2045887.818850859999657, 336250.975591516995337 ], [ 2045936.583595962263644, 336125.0 ], [ 2045989.164918018272147, 335989.164918018388562 ], [ 2046000.118065600050613, 335960.869286764995195 ], [ 2046121.775548239937052, 335773.703928861010354 ], [ 2046239.942066502058879, 335739.942066502058879 ], [ 2046125.0, 335625.0 ], [ 2046125.0, 335375.0 ], [ 2045875.0, 335375.0 ], [ 2045875.0, 335125.0 ], [ 2045875.0, 334875.0 ], [ 2045625.0, 334875.0 ], [ 2045625.0, 334625.0 ], [ 2045375.0, 334625.0 ], [ 2045375.0, 334375.0 ], [ 2045125.0, 334375.0 ], [ 2044875.0, 334375.0 ], [ 2044875.0, 334125.0 ], [ 2044625.0, 334125.0 ], [ 2044625.0, 333875.0 ], [ 2044625.0, 333544.825958084082231 ], [ 2044521.511738159926608, 333509.003098217013758 ], [ 2044502.733377312542871, 333497.266622687457129 ], [ 2044125.0, 333261.183261868485715 ], [ 2044041.19491577311419, 333208.805084226944018 ], [ 2043907.106781009119004, 333125.0 ], [ 2043625.0, 333125.0 ], [ 2043625.0, 332875.0 ], [ 2043625.0, 332625.0 ], [ 2043625.0, 332375.0 ], [ 2043625.0, 332125.0 ], [ 2043979.688020539935678, 332125.0 ], [ 2044007.247189057758078, 332007.24718905769987 ], [ 2044096.709297132911161, 331625.0 ], [ 2044100.389682869892567, 331609.274715486972127 ], [ 2044240.763701299903914, 331553.125108115025796 ], [ 2044299.595217163208872, 331549.595217163325287 ], [ 2044375.0, 331545.070930193178356 ], [ 2044625.0, 331530.070930193527602 ], [ 2044708.677096060011536, 331525.050304430013057 ], [ 2044875.0, 331467.697578934021294 ], [ 2045251.456633989932016, 331337.884946524980478 ], [ 2045287.948588171508163, 331287.948588171508163 ], [ 2045499.059699283214286, 330999.059699283330701 ], [ 2045607.07081400998868, 330851.255015973991249 ], [ 2045634.221415924606845, 330625.0 ], [ 2045664.221415922045708, 330375.0 ], [ 2045691.295225060079247, 330149.384923832025379 ], [ 2045711.48899010871537, 330125.0 ], [ 2045785.558080059709027, 330035.55808005965082 ], [ 2046012.053806556155905, 329762.053806556214113 ], [ 2046187.283423509914428, 329550.455778538016602 ], [ 2046271.33054011175409, 329521.330540111695882 ], [ 2046375.0, 329485.405479754437692 ], [ 2046625.0, 329398.771816388296429 ], [ 2047013.977598935598508, 329263.977598935656715 ], [ 2047125.0, 329225.504489655955695 ], [ 2047132.468480929965153, 329222.916402205009945 ], [ 2047488.473845226690173, 328988.473845226631965 ], [ 2047516.157464629970491, 328970.243169034016319 ], [ 2047718.521745939273387, 328718.521745939331595 ], [ 2047899.846448329975829, 328492.971506377973128 ], [ 2047944.085763221839443, 328375.0 ] ], [ [ 2042375.0, 332625.0 ], [ 2042375.0, 332875.0 ], [ 2042125.0, 332875.0 ], [ 2042125.0, 332625.0 ], [ 2042375.0, 332625.0 ] ], [ [ 2042375.0, 332375.0 ], [ 2042625.0, 332375.0 ], [ 2042625.0, 332625.0 ], [ 2042375.0, 332625.0 ], [ 2042375.0, 332375.0 ] ], [ [ 2042625.0, 332125.0 ], [ 2042375.0, 332125.0 ], [ 2042375.0, 331875.0 ], [ 2042375.0, 331625.0 ], [ 2042375.0, 331375.0 ], [ 2042375.0, 331125.0 ], [ 2042375.0, 330875.0 ], [ 2042375.0, 330625.0 ], [ 2042625.0, 330625.0 ], [ 2042625.0, 330875.0 ], [ 2042625.0, 331125.0 ], [ 2042625.0, 331375.0 ], [ 2042625.0, 331625.0 ], [ 2042875.0, 331625.0 ], [ 2042875.0, 331875.0 ], [ 2042875.0, 332125.0 ], [ 2042875.0, 332375.0 ], [ 2042625.0, 332375.0 ], [ 2042625.0, 332125.0 ] ] ], [ [ [ 2048125.0, 334375.0 ], [ 2048375.0, 334375.0 ], [ 2048375.0, 334125.0 ], [ 2048375.0, 333875.0 ], [ 2048125.0, 333875.0 ], [ 2047875.0, 333875.0 ], [ 2047625.0, 333875.0 ], [ 2047375.0, 333875.0 ], [ 2047218.655123849865049, 333718.655123849981464 ], [ 2047125.0, 333776.929423133609816 ], [ 2047125.0, 334125.0 ], [ 2047125.0, 334375.0 ], [ 2046875.0, 334375.0 ], [ 2046875.0, 334625.0 ], [ 2047125.0, 334625.0 ], [ 2047125.0, 334875.0 ], [ 2047375.0, 334875.0 ], [ 2047375.0, 334625.0 ], [ 2047375.0, 334375.0 ], [ 2047625.0, 334375.0 ], [ 2047625.0, 334625.0 ], [ 2047875.0, 334625.0 ], [ 2048125.0, 334625.0 ], [ 2048125.0, 334375.0 ] ] ], [ [ [ 2047125.0, 335875.0 ], [ 2046875.0, 335875.0 ], [ 2046875.0, 335625.0 ], [ 2046625.0, 335625.0 ], [ 2046625.0, 335375.0 ], [ 2046375.0, 335375.0 ], [ 2046375.0, 335625.0 ], [ 2046259.751744923647493, 335740.248255076410715 ], [ 2046383.807049310067669, 335811.13700044102734 ], [ 2046625.0, 335917.545655156834982 ], [ 2046701.988157750107348, 335951.511018869990949 ], [ 2046764.311606182716787, 335985.688393817225005 ], [ 2046992.094462499953806, 336110.601573089021258 ], [ 2047125.0, 336165.978880381851923 ], [ 2047216.69289198005572, 336204.184252040984575 ], [ 2047366.425178309902549, 336269.69212730700383 ], [ 2047375.0, 336269.69212730700383 ], [ 2047488.082660950021818, 336269.69212730700383 ], [ 2047619.098411479964852, 336250.975591516995337 ], [ 2047722.039358329959214, 336138.67637677397579 ], [ 2047778.188965700101107, 335988.944090450997464 ], [ 2047737.973404365358874, 335875.0 ], [ 2047375.0, 335875.0 ], [ 2047125.0, 335875.0 ] ] ], [ [ [ 2050375.0, 346875.0 ], [ 2050625.0, 346875.0 ], [ 2050875.0, 346875.0 ], [ 2051125.0, 346875.0 ], [ 2051125.0, 347125.0 ], [ 2051375.0, 347125.0 ], [ 2051625.0, 347125.0 ], [ 2051875.0, 347125.0 ], [ 2052125.0, 347125.0 ], [ 2052125.0, 347375.0 ], [ 2052125.0, 347599.571051757840905 ], [ 2052153.325309976236895, 347625.0 ], [ 2052375.0, 347625.0 ], [ 2052625.0, 347625.0 ], [ 2052875.0, 347625.0 ], [ 2052875.0, 347875.0 ], [ 2052875.0, 348125.0 ], [ 2053125.0, 348125.0 ], [ 2053375.0, 348125.0 ], [ 2053625.0, 348125.0 ], [ 2053875.0, 348125.0 ], [ 2054125.0, 348125.0 ], [ 2054375.0, 348125.0 ], [ 2054375.0, 348375.0 ], [ 2054625.0, 348375.0 ], [ 2054625.0, 348625.0 ], [ 2054875.0, 348625.0 ], [ 2054875.0, 348875.0 ], [ 2055125.0, 348875.0 ], [ 2055375.0, 348875.0 ], [ 2055375.0, 349125.0 ], [ 2055625.0, 349125.0 ], [ 2055625.0, 349375.0 ], [ 2055875.0, 349375.0 ], [ 2055875.0, 349625.0 ], [ 2056125.0, 349625.0 ], [ 2056125.0, 349875.0 ], [ 2056125.0, 350125.0 ], [ 2056375.0, 350125.0 ], [ 2056625.0, 350125.0 ], [ 2056625.0, 350375.0 ], [ 2056875.0, 350375.0 ], [ 2057125.0, 350375.0 ], [ 2057375.0, 350375.0 ], [ 2057375.0, 350125.0 ], [ 2057625.0, 350125.0 ], [ 2057875.0, 350125.0 ], [ 2057875.0, 349875.0 ], [ 2058125.0, 349875.0 ], [ 2058375.0, 349875.0 ], [ 2058375.0, 350125.0 ], [ 2058625.0, 350125.0 ], [ 2058875.0, 350125.0 ], [ 2058875.0, 349875.0 ], [ 2059125.0, 349875.0 ], [ 2059375.0, 349875.0 ], [ 2059625.0, 349875.0 ], [ 2059875.0, 349875.0 ], [ 2060125.0, 349875.0 ], [ 2060375.0, 349875.0 ], [ 2060520.999021985335276, 349729.000978014722932 ], [ 2060131.10258738999255, 349595.865610103996005 ], [ 2060125.0, 349594.126700793916825 ], [ 2059875.0, 349522.890141654061154 ], [ 2059759.905580135295168, 349490.094419864646625 ], [ 2059625.0, 349625.0 ], [ 2059375.0, 349625.0 ], [ 2059125.0, 349625.0 ], [ 2059125.0, 349309.180464234494139 ], [ 2058875.0, 349237.943905094580259 ], [ 2058787.102232855278999, 349212.897767144721001 ], [ 2058390.464758879970759, 349099.877411657012999 ], [ 2058375.0, 349093.421250182844233 ], [ 2058125.0, 348989.052318144124001 ], [ 2058044.538433090085164, 348955.461566909914836 ], [ 2057625.0, 348780.314454066683538 ], [ 2057515.428844048874453, 348734.571155951183755 ], [ 2057426.563165670027956, 348697.47189216199331 ], [ 2057239.545636754948646, 348510.454363245167769 ], [ 2057080.307253550039604, 348351.215980038978159 ], [ 2056986.184095392236486, 348263.815904607879929 ], [ 2056875.0, 348375.0 ], [ 2056625.0, 348375.0 ], [ 2056625.0, 348121.706425654585473 ], [ 2056425.228500880068168, 348135.975818448991049 ], [ 2056375.0, 348121.624818197393324 ], [ 2056125.0, 348050.196246767998673 ], [ 2055988.736252514179796, 348011.263747485820204 ], [ 2055966.673374020028859, 348004.960067916021217 ], [ 2055625.0, 347786.513156657922082 ], [ 2055526.476974438643083, 347723.523025561473332 ], [ 2055375.0, 347875.0 ], [ 2055375.0, 348125.0 ], [ 2055125.0, 348125.0 ], [ 2054875.0, 348125.0 ], [ 2054875.0, 347875.0 ], [ 2054875.0, 347625.0 ], [ 2055125.0, 347625.0 ], [ 2055221.476974438177422, 347528.523025561822578 ], [ 2054875.0, 347307.004959938058164 ], [ 2054824.964690800057724, 347275.0151720889844 ], [ 2054750.894243598682806, 347249.105756401258986 ], [ 2054375.0, 347117.620115636324044 ], [ 2054125.0, 347030.171555965614971 ], [ 2054010.040585062000901, 346989.959414937940892 ], [ 2053625.0, 346855.274436624080408 ], [ 2053375.0, 346767.825876953371335 ], [ 2053269.186926525318995, 346730.81307347456459 ], [ 2052875.0, 346592.928757611836772 ], [ 2052625.0, 346505.480197941069491 ], [ 2052550.905592259950936, 346479.562400994997006 ], [ 2052525.807856808882207, 346474.192143191059586 ], [ 2052375.0, 346625.0 ], [ 2052125.0, 346625.0 ], [ 2051875.0, 346625.0 ], [ 2051625.0, 346625.0 ], [ 2051625.0, 346281.442863786884118 ], [ 2051375.0, 346227.949414005328435 ], [ 2051290.19634601729922, 346209.803653982817195 ], [ 2050875.0, 346120.962514442158863 ], [ 2050625.0, 346067.469064660603181 ], [ 2050407.862244250020012, 346021.007274129020516 ], [ 2050375.0, 346011.860051502706483 ], [ 2050267.940121002029628, 345982.05987899802858 ], [ 2050125.0, 346125.0 ], [ 2049875.0, 346125.0 ], [ 2049875.0, 345872.684793770487886 ], [ 2049625.0, 345803.097164904407691 ], [ 2049375.0, 345733.509536038327496 ], [ 2049290.117540357168764, 345709.882459642831236 ], [ 2048875.0, 345594.334278306108899 ], [ 2048625.0, 345524.746649439970497 ], [ 2048625.0, 345875.0 ], [ 2048375.0, 345875.0 ], [ 2048125.0, 345875.0 ], [ 2048125.0, 346125.0 ], [ 2048375.0, 346125.0 ], [ 2048625.0, 346125.0 ], [ 2048875.0, 346125.0 ], [ 2049125.0, 346125.0 ], [ 2049125.0, 346375.0 ], [ 2049375.0, 346375.0 ], [ 2049625.0, 346375.0 ], [ 2049625.0, 346625.0 ], [ 2049875.0, 346625.0 ], [ 2050125.0, 346625.0 ], [ 2050375.0, 346625.0 ], [ 2050375.0, 346875.0 ] ], [ [ 2054375.0, 347875.0 ], [ 2054625.0, 347875.0 ], [ 2054625.0, 348125.0 ], [ 2054375.0, 348125.0 ], [ 2054375.0, 347875.0 ] ], [ [ 2056125.0, 349375.0 ], [ 2056375.0, 349375.0 ], [ 2056375.0, 349625.0 ], [ 2056125.0, 349625.0 ], [ 2056125.0, 349375.0 ] ], [ [ 2058625.0, 349875.0 ], [ 2058625.0, 349625.0 ], [ 2058875.0, 349625.0 ], [ 2058875.0, 349875.0 ], [ 2058625.0, 349875.0 ] ], [ [ 2054125.0, 347625.0 ], [ 2054125.0, 347875.0 ], [ 2053875.0, 347875.0 ], [ 2053875.0, 347625.0 ], [ 2054125.0, 347625.0 ] ], [ [ 2057125.0, 348875.0 ], [ 2057375.0, 348875.0 ], [ 2057375.0, 349125.0 ], [ 2057125.0, 349125.0 ], [ 2057125.0, 348875.0 ] ], [ [ 2055875.0, 348625.0 ], [ 2056125.0, 348625.0 ], [ 2056125.0, 348875.0 ], [ 2055875.0, 348875.0 ], [ 2055875.0, 348625.0 ] ], [ [ 2056625.0, 349375.0 ], [ 2056625.0, 349125.0 ], [ 2056875.0, 349125.0 ], [ 2056875.0, 349375.0 ], [ 2056875.0, 349625.0 ], [ 2056875.0, 349875.0 ], [ 2056625.0, 349875.0 ], [ 2056625.0, 349625.0 ], [ 2056625.0, 349375.0 ] ] ], [ [ [ 2061375.0, 353875.0 ], [ 2061125.0, 353875.0 ], [ 2061125.0, 354125.0 ], [ 2061125.0, 354375.0 ], [ 2060875.0, 354375.0 ], [ 2060875.0, 354625.0 ], [ 2060875.0, 354875.0 ], [ 2060875.0, 355125.0 ], [ 2061125.0, 355125.0 ], [ 2061125.0, 355375.0 ], [ 2061125.0, 355625.0 ], [ 2061125.0, 355875.0 ], [ 2061375.0, 355875.0 ], [ 2061375.0, 356125.0 ], [ 2061375.0, 356375.0 ], [ 2061625.0, 356375.0 ], [ 2061875.0, 356375.0 ], [ 2061875.0, 356625.0 ], [ 2062125.0, 356625.0 ], [ 2062375.0, 356625.0 ], [ 2062375.0, 356375.0 ], [ 2062375.0, 356125.0 ], [ 2062375.0, 355875.0 ], [ 2062375.0, 355625.0 ], [ 2062375.0, 355375.0 ], [ 2062375.0, 355125.0 ], [ 2062375.0, 354875.0 ], [ 2062625.0, 354875.0 ], [ 2062625.0, 354625.0 ], [ 2062875.0, 354625.0 ], [ 2063125.0, 354625.0 ], [ 2063375.0, 354625.0 ], [ 2063625.0, 354625.0 ], [ 2063625.0, 354875.0 ], [ 2063875.0, 354875.0 ], [ 2064125.0, 354875.0 ], [ 2064375.0, 354875.0 ], [ 2064625.0, 354875.0 ], [ 2064875.0, 354875.0 ], [ 2065125.0, 354875.0 ], [ 2065125.0, 355125.0 ], [ 2064875.0, 355125.0 ], [ 2064875.0, 355375.0 ], [ 2064625.0, 355375.0 ], [ 2064625.0, 355625.0 ], [ 2064375.0, 355625.0 ], [ 2064125.0, 355625.0 ], [ 2064125.0, 355875.0 ], [ 2063875.0, 355875.0 ], [ 2063875.0, 356125.0 ], [ 2064125.0, 356125.0 ], [ 2064375.0, 356125.0 ], [ 2064625.0, 356125.0 ], [ 2064875.0, 356125.0 ], [ 2064875.0, 355875.0 ], [ 2065125.0, 355875.0 ], [ 2065125.0, 355625.0 ], [ 2065375.0, 355625.0 ], [ 2065375.0, 355375.0 ], [ 2065625.0, 355375.0 ], [ 2065625.0, 355125.0 ], [ 2065625.0, 354875.0 ], [ 2065625.0, 354625.0 ], [ 2065625.0, 354375.0 ], [ 2065875.0, 354375.0 ], [ 2065875.0, 354125.0 ], [ 2065625.0, 354125.0 ], [ 2065625.0, 353875.0 ], [ 2065375.0, 353875.0 ], [ 2065125.0, 353875.0 ], [ 2065125.0, 353625.0 ], [ 2064875.0, 353625.0 ], [ 2064625.0, 353625.0 ], [ 2064625.0, 353875.0 ], [ 2064375.0, 353875.0 ], [ 2064125.0, 353875.0 ], [ 2063875.0, 353875.0 ], [ 2063625.0, 353875.0 ], [ 2063375.0, 353875.0 ], [ 2063125.0, 353875.0 ], [ 2062875.0, 353875.0 ], [ 2062875.0, 353625.0 ], [ 2062625.0, 353625.0 ], [ 2062375.0, 353625.0 ], [ 2062125.0, 353625.0 ], [ 2061875.0, 353625.0 ], [ 2061625.0, 353625.0 ], [ 2061375.0, 353625.0 ], [ 2061375.0, 353875.0 ] ], [ [ 2062875.0, 354125.0 ], [ 2062625.0, 354125.0 ], [ 2062625.0, 353875.0 ], [ 2062875.0, 353875.0 ], [ 2062875.0, 354125.0 ] ], [ [ 2061375.0, 354625.0 ], [ 2061625.0, 354625.0 ], [ 2061625.0, 354875.0 ], [ 2061375.0, 354875.0 ], [ 2061375.0, 354625.0 ] ] ], [ [ [ 2064375.0, 352375.0 ], [ 2064375.0, 352625.0 ], [ 2064625.0, 352625.0 ], [ 2064875.0, 352625.0 ], [ 2064875.0, 352875.0 ], [ 2065125.0, 352875.0 ], [ 2065375.0, 352875.0 ], [ 2065375.0, 353125.0 ], [ 2065625.0, 353125.0 ], [ 2065625.0, 353375.0 ], [ 2065875.0, 353375.0 ], [ 2066125.0, 353375.0 ], [ 2066125.0, 353625.0 ], [ 2066375.0, 353625.0 ], [ 2066625.0, 353625.0 ], [ 2066875.0, 353625.0 ], [ 2066875.0, 353875.0 ], [ 2067125.0, 353875.0 ], [ 2067375.0, 353875.0 ], [ 2067625.0, 353875.0 ], [ 2067625.0, 354125.0 ], [ 2067875.0, 354125.0 ], [ 2068125.0, 354125.0 ], [ 2068375.0, 354125.0 ], [ 2068375.0, 354375.0 ], [ 2068625.0, 354375.0 ], [ 2068625.0, 354625.0 ], [ 2068875.0, 354625.0 ], [ 2069125.0, 354625.0 ], [ 2069125.0, 354875.0 ], [ 2069375.0, 354875.0 ], [ 2069625.0, 354875.0 ], [ 2069625.0, 355125.0 ], [ 2069875.0, 355125.0 ], [ 2069875.0, 355375.0 ], [ 2070125.0, 355375.0 ], [ 2070375.0, 355375.0 ], [ 2070375.0, 355625.0 ], [ 2070625.0, 355625.0 ], [ 2070625.0, 355875.0 ], [ 2070875.0, 355875.0 ], [ 2070875.0, 356125.0 ], [ 2071125.0, 356125.0 ], [ 2071125.0, 356375.0 ], [ 2071125.0, 356625.0 ], [ 2071375.0, 356625.0 ], [ 2071375.0, 356875.0 ], [ 2071375.0, 357125.0 ], [ 2071375.0, 357375.0 ], [ 2071375.0, 357625.0 ], [ 2071625.0, 357625.0 ], [ 2071875.0, 357625.0 ], [ 2072125.0, 357625.0 ], [ 2072375.0, 357625.0 ], [ 2072375.0, 357375.0 ], [ 2072625.0, 357375.0 ], [ 2072625.0, 357625.0 ], [ 2072875.0, 357625.0 ], [ 2072875.0, 357875.0 ], [ 2072875.0, 358125.0 ], [ 2072875.0, 358375.0 ], [ 2072625.0, 358375.0 ], [ 2072375.0, 358375.0 ], [ 2072375.0, 358125.0 ], [ 2072375.0, 357875.0 ], [ 2072125.0, 357875.0 ], [ 2071875.0, 357875.0 ], [ 2071625.0, 357875.0 ], [ 2071625.0, 358125.0 ], [ 2071625.0, 358375.0 ], [ 2071625.0, 358625.0 ], [ 2071625.0, 358875.0 ], [ 2071375.0, 358875.0 ], [ 2071375.0, 359125.0 ], [ 2071625.0, 359125.0 ], [ 2071625.0, 359375.0 ], [ 2071875.0, 359375.0 ], [ 2071875.0, 359625.0 ], [ 2071625.0, 359625.0 ], [ 2071625.0, 359875.0 ], [ 2071625.0, 360125.0 ], [ 2071875.0, 360125.0 ], [ 2071875.0, 360375.0 ], [ 2071875.0, 360625.0 ], [ 2071875.0, 360875.0 ], [ 2072125.0, 360875.0 ], [ 2072125.0, 361125.0 ], [ 2072125.0, 361375.0 ], [ 2072375.0, 361375.0 ], [ 2072375.0, 361625.0 ], [ 2072625.0, 361625.0 ], [ 2072875.0, 361625.0 ], [ 2072875.0, 361875.0 ], [ 2073125.0, 361875.0 ], [ 2073125.0, 362125.0 ], [ 2073375.0, 362125.0 ], [ 2073375.0, 362375.0 ], [ 2073625.0, 362375.0 ], [ 2073625.0, 362625.0 ], [ 2073875.0, 362625.0 ], [ 2073875.0, 362875.0 ], [ 2074125.0, 362875.0 ], [ 2074125.0, 363125.0 ], [ 2074125.0, 363375.0 ], [ 2074375.0, 363375.0 ], [ 2074625.0, 363375.0 ], [ 2074625.0, 363625.0 ], [ 2074875.0, 363625.0 ], [ 2074875.0, 363875.0 ], [ 2074875.0, 364125.0 ], [ 2075125.0, 364125.0 ], [ 2075125.0, 364375.0 ], [ 2075125.0, 364625.0 ], [ 2075375.0, 364625.0 ], [ 2075375.0, 364875.0 ], [ 2075625.0, 364875.0 ], [ 2075875.0, 364875.0 ], [ 2075875.0, 365125.0 ], [ 2075875.0, 365375.0 ], [ 2076125.0, 365375.0 ], [ 2076125.0, 365625.0 ], [ 2076375.0, 365625.0 ], [ 2076375.0, 365875.0 ], [ 2076625.0, 365875.0 ], [ 2076625.0, 366125.0 ], [ 2076875.0, 366125.0 ], [ 2077125.0, 366125.0 ], [ 2077125.0, 365875.0 ], [ 2077125.0, 365625.0 ], [ 2077125.0, 365375.0 ], [ 2077125.0, 365125.0 ], [ 2077125.0, 364875.0 ], [ 2077375.0, 364875.0 ], [ 2077625.0, 364875.0 ], [ 2077875.0, 364875.0 ], [ 2078125.0, 364875.0 ], [ 2078375.0, 364875.0 ], [ 2078625.0, 364875.0 ], [ 2078875.0, 364875.0 ], [ 2078875.0, 364625.0 ], [ 2079125.0, 364625.0 ], [ 2079375.0, 364625.0 ], [ 2079625.0, 364625.0 ], [ 2079875.0, 364625.0 ], [ 2079875.0, 364375.0 ], [ 2080125.0, 364375.0 ], [ 2080375.0, 364375.0 ], [ 2080625.0, 364375.0 ], [ 2080875.0, 364375.0 ], [ 2081125.0, 364375.0 ], [ 2081375.0, 364375.0 ], [ 2081625.0, 364375.0 ], [ 2081875.0, 364375.0 ], [ 2081875.0, 363984.556887765647843 ], [ 2081796.449778583133593, 363953.550221416982822 ], [ 2081767.417961139930412, 363942.090293478977401 ], [ 2081724.657114746980369, 363875.0 ], [ 2081491.233539879787713, 363508.766460120212287 ], [ 2081405.975796067388728, 363375.0 ], [ 2081224.63842322002165, 363090.487915013974998 ], [ 2081210.637321189278737, 363039.362678810663056 ], [ 2081125.0, 363125.0 ], [ 2080875.0, 363125.0 ], [ 2080875.0, 362875.0 ], [ 2080875.0, 362625.0 ], [ 2081049.399536174023524, 362450.600463825976476 ], [ 2081028.695674711605534, 362375.0 ], [ 2080625.0, 362375.0 ], [ 2080625.0, 362125.0 ], [ 2080625.0, 361875.0 ], [ 2080625.0, 361625.0 ], [ 2080780.669894482009113, 361469.330105518107302 ], [ 2080754.836753551848233, 361375.0 ], [ 2080375.0, 361375.0 ], [ 2080125.0, 361375.0 ], [ 2080125.0, 361625.0 ], [ 2080125.0, 361875.0 ], [ 2080125.0, 362125.0 ], [ 2079875.0, 362125.0 ], [ 2079875.0, 361875.0 ], [ 2079625.0, 361875.0 ], [ 2079625.0, 361625.0 ], [ 2079875.0, 361625.0 ], [ 2079875.0, 361375.0 ], [ 2079625.0, 361375.0 ], [ 2079625.0, 361125.0 ], [ 2079375.0, 361125.0 ], [ 2079375.0, 360875.0 ], [ 2079125.0, 360875.0 ], [ 2078875.0, 360875.0 ], [ 2078875.0, 360625.0 ], [ 2079125.0, 360625.0 ], [ 2079375.0, 360625.0 ], [ 2079375.0, 360375.0 ], [ 2079125.0, 360375.0 ], [ 2078875.0, 360375.0 ], [ 2078875.0, 360125.0 ], [ 2078875.0, 359875.0 ], [ 2078625.0, 359875.0 ], [ 2078625.0, 359625.0 ], [ 2078375.0, 359625.0 ], [ 2078375.0, 359375.0 ], [ 2078125.0, 359375.0 ], [ 2077875.0, 359375.0 ], [ 2077875.0, 359625.0 ], [ 2077625.0, 359625.0 ], [ 2077625.0, 359375.0 ], [ 2077375.0, 359375.0 ], [ 2077375.0, 359625.0 ], [ 2077375.0, 359875.0 ], [ 2077375.0, 360125.0 ], [ 2077125.0, 360125.0 ], [ 2077125.0, 359875.0 ], [ 2076875.0, 359875.0 ], [ 2076625.0, 359875.0 ], [ 2076625.0, 359625.0 ], [ 2076375.0, 359625.0 ], [ 2076375.0, 359375.0 ], [ 2076125.0, 359375.0 ], [ 2076125.0, 359125.0 ], [ 2075875.0, 359125.0 ], [ 2075625.0, 359125.0 ], [ 2075625.0, 359375.0 ], [ 2075375.0, 359375.0 ], [ 2075125.0, 359375.0 ], [ 2074875.0, 359375.0 ], [ 2074875.0, 359625.0 ], [ 2074625.0, 359625.0 ], [ 2074625.0, 359875.0 ], [ 2074375.0, 359875.0 ], [ 2074375.0, 360125.0 ], [ 2074125.0, 360125.0 ], [ 2073875.0, 360125.0 ], [ 2073875.0, 359875.0 ], [ 2073875.0, 359625.0 ], [ 2073625.0, 359625.0 ], [ 2073625.0, 359375.0 ], [ 2073625.0, 359125.0 ], [ 2073875.0, 359125.0 ], [ 2074125.0, 359125.0 ], [ 2074125.0, 358875.0 ], [ 2074125.0, 358625.0 ], [ 2074375.0, 358625.0 ], [ 2074375.0, 358875.0 ], [ 2074625.0, 358875.0 ], [ 2074625.0, 358625.0 ], [ 2074625.0, 358375.0 ], [ 2074625.0, 358125.0 ], [ 2074875.0, 358125.0 ], [ 2074875.0, 358375.0 ], [ 2074875.0, 358625.0 ], [ 2075125.0, 358625.0 ], [ 2075375.0, 358625.0 ], [ 2075375.0, 358875.0 ], [ 2075625.0, 358875.0 ], [ 2075625.0, 358625.0 ], [ 2075875.0, 358625.0 ], [ 2075875.0, 358875.0 ], [ 2076125.0, 358875.0 ], [ 2076125.0, 358625.0 ], [ 2076375.0, 358625.0 ], [ 2076375.0, 358375.0 ], [ 2076625.0, 358375.0 ], [ 2076625.0, 358625.0 ], [ 2076625.0, 358875.0 ], [ 2076625.0, 359125.0 ], [ 2076625.0, 359375.0 ], [ 2076875.0, 359375.0 ], [ 2076875.0, 359125.0 ], [ 2077125.0, 359125.0 ], [ 2077125.0, 358875.0 ], [ 2077375.0, 358875.0 ], [ 2077375.0, 359125.0 ], [ 2077625.0, 359125.0 ], [ 2077625.0, 358875.0 ], [ 2077625.0, 358625.0 ], [ 2077375.0, 358625.0 ], [ 2077125.0, 358625.0 ], [ 2077125.0, 358375.0 ], [ 2077125.0, 358125.0 ], [ 2077125.0, 357875.0 ], [ 2077125.0, 357625.0 ], [ 2077248.277869393816218, 357501.722130606183782 ], [ 2076875.0, 357311.750357790791895 ], [ 2076751.236449274467304, 357248.763550725532696 ], [ 2076461.280064549995586, 357101.196462072024588 ], [ 2076375.0, 357084.972860190784559 ], [ 2076125.0, 357037.964313182164915 ], [ 2076125.0, 357375.0 ], [ 2075875.0, 357375.0 ], [ 2075625.0, 357375.0 ], [ 2075375.0, 357375.0 ], [ 2075125.0, 357375.0 ], [ 2075125.0, 357625.0 ], [ 2074875.0, 357625.0 ], [ 2074625.0, 357625.0 ], [ 2074375.0, 357625.0 ], [ 2074375.0, 357375.0 ], [ 2074625.0, 357375.0 ], [ 2074625.0, 357125.0 ], [ 2074375.0, 357125.0 ], [ 2074125.0, 357125.0 ], [ 2074125.0, 356875.0 ], [ 2074375.0, 356875.0 ], [ 2074625.0, 356875.0 ], [ 2074625.0, 356625.0 ], [ 2074375.0, 356625.0 ], [ 2074125.0, 356625.0 ], [ 2073875.0, 356625.0 ], [ 2073875.0, 356375.0 ], [ 2073625.0, 356375.0 ], [ 2073625.0, 356125.0 ], [ 2073375.0, 356125.0 ], [ 2073375.0, 356375.0 ], [ 2073125.0, 356375.0 ], [ 2073125.0, 356125.0 ], [ 2073125.0, 355875.0 ], [ 2073125.0, 355625.0 ], [ 2073375.0, 355625.0 ], [ 2073502.373224553652108, 355497.626775446347892 ], [ 2073125.0, 355363.44962893857155 ], [ 2072875.0, 355274.560740049812011 ], [ 2072764.668306520674378, 355235.33169347938383 ], [ 2072375.0, 355096.782962272234727 ], [ 2072125.0, 355007.894073383475188 ], [ 2072026.963388487463817, 354973.036611512419768 ], [ 2071625.0, 354830.116295605956111 ], [ 2071375.0, 354741.227406717138365 ], [ 2071289.258470454486087, 354710.741529545455705 ], [ 2070958.61854215990752, 354593.180666151980404 ], [ 2070875.0, 354561.541217767167836 ], [ 2070739.666175345424563, 354510.333824654691853 ], [ 2070625.0, 354625.0 ], [ 2070375.0, 354625.0 ], [ 2070375.0, 354372.352028578228783 ], [ 2070125.0, 354277.757433983730152 ], [ 2070014.175979266641662, 354235.824020733358338 ], [ 2069625.0, 354088.568244794732891 ], [ 2069375.0, 353993.973650200292468 ], [ 2069288.685783188091591, 353961.314216811966617 ], [ 2068881.083069419953972, 353807.086162953986786 ], [ 2068875.0, 353805.072173754160758 ], [ 2068739.717351697385311, 353760.282648302498274 ], [ 2068375.0, 353639.53163321322063 ], [ 2068125.0, 353556.761362942750566 ], [ 2067988.448316165013239, 353511.551683835103177 ], [ 2067875.0, 353625.0 ], [ 2067625.0, 353625.0 ], [ 2067375.0, 353625.0 ], [ 2067375.0, 353288.853856756235473 ], [ 2067265.248831795528531, 353234.751168204587884 ], [ 2066875.0, 353042.374983516347129 ], [ 2066762.890341229736805, 352987.109658770321403 ], [ 2066375.0, 352795.896110276458785 ], [ 2066260.531850663945079, 352739.468149336054921 ], [ 2066167.185379809932783, 352693.452283421996981 ], [ 2065875.0, 352565.470257554552518 ], [ 2065742.546545034041628, 352507.453454966016579 ], [ 2065375.0, 352346.461993091274053 ], [ 2065220.994820896303281, 352279.005179103580303 ], [ 2065125.0, 352375.0 ], [ 2064875.0, 352375.0 ], [ 2064875.0, 352110.745114879333414 ], [ 2064722.172132423147559, 352027.827867576968856 ], [ 2064375.0, 351839.468519134621602 ], [ 2064235.965235871262848, 351764.034764128620736 ], [ 2064155.157782339956611, 351720.192422319028992 ], [ 2063875.0, 351530.590690837008879 ], [ 2063782.207961488747969, 351467.792038511310238 ], [ 2063484.015190403908491, 351265.984809596033301 ], [ 2063228.689260710030794, 351093.188473339017946 ], [ 2063125.0, 351030.452113917737734 ], [ 2063125.0, 351375.0 ], [ 2062875.0, 351375.0 ], [ 2062875.0, 351625.0 ], [ 2063125.0, 351625.0 ], [ 2063375.0, 351625.0 ], [ 2063375.0, 351875.0 ], [ 2063625.0, 351875.0 ], [ 2063625.0, 352125.0 ], [ 2063875.0, 352125.0 ], [ 2063875.0, 352375.0 ], [ 2064125.0, 352375.0 ], [ 2064375.0, 352375.0 ] ], [ [ 2072625.0, 357125.0 ], [ 2072875.0, 357125.0 ], [ 2073125.0, 357125.0 ], [ 2073125.0, 357375.0 ], [ 2072875.0, 357375.0 ], [ 2072625.0, 357375.0 ], [ 2072625.0, 357125.0 ] ], [ [ 2073875.0, 357375.0 ], [ 2074125.0, 357375.0 ], [ 2074125.0, 357625.0 ], [ 2073875.0, 357625.0 ], [ 2073625.0, 357625.0 ], [ 2073625.0, 357375.0 ], [ 2073625.0, 357125.0 ], [ 2073875.0, 357125.0 ], [ 2073875.0, 357375.0 ] ], [ [ 2070125.0, 354875.0 ], [ 2070375.0, 354875.0 ], [ 2070375.0, 355125.0 ], [ 2070125.0, 355125.0 ], [ 2070125.0, 354875.0 ] ], [ [ 2072375.0, 359625.0 ], [ 2072375.0, 359375.0 ], [ 2072625.0, 359375.0 ], [ 2072625.0, 359625.0 ], [ 2072375.0, 359625.0 ] ], [ [ 2072625.0, 360125.0 ], [ 2072625.0, 360375.0 ], [ 2072375.0, 360375.0 ], [ 2072375.0, 360125.0 ], [ 2072625.0, 360125.0 ] ], [ [ 2072625.0, 361125.0 ], [ 2072375.0, 361125.0 ], [ 2072375.0, 360875.0 ], [ 2072625.0, 360875.0 ], [ 2072625.0, 361125.0 ] ], [ [ 2076125.0, 362875.0 ], [ 2076125.0, 362625.0 ], [ 2076375.0, 362625.0 ], [ 2076625.0, 362625.0 ], [ 2076875.0, 362625.0 ], [ 2076875.0, 362375.0 ], [ 2076875.0, 362125.0 ], [ 2077125.0, 362125.0 ], [ 2077125.0, 362375.0 ], [ 2077375.0, 362375.0 ], [ 2077375.0, 362625.0 ], [ 2077125.0, 362625.0 ], [ 2077125.0, 362875.0 ], [ 2077375.0, 362875.0 ], [ 2077625.0, 362875.0 ], [ 2077625.0, 363125.0 ], [ 2077625.0, 363375.0 ], [ 2077875.0, 363375.0 ], [ 2078125.0, 363375.0 ], [ 2078375.0, 363375.0 ], [ 2078375.0, 363625.0 ], [ 2078125.0, 363625.0 ], [ 2078125.0, 363875.0 ], [ 2077875.0, 363875.0 ], [ 2077875.0, 364125.0 ], [ 2077625.0, 364125.0 ], [ 2077625.0, 363875.0 ], [ 2077375.0, 363875.0 ], [ 2077125.0, 363875.0 ], [ 2077125.0, 363625.0 ], [ 2076875.0, 363625.0 ], [ 2076875.0, 363375.0 ], [ 2076625.0, 363375.0 ], [ 2076375.0, 363375.0 ], [ 2076375.0, 363125.0 ], [ 2076125.0, 363125.0 ], [ 2075875.0, 363125.0 ], [ 2075875.0, 362875.0 ], [ 2076125.0, 362875.0 ] ], [ [ 2077125.0, 361875.0 ], [ 2077375.0, 361875.0 ], [ 2077625.0, 361875.0 ], [ 2077625.0, 362125.0 ], [ 2077375.0, 362125.0 ], [ 2077125.0, 362125.0 ], [ 2077125.0, 361875.0 ] ], [ [ 2077625.0, 360625.0 ], [ 2077375.0, 360625.0 ], [ 2077375.0, 360375.0 ], [ 2077625.0, 360375.0 ], [ 2077625.0, 360625.0 ] ], [ [ 2073875.0, 361625.0 ], [ 2073625.0, 361625.0 ], [ 2073625.0, 361375.0 ], [ 2073875.0, 361375.0 ], [ 2074125.0, 361375.0 ], [ 2074125.0, 361125.0 ], [ 2074125.0, 360875.0 ], [ 2074375.0, 360875.0 ], [ 2074625.0, 360875.0 ], [ 2074625.0, 360625.0 ], [ 2074875.0, 360625.0 ], [ 2075125.0, 360625.0 ], [ 2075375.0, 360625.0 ], [ 2075375.0, 360875.0 ], [ 2075375.0, 361125.0 ], [ 2075125.0, 361125.0 ], [ 2074875.0, 361125.0 ], [ 2074625.0, 361125.0 ], [ 2074375.0, 361125.0 ], [ 2074375.0, 361375.0 ], [ 2074375.0, 361625.0 ], [ 2074375.0, 361875.0 ], [ 2074125.0, 361875.0 ], [ 2074125.0, 362125.0 ], [ 2073875.0, 362125.0 ], [ 2073875.0, 361875.0 ], [ 2073875.0, 361625.0 ] ], [ [ 2075125.0, 362125.0 ], [ 2075125.0, 362375.0 ], [ 2074875.0, 362375.0 ], [ 2074875.0, 362125.0 ], [ 2075125.0, 362125.0 ] ], [ [ 2074625.0, 362625.0 ], [ 2074875.0, 362625.0 ], [ 2074875.0, 362875.0 ], [ 2074625.0, 362875.0 ], [ 2074625.0, 362625.0 ] ], [ [ 2076125.0, 357625.0 ], [ 2076125.0, 357875.0 ], [ 2076375.0, 357875.0 ], [ 2076375.0, 358125.0 ], [ 2076125.0, 358125.0 ], [ 2075875.0, 358125.0 ], [ 2075875.0, 357875.0 ], [ 2075625.0, 357875.0 ], [ 2075625.0, 357625.0 ], [ 2075875.0, 357625.0 ], [ 2076125.0, 357625.0 ] ], [ [ 2076125.0, 360375.0 ], [ 2076125.0, 360625.0 ], [ 2075875.0, 360625.0 ], [ 2075875.0, 360375.0 ], [ 2076125.0, 360375.0 ] ], [ [ 2075875.0, 363875.0 ], [ 2075875.0, 364125.0 ], [ 2075875.0, 364375.0 ], [ 2075625.0, 364375.0 ], [ 2075625.0, 364125.0 ], [ 2075625.0, 363875.0 ], [ 2075875.0, 363875.0 ] ], [ [ 2080125.0, 363625.0 ], [ 2080125.0, 363375.0 ], [ 2080375.0, 363375.0 ], [ 2080375.0, 363625.0 ], [ 2080125.0, 363625.0 ] ], [ [ 2078125.0, 361375.0 ], [ 2078125.0, 361125.0 ], [ 2078375.0, 361125.0 ], [ 2078375.0, 361375.0 ], [ 2078125.0, 361375.0 ] ], [ [ 2078125.0, 361625.0 ], [ 2077875.0, 361625.0 ], [ 2077875.0, 361375.0 ], [ 2078125.0, 361375.0 ], [ 2078125.0, 361625.0 ] ], [ [ 2078875.0, 362875.0 ], [ 2078875.0, 362625.0 ], [ 2079125.0, 362625.0 ], [ 2079375.0, 362625.0 ], [ 2079375.0, 362375.0 ], [ 2079625.0, 362375.0 ], [ 2079625.0, 362625.0 ], [ 2079875.0, 362625.0 ], [ 2079875.0, 362875.0 ], [ 2079875.0, 363125.0 ], [ 2079875.0, 363375.0 ], [ 2079625.0, 363375.0 ], [ 2079375.0, 363375.0 ], [ 2079375.0, 363125.0 ], [ 2079375.0, 362875.0 ], [ 2079125.0, 362875.0 ], [ 2078875.0, 362875.0 ] ] ], [ [ [ 2046125.0, 362625.0 ], [ 2046125.0, 362883.08905790746212 ], [ 2046375.0, 362906.344871860928833 ], [ 2046375.0, 362625.0 ], [ 2046625.0, 362625.0 ], [ 2046625.0, 362375.0 ], [ 2046625.0, 362125.0 ], [ 2046625.0, 361875.0 ], [ 2046625.0, 361625.0 ], [ 2046625.0, 361375.0 ], [ 2046875.0, 361375.0 ], [ 2046875.0, 361125.0 ], [ 2047125.0, 361125.0 ], [ 2047375.0, 361125.0 ], [ 2047625.0, 361125.0 ], [ 2047875.0, 361125.0 ], [ 2047875.0, 360875.0 ], [ 2047875.0, 360625.0 ], [ 2047875.0, 360375.0 ], [ 2047625.0, 360375.0 ], [ 2047625.0, 360125.0 ], [ 2047375.0, 360125.0 ], [ 2047375.0, 359875.0 ], [ 2047375.0, 359625.0 ], [ 2047125.0, 359625.0 ], [ 2047125.0, 359375.0 ], [ 2047125.0, 359125.0 ], [ 2046875.0, 359125.0 ], [ 2046875.0, 359375.0 ], [ 2046625.0, 359375.0 ], [ 2046625.0, 359625.0 ], [ 2046625.0, 359875.0 ], [ 2046375.0, 359875.0 ], [ 2046375.0, 360125.0 ], [ 2046375.0, 360375.0 ], [ 2046125.0, 360375.0 ], [ 2045875.0, 360375.0 ], [ 2045875.0, 360625.0 ], [ 2045875.0, 360875.0 ], [ 2045875.0, 361125.0 ], [ 2045625.0, 361125.0 ], [ 2045625.0, 361375.0 ], [ 2045625.0, 361625.0 ], [ 2045625.0, 361875.0 ], [ 2045375.0, 361875.0 ], [ 2045375.0, 362125.0 ], [ 2045125.0, 362125.0 ], [ 2045125.0, 362375.0 ], [ 2045375.0, 362375.0 ], [ 2045625.0, 362375.0 ], [ 2045875.0, 362375.0 ], [ 2045875.0, 362625.0 ], [ 2046125.0, 362625.0 ] ], [ [ 2047625.0, 360875.0 ], [ 2047375.0, 360875.0 ], [ 2047375.0, 360625.0 ], [ 2047625.0, 360625.0 ], [ 2047625.0, 360875.0 ] ] ], [ [ [ 2054625.0, 355499.996281132742297 ], [ 2054875.0, 355518.613302409474272 ], [ 2055125.0, 355537.230323686206248 ], [ 2055206.686629440402612, 355543.313370559480973 ], [ 2055405.177300299983472, 355558.094590729975607 ], [ 2055625.0, 355645.153085660480428 ], [ 2055625.0, 355375.0 ], [ 2055875.0, 355375.0 ], [ 2055875.0, 355744.162986650306266 ], [ 2055968.720130129950121, 355781.279869870049879 ], [ 2056125.0, 355625.0 ], [ 2056375.0, 355625.0 ], [ 2056375.0, 355375.0 ], [ 2056625.0, 355375.0 ], [ 2056625.0, 355625.0 ], [ 2056875.0, 355625.0 ], [ 2056875.0, 355375.0 ], [ 2057125.0, 355375.0 ], [ 2057375.0, 355375.0 ], [ 2057375.0, 355625.0 ], [ 2057375.0, 355875.0 ], [ 2057375.0, 356125.0 ], [ 2057125.0, 356125.0 ], [ 2057125.0, 356375.0 ], [ 2056817.524534153053537, 356375.0 ], [ 2056883.783627749886364, 356437.771772880980279 ], [ 2056947.830443567596376, 356750.0 ], [ 2056958.649770909920335, 356802.744220794993453 ], [ 2056893.141895639942959, 357074.133989755995572 ], [ 2056849.058020095573738, 357125.0 ], [ 2056745.031082194764167, 357245.031082194647752 ], [ 2056528.169447730062529, 357495.256045041023754 ], [ 2056511.712746385484934, 357511.712746385543142 ], [ 2056625.0, 357625.0 ], [ 2056875.0, 357625.0 ], [ 2056875.0, 357875.0 ], [ 2056999.206282081548125, 357999.206282081606332 ], [ 2057052.232449860079214, 357869.586760849982966 ], [ 2057248.756075659999624, 357794.720617688028142 ], [ 2057250.0, 357796.710896631993819 ], [ 2057298.930689605418593, 357875.0 ], [ 2057625.0, 357875.0 ], [ 2057992.250846266048029, 357875.0 ], [ 2058002.054767834255472, 357625.0 ], [ 2058006.69421055726707, 357506.694210557383485 ], [ 2058006.775775169953704, 357504.614312936028 ], [ 2058125.0, 357398.212510592187755 ], [ 2058193.941133080050349, 357336.165490821993444 ], [ 2058375.0, 357352.625387815060094 ], [ 2058625.0, 357375.352660542761441 ], [ 2058811.586814159993082, 357392.315098193997983 ], [ 2058875.0, 357396.175031245104037 ], [ 2059125.0, 357411.39242254931014 ], [ 2059375.0, 357426.609813853574451 ], [ 2059625.0, 357441.827205157780554 ], [ 2059875.0, 357457.044596462044865 ], [ 2059887.787622109986842, 357457.822973460017238 ], [ 2060125.0, 357495.915472099150065 ], [ 2060375.0, 357536.061457500502001 ], [ 2060375.0, 357125.0 ], [ 2060375.0, 356875.0 ], [ 2060625.0, 356875.0 ], [ 2060625.0, 357125.0 ], [ 2060875.0, 357125.0 ], [ 2060875.0, 357375.0 ], [ 2060625.0, 357375.0 ], [ 2060451.632580644218251, 357548.367419355723541 ], [ 2060875.0, 357616.353428303205874 ], [ 2061125.0, 357656.499413704499602 ], [ 2061169.870323759969324, 357663.704867155000102 ], [ 2061375.0, 357675.562073874054477 ], [ 2061625.0, 357690.012940926069859 ], [ 2061875.0, 357704.46380797814345 ], [ 2062125.0, 357718.914675030158833 ], [ 2062375.0, 357733.365542082174215 ], [ 2062625.0, 357747.816409134189598 ], [ 2062745.233667867723852, 357754.766332132334355 ], [ 2062788.850669630104676, 357757.287546107021626 ], [ 2063125.0, 357921.786154585599434 ], [ 2063261.443581921281293, 357988.556418078835122 ], [ 2063625.0, 358166.467005648999475 ], [ 2063765.015010492876172, 358234.984989507123828 ], [ 2064108.366442860104144, 358403.008030877972487 ], [ 2064125.0, 358411.611594915855676 ], [ 2064265.642357896314934, 358484.357642103568651 ], [ 2064375.0, 358375.0 ], [ 2064375.0, 358125.0 ], [ 2064625.0, 358125.0 ], [ 2064625.0, 358375.0 ], [ 2064625.0, 358670.232284570811316 ], [ 2064759.960539714666083, 358740.039460285275709 ], [ 2064875.0, 358625.0 ], [ 2065125.0, 358625.0 ], [ 2065125.0, 358375.0 ], [ 2065375.0, 358375.0 ], [ 2065375.0, 358625.0 ], [ 2065625.0, 358625.0 ], [ 2065875.0, 358625.0 ], [ 2065875.0, 358875.0 ], [ 2066125.0, 358875.0 ], [ 2066125.0, 359125.0 ], [ 2066375.0, 359125.0 ], [ 2066375.0, 359375.0 ], [ 2066236.657446560449898, 359513.342553439608309 ], [ 2066382.425541399978101, 359591.508053570985794 ], [ 2066489.289956248365343, 359760.710043751518242 ], [ 2066625.0, 359625.0 ], [ 2066625.0, 359375.0 ], [ 2066875.0, 359375.0 ], [ 2066875.0, 359625.0 ], [ 2066875.0, 359875.0 ], [ 2066501.330059669679031, 359875.0 ], [ 2066504.083024040097371, 359919.047429903002921 ], [ 2066691.248381939949468, 360274.661609922011849 ], [ 2066717.802704068599269, 360282.197295931458939 ], [ 2067125.0, 360397.753285316983238 ], [ 2067375.0, 360468.699231262668036 ], [ 2067383.76020618993789, 360471.185235721990466 ], [ 2067476.595123366219923, 360523.404876633721869 ], [ 2067832.957065159920603, 360723.858468892984092 ], [ 2067875.0, 360743.378402926202398 ], [ 2067964.887919952394441, 360785.112080047605559 ], [ 2068094.988566220039502, 360845.515951530018356 ], [ 2068223.055662324884906, 361026.944337675115094 ], [ 2068292.271423967322335, 361125.0 ], [ 2068319.586995709920302, 361163.697059968020767 ], [ 2068348.93462627241388, 361375.0 ], [ 2068366.3783351900056, 361500.594704195973463 ], [ 2068310.099748992593959, 361625.0 ], [ 2068252.4457288144622, 361752.445728814403992 ], [ 2068188.571245179977268, 361893.641955794999376 ], [ 2068014.422521923435852, 362014.422521923435852 ], [ 2067719.184426684165373, 362219.184426684165373 ], [ 2067875.0, 362375.0 ], [ 2067875.0, 362625.0 ], [ 2067625.0, 362625.0 ], [ 2067625.0, 362284.505883899983019 ], [ 2067608.358635670039803, 362296.047475290019065 ], [ 2067205.192143323365599, 362455.192143323307391 ], [ 2067125.0, 362486.846936740737874 ], [ 2066897.130275639938191, 362576.795512147014961 ], [ 2066875.0, 362582.406004562682938 ], [ 2066625.0, 362645.786286251968704 ], [ 2066242.705913750454783, 362742.705913750454783 ], [ 2066232.693255069898441, 362745.244334260991309 ], [ 2066125.0, 362774.615222007560078 ], [ 2065923.870414529927075, 362829.468745318008587 ], [ 2065734.449496464570984, 362984.449496464570984 ], [ 2065459.449496466200799, 363209.449496466317214 ], [ 2065409.165680299978703, 363250.590800602978561 ], [ 2065240.716858180006966, 363465.830962193023879 ], [ 2065507.156448191963136, 363742.843551808095071 ], [ 2065752.292634962592274, 363997.707365037407726 ], [ 2065997.428821733221412, 364252.571178266778588 ], [ 2066242.565008503850549, 364507.434991496091243 ], [ 2066419.858612979995087, 364691.764056466985494 ], [ 2066520.182177630718797, 364729.817822369164787 ], [ 2066625.0, 364625.0 ], [ 2066875.0, 364625.0 ], [ 2066875.0, 364864.40389292355394 ], [ 2067125.0, 364959.231479130859952 ], [ 2067234.02791986009106, 365000.586897008994129 ], [ 2067375.0, 365030.145558973774314 ], [ 2067453.413004581583664, 365046.586995418299921 ], [ 2067625.0, 364875.0 ], [ 2067875.0, 364875.0 ], [ 2067875.0, 365134.984268651111051 ], [ 2068125.0, 365187.403623489721213 ], [ 2068375.0, 365239.822978328389581 ], [ 2068394.453138869954273, 365243.901862284983508 ], [ 2068470.574728991370648, 365279.425271008512937 ], [ 2068875.0, 365468.157064146769699 ], [ 2068955.949212579987943, 365505.933363350981381 ], [ 2068974.702985221985728, 365525.297014777956065 ], [ 2069220.70298522291705, 365779.297014777141158 ], [ 2069466.702985223848373, 366033.297014776268043 ], [ 2069712.702985224546865, 366287.297014775394928 ], [ 2069958.702985225478187, 366541.297014774521813 ], [ 2070039.769655956188217, 366625.0 ], [ 2070107.016163700027391, 366694.433386043994687 ], [ 2070295.117965420009568, 366954.882034580048639 ], [ 2070375.0, 366875.0 ], [ 2070375.0, 366625.0 ], [ 2070625.0, 366625.0 ], [ 2070625.0, 366875.0 ], [ 2070625.0, 367125.0 ], [ 2070875.0, 367125.0 ], [ 2070875.0, 367375.0 ], [ 2070594.4274010383524, 367375.0 ], [ 2070623.273554883897305, 367625.0 ], [ 2070649.795701619936153, 367854.858605051995255 ], [ 2070648.246363546932116, 367875.0 ], [ 2070875.0, 367875.0 ], [ 2071125.0, 367875.0 ], [ 2071125.0, 368125.0 ], [ 2070875.0, 368125.0 ], [ 2070629.015594316646457, 368125.0 ], [ 2070612.362630039919168, 368341.488535602984484 ], [ 2070770.930509852478281, 368479.069490147521719 ], [ 2071038.647045284276828, 368711.352954715664964 ], [ 2071125.0, 368625.0 ], [ 2071125.0, 368375.0 ], [ 2071375.0, 368375.0 ], [ 2071375.0, 368625.0 ], [ 2071625.0, 368625.0 ], [ 2071625.0, 368875.0 ], [ 2071875.0, 368875.0 ], [ 2071875.0, 369158.764727400324773 ], [ 2072125.0, 369264.604143458185717 ], [ 2072202.560165878152475, 369297.439834121789318 ], [ 2072375.0, 369125.0 ], [ 2072625.0, 369125.0 ], [ 2072625.0, 369491.622143981629051 ], [ 2072709.086039663525298, 369540.913960336416494 ], [ 2073024.303430967032909, 369725.696569032850675 ], [ 2073344.976855440065265, 369913.677542001008987 ], [ 2073375.0, 369914.783657853200566 ], [ 2073625.0, 369923.994184168870561 ], [ 2073875.0, 369933.204710484540556 ], [ 2074125.0, 369942.41523680021055 ], [ 2074375.0, 369951.625763115880545 ], [ 2074625.0, 369960.83628943155054 ], [ 2074875.0, 369970.046815747220535 ], [ 2075123.047755540115759, 369979.185417267028242 ], [ 2075125.0, 369978.518194476957433 ], [ 2075375.0, 369893.075156501901802 ], [ 2075761.112616637954488, 369761.112616637838073 ], [ 2075862.350919259944931, 369726.512184095976409 ], [ 2075875.0, 369724.624261597462464 ], [ 2076125.0, 369687.310828761721496 ], [ 2076375.0, 369649.997395926038735 ], [ 2076625.0, 369612.683963090297766 ], [ 2077049.348383468342945, 369549.348383468342945 ], [ 2077116.358817219967023, 369539.346826191991568 ], [ 2077125.0, 369538.026645489502698 ], [ 2077375.0, 369499.832201044948306 ], [ 2077625.0, 369461.637756600452121 ], [ 2077875.0, 369423.443312155897729 ], [ 2078125.0, 369385.248867711401545 ], [ 2078375.0, 369347.05442326690536 ], [ 2078463.949394129915163, 369333.464932497008704 ], [ 2078625.0, 369390.471424402145203 ], [ 2078875.0, 369478.963006903766654 ], [ 2078982.858659303281456, 369517.141340696776751 ], [ 2079375.0, 369655.946171907067765 ], [ 2079536.786761781433597, 369713.213238218508195 ], [ 2079624.374613140011206, 369744.216388517001178 ], [ 2079875.0, 369963.072360141552053 ], [ 2079961.44257466122508, 370038.55742533877492 ], [ 2080228.359867894090712, 370271.640132105909288 ], [ 2080375.0, 370125.0 ], [ 2080375.0, 369875.0 ], [ 2080625.0, 369875.0 ], [ 2080625.0, 370125.0 ], [ 2080625.0, 370457.010325575945899 ], [ 2080745.477443273877725, 370504.522556726180483 ], [ 2080953.248654260067269, 370586.460499086999334 ], [ 2081125.0, 370603.635633661004249 ], [ 2081375.0, 370628.635633661004249 ], [ 2081625.0, 370653.635633661004249 ], [ 2081625.0, 370375.0 ], [ 2081875.0, 370375.0 ], [ 2081875.0, 370678.635633661004249 ], [ 2082125.0, 370703.635633661004249 ], [ 2082125.0, 370375.0 ], [ 2082375.0, 370375.0 ], [ 2082375.0, 370728.635633660946041 ], [ 2082544.154196450021118, 370745.551053305971436 ], [ 2082625.0, 370759.279585984244477 ], [ 2082723.922289400594309, 370776.077710599405691 ], [ 2083125.0, 370844.185246361419559 ], [ 2083375.0, 370886.638076550036203 ], [ 2083536.130593339912593, 370913.999875419016462 ], [ 2083625.0, 370925.693218400643673 ], [ 2083875.0, 370958.587955242895987 ], [ 2084125.0, 370991.482692085148301 ], [ 2084247.358953380025923, 371007.582554372027516 ], [ 2084375.0, 370967.872006534249522 ], [ 2084668.481008660048246, 370876.566803838999476 ], [ 2084744.536088891560212, 370625.0 ], [ 2084375.0, 370625.0 ], [ 2084375.0, 370375.0 ], [ 2084780.131389210000634, 370375.0 ], [ 2084754.902031411183998, 370125.0 ], [ 2084729.672673612367362, 369875.0 ], [ 2084704.443315813550726, 369625.0 ], [ 2084687.197544449940324, 369454.110083765001036 ], [ 2084665.986869817599654, 369375.0 ], [ 2084598.957884310977533, 369125.0 ], [ 2084498.74964591441676, 368751.250354085525032 ], [ 2084375.0, 368875.0 ], [ 2084125.0, 368875.0 ], [ 2084125.0, 368625.0 ], [ 2084464.899913297733292, 368625.0 ], [ 2084397.870927791111171, 368375.0 ], [ 2084340.941632329951972, 368162.669114223972429 ], [ 2084341.959716498153284, 368125.0 ], [ 2084348.716473254840821, 367875.0 ], [ 2084125.0, 367875.0 ], [ 2084125.0, 368125.0 ], [ 2083875.0, 368125.0 ], [ 2083875.0, 367875.0 ], [ 2083625.0, 367875.0 ], [ 2083625.0, 367625.0 ], [ 2083375.0, 367625.0 ], [ 2083375.0, 367375.0 ], [ 2083625.0, 367375.0 ], [ 2083875.0, 367375.0 ], [ 2083875.0, 367125.0 ], [ 2084125.0, 367125.0 ], [ 2084368.98674352443777, 367125.0 ], [ 2084375.743500281125307, 366875.0 ], [ 2084382.500257037812844, 366625.0 ], [ 2084389.25701379426755, 366375.0 ], [ 2084396.013770550955087, 366125.0 ], [ 2084402.770527307642624, 365875.0 ], [ 2084409.52728406409733, 365625.0 ], [ 2084415.807775489985943, 365392.62181723798858 ], [ 2084237.027790324995294, 365262.972209675121121 ], [ 2084125.0, 365375.0 ], [ 2083875.0, 365375.0 ], [ 2083625.0, 365375.0 ], [ 2083625.0, 365125.0 ], [ 2083625.0, 364819.135262491530739 ], [ 2083512.470268202014267, 364737.52973179804394 ], [ 2083222.647259352728724, 364527.352740647213068 ], [ 2083125.0, 364625.0 ], [ 2083125.0, 364875.0 ], [ 2082875.0, 364875.0 ], [ 2082875.0, 365125.0 ], [ 2082875.0, 365375.0 ], [ 2082875.0, 365625.0 ], [ 2082625.0, 365625.0 ], [ 2082625.0, 365875.0 ], [ 2082625.0, 366125.0 ], [ 2082375.0, 366125.0 ], [ 2082375.0, 366375.0 ], [ 2082375.0, 366625.0 ], [ 2082375.0, 366875.0 ], [ 2082125.0, 366875.0 ], [ 2081875.0, 366875.0 ], [ 2081875.0, 367125.0 ], [ 2081875.0, 367375.0 ], [ 2081625.0, 367375.0 ], [ 2081625.0, 367625.0 ], [ 2081375.0, 367625.0 ], [ 2081125.0, 367625.0 ], [ 2081125.0, 367875.0 ], [ 2080875.0, 367875.0 ], [ 2080625.0, 367875.0 ], [ 2080625.0, 368125.0 ], [ 2080375.0, 368125.0 ], [ 2080125.0, 368125.0 ], [ 2079875.0, 368125.0 ], [ 2079625.0, 368125.0 ], [ 2079375.0, 368125.0 ], [ 2079125.0, 368125.0 ], [ 2078875.0, 368125.0 ], [ 2078625.0, 368125.0 ], [ 2078375.0, 368125.0 ], [ 2078125.0, 368125.0 ], [ 2078125.0, 367875.0 ], [ 2077875.0, 367875.0 ], [ 2077625.0, 367875.0 ], [ 2077375.0, 367875.0 ], [ 2077375.0, 367625.0 ], [ 2077125.0, 367625.0 ], [ 2076875.0, 367625.0 ], [ 2076625.0, 367625.0 ], [ 2076625.0, 367375.0 ], [ 2076375.0, 367375.0 ], [ 2076375.0, 367125.0 ], [ 2076125.0, 367125.0 ], [ 2076125.0, 366875.0 ], [ 2075875.0, 366875.0 ], [ 2075875.0, 366625.0 ], [ 2075625.0, 366625.0 ], [ 2075625.0, 366375.0 ], [ 2075375.0, 366375.0 ], [ 2075375.0, 366125.0 ], [ 2075125.0, 366125.0 ], [ 2075125.0, 365875.0 ], [ 2074875.0, 365875.0 ], [ 2074625.0, 365875.0 ], [ 2074625.0, 366125.0 ], [ 2074375.0, 366125.0 ], [ 2074375.0, 365875.0 ], [ 2074125.0, 365875.0 ], [ 2074125.0, 365625.0 ], [ 2073875.0, 365625.0 ], [ 2073875.0, 365375.0 ], [ 2073625.0, 365375.0 ], [ 2073625.0, 365125.0 ], [ 2073375.0, 365125.0 ], [ 2073375.0, 364875.0 ], [ 2073125.0, 364875.0 ], [ 2072875.0, 364875.0 ], [ 2072875.0, 364625.0 ], [ 2072625.0, 364625.0 ], [ 2072625.0, 364375.0 ], [ 2072625.0, 364125.0 ], [ 2072625.0, 363875.0 ], [ 2072375.0, 363875.0 ], [ 2072375.0, 363625.0 ], [ 2072375.0, 363375.0 ], [ 2072375.0, 363125.0 ], [ 2072125.0, 363125.0 ], [ 2071875.0, 363125.0 ], [ 2071875.0, 362875.0 ], [ 2071625.0, 362875.0 ], [ 2071625.0, 362625.0 ], [ 2071625.0, 362375.0 ], [ 2071375.0, 362375.0 ], [ 2071375.0, 362125.0 ], [ 2071125.0, 362125.0 ], [ 2071125.0, 361875.0 ], [ 2071125.0, 361625.0 ], [ 2070875.0, 361625.0 ], [ 2070875.0, 361375.0 ], [ 2070875.0, 361125.0 ], [ 2070875.0, 360875.0 ], [ 2070625.0, 360875.0 ], [ 2070625.0, 360625.0 ], [ 2070625.0, 360375.0 ], [ 2070625.0, 360125.0 ], [ 2070625.0, 359875.0 ], [ 2070375.0, 359875.0 ], [ 2070375.0, 360125.0 ], [ 2070125.0, 360125.0 ], [ 2069875.0, 360125.0 ], [ 2069625.0, 360125.0 ], [ 2069375.0, 360125.0 ], [ 2069125.0, 360125.0 ], [ 2068875.0, 360125.0 ], [ 2068625.0, 360125.0 ], [ 2068625.0, 360375.0 ], [ 2068375.0, 360375.0 ], [ 2068375.0, 360125.0 ], [ 2068125.0, 360125.0 ], [ 2067875.0, 360125.0 ], [ 2067625.0, 360125.0 ], [ 2067375.0, 360125.0 ], [ 2067375.0, 359875.0 ], [ 2067625.0, 359875.0 ], [ 2067625.0, 359625.0 ], [ 2067625.0, 359375.0 ], [ 2067375.0, 359375.0 ], [ 2067125.0, 359375.0 ], [ 2067125.0, 359125.0 ], [ 2066875.0, 359125.0 ], [ 2066875.0, 358875.0 ], [ 2066875.0, 358625.0 ], [ 2066625.0, 358625.0 ], [ 2066625.0, 358375.0 ], [ 2066625.0, 358125.0 ], [ 2066375.0, 358125.0 ], [ 2066125.0, 358125.0 ], [ 2066125.0, 357875.0 ], [ 2066125.0, 357625.0 ], [ 2065875.0, 357625.0 ], [ 2065875.0, 357375.0 ], [ 2065875.0, 357125.0 ], [ 2065875.0, 356875.0 ], [ 2065875.0, 356625.0 ], [ 2066125.0, 356625.0 ], [ 2066125.0, 356375.0 ], [ 2066125.0, 356125.0 ], [ 2065875.0, 356125.0 ], [ 2065875.0, 356375.0 ], [ 2065625.0, 356375.0 ], [ 2065625.0, 356625.0 ], [ 2065375.0, 356625.0 ], [ 2065125.0, 356625.0 ], [ 2065125.0, 356875.0 ], [ 2064875.0, 356875.0 ], [ 2064625.0, 356875.0 ], [ 2064375.0, 356875.0 ], [ 2064125.0, 356875.0 ], [ 2063875.0, 356875.0 ], [ 2063625.0, 356875.0 ], [ 2063375.0, 356875.0 ], [ 2063375.0, 357125.0 ], [ 2063125.0, 357125.0 ], [ 2062875.0, 357125.0 ], [ 2062625.0, 357125.0 ], [ 2062625.0, 357375.0 ], [ 2062375.0, 357375.0 ], [ 2062125.0, 357375.0 ], [ 2061875.0, 357375.0 ], [ 2061625.0, 357375.0 ], [ 2061375.0, 357375.0 ], [ 2061375.0, 357125.0 ], [ 2061125.0, 357125.0 ], [ 2061125.0, 356875.0 ], [ 2060875.0, 356875.0 ], [ 2060875.0, 356625.0 ], [ 2060625.0, 356625.0 ], [ 2060625.0, 356375.0 ], [ 2060625.0, 356125.0 ], [ 2060375.0, 356125.0 ], [ 2060375.0, 355875.0 ], [ 2060375.0, 355625.0 ], [ 2060125.0, 355625.0 ], [ 2059875.0, 355625.0 ], [ 2059875.0, 355375.0 ], [ 2059625.0, 355375.0 ], [ 2059375.0, 355375.0 ], [ 2059125.0, 355375.0 ], [ 2059125.0, 355125.0 ], [ 2058875.0, 355125.0 ], [ 2058625.0, 355125.0 ], [ 2058375.0, 355125.0 ], [ 2058125.0, 355125.0 ], [ 2058125.0, 354875.0 ], [ 2057875.0, 354875.0 ], [ 2057625.0, 354875.0 ], [ 2057375.0, 354875.0 ], [ 2057125.0, 354875.0 ], [ 2056875.0, 354875.0 ], [ 2056625.0, 354875.0 ], [ 2056375.0, 354875.0 ], [ 2056125.0, 354875.0 ], [ 2055875.0, 354875.0 ], [ 2055625.0, 354875.0 ], [ 2055625.0, 354625.0 ], [ 2055375.0, 354625.0 ], [ 2055125.0, 354625.0 ], [ 2054875.0, 354625.0 ], [ 2054875.0, 354875.0 ], [ 2054625.0, 354875.0 ], [ 2054375.0, 354875.0 ], [ 2054125.0, 354875.0 ], [ 2053875.0, 354875.0 ], [ 2053875.0, 355125.0 ], [ 2053625.0, 355125.0 ], [ 2053375.0, 355125.0 ], [ 2053125.0, 355125.0 ], [ 2052875.0, 355125.0 ], [ 2052875.0, 355487.659560176252853 ], [ 2052897.161504379939288, 355473.870179673016537 ], [ 2053125.0, 355467.06903055019211 ], [ 2053375.0, 355459.606343983206898 ], [ 2053524.165453359950334, 355455.153643883008044 ], [ 2053625.0, 355458.923159645171836 ], [ 2053875.0, 355468.268954037455842 ], [ 2054125.0, 355477.614748429739848 ], [ 2054375.0, 355486.960542822023854 ], [ 2054525.500118149910122, 355492.58671546302503 ], [ 2054625.0, 355499.996281132742297 ] ], [ [ 2056125.0, 355375.0 ], [ 2056125.0, 355125.0 ], [ 2056375.0, 355125.0 ], [ 2056375.0, 355375.0 ], [ 2056125.0, 355375.0 ] ], [ [ 2083875.0, 368625.0 ], [ 2083875.0, 368375.0 ], [ 2084125.0, 368375.0 ], [ 2084125.0, 368625.0 ], [ 2083875.0, 368625.0 ] ], [ [ 2076375.0, 367625.0 ], [ 2076375.0, 367875.0 ], [ 2076375.0, 368125.0 ], [ 2076125.0, 368125.0 ], [ 2076125.0, 367875.0 ], [ 2076125.0, 367625.0 ], [ 2076125.0, 367375.0 ], [ 2076375.0, 367375.0 ], [ 2076375.0, 367625.0 ] ], [ [ 2073875.0, 366125.0 ], [ 2074125.0, 366125.0 ], [ 2074125.0, 366375.0 ], [ 2074125.0, 366625.0 ], [ 2073875.0, 366625.0 ], [ 2073625.0, 366625.0 ], [ 2073625.0, 366375.0 ], [ 2073625.0, 366125.0 ], [ 2073875.0, 366125.0 ] ], [ [ 2071125.0, 364875.0 ], [ 2070875.0, 364875.0 ], [ 2070875.0, 364625.0 ], [ 2070875.0, 364375.0 ], [ 2070625.0, 364375.0 ], [ 2070375.0, 364375.0 ], [ 2070125.0, 364375.0 ], [ 2070125.0, 364125.0 ], [ 2069875.0, 364125.0 ], [ 2069625.0, 364125.0 ], [ 2069625.0, 363875.0 ], [ 2069375.0, 363875.0 ], [ 2069125.0, 363875.0 ], [ 2068875.0, 363875.0 ], [ 2068875.0, 363625.0 ], [ 2068625.0, 363625.0 ], [ 2068625.0, 363375.0 ], [ 2068875.0, 363375.0 ], [ 2069125.0, 363375.0 ], [ 2069375.0, 363375.0 ], [ 2069625.0, 363375.0 ], [ 2069625.0, 363625.0 ], [ 2069875.0, 363625.0 ], [ 2069875.0, 363875.0 ], [ 2070125.0, 363875.0 ], [ 2070125.0, 363625.0 ], [ 2070375.0, 363625.0 ], [ 2070375.0, 363875.0 ], [ 2070625.0, 363875.0 ], [ 2070625.0, 363625.0 ], [ 2070875.0, 363625.0 ], [ 2071125.0, 363625.0 ], [ 2071125.0, 363875.0 ], [ 2071375.0, 363875.0 ], [ 2071375.0, 363625.0 ], [ 2071375.0, 363375.0 ], [ 2071625.0, 363375.0 ], [ 2071625.0, 363625.0 ], [ 2071875.0, 363625.0 ], [ 2071875.0, 363875.0 ], [ 2071875.0, 364125.0 ], [ 2072125.0, 364125.0 ], [ 2072125.0, 364375.0 ], [ 2072125.0, 364625.0 ], [ 2072125.0, 364875.0 ], [ 2071875.0, 364875.0 ], [ 2071875.0, 364625.0 ], [ 2071625.0, 364625.0 ], [ 2071375.0, 364625.0 ], [ 2071125.0, 364625.0 ], [ 2071125.0, 364875.0 ] ], [ [ 2057375.0, 357625.0 ], [ 2057250.0, 357750.0 ], [ 2057125.0, 357625.0 ], [ 2057125.0, 357375.0 ], [ 2057375.0, 357375.0 ], [ 2057375.0, 357625.0 ] ], [ [ 2073625.0, 368125.0 ], [ 2073625.0, 368375.0 ], [ 2073375.0, 368375.0 ], [ 2073375.0, 368125.0 ], [ 2073125.0, 368125.0 ], [ 2073125.0, 367875.0 ], [ 2073125.0, 367625.0 ], [ 2073125.0, 367375.0 ], [ 2073375.0, 367375.0 ], [ 2073625.0, 367375.0 ], [ 2073875.0, 367375.0 ], [ 2073875.0, 367625.0 ], [ 2073625.0, 367625.0 ], [ 2073625.0, 367875.0 ], [ 2073625.0, 368125.0 ] ], [ [ 2059375.0, 355875.0 ], [ 2059375.0, 355625.0 ], [ 2059625.0, 355625.0 ], [ 2059625.0, 355875.0 ], [ 2059375.0, 355875.0 ] ], [ [ 2059375.0, 356625.0 ], [ 2059125.0, 356625.0 ], [ 2059125.0, 356375.0 ], [ 2059125.0, 356125.0 ], [ 2059375.0, 356125.0 ], [ 2059375.0, 356375.0 ], [ 2059375.0, 356625.0 ] ], [ [ 2059625.0, 356625.0 ], [ 2059625.0, 356875.0 ], [ 2059375.0, 356875.0 ], [ 2059375.0, 356625.0 ], [ 2059625.0, 356625.0 ] ], [ [ 2068125.0, 364125.0 ], [ 2068125.0, 364375.0 ], [ 2067875.0, 364375.0 ], [ 2067875.0, 364125.0 ], [ 2068125.0, 364125.0 ] ], [ [ 2068125.0, 363625.0 ], [ 2068125.0, 363875.0 ], [ 2067875.0, 363875.0 ], [ 2067875.0, 363625.0 ], [ 2068125.0, 363625.0 ] ], [ [ 2068375.0, 363375.0 ], [ 2068125.0, 363375.0 ], [ 2068125.0, 363125.0 ], [ 2068375.0, 363125.0 ], [ 2068375.0, 363375.0 ] ], [ [ 2068125.0, 362125.0 ], [ 2068375.0, 362125.0 ], [ 2068625.0, 362125.0 ], [ 2068875.0, 362125.0 ], [ 2069125.0, 362125.0 ], [ 2069125.0, 362375.0 ], [ 2068875.0, 362375.0 ], [ 2068625.0, 362375.0 ], [ 2068375.0, 362375.0 ], [ 2068125.0, 362375.0 ], [ 2068125.0, 362125.0 ] ], [ [ 2066125.0, 363875.0 ], [ 2065875.0, 363875.0 ], [ 2065875.0, 363625.0 ], [ 2066125.0, 363625.0 ], [ 2066125.0, 363875.0 ] ], [ [ 2066875.0, 364125.0 ], [ 2066625.0, 364125.0 ], [ 2066625.0, 363875.0 ], [ 2066875.0, 363875.0 ], [ 2066875.0, 364125.0 ] ], [ [ 2066375.0, 363375.0 ], [ 2066125.0, 363375.0 ], [ 2066125.0, 363125.0 ], [ 2066375.0, 363125.0 ], [ 2066625.0, 363125.0 ], [ 2066625.0, 363375.0 ], [ 2066375.0, 363375.0 ] ], [ [ 2067125.0, 363125.0 ], [ 2067375.0, 363125.0 ], [ 2067625.0, 363125.0 ], [ 2067875.0, 363125.0 ], [ 2067875.0, 363375.0 ], [ 2067625.0, 363375.0 ], [ 2067375.0, 363375.0 ], [ 2067125.0, 363375.0 ], [ 2067125.0, 363125.0 ] ], [ [ 2071125.0, 366375.0 ], [ 2070875.0, 366375.0 ], [ 2070875.0, 366125.0 ], [ 2071125.0, 366125.0 ], [ 2071125.0, 366375.0 ] ], [ [ 2071125.0, 365875.0 ], [ 2071375.0, 365875.0 ], [ 2071375.0, 366125.0 ], [ 2071125.0, 366125.0 ], [ 2071125.0, 365875.0 ] ], [ [ 2070875.0, 365375.0 ], [ 2070625.0, 365375.0 ], [ 2070625.0, 365125.0 ], [ 2070875.0, 365125.0 ], [ 2070875.0, 365375.0 ] ], [ [ 2070625.0, 362625.0 ], [ 2070875.0, 362625.0 ], [ 2070875.0, 362875.0 ], [ 2070625.0, 362875.0 ], [ 2070625.0, 363125.0 ], [ 2070625.0, 363375.0 ], [ 2070375.0, 363375.0 ], [ 2070375.0, 363125.0 ], [ 2070125.0, 363125.0 ], [ 2070125.0, 362875.0 ], [ 2070375.0, 362875.0 ], [ 2070375.0, 362625.0 ], [ 2070375.0, 362375.0 ], [ 2070625.0, 362375.0 ], [ 2070625.0, 362625.0 ] ], [ [ 2069625.0, 361375.0 ], [ 2069875.0, 361375.0 ], [ 2070125.0, 361375.0 ], [ 2070125.0, 361625.0 ], [ 2070125.0, 361875.0 ], [ 2069875.0, 361875.0 ], [ 2069875.0, 362125.0 ], [ 2069625.0, 362125.0 ], [ 2069625.0, 361875.0 ], [ 2069375.0, 361875.0 ], [ 2069375.0, 361625.0 ], [ 2069375.0, 361375.0 ], [ 2069625.0, 361375.0 ] ], [ [ 2069125.0, 364375.0 ], [ 2069375.0, 364375.0 ], [ 2069375.0, 364625.0 ], [ 2069375.0, 364875.0 ], [ 2069125.0, 364875.0 ], [ 2069125.0, 364625.0 ], [ 2068875.0, 364625.0 ], [ 2068875.0, 364875.0 ], [ 2068625.0, 364875.0 ], [ 2068625.0, 364625.0 ], [ 2068625.0, 364375.0 ], [ 2068875.0, 364375.0 ], [ 2069125.0, 364375.0 ] ], [ [ 2071625.0, 366625.0 ], [ 2071625.0, 366875.0 ], [ 2071375.0, 366875.0 ], [ 2071375.0, 366625.0 ], [ 2071625.0, 366625.0 ] ], [ [ 2072125.0, 365875.0 ], [ 2072125.0, 365625.0 ], [ 2072375.0, 365625.0 ], [ 2072375.0, 365875.0 ], [ 2072125.0, 365875.0 ] ], [ [ 2075375.0, 367625.0 ], [ 2075375.0, 367375.0 ], [ 2075625.0, 367375.0 ], [ 2075625.0, 367625.0 ], [ 2075375.0, 367625.0 ] ], [ [ 2075125.0, 367375.0 ], [ 2075125.0, 367125.0 ], [ 2074875.0, 367125.0 ], [ 2074875.0, 366875.0 ], [ 2075125.0, 366875.0 ], [ 2075375.0, 366875.0 ], [ 2075625.0, 366875.0 ], [ 2075625.0, 367125.0 ], [ 2075375.0, 367125.0 ], [ 2075375.0, 367375.0 ], [ 2075125.0, 367375.0 ] ], [ [ 2075875.0, 367625.0 ], [ 2075875.0, 367875.0 ], [ 2075625.0, 367875.0 ], [ 2075625.0, 367625.0 ], [ 2075875.0, 367625.0 ] ], [ [ 2074125.0, 368375.0 ], [ 2074125.0, 368125.0 ], [ 2074375.0, 368125.0 ], [ 2074375.0, 368375.0 ], [ 2074125.0, 368375.0 ] ], [ [ 2076875.0, 368625.0 ], [ 2076875.0, 368375.0 ], [ 2077125.0, 368375.0 ], [ 2077125.0, 368625.0 ], [ 2076875.0, 368625.0 ] ], [ [ 2076375.0, 369375.0 ], [ 2076375.0, 369125.0 ], [ 2076375.0, 368875.0 ], [ 2076625.0, 368875.0 ], [ 2076625.0, 369125.0 ], [ 2076625.0, 369375.0 ], [ 2076375.0, 369375.0 ] ], [ [ 2079125.0, 368625.0 ], [ 2079125.0, 368875.0 ], [ 2078875.0, 368875.0 ], [ 2078875.0, 368625.0 ], [ 2078875.0, 368375.0 ], [ 2079125.0, 368375.0 ], [ 2079125.0, 368625.0 ] ], [ [ 2083625.0, 368875.0 ], [ 2083375.0, 368875.0 ], [ 2083125.0, 368875.0 ], [ 2083125.0, 369125.0 ], [ 2083125.0, 369375.0 ], [ 2082875.0, 369375.0 ], [ 2082875.0, 369125.0 ], [ 2082625.0, 369125.0 ], [ 2082625.0, 368875.0 ], [ 2082625.0, 368625.0 ], [ 2082375.0, 368625.0 ], [ 2082125.0, 368625.0 ], [ 2082125.0, 368375.0 ], [ 2082125.0, 368125.0 ], [ 2082125.0, 367875.0 ], [ 2082375.0, 367875.0 ], [ 2082375.0, 368125.0 ], [ 2082625.0, 368125.0 ], [ 2082625.0, 367875.0 ], [ 2082875.0, 367875.0 ], [ 2083125.0, 367875.0 ], [ 2083125.0, 368125.0 ], [ 2083125.0, 368375.0 ], [ 2083125.0, 368625.0 ], [ 2083375.0, 368625.0 ], [ 2083625.0, 368625.0 ], [ 2083625.0, 368875.0 ] ], [ [ 2082625.0, 366625.0 ], [ 2082875.0, 366625.0 ], [ 2082875.0, 366875.0 ], [ 2082625.0, 366875.0 ], [ 2082625.0, 366625.0 ] ], [ [ 2081125.0, 369625.0 ], [ 2081125.0, 369875.0 ], [ 2080875.0, 369875.0 ], [ 2080875.0, 369625.0 ], [ 2080875.0, 369375.0 ], [ 2081125.0, 369375.0 ], [ 2081125.0, 369625.0 ] ] ] ] } }
]
}

==================================================

File: C:\GH\ras-commander\examples\README.md
==================================================
# RAS Commander Examples

This directory contains example notebooks demonstrating how to use the `ras-commander` library for automating HEC-RAS operations. These examples cover basic to advanced usage scenarios and provide a practical guide for hydraulic modelers looking to automate their workflows.

## Overview

HEC-RAS (Hydrologic Engineering Center's River Analysis System) is widely used for hydraulic modeling. The `ras-commander` library provides a Python interface to automate HEC-RAS operations without using the graphical user interface. This enables batch processing, sensitivity analysis, and integration with other Python tools for water resources engineering.

These example notebooks are designed to:
- Demonstrate key functionalities of the `ras-commander` library
- Provide practical use cases for automation
- Guide users from basic to advanced operations
- Serve as templates for your own automation scripts

## Examples

### [00_Using_RasExamples.ipynb](00_Using_RasExamples.ipynb)

This notebook introduces the `RasExamples` class, which provides easy access to HEC-RAS example projects for testing and demonstration purposes.

**Key contents:**
- Installing `ras-commander` from pip
- Using flexible imports for development without installation
- Extracting specific HEC-RAS example projects by folder name
- Advanced usage options for managing example projects
- Listing available example projects and categories
- Working with the new pipes and conduits examples (version 6.6)

### [01_project_initialization.ipynb](01_project_initialization.ipynb)

This notebook covers initializing and working with HEC-RAS projects using the `ras-commander` library.

**Key contents:**
- Setting up and configuring the RAS Commander environment
- Downloading and extracting example HEC-RAS projects
- Initializing HEC-RAS projects using the global `ras` object
- Initializing multiple HEC-RAS projects using custom RAS objects
- Accessing various project components (plans, geometries, flows, boundaries)
- Understanding the RAS object structure and its components
- Working with boundary conditions
- Comparing multiple projects

### [02_plan_and_geometry_operations.ipynb](02_plan_and_geometry_operations.ipynb)

This notebook demonstrates operations on HEC-RAS plan and geometry files using the RAS Commander library.

**Key contents:**
- Project initialization and understanding plan/geometry files
- Cloning plans to create new simulation scenarios
- Cloning geometry files for modified versions
- Setting geometry files for plans
- Clearing geometry preprocessor files
- Configuring simulation parameters and intervals
- Setting run flags and updating descriptions
- Cloning and configuring unsteady flow files
- Computing plans and verifying results
- Working with advanced HDF data
- Best practices for plan and geometry operations

### [03_unsteady_flow_operations.ipynb](03_unsteady_flow_operations.ipynb)

This notebook demonstrates operations on unsteady flow files using the RAS Commander library.

**Key contents:**
- Understanding unsteady flow files in HEC-RAS
- Extracting boundary conditions and tables from unsteady flow files
- Inspecting and analyzing boundary condition structures
- Working with different boundary condition types (flow hydrographs, stage hydrographs, etc.)
- Modifying flow titles in unsteady flow files
- Configuring restart settings for continuing simulations
- Extracting and working with flow tables
- Modifying flow tables and writing them back to files
- Applying updated unsteady flow to a plan and computing results

### [04_multiple_project_operations.ipynb](04_multiple_project_operations.ipynb)

This notebook demonstrates how to work with multiple HEC-RAS projects simultaneously using the RAS Commander library.

**Key contents:**
- Initializing and managing multiple HEC-RAS projects
- Cloning and modifying plans across different projects
- Running computations for multiple projects in parallel
- Optimizing computing resources when working with multiple models
- Analyzing and comparing results from different projects
- Building comprehensive multi-project workflows
- Best practices for multiple project management
- Setting up compute folders for multiple projects
- Comparing project structures and results

### [05_single_plan_execution.ipynb](05_single_plan_execution.ipynb)

This notebook focuses specifically on executing a single HEC-RAS plan with various configuration options.

**Key contents:**
- Understanding the `RasCmdr.compute_plan` method and its parameters
- Executing a plan with a specified number of processor cores
- Creating and managing destination folders for computations
- Overwriting existing destination folders
- Verifying computation results
- Options for single plan execution (basic execution, destination folder, number of cores, etc.)
- Best practices for single plan execution

### [06_executing_plan_sets.ipynb](06_executing_plan_sets.ipynb)

This notebook demonstrates different ways to specify and execute HEC-RAS plans using the RAS Commander library.

**Key contents:**
- Understanding plan specification in HEC-RAS
- Sequential execution of specific plans
- Selective plan execution based on criteria
- Running only plans without HDF results
- Verifying execution results
- Best practices for plan specification
- Choosing appropriate execution methods based on scenario
- Understanding the importance of plan selection for efficiency

### [07_sequential_plan_execution.ipynb](07_sequential_plan_execution.ipynb)

This notebook demonstrates how to sequentially execute multiple HEC-RAS plans using the RAS Commander library.

**Key contents:**
- Understanding sequential execution in HEC-RAS
- Using the `RasCmdr.compute_test_mode` method
- Executing all plans in a project sequentially
- Analyzing the test folder after sequential execution
- Executing specific plans with geometry preprocessor clearing
- Best practices for sequential execution
- Environment setup and test folder management
- Benefits of sequential execution (controlled resource usage, dependency management, etc.)

### [08_parallel_execution.ipynb](08_parallel_execution.ipynb)

This notebook demonstrates how to execute multiple HEC-RAS plans in parallel to maximize computational efficiency.

**Key contents:**
- Understanding parallel execution in HEC-RAS
- Setting up a working environment for parallel execution
- Checking system resources for optimal parallel execution
- Executing all plans in a project in parallel
- Executing specific plans in parallel
- Dynamic worker allocation based on available resources
- Balancing workers and cores per worker
- Analyzing parallel execution results
- Performance comparison between different parallel configurations
- Best practices for parallel execution

### [09_plan_parameter_operations.ipynb](09_plan_parameter_operations.ipynb)

This notebook demonstrates how to perform key operations on HEC-RAS plan files, focusing on modifying simulation parameters.

**Key contents:**
- Understanding plan files in HEC-RAS
- Retrieving specific values from plan files
- Updating run flags to control which components will run
- Modifying computation and output time intervals
- Reading and updating plan descriptions
- Changing simulation start and end dates
- Verifying updated plan values
- Best practices for plan operations
- Automating parameter adjustments for sensitivity analysis
- Managing documentation through plan descriptions

### [10_1d_hdf_data_extraction.ipynb](10_1d_hdf_data_extraction.ipynb)

This notebook demonstrates how to extract and analyze 1D data from HEC-RAS HDF files using the RAS Commander library.

**Key contents:**
- Accessing and extracting base geometry attributes from HDF files
- Working with 1D cross-section data, including station-elevation profiles
- Visualizing cross-section properties like Manning's n values
- Extracting river centerlines, bank lines, and edge lines
- Analyzing runtime data and compute messages
- Processing and visualizing ineffective flow areas
- Extracting time series data for 1D cross sections
- Plotting cross-section elevation profiles with bank stations

### [11_2d_hdf_data_extraction.ipynb](11_2d_hdf_data_extraction.ipynb)

This notebook shows how to extract and analyze 2D data from HEC-RAS HDF files using the RAS Commander library.

**Key contents:**
- Working with 2D flow area attributes and perimeter polygons
- Extracting and visualizing mesh cell faces, polygons, and points
- Finding nearest faces and cells to specific points
- Extracting boundary condition lines and breaklines
- Analyzing maximum water surface elevations and timing
- Working with maximum face velocities and water surface errors
- Visualizing 2D model results with terrain data
- Extracting and interpreting cell and face time series data

### [12_2d_hdf_data_extraction_pipes_and_pumps.ipynb](12_2d_hdf_data_extraction_pipes_and_pumps.ipynb)

This notebook focuses on extracting and analyzing data related to pipes, conduits, and pump stations from HEC-RAS HDF files.

**Key contents:**
- Working with pipe conduits and associated geometries
- Extracting pipe node information and properties
- Analyzing pipe network connectivity and structures
- Visualizing pipe networks with node elevations
- Working with pump stations and pump groups
- Extracting pipe and node time series data
- Analyzing face flow, velocity, and water surface values
- Processing and visualizing pump station operation data

### [13_2d_detail_face_data_extraction.ipynb](13_2d_detail_face_data_extraction.ipynb)

This notebook demonstrates techniques for detailed face data extraction from 2D HEC-RAS models.

**Key contents:**
- Extracting and analyzing detailed face property tables
- Working with profile lines to identify cell faces
- Finding faces perpendicular to flow for discharge calculations
- Converting face velocities and flows to positive values
- Calculating discharge-weighted velocities for profile lines
- Comparing discharge-weighted and simple average velocities
- Visualizing time series data for selected faces
- Creating profile-specific result datasets for analysis

### [14_fluvial_pluvial_delineation.ipynb](14_fluvial_pluvial_delineation.ipynb)

This notebook demonstrates how to delineate fluvial and pluvial flooding areas based on the timing of maximum water surface elevations.

**Key contents:**
- Extracting maximum water surface elevation and timing data
- Identifying adjacent cells with dissimilar flood timing
- Calculating boundaries between fluvial and pluvial flooding
- Filtering boundaries based on length thresholds
- Visualizing the fluvial-pluvial boundary on a map
- Exporting boundaries to GeoJSON format
- Understanding the difference between river-driven and rainfall-driven flooding
- Using cell polygon geometry for spatial analysis

### [15_mannings_sensitivity_bulk_analysis.ipynb](15_mannings_sensitivity_bulk_analysis.ipynb)

This notebook provides tools for analyzing the sensitivity of HEC-RAS models to changes in Manning's n values applied *in bulk* across land cover types based on literature ranges.

**Key contents:**
- Defining Manning's n ranges (min/max) for various land cover types.
- Automating the creation of scenarios (min, max, current n values).
- Applying bulk changes to base and/or regional Manning's overrides.
- Running sensitivity scenarios in parallel.
- Extracting results at a point of interest.
- Comparing and visualizing the impact of bulk Manning's n changes on water surface elevation.

### [16_mannings_sensitivity_multi-interval.ipynb](16_mannings_sensitivity_multi-interval.ipynb)

This notebook performs a more detailed Manning's n sensitivity analysis by varying the roughness coefficient for *individual significant land uses* across a range of values.

**Key contents:**
- Analyzing land cover statistics within 2D mesh areas.
- Identifying significant land cover types based on area threshold.
- Generating multiple test plans by varying the n value for one land cover type at a time, across its literature-based range (min to max).
- Applying changes individually to base or regional overrides.
- Running sensitivity scenarios in parallel.
- Extracting and visualizing results to show sensitivity to specific land cover roughness.
- Estimating the number of plans to be generated and managing potential HEC-RAS limits.

### [101_Core_Sensitivity.ipynb](101_Core_Sensitivity.ipynb)

This notebook tests HEC-RAS performance with different CPU core configurations to optimize computational efficiency.

**Key contents:**
- Setting up a controlled testing environment
- Running the same plan with varying core counts
- Measuring execution time for each configuration
- Analyzing performance scaling with increased cores
- Creating visualization of performance metrics
- Calculating unit runtime based on single-core performance
- Understanding diminishing returns with multiple cores
- Identifying optimal core count for specific models

### [102_benchmarking_versions_6.1_to_6.6.ipynb](102_benchmarking_versions_6.1_to_6.6.ipynb)

This notebook compares performance across different versions of HEC-RAS by running the same plan across multiple software versions.

**Key contents:**
- Running the same model across multiple HEC-RAS versions
- Measuring preprocessing, computation, and postprocessing times
- Analyzing volume error changes between versions
- Creating visualizations of performance trends
- Identifying performance improvements between versions
- Understanding version-specific computational differences
- Setting up flexible testing environments for multiple versions
- Interpreting HEC-RAS version performance evolution

### [103_Generating_AEP_Events_from_Atlas_14.ipynb](103_Generating_AEP_Events_from_Atlas_14.ipynb)

This notebook demonstrates an end-to-end workflow for generating and analyzing multiple Annual Exceedance Probability events.

**Key contents:**
- Generating hyetographs from NOAA Atlas 14 precipitation frequency data
- Parsing duration strings and interpolating precipitation depths
- Applying the Alternating Block Method for hyetograph creation
- Cloning and configuring HEC-RAS plans for different AEP events
- Executing multiple plans in parallel with resource optimization
- Extracting and visualizing results for multiple AEP scenarios
- Creating a complete workflow from data to flood analysis
- Comparing results across different return period events

### [17_extracting_profiles_with_hecrascontroller and RasControl.ipynb](17_extracting_profiles_with_hecrascontroller%20and%20RasControl.ipynb)

This notebook demonstrates the **RasControl** class for working with legacy HEC-RAS versions (3.x-4.x) using the HECRASController COM interface.

**Key contents:**
- Introduction to RasControl wrapper for HECRASController
- Using ras-commander style API with plan numbers instead of file paths
- Running steady state plans and extracting profile results
- Running unsteady plans and extracting time series results
- Understanding output times and the "Max WS" special timestep
- Extracting and plotting steady state profiles across multiple profiles
- Visualizing unsteady time series at cross sections
- Supported versions: 3.1, 4.1, 5.0.x (501-507), 6.0, 6.3, 6.6
- Multi-version comparison for migration validation
- Integration with `init_ras_project()` and the global `ras` object
- Open-operate-close pattern to prevent conflicts with modern workflows


## Contributing

If you have suggestions for additional examples or improvements to existing ones, please feel free to contribute by submitting pull requests or opening issues in the repository.
==================================================

File: C:\GH\ras-commander\examples\RemoteWorkers.json
==================================================
{
  "workers": [

    {
      "name": "CLB-04",
      "worker_type": "psexec",
      "hostname": "192.168.3.8",
      "share_path": "\\\\192.168.3.8\\RasRemote",
      "worker_folder": "C:\\RasRemote",
      "username": ".\\bill",
      "password": "Katzen84!!",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 1,
      "cores_total": 4,
      "cores_per_plan": 2,
      "enabled": true
    },
    {
      "name": "Local Compute",
      "worker_type": "local",
      "worker_folder": "C:\\RasRemote",
      "process_priority": "low",
      "queue_priority": 0,
      "cores_total": 4,
      "cores_per_plan": 2,
      "enabled": true
    },
    {
      "name": "CLB-05",
      "worker_type": "psexec",
      "hostname": "192.168.3.24",
      "share_path": "\\\\192.168.3.24\\RasRemote",
      "worker_folder": "C:\\RasRemote",
      "username": ".\\bill",
      "password": "Katzen84!!",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 1,
      "cores_total": 4,
      "cores_per_plan": 2,
      "enabled": true
    },
    {
      "name": "CLB-03-VM1",
      "worker_type": "psexec",
      "hostname": "192.168.3.21",
      "share_path": "\\\\192.168.3.21\\RasRemote",
      "worker_folder": "C:\\RasRemote",
      "username": ".\\bill",
      "password": "CLBBill11!!",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 2,
      "cores_total": 2,
      "cores_per_plan": 2,
      "enabled": true
    }
  ]
}

==================================================

File: C:\GH\ras-commander\examples\RemoteWorkers.json.template
==================================================
{
  "workers": [
    {
      "name": "Local Compute",
      "hostname": "localhost",
      "share_path": "C:\\Temp\\RasRemote",
      "username": "local_user",
      "password": "local_password",
      "ras_exe_path": "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 0,
      "cores_total": 4,
      "cores_per_plan": 2,
      "enabled": true
    },
    {
      "name": "Primary Workstation",
      "hostname": "192.168.1.100",
      "share_path": "\\\\192.168.1.100\\RasRemote",
      "username": "your_username",
      "password": "your_password",
      "ras_exe_path": "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 1,
      "cores_total": 16,
      "cores_per_plan": 4,
      "enabled": true
    },
    {
      "name": "Secondary Workstation",
      "hostname": "192.168.1.101",
      "share_path": "\\\\192.168.1.101\\RasRemote",
      "username": "your_username",
      "password": "your_password",
      "ras_exe_path": "C:\\Program Files\\HEC\\HEC-RAS\\6.3\\RAS.exe",
      "session_id": 2,
      "process_priority": "low",
      "queue_priority": 1,
      "cores_total": 8,
      "cores_per_plan": 4,
      "enabled": false
    }
  ]
}

==================================================

File: C:\GH\ras-commander\examples\REMOTE_WORKERS_README.md
==================================================
# RemoteWorkers.json Configuration Guide

**Purpose:** Secure credential storage for remote HEC-RAS execution workers

**Security:** This file is in `.gitignore` and will NOT be committed to the repository.

---

## Quick Setup

### 1. Copy the template:
```bash
copy RemoteWorkers.json.template RemoteWorkers.json
```

### 2. Edit `RemoteWorkers.json` with your worker details

### 3. Run the notebook - credentials load automatically!

---

## JSON File Format

```json
{
  "workers": [
    {
      "name": "Descriptive Name",
      "hostname": "IP_or_hostname",
      "share_path": "\\\\hostname\\ShareName",
      "username": "your_username",
      "password": "your_password",
      "ras_exe_path": "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe",
      "session_id": 2,
      "priority": "low",
      "enabled": true
    }
  ]
}
```

---

## Field Descriptions

| Field | Description | Example | Required |
|-------|-------------|---------|----------|
| `name` | Friendly name for the worker | `"Office Workstation"` | Yes |
| `hostname` | IP address or machine name | `"192.168.1.100"` or `"WORKSTATION-01"` | Yes |
| `share_path` | UNC path to network share | `"\\\\192.168.1.100\\RasRemote"` | Yes |
| `username` | Windows username | `"bill"` or `"DOMAIN\\user"` | Yes |
| `password` | Windows password | `"SecurePass123"` | Yes |
| `ras_exe_path` | Full path to RAS.exe on remote machine | `"C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe"` | Yes |
| `session_id` | User session ID (use `query user` to find) | `2` | Yes |
| `priority` | Process priority | `"low"`, `"below normal"`, or `"normal"` | No (default: `"low"`) |
| `enabled` | Whether to use this worker | `true` or `false` | No (default: `true`) |

---

## Finding Session ID

**On the remote machine**, run:
```cmd
query user
```

Output example:
```
USERNAME    SESSIONNAME    ID  STATE
bill        console         2  Active
```

Use the **ID** value (2 in this example) for `session_id`.

**Typical values:**
- Session 2: Most common for single-user workstations
- Session 1: Older Windows or first console session
- Session 3+: Additional RDP sessions

---

## Multiple Workers Example

```json
{
  "workers": [
    {
      "name": "Office PC 1",
      "hostname": "192.168.1.10",
      "share_path": "\\\\192.168.1.10\\RasRemote",
      "username": "bill",
      "password": "pass1",
      "ras_exe_path": "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe",
      "session_id": 2,
      "enabled": true
    },
    {
      "name": "Office PC 2",
      "hostname": "192.168.1.11",
      "share_path": "\\\\192.168.1.11\\RasRemote",
      "username": "user2",
      "password": "pass2",
      "ras_exe_path": "C:\\Program Files\\HEC\\HEC-RAS\\6.3\\RAS.exe",
      "session_id": 2,
      "enabled": true
    },
    {
      "name": "Backup PC (disabled)",
      "hostname": "192.168.1.12",
      "share_path": "\\\\192.168.1.12\\RasRemote",
      "username": "user3",
      "password": "pass3",
      "ras_exe_path": "C:\\Program Files\\HEC\\HEC-RAS\\6.6\\RAS.exe",
      "session_id": 2,
      "enabled": false
    }
  ]
}
```

The notebook will use all workers where `enabled: true`.

---

## Security Best Practices

### ✅ DO:
- Keep `RemoteWorkers.json` local only (it's in `.gitignore`)
- Use strong passwords
- Rotate passwords regularly
- Limit file permissions (Windows: Right-click → Properties → Security)
- Use VPN when accessing remote office networks

### ❌ DON'T:
- Don't commit `RemoteWorkers.json` to git
- Don't share the file publicly
- Don't use weak passwords
- Don't email the file (credentials in plain text)
- Don't store in cloud storage (Dropbox, OneDrive, etc.)

---

## Path Format Notes

### Windows Paths - Use Double Backslashes:
```json
"share_path": "\\\\192.168.1.100\\RasRemote",
"ras_exe_path": "C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\RAS.exe"
```

**Why double backslashes?**
- JSON requires escaping backslashes
- `\\` in JSON becomes `\` in Python
- `\\\\hostname` in JSON becomes `\\hostname` (UNC path) in Python

---

## Troubleshooting

### "RemoteWorkers.json not found"
**Solution:** Copy the template:
```cmd
copy RemoteWorkers.json.template RemoteWorkers.json
```

### JSON Syntax Errors
**Common issues:**
- Missing commas between objects
- Trailing comma after last object
- Unescaped backslashes (use `\\` not `\`)
- Smart quotes instead of straight quotes

**Validate JSON:** Use https://jsonlint.com/ or VS Code's JSON validator

### Wrong Session ID
**Symptoms:** PsExec hangs or timeout

**Solution:**
1. On remote machine: `query user`
2. Find the ID column value
3. Update `session_id` in JSON
4. Restart notebook kernel and reload

---

## Example: Converting from Hardcoded to JSON

**Old notebook code (hardcoded):**
```python
REMOTE_CONFIG = {
    "hostname": "192.168.3.8",
    "password": "your_password_here",  # Credentials in notebook!
    # ...
}
```

**New notebook code (JSON):**
```python
import json
with open("RemoteWorkers.json") as f:
    worker_configs = json.load(f)
REMOTE_CONFIG = worker_configs["workers"][0]
# Credentials loaded securely from external file
```

---

## Advanced: Environment Variables

For even more security, use environment variables:

**Set environment variable (PowerShell):**
```powershell
$env:RAS_REMOTE_PASSWORD="YourPassword"
```

**Load in notebook:**
```python
import os
REMOTE_CONFIG["password"] = os.environ.get("RAS_REMOTE_PASSWORD", "")
```

---

## Worker Management

### Temporarily Disable a Worker:
```json
{
  "name": "Slow PC",
  "enabled": false,  # Set to false to skip
  // ...
}
```

### Add New Worker:
Add a new object to the `workers` array with all required fields.

### Remove Worker:
Delete the object from the `workers` array or set `enabled: false`.

---

## File Location

**Where to put RemoteWorkers.json:**
- Same directory as the notebook (`examples/`)
- The notebook looks for it in the current working directory
- Use absolute path if needed: `Path("/path/to/RemoteWorkers.json")`

---

**Template file:** `RemoteWorkers.json.template` (safe to commit)
**Your file:** `RemoteWorkers.json` (in .gitignore, never committed)

**Status:** ✅ Secure credential management implemented!

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_100_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.09040491041908805
2,0.0955077907605224
3,0.10146987810261088
4,0.10855497206608167
5,0.1171543680932885
6,0.1278780203205363
7,0.146970561522203
8,0.16593941033554094
9,0.1936155742022425
10,0.2697157353332229
11,0.3599999999999999
12,1.2
13,0.47
14,0.306960245354186
15,0.2433240193125914
16,0.17831774068604123
17,0.15566677680236962
18,0.13948993645160312
19,0.1221999761240089
20,0.11263390133511564
21,0.10485136436093967
22,0.09836722663443354
23,0.09286196347106301
24,0.08811562831231079

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_10_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.06039156315395777
2,0.06375521611108814
3,0.06768230354162785
4,0.07234523361103751
5,0.07799952445440228
6,0.0850430998832925
7,0.09928617513316373
8,0.11172527137238264
9,0.1298047855496105
10,0.18441307951840247
11,0.24
12,0.714
13,0.32600000000000007
14,0.20806923839369285
15,0.16751768208790474
16,0.11982101594250372
17,0.10499403807898
18,0.09436871392335933
19,0.08131460382996858
20,0.07502791218397897
21,0.06990827571771163
22,0.06563904234299356
23,0.06201147001043372
24,0.05888175515950733

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_25_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.07260426998002334
2,0.07665162231333023
3,0.08137715944970658
4,0.0869884475092384
5,0.09379312728081013
6,0.10227032363387689
7,0.1187727466883497
8,0.13373867053642075
9,0.1555066993867329
10,0.21723588907914926
11,0.29000000000000004
12,0.886
13,0.384
14,0.24600987393864338
15,0.1967542369822075
16,0.14348388189104222
17,0.1256388908154591
18,0.11285911068199495
19,0.09778286786544221
20,0.09021687457399974
21,0.08405581609065793
22,0.07891843577904822
23,0.07455341770829094
24,0.07078763781557518

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_2_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.039444248438275764
2,0.04167741641696132
3,0.04428704307942355
4,0.04738880027716674
5,0.05115429786673542
6,0.055851100908542506
7,0.06613796588496257
8,0.07448873415720048
9,0.08663816527821133
10,0.1248195283605078
11,0.16500000000000004
12,0.474
13,0.22199999999999998
14,0.140734851235629
15,0.11344562040386319
16,0.07992740765575301
17,0.06996893628396816
18,0.0628387907399044
19,0.053364049126953805
20,0.04917477333825038
21,0.04576733441289149
22,0.042928943389559215
23,0.0405194807297482
24,0.03844251201549165

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_50_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.08192031837455449
2,0.08649776823482647
3,0.09184292815034834
4,0.09819090381104534
5,0.10589020511972391
6,0.11548369828277005
7,0.13208308858222972
8,0.14899627794001002
9,0.17364775403361454
10,0.24348456417803233
11,0.32000000000000006
12,1.03
13,0.43999999999999995
14,0.27642512827887034
15,0.2200903075430971
16,0.1600253022656406
17,0.13983878833910923
18,0.12540878883939577
19,0.11040508620362299
20,0.10184361090041572
21,0.09487313550894516
22,0.08906171957461506
23,0.08412468238815496
24,0.07986594345097853

==================================================

File: C:\GH\ras-commander\examples\hyetographs\hyetograph_ARI_5_years_pos50pct_24hr.csv
==================================================
Time_hour,Precipitation_in
1,0.05100624290168243
2,0.053861614565144045
3,0.0571962224527196
4,0.06115689800693991
5,0.06596132300525692
6,0.07194862056091855
7,0.08420784635189071
8,0.09480066356128192
9,0.11020467787180732
10,0.15808375054017998
11,0.21000000000000008
12,0.601
13,0.279
14,0.1782322703437993
15,0.1436839791160207
16,0.10169725937061136
17,0.08906792110929018
18,0.08002163173511834
19,0.06877894224371994
20,0.06343613417866356
21,0.05908679180980725
22,0.05546110471921306
23,0.052381270043452055
24,0.049724835512482635

==================================================

