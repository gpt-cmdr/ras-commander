File: c:\GH\ras-commander\ras_commander\RasCmdr.py
==================================================
"""
Execution operations for running HEC-RAS simulations using subprocess.
Based on the HEC-Commander project's "Command Line is All You Need" approach, leveraging the -c compute flag to run HEC-RAS and orchestrating changes directly in the RAS input files to achieve automation outcomes. 
"""

import os
import subprocess
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from .RasPrj import ras, RasPrj, init_ras_project, get_ras_exe
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUtils import RasUtils
import logging
import time
import queue
from threading import Thread, Lock
from typing import Union, List, Optional, Dict
from pathlib import Path
import shutil
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Thread
from itertools import cycle
from ras_commander.RasPrj import RasPrj  # Ensure RasPrj is imported
from threading import Lock, Thread, current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import cycle
from typing import Union, List, Optional, Dict


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# TO DO: 
# 1. Alternate Run Mode for compute_plan and compute_parallel:  Using Powershell to execute the HEC-RAS command and hide the RAS window and all child windows.
#    If this is implemented, and the plan has a popup, then the plan will not execute.  This is a deal breaker for many scenarios, and should only be used
#    as a special option for those who don't want to deal with the popups, or want to run in the background.  This option should be limited to non-commercial use.
# 2. Implment compute_plan_remote to go along with compute_plan.  This will be a compute_plan that is run on a remote machine via a psexec command.
#    First, we will use the keyring package to securely store the remote machine username and password.
#    Second, we will implement the psexec command to execute the HEC-RAS command on the remote machine.
#    Each machine will need to be initialized as a remote_worker object, which will store the machine name, username, password, ras_exe_path, local folder path and other relevant info.
#    A separate RasRemote class will be created to handle the creation of the remote_worker objects and the necessary abstractions. 
#    The compute_plan_remote function will live in RasCmdr, and will be a thin abstraction above the RasRemote class, since the functions will be simliar to the existing compute_plan functions, but specific to remote execution.  


class RasCmdr:
    @staticmethod
    def compute_plan(
        plan_number,
        dest_folder=None, 
        ras_object=None,
        clear_geompre=False,
        num_cores=None,
        overwrite_dest=False
    ):
        """
        Execute a HEC-RAS plan.

        Args:
            plan_number (str, Path): The plan number to execute (e.g., "01", "02") or the full path to the plan file.
            dest_folder (str, Path, optional): Name of the folder or full path for computation.
                If a string is provided, it will be created in the same parent directory as the project folder.
                If a full path is provided, it will be used as is.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files. Defaults to False.
            num_cores (int, optional): Number of cores to use for the plan execution. If None, the current setting is not changed.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            bool: True if the execution was successful, False otherwise.

        Raises:
            ValueError: If the specified dest_folder already exists and is not empty, and overwrite_dest is False.
        """
        ras_obj = ras_object if ras_object is not None else ras
        logging.info(f"Using ras_object with project folder: {ras_obj.project_folder}")
        ras_obj.check_initialized()
        
        if dest_folder is not None:
            dest_folder = Path(ras_obj.project_folder).parent / dest_folder if isinstance(dest_folder, str) else Path(dest_folder)
            
            if dest_folder.exists():
                if overwrite_dest:
                    shutil.rmtree(dest_folder)
                    logging.info(f"Destination folder '{dest_folder}' exists. Overwriting as per overwrite_dest=True.")
                elif any(dest_folder.iterdir()):
                    error_msg = f"Destination folder '{dest_folder}' exists and is not empty. Use overwrite_dest=True to overwrite."
                    logging.error(error_msg)
                    raise ValueError(error_msg)
            
            dest_folder.mkdir(parents=True, exist_ok=True)
            shutil.copytree(ras_obj.project_folder, dest_folder, dirs_exist_ok=True)
            logging.info(f"Copied project folder to destination: {dest_folder}")
            
            compute_ras = RasPrj()
            compute_ras.initialize(dest_folder, ras_obj.ras_exe_path)
            compute_prj_path = compute_ras.prj_file
        else:
            compute_ras = ras_obj
            compute_prj_path = ras_obj.prj_file

        # Determine the plan path
        compute_plan_path = Path(plan_number) if isinstance(plan_number, (str, Path)) and Path(plan_number).is_file() else RasPlan.get_plan_path(plan_number, compute_ras)

        if not compute_prj_path or not compute_plan_path:
            logging.error(f"Could not find project file or plan file for plan {plan_number}")
            return False

        # Clear geometry preprocessor files if requested
        if clear_geompre:
            try:
                RasGeo.clear_geompre_files(compute_plan_path, ras_object=compute_ras)
                logging.info(f"Cleared geometry preprocessor files for plan: {plan_number}")
            except Exception as e:
                logging.error(f"Error clearing geometry preprocessor files for plan {plan_number}: {str(e)}")

        # Set the number of cores if specified
        if num_cores is not None:
            try:
                RasPlan.set_num_cores(compute_plan_path, num_cores=num_cores, ras_object=compute_ras)
                logging.info(f"Set number of cores to {num_cores} for plan: {plan_number}")
            except Exception as e:
                logging.error(f"Error setting number of cores for plan {plan_number}: {str(e)}")

        # Prepare the command for HEC-RAS execution
        cmd = f'"{compute_ras.ras_exe_path}" -c "{compute_prj_path}" "{compute_plan_path}"'
        logging.info("Running HEC-RAS from the Command Line:")
        logging.info(f"Running command: {cmd}")

        # Execute the HEC-RAS command
        start_time = time.time()
        try:
            subprocess.run(cmd, check=True, shell=True, capture_output=True, text=True)
            end_time = time.time()
            run_time = end_time - start_time
            logging.info(f"HEC-RAS execution completed for plan: {plan_number}")
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
            return True
        except subprocess.CalledProcessError as e:
            end_time = time.time()
            run_time = end_time - start_time
            logging.error(f"Error running plan: {plan_number}")
            logging.error(f"Error message: {e.output}")
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
            return False
        finally:
            # Update the RAS object's dataframes
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    


    @staticmethod
    def compute_parallel(
        plan_number: Union[str, List[str], None] = None,
        max_workers: int = 2,
        num_cores: int = 2,
        clear_geompre: bool = False,
        ras_object: Optional['RasPrj'] = None,  # Type hinting as string to avoid NameError
        dest_folder: Union[str, Path, None] = None,
        overwrite_dest: bool = False
    ) -> Dict[str, bool]:
        """
        [Docstring remains unchanged]
        """
        ras_obj = ras_object or ras  # Assuming 'ras' is a global RasPrj instance
        ras_obj.check_initialized()

        project_folder = Path(ras_obj.project_folder)

        if dest_folder is not None:
            dest_folder_path = Path(dest_folder)
            if dest_folder_path.exists():
                if overwrite_dest:
                    shutil.rmtree(dest_folder_path)
                    logging.info(f"Destination folder '{dest_folder_path}' exists. Overwriting as per overwrite_dest=True.")
                elif any(dest_folder_path.iterdir()):
                    error_msg = f"Destination folder '{dest_folder_path}' exists and is not empty. Use overwrite_dest=True to overwrite."
                    logging.error(error_msg)
                    raise ValueError(error_msg)
            dest_folder_path.mkdir(parents=True, exist_ok=True)
            shutil.copytree(project_folder, dest_folder_path, dirs_exist_ok=True)
            logging.info(f"Copied project folder to destination: {dest_folder_path}")
            project_folder = dest_folder_path

        if plan_number:
            if isinstance(plan_number, str):
                plan_number = [plan_number]
            ras_obj.plan_df = ras_obj.plan_df[ras_obj.plan_df['plan_number'].isin(plan_number)]
            logging.info(f"Filtered plans to execute: {plan_number}")

        num_plans = len(ras_obj.plan_df)
        max_workers = min(max_workers, num_plans) if num_plans > 0 else 1
        logging.info(f"Adjusted max_workers to {max_workers} based on the number of plans: {num_plans}")

        # Clean up existing worker folders and create new ones
        worker_ras_objects = {}
        for worker_id in range(1, max_workers + 1):
            worker_folder = project_folder.parent / f"{project_folder.name} [Worker {worker_id}]"
            if worker_folder.exists():
                shutil.rmtree(worker_folder)
                logging.info(f"Removed existing worker folder: {worker_folder}")
            shutil.copytree(project_folder, worker_folder)
            logging.info(f"Created worker folder: {worker_folder}")

            # Instantiate RasPrj properly
            ras_instance = RasPrj()  # Add necessary parameters if required
            worker_ras_instance = init_ras_project(
                ras_project_folder=worker_folder,
                ras_version=ras_obj.ras_exe_path,
                ras_instance=ras_instance  # Pass the instance instead of a string
            )
            worker_ras_objects[worker_id] = worker_ras_instance

        # Distribute plans among workers in a round-robin fashion
        worker_cycle = cycle(range(1, max_workers + 1))
        plan_assignments = [(next(worker_cycle), plan_num) for plan_num in ras_obj.plan_df['plan_number']]

        # Initialize ThreadPoolExecutor without tracking individual plan success
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit all plan executions to the executor
            futures = [
                executor.submit(
                    RasCmdr.compute_plan,
                    plan_num, 
                    ras_object=worker_ras_objects[worker_id], 
                    clear_geompre=clear_geompre,
                    num_cores=num_cores
                )
                for worker_id, plan_num in plan_assignments
            ]

            # Optionally, you can log when each plan starts and completes
            for future, (worker_id, plan_num) in zip(as_completed(futures), plan_assignments):
                try:
                    future.result()  # We don't need the success flag here
                    logging.info(f"Plan {plan_num} executed in worker {worker_id}")
                except Exception as e:
                    logging.error(f"Plan {plan_num} failed in worker {worker_id}: {str(e)}")
                    # Depending on requirements, you might want to handle retries or mark these plans differently

        # Consolidate results
        final_dest_folder = dest_folder_path if dest_folder is not None else project_folder.parent / f"{project_folder.name} [Computed]"
        final_dest_folder.mkdir(parents=True, exist_ok=True)
        logging.info(f"Final destination for computed results: {final_dest_folder}")

        for worker_ras in worker_ras_objects.values():
            worker_folder = Path(worker_ras.project_folder)
            try:
                for item in worker_folder.iterdir():
                    dest_path = final_dest_folder / item.name
                    if dest_path.exists():
                        if dest_path.is_dir():
                            shutil.rmtree(dest_path)
                            logging.debug(f"Removed existing directory at {dest_path}")
                        else:
                            dest_path.unlink()
                            logging.debug(f"Removed existing file at {dest_path}")
                    shutil.move(str(item), final_dest_folder)
                    logging.debug(f"Moved {item} to {final_dest_folder}")
                shutil.rmtree(worker_folder)
                logging.info(f"Removed worker folder: {worker_folder}")
            except Exception as e:
                logging.error(f"Error moving results from {worker_folder} to {final_dest_folder}: {str(e)}")

        # Initialize a new RasPrj object for the final destination
        try:
            # Create a new RasPrj instance
            final_dest_folder_ras_obj = RasPrj()
            
            # Initialize it using init_ras_project
            final_dest_folder_ras_obj = init_ras_project(
                ras_project_folder=final_dest_folder, 
                ras_version=ras_obj.ras_exe_path,
                ras_instance=final_dest_folder_ras_obj
            )
            
            # Now we can check if it's initialized
            final_dest_folder_ras_obj.check_initialized()
        except Exception as e:
            logging.error(f"Failed to initialize RasPrj for final destination: {str(e)}")
            raise

        # Retrieve plan entries and check for HDF results
        try:
            plan_entries = final_dest_folder_ras_obj.get_prj_entries('Plan')
        except Exception as e:
            logging.error(f"Failed to retrieve plan entries from final RasPrj: {str(e)}")
            raise

        execution_results: Dict[str, bool] = {}
        for _, row in ras_obj.plan_df.iterrows():
            plan_num = row['plan_number']
            # Find the corresponding entry in plan_entries
            entry = plan_entries[plan_entries['plan_number'] == plan_num]
            if not entry.empty:
                hdf_path = entry.iloc[0].get('HDF_Results_Path')
                success = hdf_path is not None and Path(hdf_path).exists()
            else:
                success = False
            execution_results[plan_num] = success

        # Print execution results for each plan
        logging.info("\nExecution Results:")
        for plan_num, success in execution_results.items():
            status = 'Successful' if success else 'Failed'
            logging.info(f"Plan {plan_num}: {status} \n(HDF_Results_Path: {hdf_path})")
            
        ras_obj = ras_object or ras
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return execution_results
    

    @staticmethod
    def compute_test_mode(
        plan_number=None, 
        dest_folder_suffix="[Test]", 
        clear_geompre=False, 
        num_cores=None, 
        ras_object=None,
        overwrite_dest=False
    ):
        """
        Execute HEC-RAS plans in test mode.  This is a re-creation of the HEC-RAS command line -test flag, 
        which does not work in recent versions of HEC-RAS.
        
        As a special-purpose function that emulates the original -test flag, it operates differently than the 
        other two compute_ functions.  Per the original HEC-RAS test flag, it creates a separate test folder,
        copies the project there, and executes the specified plans in sequential order.
        
        For most purposes, just copying a the project folder, initing that new folder, then running each plan 
        with compute_plan is a simpler and more flexible approach.  This is shown in the examples provided
        in the ras-commander library.

        Args:
            plan_number (str, list[str], optional): Plan number or list of plan numbers to execute. 
                If None, all plans will be executed. Default is None.
            dest_folder_suffix (str, optional): Suffix to append to the test folder name to create dest_folder. 
                Defaults to "[Test]".
                dest_folder is always created in the project folder's parent directory.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files.
                Defaults to False.
            num_cores (int, optional): Maximum number of cores to use for each plan.
                If None, the current setting is not changed. Default is None.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            None

        Example:
            Run all plans: RasCommander.compute_test_mode()
            Run a specific plan: RasCommander.compute_test_mode(plan_number="01")
            Run multiple plans: RasCommander.compute_test_mode(plan_number=["01", "03", "05"])
            Run plans with a custom folder suffix: RasCommander.compute_test_mode(dest_folder_suffix="[TestRun]")
            Run plans and clear geometry preprocessor files: RasCommander.compute_test_mode(clear_geompre=True)
            Run plans with a specific number of cores: RasCommander.compute_test_mode(num_cores=4)
            
        Notes:
            - This function executes plans in a separate folder for isolated testing.
            - If plan_number is not provided, all plans in the project will be executed.
            - The function does not change the geometry preprocessor and IB tables settings.  
                - To force recomputing of geometry preprocessor and IB tables, use the clear_geompre=True option.
            - Plans are executed sequentially.
            - Because copying the project is implicit, only a dest_folder_suffix option is provided.
            - For more flexible run management, use the compute_parallel or compute_sequential functions.
        """
        
        # This line of code is used to initialize the RasPrj object with the default "ras" object if no specific object is provided.
        ras_obj = ras_object or ras
        # This line of code is used to check if the RasPrj object is initialized.
        ras_obj.check_initialized()
        
        logging.info("Starting the compute_test_mode...")
           
        # Use the project folder from the ras object
        project_folder = ras_obj.project_folder

        # Check if the project folder exists
        if not project_folder.exists():
            logging.error(f"Project folder '{project_folder}' does not exist.")
            return

        # Create test folder with the specified suffix in the same directory as the project folder
        compute_folder = project_folder.parent / f"{project_folder.name} {dest_folder_suffix}"
        logging.info(f"Creating the test folder: {compute_folder}...")

        # Check if the compute folder exists and is empty
        if compute_folder.exists():
            if overwrite_dest:
                shutil.rmtree(compute_folder)
                logging.info(f"Compute folder '{compute_folder}' exists. Overwriting as per overwrite_dest=True.")
            elif any(compute_folder.iterdir()):
                error_msg = (
                    f"Compute folder '{compute_folder}' exists and is not empty. "
                    "Use overwrite_dest=True to overwrite."
                )
                logging.error(error_msg)
                raise ValueError(error_msg)
        else:
            try:
                shutil.copytree(project_folder, compute_folder)
                logging.info(f"Copied project folder to compute folder: {compute_folder}")
            except FileNotFoundError:
                logging.error(f"Unable to copy project folder. Source folder '{project_folder}' not found.")
                return
            except PermissionError:
                logging.error(f"Permission denied when trying to create or copy to '{compute_folder}'.")
                return
            except Exception as e:
                logging.error(f"Error occurred while copying project folder: {str(e)}")
                return

        # Initialize a new RAS project in the compute folder
        try:
            compute_ras = RasPrj()
            compute_ras.initialize(compute_folder, ras_obj.ras_exe_path)
            compute_prj_path = compute_ras.prj_file
            logging.info(f"Initialized RAS project in compute folder: {compute_prj_path}")
        except Exception as e:
            logging.error(f"Error initializing RAS project in compute folder: {str(e)}")
            return

        if not compute_prj_path:
            logging.error("Project file not found.")
            return

        # Get plan entries
        logging.info("Getting plan entries...")
        try:
            ras_compute_plan_entries = compute_ras.plan_df
            logging.info("Retrieved plan entries successfully.")
        except Exception as e:
            logging.error(f"Error retrieving plan entries: {str(e)}")
            return

        if plan_number:
            if isinstance(plan_number, str):
                plan_number = [plan_number]
            ras_compute_plan_entries = ras_compute_plan_entries[
                ras_compute_plan_entries['plan_number'].isin(plan_number)
            ]
            logging.info(f"Filtered plans to execute: {plan_number}")

        logging.info("Running selected plans sequentially...")
        for _, plan in ras_compute_plan_entries.iterrows():
            plan_number = plan["plan_number"]
            start_time = time.time()
            try:
                success = RasCmdr.compute_plan(
                    plan_number,
                    ras_object=compute_ras,
                    clear_geompre=clear_geompre,
                    num_cores=num_cores
                )
                if success:
                    logging.info(f"Successfully computed plan {plan_number}")
                else:
                    logging.error(f"Failed to compute plan {plan_number}")
            except Exception as e:
                logging.error(f"Error computing plan {plan_number}: {str(e)}")
            end_time = time.time()
            run_time = end_time - start_time
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")

        logging.info("All selected plans have been executed.")
        logging.info("compute_test_mode completed.")

        ras_obj = ras_object or ras
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    
==================================================

File: c:\GH\ras-commander\ras_commander\RasExamples.py
==================================================
import os
import requests
import zipfile
import pandas as pd
from pathlib import Path
import shutil
from typing import Union, List
import csv
from datetime import datetime
import logging
import re
from tqdm import tqdm

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

class RasExamples:
    """
    A class for quickly loading HEC-RAS example projects for testing and development of ras-commander.

    This class provides functionality to download, extract, and manage HEC-RAS example projects.
    It supports both default HEC-RAS example projects and custom projects from user-provided URLs.
    Additionally, it includes functionality to download FEMA's Base Level Engineering (BLE) models
    from CSV files provided by the FEMA Estimated Base Flood Elevation (BFE) Viewer.

    [Documentation as previously provided]
    """

    def __init__(self):
        """
        Initialize the RasExamples class.
        """
        self.base_url = 'https://github.com/HydrologicEngineeringCenter/hec-downloads/releases/download/'
        self.valid_versions = [
            "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
            "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
            "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
        ]
        self.base_dir = Path.cwd()
        self.examples_dir = self.base_dir
        self.projects_dir = self.examples_dir / 'example_projects'
        self.zip_file_path = None
        self.folder_df = None
        self.csv_file_path = self.examples_dir / 'example_projects.csv'

        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logging.info(f"Example projects folder: {self.projects_dir}")
        self._load_project_data()

    def _load_project_data(self):
        """
        Load project data from CSV if up-to-date, otherwise extract from zip.
        """
        self._find_zip_file()
        
        if not self.zip_file_path:
            logging.info("No example projects zip file found. Downloading...")
            self.get_example_projects()
        
        try:
            zip_modified_time = os.path.getmtime(self.zip_file_path)
        except FileNotFoundError:
            logging.error(f"Zip file not found at {self.zip_file_path}.")
            return
        
        if self.csv_file_path.exists():
            csv_modified_time = os.path.getmtime(self.csv_file_path)
            
            if csv_modified_time >= zip_modified_time:
                logging.info("Loading project data from CSV...")
                try:
                    self.folder_df = pd.read_csv(self.csv_file_path)
                    logging.info(f"Loaded {len(self.folder_df)} projects from CSV. Use list_categories() and list_projects() to explore them.")
                except Exception as e:
                    logging.error(f"Failed to read CSV file: {e}")
                    self.folder_df = None
                return

        logging.info("Extracting folder structure from zip file...")
        self._extract_folder_structure()
        self._save_to_csv()

    def _find_zip_file(self):
        """Locate the example projects zip file in the examples directory."""
        for version in self.valid_versions:
            potential_zip = self.examples_dir / f"Example_Projects_{version.replace('.', '_')}.zip"
            if potential_zip.exists():
                self.zip_file_path = potential_zip
                logging.info(f"Found zip file: {self.zip_file_path}")
                break
        else:
            logging.warning("No existing example projects zip file found.")

    def _extract_folder_structure(self):
        """
        Extract folder structure from the zip file.

        Populates folder_df with category and project information.
        """
        folder_data = []
        try:
            with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                for file in zip_ref.namelist():
                    parts = Path(file).parts
                    if len(parts) > 2:
                        folder_data.append({
                            'Category': parts[1],
                            'Project': parts[2]
                        })
        
            self.folder_df = pd.DataFrame(folder_data).drop_duplicates()
            logging.info(f"Extracted {len(self.folder_df)} projects.")
            logging.debug(f"folder_df:\n{self.folder_df}")
        except zipfile.BadZipFile:
            logging.error(f"The file {self.zip_file_path} is not a valid zip file.")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])
        except Exception as e:
            logging.error(f"An error occurred while extracting the folder structure: {str(e)}")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])

    def _save_to_csv(self):
        """Save the extracted folder structure to CSV file."""
        if self.folder_df is not None and not self.folder_df.empty:
            try:
                self.folder_df.to_csv(self.csv_file_path, index=False)
                logging.info(f"Saved project data to {self.csv_file_path}")
            except Exception as e:
                logging.error(f"Failed to save project data to CSV: {e}")
        else:
            logging.warning("No folder data to save to CSV.")

    def get_example_projects(self, version_number='6.5'):
        """
        Download and extract HEC-RAS example projects for a specified version.
        """
        logging.info(f"Getting example projects for version {version_number}")
        if version_number not in self.valid_versions:
            error_msg = f"Invalid version number. Valid versions are: {', '.join(self.valid_versions)}"
            logging.error(error_msg)
            raise ValueError(error_msg)

        zip_url = f"{self.base_url}1.0.31/Example_Projects_{version_number.replace('.', '_')}.zip"
        
        self.examples_dir.mkdir(parents=True, exist_ok=True)
        
        self.zip_file_path = self.examples_dir / f"Example_Projects_{version_number.replace('.', '_')}.zip"

        if not self.zip_file_path.exists():
            logging.info(f"Downloading HEC-RAS Example Projects from {zip_url}. \nThe file is over 400 MB, so it may take a few minutes to download....")
            try:
                response = requests.get(zip_url, stream=True)
                response.raise_for_status()
                with open(self.zip_file_path, 'wb') as file:
                    shutil.copyfileobj(response.raw, file)
                logging.info(f"Downloaded to {self.zip_file_path}")
            except requests.exceptions.RequestException as e:
                logging.error(f"Failed to download the zip file: {e}")
                raise
        else:
            logging.info("HEC-RAS Example Projects zip file already exists. Skipping download.")

        self._load_project_data()
        return self.projects_dir

    def list_categories(self):
        """
        List all categories of example projects.
        """
        if self.folder_df is None or 'Category' not in self.folder_df.columns:
            logging.warning("No categories available. Make sure the zip file is properly loaded.")
            return []
        categories = self.folder_df['Category'].unique()
        logging.info(f"Available categories: {', '.join(categories)}")
        return categories.tolist()

    def list_projects(self, category=None):
        """
        List all projects or projects in a specific category.
        """
        if self.folder_df is None:
            logging.warning("No projects available. Make sure the zip file is properly loaded.")
            return []
        if category:
            projects = self.folder_df[self.folder_df['Category'] == category]['Project'].unique()
            logging.info(f"Projects in category '{category}': {', '.join(projects)}")
        else:
            projects = self.folder_df['Project'].unique()
            logging.info(f"All available projects: {', '.join(projects)}")
        return projects.tolist()

    def extract_project(self, project_names: Union[str, List[str]]):
        """
        Extract one or more specific HEC-RAS projects from the zip file.
        """
        if isinstance(project_names, str):
            project_names = [project_names]

        extracted_paths = []

        for project_name in project_names:
            logging.info("----- RasExamples Extracting Project -----")
            logging.info(f"Extracting project '{project_name}'")
            project_path = self.projects_dir / project_name

            if project_path.exists():
                logging.info(f"Project '{project_name}' already exists. Deleting existing folder...")
                try:
                    shutil.rmtree(project_path)
                    logging.info(f"Existing folder for project '{project_name}' has been deleted.")
                except Exception as e:
                    logging.error(f"Failed to delete existing project folder '{project_name}': {e}")
                    continue

            if self.folder_df is None or self.folder_df.empty:
                error_msg = "No project information available. Make sure the zip file is properly loaded."
                logging.error(error_msg)
                raise ValueError(error_msg)

            project_info = self.folder_df[self.folder_df['Project'] == project_name]
            if project_info.empty:
                error_msg = f"Project '{project_name}' not found in the zip file."
                logging.error(error_msg)
                raise ValueError(error_msg)

            category = project_info['Category'].iloc[0]
            
            # Ensure the project directory exists
            project_path.mkdir(parents=True, exist_ok=True)

            try:
                with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                    for file in zip_ref.namelist():
                        parts = Path(file).parts
                        if len(parts) > 2 and parts[2] == project_name:
                            # Remove the first two levels (category and project name)
                            relative_path = Path(*parts[3:])
                            extract_path = project_path / relative_path
                            if file.endswith('/'):
                                extract_path.mkdir(parents=True, exist_ok=True)
                            else:
                                extract_path.parent.mkdir(parents=True, exist_ok=True)
                                with zip_ref.open(file) as source, open(extract_path, "wb") as target:
                                    shutil.copyfileobj(source, target)

                logging.info(f"Successfully extracted project '{project_name}' to {project_path}")
                extracted_paths.append(project_path)
            except zipfile.BadZipFile:
                logging.error(f"Error: The file {self.zip_file_path} is not a valid zip file.")
            except FileNotFoundError:
                logging.error(f"Error: The file {self.zip_file_path} was not found.")
            except Exception as e:
                logging.error(f"An unexpected error occurred while extracting the project: {str(e)}")
            logging.info("----- RasExamples Extraction Complete -----")
        return extracted_paths

    def is_project_extracted(self, project_name):
        """
        Check if a specific project is already extracted.
        """
        project_path = self.projects_dir / project_name
        is_extracted = project_path.exists()
        logging.info(f"Project '{project_name}' extracted: {is_extracted}")
        return is_extracted

    def clean_projects_directory(self):
        """Remove all extracted projects from the example_projects directory."""
        logging.info(f"Cleaning projects directory: {self.projects_dir}")
        if self.projects_dir.exists():
            try:
                shutil.rmtree(self.projects_dir)
                logging.info("All projects have been removed.")
            except Exception as e:
                logging.error(f"Failed to remove projects directory: {e}")
        else:
            logging.warning("Projects directory does not exist.")
        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logging.info("Projects directory cleaned and recreated.")
        
    def download_fema_ble_model(self, csv_file: Union[str, Path], output_base_dir: Union[str, Path] = None):
        """
        Download a single FEMA Base Level Engineering (BLE) model from a CSV file and organize it into folders.

        This function performs the following steps:
        1. Reads the specified CSV file to get the download URLs.
        2. Creates a folder for the region (e.g., `LowerPearl`, `BogueChitto`, etc.).
        3. Downloads the zip files to the same folder as the CSV.
        4. Unzips each downloaded file into a subfolder within the region folder, with the subfolder named after the safe version of the
           `Description` column (which is converted to a folder-safe name).
        5. Leaves the zip files in place in the CSV folder.
        6. Does not download files again if they already exist in the CSV folder.

        **Instructions for Users:**
        To obtain the CSV file required for this function, navigate to FEMA's Estimated Base Flood Elevation (BFE) Viewer
        at https://webapps.usgs.gov/infrm/estBFE/. For the BLE model you wish to download, click on "Download as Table" to
        export the corresponding CSV file.

        Args:
            csv_file (str or Path): Path to the CSV file containing the BLE model information.
            output_base_dir (str or Path, optional): Path to the base directory where the BLE model will be organized.
                                                     Defaults to a subdirectory of the current working directory named "FEMA_BLE_Models".

        Raises:
            FileNotFoundError: If the specified CSV file does not exist.
            Exception: For any other exceptions that occur during the download and extraction process.
        """
        csv_file = Path(csv_file)
        if output_base_dir is None:
            output_base_dir = Path.cwd() / "FEMA_BLE_Models"
        else:
            output_base_dir = Path(output_base_dir)

        if not csv_file.exists() or not csv_file.is_file():
            logging.error(f"The specified CSV file does not exist: {csv_file}")
            raise FileNotFoundError(f"The specified CSV file does not exist: {csv_file}")

        output_base_dir.mkdir(parents=True, exist_ok=True)
        logging.info(f"BLE model will be organized in: {output_base_dir}")

        try:
            # Extract region name from the filename (assuming format <AnyCharacters>_<Region>_DownloadIndex.csv)
            match = re.match(r'.+?_(.+?)_DownloadIndex\.csv', csv_file.name)
            if not match:
                logging.warning(f"Filename does not match expected pattern and will be skipped: {csv_file.name}")
                return
            region = match.group(1)
            logging.info(f"Processing region: {region}")

            # Create folder for this region
            region_folder = output_base_dir / region
            region_folder.mkdir(parents=True, exist_ok=True)
            logging.info(f"Created/verified region folder: {region_folder}")

            # Read the CSV file
            try:
                df = pd.read_csv(csv_file, comment='#')
            except pd.errors.ParserError as e:
                logging.error(f"Error parsing CSV file {csv_file.name}: {e}")
                return

            # Verify required columns exist
            required_columns = {'URL', 'FileName', 'FileSize', 'Description', 'Details'}
            if not required_columns.issubset(df.columns):
                logging.warning(f"CSV file {csv_file.name} is missing required columns and will be skipped.")
                return

            # Process each row in the CSV
            for index, row in tqdm(df.iterrows(), total=len(df), desc="Downloading files", unit="file"):
                description = row['Description']
                download_url = row['URL']
                file_name = row['FileName']
                file_size_str = row['FileSize']

                # Convert file size to bytes
                try:
                    file_size = self._convert_size_to_bytes(file_size_str)
                except ValueError as e:
                    logging.error(f"Error converting file size '{file_size_str}' to bytes: {e}")
                    continue

                # Create a subfolder based on the safe description name
                safe_description = self._make_safe_folder_name(description)
                description_folder = region_folder / safe_description

                # Download the file to the CSV folder if it does not already exist
                csv_folder = csv_file.parent
                downloaded_file = csv_folder / file_name
                if not downloaded_file.exists():
                    try:
                        logging.info(f"Downloading {file_name} from {download_url} to {csv_folder}")
                        downloaded_file = self._download_file_with_progress(download_url, csv_folder, file_size)
                        logging.info(f"Downloaded file to: {downloaded_file}")
                    except Exception as e:
                        logging.error(f"Failed to download {download_url}: {e}")
                        continue
                else:
                    logging.info(f"File {file_name} already exists in {csv_folder}, skipping download.")

                # If it's a zip file, unzip it to the description folder
                if downloaded_file.suffix == '.zip':
                    # If the folder exists, delete it
                    if description_folder.exists():
                        logging.info(f"Folder {description_folder} already exists. Deleting it.")
                        shutil.rmtree(description_folder)

                    description_folder.mkdir(parents=True, exist_ok=True)
                    logging.info(f"Created/verified description folder: {description_folder}")

                    logging.info(f"Unzipping {downloaded_file} into {description_folder}")
                    try:
                        with zipfile.ZipFile(downloaded_file, 'r') as zip_ref:
                            zip_ref.extractall(description_folder)
                        logging.info(f"Unzipped {downloaded_file} successfully.")
                    except Exception as e:
                        logging.error(f"Failed to extract {downloaded_file}: {e}")
        except Exception as e:
            logging.error(f"An error occurred while processing {csv_file.name}: {e}")

    def _make_safe_folder_name(self, name: str) -> str:
        """
        Convert a string to a safe folder name by replacing unsafe characters with underscores.
        """
        safe_name = re.sub(r'[^a-zA-Z0-9_\-]', '_', name)
        logging.debug(f"Converted '{name}' to safe folder name '{safe_name}'")
        return safe_name

    def _download_file_with_progress(self, url: str, dest_folder: Path, file_size: int) -> Path:
        """
        Download a file from a URL to a specified destination folder with progress bar.
        """
        local_filename = dest_folder / url.split('/')[-1]
        try:
            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(local_filename, 'wb') as f, tqdm(
                    desc=local_filename.name,
                    total=file_size,
                    unit='iB',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as progress_bar:
                    for chunk in r.iter_content(chunk_size=8192):
                        size = f.write(chunk)
                        progress_bar.update(size)
            logging.info(f"Successfully downloaded {url} to {local_filename}")
            return local_filename
        except requests.exceptions.RequestException as e:
            logging.error(f"Request failed for {url}: {e}")
            raise
        except Exception as e:
            logging.error(f"Failed to write file {local_filename}: {e}")
            raise

    def _convert_size_to_bytes(self, size_str: str) -> int:
        """
        Convert a human-readable file size to bytes.
        """
        units = {'B': 1, 'KB': 1024, 'MB': 1024**2, 'GB': 1024**3, 'TB': 1024**4}
        size_str = size_str.upper().replace(' ', '')
        if not re.match(r'^\d+(\.\d+)?[BKMGT]B?$', size_str):
            raise ValueError(f"Invalid size string: {size_str}")
        
        number, unit = float(re.findall(r'[\d\.]+', size_str)[0]), re.findall(r'[BKMGT]B?', size_str)[0]
        return int(number * units[unit])

    # Example usage:
    # ras_examples = RasExamples()
    # ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
    # extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
    # for path in extracted_paths:
    #     logging.info(f"Extracted to: {path}")


"""
### How to Use the Revised `RasExamples` Class

1. **Instantiate the Class:**
   ```python
   ras_examples = RasExamples()
   ```

2. **Download FEMA BLE Models:**
   - Ensure you have the required CSV files by visiting [FEMA's Estimated Base Flood Elevation (BFE) Viewer](https://webapps.usgs.gov/infrm/estBFE/) and using the "Download as Table" option for each BLE model you wish to access.
   - Call the `download_fema_ble_models` method with the appropriate paths:
     ```python
     ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
     ```
     - Replace `'/path/to/csv/files'` with the directory containing your CSV files.
     - Replace `'/path/to/output/folder'` with the directory where you want the BLE models to be downloaded and organized.

3. **Extract Projects (If Needed):**
   - After downloading, you can extract specific projects using the existing `extract_project` method:
     ```python
     extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
     for path in extracted_paths:
         logging.info(f"Extracted to: {path}")
     ```

4. **Explore Projects and Categories:**
   - List available categories:
     ```python
     categories = ras_examples.list_categories()
     ```
   - List projects within a specific category:
     ```python
     projects = ras_examples.list_projects(category='SomeCategory')
     ```

5. **Clean Projects Directory (If Needed):**
   - To remove all extracted projects:
     ```python
     ras_examples.clean_projects_directory()
     ```

### Dependencies

Ensure that the following Python packages are installed:

- `pandas`
- `requests`

You can install them using `pip`:

```bash
pip install pandas requests
```

### Notes

- The class uses Python's `logging` module to provide detailed information about its operations. Ensure that the logging level is set appropriately to capture the desired amount of detail.
- The `download_fema_ble_models` method handles large file downloads by streaming data in chunks, which is memory-efficient.
- All folder names are sanitized to prevent filesystem errors due to unsafe characters.
"""
==================================================

File: c:\GH\ras-commander\ras_commander\RasGeo.py
==================================================
"""
Operations for handling geometry files in HEC-RAS projects.
"""
from pathlib import Path
from typing import List, Union
from .RasPlan import RasPlan
from .RasPrj import ras
import logging
import re

# Configure logging at the module level
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    # You can add a filename parameter here to log to a file
    # filename='rasgeo.log',
    # Uncomment the above line to enable file logging
)

class RasGeo:
    """
    A class for operations on HEC-RAS geometry files.
    """
    
    @staticmethod
    def clear_geompre_files(
        plan_files: Union[str, Path, List[Union[str, Path]]] = None,
        ras_object = None
    ) -> None:
        """
        Clear HEC-RAS geometry preprocessor files for specified plan files or all plan files in the project directory.
        
        Limitations/Future Work:
        - This function only deletes the geometry preprocessor file.
        - It does not clear the IB tables.
        - It also does not clear geometry preprocessor tables from the geometry HDF.
        - All of these features will need to be added to reliably remove geometry preprocessor files for 1D and 2D projects.
        
        Parameters:
            plan_files (Union[str, Path, List[Union[str, Path]]], optional): 
                Full path(s) to the HEC-RAS plan file(s) (.p*).
                If None, clears all plan files in the project directory.
            ras_object: An optional RAS object instance.
        
        Returns:
            None
        
        Examples:
            # Clear all geometry preprocessor files in the project directory
            RasGeo.clear_geompre_files()
            
            # Clear a single plan file
            RasGeo.clear_geompre_files(r'path/to/plan.p01')
            
            # Clear multiple plan files
            RasGeo.clear_geompre_files([r'path/to/plan1.p01', r'path/to/plan2.p02'])

        Note:
            This function updates the ras object's geometry dataframe after clearing the preprocessor files.
        """
        ## Explicit Function Steps
        # 1. Initialize the ras_object, defaulting to the global ras if not provided.
        # 2. Define a helper function to clear a single geometry preprocessor file.
        # 3. Determine the list of plan files to process based on the input.
        # 4. Iterate over each plan file and clear its geometry preprocessor file.
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        def clear_single_file(plan_file: Union[str, Path], ras_obj) -> None:
            plan_path = Path(plan_file)
            geom_preprocessor_suffix = '.c' + ''.join(plan_path.suffixes[1:]) if plan_path.suffixes else '.c'
            geom_preprocessor_file = plan_path.with_suffix(geom_preprocessor_suffix)
            if geom_preprocessor_file.exists():
                try:
                    logging.info(f"Deleting geometry preprocessor file: {geom_preprocessor_file}")
                    geom_preprocessor_file.unlink()
                    logging.info("File deletion completed successfully.")
                except PermissionError:
                    logging.error(f"Permission denied: Unable to delete geometry preprocessor file: {geom_preprocessor_file}.")
                    raise PermissionError(f"Unable to delete geometry preprocessor file: {geom_preprocessor_file}. Permission denied.")
                except OSError as e:
                    logging.error(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
                    raise OSError(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
            else:
                logging.warning(f"No geometry preprocessor file found for: {plan_file}")
        
        if plan_files is None:
            logging.info("Clearing all geometry preprocessor files in the project directory.")
            plan_files_to_clear = list(ras_obj.project_folder.glob(r'*.p*'))
        elif isinstance(plan_files, (str, Path)):
            plan_files_to_clear = [plan_files]
            logging.info(f"Clearing geometry preprocessor file for single plan: {plan_files}")
        elif isinstance(plan_files, list):
            plan_files_to_clear = plan_files
            logging.info(f"Clearing geometry preprocessor files for multiple plans: {plan_files}")
        else:
            logging.error("Invalid input type for plan_files.")
            raise ValueError("Invalid input. Please provide a string, Path, list of paths, or None.")
        
        for plan_file in plan_files_to_clear:
            clear_single_file(plan_file, ras_obj)
        
        # Update the geometry dataframe
        try:
            ras_obj.geom_df = ras_obj.get_geom_entries()
            logging.info("Geometry dataframe updated successfully.")
        except Exception as e:
            logging.error(f"Failed to update geometry dataframe: {str(e)}")
            raise

==================================================

File: c:\GH\ras-commander\ras_commander\RasHdf.py
==================================================
"""
RasHdf Module

This module provides utilities for working with HDF files in HEC-RAS projects.
It contains the RasHdf class, which offers various static methods for extracting,
analyzing, and manipulating data from HEC-RAS HDF files.

Note:
    This method is decorated with @hdf_operation, which handles the opening and closing of the HDF file.
    The decorator should be used for all methods that directly interact with HDF files.
    It ensures proper file handling and error management.

    When using the @hdf_operation decorator:
    - The method receives an open h5py.File object as its first argument after 'cls'.
    - Error handling for file operations is managed by the decorator.
    - The HDF file is automatically closed after the method execution.

    Methods without this decorator must manually handle file opening, closing, and error management.
    Failure to use the decorator or properly manage the file can lead to resource leaks or file access errors.

Example:
    @classmethod
    @hdf_operation
    def example_method(cls, hdf_file: h5py.File, other_args):
        # Method implementation using hdf_file
        

"""
import h5py
import numpy as np
import pandas as pd
from typing import Union, List, Optional, Dict, Tuple, Any, Callable
from scipy.spatial import KDTree
from pathlib import Path
from datetime import datetime
import logging
from functools import wraps
from .RasPrj import RasPrj, ras, init_ras_project

# If you're using RasPrj in type hints, you might need to use string literals to avoid circular imports
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .RasPrj import RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ])

class RasHdf:
    """
    A utility class for working with HDF files in HEC-RAS projects.

    This class provides static methods for various operations on HDF files,
    including listing paths, extracting data, and performing analyses on
    HEC-RAS project data stored in HDF format.
    """
        
    @staticmethod
    def hdf_operation(func):
        @wraps(func)
        def wrapper(cls, hdf_input: Union[str, Path], *args: Any, **kwargs: Any) -> Any:
            from ras_commander import ras  # Import here to avoid circular import
            ras_obj = kwargs.pop('ras_object', None) or ras
            try:
                hdf_filename = cls._get_hdf_filename(hdf_input, ras_obj)
                with h5py.File(hdf_filename, 'r') as hdf_file:
                    return func(cls, hdf_file, *args, **kwargs)
            except Exception as e:
                logging.error(f"Error in {func.__name__}: {e}")
                return None
        return classmethod(wrapper)
    
    @classmethod
    def get_hdf_paths_with_properties(cls, hdf_input: Union[str, Path], ras_object=None) -> pd.DataFrame:
        """
        List all paths in the HDF file with their properties.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all paths and their properties in the HDF file.

        Example:
            >>> paths_df = RasHdf.get_hdf_paths_with_properties("path/to/file.hdf")
            >>> print(paths_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            paths = []
            def visitor_func(name: str, node: h5py.Group) -> None:
                path_info = {
                    "HDF_Path": name,
                    "Type": type(node).__name__,
                    "Shape": getattr(node, "shape", None),
                    "Size": getattr(node, "size", None),
                    "Dtype": getattr(node, "dtype", None)
                }
                paths.append(path_info)
            hdf_file.visititems(visitor_func)
            return pd.DataFrame(paths)
    
    @classmethod
    def get_runtime_data(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract runtime and compute time data from a single HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing runtime and compute time data, or None if data extraction fails.

        Example:
            >>> runtime_df = RasHdf.get_runtime_data("path/to/file.hdf")
            >>> if runtime_df is not None:
            ...     print(runtime_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            logging.info(f"Extracting Plan Information from: {Path(hdf_file.filename).name}")
            plan_info = hdf_file.get('/Plan Data/Plan Information')
            if plan_info is None:
                logging.warning("Group '/Plan Data/Plan Information' not found.")
                return None

            plan_name = plan_info.attrs.get('Plan Name', 'Unknown')
            plan_name = plan_name.decode('utf-8') if isinstance(plan_name, bytes) else plan_name
            logging.info(f"Plan Name: {plan_name}")

            start_time_str = plan_info.attrs.get('Simulation Start Time', 'Unknown')
            end_time_str = plan_info.attrs.get('Simulation End Time', 'Unknown')
            start_time_str = start_time_str.decode('utf-8') if isinstance(start_time_str, bytes) else start_time_str
            end_time_str = end_time_str.decode('utf-8') if isinstance(end_time_str, bytes) else end_time_str

            start_time = datetime.strptime(start_time_str, "%d%b%Y %H:%M:%S")
            end_time = datetime.strptime(end_time_str, "%d%b%Y %H:%M:%S")
            simulation_duration = end_time - start_time
            simulation_hours = simulation_duration.total_seconds() / 3600

            logging.info(f"Simulation Start Time: {start_time_str}")
            logging.info(f"Simulation End Time: {end_time_str}")
            logging.info(f"Simulation Duration (hours): {simulation_hours}")

            compute_processes = hdf_file.get('/Results/Summary/Compute Processes')
            if compute_processes is None:
                logging.warning("Dataset '/Results/Summary/Compute Processes' not found.")
                return None

            process_names = [name.decode('utf-8') for name in compute_processes['Process'][:]]
            filenames = [filename.decode('utf-8') for filename in compute_processes['Filename'][:]]
            completion_times = compute_processes['Compute Time (ms)'][:]

            compute_processes_df = pd.DataFrame({
                'Process': process_names,
                'Filename': filenames,
                'Compute Time (ms)': completion_times,
                'Compute Time (s)': completion_times / 1000,
                'Compute Time (hours)': completion_times / (1000 * 3600)
            })

            logging.debug("Compute processes DataFrame:")
            logging.debug(compute_processes_df)

            compute_processes_summary = {
                'Plan Name': [plan_name],
                'File Name': [Path(hdf_file.filename).name],
                'Simulation Start Time': [start_time_str],
                'Simulation End Time': [end_time_str],
                'Simulation Duration (s)': [simulation_duration.total_seconds()],
                'Simulation Time (hr)': [simulation_hours],
                'Completing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Geometry']['Compute Time (hours)'].values[0] if 'Completing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Preprocessing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Preprocessing Geometry']['Compute Time (hours)'].values[0] if 'Preprocessing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Completing Event Conditions (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Event Conditions']['Compute Time (hours)'].values[0] if 'Completing Event Conditions' in compute_processes_df['Process'].values else 'N/A'],
                'Unsteady Flow Computations (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Unsteady Flow Computations']['Compute Time (hours)'].values[0] if 'Unsteady Flow Computations' in compute_processes_df['Process'].values else 'N/A'],
                'Complete Process (hr)': [compute_processes_df['Compute Time (hours)'].sum()]
            }

            compute_processes_summary['Unsteady Flow Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Unsteady Flow Computations (hr)'][0] if compute_processes_summary['Unsteady Flow Computations (hr)'][0] != 'N/A' else 'N/A']
            compute_processes_summary['Complete Process Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Complete Process (hr)'][0] if compute_processes_summary['Complete Process (hr)'][0] != 'N/A' else 'N/A']

            compute_summary_df = pd.DataFrame(compute_processes_summary)
            logging.debug("Compute summary DataFrame:")
            logging.debug(compute_summary_df)

            return compute_summary_df

    # List 2D Flow Area Groups (needed for later functions that extract specific datasets)
    
    @classmethod
    @hdf_operation
    def get_2d_flow_area_names(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[List[str]]:
        """
        List 2D Flow Area names from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[List[str]]: List of 2D Flow Area names, or None if no 2D Flow Areas are found.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas' in hdf_file:
                group = hdf_file['Geometry/2D Flow Areas']
                group_names = [name for name in group.keys() if isinstance(group[name], h5py.Group)]
                if not group_names:
                    logging.warning("No 2D Flow Areas found in the HDF file")
                    return None
                logging.info(f"Found {len(group_names)} 2D Flow Areas")
                return group_names
            else:
                logging.warning("No 2D Flow Areas found in the HDF file")
                return None
            
    @classmethod
    @hdf_operation
    def get_2d_flow_area_attributes(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract 2D Flow Area Attributes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing 2D Flow Area Attributes, or None if attributes are not found.

        Example:
            >>> attributes_df = RasHdf.get_2d_flow_area_attributes("path/to/file.hdf")
            >>> if attributes_df is not None:
            ...     print(attributes_df.head())
            ... else:
            ...     print("No 2D Flow Area attributes found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas/Attributes' in hdf_file:
                attributes = hdf_file['Geometry/2D Flow Areas/Attributes'][()]
                attributes_df = pd.DataFrame(attributes)
                logging.info(f"Extracted 2D Flow Area attributes: {attributes_df.shape[0]} rows, {attributes_df.shape[1]} columns")
                return attributes_df
            else:
                logging.warning("No 2D Flow Area attributes found in the HDF file")
                return None
            
    @classmethod
    @hdf_operation
    def get_cell_info(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Info from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Info, or None if the data is not found.

        Example:
            >>> cell_info_df = RasHdf.get_cell_info("path/to/file.hdf")
            >>> if cell_info_df is not None:
            ...     print(cell_info_df.head())
            ... else:
            ...     print("No Cell Info found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_info_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Info', ['Start', 'End'])
            if cell_info_df is not None:
                logging.info(f"Extracted Cell Info: {cell_info_df.shape[0]} rows, {cell_info_df.shape[1]} columns")
            else:
                logging.warning("No Cell Info found in the HDF file")
            return cell_info_df
        
    @classmethod
    @hdf_operation
    def get_cell_points(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Points, or None if the data is not found.

        Example:
            >>> cell_points_df = RasHdf.get_cell_points("path/to/file.hdf")
            >>> if cell_points_df is not None:
            ...     print(cell_points_df.head())
            ... else:
            ...     print("No Cell Points found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_points_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Points', ['X', 'Y'])
            if cell_points_df is not None:
                logging.info(f"Extracted Cell Points: {cell_points_df.shape[0]} rows, {cell_points_df.shape[1]} columns")
            else:
                logging.warning("No Cell Points found in the HDF file")
            return cell_points_df
    
    @classmethod
    @hdf_operation
    def get_polygon_info_and_parts(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Polygon Info and Parts from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Polygon Info and Polygon Parts respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> polygon_info_df, polygon_parts_df = RasHdf.get_polygon_info_and_parts("path/to/file.hdf")
            >>> if polygon_info_df is not None and polygon_parts_df is not None:
            ...     print("Polygon Info:")
            ...     print(polygon_info_df.head())
            ...     print("Polygon Parts:")
            ...     print(polygon_parts_df.head())
            ... else:
            ...     print("Polygon data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            # Retrieve the area name, defaulting to the first found if not provided
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            # Construct the base path for dataset extraction
            base_path = f'Geometry/2D Flow Areas'
            
            # Extract Polygon Info and Parts datasets
            polygon_info_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Info', ['Column1', 'Column2', 'Column3', 'Column4'])
            polygon_parts_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Parts', ['Start', 'Count'])

            # Log warnings if no data is found
            if polygon_info_df is None and polygon_parts_df is None:
                logging.warning(f"No Polygon Info or Parts found for 2D Flow Area: {area_name}")

            return polygon_info_df, polygon_parts_df

    @classmethod
    @hdf_operation
    def get_polygon_points(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Polygon Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Polygon Points, or None if the data is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            # This path does not include the area name
            polygon_points_path = f'Geometry/2D Flow Areas/Polygon Points'
            if polygon_points_path in hdf_file:
                polygon_points = hdf_file[polygon_points_path][()]
                polygon_points_df = pd.DataFrame(polygon_points, columns=['X', 'Y'])
                logging.info(f"Extracted Polygon Points for 2D Flow Area {area_name}: {polygon_points_df.shape[0]} rows, {polygon_points_df.shape[1]} columns")
                return polygon_points_df
            else:
                logging.warning(f"No Polygon Points found for 2D Flow Area: {area_name}")
                return None
            
    @classmethod
    @hdf_operation
    def get_cells_center_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Cells Center Coordinates and Manning's n from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Cells Center Coordinates and Manning's n respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> coords_df, mannings_df = RasHdf.get_cells_center_data("path/to/file.hdf")
            >>> if coords_df is not None and mannings_df is not None:
            ...     print("Cell Center Coordinates:")
            ...     print(coords_df.head())
            ...     print("Manning's n:")
            ...     print(mannings_df.head())
            ... else:
            ...     print("Cell center data not found")
        """
        logging.info(f"Entering get_cells_center_data method")
        logging.info(f"Input parameters: hdf_input={hdf_input}, area_name={area_name}")
        
        try:
            hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
            logging.info(f"HDF filename: {hdf_filename}")
            
            with h5py.File(hdf_filename, 'r') as hdf_file:
                logging.info(f"Successfully opened HDF file: {hdf_filename}")
                
                logging.info(f"Getting Cells Center Data for 2D Flow Area: {area_name}")
                area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
                logging.info(f"Area Name: {area_name}")
                
                base_path = f'Geometry/2D Flow Areas/{area_name}'
                cells_center_coord_path = f'{base_path}/Cells Center Coordinate'
                cells_manning_n_path = f'{base_path}/Cells Center Manning\'s n'
                
                logging.info(f"Extracting dataset from path: {cells_center_coord_path}")
                cells_center_coord_df = cls._extract_dataset(hdf_file, cells_center_coord_path, ['X', 'Y'])
                
                logging.info(f"Extracting dataset from path: {cells_manning_n_path}")
                cells_manning_n_df = cls._extract_dataset(hdf_file, cells_manning_n_path, ['Manning\'s n'])

                if cells_center_coord_df is not None and cells_manning_n_df is not None:
                    logging.info(f"Extracted Cells Center Data for 2D Flow Area: {area_name}")
                    logging.info(f"Cells Center Coordinates shape: {cells_center_coord_df.shape}, dtype: {cells_center_coord_df.dtypes}")
                    logging.info(f"Cells Manning's n shape: {cells_manning_n_df.shape}, dtype: {cells_manning_n_df.dtypes}")
                else:
                    logging.warning(f"Cells Center Data not found for 2D Flow Area: {area_name}")

                return cells_center_coord_df, cells_manning_n_df
        
        except Exception as e:
            logging.error(f"Error in get_cells_center_data: {str(e)}", exc_info=True)
            return None, None

    @classmethod
    @hdf_operation
    def get_faces_area_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Faces Area Elevation Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces Area Elevation Values, or None if the data is not found.

        Example:
            >>> elevation_df = RasHdf.get_faces_area_elevation_data("path/to/file.hdf")
            >>> if elevation_df is not None:
            ...     print(elevation_df.head())
            ... else:
            ...     print("No Faces Area Elevation data found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            base_path = f'Geometry/2D Flow Areas/{area_name}'
            area_elev_values_path = f'{base_path}/Faces Area Elevation Values'
            
            if area_elev_values_path in hdf_file:
                area_elev_values = hdf_file[area_elev_values_path][()]
                area_elev_values_df = pd.DataFrame(area_elev_values, columns=['Elevation', 'Area', 'Wetted Perimeter', 'Manning\'s n'])
                
                logging.info(f"Extracted Faces Area Elevation Values for 2D Flow Area: {area_name}")
                logging.info(f"Faces Area Elevation Values shape: {area_elev_values.shape}, dtype: {area_elev_values.dtype}")
                
                return area_elev_values_df
            else:
                logging.warning(f"Faces Area Elevation Values not found for 2D Flow Area: {area_name}")
                return None

    @classmethod
    @hdf_operation
    def get_faces_indexes(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Cell and FacePoint Indexes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Faces Cell Indexes and FacePoint Indexes respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> cell_indexes_df, facepoint_indexes_df = RasHdf.get_faces_indexes("path/to/file.hdf")
            >>> if cell_indexes_df is not None and facepoint_indexes_df is not None:
            ...     print("Faces Cell Indexes:")
            ...     print(cell_indexes_df.head())
            ...     print("Faces FacePoint Indexes:")
            ...     print(facepoint_indexes_df.head())
            ... else:
            ...     print("Faces indexes data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            cell_indexes_path = f'{base_path}/Faces Cell Indexes'
            facepoint_indexes_path = f'{base_path}/Faces FacePoint Indexes'
            
            cell_indexes_df = cls._extract_dataset(hdf_file, cell_indexes_path, ['Left Cell', 'Right Cell'])
            facepoint_indexes_df = cls._extract_dataset(hdf_file, facepoint_indexes_path, ['Start FacePoint', 'End FacePoint'])

            if cell_indexes_df is not None and facepoint_indexes_df is not None:
                logging.info(f"Extracted Faces Indexes for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Indexes not found for 2D Flow Area: {area_name}")

            return cell_indexes_df, facepoint_indexes_df
        
        
        
    @classmethod
    @hdf_operation
    def get_faces_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Low Elevation Centroid and Minimum Elevation from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Low Elevation Centroid and Minimum Elevation.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            low_elev_centroid = cls._extract_dataset(hdf_file, f'{base_path}/Faces Low Elevation Centroid', ['Low Elevation Centroid'])
            min_elevation = cls._extract_dataset(hdf_file, f'{base_path}/Faces Minimum Elevation', ['Minimum Elevation'])

            if low_elev_centroid is not None and min_elevation is not None:
                logging.info(f"Extracted Faces Elevation Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Elevation Data not found for 2D Flow Area: {area_name}")

            return low_elev_centroid, min_elevation
    
    @classmethod
    @hdf_operation
    def get_faces_vector_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Faces NormalUnitVector and Length from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces NormalUnitVector and Length.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            vector_data = cls._extract_dataset(hdf_file, f'{base_path}/Faces NormalUnitVector and Length', ['NormalX', 'NormalY', 'Length'])

            if vector_data is not None:
                logging.info(f"Extracted Faces Vector Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Vector Data not found for 2D Flow Area: {area_name}")

            return vector_data

    @classmethod
    @hdf_operation
    def get_faces_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Perimeter Info and Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Perimeter Info and Values.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.

        Example:
            >>> perimeter_info_df, perimeter_values_df = RasHdf.get_faces_perimeter_data("path/to/file.hdf")
            >>> if perimeter_info_df is not None and perimeter_values_df is not None:
            ...     print("Perimeter Info:")
            ...     print(perimeter_info_df.head())
            ...     print("Perimeter Values:")
            ...     print(perimeter_values_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            perimeter_info = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Info', ['Start', 'Count'])
            perimeter_values = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Values', ['X', 'Y'])

            if perimeter_info is not None and perimeter_values is not None:
                logging.info(f"Extracted Faces Perimeter Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Perimeter Data not found for 2D Flow Area: {area_name}")

            return perimeter_info, perimeter_values

    @classmethod
    @hdf_operation
    def get_infiltration_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Infiltration Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing various Infiltration Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            # Retrieve the area name from the HDF file or use the first found
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            # Define the base path for the Infiltration data
            base_path = f'Geometry/2D Flow Areas/{area_name}/Infiltration'
            
            # Extract various datasets related to infiltration
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            initial_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Initial Deficit', ['Initial Deficit'])
            maximum_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Maximum Deficit', ['Maximum Deficit'])
            potential_percolation_rate = cls._extract_dataset(hdf_file, f'{base_path}/Potential Percolation Rate', ['Potential Percolation Rate'])

            # Log the extraction status
            if all(df is not None for df in [cell_classifications, face_classifications, initial_deficit, maximum_deficit, potential_percolation_rate]):
                logging.info(f"Extracted Infiltration Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Some or all Infiltration Data not found for 2D Flow Area: {area_name}")

            return cell_classifications, face_classifications, initial_deficit, maximum_deficit, potential_percolation_rate
        
    @classmethod
    @hdf_operation
    def get_percent_impervious_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Percent Impervious Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Cell Classifications, Face Classifications, and Percent Impervious Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}/Percent Impervious'
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            percent_impervious = cls._extract_dataset(hdf_file, f'{base_path}/Percent Impervious', ['Percent Impervious'])

            if all([df is not None for df in [cell_classifications, face_classifications, percent_impervious]]):
                logging.info(f"Extracted Percent Impervious Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Some or all Percent Impervious Data not found for 2D Flow Area: {area_name}")

            return cell_classifications, face_classifications, percent_impervious

    @classmethod
    @hdf_operation
    def get_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Perimeter Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Perimeter Data

        Example:
            >>> perimeter_df = RasHdf.get_perimeter_data("path/to/file.hdf")
            >>> if perimeter_df is not None:
            ...     print(perimeter_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            perimeter_path = f'Geometry/2D Flow Areas/{area_name}/Perimeter'
            perimeter_df = cls._extract_dataset(hdf_file, perimeter_path, ['X', 'Y'])

            if perimeter_df is not None:
                logging.info(f"Extracted Perimeter Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Perimeter Data not found for 2D Flow Area: {area_name}")

            return perimeter_df

# Private Class Methods (to save code duplication)


    @classmethod
    def _get_area_name(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> str:
        """
        Get the 2D Flow Area name from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): The provided area name, if any.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            str: The 2D Flow Area name.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file or if the specified area name is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if area_name is None:
                area_names = [name for name in hdf_file['Geometry/2D Flow Areas'].keys() if isinstance(hdf_file['Geometry/2D Flow Areas'][name], h5py.Group)]
                if not area_names:
                    raise ValueError("No 2D Flow Areas found in the HDF file")
                area_name = area_names[0]
                logging.info(f"Using first 2D Flow Area found: {area_name}")
            else:
                if area_name not in hdf_file['Geometry/2D Flow Areas']:
                    raise ValueError(f"2D Flow Area '{area_name}' not found in the HDF file")
                logging.info(f"Using 2D Flow Area provided by user: {area_name}")
        return area_name

    @classmethod
    def _extract_dataset(cls, hdf_input: Union[str, Path], dataset_path: str, column_names: List[str], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract a dataset from the HDF file and convert it to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            dataset_path (str): The path to the dataset within the HDF file.
            column_names (List[str]): The names to assign to the DataFrame columns.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: The extracted data as a DataFrame, or None if the dataset is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                dataset = hdf_file[dataset_path][()]
                df = pd.DataFrame(dataset, columns=column_names)
                logging.info(f"Extracted dataset: {dataset_path}")
                return df
            except KeyError:
                logging.warning(f"Dataset not found: {dataset_path}")
                return None
    @classmethod
    @hdf_operation
    def read_hdf_to_dataframe(cls, hdf_input: Union[str, Path], dataset_path: str, fill_value: Union[int, float, str] = -9999, ras_object=None) -> pd.DataFrame:
        """
        Reads an HDF5 dataset and converts it into a pandas DataFrame, handling byte strings and missing values.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            dataset_path (str): Path to the dataset within the HDF file.
            fill_value (Union[int, float, str], optional): The value to use for filling missing data. Defaults to -9999.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: The resulting DataFrame with byte strings decoded and missing values replaced.

        Raises:
            KeyError: If the dataset is not found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_dataset = hdf_file[dataset_path]
                hdf_dataframe = cls.convert_to_dataframe_array(hdf_dataset)
                byte_columns = [col for col in hdf_dataframe.columns if isinstance(hdf_dataframe[col].iloc[0], (bytes, bytearray))]
                
                hdf_dataframe[byte_columns] = hdf_dataframe[byte_columns].applymap(lambda x: x.decode('utf-8') if isinstance(x, (bytes, bytearray)) else x)
                hdf_dataframe = hdf_dataframe.replace({fill_value: np.NaN})
                
                logging.info(f"Successfully read dataset: {dataset_path}")
                return hdf_dataframe
            except KeyError:
                logging.error(f"Dataset not found: {dataset_path}")
                raise
        
    @classmethod
    @hdf_operation
    def get_group_attributes_as_df(cls, hdf_input: Union[str, Path], group_path: str, ras_object=None) -> pd.DataFrame:
        """
        Convert attributes inside a given HDF group to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            group_path (str): Path of the group in the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all attributes in the specified group with their properties.

        Raises:
            KeyError: If the specified group_path is not found in the file.

        Example:
            >>> attributes_df = RasHdf.get_group_attributes_as_df("path/to/file.hdf", "/Results/Unsteady/Output")
            >>> print(attributes_df.head())
        """
        hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
        
        with h5py.File(hdf_filename, 'r') as hdf_file:
            try:
                group = hdf_file[group_path]
                attributes = []
                for attr in group.attrs:
                    value = group.attrs[attr]
                    attr_info = {
                        'Attribute': attr,
                        'Value': value,
                        'Type': type(value).__name__,
                        'Shape': value.shape if isinstance(value, np.ndarray) else None,
                        'Size': value.size if isinstance(value, np.ndarray) else None,
                        'Dtype': value.dtype if isinstance(value, np.ndarray) else None
                    }
                    if isinstance(value, bytes):
                        attr_info['Value'] = value.decode('utf-8')
                    elif isinstance(value, np.ndarray):
                        if value.dtype.kind == 'S':
                            attr_info['Value'] = [v.decode('utf-8') for v in value]
                        elif value.dtype.kind in ['i', 'f', 'u']:
                            attr_info['Value'] = value.tolist()
                    attributes.append(attr_info)
                
                return pd.DataFrame(attributes)
            except KeyError:
                logging.error(f"Group not found: {group_path}")
                raise

    # Last functions from PyHMT2D:


    @classmethod
    @hdf_operation
    def get_2d_area_solution_times(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution times for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution times, or None if not found.
        
        Example:
            >>> solution_times = RasHdf.get_2d_area_solution_times("03", area_name="Area1")
            >>> print(solution_times)
            [0.0, 0.5, 1.0, ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_times = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time']
                )
                logging.info(f"Retrieved {len(solution_times)} solution times for 2D Flow Area: {area_name}")
                return solution_times
            except KeyError:
                logging.warning(f"Solution times not found for 2D Flow Area: {area_name}")
                return None
    @classmethod
    @hdf_operation
    def get_2d_area_solution_time_dates(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution time dates for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution time dates, or None if not found.
        
        Example:
            >>> solution_time_dates = RasHdf.get_2d_area_solution_time_dates("03", area_name="Area1")
            >>> print(solution_time_dates)
            ['2024-01-01T00:00:00', '2024-01-01T00:30:00', ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_time_dates = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time Date Stamp']
                )
                logging.info(f"Retrieved {len(solution_time_dates)} solution time dates for 2D Flow Area: {area_name}")
                return solution_time_dates
            except KeyError:
                logging.warning(f"Solution time dates not found for 2D Flow Area: {area_name}")
                return None

    @classmethod
    @hdf_operation
    def load_2d_area_solutions(
        cls,
        hdf_file: h5py.File,
        ras_object=None
    ) -> Optional[Dict[str, pd.DataFrame]]:
        """
        Load 2D Area Solutions (Water Surface Elevation and Face Normal Velocity) from the HDF file
        and provide them as pandas DataFrames.

        **Note:** 
            - This function has only been tested with HEC-RAS version 6.5.
            - Ensure that the HDF file structure matches the expected paths.

        Args:
            hdf_file (h5py.File): An open HDF5 file object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[Dict[str, pd.DataFrame]]: A dictionary containing:
                - 'solution_times': DataFrame of solution times.
                - For each 2D Flow Area:
                    - '{Area_Name}_WSE': Water Surface Elevation DataFrame.
                    - '{Area_Name}_Face_Velocity': Face Normal Velocity DataFrame.
        """
        try:
            # Extract solution times
            solution_times_path = '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time'
            if solution_times_path not in hdf_file:
                logging.error(f"Solution times dataset not found at path: {solution_times_path}")
                return None

            solution_times = hdf_file[solution_times_path][()]
            solution_times_df = pd.DataFrame({
                'Time_Step': solution_times
            })
            logging.info(f"Extracted Solution Times: {solution_times_df.shape[0]} time steps")

            # Initialize dictionary to hold all dataframes
            solutions_dict = {
                'solution_times': solution_times_df
            }

            # Get list of 2D Flow Areas
            two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
            if not two_d_area_names:
                logging.error("No 2D Flow Areas found in the HDF file.")
                return solutions_dict

            for area in two_d_area_names:
                logging.info(f"Processing 2D Flow Area: {area}")

                # Paths for WSE and Face Velocity datasets
                wse_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Water Surface'
                face_velocity_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Face Velocity'

                # Extract Water Surface Elevation (WSE)
                if wse_path not in hdf_file:
                    logging.warning(f"WSE dataset not found for area '{area}' at path: {wse_path}")
                    continue

                wse_data = hdf_file[wse_path][()]
                # Assuming cell center coordinates are required for WSE
                cell_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Cell Center Coordinate'
                if cell_center_coords_path not in hdf_file:
                    logging.warning(f"Cell Center Coordinate dataset not found for area '{area}' at path: {cell_center_coords_path}")
                    continue

                cell_center_coords = hdf_file[cell_center_coords_path][()]
                if cell_center_coords.shape[0] != wse_data.shape[1]:
                    logging.warning(f"Mismatch between Cell Center Coordinates and WSE data for area '{area}'.")
                    continue

                wse_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, wse_data.shape[1]),
                    'Cell_ID': np.tile(np.arange(wse_data.shape[1]), wse_data.shape[0]),
                    'X': cell_center_coords[:, 0].repeat(wse_data.shape[0]),
                    'Y': cell_center_coords[:, 1].repeat(wse_data.shape[0]),
                    'WSE': wse_data.flatten()
                })
                solutions_dict[f'{area}_WSE'] = wse_df
                logging.info(f"Extracted WSE for area '{area}': {wse_df.shape[0]} records")

                # Extract Face Normal Velocity
                if face_velocity_path not in hdf_file:
                    logging.warning(f"Face Velocity dataset not found for area '{area}' at path: {face_velocity_path}")
                    continue

                face_velocity_data = hdf_file[face_velocity_path][()]
                # Assuming face center points are required for velocities
                face_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Face Points Coordinates'
                if face_center_coords_path not in hdf_file:
                    logging.warning(f"Face Points Coordinates dataset not found for area '{area}' at path: {face_center_coords_path}")
                    continue

                face_center_coords = hdf_file[face_center_coords_path][()]
                if face_center_coords.shape[0] != face_velocity_data.shape[1]:
                    logging.warning(f"Mismatch between Face Center Coordinates and Face Velocity data for area '{area}'.")
                    continue

                face_velocity_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, face_velocity_data.shape[1]),
                    'Face_ID': np.tile(np.arange(face_velocity_data.shape[1]), face_velocity_data.shape[0]),
                    'X': face_center_coords[:, 0].repeat(face_velocity_data.shape[0]),
                    'Y': face_center_coords[:, 1].repeat(face_velocity_data.shape[0]),
                    'Normal_Velocity_ft_s': face_velocity_data.flatten()
                })
                solutions_dict[f'{area}_Face_Velocity'] = face_velocity_df
                logging.info(f"Extracted Face Velocity for area '{area}': {face_velocity_df.shape[0]} records")

            return solutions_dict

        except Exception as e:
            logging.error(f"An error occurred while loading 2D area solutions: {e}", exc_info=True)
            return None


    @classmethod
    @hdf_operation
    def build_2d_area_face_hydraulic_information(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[List[np.ndarray]]]:
        """
        Build face hydraulic information tables (elevation, area, wetted perimeter, Manning's n) for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[List[np.ndarray]]]: Nested lists containing hydraulic information for each face in each 2D Flow Area.
        
        Example:
            >>> hydraulic_info = RasHdf.build_2d_area_face_hydraulic_information("03")
            >>> print(hydraulic_info[0][0])  # First face of first area
            [[Elevation1, Area1, WettedPerim1, ManningN1],
             [Elevation2, Area2, WettedPerim2, ManningN2],
             ...]
        """
        try:
            ras_obj = ras_object if ras_object is not None else ras
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_obj), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                hydraulic_info_table = []

                for area in two_d_area_names:
                    face_elev_info = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Info'])
                    face_elev_values = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Values'])
                    
                    area_hydraulic_info = []
                    for face in face_elev_info:
                        start_row, count = face
                        face_data = face_elev_values[start_row:start_row + count].copy()
                        area_hydraulic_info.append(face_data)
                        logging.info(f"Processed hydraulic information for face {face} in 2D Flow Area: {area}")
                    
                    hydraulic_info_table.append(area_hydraulic_info)

                return hydraulic_info_table

        except KeyError as e:
            logging.error(f"Error building face hydraulic information: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_face_point_coordinates_list(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build a list of face point coordinates for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point coordinates for each 2D Flow Area.
        
        Example:
            >>> face_coords_list = RasHdf.build_2d_area_face_point_coordinates_list("03")
            >>> print(face_coords_list[0])  # Coordinates for first area
            [[X1, Y1], [X2, Y2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_point_coords_list = []

                for area in two_d_area_names:
                    face_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    face_point_coords_list.append(face_points)
                    logging.info(f"Built face point coordinates list for 2D Flow Area: {area}")

                return face_point_coords_list

        except KeyError as e:
            logging.error(f"Error building face point coordinates list: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_face_profile(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None, n_face_profile_points: int = 10) -> Optional[List[np.ndarray]]:
        """
        Build face profiles representing sub-grid terrain for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
            n_face_profile_points (int): Number of points to interpolate along each face profile.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of profile points for each face in each 2D Flow Area.
        
        Example:
            >>> face_profiles = RasHdf.build_2d_area_face_profile("03", n_face_profile_points=20)
            >>> print(face_profiles[0][0])  # Profile points for first face of first area
            [[X1, Y1, Z1], [X2, Y2, Z2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                print(f"Building face profiles for {len(two_d_area_names)} 2D Flow Areas")
                print(f"Area names: {two_d_area_names}")
                face_profiles = []

                for area in two_d_area_names:
                    face_faces = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_point_coords = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    profile_points_all_faces = []

                    for face in face_faces:
                        face_start, face_end = face
                        start_coords = face_point_coords[face_start]
                        end_coords = face_point_coords[face_end]
                        
                        length = cls.horizontal_distance(start_coords, end_coords)
                        stations = np.linspace(0, length, n_face_profile_points, endpoint=True)
                        
                        interpolated_points = np.array([
                            start_coords + (end_coords - start_coords) * i / (n_face_profile_points - 1)
                            for i in range(n_face_profile_points)
                        ])
                        
                        # Interpolate Z coordinates (assuming a method exists)
                        interpolated_points = cls.interpolate_z_coords(interpolated_points)
                        
                        profile_points_all_faces.append(interpolated_points)
                        logging.info(f"Built face profile for face {face} in 2D Flow Area: {area}")

                    face_profiles.append(profile_points_all_faces)

                return face_profiles

        except KeyError as e:
            logging.error(f"Error building face profiles: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_face_facepoints(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build face's facepoint list for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point indexes for each face in each 2D Flow Area.
        
        Example:
            >>> face_facepoints = RasHdf.build_face_facepoints("03")
            >>> print(face_facepoints[0][0])  # FacePoint indexes for first face of first area
            [start_idx, end_idx]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_facepoints_list = []

                for area in two_d_area_names:
                    face_facepoints = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_facepoints_list.append(face_facepoints)
                    logging.info(f"Built face facepoints list for 2D Flow Area: {area}")

                return face_facepoints_list

        except KeyError as e:
            logging.error(f"Error building face facepoints list: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_boundaries(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
        """
        Build boundaries with their point lists for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
                Tuple containing total boundaries, boundary IDs, boundary names, associated 2D Flow Area names, boundary types,
                total points per boundary, and boundary point lists.
        
        Example:
            >>> total_boundaries, boundary_ids, boundary_names, flow_area_names, boundary_types, total_points, boundary_points = RasHdf.build_2d_area_boundaries("03")
            >>> print(total_boundaries)
            5
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                total_boundaries = 0
                boundary_ids = []
                boundary_names = []
                flow_area_names = []
                boundary_types = []
                total_points_per_boundary = []
                boundary_points_list = []

                for area in two_d_area_names:
                    boundary_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Boundary Points'])
                    if boundary_points.size == 0:
                        logging.warning(f"No boundary points found for 2D Flow Area: {area}")
                        continue

                    current_boundary_id = boundary_points[0][0]
                    current_boundary_points = [boundary_points[0][2], boundary_points[0][3]]
                    boundary_id = current_boundary_id

                    for point in boundary_points[1:]:
                        if point[0] == current_boundary_id:
                            current_boundary_points.append(point[3])
                        else:
                            # Save the completed boundary
                            boundary_ids.append(current_boundary_id)
                            boundary_names.append(point[0])  # Assuming boundary name is stored here
                            flow_area_names.append(area)
                            boundary_types.append(point[2])  # Assuming boundary type is stored here
                            total_points_per_boundary.append(len(current_boundary_points))
                            boundary_points_list.append(np.array(current_boundary_points))
                            total_boundaries += 1

                            # Start a new boundary
                            current_boundary_id = point[0]
                            current_boundary_points = [point[2], point[3]]

                    # Save the last boundary
                    boundary_ids.append(current_boundary_id)
                    boundary_names.append(boundary_points[-1][0])  # Assuming boundary name is stored here
                    flow_area_names.append(area)
                    boundary_types.append(boundary_points[-1][2])  # Assuming boundary type is stored here
                    total_points_per_boundary.append(len(current_boundary_points))
                    boundary_points_list.append(np.array(current_boundary_points))
                    total_boundaries += 1

                    logging.info(f"Built boundaries for 2D Flow Area: {area}, Total Boundaries: {total_boundaries}")

                return (total_boundaries, np.array(boundary_ids), boundary_names, flow_area_names, boundary_types, np.array(total_points_per_boundary), np.array(boundary_points_list))

        except KeyError as e:
            logging.error(f"Error building boundaries: {e}")
            return None

    # Helper Methods for New Functionalities


    @classmethod
    def horizontal_distance(cls, coord1: np.ndarray, coord2: np.ndarray) -> float:
        """
        Calculate the horizontal distance between two coordinate points.
        
        Args:
            coord1 (np.ndarray): First coordinate point [X, Y].
            coord2 (np.ndarray): Second coordinate point [X, Y].
        
        Returns:
            float: Horizontal distance.
        
        Example:
            >>> distance = RasHdf.horizontal_distance([0, 0], [3, 4])
            >>> print(distance)
            5.0
        """
        return np.linalg.norm(coord2 - coord1)

    @classmethod
    def interpolate_z_coords(cls, points: np.ndarray) -> np.ndarray:
        """
        Interpolate Z coordinates for a set of points.
        
        Args:
            points (np.ndarray): Array of points with [X, Y].
        
        Returns:
            np.ndarray: Array of points with [X, Y, Z].
        
        Example:
            >>> interpolated = RasHdf.interpolate_z_coords(np.array([[0,0], [1,1]]))
            >>> print(interpolated)
            [[0, 0, Z0],
             [1, 1, Z1]]
        """
        # Placeholder for actual interpolation logic
        # This should be replaced with the appropriate interpolation method
        z_coords = np.zeros((points.shape[0], 1))  # Assuming Z=0 for simplicity
        return np.hstack((points, z_coords))
   







    @classmethod
    @hdf_operation
    def extract_string_from_hdf(
        cls,
        hdf_input: Union[str, Path],
        hdf_path: str,
        ras_object: Optional["RasPrj"] = None
    ) -> str:
        """
        Extract string from HDF object at a given path.

        Args:
            hdf_input (Union[str, Path]): Either the plan number or the full path to the HDF file.
            hdf_path (str): Path of the object in the HDF file.
            ras_object (Optional["RasPrj"]): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            str: Extracted string from the specified HDF object.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.
            KeyError: If the specified hdf_path is not found in the file.

        Example:
            >>> result = RasHdf.extract_string_from_hdf("path/to/file.hdf", "/Results/Summary/Compute Messages (text)")
            >>> print(result)
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_object = hdf_file[hdf_path]
                if isinstance(hdf_object, h5py.Group):
                    return f"Group: {hdf_path}\nContents: {list(hdf_object.keys())}"
                elif isinstance(hdf_object, h5py.Dataset):
                    data = hdf_object[()]
                    if isinstance(data, bytes):
                        return data.decode('utf-8')
                    elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':
                        return [v.decode('utf-8') for v in data]
                    else:
                        return str(data)
                else:
                    return f"Unsupported object type: {type(hdf_object)}"
            except KeyError:
                raise KeyError(f"Path not found: {hdf_path}")

    @classmethod
    @staticmethod
    def decode_byte_strings(dataframe: pd.DataFrame) -> pd.DataFrame:
        """
        Decodes byte strings in a DataFrame to regular string objects.

        This function converts columns with byte-encoded strings (e.g., b'string') into UTF-8 decoded strings.

        Args:
            dataframe (pd.DataFrame): The DataFrame containing byte-encoded string columns.

        Returns:
            pd.DataFrame: The DataFrame with byte strings decoded to regular strings.

        Example:
            >>> df = pd.DataFrame({'A': [b'hello', b'world'], 'B': [1, 2]})
            >>> decoded_df = RasHdf.decode_byte_strings(df)
            >>> print(decoded_df)
                A  B
            0  hello  1
            1  world  2
        """
        str_df = dataframe.select_dtypes(['object'])
        str_df = str_df.stack().str.decode('utf-8').unstack()
        for col in str_df:
            dataframe[col] = str_df[col]
        return dataframe

    @classmethod
    @staticmethod
    def perform_kdtree_query(
        reference_points: np.ndarray,
        query_points: np.ndarray,
        max_distance: float = 2.0
    ) -> np.ndarray:
        """
        Performs a KDTree query between two datasets and returns indices with distances exceeding max_distance set to -1.

        Args:
            reference_points (np.ndarray): The reference dataset for KDTree.
            query_points (np.ndarray): The query dataset to search against KDTree of reference_points.
            max_distance (float, optional): The maximum distance threshold. Indices with distances greater than this are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices from reference_points that are nearest to each point in query_points. 
                        Indices with distances > max_distance are set to -1.

        Example:
            >>> ref_points = np.array([[0, 0], [1, 1], [2, 2]])
            >>> query_points = np.array([[0.5, 0.5], [3, 3]])
            >>> result = RasHdf.perform_kdtree_query(ref_points, query_points)
            >>> print(result)
            array([ 0, -1])
        """
        dist, snap = KDTree(reference_points).query(query_points, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        return snap

    @classmethod
    @staticmethod
    def find_nearest_neighbors(points: np.ndarray, max_distance: float = 2.0) -> np.ndarray:
        """
        Creates a self KDTree for dataset points and finds nearest neighbors excluding self, 
        with distances above max_distance set to -1.

        Args:
            points (np.ndarray): The dataset to build the KDTree from and query against itself.
            max_distance (float, optional): The maximum distance threshold. Indices with distances 
                                            greater than max_distance are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices representing the nearest neighbor in points for each point in points. 
                        Indices with distances > max_distance or self-matches are set to -1.

        Example:
            >>> points = np.array([[0, 0], [1, 1], [2, 2], [10, 10]])
            >>> result = RasHdf.find_nearest_neighbors(points)
            >>> print(result)
            array([1, 0, 1, -1])
        """
        dist, snap = KDTree(points).query(points, k=2, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        
        snp = pd.DataFrame(snap, index=np.arange(len(snap)))
        snp = snp.replace(-1, np.nan)
        snp.loc[snp[0] == snp.index, 0] = np.nan
        snp.loc[snp[1] == snp.index, 1] = np.nan
        filled = snp[0].fillna(snp[1])
        snapped = filled.fillna(-1).astype(np.int64).to_numpy()
        return snapped

    @classmethod
    @staticmethod
    def consolidate_dataframe(
        dataframe: pd.DataFrame,
        group_by: Optional[Union[str, List[str]]] = None,
        pivot_columns: Optional[Union[str, List[str]]] = None,
        level: Optional[int] = None,
        n_dimensional: bool = False,
        aggregation_method: Union[str, Callable] = 'list'
    ) -> pd.DataFrame:
        """
        Consolidate rows in a DataFrame by merging duplicate values into lists or using a specified aggregation function.

        Args:
            dataframe (pd.DataFrame): The DataFrame to consolidate.
            group_by (Optional[Union[str, List[str]]]): Columns or indices to group by.
            pivot_columns (Optional[Union[str, List[str]]]): Columns to pivot.
            level (Optional[int]): Level of multi-index to group by.
            n_dimensional (bool): If True, use a pivot table for N-Dimensional consolidation.
            aggregation_method (Union[str, Callable]): Aggregation method, e.g., 'list' to aggregate into lists.

        Returns:
            pd.DataFrame: The consolidated DataFrame.

        Example:
            >>> df = pd.DataFrame({'A': [1, 1, 2], 'B': [4, 5, 6], 'C': [7, 8, 9]})
            >>> result = RasHdf.consolidate_dataframe(df, group_by='A')
            >>> print(result)
            B         C
            A            
            1  [4, 5]  [7, 8]
            2  [6]     [9]
        """
        if aggregation_method == 'list':
            agg_func = lambda x: tuple(x)
        else:
            agg_func = aggregation_method

        if n_dimensional:
            result = dataframe.pivot_table(group_by, pivot_columns, aggfunc=agg_func)
        else:
            result = dataframe.groupby(group_by, level=level).agg(agg_func).applymap(list)

        return result
    
    @classmethod
    @staticmethod
    def find_nearest_value(array: Union[list, np.ndarray], target_value: Union[int, float]) -> Union[int, float]:
        """
        Finds the nearest value in a NumPy array to the specified target value.

        Args:
            array (Union[list, np.ndarray]): The array to search within.
            target_value (Union[int, float]): The value to find the nearest neighbor to.

        Returns:
            Union[int, float]: The nearest value in the array to the specified target value.

        Example:
            >>> arr = np.array([1, 3, 5, 7, 9])
            >>> result = RasHdf.find_nearest_value(arr, 6)
            >>> print(result)
            5
        """
        array = np.asarray(array)
        idx = (np.abs(array - target_value)).argmin()
        return array[idx]
    
    @staticmethod
    def _get_hdf_filename(hdf_input: Union[str, Path, h5py.File], ras_object=None) -> Path:
        """
        Get the HDF filename from the input.

        Args:
            hdf_input (Union[str, Path, h5py.File]): The plan number, full path to the HDF file as a string, a Path object, or an h5py.File object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Path: The full path to the HDF file as a Path object.

        Raises:
            ValueError: If no HDF file is found for the given plan number or if the input type is invalid.
            FileNotFoundError: If the specified HDF file does not exist.
        """

        # If hdf_input is already an h5py.File object, return its filename
        if isinstance(hdf_input, h5py.File):
            return Path(hdf_input.filename)

        # Convert to Path object if it's a string
        hdf_input = Path(hdf_input)

        # If hdf_input is a file path, return it directly
        if hdf_input.is_file():
            return hdf_input

        # If hdf_input is not a file path, assume it's a plan number and require ras_object
        ras_obj = ras_object or ras
        if not ras_obj.initialized:
            raise ValueError("ras_object is not initialized. ras_object is required when hdf_input is not a direct file path.")

        plan_info = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == str(hdf_input)]
        if plan_info.empty:
            raise ValueError(f"No HDF file found for plan number {hdf_input}")

        hdf_filename = Path(plan_info.iloc[0]['HDF_Results_Path'])
        if not hdf_filename.is_file():
            raise FileNotFoundError(f"HDF file not found: {hdf_filename}")

        return hdf_filename




def save_dataframe_to_hdf(
    dataframe: pd.DataFrame,
    hdf_parent_group: h5py.Group,
    dataset_name: str,
    attributes: Optional[Dict[str, Union[int, float, str]]] = None,
    fill_value: Union[int, float, str] = -9999,
    **kwargs: Any
) -> h5py.Dataset:
    """
    Save a pandas DataFrame to an HDF5 dataset within a specified parent group.

    This function addresses limitations of `pd.to_hdf()` by using h5py to create and save datasets.

    Args:
        dataframe (pd.DataFrame): The DataFrame to save.
        hdf_parent_group (h5py.Group): The parent HDF5 group where the dataset will be created.
        dataset_name (str): The name of the new dataset to add in the HDF5 parent group.
        attributes (Optional[Dict[str, Union[int, float, str]]]): A dictionary of attributes to add to the dataset.
        fill_value (Union[int, float, str]): The value to use for filling missing data.
        **kwargs: Additional keyword arguments passed to `hdf_parent_group.create_dataset()`.

    Returns:
        h5py.Dataset: The created HDF5 dataset within the parent group.

    Raises:
        ValueError: If the DataFrame columns are not consistent.

    Example:
        >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
        >>> with h5py.File('data.h5', 'w') as f:
        ...     group = f.create_group('my_group')
        ...     dataset = save_dataframe_to_hdf(df, group, 'my_dataset')
        >>> print(dataset)
    """
    df = dataframe.copy()

    # Replace '/' in column names with '-' to avoid issues in HDF5
    if df.columns.dtype == 'O':
        df.columns = df.columns.str.replace('/', '-', regex=False)
    
    # Fill missing values with the specified fill_value
    df = df.fillna(fill_value)
    
    # Identify string columns and ensure consistency
    string_cols = df.select_dtypes(include=['object']).columns
    if not string_cols.equals(df.select_dtypes(include=['object']).columns):
        raise ValueError("Inconsistent string columns detected")
    
    # Encode string columns to bytes
    df[string_cols] = df[string_cols].applymap(lambda x: x.encode('utf-8')).astype('bytes')

    # Prepare data for HDF5 dataset creation
    arr = df.to_records(index=False) if not isinstance(df.columns, pd.RangeIndex) else df.values
    
    # Remove existing dataset if it exists
    if dataset_name in hdf_parent_group:
        del hdf_parent_group[dataset_name]
    
    # Create the dataset in the HDF5 file
    dataset = hdf_parent_group.create_dataset(dataset_name, data=arr, **kwargs)
    
    # Update dataset attributes if provided
    if attributes:
        dataset.attrs.update(attributes)
    
    logging.info(f"Successfully saved DataFrame to dataset: {dataset_name}")
    return dataset


==================================================

File: c:\GH\ras-commander\ras_commander\RasPlan.py
==================================================
import re
import logging
from pathlib import Path
import shutil
from typing import Union, Optional
import pandas as pd
from .RasPrj import RasPrj, ras
from .RasUtils import RasUtils


from pathlib import Path
from typing import Union, Any
import logging
import re


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class RasPlan:
    """
    A class for operations on HEC-RAS plan files.
    """

    @staticmethod
    def set_geom(plan_number: Union[str, int], new_geom: Union[str, int], ras_object=None) -> pd.DataFrame:
        """
        Set the geometry for the specified plan.

        Parameters:
            plan_number (Union[str, int]): The plan number to update.
            new_geom (Union[str, int]): The new geometry number to set.
            ras_object: An optional RAS object instance.

        Returns:
            pd.DataFrame: The updated geometry DataFrame.

        Example:
            updated_geom_df = RasPlan.set_geom('02', '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Ensure plan_number and new_geom are strings
        plan_number = str(plan_number).zfill(2)
        new_geom = str(new_geom).zfill(2)

        # Before doing anything, make sure the plan, geom, flow, and unsteady dataframes are current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        # Log the current geometry DataFrame for debugging
        logging.debug("Current geometry DataFrame within the function:")
        logging.debug(ras_obj.geom_df)

        if new_geom not in ras_obj.geom_df['geom_number'].values:
            logging.error(f"Geometry {new_geom} not found in project.")
            raise ValueError(f"Geometry {new_geom} not found in project.")

        # Update the geometry for the specified plan
        ras_obj.plan_df.loc[ras_obj.plan_df['plan_number'] == plan_number, 'geom_number'] = new_geom

        logging.info(f"Geometry for plan {plan_number} set to {new_geom}")
        logging.debug("Updated plan DataFrame:")
        logging.debug(ras_obj.plan_df)

        # Update the project file
        prj_file_path = ras_obj.prj_file
        try:
            with open(prj_file_path, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {prj_file_path}")
            raise

        plan_pattern = re.compile(rf"^Plan File=p{plan_number}", re.IGNORECASE)
        geom_pattern = re.compile(r"^Geom File=g\d+", re.IGNORECASE)
        
        for i, line in enumerate(lines):
            if plan_pattern.match(line):
                for j in range(i+1, len(lines)):
                    if geom_pattern.match(lines[j]):
                        lines[j] = f"Geom File=g{new_geom}\n"
                        logging.info(f"Updated Geom File in project file to g{new_geom} for plan {plan_number}")
                        break
                break

        try:
            with open(prj_file_path, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated project file with new geometry for plan {plan_number}")
        except IOError as e:
            logging.error(f"Failed to write to project file: {e}")
            raise

        # Re-initialize the ras object to reflect changes
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        return ras_obj.plan_df

    @staticmethod
    def set_steady(plan_number: str, new_steady_flow_number: str, ras_object=None):
        """
        Apply a steady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02')
        new_steady_flow_number (str): Steady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified steady flow number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_steady('02', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting steady flow file to {new_steady_flow_number} in Plan {plan_number}")
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
                        
        # Update the flow dataframe in the ras instance to ensure it is current
        ras_obj.flow_df = ras_obj.get_flow_entries()
        
        if new_steady_flow_number not in ras_obj.flow_df['flow_number'].values:
            logging.error(f"Steady flow number {new_steady_flow_number} not found in project file.")
            raise ValueError(f"Steady flow number {new_steady_flow_number} not found in project file.")
        
        # Resolve the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            logging.error(f"Plan file not found: {plan_number}")
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        try:
            with open(plan_file_path, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Plan file not found: {plan_file_path}")
            raise
        
        with open(plan_file_path, 'w') as f:
            for line in lines:
                if line.startswith("Flow File=f"):
                    f.write(f"Flow File=f{new_steady_flow_number}\n")
                    logging.info(f"Updated Flow File in {plan_file_path} to f{new_steady_flow_number}")
                else:
                    f.write(line)

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_unsteady(plan_number: str, new_unsteady_flow_number: str, ras_object=None):
        """
        Apply an unsteady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '04')
        new_unsteady_flow_number (str): Unsteady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified unsteady number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_unsteady('04', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting unsteady flow file to {new_unsteady_flow_number} in Plan {plan_number}")
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the unsteady dataframe in the ras instance to ensure it is current
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        if new_unsteady_flow_number not in ras_obj.unsteady_df['unsteady_number'].values:
            logging.error(f"Unsteady number {new_unsteady_flow_number} not found in project file.")
            raise ValueError(f"Unsteady number {new_unsteady_flow_number} not found in project file.")
        
        # Get the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            logging.error(f"Plan file not found: {plan_number}")
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        try:
            RasUtils.update_plan_file(plan_file_path, 'Unsteady', new_unsteady_flow_number)
            logging.info(f"Updated unsteady flow file in {plan_file_path} to u{new_unsteady_flow_number}")
        except Exception as e:
            logging.error(f"Failed to update unsteady flow file: {e}")
            raise

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_num_cores(plan_number, num_cores, ras_object=None):
        """
        Update the maximum number of cores to use in the HEC-RAS plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02') or full path to the plan file
        num_cores (int): Maximum number of cores to use
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Notes on setting num_cores in HEC-RAS:
        The recommended setting for num_cores is 2 (most efficient) to 8 (most performant)
        More details in the HEC-Commander Repository Blog "Benchmarking is All You Need"
        https://github.com/billk-FM/HEC-Commander/blob/main/Blog/7._Benchmarking_Is_All_You_Need.md
        
        Microsoft Windows has a maximum of 64 cores that can be allocated to a single Ras.exe process. 

        Example:
        >>> # Using plan number
        >>> RasPlan.set_num_cores('02', 4)
        >>> # Using full path to plan file
        >>> RasPlan.set_num_cores('/path/to/project.p02', 4)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting num_cores to {num_cores} in Plan {plan_number}")
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Determine if plan_number is a path or a plan number
        if Path(plan_number).is_file():
            plan_file_path = Path(plan_number)
            if not plan_file_path.exists():
                logging.error(f"Plan file not found: {plan_file_path}. Please provide a valid plan number or path.")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}. Please provide a valid plan number or path.")
        else:
            # Update the plan dataframe in the ras instance to ensure it is current
            ras_obj.plan_df = ras_obj.get_prj_entries('Plan')
            
            # Get the full path of the plan file
            plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
            if not plan_file_path:
                logging.error(f"Plan file not found: {plan_number}. Please provide a valid plan number or path.")
                raise FileNotFoundError(f"Plan file not found: {plan_number}. Please provide a valid plan number or path.")
        
        cores_pattern = re.compile(r"(UNET D1 Cores= )\d+")
        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except FileNotFoundError:
            logging.error(f"Plan file not found: {plan_file_path}")
            raise
        
        new_content = cores_pattern.sub(rf"\g<1>{num_cores}", content)
        try:
            with open(plan_file_path, 'w') as file:
                file.write(new_content)
            logging.info(f"Updated {plan_file_path} with {num_cores} cores.")
        except IOError as e:
            logging.error(f"Failed to write to plan file: {e}")
            raise
        
        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_geom_preprocessor(file_path, run_htab, use_ib_tables, ras_object=None):
        """
        Update the simulation plan file to modify the `Run HTab` and `UNET Use Existing IB Tables` settings.
        
        Parameters:
        file_path (str): Path to the simulation plan file (.p06 or similar) that you want to modify.
        run_htab (int): Value for the `Run HTab` setting:
            - `0` : Do not run the geometry preprocessor, use existing geometry tables.
            - `-1` : Run the geometry preprocessor, forcing a recomputation of the geometry tables.
        use_ib_tables (int): Value for the `UNET Use Existing IB Tables` setting:
            - `0` : Use existing interpolation/boundary (IB) tables without recomputing them.
            - `-1` : Do not use existing IB tables, force a recomputation.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If `run_htab` or `use_ib_tables` are not integers or not within the accepted values (`0` or `-1`).
        FileNotFoundError: If the specified file does not exist.
        IOError: If there is an error reading or writing the file.

        Example:
        >>> RasPlan.set_geom_preprocessor('/path/to/project.p06', run_htab=-1, use_ib_tables=0)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        if run_htab not in [-1, 0]:
            logging.error("Invalid value for `Run HTab`. Expected `0` or `-1`.")
            raise ValueError("Invalid value for `Run HTab`. Expected `0` or `-1`.")
        if use_ib_tables not in [-1, 0]:
            logging.error("Invalid value for `UNET Use Existing IB Tables`. Expected `0` or `-1`.")
            raise ValueError("Invalid value for `UNET Use Existing IB Tables`. Expected `0` or `-1`.")
        try:
            logging.info(f"Reading the file: {file_path}")
            with open(file_path, 'r') as file:
                lines = file.readlines()
            logging.info("Updating the file with new settings...")
            updated_lines = []
            for line in lines:
                if line.lstrip().startswith("Run HTab="):
                    updated_line = f"Run HTab= {run_htab} \n"
                    updated_lines.append(updated_line)
                    logging.info(f"Updated 'Run HTab' to {run_htab}")
                elif line.lstrip().startswith("UNET Use Existing IB Tables="):
                    updated_line = f"UNET Use Existing IB Tables= {use_ib_tables} \n"
                    updated_lines.append(updated_line)
                    logging.info(f"Updated 'UNET Use Existing IB Tables' to {use_ib_tables}")
                else:
                    updated_lines.append(line)
            logging.info(f"Writing the updated settings back to the file: {file_path}")
            with open(file_path, 'w') as file:
                file.writelines(updated_lines)
            logging.info("File update completed successfully.")
        except FileNotFoundError:
            logging.error(f"The file '{file_path}' does not exist.")
            raise FileNotFoundError(f"The file '{file_path}' does not exist.")
        except IOError as e:
            logging.error(f"An error occurred while reading or writing the file: {e}")
            raise IOError(f"An error occurred while reading or writing the file: {e}")

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    # Get Functions to retrieve file paths for plan, flow, unsteady, geometry and results files

    @staticmethod
    def get_results_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Retrieve the results file path for a given HEC-RAS plan number.

        Args:
            plan_number (str): The HEC-RAS plan number for which to find the results path.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            Optional[str]: The full path to the results file if found and the file exists, or None if not found.

        Raises:
            RuntimeError: If the project is not initialized.

        Example:
            >>> ras_plan = RasPlan()
            >>> results_path = ras_plan.get_results_path('01')
            >>> if results_path:
            ...     print(f"Results file found at: {results_path}")
            ... else:
            ...     print("Results file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the plan dataframe in the ras instance to ensure it is current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        
        # Ensure plan_number is a string
        plan_number = str(plan_number).zfill(2)
        
        # Log the plan dataframe for debugging
        logging.debug("Plan DataFrame:")
        logging.debug(ras_obj.plan_df)
        
        plan_entry = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == plan_number]
        if not plan_entry.empty:
            results_path = plan_entry['HDF_Results_Path'].iloc[0]
            if results_path and Path(results_path).exists():
                logging.info(f"Results file for Plan number {plan_number} exists at: {results_path}")
                return results_path
            else:
                logging.warning(f"Results file for Plan number {plan_number} does not exist.")
                return None
        else:
            logging.warning(f"Plan number {plan_number} not found in the entries.")
            return None

    @staticmethod
    def get_plan_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given plan number.
        
        This method ensures that the latest plan entries are included by refreshing
        the plan dataframe before searching for the requested plan number.
        
        Args:
        plan_number (str): The plan number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        Optional[str]: The full path of the plan file if found, None otherwise.
        
        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> plan_path = ras_plan.get_plan_path('01')
        >>> if plan_path:
        ...     print(f"Plan file found at: {plan_path}")
        ... else:
        ...     print("Plan file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated plan dataframe
        plan_df = ras_obj.get_plan_entries()
        
        plan_path = plan_df[plan_df['plan_number'] == plan_number]
        
        if not plan_path.empty:
            full_path = plan_path['full_path'].iloc[0]
            logging.info(f"Plan file for Plan number {plan_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Plan number {plan_number} not found in the updated plan entries.")
            return None

    @staticmethod
    def get_flow_path(flow_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given flow number.

        Args:
        flow_number (str): The flow number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the flow file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> flow_path = ras_plan.get_flow_path('01')
        >>> if flow_path:
        ...     print(f"Flow file found at: {flow_path}")
        ... else:
        ...     print("Flow file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated flow dataframe
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')
        
        flow_path = ras_obj.flow_df[ras_obj.flow_df['flow_number'] == flow_number]
        if not flow_path.empty:
            full_path = flow_path['full_path'].iloc[0]
            logging.info(f"Flow file for Flow number {flow_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Flow number {flow_number} not found in the updated flow entries.")
            return None

    @staticmethod
    def get_unsteady_path(unsteady_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given unsteady number.

        Args:
        unsteady_number (str): The unsteady number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the unsteady file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> unsteady_path = ras_plan.get_unsteady_path('01')
        >>> if unsteady_path:
        ...     print(f"Unsteady file found at: {unsteady_path}")
        ... else:
        ...     print("Unsteady file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated unsteady dataframe
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')
        
        unsteady_path = ras_obj.unsteady_df[ras_obj.unsteady_df['unsteady_number'] == unsteady_number]
        if not unsteady_path.empty:
            full_path = unsteady_path['full_path'].iloc[0]
            logging.info(f"Unsteady file for Unsteady number {unsteady_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Unsteady number {unsteady_number} not found in the updated unsteady entries.")
            return None

    @staticmethod
    def get_geom_path(geom_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given geometry number.

        Args:
        geom_number (str): The geometry number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the geometry file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> geom_path = ras_plan.get_geom_path('01')
        >>> if geom_path:
        ...     print(f"Geometry file found at: {geom_path}")
        ... else:
        ...     print("Geometry file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated geom dataframe
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')
        
        geom_path = ras_obj.geom_df[ras_obj.geom_df['geom_number'] == geom_number]
        if not geom_path.empty:
            full_path = geom_path['full_path'].iloc[0]
            logging.info(f"Geometry file for Geom number {geom_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Geometry number {geom_number} not found in the updated geometry entries.")
            return None

    # Clone Functions to copy unsteady, flow, and geometry files from templates

    @staticmethod
    def clone_plan(template_plan, new_plan_shortid=None, ras_object=None):
        """
        Create a new plan file based on a template and update the project file.
        
        Parameters:
        template_plan (str): Plan number to use as template (e.g., '01')
        new_plan_shortid (str, optional): New short identifier for the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New plan number
        
        Example:
        >>> ras_plan = RasPlan()
        >>> new_plan_number = ras_plan.clone_plan('01', new_plan_shortid='New Plan')
        >>> print(f"New plan created with number: {new_plan_number}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update plan entries without reinitializing the entire project
        ras_obj.plan_df = ras_obj.get_prj_entries('Plan')

        new_plan_num = RasPlan.get_next_number(ras_obj.plan_df['plan_number'])
        template_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{template_plan}"
        new_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{new_plan_num}"
        
        if not template_plan_path.exists():
            logging.error(f"Template plan file '{template_plan_path}' does not exist.")
            raise FileNotFoundError(f"Template plan file '{template_plan_path}' does not exist.")

        shutil.copy(template_plan_path, new_plan_path)
        logging.info(f"Copied {template_plan_path} to {new_plan_path}")

        try:
            with open(new_plan_path, 'r') as f:
                plan_lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"New plan file not found after copying: {new_plan_path}")
            raise

        shortid_pattern = re.compile(r'^Short Identifier=(.*)$', re.IGNORECASE)
        for i, line in enumerate(plan_lines):
            match = shortid_pattern.match(line.strip())
            if match:
                current_shortid = match.group(1)
                if new_plan_shortid is None:
                    new_shortid = (current_shortid + "_copy")[:24]
                else:
                    new_shortid = new_plan_shortid[:24]
                plan_lines[i] = f"Short Identifier={new_shortid}\n"
                logging.info(f"Updated 'Short Identifier' to '{new_shortid}' in {new_plan_path}")
                break

        try:
            with open(new_plan_path, 'w') as f:
                f.writelines(plan_lines)
            logging.info(f"Updated short identifier in {new_plan_path}")
        except IOError as e:
            logging.error(f"Failed to write updated short identifier to {new_plan_path}: {e}")
            raise

        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Plan File entry line
        new_plan_line = f"Plan File=p{new_plan_num}\n"

        # Find the correct insertion point for the new Plan File entry
        plan_file_pattern = re.compile(r'^Plan File=p(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = plan_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_plan_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_plan_line)
            logging.info(f"Inserted new plan line at index {insertion_index}")
        else:
            # Try to insert after the last Plan File entry
            plan_indices = [i for i, line in enumerate(lines) if plan_file_pattern.match(line.strip())]
            if plan_indices:
                last_plan_index = plan_indices[-1]
                lines.insert(last_plan_index + 1, new_plan_line)
                logging.info(f"Inserted new plan line after index {last_plan_index}")
            else:
                # Append at the end if no Plan File entries exist
                lines.append(new_plan_line)
                logging.info(f"Appended new plan line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new plan p{new_plan_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_plan = new_plan_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return new_plan

    @staticmethod
    def clone_unsteady(template_unsteady, ras_object=None):
        """
        Copy unsteady flow files from a template, find the next unsteady number,
        and update the project file accordingly.

        Parameters:
        template_unsteady (str): Unsteady flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        str: New unsteady flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_unsteady_num = ras_plan.clone_unsteady('01')
        >>> print(f"New unsteady flow file created: u{new_unsteady_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update unsteady entries without reinitializing the entire project
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')

        new_unsteady_num = RasPlan.get_next_number(ras_obj.unsteady_df['unsteady_number'])
        template_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}"
        new_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}"

        if not template_unsteady_path.exists():
            logging.error(f"Template unsteady file '{template_unsteady_path}' does not exist.")
            raise FileNotFoundError(f"Template unsteady file '{template_unsteady_path}' does not exist.")

        shutil.copy(template_unsteady_path, new_unsteady_path)
        logging.info(f"Copied {template_unsteady_path} to {new_unsteady_path}")

        # Copy the corresponding .hdf file if it exists
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}.hdf"
        if template_hdf_path.exists():
            shutil.copy(template_hdf_path, new_hdf_path)
            logging.info(f"Copied {template_hdf_path} to {new_hdf_path}")
        else:
            logging.warning(f"No corresponding .hdf file found for '{template_unsteady_path}'. Skipping '.hdf' copy.")

        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Unsteady Flow File entry line
        new_unsteady_line = f"Unsteady File=u{new_unsteady_num}\n"

        # Find the correct insertion point for the new Unsteady Flow File entry
        unsteady_file_pattern = re.compile(r'^Unsteady File=u(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = unsteady_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_unsteady_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_unsteady_line)
            logging.info(f"Inserted new unsteady flow line at index {insertion_index}")
        else:
            # Try to insert after the last Unsteady Flow File entry
            unsteady_indices = [i for i, line in enumerate(lines) if unsteady_file_pattern.match(line.strip())]
            if unsteady_indices:
                last_unsteady_index = unsteady_indices[-1]
                lines.insert(last_unsteady_index + 1, new_unsteady_line)
                logging.info(f"Inserted new unsteady flow line after index {last_unsteady_index}")
            else:
                # Append at the end if no Unsteady Flow File entries exist
                lines.append(new_unsteady_line)
                logging.info(f"Appended new unsteady flow line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new unsteady flow file u{new_unsteady_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_unsteady = new_unsteady_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)
        
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        return new_unsteady

    @staticmethod
    def clone_steady(template_flow, ras_object=None):
        """
        Copy steady flow files from a template, find the next flow number,
        and update the project file accordingly.
        
        Parameters:
        template_flow (str): Flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_flow_num = ras_plan.clone_steady('01')
        >>> print(f"New steady flow file created: f{new_flow_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update flow entries without reinitializing the entire project
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')

        new_flow_num = RasPlan.get_next_number(ras_obj.flow_df['flow_number'])
        template_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{template_flow}"
        new_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{new_flow_num}"

        if not template_flow_path.exists():
            logging.error(f"Template steady flow file '{template_flow_path}' does not exist.")
            raise FileNotFoundError(f"Template steady flow file '{template_flow_path}' does not exist.")

        shutil.copy(template_flow_path, new_flow_path)
        logging.info(f"Copied {template_flow_path} to {new_flow_path}")

        # Read the contents of the project file
        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Steady Flow File entry line
        new_flow_line = f"Flow File=f{new_flow_num}\n"

        # Find the correct insertion point for the new Steady Flow File entry
        flow_file_pattern = re.compile(r'^Flow File=f(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = flow_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_flow_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_flow_line)
            logging.info(f"Inserted new steady flow line at index {insertion_index}")
        else:
            # Try to insert after the last Steady Flow File entry
            flow_indices = [i for i, line in enumerate(lines) if flow_file_pattern.match(line.strip())]
            if flow_indices:
                last_flow_index = flow_indices[-1]
                lines.insert(last_flow_index + 1, new_flow_line)
                logging.info(f"Inserted new steady flow line after index {last_flow_index}")
            else:
                # Append at the end if no Steady Flow File entries exist
                lines.append(new_flow_line)
                logging.info(f"Appended new steady flow line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new steady flow file f{new_flow_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_steady = new_flow_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)
        
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        return new_steady

    @staticmethod
    def clone_geom(template_geom, ras_object=None):
        """
        Copy geometry files from a template, find the next geometry number,
        and update the project file accordingly.
        
        Parameters:
        template_geom (str): Geometry number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New geometry number (e.g., '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update geometry entries without reinitializing the entire project
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')
        logging.debug(f"Updated geometry entries:\n{ras_obj.geom_df}")

        template_geom_filename = f"{ras_obj.project_name}.g{template_geom}"
        template_geom_path = ras_obj.project_folder / template_geom_filename

        if not template_geom_path.is_file():
            logging.error(f"Template geometry file '{template_geom_path}' does not exist.")
            raise FileNotFoundError(f"Template geometry file '{template_geom_path}' does not exist.")

        next_geom_number = RasPlan.get_next_number(ras_obj.geom_df['geom_number'])

        new_geom_filename = f"{ras_obj.project_name}.g{next_geom_number}"
        new_geom_path = ras_obj.project_folder / new_geom_filename

        shutil.copyfile(template_geom_path, new_geom_path)
        logging.info(f"Copied '{template_geom_path}' to '{new_geom_path}'.")

        # Handle HDF file copy
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{template_geom}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{next_geom_number}.hdf"
        if template_hdf_path.is_file():
            shutil.copyfile(template_hdf_path, new_hdf_path)
            logging.info(f"Copied '{template_hdf_path}' to '{new_hdf_path}'.")
        else:
            logging.warning(f"Template geometry HDF file '{template_hdf_path}' does not exist. Skipping '.hdf' copy.")

        try:
            with open(ras_obj.prj_file, 'r') as file:
                lines = file.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Geometry File entry line
        new_geom_line = f"Geom File=g{next_geom_number}\n"

        # Find the correct insertion point for the new Geometry File entry
        geom_file_pattern = re.compile(r'^Geom File=g(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = geom_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(next_geom_number):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_geom_line)
            logging.info(f"Inserted new geometry line at index {insertion_index}")
        else:
            # Try to insert after the last Geometry File entry
            geom_indices = [i for i, line in enumerate(lines) if geom_file_pattern.match(line.strip())]
            if geom_indices:
                last_geom_index = geom_indices[-1]
                lines.insert(last_geom_index + 1, new_geom_line)
                logging.info(f"Inserted new geometry line after index {last_geom_index}")
            else:
                # Append at the end if no Geometry File entries exist
                lines.append(new_geom_line)
                logging.info(f"Appended new geometry line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as file:
                file.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new geometry file g{next_geom_number}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_geom = next_geom_number
        
        # Update all dataframes in the ras object
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        logging.debug(f"Updated geometry entries:\n{ras_obj.geom_df}")

        return new_geom

    @staticmethod
    def get_next_number(existing_numbers):
        """
        Determine the next available number from a list of existing numbers.
        
        Parameters:
        existing_numbers (list): List of existing numbers as strings
        
        Returns:
        str: Next available number as a zero-padded string
        
        Example:
        >>> existing_numbers = ['01', '02', '04']
        >>> RasPlan.get_next_number(existing_numbers)
        '03'
        >>> existing_numbers = ['01', '02', '03']
        >>> RasPlan.get_next_number(existing_numbers)
        '04'
        """
        existing_numbers = sorted(int(num) for num in existing_numbers)
        next_number = 1
        for num in existing_numbers:
            if num == next_number:
                next_number += 1
            else:
                break
        return f"{next_number:02d}"


    @staticmethod
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading the plan file

        Available keys and their expected types:
        - 'description' (str): Plan description
        - 'computation_interval' (str): Time value for computational time step (e.g., '5SEC', '2MIN')
        - 'dss_file' (str): Name of the DSS file used
        - 'flow_file' (str): Name of the flow input file
        - 'friction_slope_method' (int): Method selection for friction slope (e.g., 1, 2)
        - 'geom_file' (str): Name of the geometry input file
        - 'mapping_interval' (str): Time interval for mapping output
        - 'plan_file' (str): Name of the plan file
        - 'plan_title' (str): Title of the simulation plan
        - 'program_version' (str): Version number of HEC-RAS
        - 'run_htab' (int): Flag to run HTab module (-1 or 1)
        - 'run_post_process' (int): Flag to run post-processing (-1 or 1)
        - 'run_sediment' (int): Flag to run sediment transport module (0 or 1)
        - 'run_unet' (int): Flag to run unsteady network module (-1 or 1)
        - 'run_wqnet' (int): Flag to run water quality module (0 or 1)
        - 'short_identifier' (str): Short name or ID for the plan
        - 'simulation_date' (str): Start and end dates/times for simulation
        - 'unet_d1_cores' (int): Number of cores used in 1D calculations
        - 'unet_use_existing_ib_tables' (int): Flag for using existing internal boundary tables (-1, 0, or 1)
        - 'unet_1d_methodology' (str): 1D calculation methodology
        - 'unet_d2_solver_type' (str): 2D solver type
        - 'unet_d2_name' (str): Name of the 2D area
        - 'run_rasmapper' (int): Flag to run RASMapper for floodplain mapping (-1 for off, 0 for on)

        Example:
        >>> computation_interval = RasPlan.get_plan_value("01", "computation_interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name', 'run_rasmapper'
        }

        if key not in valid_keys:
            logging.warning(f"Unknown key: {key}. Valid keys are: {', '.join(valid_keys)}\n Add more keys and explanations in get_plan_value() as needed.")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object=ras_obj)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'description':
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key.replace('_', ' ').title()}=(.*)"
            match = re.search(pattern, content)
            if match:
                return match.group(1).strip()
            else:
                logging.error(f"Key '{key}' not found in the plan file.")
                return None

    @staticmethod
    def update_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        value: Any,
        ras_object=None
    ) -> None:
        """
        Update a specific key-value pair in a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to update in the plan file
        value (Any): The new value to set for the key
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading or writing the plan file

        Note: See the docstring of get_plan_value for a full list of available keys and their types.

        Example:
        >>> RasPlan.update_plan_value("01", "computation_interval", "10SEC")
        >>> RasPlan.update_plan_value("/path/to/plan.p01", "run_htab", 1)
        >>> RasPlan.update_plan_value("01", "run_rasmapper", 0)  # Turn on Floodplain Mapping
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name', 'run_rasmapper'
        }

        if key not in valid_keys:
            logging.warning(f"Unknown key: {key}. Valid keys are: {', '.join(valid_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                lines = file.readlines()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        # Special handling for description
        if key == 'description':
            description_start = None
            description_end = None
            for i, line in enumerate(lines):
                if line.strip() == 'Begin DESCRIPTION':
                    description_start = i
                elif line.strip() == 'END DESCRIPTION':
                    description_end = i
                    break
            if description_start is not None and description_end is not None:
                lines[description_start+1:description_end] = [f"{value}\n"]
            else:
                lines.append(f"Begin DESCRIPTION\n{value}\nEND DESCRIPTION\n")
        else:
            # For other keys
            pattern = f"{key.replace('_', ' ').title()}="
            updated = False
            for i, line in enumerate(lines):
                if line.startswith(pattern):
                    lines[i] = f"{pattern}{value}\n"
                    updated = True
                    break
            if not updated:
                logging.error(f"Key '{key}' not found in the plan file.")
                return

        try:
            with open(plan_file_path, 'w') as file:
                file.writelines(lines)
            logging.info(f"Updated {key} in plan file: {plan_file_path}")
        except IOError as e:
            logging.error(f"Error writing to plan file {plan_file_path}: {e}")
            raise

        # Refresh RasPrj dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
==================================================

File: c:\GH\ras-commander\ras_commander\RasPrj.py
==================================================
"""RasPrj.py

This module provides a class for managing HEC-RAS projects.

Classes:
    RasPrj: A class for managing HEC-RAS projects.

Functions:
    init_ras_project: Initialize a RAS project.
    get_ras_exe: Determine the HEC-RAS executable path based on the input.

DEVELOPER NOTE:
This class is used to initialize a RAS project and is used in conjunction with the RasCmdr class to manage the execution of RAS plans.
By default, the RasPrj class is initialized with the global 'ras' object.
However, you can create multiple RasPrj instances to manage multiple projects.
Do not mix and match global 'ras' object instances and custom instances of RasPrj - it will cause errors.
"""

# Example Terminal Output for RasPrj Functions:
# logging.info("----- INSERT TEXT HERE -----")
import re
from pathlib import Path
import pandas as pd
import logging
from typing import Union, Any, List, Dict, Tuple


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class RasPrj:
    def __init__(self):
        self.initialized = False
        self.boundaries_df = None  # New attribute to store boundary conditions

    def initialize(self, project_folder, ras_exe_path):
        """
        Initialize a RasPrj instance.

        This method sets up the RasPrj instance with the given project folder and RAS executable path.
        It finds the project file, loads project data, sets the initialization flag, and now also
        extracts boundary conditions.

        Args:
            project_folder (str or Path): Path to the HEC-RAS project folder.
            ras_exe_path (str or Path): Path to the HEC-RAS executable.

        Raises:
            ValueError: If no HEC-RAS project file is found in the specified folder.

        Note:
            This method is intended for internal use. External users should use the init_ras_project function instead.
        """
        self.project_folder = Path(project_folder)
        self.prj_file = self.find_ras_prj(self.project_folder)
        if self.prj_file is None:
            logging.error(f"No HEC-RAS project file found in {self.project_folder}")
            raise ValueError(f"No HEC-RAS project file found in {self.project_folder}")
        self.project_name = Path(self.prj_file).stem
        self.ras_exe_path = ras_exe_path
        self._load_project_data()
        self.boundaries_df = self.get_boundary_conditions()  # Extract boundary conditions
        self.initialized = True
        logging.info(f"Initialization complete for project: {self.project_name}")
        logging.info(f"Plan entries: {len(self.plan_df)}, Flow entries: {len(self.flow_df)}, "
                     f"Unsteady entries: {len(self.unsteady_df)}, Geometry entries: {len(self.geom_df)}, "
                     f"Boundary conditions: {len(self.boundaries_df)}")

    def _load_project_data(self):
        """
        Load project data from the HEC-RAS project file.

        This method initializes DataFrames for plan, flow, unsteady, and geometry entries
        by calling the _get_prj_entries method for each entry type.
        """
        # Initialize DataFrames
        self.plan_df = self._get_prj_entries('Plan')
        self.flow_df = self._get_prj_entries('Flow')
        self.unsteady_df = self._get_prj_entries('Unsteady')
        self.geom_df = self._get_prj_entries('Geom')

    def _parse_plan_file(self, plan_file_path):
        """
        Parse a plan file and extract critical information.
        
        Args:
            plan_file_path (Path): Path to the plan file.
        
        Returns:
            dict: Dictionary containing extracted plan information.
        """
        plan_info = {}
        with open(plan_file_path, 'r') as file:
            content = file.read()
            
            # Extract description
            description_match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            if description_match:
                plan_info['description'] = description_match.group(1).strip()
            
            # Extract other critical information
            patterns = {
                'computation_interval': r'Computation Interval=(.+)',
                'dss_file': r'DSS File=(.+)',
                'flow_file': r'Flow File=(.+)',
                'friction_slope_method': r'Friction Slope Method=(.+)',
                'geom_file': r'Geom File=(.+)',
                'mapping_interval': r'Mapping Interval=(.+)',
                'plan_title': r'Plan Title=(.+)',
                'program_version': r'Program Version=(.+)',
                'run_htab': r'Run HTab=(.+)',
                'run_post_process': r'Run PostProcess=(.+)',
                'run_sediment': r'Run Sediment=(.+)',
                'run_unet': r'Run UNet=(.+)',
                'run_wqnet': r'Run WQNet=(.+)',
                'short_identifier': r'Short Identifier=(.+)',
                'simulation_date': r'Simulation Date=(.+)',
                'unet_d1_cores': r'UNET D1 Cores=(.+)',
                'unet_use_existing_ib_tables': r'UNET Use Existing IB Tables=(.+)',
                'unet_1d_methodology': r'UNET 1D Methodology=(.+)',
                'unet_d2_solver_type': r'UNET D2 SolverType=(.+)',
                'unet_d2_name': r'UNET D2 Name=(.+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    plan_info[key] = match.group(1).strip()
        
        return plan_info
    
    def _get_prj_entries(self, entry_type):
        """
        Extract entries of a specific type from the HEC-RAS project file.

        Args:
            entry_type (str): The type of entry to extract (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the extracted entries.

        Note:
            This method reads the project file and extracts entries matching the specified type.
            For 'Unsteady' entries, it parses additional information from the unsteady file.
        """
        entries = []
        pattern = re.compile(rf"{entry_type} File=(\w+)")

        try:
            with open(self.prj_file, 'r') as file:
                for line in file:
                    match = pattern.match(line.strip())
                    if match:
                        file_name = match.group(1)
                        full_path = str(self.project_folder / f"{self.project_name}.{file_name}")
                        entry = {
                            f'{entry_type.lower()}_number': file_name[1:],
                            'full_path': full_path
                        }

                        if entry_type == 'Plan':
                            plan_info = self._parse_plan_file(Path(full_path))
                            entry.update(plan_info)
                            
                            # Add HDF results path if it exists
                            hdf_results_path = self.project_folder / f"{self.project_name}.p{file_name[1:]}.hdf"
                            entry['HDF_Results_Path'] = str(hdf_results_path) if hdf_results_path.exists() else None

                        if entry_type == 'Unsteady':
                            unsteady_info = self._parse_unsteady_file(Path(full_path))
                            entry.update(unsteady_info)

                        entries.append(entry)
        except Exception as e:
            logging.exception(f"Failed to read project file {self.prj_file}: {e}")
            raise

        return pd.DataFrame(entries)

    def _parse_unsteady_file(self, unsteady_file_path):
        """
        Parse an unsteady flow file and extract critical information.
        
        Args:
            unsteady_file_path (Path): Path to the unsteady flow file.
        
        Returns:
            dict: Dictionary containing extracted unsteady flow information.
        """
        unsteady_info = {}
        with open(unsteady_file_path, 'r') as file:
            content = file.read()
            
            # Extract critical information
            patterns = {
                'flow_title': r'Flow Title=(.+)',
                'program_version': r'Program Version=(.+)',
                'use_restart': r'Use Restart=(.+)',
                'precipitation_mode': r'Precipitation Mode=(.+)',
                'wind_mode': r'Wind Mode=(.+)',
                'precipitation_bc_mode': r'Met BC=Precipitation\|Mode=(.+)',
                'evapotranspiration_bc_mode': r'Met BC=Evapotranspiration\|Mode=(.+)',
                'precipitation_expanded_view': r'Met BC=Precipitation\|Expanded View=(.+)',
                'precipitation_constant_units': r'Met BC=Precipitation\|Constant Units=(.+)',
                'precipitation_gridded_source': r'Met BC=Precipitation\|Gridded Source=(.+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    unsteady_info[key] = match.group(1).strip()
        
        return unsteady_info

    @property
    def is_initialized(self):
        """
        Check if the RasPrj instance has been initialized.

        Returns:
            bool: True if the instance has been initialized, False otherwise.
        """
        return self.initialized

    def check_initialized(self):
        """
        Ensure that the RasPrj instance has been initialized.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        if not self.initialized:
            logging.error("Project not initialized. Call init_ras_project() first.")
            raise RuntimeError("Project not initialized. Call init_ras_project() first.")

    @staticmethod
    def find_ras_prj(folder_path):
        """
        Find the appropriate HEC-RAS project file (.prj) in the given folder.
        
        Parameters:
        folder_path (str or Path): Path to the folder containing HEC-RAS files.
        
        Returns:
        Path: The full path of the selected .prj file or None if no suitable file is found.
        """
        folder_path = Path(folder_path)
        prj_files = list(folder_path.glob("*.prj"))
        rasmap_files = list(folder_path.glob("*.rasmap"))
        if len(prj_files) == 1:
            logging.info(f"Single .prj file found: {prj_files[0]}")
            return prj_files[0].resolve()
        if len(prj_files) > 1:
            if len(rasmap_files) == 1:
                base_filename = rasmap_files[0].stem
                prj_file = folder_path / f"{base_filename}.prj"
                if prj_file.exists():
                    logging.info(f"Matched .prj file based on .rasmap: {prj_file}")
                    return prj_file.resolve()
            for prj_file in prj_files:
                try:
                    with open(prj_file, 'r') as file:
                        content = file.read()
                        if "Proj Title=" in content:
                            logging.info(f".prj file with 'Proj Title=' found: {prj_file}")
                            return prj_file.resolve()
                except Exception as e:
                    logging.warning(f"Failed to read .prj file {prj_file}: {e}")
                    continue
        logging.warning("No suitable .prj file found after all checks.")
        return None

    def get_project_name(self):
        """
        Get the name of the HEC-RAS project.

        Returns:
            str: The name of the project.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self.project_name

    def get_prj_entries(self, entry_type):
        """
        Get entries of a specific type from the HEC-RAS project.

        Args:
            entry_type (str): The type of entry to retrieve (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the requested entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries(entry_type)

    def get_plan_entries(self):
        """
        Get all plan entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all plan entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Plan')

    def get_flow_entries(self):
        """
        Get all flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Flow')

    def get_unsteady_entries(self):
        """
        Get all unsteady flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all unsteady flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Unsteady')

    def get_geom_entries(self):
        """
        Get all geometry entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all geometry entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Geom')
    
    def get_hdf_entries(self):
        """
        Get HDF entries for plans that have results.
        
        Returns:
        pd.DataFrame: A DataFrame containing plan entries with HDF results.
                  Returns an empty DataFrame if no HDF entries are found.
        """
        self.check_initialized()
        
        # Filter the plan_df to include only entries with existing HDF results
        hdf_entries = self.plan_df[self.plan_df['HDF_Results_Path'].notna()].copy()
        
        # If no HDF entries are found, log the information
        if hdf_entries.empty:
            logging.info("No HDF entries found.")
            return pd.DataFrame(columns=self.plan_df.columns)
        
        logging.info(f"Found {len(hdf_entries)} HDF entries.")
        return hdf_entries
    
    def print_data(self):
        """Print all RAS Object data for this instance."""
        self.check_initialized()
        logging.info(f"--- Data for {self.project_name} ---")
        logging.info(f"Project folder: {self.project_folder}")
        logging.info(f"PRJ file: {self.prj_file}")
        logging.info(f"HEC-RAS executable: {self.ras_exe_path}")
        logging.info("Plan files:")
        logging.info(f"\n{self.plan_df}")
        logging.info("Flow files:")
        logging.info(f"\n{self.flow_df}")
        logging.info("Unsteady flow files:")
        logging.info(f"\n{self.unsteady_df}")
        logging.info("Geometry files:")
        logging.info(f"\n{self.geom_df}")
        logging.info("HDF entries:")
        logging.info(f"\n{self.get_hdf_entries()}")
        logging.info("Boundary conditions:")
        logging.info(f"\n{self.boundaries_df}")
        logging.info("----------------------------")


    @staticmethod
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If an invalid key is provided or if the plan file is not found
        IOError: If there's an error reading the plan file

        Note: See the docstring of update_plan_file for a full list of available keys and their types.

        Example:
        >>> computation_interval = RasUtils.get_plan_value("01", "computation_interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name'
        }

        if key not in valid_keys:
            raise ValueError(f"Invalid key: {key}. Valid keys are: {', '.join(valid_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'description':
            import re
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key.replace('_', ' ').title()}=(.*)"
            import re
            match = re.search(pattern, content)
            return match.group(1).strip() if match else None

    def get_boundary_conditions(self) -> pd.DataFrame:
        """
        Extract boundary conditions from unsteady flow files and create a DataFrame.

        This method parses unsteady flow files to extract boundary condition information.
        It creates a DataFrame with structured data for known boundary condition types
        and parameters, and associates this information with the corresponding unsteady flow file.

        Note:
        Any lines in the boundary condition blocks that are not explicitly parsed and
        incorporated into the DataFrame are captured in a multi-line string. This string
        is logged at the DEBUG level for each boundary condition. This feature is crucial
        for developers incorporating new boundary condition types or parameters, as it
        allows them to see what information might be missing from the current parsing logic.

        Returns:
            pd.DataFrame: A DataFrame containing detailed boundary condition information,
                          linked to the unsteady flow files.

        Usage:
            To see the unparsed lines, set the logging level to DEBUG before calling this method:
            
            import logging
            logging.getLogger().setLevel(logging.DEBUG)
            
            boundaries_df = ras_project.get_boundary_conditions()
        """
        boundary_data = []
        
        for _, row in self.unsteady_df.iterrows():
            unsteady_file_path = row['full_path']
            unsteady_number = row['unsteady_number']
            
            with open(unsteady_file_path, 'r') as file:
                content = file.read()
                
            bc_blocks = re.split(r'(?=Boundary Location=)', content)[1:]
            
            for i, block in enumerate(bc_blocks, 1):
                bc_info, unparsed_lines = self._parse_boundary_condition(block, unsteady_number, i)
                boundary_data.append(bc_info)
                
                if unparsed_lines:
                    logging.debug(f"Unparsed lines for boundary condition {i} in unsteady file {unsteady_number}:\n{unparsed_lines}")
        
        boundaries_df = pd.DataFrame(boundary_data)
        
        # Merge with unsteady_df to get relevant unsteady flow file information
        merged_df = pd.merge(boundaries_df, self.unsteady_df, 
                             left_on='unsteady_number', right_on='unsteady_number', how='left')
        
        return merged_df

    def _parse_boundary_condition(self, block: str, unsteady_number: str, bc_number: int) -> Tuple[Dict, str]:
        lines = block.split('\n')
        bc_info = {
            'unsteady_number': unsteady_number,
            'boundary_condition_number': bc_number
        }
        
        parsed_lines = set()
        
        # Parse Boundary Location
        boundary_location = lines[0].split('=')[1].strip()
        fields = [field.strip() for field in boundary_location.split(',')]
        bc_info.update({
            'river_reach_name': fields[0] if len(fields) > 0 else '',
            'river_station': fields[1] if len(fields) > 1 else '',
            'storage_area_name': fields[2] if len(fields) > 2 else '',
            'pump_station_name': fields[3] if len(fields) > 3 else ''
        })
        parsed_lines.add(0)
        
        # Determine BC Type
        bc_types = {
            'Flow Hydrograph=': 'Flow Hydrograph',
            'Lateral Inflow Hydrograph=': 'Lateral Inflow Hydrograph',
            'Uniform Lateral Inflow Hydrograph=': 'Uniform Lateral Inflow Hydrograph',
            'Stage Hydrograph=': 'Stage Hydrograph',
            'Friction Slope=': 'Normal Depth',
            'Gate Name=': 'Gate Opening'
        }
        
        bc_info['bc_type'] = 'Unknown'
        bc_info['hydrograph_type'] = None
        for i, line in enumerate(lines[1:], 1):
            for key, bc_type in bc_types.items():
                if line.startswith(key):
                    bc_info['bc_type'] = bc_type
                    if 'Hydrograph' in bc_type:
                        bc_info['hydrograph_type'] = bc_type
                    parsed_lines.add(i)
                    break
            if bc_info['bc_type'] != 'Unknown':
                break
        
        # Parse other fields
        known_fields = ['Interval', 'DSS Path', 'Use DSS', 'Use Fixed Start Time', 'Fixed Start Date/Time',
                        'Is Critical Boundary', 'Critical Boundary Flow', 'DSS File']
        for i, line in enumerate(lines):
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                if key in known_fields:
                    bc_info[key] = value.strip()
                    parsed_lines.add(i)
        
        # Handle hydrograph values
        bc_info['hydrograph_num_values'] = 0
        if bc_info['hydrograph_type']:
            hydrograph_key = f"{bc_info['hydrograph_type']}="
            hydrograph_line = next((line for i, line in enumerate(lines) if line.startswith(hydrograph_key)), None)
            if hydrograph_line:
                hydrograph_index = lines.index(hydrograph_line)
                values_count = int(hydrograph_line.split('=')[1].strip())
                bc_info['hydrograph_num_values'] = values_count
                if values_count > 0:
                    values = ' '.join(lines[hydrograph_index + 1:]).split()[:values_count]
                    bc_info['hydrograph_values'] = values
                    parsed_lines.update(range(hydrograph_index, hydrograph_index + (values_count // 5) + 2))
        
        # Collect unparsed lines
        unparsed_lines = '\n'.join(line for i, line in enumerate(lines) if i not in parsed_lines and line.strip())
        
        return bc_info, unparsed_lines


# Create a global instance named 'ras'
ras = RasPrj()

# END OF CLASS DEFINITION




# START OF FUNCTION DEFINITIONS


def init_ras_project(ras_project_folder, ras_version, ras_instance=None):
    """
    Initialize a RAS project.

    USE THIS FUNCTION TO INITIALIZE A RAS PROJECT, NOT THE INITIALIZE METHOD OF THE RasPrj CLASS.
    The initialize method of the RasPrj class only modifies the global 'ras' object.

    This function creates or initializes a RasPrj instance, providing a safer and more
    flexible interface than directly using the 'initialize' method.

    Parameters:
    -----------
    ras_project_folder : str
        The path to the RAS project folder.
    ras_version : str
        The version of RAS to use (e.g., "6.5").
        The version can also be a full path to the Ras.exe file. (Useful when calling ras objects for folder copies.)
    ras_instance : RasPrj, optional
        An instance of RasPrj to initialize. If None, the global 'ras' instance is used.

    Returns:
    --------
    RasPrj
        An initialized RasPrj instance.

    Usage:
    ------
    1. For general use with a single project:
        init_ras_project("/path/to/project", "6.5")
        # Use the global 'ras' object after initialization

    2. For managing multiple projects:
        project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
        project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

    Notes:
    ------
    - This function is preferred over directly calling the 'initialize' method.
    - It supports both the global 'ras' object and custom instances.
    - Be consistent in your approach: stick to either the global 'ras' object
      or custom instances throughout your script or application.
    - Document your choice of approach clearly in your code.

    Warnings:
    ---------
    Avoid mixing use of the global 'ras' object and custom instances to prevent
    confusion and potential bugs.
    """
    logging.info(f"Initializing project in folder: {ras_project_folder}")
    logging.info(f"Using ras_instance with id: {id(ras_instance)}")
    


    if not Path(ras_project_folder).exists():
        logging.error(f"The specified RAS project folder does not exist: {ras_project_folder}. Please check the path and try again.")
        raise FileNotFoundError(f"The specified RAS project folder does not exist: {ras_project_folder}. Please check the path and try again.")

    ras_exe_path = get_ras_exe(ras_version)

    if ras_instance is None:
        logging.info("Initializing global 'ras' object via init_ras_project function.")
        ras_instance = ras
    elif not isinstance(ras_instance, RasPrj):
        logging.error("Provided ras_instance is not an instance of RasPrj.")
        raise TypeError("ras_instance must be an instance of RasPrj or None.")

    # Initialize the RasPrj instance
    ras_instance.initialize(ras_project_folder, ras_exe_path)
    
    logging.info(f"Project initialized. ras_instance project folder: {ras_instance.project_folder}")
    return ras_instance


def get_ras_exe(ras_version):
    """
    Determine the HEC-RAS executable path based on the input.
    
    Args:
    ras_version (str): Either a version number or a full path to the HEC-RAS executable.
    
    Returns:
    str: The full path to the HEC-RAS executable.
    
    Raises:
    ValueError: If the input is neither a valid version number nor a valid file path.
    FileNotFoundError: If the executable file does not exist at the specified or constructed path.
    """
    ras_version_numbers = [
        "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
        "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
        "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
    ]
    
    hecras_path = Path(ras_version)
    
    if hecras_path.is_file() and hecras_path.suffix.lower() == '.exe':
        logging.info(f"HEC-RAS executable found at specified path: {hecras_path}")
        return str(hecras_path)
    
    if ras_version in ras_version_numbers:
        default_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
        if default_path.is_file():
            logging.info(f"HEC-RAS executable found at default path: {default_path}")
            return str(default_path)
        else:
            logging.error(f"HEC-RAS executable not found at the expected path: {default_path}")
            raise FileNotFoundError(f"HEC-RAS executable not found at the expected path: {default_path}")
    
    try:
        version_float = float(ras_version)
        if version_float > max(float(v) for v in ras_version_numbers):
            newer_version_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
            if newer_version_path.is_file():
                logging.info(f"Newer version of HEC-RAS executable found at: {newer_version_path}")
                return str(newer_version_path)
            else:
                logging.error("Newer version of HEC-RAS was specified, but the executable was not found.")
                raise FileNotFoundError(
                    f"Newer version of HEC-RAS was specified. Check the version number or pass the full Ras.exe path as the function argument instead of the version number. The script looked for the executable at: {newer_version_path}"
                )
    except ValueError:
        pass
    
    logging.error(
        f"Invalid HEC-RAS version or path: {ras_version}. "
        f"Please provide a valid version number from {ras_version_numbers} "
        "or a full path to the HEC-RAS executable."
    )
    raise ValueError(
        f"Invalid HEC-RAS version or path: {ras_version}. "
        f"Please provide a valid version number from {ras_version_numbers} "
        "or a full path to the HEC-RAS executable."
    )
    
==================================================

File: c:\GH\ras-commander\ras_commander\RasUnsteady.py
==================================================
"""
Operations for handling unsteady flow files in HEC-RAS projects.
"""
from pathlib import Path
from .RasPrj import ras
import logging
import re

# Configure logging at the module level
logging.basicConfig(
    level=logging.INFO,  # Set to DEBUG for more detailed output
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # Logs to console
        # Uncomment the next line to enable logging to a file
        # logging.FileHandler('ras_unsteady.log')
    ]
)

class RasUnsteady:
    """
    Class for all operations related to HEC-RAS unsteady flow files.
    """
    
    @staticmethod
    def update_unsteady_parameters(unsteady_file, modifications, ras_object=None):
        """
        Modify parameters in an unsteady flow file.
        
        Parameters:
        unsteady_file (str): Full path to the unsteady flow file
        modifications (dict): Dictionary of modifications to apply, where keys are parameter names and values are new values
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Note:
            This function updates the ras object's unsteady dataframe after modifying the unsteady flow file.
        
        Example:
            from ras_commander import RasCmdr
            
            # Initialize RAS project
            ras_cmdr = RasCmdr()
            ras_cmdr.init_ras_project(project_folder, ras_version)
            
            # Update unsteady parameters
            unsteady_file = r"path/to/unsteady_file.u01"
            modifications = {"Parameter1": "NewValue1", "Parameter2": "NewValue2"}
            RasUnsteady.update_unsteady_parameters(unsteady_file, modifications, ras_object=ras_cmdr.ras)
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        unsteady_path = Path(unsteady_file)
        try:
            with open(unsteady_path, 'r') as f:
                lines = f.readlines()
            logging.debug(f"Successfully read unsteady flow file: {unsteady_path}")
        except FileNotFoundError:
            logging.error(f"Unsteady flow file not found: {unsteady_path}")
            raise FileNotFoundError(f"Unsteady flow file not found: {unsteady_path}")
        except PermissionError:
            logging.error(f"Permission denied when reading unsteady flow file: {unsteady_path}")
            raise PermissionError(f"Permission denied when reading unsteady flow file: {unsteady_path}")
        
        updated = False
        for i, line in enumerate(lines):
            for param, new_value in modifications.items():
                if line.startswith(f"{param}="):
                    old_value = line.strip().split('=')[1]
                    lines[i] = f"{param}={new_value}\n"
                    updated = True
                    logging.info(f"Updated {param} from {old_value} to {new_value}")
        
        if updated:
            try:
                with open(unsteady_path, 'w') as f:
                    f.writelines(lines)
                logging.debug(f"Successfully wrote modifications to unsteady flow file: {unsteady_path}")
            except PermissionError:
                logging.error(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
                raise PermissionError(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
            except IOError as e:
                logging.error(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
                raise IOError(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
            logging.info(f"Applied modifications to {unsteady_file}")
        else:
            logging.warning(f"No matching parameters found in {unsteady_file}")
    
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

==================================================

File: c:\GH\ras-commander\ras_commander\RasUtils.py
==================================================
"""
Utility functions for the ras-commander library.
"""
import os
import shutil
import logging
import time
from pathlib import Path
from .RasPrj import ras
from typing import Union, Optional, Dict
import pandas as pd
import numpy as np

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class RasUtils:
    """
    A class containing utility functions for the ras-commander library.
    When integrating new functions that do not clearly fit into other classes, add them here.
    """

    @staticmethod
    def create_backup(file_path: Path, backup_suffix: str = "_backup", ras_object=None) -> Path:
        """
        Create a backup of the specified file.

        Parameters:
        file_path (Path): Path to the file to be backed up
        backup_suffix (str): Suffix to append to the backup file name
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the created backup file

        Example:
        >>> backup_path = RasUtils.create_backup(Path("project.prj"))
        >>> print(f"Backup created at: {backup_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        original_path = Path(file_path)
        backup_path = original_path.with_name(f"{original_path.stem}{backup_suffix}{original_path.suffix}")
        try:
            shutil.copy2(original_path, backup_path)
            logging.info(f"Backup created: {backup_path}")
        except Exception as e:
            logging.error(f"Failed to create backup for {original_path}: {e}")
            raise
        return backup_path

    @staticmethod
    def restore_from_backup(backup_path: Path, remove_backup: bool = True, ras_object=None) -> Path:
        """
        Restore a file from its backup.

        Parameters:
        backup_path (Path): Path to the backup file
        remove_backup (bool): Whether to remove the backup file after restoration
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the restored file

        Example:
        >>> restored_path = RasUtils.restore_from_backup(Path("project_backup.prj"))
        >>> print(f"File restored to: {restored_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        backup_path = Path(backup_path)
        if '_backup' not in backup_path.stem:
            logging.error(f"Backup suffix '_backup' not found in {backup_path.name}")
            raise ValueError(f"Backup suffix '_backup' not found in {backup_path.name}")
        
        original_stem = backup_path.stem.rsplit('_backup', 1)[0]
        original_path = backup_path.with_name(f"{original_stem}{backup_path.suffix}")
        try:
            shutil.copy2(backup_path, original_path)
            logging.info(f"File restored: {original_path}")
            if remove_backup:
                backup_path.unlink()
                logging.info(f"Backup removed: {backup_path}")
        except Exception as e:
            logging.error(f"Failed to restore from backup {backup_path}: {e}")
            raise
        return original_path

    @staticmethod
    def create_directory(directory_path: Path, ras_object=None) -> Path:
        """
        Ensure that a directory exists, creating it if necessary.

        Parameters:
        directory_path (Path): Path to the directory
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the ensured directory

        Example:
        >>> ensured_dir = RasUtils.create_directory(Path("output"))
        >>> print(f"Directory ensured: {ensured_dir}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(directory_path)
        try:
            path.mkdir(parents=True, exist_ok=True)
            logging.info(f"Directory ensured: {path}")
        except Exception as e:
            logging.error(f"Failed to create directory {path}: {e}")
            raise
        return path

    @staticmethod
    def find_files_by_extension(extension: str, ras_object=None) -> list:
        """
        List all files in the project directory with a specific extension.

        Parameters:
        extension (str): File extension to filter (e.g., '.prj')
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        list: List of file paths matching the extension

        Example:
        >>> prj_files = RasUtils.find_files_by_extension('.prj')
        >>> print(f"Found {len(prj_files)} .prj files")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        try:
            files = list(ras_obj.project_folder.glob(f"*{extension}"))
            file_list = [str(file) for file in files]
            logging.info(f"Found {len(file_list)} files with extension '{extension}' in {ras_obj.project_folder}")
            return file_list
        except Exception as e:
            logging.error(f"Failed to find files with extension '{extension}': {e}")
            raise

    @staticmethod
    def get_file_size(file_path: Path, ras_object=None) -> Optional[int]:
        """
        Get the size of a file in bytes.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[int]: Size of the file in bytes, or None if the file does not exist

        Example:
        >>> size = RasUtils.get_file_size(Path("project.prj"))
        >>> print(f"File size: {size} bytes")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                size = path.stat().st_size
                logging.info(f"Size of {path}: {size} bytes")
                return size
            except Exception as e:
                logging.error(f"Failed to get size for {path}: {e}")
                raise
        else:
            logging.warning(f"File not found: {path}")
            return None

    @staticmethod
    def get_file_modification_time(file_path: Path, ras_object=None) -> Optional[float]:
        """
        Get the last modification time of a file.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[float]: Last modification time as a timestamp, or None if the file does not exist

        Example:
        >>> mtime = RasUtils.get_file_modification_time(Path("project.prj"))
        >>> print(f"Last modified: {mtime}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                mtime = path.stat().st_mtime
                logging.info(f"Last modification time of {path}: {mtime}")
                return mtime
            except Exception as e:
                logging.error(f"Failed to get modification time for {path}: {e}")
                raise
        else:
            logging.warning(f"File not found: {path}")
            return None

    @staticmethod
    def get_plan_path(current_plan_number_or_path: Union[str, Path], ras_object=None) -> Path:
        """
        Get the path for a plan file with a given plan number or path.

        Parameters:
        current_plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Full path to the plan file

        Example:
        >>> plan_path = RasUtils.get_plan_path(1)
        >>> print(f"Plan file path: {plan_path}")
        >>> plan_path = RasUtils.get_plan_path("path/to/plan.p01")
        >>> print(f"Plan file path: {plan_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        plan_path = Path(current_plan_number_or_path)
        if plan_path.is_file():
            logging.info(f"Using provided plan file path: {plan_path}")
            return plan_path
        
        try:
            current_plan_number = f"{int(current_plan_number_or_path):02d}"  # Ensure two-digit format
            logging.info(f"Converted plan number to two-digit format: {current_plan_number}")
        except ValueError:
            logging.error(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
            raise ValueError(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
        
        plan_name = f"{ras_obj.project_name}.p{current_plan_number}"
        full_plan_path = ras_obj.project_folder / plan_name
        logging.info(f"Constructed plan file path: {full_plan_path}")
        return full_plan_path

    @staticmethod
    def remove_with_retry(
        path: Path,
        max_attempts: int = 5,
        initial_delay: float = 1.0,
        is_folder: bool = True,
        ras_object=None
    ) -> bool:
        """
        Attempts to remove a file or folder with retry logic and exponential backoff.

        Parameters:
        path (Path): Path to the file or folder to be removed.
        max_attempts (int): Maximum number of removal attempts.
        initial_delay (float): Initial delay between attempts in seconds.
        is_folder (bool): If True, the path is treated as a folder; if False, it's treated as a file.
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        bool: True if the file or folder was successfully removed, False otherwise.

        Example:
        >>> success = RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
        >>> print(f"Removal successful: {success}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        path = Path(path)
        for attempt in range(1, max_attempts + 1):
            try:
                if path.exists():
                    if is_folder:
                        shutil.rmtree(path)
                        logging.info(f"Folder removed: {path}")
                    else:
                        path.unlink()
                        logging.info(f"File removed: {path}")
                else:
                    logging.info(f"Path does not exist, nothing to remove: {path}")
                return True
            except PermissionError as pe:
                if attempt < max_attempts:
                    delay = initial_delay * (2 ** (attempt - 1))  # Exponential backoff
                    logging.warning(
                        f"PermissionError on attempt {attempt} to remove {path}: {pe}. "
                        f"Retrying in {delay} seconds..."
                    )
                    time.sleep(delay)
                else:
                    logging.error(
                        f"Failed to remove {path} after {max_attempts} attempts due to PermissionError: {pe}. Skipping."
                    )
                    return False
            except Exception as e:
                logging.error(f"Failed to remove {path} on attempt {attempt}: {e}")
                return False
        return False

    @staticmethod
    def update_plan_file(
        plan_number_or_path: Union[str, Path],
        file_type: str,
        entry_number: int,
        ras_object=None
    ) -> None:
        """
        Update a plan file with a new file reference.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        file_type (str): Type of file to update ('Geom', 'Flow', or 'Unsteady')
        entry_number (int): Number (from 1 to 99) to set
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Raises:
        ValueError: If an invalid file_type is provided
        FileNotFoundError: If the plan file doesn't exist

        Example:
        >>> RasUtils.update_plan_file(1, "Geom", 2)
        >>> RasUtils.update_plan_file("path/to/plan.p01", "Geom", 2)
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        valid_file_types = {'Geom': 'g', 'Flow': 'f', 'Unsteady': 'u'}
        if file_type not in valid_file_types:
            logging.error(
                f"Invalid file_type '{file_type}'. Expected one of: {', '.join(valid_file_types.keys())}"
            )
            raise ValueError(
                f"Invalid file_type. Expected one of: {', '.join(valid_file_types.keys())}"
            )

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                logging.error(f"Plan file not found: {plan_file_path}")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}")
        
        file_prefix = valid_file_types[file_type]
        search_pattern = f"{file_type} File="
        formatted_entry_number = f"{int(entry_number):02d}"  # Ensure two-digit format

        try:
            RasUtils.check_file_access(plan_file_path, 'r')
            with plan_file_path.open('r') as file:
                lines = file.readlines()
        except Exception as e:
            logging.error(f"Failed to read plan file {plan_file_path}: {e}")
            raise

        updated = False
        for i, line in enumerate(lines):
            if line.startswith(search_pattern):
                lines[i] = f"{search_pattern}{file_prefix}{formatted_entry_number}\n"
                logging.info(
                    f"Updated {file_type} File in {plan_file_path} to {file_prefix}{formatted_entry_number}"
                )
                updated = True
                break

        if not updated:
            logging.warning(
                f"Search pattern '{search_pattern}' not found in {plan_file_path}. No update performed."
            )

        try:
            with plan_file_path.open('w') as file:
                file.writelines(lines)
            logging.info(f"Successfully updated plan file: {plan_file_path}")
        except Exception as e:
            logging.error(f"Failed to write updates to plan file {plan_file_path}: {e}")
            raise

        # Refresh RasPrj dataframes
        try:
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
            logging.info("RAS object dataframes have been refreshed.")
        except Exception as e:
            logging.error(f"Failed to refresh RasPrj dataframes: {e}")
            raise

    @staticmethod
    def check_file_access(file_path: Path, mode: str = 'r') -> None:
        """
        Check if the file can be accessed with the specified mode.

        Parameters:
        file_path (Path): Path to the file
        mode (str): Mode to check ('r' for read, 'w' for write, etc.)

        Raises:
        FileNotFoundError: If the file does not exist
        PermissionError: If the required permissions are not met
        """
        path = Path(file_path)
        if not path.exists():
            logging.error(f"File not found: {file_path}")
            raise FileNotFoundError(f"File not found: {file_path}")
        
        if mode in ('r', 'rb'):
            if not os.access(path, os.R_OK):
                logging.error(f"Read permission denied for file: {file_path}")
                raise PermissionError(f"Read permission denied for file: {file_path}")
            else:
                logging.debug(f"Read access granted for file: {file_path}")
        
        if mode in ('w', 'wb', 'a', 'ab'):
            parent_dir = path.parent
            if not os.access(parent_dir, os.W_OK):
                logging.error(f"Write permission denied for directory: {parent_dir}")
                raise PermissionError(f"Write permission denied for directory: {parent_dir}")
            else:
                logging.debug(f"Write access granted for directory: {parent_dir}")




#  --------------------------   Functions below were imported from funkshuns.py  --------------------------
#  --------------------------   Converted to ras-commander style guide   ----------------------------------




    @staticmethod
    def convert_to_dataframe(data_source: Union[pd.DataFrame, Path], **kwargs) -> pd.DataFrame:
        """
        Converts input to a pandas DataFrame. Supports existing DataFrames or file paths (CSV, Excel, TSV, Parquet).

        Args:
            data_source (Union[pd.DataFrame, Path]): The input to convert to a DataFrame. Can be a file path or an existing DataFrame.
            **kwargs: Additional keyword arguments to pass to pandas read functions.

        Returns:
            pd.DataFrame: The resulting DataFrame.

        Raises:
            NotImplementedError: If the file type is unsupported or input type is invalid.

        Example:
            >>> df = RasUtils.convert_to_dataframe(Path("data.csv"))
            >>> print(type(df))
            <class 'pandas.core.frame.DataFrame'>
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        if isinstance(data_source, pd.DataFrame):
            return data_source.copy()
        elif isinstance(data_source, Path):
            ext = data_source.suffix.replace('.', '', 1)
            if ext == 'csv':
                return pd.read_csv(data_source, **kwargs)
            elif ext.startswith('x'):
                return pd.read_excel(data_source, **kwargs)
            elif ext == "tsv":
                return pd.read_csv(data_source, sep="\t", **kwargs)
            elif ext in ["parquet", "pq", "parq"]:
                return pd.read_parquet(data_source, **kwargs)
            else:
                raise NotImplementedError(f"Unsupported file type {ext}. Should be one of csv, tsv, parquet, or xlsx.")
        else:
            raise NotImplementedError(f"Unsupported type {type(data_source)}. Only file path / existing DataFrame supported at this time")

    @staticmethod
    def save_to_excel(dataframe: pd.DataFrame, excel_path: Path, **kwargs) -> None:
        """
        Saves a pandas DataFrame to an Excel file with retry functionality.

        Args:
            dataframe (pd.DataFrame): The DataFrame to save.
            excel_path (Path): The path to the Excel file where the DataFrame will be saved.
            **kwargs: Additional keyword arguments passed to `DataFrame.to_excel()`.

        Raises:
            IOError: If the file cannot be saved after multiple attempts.

        Example:
            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
            >>> RasUtils.save_to_excel(df, Path('output.xlsx'))
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        saved = False
        max_attempts = 3
        attempt = 0

        while not saved and attempt < max_attempts:
            try:
                dataframe.to_excel(excel_path, **kwargs)
                print(f'DataFrame successfully saved to \n{excel_path}')
                saved = True
            except IOError as e:
                attempt += 1
                if attempt < max_attempts:
                    print(f"Error saving file. Attempt {attempt} of {max_attempts}. Please close the Excel document if it's open.")
                else:
                    raise IOError(f"Failed to save {excel_path} after {max_attempts} attempts. Last error: {str(e)}")










#####  Statistical Metrics #####


    @staticmethod
    def calculate_rmse(observed_values: np.ndarray, predicted_values: np.ndarray, normalized: bool = True) -> float:
        """
        Calculate the Root Mean Squared Error (RMSE) between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            normalized (bool, optional): Whether to normalize RMSE to a percentage of observed_values. Defaults to True.

        Returns:
            float: The calculated RMSE value.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_rmse(observed, predicted)
            0.06396394
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        rmse = np.sqrt(np.mean((predicted_values - observed_values) ** 2))
        
        if normalized:
            rmse = rmse / np.abs(np.mean(observed_values))
        
        return rmse

    @staticmethod
    def calculate_percent_bias(observed_values: np.ndarray, predicted_values: np.ndarray, as_percentage: bool = False) -> float:
        """
        Calculate the Percent Bias between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            as_percentage (bool, optional): If True, return bias as a percentage. Defaults to False.

        Returns:
            float: The calculated Percent Bias.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)
            3.33333333
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        multiplier = 100 if as_percentage else 1
        
        percent_bias = multiplier * (np.mean(predicted_values) - np.mean(observed_values)) / np.mean(observed_values)
        
        return percent_bias

    @staticmethod
    def calculate_error_metrics(observed_values: np.ndarray, predicted_values: np.ndarray) -> Dict[str, float]:
        """
        Compute a trio of error metrics: correlation, RMSE, and Percent Bias.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.

        Returns:
            Dict[str, float]: A dictionary containing correlation ('cor'), RMSE ('rmse'), and Percent Bias ('pb').

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_error_metrics(observed, predicted)
            {'cor': 0.9993, 'rmse': 0.06396, 'pb': 0.03333}
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        correlation = np.corrcoef(observed_values, predicted_values)[0, 1]
        rmse = RasUtils.calculate_rmse(observed_values, predicted_values)
        percent_bias = RasUtils.calculate_percent_bias(observed_values, predicted_values)
        
        return {'cor': correlation, 'rmse': rmse, 'pb': percent_bias}





==================================================

File: c:\GH\ras-commander\ras_commander\_version.py
==================================================
# file generated by setuptools_scm
# don't change, don't track in version control
TYPE_CHECKING = False
if TYPE_CHECKING:
    from typing import Tuple, Union
    VERSION_TUPLE = Tuple[Union[int, str], ...]
else:
    VERSION_TUPLE = object

version: str
__version__: str
__version_tuple__: VERSION_TUPLE
version_tuple: VERSION_TUPLE

__version__ = version = '0.29.dev1+g22e75d4.d20240919'
__version_tuple__ = version_tuple = (0, 29, 'dev1', 'g22e75d4.d20240919')

==================================================

File: c:\GH\ras-commander\ras_commander\__init__.py
==================================================
from importlib.metadata import version, PackageNotFoundError

try:
    __version__ = version("ras-commander")
except PackageNotFoundError:
    # package is not installed
    __version__ = "unknown"

# Import all necessary functions and classes directly
from .RasPrj import ras, init_ras_project, get_ras_exe
from .RasPrj import RasPrj
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUnsteady import RasUnsteady
from .RasCmdr import RasCmdr
from .RasUtils import RasUtils
from .RasExamples import RasExamples
from .RasHdf import RasHdf  # Add this line

# Import all attributes from these modules
from .RasPrj import *
from .RasPlan import *
from .RasGeo import *
from .RasUnsteady import *
from .RasCmdr import *
from .RasUtils import *
from .RasExamples import *
from .RasHdf import *  # Add this line

# Define __all__ to specify what should be imported when using "from ras_commander import *"
__all__ = [
    "ras",
    "init_ras_project",
    "get_ras_exe",
    "RasPrj",
    "RasPlan",
    "RasGeo",
    "RasUnsteady",
    "RasCmdr",
    "RasUtils",
    "RasExamples",
    "RasHdf"  # Add this line
]

==================================================

