File: c:\GH\ras-commander\examples\01_project_initialization.py
==================================================
# 01_project_initialization.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example demonstrates both the default global 'ras' object and custom ras objects.
# 2. The global 'ras' object is suitable for simple scripts working with a single project.
# 3. Custom ras objects are recommended for complex scripts or when working with multiple projects.
# 4. The init_ras_project function initializes a project and sets up the ras object.
# 5. Each ras object contains comprehensive information about its project, including plan, geometry, flow files, and boundary conditions.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Use descriptive names for custom ras objects to clearly identify different projects.

def print_ras_object_data(ras_obj, project_name):
    print(f"\n{project_name} Project Data:")
    print("=" * 50)
    print(f"Project Name: {ras_obj.get_project_name()}")
    print(f"Project Folder: {ras_obj.project_folder}")
    print(f"PRJ File: {ras_obj.prj_file}")
    print(f"HEC-RAS Executable Path: {ras_obj.ras_exe_path}")
    
    print("\nPlan Files DataFrame:")
    print(ras_obj.plan_df)
    
    print("\nFlow Files DataFrame:")
    print(ras_obj.flow_df)
    
    print("\nUnsteady Flow Files DataFrame:")
    print(ras_obj.unsteady_df)
    
    print("\nGeometry Files DataFrame:")
    print(ras_obj.geom_df)
    
    print("\nHDF Entries DataFrame:")
    print(ras_obj.get_hdf_entries())
    
    print("\nBoundary Conditions DataFrame:")
    print(ras_obj.get_boundary_conditions())
    
    print("\nMeteorological Data:")
    for attr in ['precipitation_mode', 'wind_mode', 'precipitation_metadata', 'evapotranspiration_metadata']:
        if hasattr(ras_obj, attr):
            print(f"{attr.capitalize().replace('_', ' ')}: {getattr(ras_obj, attr)}")
        else:
            print(f"{attr.capitalize().replace('_', ' ')}: Not available")

def main():
    # Get the current script's directory
    current_dir = Path(__file__).parent
    
    # Define paths to example projects
    bald_eagle_path = current_dir.parent / "examples" / "example_projects" / "Balde Eagle Creek"
    multi_2d_path = current_dir.parent / "examples" / "example_projects" / "BaldEagleCrkMulti2D"
    muncie_path = current_dir.parent / "examples" / "example_projects" / "Muncie"

    print("Example Set 1: Using the default global 'ras' object")
    print("-----------------------------------------------------")

    # Initialize using the global RAS instance
    print("Step 1: Initializing with global RAS instance")
    init_ras_project(bald_eagle_path, "6.5") # This will set the global 'ras' object
    print_ras_object_data(ras, "Global RAS Instance (Bald Eagle Creek)")

    print("\nExample Set 2: Using custom ras objects")
    print("-----------------------------------------------------")

    # Initialize multiple project instances
    print("Step 1: Initializing multiple project instances")
    multi_2d_project = init_ras_project(multi_2d_path, "6.5")
    muncie_project = init_ras_project(muncie_path, "6.5")

    print_ras_object_data(multi_2d_project, "Multi2D Project")
    print_ras_object_data(muncie_project, "Muncie Project")

    print("\nExample of simplified import (not recommended for complex scripts)")
    print("-----------------------------------------------------")
    print("from ras_commander import *")
    print("# This allows you to use all functions and classes without prefixes")
    print("# For example: compute_plan() instead of RasCmdr.compute_plan()")
    print("# Note: This approach can lead to naming conflicts and is generally not recommended for larger scripts")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\02_plan_operations.py
==================================================
# 02_plan_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import datetime

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on plans, geometries, and unsteady flows using the functions within the RasPlan Class.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Geometry Cloning: Clone a geometry associated with the original plan, generating a new geometry entry.
4. Unsteady Flow Cloning: Clone an unsteady flow, creating a new unsteady flow entry.
5. Plan Configuration:
   a. Set the cloned geometry for the new plan.
   b. Set the cloned unsteady flow for the new plan.
   c. Update the number of cores to be used for the new plan.
   d. Configure geometry preprocessor options for the new plan.
6. Update Simulation Parameters: Modify various simulation parameters in the new plan.
7. Plan Computation: Compute the new plan and verify successful execution.
8. Results Verification: Check the HDF entries to confirm that results were written.
"""

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()
    
    # Step 2: Clone a geometry
    print("Step 2: Cloning a geometry")
    new_geo_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geo_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()
    
    # Step 3: Clone an unsteady flow
    print("Step 3: Cloning an unsteady flow")
    new_unsteady_number = RasPlan.clone_unsteady("02")
    print(f"New unsteady flow created: {new_unsteady_number}")
    print("Updated unsteady flow files:")
    print(ras.unsteady_df)
    print()

    # Step 4: Set geometry for the cloned plan
    print("Step 4: Setting geometry for a plan")
    RasPlan.set_geom(new_plan_number, new_geo_number)
    plan_path = RasPlan.get_plan_path(new_plan_number)
    print(f"Updated geometry for plan {new_plan_number}")
    print(f"Plan file path: {plan_path}")
    print()

    # Step 5: Set unsteady flow for the cloned plan
    print("Step 5: Setting unsteady flow for a plan")
    RasPlan.set_unsteady(new_plan_number, new_unsteady_number)
    print(f"Updated unsteady flow for plan {new_plan_number}")
    print()

    # Step 6: Set the number of cores for the cloned plan
    print("Step 6: Setting the number of cores for a plan")
    RasPlan.set_num_cores(new_plan_number, 2)
    print(f"Updated number of cores for plan {new_plan_number}")
    print()

    # Step 7: Set geometry preprocessor options for the cloned plan
    print("Step 7: Setting geometry preprocessor options")
    RasPlan.set_geom_preprocessor(plan_path, run_htab=-1, use_ib_tables=-1)
    print(f"Updated geometry preprocessor options for plan {new_plan_number}")
    print()

    # Step 8: Update simulation parameters
    print("Step 8: Updating simulation parameters")

    # Import the datetime module
    from datetime import datetime

    # Update simulation date
    start_date = datetime(2023, 1, 1, 0, 0)
    end_date = datetime(2023, 1, 5, 23, 59)
    RasPlan.update_simulation_date(new_plan_number, start_date, end_date)

    # Update plan intervals
    RasPlan.update_plan_intervals(
        new_plan_number,
        computation_interval="1MIN",
        output_interval="15MIN",
        mapping_interval="30MIN"
    )

    # Update run flags
    RasPlan.update_run_flags(
        new_plan_number,
        geometry_preprocessor=True,
        unsteady_flow_simulation=True,
        post_processor=True,
        floodplain_mapping=True
    )

    # Update plan description
    new_description = "Updated plan with modified simulation parameters"
    RasPlan.update_plan_description(new_plan_number, new_description)


    print("Updated simulation parameters")
    print()


    # Step 9: Compute the cloned plan
    print("Step 10: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
    print()
    
    # Step 11: Get the HDF entries for the cloned plan to prove that the results were written
    print("Step 11: Retrieving HDF entries for the cloned plan")
    # Refresh the plan entries to ensure we have the latest data
    ras.plan_df = ras.get_plan_entries()
    hdf_entries = ras.get_hdf_entries()
    if not hdf_entries.empty:
        print("HDF entries for the cloned plan:")
        print(hdf_entries)
    else:
        print("No HDF entries found. This could mean the plan hasn't been computed successfully or the results haven't been written yet.")
    
    # Display the plan entries to see if the HDF path is populated
    print("\nCurrent plan entries:")
    print(ras.plan_df)
    
if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\03_geometry_operations.py
==================================================
# 03_geometry_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasGeo class provides methods for working with geometry files and preprocessor operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Always clear geometry preprocessor files before making significant changes to ensure clean results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Muncie"
    init_ras_project(project_path, "6.6")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()

    # Step 2: Clone a geometry file and assign it to the cloned plan
    print("Step 2: Cloning a geometry file and assigning it to the cloned plan")
    new_geom_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geom_number}")
    print(f"Now set the new geometry to the new plan")
    RasPlan.set_geom(new_plan_number, new_geom_number)
    print(f"New geometry {new_geom_number} assigned to plan {new_plan_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()

    # Step 3: Clear geometry preprocessor files for the cloned plan
    print("Step 3: Clearing geometry preprocessor files for the cloned plan")
    plan_path = RasPlan.get_plan_path(new_plan_number)
    RasGeo.clear_geompre_files(plan_path)
    print(f"Cleared geometry preprocessor files for plan {new_plan_number}")
    print()

    # Step 4: Clear geometry preprocessor files for all plans
    print("Step 4: Clearing geometry preprocessor files for all plans")
    RasGeo.clear_geompre_files()
    print("Cleared geometry preprocessor files for all plans")
    print()

    # Step 5: Print the updated plan information
    print("Step 5: Updated plan information")
    plan_df = ras.get_plan_entries()
    print(plan_df)
    print()

    # Step 6: Compute the cloned plan with new geometry and core count
    print("Step 6: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
        
    # Step 7: Get and print results paths
    print("\nStep 7: Getting results paths")
    for plan_number in [new_plan_number, "01"]:  # Check both the new plan and the original plan
        results_path = RasPlan.get_results_path(plan_number)
        if results_path:
            print(f"Results for plan {plan_number} are located at: {results_path}")
        else:
            print(f"No results found for plan {plan_number}")
        

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\04_unsteady_flow_operations.py
==================================================
# 04_unsteady_flow_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on unsteady flow files using the RasUnsteady class.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Extract Boundary and Tables: Extract boundary conditions and associated tables from an unsteady flow file.
3. Print Boundaries and Tables: Display the extracted boundary conditions and tables.
4. Update Unsteady Parameters: Modify parameters in the unsteady flow file.
5. Verify Changes: Check the updated unsteady flow file to confirm the changes.
"""

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Initial unsteady flow files:")
    print(ras.unsteady_df)
    print()

    # Step 1: Extract boundary and tables
    print("Step 1: Extracting boundary conditions and tables")
    unsteady_file = RasPlan.get_unsteady_path("02")  # Using unsteady flow file "02"
    print(f"Unsteady file: {unsteady_file}")
    boundaries_df = RasUnsteady.extract_boundary_and_tables(unsteady_file)
    print("Extracted boundary conditions and tables")
    #print(boundaries_df)

    # Step 2: Print boundaries and tables
    print("Step 2: Printing boundaries and tables")
    RasUnsteady.print_boundaries_and_tables(boundaries_df)
    print()

    # Step 3: Update unsteady parameters
    #print("Step 3: Updating unsteady flow parameters")
    #modifications = {
    #    "Computation Interval": "30SEC",
    #    "Output Interval": "10MIN",
    #    "Mapping Interval": "1HOUR"
    #}
    #RasUnsteady.update_unsteady_parameters(unsteady_file, modifications)
    #print("Updated unsteady flow parameters")
    #print()

    
if __name__ == "__main__":
    main()


==================================================

File: c:\GH\ras-commander\examples\05_utility_functions.py
==================================================
# 05_utility_functions.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasUtils class provides various utility functions for working with HEC-RAS projects.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")
    plan_number = "01"

    # Example 1: Get plan path using RasUtils
    print("Example 1: Getting plan path")
    plan_path = RasUtils.get_plan_path(plan_number)
    print(f"Path for plan {plan_number} is: {plan_path}")
    
    # Example 2: Get geometry path using RasPlan
    print("\nExample 2: Getting geometry path")
    geom_number = "01"
    geom_path = RasPlan.get_geom_path(geom_number)
    print(f"Path for geometry {geom_number} is: {geom_path}")
    
    # Example 3: Get unsteady flow path using RasPlan
    print("\nExample 3: Getting unsteady flow path")
    unsteady_number = "01"
    unsteady_path = RasPlan.get_unsteady_path(unsteady_number)
    print(f"Path for unsteady flow {unsteady_number} is: {unsteady_path}")
    
    # Example 4: Get project name
    print("\nExample 4: Getting project name")
    project_name = ras.get_project_name()
    print(f"Project name: {project_name}")


if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\06_single_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Define the "example_projects" folder in the same directory as the script
examples_path = Path(__file__).parent / "example_projects"

# Delete the project if it exists
if examples_path.exists():
    import shutil
    shutil.rmtree(examples_path)

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan
    print("Example 1: Executing a single plan")
    plan_number = "01"
    success = RasCmdr.compute_plan(plan_number)
    if success:
        print(f"Plan {plan_number} executed successfully")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 2: Execute a plan in a separate destination folder
    print("Example 2: Executing a plan in a separate destination folder")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder)
    if success:
        print(f"Plan {plan_number} executed successfully in {dest_folder}")
    else:
        print(f"Plan {plan_number} execution failed in {dest_folder}")
    print()

    # Example 3: Get and print results path
    print("Example 3: Getting results path")
    results_path = RasPlan.get_results_path(plan_number)
    if results_path:
        print(f"Results for plan {plan_number} are located at: {results_path}")
    else:
        print(f"No results found for plan {plan_number}")
    print()    

    # Example 4: Execute a plan with cleared geometry preprocessor files
    print("Example 4: Executing a plan with cleared geometry preprocessor files")
    plan_number = "03"
    dest_folder = project_path.parent / "compute_test_3"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, clear_geompre=True)
    if success:
        print(f"Plan {plan_number} executed successfully with cleared geometry preprocessor files")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 5: Execute a plan with a specified number of cores, overwriting compute_test_3
    print("Example 5: Executing a plan with a specified number of cores, overwriting compute_test_3")
    plan_number = "01"
    num_cores = 2  # Specify the number of cores to use
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=num_cores, overwrite_dest=True)
    if success:
        print(f"Plan {plan_number} executed successfully using {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 6: Execute a plan with all new options combined
    print("Example 6: Executing a plan with all new options combined")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_all_options"
    num_cores = 4
    
    success = RasCmdr.compute_plan(
        plan_number,
        dest_folder=dest_folder,
        clear_geompre=True,
        num_cores=num_cores
    )
    if success:
        print(f"Plan {plan_number} executed successfully with all options:")
        print(f"- Destination folder: {dest_folder}")
        print(f"- Cleared geometry preprocessor files")
        print(f"- Used {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\07_sequential_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path
# Define the keys to search for in folder names
# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of all plans with overwrite_dest
    print("Example 1: Sequential execution of all plans with overwrite_dest")
    RasCmdr.compute_test_mode(
        dest_folder_suffix="[AllSequential]",
        overwrite_dest=True
    )
    print("Sequential execution of all plans completed with overwrite_dest")
    print()
    
    # Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest
    print("Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest")
    RasCmdr.compute_test_mode(
        plan_number=["01", "02"],
        dest_folder_suffix="[SpecificSequentialClearGeompre]",
        clear_geompre=True,
        overwrite_dest=True
    )
    print("Sequential execution of specific plans completed with clearing geompre files and overwrite_dest")
    print()

    # Example 3: Demonstrate clearing geompre files for specific plans
    print("Example 3: Clearing geompre files for specific plans")
    plan_files = [RasPlan.get_plan_path("01"), RasPlan.get_plan_path("02")]
    RasGeo.clear_geompre_files(plan_files)
    print("Geometry preprocessor files cleared for specific plans")
    print()

    # Example 4: Demonstrate clearing all geompre files
    print("Example 4: Clearing all geompre files")
    RasGeo.clear_geompre_files()
    print("All geometry preprocessor files cleared")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\08_parallel_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Initialize the project using a new RasPrj object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    source_project = init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(source_project.plan_df)
    print()

    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel"
    results_all = RasCmdr.compute_parallel(
        max_workers=3,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.6")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()

    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores)
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.6")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\09_specifying_plans.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path

# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides methods for executing plans in various ways.
# 5. You can specify individual plans or lists of plans for batch operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. When specifying plans, use plan numbers as strings (e.g., "01", "02") for consistency.
# 5. Always check the available plans in the project before specifying plan numbers for execution.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of specific plans
    print("Example 1: Sequential execution of specific plans (1 and 3)")
    RasCmdr.compute_test_mode(plan_number=["01", "03"], dest_folder_suffix="[SpecificSequential]", num_cores=6)
    print("Sequential execution of specific plans completed")
    print()

    # Example 2: Parallel execution of specific plans
    print("Example 2: Parallel execution of specific plans")
    results_specific = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute all plans
    print("Example 3: Execute all plans")
    all_plan_numbers = ras.plan_df['plan_number'].tolist()
    RasCmdr.compute_test_mode(plan_number=all_plan_numbers, dest_folder_suffix="[AllPlans]")
    print("Execution of all plans completed")
    print()

if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\10_arguments_for_compute.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides various arguments for fine-tuning plan computation:
#    - plan_number: String representing the plan number to compute (e.g., "01")
#    - dest_folder: Path object specifying the destination folder for computation results
#    - clear_geompre: Boolean to clear geometry preprocessor files before computation
#    - num_cores: Integer specifying the number of cores to use
#    - overwrite_dest: Boolean to determine if existing destination folders should be overwritten

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Utilize the various arguments in compute functions to customize plan execution.
# 5. Always consider your system's capabilities when setting num_cores.
# 6. Use clear_geompre=True when you want to ensure a clean computation environment.
# 7. Specify dest_folder to keep your project folder organized and prevent overwriting previous results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution (compute_test_mode) with various arguments
    print("Example 1: Sequential execution with various arguments")
    for plan_number in ["01", "02"]:
        # Put dest_folder in the parent directory of the project folder (placing it horizontally with the project folder)
        # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory. 
        # So instead of building the full folder name or path, we only define the suffix. 
        dest_folder_suffix = f"_{plan_number}_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number=plan_number,
            dest_folder_suffix=dest_folder_suffix,  # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=True
        )
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print("Sequential execution completed")
    print()
    
    # This variation will fail, as the folder already exists and overwrite_dest is False.  
    # Be sure to think step by step about folder management in your multi-folder automation workflows:
    # Also, try to run the same thing with compute_parallel, but with overwrite_dest=False
    # Since we just created these folders, they are not empty, so this should generate an error message on the terminal
    # Put in Try-Except block:
    try:
        dest_folder = project_path.parent / f"{ras.project_name}_compute_test_01_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number="01",
            dest_folder_suffix=dest_folder_suffix,
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=False
        )
    except ValueError as e:
        print(f"If the example operates successfully (it is meant to generate an error above), you will not see this message.")

    # Example 2: Parallel execution (compute_parallel) with various arguments
    print("Example 2: Parallel execution with various arguments")
    results = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2,
        dest_folder=project_path.parent / "parallel_results",
        clear_geompre=True
    )
    print("Parallel execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Single plan execution (compute_plan) with specific arguments
    print("Example 3: Single plan execution with specific arguments")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=2, clear_geompre=True, overwrite_dest=True)
    print(f"Single plan execution: {'Successful' if success else 'Failed'}")

if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\12_plan_set_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

import pandas as pd


def create_plan_set(base_plan, base_geom, num_copies):
    plan_set = []
    for i in range(num_copies):
        new_plan = RasPlan.clone_plan(base_plan)
        new_geom = RasPlan.clone_geom(base_geom)
        RasPlan.set_geom(new_plan, new_geom)
        plan_set.append({
            'plan_number': new_plan,
            'geom_number': new_geom
        })
    return pd.DataFrame(plan_set)

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print("\nAvailable geometries:")
    print(ras.geom_df)
    print()

    # Create a plan set
    base_plan = "01"
    base_geom = "01"
    num_copies = 5
    plan_set = create_plan_set(base_plan, base_geom, num_copies)
    
    print("Created plan set:")
    print(plan_set)
    print()

    # Placeholder for user to insert code that makes programmatic changes to the model
    # For example:
    # for index, row in plan_set.iterrows():
    #     plan_path = RasPlan.get_plan_path(row['plan_number'])
    #     geom_path = RasPlan.get_geom_path(row['geom_number'])
    #     # Make changes to the plan or geometry file here
    #     # For example, you could modify Manning's n values, cross-section data, etc.

    # Execute the plan set in parallel
    print("Executing plan set in parallel")
    results = RasCmdr.compute_parallel(
        plan_number=plan_set['plan_number'].tolist(),
        max_workers=3,
        num_cores=2
    )

    # Add execution results to the plan_set DataFrame
    plan_set['execution_success'] = plan_set['plan_number'].map(results)

    print("\nPlan set execution results:")
    print(plan_set)

    # Here you could add code to analyze the results, such as:
    # - Extracting key output values from each simulation
    # - Comparing results across different plans
    # - Creating visualizations of the results

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\13_multiple_project_operations.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "Muncie"])

#### --- START OF SCRIPT --- ####

def execute_plan(plan_number, ras_object, compute_folder):
    # Set the number of cores to 2 before executing the plan
    RasPlan.set_num_cores(plan_number, 2, ras_object=ras_object)
    
    # Execute the plan in the compute folder
    success = RasCmdr.compute_plan(plan_number, ras_object=ras_object, dest_folder=compute_folder)
    
    return plan_number, success

def main():
    # Initialize two projects
    current_dir = Path(__file__).parent
    bald_eagle_path = current_dir / "example_projects" / "Balde Eagle Creek"
    muncie_path = current_dir / "example_projects" / "Muncie"
    
    bald_eagle = init_ras_project(bald_eagle_path, "6.6")
    muncie = init_ras_project(muncie_path, "6.6")

    print("Available plans in Bald Eagle Creek project:")
    print(bald_eagle.plan_df)
    print("\nAvailable plans in Muncie project:")
    print(muncie.plan_df)
    print()

    # Example 1: Clone plans with custom short identifiers
    print("Example 1: Cloning plans with custom short identifiers")
    new_bald_eagle_plan = RasPlan.clone_plan("01", new_plan_shortid="BECustom", ras_object=bald_eagle)
    new_muncie_plan = RasPlan.clone_plan("01", new_plan_shortid="MunCustom", ras_object=muncie)
    print(f"Created new plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Created new plan {new_muncie_plan} in Muncie project")
    print()

    # Example 2: Set geometry for the new plans
    print("Example 2: Setting geometry for the new plans")
    RasPlan.set_geom(new_bald_eagle_plan, "01", ras_object=bald_eagle)
    RasPlan.set_geom(new_muncie_plan, "01", ras_object=muncie)
    print(f"Set geometry for plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Set geometry for plan {new_muncie_plan} in Muncie project")
    print()


    # Example 3: Execute plans for both projects simultaneously in separate compute folders
    print("Example 4: Executing plans for both projects simultaneously in separate compute folders")
    
    # Create compute folders
    bald_eagle_compute_folder = bald_eagle_path.parent / "compute_bald_eagle"
    muncie_compute_folder = muncie_path.parent / "compute_muncie"
    
    # Remove existing compute folders if they exist
    for folder in [bald_eagle_compute_folder, muncie_compute_folder]:
        if folder.exists():
            shutil.rmtree(folder)
        folder.mkdir(parents=True, exist_ok=True)
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(execute_plan, new_bald_eagle_plan, bald_eagle, bald_eagle_compute_folder),
            executor.submit(execute_plan, new_muncie_plan, muncie, muncie_compute_folder)
        ]
        
        results = {}
        for future in futures:
            plan_number, success = future.result()
            results[plan_number] = success

    print("Execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print()

    # Example 4: Get and print results paths
    print("Example 5: Getting results paths")
    bald_eagle_results = RasPlan.get_results_path(new_bald_eagle_plan, ras_object=bald_eagle)
    muncie_results = RasPlan.get_results_path(new_muncie_plan, ras_object=muncie)

    if bald_eagle_results:
        print(f"Results for Bald Eagle Creek plan {new_bald_eagle_plan} are located at: {bald_eagle_results}")
    else:
        print(f"No results found for Bald Eagle Creek plan {new_bald_eagle_plan}")

    if muncie_results:
        print(f"Results for Muncie plan {new_muncie_plan} are located at: {muncie_results}")
    else:
        print(f"No results found for Muncie plan {new_muncie_plan}")

    print("\nNote: The original project folders can now be edited while the compute operations are running in separate folders.")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\14_Core_Sensitivity.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ras-commander pandas requests pathlib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14_Core_Sensitivity.ipynb\n",
    "Testing Core Sensitivity for RAS using the Bald Eagle Creek Multi-Gage 2D project.  \n",
    "\n",
    "\n",
    "This should take around 15-45 minutes to run depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "\n",
    "print(\"ras_commander imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, RasGeo\n",
    "\n",
    "# Step 1: Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
    "\n",
    "# Use Path.cwd() to get the current working directory in a Jupyter Notebook\n",
    "current_directory = Path.cwd()\n",
    "project_path = current_directory / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
    "\n",
    "# Step 2: Initialize the Muncie Project using init_ras_project (from ras_commander)\n",
    "muncie_project = init_ras_project(project_path, \"6.6\")\n",
    "\n",
    "# Step 3: Initialize a DataFrame to store execution results\n",
    "results = []\n",
    "\n",
    "# Step 4: Run sensitivity analysis for Plan 03 with core counts 1-8\n",
    "plan_number = '03'\n",
    "print(f\"Running sensitivity analysis for Plan {plan_number}\")\n",
    "\n",
    "# Clear geompre files before running the plan\n",
    "plan_path = RasPlan.get_plan_path(plan_number)\n",
    "RasGeo.clear_geompre_files(plan_path)\n",
    "\n",
    "for cores in range(1, 9):\n",
    "    print(f\"Running with {cores} core(s)\")\n",
    "    # Set core count for this plan\n",
    "    RasPlan.set_num_cores(plan_number, cores)\n",
    "    \n",
    "    # Time the execution of the plan\n",
    "    start_time = time.time()\n",
    "    RasCmdr.compute_plan(plan_number)\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"plan_number\": plan_number,\n",
    "        \"cores\": cores,\n",
    "        \"execution_time\": execution_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "print(\"Sensitivity analysis complete\")\n",
    "\n",
    "# Step 5: Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv(\"core_sensitivity_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FOR REVISIONS:\n",
    "- Use HDF compute summary to show the time for each preproces/unsteady compute/postprocess step. \n",
    "- First, run preprocessor and then toggle options to only run unsteady compute and postprocess. \n",
    "- Plot each step separately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, load the results from a CSV file\n",
    "results_df = pd.read_csv(\"core_sensitivity_results.csv\")\n",
    "\n",
    "# Display the results dataframe for verification\n",
    "print(\"results_df DataFrame:\")\n",
    "display(results_df)\n",
    "\n",
    "# Step 6: Calculate unit runtime (based on 1 core execution time)\n",
    "results_df['unit_runtime'] = results_df.groupby('plan_number')['execution_time'].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "# Get the project name from the ras object\n",
    "project_name = ras.project_name\n",
    "\n",
    "# Step 7: Plot a line chart for unit runtime vs. cores for each plan\n",
    "plt.figure(figsize=(10, 6))\n",
    "for plan in results_df['plan_number'].unique():\n",
    "    plan_data = results_df[results_df['plan_number'] == plan]\n",
    "    plt.plot(plan_data['cores'], plan_data['unit_runtime'], label=f\"Plan {plan}\")\n",
    "\n",
    "plt.xlabel(\"Number of Cores\")\n",
    "plt.ylabel(\"Unit Runtime (Relative to 1 Core)\")\n",
    "plt.title(f\"{project_name} (HEC Example Project)\\nCore Count Sensitivity Analysis\")\n",
    "plt.legend(title=\"Plan Number\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "summary_stats = results_df.groupby('cores')['execution_time'].agg(['mean', 'min', 'max'])\n",
    "display(summary_stats)\n",
    "\n",
    "# Calculate and print speedup\n",
    "speedup = results_df[results_df['cores'] == 1]['execution_time'].mean() / results_df[results_df['cores'] == 8]['execution_time'].mean()\n",
    "print(f\"\\nAverage speedup from 1 to 8 cores: {speedup:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "releasecmdr311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\15_plan_key_operations.py
==================================================
# 15_plan_key_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
from datetime import datetime, timedelta

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    ras_obj = init_ras_project(project_path, "6.6")

    print("Example 15: Plan Key Operations")
    print("------------------------------------------")

    # Get the first plan number
    plan_number = ras_obj.plan_df['plan_number'].iloc[0]
    print(f"Working with Plan: {plan_number}")

    # 1. Get and print initial plan values
    keys_to_check = ['Computation Interval', 'Simulation Date', 'Short Identifier', 'UNET D1 Cores']
    print("\n1. Initial Plan Values:")
    for key in keys_to_check:
        value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {value}")

    # 2. Update run flags
    print("\n2. Updating Run Flags:")
    RasPlan.update_run_flags(
        plan_number,
        geometry_preprocessor=True,
        unsteady_flow_simulation=True,
        run_sediment=False,
        post_processor=True,
        floodplain_mapping=False,
        ras_object=ras_obj
    )
    print("  Run flags updated.")

    # 3. Update plan intervals
    print("\n3. Updating Plan Intervals:")
    RasPlan.update_plan_intervals(
        plan_number,
        computation_interval="5SEC",
        output_interval="1MIN",
        instantaneous_interval="5MIN",
        mapping_interval="15MIN",
        ras_object=ras_obj
    )
    print("  Plan intervals updated.")

    # 4. Update plan description
    
    print("\n4. Current Plan Description:")
    current_description = RasPlan.read_plan_description(plan_number, ras_object=ras_obj)
    print(f"  {current_description}")    
    print("\n4. Updating Plan Description:")
    new_description = "This is an updated plan description for testing purposes."
    RasPlan.update_plan_description(plan_number, new_description, ras_object=ras_obj)
    print("  Plan description updated.")

    # 5. Update simulation date
    print("\n5. Updating Simulation Date:")
    start_date = datetime.now()
    end_date = start_date + timedelta(days=1)
    RasPlan.update_simulation_date(plan_number, start_date, end_date, ras_object=ras_obj)
    print(f"  Simulation date updated to: {start_date} - {end_date}")

    # 6. Get and print updated plan values
    print("\n6. Updated Plan Values:")
    for key in keys_to_check:
        value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {value}")

    # 7. Get updated description
    print("\n7. Updated Plan Description:")
    updated_description = RasPlan.read_plan_description(plan_number, ras_object=ras_obj)
    print(f"  {updated_description}")

    print("\nExample 15 completed.")

if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\16_scanning_ras_project_info.py
==================================================
import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    from ras_commander import init_ras_project, RasPrj, RasExamples
except ImportError:
    sys.path.append(str(parent_directory))
    from ras_commander import init_ras_project, RasPrj, RasExamples

import logging

def generate_category_summary(category_path):
    summary = []
    summary.append(f"RAS-Commander Example Projects Summary for Category: {category_path.name}\n")
    summary.append("=" * 80 + "\n\n")

    for project_path in category_path.iterdir():
        if project_path.is_dir():
            summary.append(f"Project Folder: {project_path.name}")
            summary.append(f"Full Path: {project_path.resolve()}\n")

            try:
                ras_project = init_ras_project(project_path, "6.6", ras_instance=RasPrj())
                
                summary.append(f"Project Name: {ras_project.get_project_name()}")
                summary.append(f"PRJ File: {ras_project.prj_file}")
                summary.append(f"RAS Executable: {ras_project.ras_exe_path}\n")

                summary.append("Plan Files:")
                summary.append(ras_project.plan_df.to_string())
                summary.append("\n")

                summary.append("Flow Files:")
                summary.append(ras_project.flow_df.to_string())
                summary.append("\n")

                summary.append("Geometry Files:")
                summary.append(ras_project.geom_df.to_string())
                summary.append("\n")

                summary.append("Unsteady Flow Files:")
                summary.append(ras_project.unsteady_df.to_string())
                summary.append("\n")

                summary.append("Boundary Conditions:")
                summary.append(ras_project.boundaries_df.to_string())
                summary.append("\n")

                # Add unparsed lines for each boundary condition
                summary.append("Unparsed Boundary Condition Lines:")
                for _, row in ras_project.boundaries_df.iterrows():
                    bc_number = row['boundary_condition_number']
                    unsteady_number = row['unsteady_number']
                    unparsed_lines = ras_project._parse_boundary_condition(
                        ras_project._get_boundary_condition_block(unsteady_number, bc_number),
                        unsteady_number,
                        bc_number
                    )[1]
                    if unparsed_lines:
                        summary.append(f"BC {bc_number} in Unsteady File {unsteady_number}:")
                        summary.append(unparsed_lines)
                        summary.append("\n")
                summary.append("\n")

            except Exception as e:
                summary.append(f"Error initializing RAS project: {str(e)}\n")

            summary.append("-" * 80 + "\n\n")

    return "\n".join(summary)

def main():
    # Set logging level to DEBUG to capture unparsed lines
    logging.getLogger().setLevel(logging.DEBUG)

    ras_examples = RasExamples()
    selected_categories = ["1D Unsteady Flow Hydraulics", "2D Unsteady Flow Hydraulics"]

    base_dir = Path.cwd() / "ras_example_categories"
    base_dir.mkdir(exist_ok=True)

    for category in selected_categories:
        category_dir = base_dir / category
        category_dir.mkdir(exist_ok=True)

        projects = ras_examples.list_projects(category)
        extracted_paths = ras_examples.extract_project(projects)

        # Move extracted projects to the category directory
        for path in extracted_paths:
            new_path = category_dir / path.name
            path.rename(new_path)

        # Generate and save summary for this category
        summary_text = generate_category_summary(category_dir)
        output_file = base_dir / f"ras-commander {category} summary.txt"
        with open(output_file, "w") as f:
            f.write(summary_text)

        print(f"Summary for category '{category}' has been written to: {output_file}")

    print("All category summaries have been generated.")

    # Clean up extracted projects
    ras_examples.clean_projects_directory()
    print("Cleaned up original extracted example projects.")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\17_parallel_execution_ble.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math
import logging

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

# Initialize RasExamples
ras_examples = RasExamples()

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

##  WHISKY CHITTO DOES NOT WORK - BLE MODEL IS BROKEN AND REQUIRED FIXING BEFORE RUNNING

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Define paths
    current_dir = Path(__file__).parent
    csv_directory = current_dir / "FEMA_BLE_Models"
    csv_file = csv_directory / "08080204_WhiskyChitto_DownloadIndex.csv"
    
    # Download FEMA BLE Models (specifically WhiskyChitto)
    ras_examples.download_fema_ble_model(csv_file=csv_file)
    
    
    # Initialize the RasPrj object for WhiskyChitto
    project_path = csv_directory / "WhiskyChitto" / "HECRAS_Models" / "Model" / "Input"
    logging.info(f"Initializing RasPrj for project at: {project_path}")
    whisky_project = init_ras_project(project_path, "5.0.7")
    
    print("Available plans:")
    print(whisky_project.plan_df)
    print()
    
    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel_whisky"
    results_all = RasCmdr.compute_parallel(
        max_workers=2,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.6")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()
    
    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific_whisky"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores) if num_cores > 0 else 1
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic_whisky"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.6")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()


==================================================

File: c:\GH\ras-commander\examples\18_benchmarking_version_6.6.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasHdf, RasUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define versions to compare\n",
    "versions = ['6.6', '6.5', '6.4.1', '6.3.1', '6.2', '6.1', '5.0.7']\n",
    "\n",
    "# Extract BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "project_path = ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all plan numbers\n",
    "ras_project = init_ras_project(project_path, \"6.5\")\n",
    "print(ras_project)\n",
    "plan_numbers = ras_project.plan_df['plan_number'].tolist()\n",
    "print(plan_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ras_commander import RasGeo\n",
    "\n",
    "def run_simulation(version, plan_number):\n",
    "    # Initialize project for the specific version\n",
    "    ras_project = init_ras_project(project_path, str(version))\n",
    "    \n",
    "    # Clear geometry preprocessor files\n",
    "    plan_path = RasPlan.get_plan_path(plan_number, ras_object=ras_project)\n",
    "    RasGeo.clear_geompre_files(plan_path, ras_object=ras_project)\n",
    "    \n",
    "    # Set number of cores to 6\n",
    "    RasPlan.set_num_cores(plan_number, \"6\", ras_object=ras_project)\n",
    "    \n",
    "    # Ensure geometry preprocessing is done\n",
    "    RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=ras_project)\n",
    "    \n",
    "    # Compute the plan\n",
    "    start_time = time.time()\n",
    "    success = RasCmdr.compute_plan(plan_number, ras_object=ras_project)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    if success:\n",
    "        # Get HDF file path\n",
    "        hdf_path = RasPlan.get_results_path(plan_number, ras_object=ras_project)\n",
    "        \n",
    "        # Extract data from HDF file\n",
    "        runtime_data = RasHdf.get_runtime_data(hdf_path, ras_object=ras_project)\n",
    "        \n",
    "        # Extract required information\n",
    "        preprocessor_time = runtime_data['Preprocessing Geometry (hr)'].values[0]\n",
    "        unsteady_compute_time = runtime_data['Unsteady Flow Computations (hr)'].values[0]\n",
    "        \n",
    "        # Get volume accounting data\n",
    "        volume_accounting = RasHdf.get_group_attributes_as_df(hdf_path, \"Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D\", ras_object=ras_project)\n",
    "        volume_error = volume_accounting['Volume Error (%)'].values[0]\n",
    "        \n",
    "        return {\n",
    "            'Version': version,\n",
    "            'Plan': plan_number,\n",
    "            'Preprocessor Time (hr)': preprocessor_time,\n",
    "            'Unsteady Compute Time (hr)': unsteady_compute_time,\n",
    "            'Volume Error (%)': volume_error,\n",
    "            'Total Time (hr)': total_time / 3600  # Convert seconds to hours\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run simulations for all versions and plans sequentially\n",
    "results = []\n",
    "for version in versions:\n",
    "    for plan in plan_numbers:\n",
    "        print(f\"Running simulation for Version {version}, Plan {plan}\")\n",
    "        result = run_simulation(version, plan)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"Completed: Version {version}, Plan {plan}\")\n",
    "        else:\n",
    "            print(f\"Failed: Version {version}, Plan {plan}\")\n",
    "\n",
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save initial results to CSV\n",
    "df.to_csv('save_initial_results.csv', index=False)\n",
    "\n",
    "print(\"Initial results saved to 'save_initial_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages across plans for each version\n",
    "df_avg = df.groupby('Version').mean().reset_index()\n",
    "\n",
    "# Create line graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Unsteady Runtime vs Version\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_avg['Version'], df_avg['Unsteady Compute Time (hr)'], marker='o')\n",
    "plt.title('Average Unsteady Runtime vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Unsteady Runtime (hours)')\n",
    "\n",
    "# Volume Error vs Version\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_avg['Version'], df_avg['Volume Error (%)'], marker='o')\n",
    "plt.title('Average Volume Error vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Volume Error (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "df.to_csv('hecras_version_comparison.csv', index=False)\n",
    "df_avg.to_csv('hecras_version_comparison_averages.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'hecras_version_comparison.csv' and 'hecras_version_comparison_averages.csv'\")\n",
    "print(\"Graphs have been displayed. Please check the output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fffff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\19_1d_hdf_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 1D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray','rtree']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import pyproj\n","from shapely.geometry import Point, LineString, Polygon\n","import xarray as xr\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# Install ras-commander if you are not in a dev environment. \n","# install_module(ras-commander)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","\n","print(\"ras_commander imported successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the BaldEagleCrkMulti2D project from HEC and run plan 01\n","\n","# Define the path to the BaldEagleCrkMulti2D project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","bald_eagle_path = current_dir / \"example_projects\" / \"Balde Eagle Creek\"\n","import logging\n","\n","# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = bald_eagle_path / \"BaldEagle.p01.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"Balde Eagle Creek\"])\n","\n","    # Initialize custom Ras object\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    logging.info(f\"Balde Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Balde Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"01\"\n","\n","    # Execute Plan 06 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"BaldEagle.p01.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = RasPrj()\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    plan_number = \"01\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n","\n","# Display plan_df for bald_eagle project\n","print(\"Plan DataFrame for bald_eagle project:\")\n","display(bald_eagle.plan_df)\n","\n","# Display geom_df for bald_eagle project\n","print(\"\\nGeometry DataFrame for bald_eagle project:\")\n","display(bald_eagle.geom_df)\n","\n","# Get the plan HDF path\n","plan_number = \"01\"  # Assuming we're using plan 01 as in the previous code\n","plan_hdf_path = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n","\n","# Get the geometry file number from the plan DataFrame\n","geom_file = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n","geom_number = geom_file[1:]  # Remove the 'g' prefix\n","\n","# Get the geometry HDF path\n","geom_hdf_path = bald_eagle.geom_df.loc[bald_eagle.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n","\n","print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n","print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"markdown","metadata":{},"source":["RasHdfUtils\n","| Method Name | Description |\n","|-------------|-------------|\n","| get_attrs | Converts attributes from a HEC-RAS HDF file into a Python dictionary for a given attribute path |\n","| get_root_attrs | Returns attributes at root level of HEC-RAS HDF file |\n","| get_hdf_paths_with_properties | Gets all paths in the HDF file with their properties |\n","| get_group_attributes_as_df | Gets attributes of a group in the HDF file as a DataFrame |\n","| get_hdf_filename | Gets the HDF filename from various input types |\n","| get_runtime_data | Extracts runtime and compute time data from a single HDF file |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get HDF Paths with Properties (For Exploring HDF Files)\n","hdf_paths_df = HdfUtils.get_hdf_paths_with_properties(plan_number, ras_object=bald_eagle)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = HdfResultsPlan.get_runtime_data(hdf_input=plan_number, ras_object=bald_eagle)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"markdown","metadata":{},"source":["Table of all the functions in the RasGeomHdf class from the ras_commander/RasGeomHdf.py file:\n","\n","| Function Name | Description |\n","|---------------|-------------|\n","| projection | Returns the projection of the RAS geometry as a pyproj.CRS object |\n","| get_geom_attrs | Returns base geometry attributes from a HEC-RAS HDF file |\n","\n","| mesh_area_names | Returns a list of the 2D mesh area names of the RAS geometry |\n","| get_geom_2d_flow_area_attrs | Returns geometry 2d flow area attributes from a HEC-RAS HDF file |\n","| mesh_areas | Returns 2D flow area perimeter polygons |\n","| mesh_cell_polygons | Returns 2D flow mesh cell polygons |\n","| mesh_cell_points | Returns 2D flow mesh cell points |\n","| mesh_cell_faces | Returns 2D flow mesh cell faces |\n","\n","| get_geom_structures_attrs | Returns geometry structures attributes from a HEC-RAS HDF file |\n","\n","\n","\n","\n","| bc_lines | Returns 2D mesh area boundary condition lines |\n","| breaklines | Returns 2D mesh area breaklines |\n","\n","\n","\n","| refinement_regions | Returns 2D mesh area refinement regions |\n","| structures | Returns the model structures |\n","| reference_lines_names | Returns reference line names |\n","| reference_points_names | Returns reference point names |\n","| reference_lines | Returns the reference lines geometry and attributes |\n","| reference_points | Returns the reference points geometry and attributes |\n","| cross_sections | Returns the model 1D cross sections |\n","| river_reaches | Returns the model 1D river reach lines |\n","| cross_sections_elevations | Returns the model cross section elevation information |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n","print(geom_hdf_path)\n","\n","# For the example project, plan 06 is associated with geometry 09\n","# If you want to call the geometry by number, call RasHdfGeom functions with a number\n","# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfUtils for extracting projection\n","print(\"\\nExtracting Projection from HDF\")\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Projection: {projection}\")\n","else:\n","    print(\"No projection information found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfPlan for geometry-related operations\n","print(\"\\nExample: Extracting Base Geometry Attributes\")\n","geom_attrs = HdfPlan.get_geom_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if geom_attrs:\n","    # Convert the dictionary to a DataFrame for better display\n","    geom_attrs_df = pd.DataFrame([geom_attrs])\n","    \n","    # Display the DataFrame\n","    print(\"Base Geometry Attributes:\")\n","    display(geom_attrs_df)\n","else:\n","    print(\"No base geometry attributes found.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfMesh for geometry-related operations\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get geometry structures attributes\n","print(\"\\nGetting geometry structures attributes\")\n","geom_structures_attrs = HdfStruc.get_geom_structures_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if geom_structures_attrs:\n","    print(\"Geometry structures attributes:\")\n","    for key, value in geom_structures_attrs.items():\n","        print(f\"{key}: {value}\")\n","else:\n","    print(\"No geometry structures attributes found.\")"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["# TODO: Paths and Functions for each type of structure: \n","\n","# Getting geometry structures attributes\n","# Geometry structures attributes:\n","# Bridge/Culvert Count: 0\n","# Connection Count: 4\n","# Has Bridge Opening (2D): 0\n","# Inline Structure Count: 0\n","# Lateral Structure Count: 0"]},{"cell_type":"markdown","metadata":{},"source":["### NEED TO EDIT THIS TO SHOW BC LINES WITH RIVERS AND CROSS SECTIONS"]},{"cell_type":"markdown","metadata":{},"source":["# Example: Extract Boundary Condition Lines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 7: Extracting Boundary Condition Lines and Plotting with 2D Flow Area Perimeter Polygons\")\n","bc_lines_df = HdfBndry.bc_lines(geom_hdf_path, ras_object=bald_eagle)\n","if not bc_lines_df.empty:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines found.\")\n","\n","# Plot if data exists\n","if not bc_lines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot boundary condition lines\n","    if not bc_lines_df.empty:\n","        bc_lines_df.plot(ax=ax, color='red', linewidth=2, label='Boundary Condition Lines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Boundary Condition Lines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# INSTEAD OF hdf_input, USE plan_hdf_path or geom_hdf_path as appropriate "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get structures\n","structures_gdf = HdfStruc.structures(geom_hdf_path, ras_object=bald_eagle)\n","print(\"Structures:\")\n","if not structures_gdf.empty:\n","    display(structures_gdf.head())\n","else:\n","    print(\"No structures found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference line names\n","ref_line_names = HdfBndry.reference_lines_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Line Names:\")\n","print(ref_line_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference point names\n","ref_point_names = HdfBndry.reference_points_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Point Names:\")\n","print(ref_point_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference lines\n","ref_lines_gdf = HdfBndry.reference_lines(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines:\")\n","if not ref_lines_gdf.empty:\n","    display(ref_lines_gdf.head())\n","else:\n","    print(\"No reference lines found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference points\n","ref_points_gdf = HdfBndry.reference_points(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points:\")\n","if not ref_points_gdf.empty:\n","    display(ref_points_gdf.head())\n","else:\n","    print(\"No reference points found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{"image.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{},"source":["![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Recursively explore the Cross Sections structure in the geometry HDF file\n","import h5py\n","def print_hdf_structure(name, obj):\n","    \"\"\"Print information about HDF5 object\"\"\"\n","    print(f\"\\nPath: {name}\")\n","    print(f\"Type: {type(obj).__name__}\")\n","    \n","    if isinstance(obj, h5py.Dataset):\n","        print(f\"Shape: {obj.shape}\")\n","        print(f\"Dtype: {obj.dtype}\")\n","        print(\"Attributes:\")\n","        for key, value in obj.attrs.items():\n","            print(f\"  {key}: {value}\")\n","\n","def explore_cross_sections(file_path):\n","    \"\"\"\n","    Recursively explore and print Cross Sections structure in HDF5 file\n","    \n","    :param file_path: Path to the HDF5 file\n","    \"\"\"\n","    try:\n","        with h5py.File(file_path, 'r') as hdf_file:\n","            if '/Geometry/Cross Sections' in hdf_file:\n","                xs_group = hdf_file['/Geometry/Cross Sections']\n","                xs_group.visititems(print_hdf_structure)\n","            else:\n","                print(\"Cross Sections group not found in geometry file\")\n","    except Exception as e:\n","        print(f\"Error exploring HDF file: {e}\")\n","\n","print(\"\\nExploring Cross Sections structure in geometry file:\")\n","print(\"HDF Base Path: /Geometry/Cross Sections \")\n","explore_cross_sections(geom_hdf_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get cross section geodataframe\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","with pd.option_context('display.max_columns', None):  # Show all columns\n","    display(cross_sections_gdf)"]},{"cell_type":"markdown","metadata":{},"source":["cross_sections_gdf: \n","\n","| geometry | station_elevation | mannings_n | ineffective_blocks | River | Reach | RS | Name | Description | Len Left | Len Channel | Len Right | Left Bank | Right Bank | Friction Mode | Contr | Expan | Left Levee Sta | Left Levee Elev | Right Levee Sta | Right Levee Elev | HP Count | HP Start Elev | HP Vert Incr | HP LOB Slices | HP Chan Slices | HP ROB Slices | Ineff Block Mode | Obstr Block Mode | Default Centerline | Last Edited |\n","|-----------|-------------------|------------|--------------------|-------|-------|----|------|-------------|----------|-------------|-----------|-----------|------------|----------------|-------|-------|----------------|-----------------|----------------|------------------|----------|----------------|---------------|----------------|----------------|----------------|------------------|------------------|-------------------|--------------|\n","| 0         | LINESTRING (1968668.17 290166.79, 1969067.87 2... | [[0.0, 660.41], [5.0, 660.61], [40.0, 659.85],... | {'Station': [0.0, 190.0, 375.0], 'Mann n': [0.... | []    | Bald Eagle | Loc Hav | 138154.4 |             | 358.429993 | 463.640015 | 517.640015 | 190.000000 | 375.000000 | Basic Mann n | 0.1   | 0.3   | NaN            | NaN             | NaN            | NaN              | 49       | 656.799988      | 1.0           | 5              | 5              | 5              | 0                | 0                | 0                 | 18Sep2000 09:10:52 |\n","| 1         | LINESTRING (1968627.02 290584.12, 1969009.09 2... | [[0.0, 664.28], [50.0, 661.73], [55.0, 661.54]... | {'Station': [0.0, 535.0, 672.5599975585938], '... | []    | Bald Eagle | Loc Hav | 137690.8 |             | 305.709991 | 363.839996 | 382.829987 | 535.000000 | 672.559998 | Basic Mann n | 0.1   | 0.3   | NaN            | NaN             | NaN            | NaN              | 65       | 654.229980      | 1.0           | 5              | 5              | 5              | 0                | 0                | 0                 | 18Sep2000 09:10:52 |\n","| 2         | LINESTRING (1968585.88 290854.5, 1968868.02 29... | [[0.0, 662.72], [20.0, 665.5], [25.0, 666.48],... | {'Station': [0.0, 580.0, 717.239990234375], 'M... | []    | Bald Eagle | Loc Hav | 137327.0 |             | 732.929993 | 762.020020 | 765.359985 | 580.000000 | 717.239990 | Basic Mann n | 0.1   | 0.3   | NaN            | NaN             | NaN            | NaN              | 66       | 653.900024      | 1.0           | 5              | 5              | 5              | 0                | 0                | 0                 | 18Sep2000 09:10:52 |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter cross sections to show only those with ineffective blocks\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","\n","if not cross_sections_gdf.empty:\n","    # Filter rows where ineffective_blocks is not empty\n","    ineffective_xs = cross_sections_gdf[cross_sections_gdf['ineffective_blocks'].apply(len) > 0]\n","    \n","    if not ineffective_xs.empty:\n","        print(\"\\nCross Sections with Ineffective Flow Areas:\")\n","        display(ineffective_xs)\n","    else:\n","        print(\"\\nNo cross sections found with ineffective flow areas.\")\n","else:\n","    print(\"No cross sections found in the geometry file.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross sections data\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross Section Information:\")\n","if not cross_sections_gdf.empty:\n","    for idx, row in cross_sections_gdf.iterrows():\n","        print(f\"\\nCross Section {idx + 1}:\")\n","        print(f\"River: {row['River']}\")\n","        print(f\"Reach: {row['Reach']}\")\n","        print(\"\\nGeometry:\")\n","        print(row['geometry'])\n","        print(\"\\nStation-Elevation Points:\")\n","        \n","        # Print header\n","        print(\"     #      Station   Elevation        #      Station   Elevation        #      Station   Elevation        #      Station   Elevation        #      Station   Elevation\")\n","        print(\"-\" * 150)\n","        \n","        # Calculate number of rows needed\n","        points = row['station_elevation']\n","        num_rows = (len(points) + 4) // 5  # Round up division\n","        \n","        # Print points in 5 columns\n","        for i in range(num_rows):\n","            line = \"\"\n","            for j in range(5):\n","                point_idx = i + j * num_rows\n","                if point_idx < len(points):\n","                    station, elevation = points[point_idx]\n","                    line += f\"{point_idx+1:6d} {station:10.2f} {elevation:10.2f}    \"\n","            print(line)\n","        print(\"-\" * 150)\n","else:\n","    print(\"No cross sections found in the geometry file.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot cross sections on map\n","import matplotlib.pyplot as plt\n","\n","# Get cross sections data\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","\n","if not cross_sections_gdf.empty:\n","    # Create figure and axis\n","    fig, ax = plt.subplots(figsize=(15,10))\n","    \n","    # Plot cross sections\n","    cross_sections_gdf.plot(ax=ax, color='red', linewidth=1, label='Cross Sections')\n","    \n","    # Add river name and reach labels\n","    #for idx, row in cross_sections_gdf.iterrows():\n","    #    # Get midpoint of cross section line for label placement\n","    #    midpoint = row.geometry.centroid\n","    #    label = f\"{row['River']}\\n{row['Reach']}\\nRS: {row['RS']}\"\n","    #    ax.annotate(label, (midpoint.x, midpoint.y), \n","    #               xytext=(5, 5), textcoords='offset points',\n","    #               fontsize=8, bbox=dict(facecolor='white', alpha=0.7))\n","    \n","    # Customize plot\n","    ax.set_title('Cross Sections Location Map')\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Equal aspect ratio to preserve shape\n","    ax.set_aspect('equal')\n","    \n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cross sections found in the geometry file.\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot cross sections with Manning's n values colored by value\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from shapely.geometry import LineString\n","\n","# Get cross sections data\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Create figure\n","fig, ax1 = plt.subplots(figsize=(20,10))\n","\n","# Create colormap\n","cmap = plt.cm.viridis\n","norm = plt.Normalize(vmin=0.02, vmax=0.08)  # Typical Manning's n range\n","\n","# Plot cross sections colored by Manning's n\n","for idx, row in cross_sections_gdf.iterrows():\n","    # Extract Manning's n values and stations\n","    mannings = row['mannings_n']\n","    n_values = mannings['Mann n']\n","    stations = mannings['Station']\n","    \n","    # Get the full linestring coordinates\n","    line_coords = list(row.geometry.coords)\n","    \n","    # Calculate total length of the cross section\n","    total_length = row.geometry.length\n","    \n","    # For each Manning's n segment\n","    for i in range(len(n_values)-1):\n","        # Calculate the start and end proportions along the line\n","        start_prop = stations[i] / stations[-1]\n","        end_prop = stations[i+1] / stations[-1]\n","        \n","        # Get the start and end points for this segment\n","        start_idx = int(start_prop * (len(line_coords)-1))\n","        end_idx = int(end_prop * (len(line_coords)-1))\n","        \n","        # Extract the segment coordinates\n","        segment_coords = line_coords[start_idx:end_idx+1]\n","        \n","        if len(segment_coords) >= 2:\n","            # Create a line segment\n","            segment = LineString(segment_coords)\n","            \n","            # Get color from colormap for this n value\n","            color = cmap(norm(n_values[i]))\n","            \n","            # Plot the segment\n","            ax1.plot(*segment.xy, color=color, linewidth=2)\n","\n","# Add colorbar\n","sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n","sm.set_array([])\n","plt.colorbar(sm, ax=ax1, label=\"Manning's n Value\")\n","\n","ax1.set_title(\"Cross Sections Colored by Manning's n Values\")\n","ax1.grid(True)\n","ax1.set_aspect('equal')\n","\n","plt.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot cross sections with ineffective flow areas\n","import matplotlib.pyplot as plt\n","\n","# Get cross sections data\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Create figure\n","fig, ax2 = plt.subplots(figsize=(20,10))\n","\n","# Plot all cross sections first\n","cross_sections_gdf.plot(ax=ax2, color='lightgray', linewidth=1, label='Cross Sections')\n","\n","# Plot ineffective flow areas with thicker lines\n","ineffective_sections = cross_sections_gdf[cross_sections_gdf['ineffective_blocks'].apply(lambda x: len(x) > 0)]\n","ineffective_sections.plot(ax=ax2, color='red', linewidth=3, label='Ineffective Flow Areas')\n","\n","# Add ineffective flow area labels with offset to lower right\n","for idx, row in cross_sections_gdf.iterrows():\n","    # Get midpoint of cross section line\n","    midpoint = row.geometry.centroid\n","    \n","    # Extract ineffective flow blocks\n","    ineff_blocks = row['ineffective_blocks']\n","    \n","    if ineff_blocks:  # Only label if there are ineffective blocks\n","        label_parts = []\n","        # Add RS to first line of label\n","        label_parts.append(f\"RS: {row['RS']}\")\n","        for block in ineff_blocks:\n","            label_parts.append(\n","                f\"L:{block['Left Sta']:.0f}-R:{block['Right Sta']:.0f}\\n\"\n","                f\"Elev: {block['Elevation']:.2f}\\n\"\n","                f\"Permanent: {block['Permanent']}\"\n","            )\n","        \n","        label = '\\n'.join(label_parts)\n","        \n","        ax2.annotate(label, (midpoint.x, midpoint.y),\n","                    xytext=(15, -15),  # Offset to lower right\n","                    textcoords='offset points',\n","                    fontsize=8, \n","                    bbox=dict(facecolor='white', alpha=0.7),\n","                    arrowprops=dict(arrowstyle='->'),\n","                    horizontalalignment='left',\n","                    verticalalignment='top')\n","\n","ax2.set_title('Cross Sections with Ineffective Flow Areas')\n","ax2.grid(True)\n","ax2.legend()\n","ax2.set_aspect('equal')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot cross section elevation for cross section 42\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Get cross sections data\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","\n","if not cross_sections_gdf.empty:\n","    # Get station-elevation data for cross section 42\n","    station_elevation = cross_sections_gdf.iloc[42]['station_elevation']\n","    \n","    # Convert list of lists to numpy arrays for plotting\n","    stations = np.array([point[0] for point in station_elevation])\n","    elevations = np.array([point[1] for point in station_elevation])\n","    \n","    # Create figure and axis\n","    fig, ax = plt.subplots(figsize=(12,8))\n","    \n","    # Plot cross section\n","    ax.plot(stations, elevations, 'b-', linewidth=2)\n","    \n","    # Add labels and title\n","    river = cross_sections_gdf.iloc[42]['River']\n","    reach = cross_sections_gdf.iloc[42]['Reach'] \n","    rs = cross_sections_gdf.iloc[42]['RS']\n","    \n","    # Show bank stations as dots\n","    left_bank_station = cross_sections_gdf.iloc[42]['Left Bank']\n","    right_bank_station = cross_sections_gdf.iloc[42]['Right Bank']\n","    \n","    # Interpolating bank stations for plotting\n","    ax.plot(left_bank_station, elevations[np.searchsorted(stations, left_bank_station)], 'ro', label='Left Bank Station')\n","    ax.plot(right_bank_station, elevations[np.searchsorted(stations, right_bank_station)], 'ro', label='Right Bank Station')\n","    \n","    ax.set_title(f'Cross Section Profile\\nRiver: {river}, Reach: {reach}, RS: {rs}\\n'\n","                 f'Left Bank Station: {left_bank_station}, Right Bank Station: {right_bank_station}')\n","    ax.set_xlabel('Station (ft)')\n","    ax.set_ylabel('Elevation (ft)')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cross sections found in the geometry file.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def explore_river_centerlines(file_path):\n","    \"\"\"\n","    Recursively explore and print River Centerlines structure in HDF5 file\n","    \n","    :param file_path: Path to the HDF5 file\n","    \"\"\"\n","    try:\n","        with h5py.File(file_path, 'r') as hdf_file:\n","            if '/Geometry/River Centerlines' in hdf_file:\n","                group = hdf_file['/Geometry/River Centerlines']\n","                group.visititems(print_hdf_structure)\n","            else:\n","                print(\"River Centerlines group not found in geometry file\")\n","    except Exception as e:\n","        print(f\"Error exploring HDF file: {e}\")\n","        \n","print(\"\\nExploring geometry file structures:\")\n","print(\"\\nRiver Centerlines:\")\n","explore_river_centerlines(geom_hdf_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example usage:\n","centerlines = HdfXsec.river_centerlines(geom_hdf_path)\n","centerlines_with_stations = HdfXsec.get_river_stationing(centerlines)\n","\n","# Display results\n","print(\"\\nRiver Centerlines:\")\n","display(centerlines.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot river centerlines with labels\n","import matplotlib.pyplot as plt\n","import geopandas as gpd\n","\n","# Create figure and axis\n","fig, ax = plt.subplots(figsize=(15, 10))\n","\n","# Plot centerlines\n","centerlines.plot(ax=ax, color='blue', linewidth=2, label='River Centerline')\n","\n","# Add river/reach labels\n","for idx, row in centerlines.iterrows():\n","    # Get midpoint of the line for label placement\n","    midpoint = row.geometry.interpolate(0.5, normalized=True)\n","    \n","    # Create label text combining river and reach names\n","    label = f\"{row['River Name']}\\n{row['Reach Name']}\"\n","    \n","    # Add text annotation\n","    ax.annotate(label, \n","                xy=(midpoint.x, midpoint.y),\n","                xytext=(10, 10), # Offset text slightly\n","                textcoords='offset points',\n","                fontsize=10,\n","                bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n","\n","# Add labels and title\n","ax.set_title('River Centerlines', fontsize=14)\n","ax.set_xlabel('Easting', fontsize=12)\n","ax.set_ylabel('Northing', fontsize=12)\n","\n","# Add legend\n","ax.legend(fontsize=12)\n","\n","# Add grid\n","ax.grid(True)\n","\n","# Adjust layout\n","plt.tight_layout()\n","\n","# Show plot\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def explore_river_edge_lines(file_path):\n","    \"\"\"\n","    Recursively explore and print River Edge Lines structure in HDF5 file\n","    \n","    :param file_path: Path to the HDF5 file \n","    \"\"\"\n","    try:\n","        with h5py.File(file_path, 'r') as hdf_file:\n","            if '/Geometry/River Edge Lines' in hdf_file:\n","                group = hdf_file['/Geometry/River Edge Lines']\n","                group.visititems(print_hdf_structure)\n","            else:\n","                print(\"River Edge Lines group not found in geometry file\")\n","    except Exception as e:\n","        print(f\"Error exploring HDF file: {e}\")\n","        \n","print(\"\\nRiver Edge Lines:\")\n","explore_river_edge_lines(geom_hdf_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Example usage:\n","edge_lines = HdfXsec.river_edge_lines(geom_hdf_path)\n","centerlines = HdfXsec.river_centerlines(geom_hdf_path)\n","#Display results\n","print(\"\\nRiver Edge Lines:\")\n","display(edge_lines.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example usage:\n","bank_lines = HdfXsec.river_bank_lines(geom_hdf_path)\n","# Display results\n","print(\"\\nRiver Bank Lines:\")\n","display(bank_lines.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create figure and axis\n","fig, ax = plt.subplots(figsize=(15, 10))\n","\n","# Plot river edge lines\n","edge_lines.plot(ax=ax, color='blue', linewidth=2, label='River Edge Lines')\n","\n","# Plot centerlines for reference\n","centerlines.plot(ax=ax, color='red', linewidth=2, linestyle='--', label='River Centerline')\n","\n","# Plot river bank lines\n","bank_lines.plot(ax=ax, color='green', linewidth=2, label='River Bank Lines')\n","\n","# Add title and labels\n","ax.set_title('River Edge Lines, Centerline, and Bank Lines', fontsize=14)\n","ax.set_xlabel('Easting', fontsize=12)\n","ax.set_ylabel('Northing', fontsize=12)\n","\n","# Add legend\n","ax.legend(fontsize=12)\n","\n","# Add grid\n","ax.grid(True)\n","\n","# Adjust layout\n","plt.tight_layout()\n","\n","# Show plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get dataset structure:\n","HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/River Bank Lines/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Function to explore HDF file to assist with 1D Structures Data Extraction "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","HdfUtils.explore_hdf5(plan_hdf_path, \"/Results/Unsteady/Output/Output Blocks/Computation Block/Global/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/Structures\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract 1D Structures Geodataframe\n","\n","# Import required functions\n","from ras_commander.HdfStruc import HdfStruc\n","from ras_commander.HdfXsec import HdfXsec\n","\n","# Create instances\n","hdf_struc = HdfStruc()\n","hdf_xsec = HdfXsec()\n","\n","# Extract data into GeoDataFrames\n","structures_gdf = HdfStruc.structures(hdf_path=geom_hdf_path, datetime_to_str=True)\n","cross_sections_gdf = HdfXsec.cross_sections(hdf_path=geom_hdf_path, datetime_to_str=True)\n","centerlines_gdf = HdfXsec.river_centerlines(hdf_path=geom_hdf_path)\n","\n","# Display basic information about the structures\n","print(\"\\nStructures Summary:\")\n","print(f\"Number of structures found: {len(structures_gdf)}\")\n","display(structures_gdf)\n","\n","# Display first few rows of key attributes\n","print(\"\\nStructure Details:\")\n","display_cols = ['Structure ID', 'Structure Type', 'River Name', 'Reach Name', 'Station']\n","display_cols = [col for col in display_cols if col in structures_gdf.columns]\n","if display_cols:\n","    print(structures_gdf[display_cols].head())\n","\n","# Create visualization\n","fig, ax = plt.subplots(figsize=(15, 10))\n","\n","# Plot river centerlines\n","if not centerlines_gdf.empty:\n","    centerlines_gdf.plot(ax=ax, color='blue', linewidth=2, label='River Centerlines')\n","\n","# Plot cross sections\n","if not cross_sections_gdf.empty:\n","    cross_sections_gdf.plot(ax=ax, color='green', linewidth=1, label='Cross Sections')\n","\n","# Plot structures\n","if not structures_gdf.empty:\n","    structures_gdf.plot(ax=ax, color='red', marker='s', markersize=100, label='Structures')\n","\n","# Add title and labels\n","ax.set_title('HEC-RAS Model Components', fontsize=14)\n","ax.set_xlabel('Easting', fontsize=12)\n","ax.set_ylabel('Northing', fontsize=12)\n","\n","# Add legend\n","ax.legend(fontsize=12)\n","\n","# Add grid\n","ax.grid(True)\n","\n","# Adjust layout\n","plt.tight_layout()\n","\n","# Show plot\n","plt.show()\n","\n","# Print summary of cross sections\n","print(\"\\nCross Sections Summary:\")\n","print(f\"Number of cross sections found: {len(cross_sections_gdf)}\")\n","if not cross_sections_gdf.empty:\n","    print(\"\\nCross Section Details:\")\n","    xs_display_cols = ['River', 'Reach', 'Station']\n","    xs_display_cols = [col for col in xs_display_cols if col in cross_sections_gdf.columns]\n","    if xs_display_cols:\n","        print(cross_sections_gdf[xs_display_cols].head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract Compute Messages as String\n","print(\"Extracting Compute Messages\")\n","\n","import h5py\n","import numpy as np\n","\n","def extract_string_from_hdf(results_hdf_filename: str, hdf_path: str) -> str:\n","    \"\"\"\n","    Extract string from HDF object at a given path\n","\n","    Parameters\n","    ----------\n","    results_hdf_filename : str\n","        Name of the HDF file\n","    hdf_path : str\n","        Path of the object in the HDF file\n","\n","    Returns\n","    -------\n","    str\n","        Extracted string from the specified HDF object\n","    \"\"\"\n","    with h5py.File(results_hdf_filename, 'r') as hdf_file:\n","        try:\n","            hdf_object = hdf_file[hdf_path]\n","            if isinstance(hdf_object, h5py.Group):\n","                return f\"Group: {hdf_path}\\nContents: {list(hdf_object.keys())}\"\n","            elif isinstance(hdf_object, h5py.Dataset):\n","                data = hdf_object[()]\n","                if isinstance(data, bytes):\n","                    return data.decode('utf-8')\n","                elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':\n","                    return [v.decode('utf-8') for v in data]\n","                else:\n","                    return str(data)\n","            else:\n","                return f\"Unsupported object type: {type(hdf_object)}\"\n","        except KeyError:\n","            return f\"Path not found: {hdf_path}\"\n","\n","try:\n","    results_summary_string = extract_string_from_hdf(plan_hdf_path, '/Results/Summary/Compute Messages (text)')\n","    print(\"Compute Messages:\")\n","    \n","    # Parse and print the compute messages in a more visually friendly way\n","    messages = results_summary_string[0].split('\\r\\n')\n","    \n","    for message in messages:\n","        if message.strip():  # Skip empty lines\n","            if ':' in message:\n","                key, value = message.split(':', 1)\n","                print(f\"{key.strip():40} : {value.strip()}\")\n","            else:\n","                print(f\"\\n{message.strip()}\")\n","    \n","    # Print computation summary in a table format\n","    print(\"\\nComputation Summary:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Computation Task':<30} {'Time':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Task' in line:\n","            task, time = line.split('\\t')\n","            print(f\"{task:<30} {time:<20}\")\n","    \n","    print(\"\\nComputation Speed:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Task':<30} {'Simulation/Runtime':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Speed' in line:\n","            task, speed = line.split('\\t')\n","            print(f\"{task:<30} {speed:<20}\")\n","\n","except Exception as e:\n","    print(f\"Error extracting compute messages: {str(e)}\")\n","    print(\"\\nNote: If 'Results/Summary Output' is not in the file structure, it might indicate that the simulation didn't complete successfully or the results weren't saved properly.\")\n","\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# TODO: Convert this code cell to parse 1D compute messages\n","\n","The example project doesn't have any 1D errors to use as an example\n","\n","```\n","# Advanced Compute Messages Example - TODO: Move this function into a class of the library \n","import pandas as pd\n","import re\n","import matplotlib.pyplot as plt\n","import geopandas as gpd\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","\n","def parse_2d_compute_messages(compute_messages):\n","    \"\"\"\n","    Parse 2D compute messages to extract data lines, clean the data, \n","    and retrieve top 20 cells with the highest error.\n","\n","    Parameters:\n","        compute_messages (list or str): The raw compute messages.\n","\n","    Returns:\n","        tuple: A tuple containing the parsed compute messages string and the main DataFrame.\n","    \"\"\"\n","    try:\n","        # Handle both list and string inputs\n","        if isinstance(compute_messages, list):\n","            compute_messages = '\\n'.join(compute_messages)\n","        elif not isinstance(compute_messages, str):\n","            logging.error(f\"Unexpected type for compute_messages: {type(compute_messages)}\")\n","            return \"\", pd.DataFrame()\n","\n","        # Split the message into lines\n","        lines = compute_messages.split('\\n')\n","        logging.info(\"Successfully split compute messages into lines.\")\n","        \n","        # Initialize lists to store parsed data\n","        data_lines = []\n","        header_lines = []\n","        footer_lines = []\n","        \n","        # Regular expression to match timestamp lines\n","        timestamp_pattern = re.compile(r'^\\d{2}[A-Z]{3}\\d{4}\\s+\\d{2}:\\d{2}:\\d{2}')\n","        logging.debug(\"Compiled timestamp regular expression.\")\n","        \n","        data_started = False\n","        for line in lines:\n","            stripped_line = line.strip()\n","            if timestamp_pattern.match(stripped_line):\n","                data_started = True\n","                # Split the line and add to data_lines\n","                parts = stripped_line.split()\n","                if len(parts) >= 8:  # Ensure we have all expected columns\n","                    # Combine Date and Time into 'Date and Time'\n","                    date_time = f\"{parts[0]} {parts[1]}\"\n","                    location = parts[2]\n","                    cell_type = f\"{parts[3]} {parts[4]}\"\n","                    cell_number = parts[5]\n","                    wsel = parts[6]\n","                    error = parts[7]\n","                    iterations = parts[8] if len(parts) > 8 else None\n","                    data_lines.append([date_time, location, cell_type, cell_number, wsel, error, iterations])\n","                    logging.debug(f\"Parsed data line: {data_lines[-1]}\")\n","                else:\n","                    logging.warning(f\"Line skipped due to insufficient parts: {stripped_line}\")\n","            elif not data_started:\n","                header_lines.append(stripped_line)\n","            elif data_started and not stripped_line:\n","                data_started = False\n","            elif not data_started:\n","                footer_lines.append(stripped_line)\n","        \n","        # Create DataFrame from data lines\n","        df = pd.DataFrame(\n","            data_lines, \n","            columns=['Date and Time', 'Location', 'Cell Type', 'Cell Number', 'WSEL', 'ERROR', 'ITERATIONS']\n","        )\n","        logging.info(\"Created DataFrame from parsed data lines.\")\n","        \n","        # Clean and convert columns to appropriate types\n","        df['Cell Number'] = (\n","            pd.to_numeric(df['Cell Number'].replace('#', pd.NA), errors='coerce')\n","            .fillna(-1)\n","            .astype('Int64')\n","        )\n","        df['WSEL'] = pd.to_numeric(df['WSEL'], errors='coerce')\n","        df['ERROR'] = pd.to_numeric(df['ERROR'], errors='coerce')\n","        df['ITERATIONS'] = pd.to_numeric(df['ITERATIONS'], errors='coerce').astype('Int64')\n","        logging.info(\"Converted DataFrame columns to appropriate types.\")\n","        \n","        # Get top 20 cells with highest error\n","        top_20_cells = (\n","            df.sort_values('ERROR', ascending=False)\n","            .drop_duplicates('Cell Number')\n","            .head(20)\n","        )\n","        \n","        # Construct the reordered message\n","        reordered_message = '\\n'.join(header_lines + \n","                                      ['\\nTop 20 Cells with Highest Error:'] + \n","                                      [' '.join(map(str, row)) for row in top_20_cells.values] + \n","                                      ['\\n'] + footer_lines)\n","        \n","        logging.info(\"Reordered compute messages.\")\n","        \n","        return reordered_message, df\n","    except Exception as e:\n","        logging.error(f\"Error parsing compute messages: {e}\")\n","        return \"\", pd.DataFrame()\n","\n","# Use the function to parse compute messages\n","parsed_messages, df = parse_2d_compute_messages(results_summary_string)\n","\n","print(parsed_messages)\n","print(df)\n","\n","# Get top 20 cells with highest error\n","if not df.empty and 'ERROR' in df.columns:\n","    top_20_cells = (\n","        df.sort_values('ERROR', ascending=False)\n","        .drop_duplicates('Cell Number')\n","        .head(20)\n","    )\n","else:\n","    logging.warning(\"Unable to get top 20 cells with highest error. DataFrame is empty or 'ERROR' column is missing.\")\n","    top_20_cells = pd.DataFrame()\n","\n","# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)\n","\n","print(\"\\n2D Flow Area Groups and Perimeters:\")\n","if not mesh_areas.empty:\n","    print(\"Available columns:\", mesh_areas.columns.tolist())\n","    \n","    # Display the first few rows of the mesh_areas DataFrame\n","    print(\"\\nFirst few rows of mesh_areas DataFrame:\")\n","    display(mesh_areas.head())\n","else:\n","    print(\"No 2D Flow Area groups found in the HDF file.\")\n","\n","# Use the previously extracted cell_polygons_df\n","print(\"\\nTop 20 Cell Polygons:\")\n","if 'cell_polygons_df' in locals() and not cell_polygons_df.empty and not top_20_cells.empty:\n","    # Get the cell numbers from top_20_cells\n","    top_20_cell_numbers = top_20_cells['Cell Number'].tolist()\n","    \n","    # Filter cell_polygons_df to only include top 20 cells\n","    top_20_cell_polygons = cell_polygons_df[cell_polygons_df['cell_id'].isin(top_20_cell_numbers)]\n","    \n","    display(top_20_cell_polygons)\n","\n","    # Plot top 20 cell polygons and mesh areas\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot mesh areas\n","    mesh_areas.plot(ax=ax, edgecolor='red', facecolor='none', alpha=0.5, label='Mesh Areas')\n","    \n","    # Plot top 20 cell polygons\n","    top_20_cell_polygons.plot(ax=ax, edgecolor='blue', facecolor='none', alpha=0.7, label='Top 20 Error Cells')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Perimeters and Top 20 Cell Polygons')\n","    \n","    # Add legend\n","    ax.legend()\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No Cell Polygons found or no top 20 cells with highest error available.\")\n","    print(\"Unable to plot cell polygons.\")\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 12: Extract Plan Parameters and Volume Accounting\n","print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n","\n","# Extract plan parameters\n","plan_parameters_df = HdfPlan.get_plan_param_attrs(plan_hdf_path)\n","\n","# Extract volume accounting data\n","volume_accounting_df = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path)\n","\n","print(\"\\nPlan Parameters DataFrame:\")\n","display(plan_parameters_df)\n","\n","print(\"\\nVolume Accounting DataFrame:\")\n","display(volume_accounting_df)"]},{"cell_type":"markdown","metadata":{},"source":["# RasPlanHdf Class Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation start time\n","start_time = HdfPlan.get_simulation_start_time(plan_hdf_path)\n","print(f\"Simulation start time: {start_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation end time\n","end_time = HdfPlan.get_simulation_end_time(plan_hdf_path)\n","print(f\"Simulation end time: {end_time}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Modify the cell below to time of max wsel for 1D models"]},{"cell_type":"markdown","metadata":{},"source":["# Plot the time of the max water surface elevation (WSEL)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","from datetime import datetime\n","\n","# Convert the 'maximum_water_surface_time' to datetime objects first\n","merged_df['max_wsel_time'] = pd.to_datetime(merged_df['maximum_water_surface_time'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Convert datetime to hours since the start for colormap\n","min_time = merged_df['max_wsel_time'].min()\n","color_values = (merged_df['max_wsel_time'] - min_time).dt.total_seconds() / 3600  # Convert to hours\n","\n","scatter = ax.scatter(merged_df['x'], merged_df['y'], \n","                     c=color_values, \n","                     cmap='viridis', \n","                     s=10)\n","\n","# Customize the plot\n","ax.set_title('Time of Maximum Water Surface Elevation per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","\n","# Set up the colorbar\n","cbar = plt.colorbar(scatter)\n","cbar.set_label('Hours since simulation start')\n","\n","# Format the colorbar ticks to show hours\n","cbar.set_ticks(range(0, int(color_values.max()) + 1, 6))  # Set ticks every 6 hours\n","cbar.set_ticklabels([f'{h}h' for h in range(0, int(color_values.max()) + 1, 6)])\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","\n","# Find the overall maximum WSEL and its time\n","max_wsel_row = merged_df.loc[merged_df['maximum_water_surface'].idxmax()]\n","hours_since_start = (max_wsel_row['max_wsel_time'] - min_time).total_seconds() / 3600\n","print(f\"\\nOverall Maximum WSEL: {max_wsel_row['maximum_water_surface']:.2f} ft\")\n","print(f\"Time of Overall Maximum WSEL: {max_wsel_row['max_wsel_time']}\")\n","print(f\"Hours since simulation start: {hours_since_start:.2f} hours\")\n","print(f\"Location of Overall Maximum WSEL: X={max_wsel_row['x']}, Y={max_wsel_row['y']}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Need to add this to the ras-commander library"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get meteorology precipitation attributes\n","meteo_precip_attrs = HdfPlan.get_meteorology_precip_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMeteorology Precipitation Attributes:\")\n","for key, value in meteo_precip_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady attributes\n","results_unsteady_attrs = HdfResultsPlan.get_results_unsteady_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Attributes:\")\n","for key, value in results_unsteady_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady summary attributes\n","results_unsteady_summary_attrs = HdfResultsPlan.get_results_unsteady_summary_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Summary Attributes:\")\n","for key, value in results_unsteady_summary_attrs.items():\n","    print(f\"{key}: {value}\")\n","\n","# Get results volume accounting attributes\n","volume_accounting_attrs = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nVolume Accounting Attributes:\")\n","for key, value in volume_accounting_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\n=== HDF5 File Structure ===\\n\")\n","print(plan_hdf_path)\n","explore_hdf5(plan_hdf_path, group_path='/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Cross Sections')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xsec_results = HdfResultsXsec.extract_cross_section_results(plan_hdf_path)\n","print(xsec_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print time series for specific cross section\n","target_xs = \"Bald Eagle       Loc Hav          136202.3\"\n","\n","print(\"\\nTime Series Data for Cross Section:\", target_xs)\n","for var in ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']:\n","    print(f\"\\n{var}:\")\n","    print(xsec_results[var].sel(cross_section=target_xs).values[:5])  # Show first 5 values\n","\n","# Create time series plots\n","import matplotlib.pyplot as plt\n","\n","# Create a figure for each variable\n","variables = ['Water_Surface', 'Velocity_Total', 'Velocity_Channel', 'Flow_Lateral', 'Flow']\n","\n","for var in variables:\n","    plt.figure(figsize=(10, 5))\n","    # Convert time values to datetime if needed\n","    time_values = pd.to_datetime(xsec_results.time.values)\n","    values = xsec_results[var].sel(cross_section=target_xs).values\n","    \n","    # Plot with explicit x and y values\n","    plt.plot(time_values, values, '-', linewidth=2)\n","    \n","    plt.title(f'{var} at {target_xs}')\n","    plt.xlabel('Time')\n","    plt.ylabel(var.replace('_', ' '))\n","    plt.grid(True)\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","    \n","    # Force display\n","    plt.draw()\n","    plt.pause(0.1)\n","    plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\20_2d_hdf_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 2D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray', 'rasterio']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import pyproj\n","from shapely.geometry import Point, LineString, Polygon\n","import xarray as xr\n","from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n","import matplotlib.patches as patches\n","from matplotlib.patches import ConnectionPatch\n","import logging\n","from pathlib import Path\n","import rasterio\n","from rasterio.plot import show\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Install ras-commander if you are not in a dev environment. \n","# install_module(ras-commander)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","\n","print(\"ras_commander imported successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the BaldEagleCrkMulti2D project from HEC and run plan 01\n","\n","# Define the path to the BaldEagleCrkMulti2D project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n","import logging\n","\n","# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = bald_eagle_path / \"BaldEagleDamBrk.p06.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n","\n","    # Initialize custom Ras object\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"06\"\n","\n","    # Update run flags for the project\n","    RasPlan.update_run_flags(\n","        plan_number,\n","        geometry_preprocessor=True,\n","        unsteady_flow_simulation=True,\n","        run_sediment=False,\n","        post_processor=True,\n","        floodplain_mapping=False,\n","        ras_object=bald_eagle\n","    )\n","\n","    # Execute Plan 06 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"BaldEagleCrkMulti2D.p06.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = RasPrj()\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    plan_number = \"06\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n","\n","# Display plan_df for bald_eagle project\n","print(\"Plan DataFrame for bald_eagle project:\")\n","display(bald_eagle.plan_df)\n","\n","# Display geom_df for bald_eagle project\n","print(\"\\nGeometry DataFrame for bald_eagle project:\")\n","display(bald_eagle.geom_df)\n","\n","# Get the plan HDF path\n","plan_number = \"06\"  # Assuming we're using plan 01 as in the previous code\n","plan_hdf_path = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n","\n","# Get the geometry file number from the plan DataFrame\n","geom_file = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n","geom_number = geom_file[1:]  # Remove the 'g' prefix\n","\n","# Get the geometry HDF path\n","geom_hdf_path = bald_eagle.geom_df.loc[bald_eagle.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n","\n","print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n","print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Define the HDF input path as Plan Number\n","\n","plan_number = \"06\"  # Assuming we're using plan 01 as in the previous code\n"]},{"cell_type":"markdown","metadata":{},"source":["RasHdfUtils\n","| Method Name | Description |\n","|-------------|-------------|\n","| get_attrs | Converts attributes from a HEC-RAS HDF file into a Python dictionary for a given attribute path |\n","| get_root_attrs | Returns attributes at root level of HEC-RAS HDF file |\n","| get_hdf_paths_with_properties | Gets all paths in the HDF file with their properties |\n","| get_group_attributes_as_df | Gets attributes of a group in the HDF file as a DataFrame |\n","| get_hdf_filename | Gets the HDF filename from various input types |\n","| get_runtime_data | Extracts runtime and compute time data from a single HDF file |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get HDF Paths with Properties (For Exploring HDF Files)\n","plan_number = \"06\"  # Assuming we're using plan 06 as in the previous code\n","hdf_paths_df = HdfUtils.get_hdf_paths_with_properties(plan_number, ras_object=bald_eagle)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = HdfResultsPlan.get_runtime_data(hdf_input=plan_number, ras_object=bald_eagle)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"markdown","metadata":{},"source":["Table of all the functions in the RasGeomHdf class from the ras_commander/RasGeomHdf.py file:\n","\n","| Function Name | Description |\n","|---------------|-------------|\n","| projection | Returns the projection of the RAS geometry as a pyproj.CRS object |\n","| get_geom_attrs | Returns base geometry attributes from a HEC-RAS HDF file |\n","\n","| mesh_area_names | Returns a list of the 2D mesh area names of the RAS geometry |\n","| get_geom_2d_flow_area_attrs | Returns geometry 2d flow area attributes from a HEC-RAS HDF file |\n","| mesh_areas | Returns 2D flow area perimeter polygons |\n","| mesh_cell_polygons | Returns 2D flow mesh cell polygons |\n","| mesh_cell_points | Returns 2D flow mesh cell points |\n","| mesh_cell_faces | Returns 2D flow mesh cell faces |\n","\n","| get_geom_structures_attrs | Returns geometry structures attributes from a HEC-RAS HDF file |\n","\n","\n","\n","\n","| bc_lines | Returns 2D mesh area boundary condition lines |\n","| breaklines | Returns 2D mesh area breaklines |\n","\n","\n","\n","| refinement_regions | Returns 2D mesh area refinement regions |\n","| structures | Returns the model structures |\n","| reference_lines_names | Returns reference line names |\n","| reference_points_names | Returns reference point names |\n","| reference_lines | Returns the reference lines geometry and attributes |\n","| reference_points | Returns the reference points geometry and attributes |\n","| cross_sections | Returns the model 1D cross sections |\n","| river_reaches | Returns the model 1D river reach lines |\n","| cross_sections_elevations | Returns the model cross section elevation information |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n","print(geom_hdf_path)\n","\n","# For the example project, plan 06 is associated with geometry 09\n","# If you want to call the geometry by number, call RasHdfGeom functions with a number\n","# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfUtils for extracting projection\n","print(\"\\nExtracting Projection from HDF\")\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Projection: {projection}\")\n","else:\n","    print(\"No projection information found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfPlan for geometry-related operations\n","print(\"\\nExample: Extracting Base Geometry Attributes\")\n","geom_attrs = HdfPlan.get_geom_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if geom_attrs:\n","    # Convert the dictionary to a DataFrame for better display\n","    geom_attrs_df = pd.DataFrame([geom_attrs])\n","    \n","    # Display the DataFrame\n","    print(\"Base Geometry Attributes:\")\n","    display(geom_attrs_df)\n","else:\n","    print(\"No base geometry attributes found.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfMesh for geometry-related operations\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Attributes (get_geom_2d_flow_area_attrs)\n","print(\"\\nExample: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_df = pd.DataFrame([flow_area_attributes])\n","    \n","    # Display the DataFrame\n","    print(\"2D Flow Area Attributes:\")\n","    display(flow_area_df)\n","    \n","    # Optionally, you can access specific attributes\n","    print(\"\\nSpecific Attribute Examples:\")\n","    print(f\"Cell Average Size: {flow_area_attributes.get('Cell Average Size', 'N/A')}\")\n","    print(f\"Manning's n: {flow_area_attributes.get('Manning''s n', 'N/A')}\")\n","    print(f\"Terrain Filename: {flow_area_attributes.get('Terrain Filename', 'N/A')}\")\n","else:\n","    print(\"No 2D Flow Area attributes found.\")\n","\n","# Note: This example assumes that get_geom_2d_flow_area_attrs returns a dictionary.\n","# If it returns a different format, you may need to adjust the code accordingly.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the 2D Flow Area Perimeter Polygons\n","import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(figsize=(12, 8))\n","mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none')\n","\n","# Add labels for each polygon\n","for idx, row in mesh_areas.iterrows():\n","    centroid = row.geometry.centroid\n","    # Check if 'Name' column exists, otherwise use a default label\n","    label = row.get('Name', f'Area {idx}')\n","    ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","\n","plt.title('2D Flow Area Perimeter Polygons')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract mesh cell faces\n","print(\"\\nExample: Extracting mesh cell faces\")\n","\n","# Get mesh cell faces\n","mesh_cell_faces = HdfMesh.mesh_cell_faces(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Display the first few rows of the mesh cell faces DataFrame\n","print(\"First few rows of mesh cell faces:\")\n","display(mesh_cell_faces.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the mesh cell faces\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Plot all cell faces\n","for _, row in mesh_cell_faces.iterrows():\n","    ax.plot(*row['geometry'].xy, color='blue', linewidth=0.5, alpha=0.5)\n","\n","# Set plot title and labels\n","plt.title('Mesh Cell Faces')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","\n","# Add a colorbar to show face IDs\n","scatter = ax.scatter(\n","    mesh_cell_faces.geometry.centroid.x,\n","    mesh_cell_faces.geometry.centroid.y,\n","    c=mesh_cell_faces['face_id'],\n","    cmap='viridis',\n","    s=1,\n","    alpha=0.5\n",")\n","plt.colorbar(scatter, label='Face ID')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calculate and display some statistics\n","print(\"\\nMesh Cell Faces Statistics:\")\n","print(f\"Total number of cell faces: {len(mesh_cell_faces)}\")\n","print(f\"Number of unique meshes: {mesh_cell_faces['mesh_name'].nunique()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to find the nearest cell face to a given point\n","def find_nearest_cell_face(point, cell_faces_df):\n","    \"\"\"\n","    Find the nearest cell face to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_faces_df (GeoDataFrame): DataFrame containing cell face linestrings.\n","\n","    Returns:\n","        int: The face_id of the nearest cell face.\n","        float: The distance to the nearest cell face.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell faces\n","    distances = cell_faces_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the face_id and distance of the nearest cell face\n","    nearest_face_id = cell_faces_df.loc[nearest_index, 'face_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_face_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell face to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Get the projection from the geometry file\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Using projection: {projection}\")\n","else:\n","    print(\"No projection information found. Using default CRS.\")\n","    projection = \"EPSG:4326\"  # Default to WGS84 if no projection is found\n","\n","# Create the sample point with the correct CRS\n","sample_point = GeoDataFrame({'geometry': [Point(2042250, 351750)]}, crs=projection)\n","\n","if not mesh_cell_faces.empty and not sample_point.empty:\n","    # Ensure the CRS of the sample point matches the mesh_cell_faces\n","    if sample_point.crs != mesh_cell_faces.crs:\n","        sample_point = sample_point.to_crs(mesh_cell_faces.crs)\n","    \n","    nearest_face_id, distance = find_nearest_cell_face(sample_point.geometry.iloc[0], mesh_cell_faces)\n","    print(f\"Nearest cell face to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Face ID: {nearest_face_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell faces\n","    mesh_cell_faces.plot(ax=ax, color='blue', linewidth=0.5, alpha=0.5, label='Cell Faces')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell face\n","    nearest_face = mesh_cell_faces[mesh_cell_faces['face_id'] == nearest_face_id]\n","    nearest_face.plot(ax=ax, color='green', linewidth=2, alpha=0.7, label='Nearest Face')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell Face to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell face search due to missing data.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Cell Polygons\n","print(\"\\nExample 6: Extracting Cell Polygons\")\n","cell_polygons_df = HdfMesh.mesh_cell_polygons(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_polygons_df.empty:\n","    display(cell_polygons_df.head())\n","else:\n","    print(\"No Cell Polygons found.\")\n","\n","# Plot cell polygons\n","if not cell_polygons_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell polygons\n","    cell_polygons_df.plot(ax=ax, edgecolor='blue', facecolor='none')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Polygons')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell polygon data available for plotting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 5: Extract Cell Info\n","print(\"\\nExample 5: Extracting Cell Info\")\n","cell_info_df = HdfMesh.mesh_cell_points(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_info_df.empty:\n","    display(cell_info_df.head())\n","else:\n","    print(\"No Cell Info found.\")\n","\n","# Plot cell centers\n","import matplotlib.pyplot as plt\n","\n","if not cell_info_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell centers\n","    cell_info_df.plot(ax=ax, color='red', markersize=5)\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Centers')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell data available for plotting.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Provide function that will accept a geopandas point object and will find the nearest cell center\n","# Function to find the nearest cell center to a given point\n","def find_nearest_cell(point, cell_centers_df):\n","    \"\"\"\n","    Find the nearest cell center to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_centers_df (GeoDataFrame): DataFrame containing cell center points.\n","\n","    Returns:\n","        int: The cell_id of the nearest cell.\n","        float: The distance to the nearest cell center.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell centers\n","    distances = cell_centers_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the cell_id and distance of the nearest cell\n","    nearest_cell_id = cell_centers_df.loc[nearest_index, 'cell_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_cell_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Get the projection from the geometry file\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Using projection: {projection}\")\n","else:\n","    print(\"No projection information found. Using default CRS.\")\n","    projection = \"EPSG:4326\"  # Default to WGS84 if no projection is found\n","\n","# Create the sample point with the correct CRS\n","sample_point = GeoDataFrame({'geometry': [Point(2083500, 370800)]}, crs=projection)\n","\n","if not cell_info_df.empty and not sample_point.empty:\n","    # Ensure the CRS of the sample point matches the cell_info_df\n","    if sample_point.crs != cell_info_df.crs:\n","        sample_point = sample_point.to_crs(cell_info_df.crs)\n","    \n","    nearest_cell_id, distance = find_nearest_cell(sample_point.geometry.iloc[0], cell_info_df)\n","    print(f\"Nearest cell to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Cell ID: {nearest_cell_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell centers\n","    cell_info_df.plot(ax=ax, color='blue', markersize=5, alpha=0.5, label='Cell Centers')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell center\n","    nearest_cell = cell_info_df[cell_info_df['cell_id'] == nearest_cell_id]\n","    nearest_cell.plot(ax=ax, color='green', markersize=100, alpha=0.7, label='Nearest Cell')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell search due to missing data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get geometry structures attributes\n","print(\"\\nGetting geometry structures attributes\")\n","geom_structures_attrs = HdfStruc.get_geom_structures_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if geom_structures_attrs:\n","    print(\"Geometry structures attributes:\")\n","    for key, value in geom_structures_attrs.items():\n","        print(f\"{key}: {value}\")\n","else:\n","    print(\"No geometry structures attributes found.\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# TODO: Paths and Functions for each type of structure: \n","\n","# Getting geometry structures attributes\n","# Geometry structures attributes:\n","# Bridge/Culvert Count: 0\n","# Connection Count: 4\n","# Has Bridge Opening (2D): 0\n","# Inline Structure Count: 0\n","# Lateral Structure Count: 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Boundary Condition Lines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 7: Extracting Boundary Condition Lines and Plotting with 2D Flow Area Perimeter Polygons\")\n","bc_lines_df = HdfBndry.bc_lines(geom_hdf_path, ras_object=bald_eagle)\n","if not bc_lines_df.empty:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines found.\")\n","\n","# Plot if data exists\n","if not bc_lines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot boundary condition lines\n","    if not bc_lines_df.empty:\n","        bc_lines_df.plot(ax=ax, color='red', linewidth=2, label='Boundary Condition Lines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Boundary Condition Lines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Breaklines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 8: Extracting Breaklines and Plotting with 2D Flow Area Perimeter Polygons\")\n","breaklines_df = HdfBndry.breaklines(geom_hdf_path, ras_object=bald_eagle)\n","if not breaklines_df.empty:\n","    display(breaklines_df.head())\n","else:\n","    print(\"No Breaklines found.\")\n","\n","# Plot breaklines and 2D Flow Area Perimeter Polygons if they exist\n","if not breaklines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot breaklines\n","    if not breaklines_df.empty:\n","        breaklines_df.plot(ax=ax, color='blue', linewidth=2, label='Breaklines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Breaklines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# INSTEAD OF hdf_input, USE plan_hdf_path or geom_hdf_path as appropriate "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get structures\n","structures_gdf = HdfStruc.structures(geom_hdf_path, ras_object=bald_eagle)\n","print(\"Structures:\")\n","if not structures_gdf.empty:\n","    display(structures_gdf.head())\n","else:\n","    print(\"No structures found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference line names\n","ref_line_names = HdfBndry.reference_lines_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Line Names:\")\n","print(ref_line_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference point names\n","ref_point_names = HdfBndry.reference_points_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Point Names:\")\n","print(ref_point_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference lines\n","ref_lines_gdf = HdfBndry.reference_lines(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines:\")\n","if not ref_lines_gdf.empty:\n","    display(ref_lines_gdf.head())\n","else:\n","    print(\"No reference lines found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference points\n","ref_points_gdf = HdfBndry.reference_points(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points:\")\n","if not ref_points_gdf.empty:\n","    display(ref_points_gdf.head())\n","else:\n","    print(\"No reference points found in the geometry file.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Extract Breakline as Reference Line\n","\n","We can't use a profile line, because the mesh orientation may be quite different than the direction of flow.  \n","\n","Instead, use a breakline - the one named \"SayersDam\" should work\n","\n","We can find the information specific to faces: \n","\n","\n","\n","\n","\n","\n","# Extract Composite Results for 2D at Profile Lines to simulate Reference Lines\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Refinement Regions\n","print(\"\\nExample: Extracting Refinement Regions\")\n","\n","# Make sure to pass the bald_eagle object as the ras_object parameter\n","refinement_regions_df = HdfBndry.refinement_regions(geom_hdf_path, ras_object=bald_eagle)\n","\n","if not refinement_regions_df.empty:\n","    print(\"Refinement Regions DataFrame:\")\n","    display(refinement_regions_df.head())\n","    \n","    # Plot refinement regions\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    refinement_regions_df.plot(ax=ax, column='CellSize', legend=True, \n","                               legend_kwds={'label': 'Cell Size', 'orientation': 'horizontal'},\n","                               cmap='viridis')\n","    ax.set_title('2D Mesh Area Refinement Regions')\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No refinement regions found in the geometry file.\")\n","\n","# Example: Analyze Refinement Regions\n","if not refinement_regions_df.empty:\n","    print(\"\\nRefinement Regions Analysis:\")\n","    print(f\"Total number of refinement regions: {len(refinement_regions_df)}\")\n","    print(\"\\nCell Size Statistics:\")\n","    print(refinement_regions_df['CellSize'].describe())\n","    \n","    # Group by Shape Type\n","    shape_type_counts = refinement_regions_df['ShapeType'].value_counts()\n","    print(\"\\nRefinement Region Shape Types:\")\n","    print(shape_type_counts)\n","    \n","    # Plot Shape Type distribution\n","    plt.figure(figsize=(10, 6))\n","    shape_type_counts.plot(kind='bar')\n","    plt.title('Distribution of Refinement Region Shape Types')\n","    plt.xlabel('Shape Type')\n","    plt.ylabel('Count')\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract Compute Messages as String\n","print(\"Extracting Compute Messages\")\n","\n","import h5py\n","import numpy as np\n","\n","def extract_string_from_hdf(results_hdf_filename: str, hdf_path: str) -> str:\n","    \"\"\"\n","    Extract string from HDF object at a given path\n","\n","    Parameters\n","    ----------\n","    results_hdf_filename : str\n","        Name of the HDF file\n","    hdf_path : str\n","        Path of the object in the HDF file\n","\n","    Returns\n","    -------\n","    str\n","        Extracted string from the specified HDF object\n","    \"\"\"\n","    with h5py.File(results_hdf_filename, 'r') as hdf_file:\n","        try:\n","            hdf_object = hdf_file[hdf_path]\n","            if isinstance(hdf_object, h5py.Group):\n","                return f\"Group: {hdf_path}\\nContents: {list(hdf_object.keys())}\"\n","            elif isinstance(hdf_object, h5py.Dataset):\n","                data = hdf_object[()]\n","                if isinstance(data, bytes):\n","                    return data.decode('utf-8')\n","                elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':\n","                    return [v.decode('utf-8') for v in data]\n","                else:\n","                    return str(data)\n","            else:\n","                return f\"Unsupported object type: {type(hdf_object)}\"\n","        except KeyError:\n","            return f\"Path not found: {hdf_path}\"\n","\n","try:\n","    results_summary_string = extract_string_from_hdf(plan_hdf_path, '/Results/Summary/Compute Messages (text)')\n","    print(\"Compute Messages:\")\n","    \n","    # Parse and print the compute messages in a more visually friendly way\n","    messages = results_summary_string[0].split('\\r\\n')\n","    \n","    for message in messages:\n","        if message.strip():  # Skip empty lines\n","            if ':' in message:\n","                key, value = message.split(':', 1)\n","                print(f\"{key.strip():40} : {value.strip()}\")\n","            else:\n","                print(f\"\\n{message.strip()}\")\n","    \n","    # Print computation summary in a table format\n","    print(\"\\nComputation Summary:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Computation Task':<30} {'Time':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Task' in line:\n","            task, time = line.split('\\t')\n","            print(f\"{task:<30} {time:<20}\")\n","    \n","    print(\"\\nComputation Speed:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Task':<30} {'Simulation/Runtime':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Speed' in line:\n","            task, speed = line.split('\\t')\n","            print(f\"{task:<30} {speed:<20}\")\n","\n","except Exception as e:\n","    print(f\"Error extracting compute messages: {str(e)}\")\n","    print(\"\\nNote: If 'Results/Summary Output' is not in the file structure, it might indicate that the simulation didn't complete successfully or the results weren't saved properly.\")\n","\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Advanced Compute Messages Example - TODO: Move this function into a class of the library \n","import pandas as pd\n","import re\n","import matplotlib.pyplot as plt\n","import geopandas as gpd\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","\n","def parse_2d_compute_messages(compute_messages):\n","    \"\"\"\n","    Parse 2D compute messages to extract data lines, clean the data, \n","    and retrieve top 20 cells with the highest error.\n","\n","    Parameters:\n","        compute_messages (list or str): The raw compute messages.\n","\n","    Returns:\n","        tuple: A tuple containing the parsed compute messages string and the main DataFrame.\n","    \"\"\"\n","    try:\n","        # Handle both list and string inputs\n","        if isinstance(compute_messages, list):\n","            compute_messages = '\\n'.join(compute_messages)\n","        elif not isinstance(compute_messages, str):\n","            logging.error(f\"Unexpected type for compute_messages: {type(compute_messages)}\")\n","            return \"\", pd.DataFrame()\n","\n","        # Split the message into lines\n","        lines = compute_messages.split('\\n')\n","        logging.info(\"Successfully split compute messages into lines.\")\n","        \n","        # Initialize lists to store parsed data\n","        data_lines = []\n","        header_lines = []\n","        footer_lines = []\n","        \n","        # Regular expression to match timestamp lines\n","        timestamp_pattern = re.compile(r'^\\d{2}[A-Z]{3}\\d{4}\\s+\\d{2}:\\d{2}:\\d{2}')\n","        logging.debug(\"Compiled timestamp regular expression.\")\n","        \n","        data_started = False\n","        for line in lines:\n","            stripped_line = line.strip()\n","            if timestamp_pattern.match(stripped_line):\n","                data_started = True\n","                # Split the line and add to data_lines\n","                parts = stripped_line.split()\n","                if len(parts) >= 8:  # Ensure we have all expected columns\n","                    # Combine Date and Time into 'Date and Time'\n","                    date_time = f\"{parts[0]} {parts[1]}\"\n","                    location = parts[2]\n","                    cell_type = f\"{parts[3]} {parts[4]}\"\n","                    cell_number = parts[5]\n","                    wsel = parts[6]\n","                    error = parts[7]\n","                    iterations = parts[8] if len(parts) > 8 else None\n","                    data_lines.append([date_time, location, cell_type, cell_number, wsel, error, iterations])\n","                    logging.debug(f\"Parsed data line: {data_lines[-1]}\")\n","                else:\n","                    logging.warning(f\"Line skipped due to insufficient parts: {stripped_line}\")\n","            elif not data_started:\n","                header_lines.append(stripped_line)\n","            elif data_started and not stripped_line:\n","                data_started = False\n","            elif not data_started:\n","                footer_lines.append(stripped_line)\n","        \n","        # Create DataFrame from data lines\n","        df = pd.DataFrame(\n","            data_lines, \n","            columns=['Date and Time', 'Location', 'Cell Type', 'Cell Number', 'WSEL', 'ERROR', 'ITERATIONS']\n","        )\n","        logging.info(\"Created DataFrame from parsed data lines.\")\n","        \n","        # Clean and convert columns to appropriate types\n","        df['Cell Number'] = (\n","            pd.to_numeric(df['Cell Number'].replace('#', pd.NA), errors='coerce')\n","            .fillna(-1)\n","            .astype('Int64')\n","        )\n","        df['WSEL'] = pd.to_numeric(df['WSEL'], errors='coerce')\n","        df['ERROR'] = pd.to_numeric(df['ERROR'], errors='coerce')\n","        df['ITERATIONS'] = pd.to_numeric(df['ITERATIONS'], errors='coerce').astype('Int64')\n","        logging.info(\"Converted DataFrame columns to appropriate types.\")\n","        \n","        # Get top 20 cells with highest error\n","        top_20_cells = (\n","            df.sort_values('ERROR', ascending=False)\n","            .drop_duplicates('Cell Number')\n","            .head(20)\n","        )\n","        \n","        # Construct the reordered message\n","        reordered_message = '\\n'.join(header_lines + \n","                                      ['\\nTop 20 Cells with Highest Error:'] + \n","                                      [' '.join(map(str, row)) for row in top_20_cells.values] + \n","                                      ['\\n'] + footer_lines)\n","        \n","        logging.info(\"Reordered compute messages.\")\n","        \n","        return reordered_message, df\n","    except Exception as e:\n","        logging.error(f\"Error parsing compute messages: {e}\")\n","        return \"\", pd.DataFrame()\n","\n","# Use the function to parse compute messages\n","parsed_messages, df = parse_2d_compute_messages(results_summary_string)\n","\n","print(parsed_messages)\n","print(df)\n","\n","# Get top 20 cells with highest error\n","if not df.empty and 'ERROR' in df.columns:\n","    top_20_cells = (\n","        df.sort_values('ERROR', ascending=False)\n","        .drop_duplicates('Cell Number')\n","        .head(20)\n","    )\n","else:\n","    logging.warning(\"Unable to get top 20 cells with highest error. DataFrame is empty or 'ERROR' column is missing.\")\n","    top_20_cells = pd.DataFrame()\n","\n","# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)\n","\n","print(\"\\n2D Flow Area Groups and Perimeters:\")\n","if not mesh_areas.empty:\n","    print(\"Available columns:\", mesh_areas.columns.tolist())\n","    \n","    # Display the first few rows of the mesh_areas DataFrame\n","    print(\"\\nFirst few rows of mesh_areas DataFrame:\")\n","    display(mesh_areas.head())\n","else:\n","    print(\"No 2D Flow Area groups found in the HDF file.\")\n","\n","# Use the previously extracted cell_polygons_df\n","print(\"\\nTop 20 Cell Polygons:\")\n","if 'cell_polygons_df' in locals() and not cell_polygons_df.empty and not top_20_cells.empty:\n","    # Get the cell numbers from top_20_cells\n","    top_20_cell_numbers = top_20_cells['Cell Number'].tolist()\n","    \n","    # Filter cell_polygons_df to only include top 20 cells\n","    top_20_cell_polygons = cell_polygons_df[cell_polygons_df['cell_id'].isin(top_20_cell_numbers)]\n","    \n","    display(top_20_cell_polygons)\n","\n","    # Plot top 20 cell polygons and mesh areas\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot mesh areas\n","    mesh_areas.plot(ax=ax, edgecolor='red', facecolor='none', alpha=0.5, label='Mesh Areas')\n","    \n","    # Plot top 20 cell polygons\n","    top_20_cell_polygons.plot(ax=ax, edgecolor='blue', facecolor='none', alpha=0.7, label='Top 20 Error Cells')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Perimeters and Top 20 Cell Polygons')\n","    \n","    # Add legend\n","    ax.legend()\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No Cell Polygons found or no top 20 cells with highest error available.\")\n","    print(\"Unable to plot cell polygons.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exploratory Example for Debugging or New Features: List all paths, groups, and attributes under \"/Results/Unsteady/Summary/Volume Accounting\"\n","print(\"\\nListing paths, groups, and attributes under '/Results/Unsteady/Summary/Volume Accounting'\")\n","\n","from ras_commander import HdfUtils\n","\n","def list_hdf_structure(hdf_path: str, group_path: str) -> None:\n","    with h5py.File(hdf_path, 'r') as hdf:\n","        if group_path not in hdf:\n","            print(f\"Group '{group_path}' not found in the HDF file.\")\n","            return\n","\n","        def print_group_structure(name: str, obj: h5py.Group) -> None:\n","            indent = '  ' * name.count('/')\n","            if isinstance(obj, h5py.Group):\n","                print(f\"{indent}{name} (Group)\")\n","                for attr_name, attr_value in obj.attrs.items():\n","                    print(f\"{indent}  Attribute: {attr_name} = {attr_value}\")\n","            elif isinstance(obj, h5py.Dataset):\n","                print(f\"{indent}{name} (Dataset)\")\n","                for attr_name, attr_value in obj.attrs.items():\n","                    print(f\"{indent}  Attribute: {attr_name} = {attr_value}\")\n","\n","        hdf[group_path].visititems(print_group_structure)\n","\n","try:\n","    list_hdf_structure(plan_hdf_path, \"/Results/Unsteady/Summary/Volume Accounting\")\n","except Exception as e:\n","    print(f\"An error occurred while listing HDF structure: {str(e)}\")\n","\n","# Additional error handling and logging\n","logger = logging.getLogger(__name__)\n","logger.info(\"Finished listing HDF structure for Volume Accounting\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 12: Extract Plan Parameters and Volume Accounting\n","print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n","\n","# Extract plan parameters\n","plan_parameters_df = HdfPlan.get_plan_param_attrs(plan_hdf_path)\n","\n","# Extract volume accounting data\n","volume_accounting_df = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path)\n","\n","print(\"\\nPlan Parameters DataFrame:\")\n","display(plan_parameters_df)\n","\n","print(\"\\nVolume Accounting DataFrame:\")\n","display(volume_accounting_df)"]},{"cell_type":"markdown","metadata":{},"source":["------"]},{"cell_type":"markdown","metadata":{},"source":["# RasPlanHdf Class Functions"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation start time\n","start_time = HdfPlan.get_simulation_start_time(plan_hdf_path)\n","print(f\"Simulation start time: {start_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation end time\n","end_time = HdfPlan.get_simulation_end_time(plan_hdf_path)\n","print(f\"Simulation end time: {end_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract 2D Flow Area Attributes \n","print(\"\\nExample 4: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_attributes_df = pd.DataFrame([flow_area_attributes])\n","    display(flow_area_attributes_df)\n","else:\n","    print(\"No 2D Flow Area attributes found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max iterations\n","max_iter_df = HdfResultsMesh.mesh_max_iter(plan_hdf_path)\n","print(\"\\nMesh Max Iterations:\")\n","print(max_iter_df.attrs)\n","display(max_iter_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using mesh_max_iter, get the cell coordinates and plot the max iterations as a map\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max iterations\n","max_iter_df = HdfResultsMesh.mesh_max_iter(plan_hdf_path)\n","\n","print(\"max_iter_df\")\n","print(max_iter_df)\n","\n","# Get cell coordinates \n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max iterations with cell coordinates\n","merged_df = pd.merge(max_iter_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Print available columns for debugging\n","print(\"\\nAvailable columns:\", merged_df.columns.tolist())\n","\n","# Extract x and y coordinates from the geometry columns\n","# The error suggests geometry_x and geometry_y are the correct column names\n","merged_df['x'] = merged_df['geometry_x'].apply(lambda geom: geom.x if geom is not None else None)\n","merged_df['y'] = merged_df['geometry_y'].apply(lambda geom: geom.y if geom is not None else None)\n","\n","# Remove rows with None coordinates\n","merged_df = merged_df.dropna(subset=['x', 'y'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(merged_df['x'], merged_df['y'], \n","                    c=merged_df['cell_last_iteration'], \n","                    cmap='viridis', \n","                    s=1)\n","\n","# Customize the plot\n","ax.set_title('Max Iterations per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Iterations')\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max water surface\n","max_ws_df = HdfResultsMesh.mesh_max_ws(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Max Water Surface:\")\n","print(max_ws_df.attrs)\n","display(max_ws_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using mesh_max_ws, get the cell coordinates and plot the max water surface as a map\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max water surface\n","max_ws_df = HdfResultsMesh.mesh_max_ws(plan_hdf_path, ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max water surface with cell coordinates\n","merged_df = pd.merge(max_ws_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Print available columns for debugging\n","print(\"\\nAvailable columns:\", merged_df.columns.tolist())\n","\n","# Extract x and y coordinates from the geometry columns\n","merged_df['x'] = merged_df['geometry_x'].apply(lambda geom: geom.x if geom is not None else None)\n","merged_df['y'] = merged_df['geometry_y'].apply(lambda geom: geom.y if geom is not None else None)\n","\n","# Remove rows with None coordinates\n","merged_df = merged_df.dropna(subset=['x', 'y'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(merged_df['x'], merged_df['y'], \n","                    c=merged_df['maximum_water_surface'], \n","                    cmap='viridis', \n","                    s=10)\n","\n","# Customize the plot\n","ax.set_title('Max Water Surface per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Water Surface (ft)')\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the time of the max water surface elevation (WSEL)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","from datetime import datetime\n","\n","# Convert the 'maximum_water_surface_time' to datetime objects first\n","merged_df['max_wsel_time'] = pd.to_datetime(merged_df['maximum_water_surface_time'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Convert datetime to hours since the start for colormap\n","min_time = merged_df['max_wsel_time'].min()\n","color_values = (merged_df['max_wsel_time'] - min_time).dt.total_seconds() / 3600  # Convert to hours\n","\n","scatter = ax.scatter(merged_df['x'], merged_df['y'], \n","                     c=color_values, \n","                     cmap='viridis', \n","                     s=10)\n","\n","# Customize the plot\n","ax.set_title('Time of Maximum Water Surface Elevation per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","\n","# Set up the colorbar\n","cbar = plt.colorbar(scatter)\n","cbar.set_label('Hours since simulation start')\n","\n","# Format the colorbar ticks to show hours\n","cbar.set_ticks(range(0, int(color_values.max()) + 1, 6))  # Set ticks every 6 hours\n","cbar.set_ticklabels([f'{h}h' for h in range(0, int(color_values.max()) + 1, 6)])\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","\n","# Find the overall maximum WSEL and its time\n","max_wsel_row = merged_df.loc[merged_df['maximum_water_surface'].idxmax()]\n","hours_since_start = (max_wsel_row['max_wsel_time'] - min_time).total_seconds() / 3600\n","print(f\"\\nOverall Maximum WSEL: {max_wsel_row['maximum_water_surface']:.2f} ft\")\n","print(f\"Time of Overall Maximum WSEL: {max_wsel_row['max_wsel_time']}\")\n","print(f\"Hours since simulation start: {hours_since_start:.2f} hours\")\n","print(f\"Location of Overall Maximum WSEL: X={max_wsel_row['x']}, Y={max_wsel_row['y']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh min water surface\n","min_ws_df = HdfResultsMesh.mesh_min_ws(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Min Water Surface:\")\n","display(min_ws_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max face velocity\n","max_face_v_df = HdfResultsMesh.mesh_max_face_v(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Max Face Velocity:\")\n","display(max_face_v_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract midpoint coordinates from the LineString geometries\n","max_face_v_df['x'] = max_face_v_df['geometry'].apply(lambda geom: geom.centroid.x)\n","max_face_v_df['y'] = max_face_v_df['geometry'].apply(lambda geom: geom.centroid.y)\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(max_face_v_df['x'], max_face_v_df['y'], \n","                    c=max_face_v_df['maximum_face_velocity'].abs(),\n","                    cmap='viridis',\n","                    s=10)\n","\n","# Customize the plot\n","ax.set_title('Max Face Velocity per Face')\n","ax.set_xlabel('X Coordinate') \n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Face Velocity (ft/s)')\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the dataframe for verification\n","print(\"\\nFirst few rows of the face velocity dataframe:\")\n","display(max_face_v_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh min face velocity\n","min_face_v_df = HdfResultsMesh.mesh_min_face_v(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Min Face Velocity:\")\n","display(min_face_v_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max water surface error\n","try:\n","    max_ws_err_df = HdfResultsMesh.mesh_max_ws_err(plan_hdf_path, ras_object=bald_eagle)\n","    print(\"\\nMesh Max Water Surface Error:\")\n","    display(max_ws_err_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh max water surface error: {str(e)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max water surface error\n","import matplotlib.pyplot as plt\n","\n","# Extract x and y coordinates from the geometry points, handling None values\n","max_ws_err_df['x'] = max_ws_err_df['geometry'].apply(lambda geom: geom.x if geom is not None else None)\n","max_ws_err_df['y'] = max_ws_err_df['geometry'].apply(lambda geom: geom.y if geom is not None else None)\n","\n","# Remove any rows with None coordinates\n","max_ws_err_df = max_ws_err_df.dropna(subset=['x', 'y'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(max_ws_err_df['x'], max_ws_err_df['y'],\n","                    c=max_ws_err_df['cell_maximum_water_surface_error'],\n","                    cmap='viridis',\n","                    s=10)\n","\n","# Customize the plot\n","ax.set_title('Max Water Surface Error per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Water Surface Error (ft)')\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the dataframe for verification\n","print(\"\\nFirst few rows of the water surface error dataframe:\")\n","display(max_ws_err_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["### Need to add this to the ras-commander library"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant)\n","try:\n","    max_courant_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Courant\", ras_object=bald_eagle)\n","    print(\"\\nMesh Summary Output (Maximum Courant):\")\n","    print(max_courant_df.attrs)\n","    display(max_courant_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh summary output: {str(e)}\")\n","    # Additional error handling or logging can be added here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max Courant number\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import LineString\n","import geopandas as gpd\n","\n","# Get mesh max Courant number\n","max_courant_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Courant\", ras_object=bald_eagle)\n","\n","# Convert to GeoDataFrame\n","gdf = gpd.GeoDataFrame(max_courant_df)\n","\n","# Get centroids of line geometries for plotting\n","gdf['centroid'] = gdf.geometry.centroid\n","gdf['x'] = gdf.centroid.x\n","gdf['y'] = gdf.centroid.y\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(gdf['x'], gdf['y'],\n","                    c=gdf['maximum_face_courant'],\n","                    cmap='viridis',\n","                    s=10)\n","\n","# Customize the plot\n","ax.set_title('Max Courant Number per Face')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Courant Number')\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the dataframe for verification\n","print(\"\\nFirst few rows of the Courant number dataframe:\")\n","display(gdf.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant)\n","try:\n","    max_face_shear_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Shear Stress\", ras_object=bald_eagle)\n","    print(\"\\nMesh Summary Output (Maximum Face Shear Stress:\")\n","    print(max_face_shear_df.attrs)\n","    display(max_face_shear_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh summary output: {str(e)}\")\n","    # Additional error handling or logging can be added here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max face shear stress\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point, LineString\n","import geopandas as gpd\n","\n","# Get mesh max face shear stress\n","max_shear_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Shear Stress\", ras_object=bald_eagle)\n","\n","# Calculate centroids of the line geometries and extract coordinates\n","max_shear_df['centroid'] = max_shear_df['geometry'].apply(lambda line: line.centroid)\n","max_shear_df['x'] = max_shear_df['centroid'].apply(lambda point: point.x)\n","max_shear_df['y'] = max_shear_df['centroid'].apply(lambda point: point.y)\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","scatter = ax.scatter(max_shear_df['x'], max_shear_df['y'],\n","                    c=max_shear_df['maximum_face_shear_stress'],\n","                    cmap='viridis',\n","                    s=10)\n","\n","# Customize the plot\n","ax.set_title('Max Face Shear Stress per Face')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","plt.colorbar(scatter, label='Max Face Shear Stress (PSF)')\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","# Print the first few rows of the dataframe for verification\n","print(\"\\nFirst few rows of the shear stress dataframe:\")\n","display(max_shear_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for Minimum Water Surface\n","summary_df_min_ws = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Minimum Water Surface\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Minimum Water Surface):\")\n","display(summary_df_min_ws.head())\n","\n","# Example: Get mesh summary output for Minimum Face Velocity\n","summary_df_min_fv = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Minimum Face Velocity\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Minimum Face Velocity):\")\n","display(summary_df_min_fv.head())\n","\n","# Example: Get mesh summary output for Cell Cumulative Iteration\n","summary_df_cum_iter = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Cell Cumulative Iteration\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Cell Cumulative Iteration):\")\n","display(summary_df_cum_iter.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh timeseries output\n","\n","# Get mesh areas from previous code cell\n","mesh_areas = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","\n","if mesh_areas:\n","    mesh_name = mesh_areas[0]  # Use the first 2D flow area name\n","    timeseries_da = HdfResultsMesh.mesh_timeseries_output(plan_hdf_path, mesh_name, \"Water Surface\", ras_object=bald_eagle)\n","    print(f\"\\nMesh Timeseries Output (Water Surface) for {mesh_name}:\")\n","    print(timeseries_da)\n","else:\n","    print(\"No mesh areas found in the geometry file.\")"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["# Time Series Output Variables for Cells\n","# \n","# Variable Name: Description\n","# Water Surface: Water surface elevation\n","# Depth: Water depth\n","# Velocity: Magnitude of velocity\n","# Velocity X: X-component of velocity\n","# Velocity Y: Y-component of velocity\n","# Froude Number: Froude number\n","# Courant Number: Courant number\n","# Shear Stress: Shear stress on the bed\n","# Bed Elevation: Elevation of the bed\n","# Precipitation Rate: Rate of precipitation\n","# Infiltration Rate: Rate of infiltration\n","# Evaporation Rate: Rate of evaporation\n","# Percolation Rate: Rate of percolation\n","# Groundwater Elevation: Elevation of groundwater\n","# Groundwater Depth: Depth to groundwater\n","# Groundwater Flow: Groundwater flow rate\n","# Groundwater Velocity: Magnitude of groundwater velocity\n","# Groundwater Velocity X: X-component of groundwater velocity\n","# Groundwater Velocity Y: Y-component of groundwater velocity\n","# \n","# These variables are available for time series output at the cell level in 2D flow areas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh cells timeseries output\n","cells_timeseries_ds = HdfResultsMesh.mesh_cells_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Cells Timeseries Output:\")\n","print(cells_timeseries_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Cell Time Series Data (Random Cell ID)\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","\n","# Extract Water Surface data\n","water_surface = cells_timeseries_ds['BaldEagleCr']['Water Surface']\n","\n","# Get the time values\n","time_values = water_surface.coords['time'].values\n","\n","# Pick a random cell_id\n","random_cell_id = random.choice(water_surface.coords['cell_id'].values)\n","\n","# Extract the water surface elevation time series for the random cell\n","wsel_timeseries = water_surface.sel(cell_id=random_cell_id)\n","\n","# Find the peak value and its index\n","peak_value = wsel_timeseries.max().item()\n","peak_index = wsel_timeseries.argmax().item()\n","\n","# Create the plot\n","plt.figure(figsize=(12, 6))\n","plt.plot(time_values, wsel_timeseries, label=f'Cell ID: {random_cell_id}')\n","plt.scatter(time_values[peak_index], peak_value, color='red', s=100, zorder=5)\n","plt.annotate(f'Peak: {peak_value:.2f} ft', \n","             (time_values[peak_index], peak_value),\n","             xytext=(10, 10), textcoords='offset points',\n","             ha='left', va='bottom',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n","             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n","\n","plt.title(f'Water Surface Elevation Time Series for Random Cell (ID: {random_cell_id})')\n","plt.xlabel('Time')\n","plt.ylabel('Water Surface Elevation (ft)')\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","\n","# Log the plotting action\n","logging.info(f\"Plotted water surface elevation time series for random cell ID: {random_cell_id}\")\n","\n","# Display the plot\n","plt.show()\n","\n","# Print some statistics\n","print(f\"Statistics for Cell ID {random_cell_id}:\")\n","print(f\"Minimum WSEL: {wsel_timeseries.min().item():.2f} ft\")\n","print(f\"Maximum WSEL: {peak_value:.2f} ft\")\n","print(f\"Mean WSEL: {wsel_timeseries.mean().item():.2f} ft\")\n","print(f\"Time of peak: {time_values[peak_index]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh faces timeseries output\n","faces_timeseries_ds = HdfResultsMesh.mesh_faces_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Faces Timeseries Output:\")\n","print(faces_timeseries_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Random Face Results and Label Peak, Plus Map View\n","\n","# Step 1: Import necessary libraries \n","# In notebook cell at top of notebook\n","\n","# Step 2: Select a random valid face ID number\n","random_face = np.random.randint(0, faces_timeseries_ds.sizes['face_id'])\n","\n","# Step 3: Extract time series data for the selected face\n","variable = 'face_velocity'  # We could also use 'face_flow'\n","face_data = faces_timeseries_ds[variable].sel(face_id=random_face)\n","\n","# Step 4: Find peak value and its corresponding time\n","peak_value = face_data.max().item()\n","peak_time = face_data.idxmax().values\n","\n","# Plot time series\n","plt.figure(figsize=(12, 8))\n","plt.plot(faces_timeseries_ds.time, face_data)\n","plt.title(f'{variable.capitalize()} Time Series for Face {random_face}')\n","plt.xlabel('Time')\n","plt.ylabel(f'{variable.capitalize()} ({faces_timeseries_ds.attrs[\"units\"]})')\n","plt.grid(True)\n","\n","# Annotate the peak point\n","plt.annotate(f'Peak: ({peak_time}, {peak_value:.2f})', \n","            (peak_time, peak_value),\n","            xytext=(10, 10), textcoords='offset points',\n","            arrowprops=dict(arrowstyle=\"->\"))\n","\n","# Check for negative values and label the minimum if present\n","min_value = face_data.min().item()\n","if min_value < 0:\n","    min_time = face_data.idxmin().values\n","    plt.annotate(f'Min: ({min_time}, {min_value:.2f})', \n","                (min_time, min_value),\n","                xytext=(10, -10), textcoords='offset points',\n","                arrowprops=dict(arrowstyle=\"->\"))\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Create map view plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Get mesh faces for map view\n","mesh_faces = HdfMesh.mesh_cell_faces(plan_hdf_path, ras_object=bald_eagle)\n","\n","# Calculate mesh faces extents with 10% buffer\n","faces_bounds = mesh_faces.total_bounds\n","x_min, y_min, x_max, y_max = faces_bounds\n","buffer_x = (x_max - x_min) * 0.1\n","buffer_y = (y_max - y_min) * 0.1\n","plot_xlim = [x_min - buffer_x, x_max + buffer_x]\n","plot_ylim = [y_min - buffer_y, y_max + buffer_y]\n","\n","# Set plot limits before adding terrain\n","ax.set_xlim(plot_xlim)\n","ax.set_ylim(plot_ylim)\n","\n","# Add the terrain TIFF to the map, clipped to our desired extent\n","tiff_path = Path.cwd() / 'example_projects' / 'BaldEagleCrkMulti2D' / 'Terrain' / 'Terrain50.baldeagledem.tif'\n","with rasterio.open(tiff_path) as src:\n","    show(src, ax=ax, cmap='terrain', alpha=0.5)\n","    \n","# Reset the limits after terrain plot\n","ax.set_xlim(plot_xlim)\n","ax.set_ylim(plot_ylim)\n","\n","# Plot all faces in gray\n","mesh_faces.plot(ax=ax, color='lightgray', alpha=0.5, zorder=2)\n","\n","# Get the selected face geometry\n","selected_face = mesh_faces[mesh_faces['face_id'] == random_face]\n","\n","# Highlight the selected face in red\n","selected_face.plot(\n","    ax=ax, \n","    color='red',\n","    linewidth=2,\n","    label=f'Selected Face (ID: {random_face})',\n","    zorder=3\n",")\n","\n","# Get bounds of selected face for zoomed inset\n","bounds = selected_face.geometry.bounds.iloc[0]\n","x_center = (bounds.iloc[0] + bounds.iloc[2]) / 2\n","y_center = (bounds.iloc[1] + bounds.iloc[3]) / 2\n","buffer = max(bounds.iloc[2] - bounds.iloc[0], bounds.iloc[3] - bounds.iloc[1]) * 2\n","\n","# Create zoomed inset with a larger size, inside the map frame\n","axins = inset_axes(ax, width=\"70%\", height=\"70%\", loc='lower right',\n","                  bbox_to_anchor=(0.65, 0.05, 0.35, 0.35),\n","                  bbox_transform=ax.transAxes)\n","\n","# Plot terrain and faces in inset\n","with rasterio.open(tiff_path) as src:\n","    show(src, ax=axins, cmap='terrain', alpha=0.5)\n","    \n","# Plot zoomed view in inset\n","mesh_faces.plot(ax=axins, color='lightgray', alpha=0.5, zorder=2)\n","selected_face.plot(ax=axins, color='red', linewidth=2, zorder=3)\n","\n","# Set inset limits with slightly more context\n","axins.set_xlim(x_center - buffer/1.5, x_center + buffer/1.5)\n","axins.set_ylim(y_center - buffer/1.5, y_center + buffer/1.5)\n","\n","# Remove inset ticks for cleaner look\n","axins.set_xticks([])\n","axins.set_yticks([])\n","\n","# Add a border to the inset\n","for spine in axins.spines.values():\n","    spine.set_edgecolor('black')\n","    spine.set_linewidth(1.5)\n","\n","# Create connection lines between main plot and inset\n","# Get the selected face centroid for connection point\n","centroid = selected_face.geometry.centroid.iloc[0]\n","con1 = ConnectionPatch(\n","    xyA=(centroid.x, centroid.y), coordsA=ax.transData,\n","    xyB=(0.02, 0.98), coordsB=axins.transAxes,\n","    arrowstyle=\"-\", linestyle=\"--\", color=\"gray\", alpha=0.6\n",")\n","con2 = ConnectionPatch(\n","    xyA=(centroid.x, centroid.y), coordsA=ax.transData,\n","    xyB=(0.98, 0.02), coordsB=axins.transAxes,\n","    arrowstyle=\"-\", linestyle=\"--\", color=\"gray\", alpha=0.6\n",")\n","\n","ax.add_artist(con1)\n","ax.add_artist(con2)\n","\n","# Add title and legend to main plot\n","ax.set_title('Mesh Face Map View with Terrain')\n","ax.legend()\n","\n","# Ensure equal aspect ratio while maintaining our desired extents\n","ax.set_aspect('equal', adjustable='box')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Print summary information\n","print(f\"Random Face: {random_face}\")\n","print(f\"Peak Value: {peak_value:.2f} {faces_timeseries_ds.attrs['units']} at {peak_time}\")\n","if min_value < 0:\n","    print(f\"Minimum Value: {min_value:.2f} {faces_timeseries_ds.attrs['units']} at {min_time}\")\n","\n","# Log the plotting action\n","logging.info(f\"Plotted mesh face time series and map view for random face ID: {random_face} with terrain\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference lines\n","ref_lines_gdf = HdfBndry.reference_lines(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines:\")\n","display(ref_lines_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference points\n","ref_points_gdf = HdfBndry.reference_points(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points:\")\n","display(ref_points_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference timeseries output\n","ref_timeseries_ds = HdfResultsPlan.reference_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Timeseries Output:\")\n","print(ref_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference lines timeseries output\n","ref_lines_timeseries_ds = HdfResultsPlan.reference_lines_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines Timeseries Output:\")\n","print(ref_lines_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference points timeseries output\n","ref_points_timeseries_ds = HdfResultsPlan.reference_points_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points Timeseries Output:\")\n","print(ref_points_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference summary output\n","ref_summary_df = HdfResultsPlan.reference_summary_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Summary Output:\")\n","display(ref_summary_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get meteorology precipitation attributes\n","meteo_precip_attrs = HdfPlan.get_meteorology_precip_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMeteorology Precipitation Attributes:\")\n","for key, value in meteo_precip_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady attributes\n","results_unsteady_attrs = HdfResultsPlan.get_results_unsteady_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Attributes:\")\n","for key, value in results_unsteady_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady summary attributes\n","results_unsteady_summary_attrs = HdfResultsPlan.get_results_unsteady_summary_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Summary Attributes:\")\n","for key, value in results_unsteady_summary_attrs.items():\n","    print(f\"{key}: {value}\")\n","\n","# Get results volume accounting attributes\n","volume_accounting_attrs = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nVolume Accounting Attributes:\")\n","for key, value in volume_accounting_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# HdfUtils Examples\n","\n","# Example: Get attributes for a specific path\n","attrs = HdfUtils.get_attrs(plan_hdf_path, attr_path=\"/Results/Unsteady\")\n","print(\"\\nAttributes for /Results/Unsteady:\")\n","for key, value in attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get root attributes\n","root_attrs = HdfUtils.get_root_attrs(plan_hdf_path)\n","print(\"\\nRoot Attributes:\")\n","for key, value in root_attrs.items():\n","    print(f\"{key}: {value}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\21_2d_hdf_data_extraction pipes and pumps.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS Pipes, Conduits, and Pump Stations HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze the new HEC-RAS Conduits, Pipes, and Pump Stations results using the ras-commander library. It leverages the HdfPipe and HdfPump classes to streamline data extraction, processing, and visualization."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import pyproj\n","from shapely.geometry import Point, LineString, Polygon\n","import xarray as xr\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Install ras-commander if you are not in a dev environment. \n","# install_module(ras-commander)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    print(\"Using Local Dev Copy\")\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import (init_ras_project, HdfBase, HdfUtils, HdfFluvialPluvial, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, HdfPipe, HdfPump, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","\n","print(\"ras_commander imported successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the Pipes Beta project from HEC and run plan 01\n","\n","# Define the path to the Pipes Beta project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","pipes_ex_path = current_dir / \"example_projects\" / \"Davis\"\n","import logging\n","\n","# Check if Pipes Beta.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = pipes_ex_path / \"DavisStormSystem.p02.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the Pipes Beta project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"Davis\"])\n","\n","    # Initialize custom Ras object\n","    pipes_ex = RasPrj()\n","\n","    # Initialize the RAS project using the custom ras object\n","    pipes_ex = init_ras_project(pipes_ex_path, \"6.6\", ras_instance=pipes_ex)\n","    logging.info(f\"Pipes Beta project initialized with folder: {pipes_ex.project_folder}\")\n","    \n","    logging.info(f\"Pipes Beta object id: {id(pipes_ex)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"02\"\n","\n","    # Update run flags for the project\n","    RasPlan.update_run_flags(\n","        plan_number,\n","        geometry_preprocessor=True,\n","        unsteady_flow_simulation=True,\n","        run_sediment=False,\n","        post_processor=True,\n","        floodplain_mapping=False,\n","        ras_object=pipes_ex\n","    )\n","\n","    # Execute Plan 06 using RasCmdr for Pipes Beta\n","    print(f\"Executing Plan {plan_number} for the Pipes Beta Creek project...\")\n","    success_pipes_ex = RasCmdr.compute_plan(plan_number, ras_object=pipes_ex)\n","    if success_pipes_ex:\n","        print(f\"Plan {plan_number} executed successfully for Pipes Beta.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Pipes Beta.\\n\")\n","else:\n","    print(\"Pipes Beta.p06.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    pipes_ex = RasPrj()\n","    pipes_ex = init_ras_project(pipes_ex_path, \"6.6\", ras_instance=pipes_ex)\n","    plan_number = \"02\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n","\n","# Display plan_df for pipes_ex project\n","print(\"Plan DataFrame for pipes_ex project:\")\n","display(pipes_ex.plan_df)\n","\n","# Display geom_df for pipes_ex project\n","print(\"\\nGeometry DataFrame for pipes_ex project:\")\n","display(pipes_ex.geom_df)\n","\n","# Get the plan HDF path\n","plan_hdf_path = pipes_ex.plan_df.loc[pipes_ex.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n","\n","# Get the geometry file number from the plan DataFrame\n","geom_file = pipes_ex.plan_df.loc[pipes_ex.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n","geom_number = geom_file[1:]  # Remove the 'g' prefix\n","\n","# Get the geometry HDF path\n","geom_hdf_path = pipes_ex.geom_df.loc[pipes_ex.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n","\n","print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n","print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = HdfResultsPlan.get_runtime_data(hdf_input=plan_number, ras_object=pipes_ex)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/Pipe Conduits/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get pipe conduits\n","pipe_conduits_gdf = HdfPipe.get_pipe_conduits(plan_hdf_path)\n","print(\"\\nPipe Conduits: pipe_conduits_gdf\")\n","display(pipe_conduits_gdf.head())"]},{"cell_type":"markdown","metadata":{},"source":["pipe_conduits_gdf:  \n","\n","| Name | System Name | US Node | DS Node | Modeling Approach | Conduit Length | Max Cell Length | Shape | Rise | Span | ... | Slope | US Entrance Loss Coefficient | DS Exit Loss Coefficient | US Backflow Loss Coefficient | DS Backflow Loss Coefficient | DS Flap Gate | Major Group | Minor Group | Polyline | Terrain_Profiles |\n","|------|-------------|---------|---------|-------------------|----------------|------------------|-------|------|------|-----|-------|------------------------------|--------------------------|------------------------------|------------------------------|--------------|-------------|-------------|----------|-------------------|\n","| 0    | 134         | Davis   | O13-DMH007 | O13-DMH006 | hydraulic        | 443.740020      | 40.0             | circular | 6.0  | 6.0  | ... | 0.002723 | 0.2                        | 0.4                      | 0.2                          | 0.4                          | 0            | Major Group 2 |             | LINESTRING (6635295.441 1965214.2465, 6635196.... | [(0.0, 40.819695), (21.217846, 40.642994), (35... |\n","| 1    | 133         | Davis   | O13-DMH024 | O13-DMH009 | hydraulic        | 800.000024      | 40.0             | circular | 6.0  | 6.0  | ... | 0.001904 | 0.2                        | 0.4                      | 0.2                          | 0.4                          | 0            | Major Group 2 |             | LINESTRING (6635295.441 1965214.2465, 6635196.... | [(0.0, 40.530186), (21.1467, 40.44057), (50.88... |\n","| 2    | 132         | Davis   | O13-DMH006 | O13-SDS03 | hydraulic        | 443.740070      | 40.0             | circular | 6.0  | 6.0  | ... | 0.002816 | 0.2                        | 0.4                      | 0.2                          | 0.4                          | 0            | Major Group 2 |             | LINESTRING (6635295.441 1965214.2465, 6635196.... | [(0.0, 41.700996), (26.817467, 41.552666), (83... |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!pip install adjusttext #No longer required - optional to help with labels overlapping"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the pipe conduit linestrings\n","import matplotlib.pyplot as plt\n","\n","# Create a new figure with a specified size\n","plt.figure(figsize=(12, 9))\n","\n","# Plot each linestring from the GeoDataFrame\n","for idx, row in pipe_conduits_gdf.iterrows():\n","    # Extract coordinates from the linestring\n","    x_coords, y_coords = row['Polyline'].xy\n","    \n","    # Plot the linestring\n","    plt.plot(x_coords, y_coords, 'b-', linewidth=1, alpha=0.7)\n","    \n","    # Add vertical line markers at endpoints\n","    plt.plot([x_coords[0]], [y_coords[0]], 'x', color='black', markersize=4)\n","    plt.plot([x_coords[-1]], [y_coords[-1]], 'x', color='black', markersize=4)\n","    \n","    # Calculate center point of the line\n","    center_x = (x_coords[0] + x_coords[-1]) / 2\n","    center_y = (y_coords[0] + y_coords[-1]) / 2\n","    \n","    # Add pipe name label at center, oriented top-right\n","    plt.text(center_x, center_y, f'{row[\"Name\"]}', fontsize=8, \n","             verticalalignment='bottom', horizontalalignment='left',\n","             rotation=45)  # 45 degree angle for top-right orientation\n","\n","# Add title and labels\n","plt.title('Pipe Conduit Network Layout')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","\n","# Add grid\n","plt.grid(True, linestyle='--', alpha=0.6)\n","\n","# Adjust layout to prevent label clipping\n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the first 2 terrain profiles\n","import matplotlib.pyplot as plt\n","\n","# Extract terrain profiles from the GeoDataFrame\n","terrain_profiles = pipe_conduits_gdf['Terrain_Profiles'].tolist()\n","\n","# Create separate plots for the first 2 terrain profiles\n","for i in range(2):\n","    profile = terrain_profiles[i]\n","    \n","    # Unzip the profile into x and y coordinates\n","    x_coords, y_coords = zip(*profile)\n","    \n","    # Create a new figure for each profile\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(x_coords, y_coords, marker='o', linestyle='-', color='g', alpha=0.7)\n","    \n","    # Add title and labels\n","    plt.title(f'Terrain Profile {i + 1}')\n","    plt.xlabel('Distance along profile (m)')\n","    plt.ylabel('Elevation (m)')\n","    \n","    # Add grid\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","    \n","    # Adjust layout to prevent label clipping\n","    plt.tight_layout()\n","    \n","    # Display the plot\n","    plt.show()\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","#HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/Pipe Nodes/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get pipe nodes\n","pipe_nodes_gdf = HdfPipe.get_pipe_nodes(plan_hdf_path)\n","print(\"\\nPipe Nodes:\")\n","display(pipe_nodes_gdf.head())"]},{"cell_type":"markdown","metadata":{},"source":["pipe_nodes_gdf:\n","\n","\n","| Name         | System Name | Node Type | Node Status                     | Condtui Connections (US:DS) | Invert Elevation | Base Area | Terrain Elevation | Terrain Elevation Override | Depth     | Drop Inlet Elevation | Drop Inlet Weir Length | Drop Inlet Weir Coefficient | Drop Inlet Orifice Area | Drop Inlet Orifice Coefficient | Total Connection Count | geometry                             |\n","|--------------|-------------|-----------|----------------------------------|------------------------------|------------------|-----------|-------------------|---------------------------|-----------|----------------------|-------------------------|-----------------------------|-------------------------|-------------------------------|------------------------|-------------------------------------|\n","| O14-di027   | Davis       | Junction   | Junction with drop inlet        | 1:1                          | 36.060001        | 36.0     | 39.860001         | NaN                       | 3.799999  | 39.863369           | 3.0                     | 3.3                         | 1.0                     | 0.67                          | 2                      | POINT (6637926.81 1964917.32)     |\n","| P11-DMH004  | Davis       | Junction   | Junction with drop inlet        | 1:1                          | 38.169998        | 36.0     | 48.720001         | NaN                       | 10.550003 | 48.718811           | 3.0                     | 3.3                         | 1.0                     | 0.67                          | 2                      | POINT (6629444.634 1963504.411)   |\n","| O14-DMH005  | Davis       | Junction   | Junction with drop inlet        | 1:1                          | 31.559999        | 36.0     | 40.840000         | NaN                       | 9.280001  | 40.843731           | 3.0                     | 3.3                         | 1.0                     | 0.67                          | 2                      | POINT (6637368.497 1966084.574)   |"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","#HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/Pipe Networks/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get pipe network data\n","pipe_network_gdf = HdfPipe.get_pipe_network(plan_hdf_path)\n","print(\"\\nPipe Network Data:\")\n","display(pipe_network_gdf.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["pipe_network_gdf:\n","| Cell_ID | Conduit_ID | Node_ID | Minimum_Elevation | DS_Face_Indices | Face_Indices | US_Face_Indices | Cell_Property_Info_Index | US Face Elevation | DS Face Elevation | Min Elevation | Area | Info Index | Cell_Polygon | Face_Polylines | Node_Point |\n","|---------|------------|---------|-------------------|------------------|--------------|------------------|--------------------------|-------------------|-------------------|---------------|------|------------|---------------|----------------|------------|\n","| 0       | 0          | 0       | -1                | 26.824432        | [1]          | [0, 1]           | [0]                      | 0                 | 26.93429          | 26.824432     | 242.040024 | 0          | POLYGON ((6635288.02154 1965233.24073, 6635279... | [LINESTRING (6635288.021542038 1965233.2407260... | None       |\n","| 1       | 1          | 0       | -1                | 26.714573        | [2]          | [1, 2]           | [1]                      | 0                 | 26.93429          | 26.824432     | 242.040024 | 0          | POLYGON ((6635288.02154 1965233.24073, 6635279... | [LINESTRING (6635288.021542038 1965233.2407260... | None       |\n","| 2       | 2          | 0       | -1                | 26.604715        | [3]          | [2, 3]           | [2]                      | 0                 | 26.93429          | 26.824432     | 242.040024 | 0          | POLYGON ((6635288.02154 1965233.24073, 6635279... | [LINESTRING (6635288.021542038 1965233.2407260... | None       |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get pump stations\n","pump_stations_gdf = HdfPump.get_pump_stations(plan_hdf_path)\n","print(\"\\nPump Stations:\")\n","display(pump_stations_gdf.head())"]},{"cell_type":"markdown","metadata":{},"source":["Pump Stations:\n","| geometry                          | station_id | Name             | Inlet River | Inlet Reach | Inlet RS | Inlet RS Distance | Inlet SA/2D | Inlet Pipe Node | Outlet River | ... | Outlet Pipe Node | Reference River | Reference Reach | Reference RS | Reference RS Distance | Reference SA/2D | Reference Point | Reference Pipe Node | Highest Pump Line Elevation | Pump Groups |\n","|-----------------------------------|------------|------------------|-------------|-------------|----------|-------------------|--------------|------------------|--------------|-----|------------------|------------------|-----------------|--------------|-----------------------|------------------|-----------------|----------------------|------------------------------|-------------|\n","| POINT (6635027.027 1966080.07)   | 0          | Pump Station #1   |             |             | NaN      |                   |              | Davis [O13-SDS03] |              | ... |                  | NaN              |                 | NaN          |                       | NaN              |                 |                      | NaN                          | 1           |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get pump groups\n","pump_groups_df = HdfPump.get_pump_groups(plan_hdf_path)\n","print(\"\\nPump Groups:\")\n","display(pump_groups_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["Pump Groups:\n","| Pump Station ID | Name             | Bias On | Start Up Time | Shut Down Time | Width | Pumps | efficiency_curve_start | efficiency_curve_count | efficiency_curve |\n","|------------------|------------------|---------|----------------|----------------|-------|-------|------------------------|-----------------------|------------------|\n","| 0                | Pump Station #1   | 0       | 5.0            | NaN            | 5.0   | 1     | 0                      | 6                     | [[2.0, 70.0], [4.0, 60.0], [6.0, 55.0], [8.0, ... |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfUtils for extracting projection\n","print(\"\\nExtracting Projection from HDF\")\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Projection: {projection}\")\n","else:\n","    print(\"No projection information found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get projection from HDF file\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","\n","# Set CRS for GeoDataFrames\n","if projection:\n","    pipe_conduits_gdf.set_crs(projection, inplace=True, allow_override=True)\n","    pipe_nodes_gdf.set_crs(projection, inplace=True, allow_override=True)\n","\n","print(\"Pipe Conduits GeoDataFrame columns:\")\n","print(pipe_conduits_gdf.columns)\n","\n","print(\"\\nPipe Nodes GeoDataFrame columns:\")\n","print(pipe_nodes_gdf.columns)\n","\n","perimeter_polygons = HdfMesh.mesh_areas(geom_hdf_path, ras_object=pipes_ex)\n","if projection:\n","    perimeter_polygons.set_crs(projection, inplace=True, allow_override=True)\n","    \n","print(\"\\nPerimeter Polygons GeoDataFrame columns:\")\n","print(perimeter_polygons.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from shapely import wkt\n","import matplotlib.patches as mpatches\n","import matplotlib.lines as mlines\n","import numpy as np\n","\n","fig, ax = plt.subplots(figsize=(28, 20))\n","\n","# Plot cell polygons with 50% transparency behind the pipe network\n","cell_polygons_df = HdfMesh.mesh_cell_polygons(geom_hdf_path, ras_object=pipes_ex)\n","if not cell_polygons_df.empty:\n","    cell_polygons_df.plot(ax=ax, edgecolor='lightgray', facecolor='lightgray', alpha=0.5)\n","\n","# Plot pipe conduits - the Polyline column already contains LineString geometries\n","pipe_conduits_gdf.set_geometry('Polyline', inplace=True)\n","\n","# Plot each pipe conduit individually to ensure all are shown\n","for idx, row in pipe_conduits_gdf.iterrows():\n","    ax.plot(*row.Polyline.xy, color='blue', linewidth=1)\n","\n","# Create a colormap for node elevations\n","norm = plt.Normalize(pipe_nodes_gdf['Invert Elevation'].min(), \n","                    pipe_nodes_gdf['Invert Elevation'].max())\n","cmap = plt.cm.viridis\n","\n","# Plot pipe nodes colored by invert elevation\n","scatter = ax.scatter(pipe_nodes_gdf.geometry.x, pipe_nodes_gdf.geometry.y,\n","                    c=pipe_nodes_gdf['Invert Elevation'], \n","                    cmap=cmap, norm=norm,\n","                    s=100)\n","\n","# Add colorbar\n","cbar = plt.colorbar(scatter)\n","cbar.set_label('Invert Elevation (ft)', rotation=270, labelpad=15)\n","\n","# Add combined labels for invert and drop inlet elevations\n","for idx, row in pipe_nodes_gdf.iterrows():\n","    label_text = \"\"  # Initialize label_text for each node\n","    # Add drop inlet elevation label if it exists and is not NaN\n","    if 'Drop Inlet Elevation' in row and not np.isnan(row['Drop Inlet Elevation']):\n","        label_text += f\"TOC: {row['Drop Inlet Elevation']:.2f}\\n\"\n","    label_text += f\"INV: {row['Invert Elevation']:.2f}\"\n","    \n","    ax.annotate(label_text,\n","                xy=(row.geometry.x, row.geometry.y),\n","                xytext=(-10, -10), textcoords='offset points',\n","                fontsize=8,\n","                bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n","\n","# Add perimeter polygons \n","if not perimeter_polygons.empty:\n","    perimeter_polygons.plot(ax=ax, edgecolor='black', facecolor='none')\n","\n","# Create proxy artists for legend\n","conduit_line = mlines.Line2D([], [], color='blue', label='Conduits')\n","node_point = mlines.Line2D([], [], color='blue', marker='o', linestyle='None',\n","                          markersize=10, label='Nodes')\n","perimeter = mpatches.Patch(facecolor='none', edgecolor='black',\n","                          label='Perimeter Polygons')\n","\n","ax.set_title('Pipe Network with Node Elevations')\n","\n","# Add legend with proxy artists\n","ax.legend(handles=[conduit_line, node_point, perimeter])\n","\n","# Set aspect ratio to be equal and adjust limits\n","ax.set_aspect('equal', 'datalim')\n","ax.autoscale_view()\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize pump stations on a map\n","fig, ax = plt.subplots(figsize=(12, 8))\n","pump_stations_gdf.plot(ax=ax, color='green', markersize=50, label='Pump Stations')\n","ax.set_title('Pump Stations Location')\n","ax.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 3: Get pipe network timeseries\n","valid_variables = [\n","    \"Cell Courant\", \"Cell Water Surface\", \"Face Flow\", \"Face Velocity\",\n","    \"Face Water Surface\", \"Pipes/Pipe Flow DS\", \"Pipes/Pipe Flow US\",\n","    \"Pipes/Vel DS\", \"Pipes/Vel US\", \"Nodes/Depth\", \"Nodes/Drop Inlet Flow\",\n","    \"Nodes/Water Surface\"\n","]\n","\n","print(\"Valid variables for pipe network timeseries:\")\n","for var in valid_variables:\n","    print(f\"- {var}\")\n","\n","# Extract pipe network timeseries for each valid pipe-related variable\n","pipe_variables = [var for var in valid_variables if var.startswith(\"Pipes/\") or var.startswith(\"Nodes/\")]\n","\n","for variable in pipe_variables:\n","    try:\n","        pipe_timeseries = HdfPipe.get_pipe_network_timeseries(plan_hdf_path, variable=variable)\n","        print(f\"\\nPipe Network Timeseries ({variable}):\")\n","        print(pipe_timeseries.head())  # Print first few rows to avoid overwhelming output\n","    except Exception as e:\n","        print(f\"Error extracting {variable}: {str(e)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Pipe Network Timeseries Data Description\n","\n","The `get_pipe_network_timeseries` function returns an xarray DataArray for each variable. Here's a general description of the data structure:\n","\n","1. **Pipes/Pipe Flow DS and Pipes/Pipe Flow US**:\n","   - Dimensions: time, location (pipe IDs)\n","   - Units: ft^3/s (cubic feet per second)\n","   - Description: Represents the flow rate at the downstream (DS) and upstream (US) ends of pipes over time.\n","\n","2. **Pipes/Vel DS and Pipes/Vel US**:\n","   - Dimensions: time, location (pipe IDs)\n","   - Units: ft/s (feet per second)\n","   - Description: Shows the velocity at the downstream (DS) and upstream (US) ends of pipes over time.\n","\n","3. **Nodes/Depth**:\n","   - Dimensions: time, location (node IDs)\n","   - Units: ft (feet)\n","   - Description: Indicates the depth of water at each node over time.\n","\n","4. **Nodes/Drop Inlet Flow**:\n","   - Dimensions: time, location (node IDs)\n","   - Units: cfs (cubic feet per second)\n","   - Description: Represents the flow rate through drop inlets at each node over time.\n","\n","5. **Nodes/Water Surface**:\n","   - Dimensions: time, location (node IDs)\n","   - Units: ft (feet)\n","   - Description: Shows the water surface elevation at each node over time.\n","\n","General notes:\n","- The 'time' dimension represents the simulation timesteps.\n","- The 'location' dimension represents either pipe IDs or node IDs, depending on the variable.\n","- The number of timesteps and locations may vary depending on the specific dataset and simulation setup.\n","- Negative values in flow variables may indicate reverse flow direction.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.dates import DateFormatter\n","import numpy as np\n","import random\n","\n","# Define the variables we want to plot\n","variables = [\n","    \"Pipes/Pipe Flow DS\", \"Pipes/Pipe Flow US\", \"Pipes/Vel DS\", \"Pipes/Vel US\",\n","    \"Nodes/Depth\", \"Nodes/Drop Inlet Flow\", \"Nodes/Water Surface\"\n","]\n","\n","# Create a separate plot for each variable\n","for variable in variables:\n","    try:\n","        # Get the data for the current variable\n","        data = HdfPipe.get_pipe_network_timeseries(plan_hdf_path, variable=variable)\n","        \n","        # Create a new figure\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","        \n","        # Pick one random location\n","        random_location = random.choice(data.location.values)\n","        \n","        # Determine if it's a pipe or node variable\n","        if variable.startswith(\"Pipes/\"):\n","            location_type = \"Conduit ID\"\n","        else:\n","            location_type = \"Node ID\"\n","        \n","        # Plot the data for the randomly selected location\n","        ax.plot(data.time, data.sel(location=random_location), label=f'{location_type} {random_location}')\n","        \n","        # Set the title and labels\n","        ax.set_title(f'{variable} Over Time ({location_type} {random_location})')\n","        ax.set_xlabel('Time')  # Corrected from ax.xlabel to ax.set_xlabel\n","        ax.set_ylabel(f'{variable} ({data.attrs[\"units\"]})')  # Corrected from ax.ylabel to ax.set_ylabel\n","        \n","        # Format the x-axis to show dates nicely\n","        ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M'))\n","        plt.xticks(rotation=45)\n","        \n","        # Add a legend\n","        ax.legend(title=location_type, loc='upper left')\n","        \n","        # Adjust the layout\n","        plt.tight_layout()\n","        \n","        # Show the plot\n","        plt.show()\n","        \n","    except Exception as e:\n","        print(f\"Error plotting {variable}: {str(e)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 8: Get pump station timeseries\n","pump_station_name = pump_stations_gdf.iloc[0]['Name']  # Get the first pump station name\n","pump_timeseries = HdfPump.get_pump_station_timeseries(plan_hdf_path, pump_station=pump_station_name)\n","print(f\"\\nPump Station Timeseries ({pump_station_name}):\")\n","print(pump_timeseries)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use explore_hdf5 function to get Pipe Conduits data:\n","HdfUtils.explore_hdf5(plan_hdf_path, \"/Geometry/Pump Stations/\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract the pump station timeseries data\n","pump_station_name = pump_stations_gdf.iloc[0]['Name']  # Get the first pump station name\n","pump_timeseries = HdfPump.get_pump_station_timeseries(plan_hdf_path, pump_station=pump_station_name)\n","\n","# Print the pump station timeseries\n","print(f\"\\nPump Station Timeseries ({pump_station_name}):\")\n","print(pump_timeseries)\n","\n","# Create a new figure for plotting\n","fig, ax = plt.subplots(figsize=(12, 12))\n","\n","# Plot each variable in the timeseries\n","for variable in pump_timeseries.coords['variable'].values:\n","    data = pump_timeseries.sel(variable=variable)\n","    \n","    # Decode units to strings\n","    unit = pump_timeseries.attrs[\"units\"][list(pump_timeseries.coords[\"variable\"].values).index(variable)][1].decode('utf-8')\n","    \n","    # Check if the variable is 'Pumps on' to plot it differently\n","    if variable == 'Pumps on':\n","        # Plot with color based on the on/off status\n","        colors = ['green' if val > 0 else 'red' for val in data.values.flatten()]\n","        ax.scatter(pump_timeseries['time'], data, label=f'{variable} ({unit})', color=colors)\n","    else:\n","        ax.plot(pump_timeseries['time'], data, label=f'{variable} ({unit})')\n","        \n","        # Label the peak values\n","        peak_time = pump_timeseries['time'][data.argmax()]\n","        peak_value = data.max()\n","        ax.annotate(f'Peak: {peak_value:.2f}', xy=(peak_time, peak_value), \n","                    xytext=(peak_time, peak_value + 0.1 * peak_value), \n","                    arrowprops=dict(facecolor='black', arrowstyle='->'),\n","                    fontsize=10, color='black', ha='center')\n","\n","# Set the title and labels\n","ax.set_title(f'Timeseries Data for Pump Station: {pump_station_name}')\n","ax.set_xlabel('Time')\n","ax.set_ylabel('Values')\n","\n","# Format the x-axis to show dates nicely\n","ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d %H:%M'))\n","plt.xticks(rotation=45)\n","\n","# Add a legend\n","ax.legend(title='Variables', loc='upper left')\n","\n","# Adjust the layout\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\22_2d_detail_face_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 2D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray', 'rasterio']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import pyproj\n","from shapely.geometry import Point, LineString, Polygon\n","import xarray as xr\n","from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n","import matplotlib.patches as patches\n","from matplotlib.patches import ConnectionPatch\n","import logging\n","from pathlib import Path\n","import rasterio\n","from rasterio.plot import show\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Install ras-commander if you are not in a dev environment. \n","#install_module('ras-commander')"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import (\n","        init_ras_project, HdfMesh, HdfBndry, HdfResultsMesh, RasExamples, RasPrj, RasPlan, RasCmdr, HdfUtils, HdfResultsPlan, HdfPlan, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import (\n","        init_ras_project, HdfMesh, HdfBndry, HdfResultsMesh, RasExamples, RasPrj, RasPlan, RasCmdr, HdfUtils, HdfResultsPlan, HdfPlan, ras)\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","\n","print(\"ras_commander imported successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the Chippewa_2D project from HEC and run plan 01\n","\n","# Define the path to the Chippewa_2D project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","bald_eagle_path = current_dir / \"example_projects\" / \"Chippewa_2D\"\n","import logging\n","\n","# Check if Chippewa_2D.p02.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = bald_eagle_path / \"Chippewa_2D.p02.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the Chippewa_2D project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"Chippewa_2D\"])\n","\n","    # Initialize custom Ras object\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"02\"\n","\n","    # Update run flags for the project\n","    RasPlan.update_run_flags(\n","        plan_number,\n","        geometry_preprocessor=True,\n","        unsteady_flow_simulation=True,\n","        run_sediment=False,\n","        post_processor=True,\n","        floodplain_mapping=False,\n","        ras_object=bald_eagle\n","    )\n","\n","    # Execute Plan 02 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"Chippewa_2D.p02.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = RasPrj()\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    plan_number = \"02\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n","\n","# Display plan_df for bald_eagle project\n","print(\"Plan DataFrame for bald_eagle project:\")\n","display(bald_eagle.plan_df)\n","\n","# Display geom_df for bald_eagle project\n","print(\"\\nGeometry DataFrame for bald_eagle project:\")\n","display(bald_eagle.geom_df)\n","\n","# Get the plan HDF path\n","plan_number = \"02\"  # Assuming we're using plan 01 as in the previous code\n","plan_hdf_path = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n","\n","# Get the geometry file number from the plan DataFrame\n","geom_file = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n","geom_number = geom_file[1:]  # Remove the 'g' prefix\n","\n","# Get the geometry HDF path\n","geom_hdf_path = bald_eagle.geom_df.loc[bald_eagle.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n","\n","print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n","print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"]},{"cell_type":"markdown","metadata":{},"source":["plan dataframe: \n","\n","| plan_number | full_path | Computation Interval | DSS File | Flow File | Friction Slope Method | Geom File | Mapping Interval | Plan Title       | Program Version | ... | Run WQNet | Short Identifier | Simulation Date                     | UNET D1 Cores | UNET Use Existing IB Tables | UNET 1D Methodology | UNET D2 SolverType | UNET D2 Name | HDF_Results_Path | Geom_File |\n","|-------------|-----------|----------------------|----------|-----------|-----------------------|-----------|------------------|------------------|-----------------|-----|-----------|------------------|-------------------------------------|----------------|-----------------------------|---------------------|--------------------|---------------|-------------------|-----------|\n","| 0           | 02        | c:\\GH\\ras-commander\\examples\\example_projects\\... | 2MIN     | dss       | u04                   | 1         | g01              | 30MIN            | 100ft Sediment  | 6.40 | ...       | 0                | 100ft Sediment  | 02apr2019,0000,05may2019,2400 | 0              | -1                          | Finite Difference   | PARDISO (Direct)  | Perimeter 1  | c:\\GH\\ras-commander\\examples\\example_projects\\... | c:\\GH\\ras-commander\\examples\\example_projects\\... |"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Define the HDF input path as Plan Number\n","\n","plan_number = \"02\"  # Assuming we're using plan 01 as in the previous code\n"]},{"cell_type":"markdown","metadata":{},"source":["RasHdfUtils\n","| Method Name | Description |\n","|-------------|-------------|\n","| get_attrs | Converts attributes from a HEC-RAS HDF file into a Python dictionary for a given attribute path |\n","| get_root_attrs | Returns attributes at root level of HEC-RAS HDF file |\n","| get_hdf_paths_with_properties | Gets all paths in the HDF file with their properties |\n","| get_group_attributes_as_df | Gets attributes of a group in the HDF file as a DataFrame |\n","| get_hdf_filename | Gets the HDF filename from various input types |\n","| get_runtime_data | Extracts runtime and compute time data from a single HDF file |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get HDF Paths with Properties (For Exploring HDF Files)\n","plan_number = \"02\"  # Assuming we're using plan 02 as in the previous code\n","hdf_paths_df = HdfUtils.get_hdf_paths_with_properties(plan_number, ras_object=bald_eagle)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = HdfResultsPlan.get_runtime_data(hdf_input=plan_number, ras_object=bald_eagle)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"markdown","metadata":{},"source":["runtime_df:\n","\n","\n","| Plan Name       | File Name              | Simulation Start Time | Simulation End Time   | Simulation Duration (s) | Simulation Time (hr) | Completing Geometry (hr) | Preprocessing Geometry (hr) | Completing Event Conditions (hr) | Unsteady Flow Computations (hr) | Complete Process (hr) | Unsteady Flow Speed (hr/hr) | Complete Process Speed (hr/hr) |\n","|------------------|-----------------------|-----------------------|-----------------------|-------------------------|-----------------------|---------------------------|-------------------------------|----------------------------------|----------------------------------|------------------------|-------------------------------|----------------------------------|\n","| 0                | 100ft Sediment        | Chippewa_2D.p02.hdf   | 02Apr2019 00:00:00   | 06May2019 00:00:00     | 2937600.0             | 816.0                     | N/A                           | 0.000096                          | N/A                              | N/A                    | 0.040035                      | N/A                              | 20382.307025                     |"]},{"cell_type":"markdown","metadata":{},"source":["Table of all the functions in the RasGeomHdf class from the ras_commander/RasGeomHdf.py file:\n","\n","| Function Name | Description |\n","|---------------|-------------|\n","| projection | Returns the projection of the RAS geometry as a pyproj.CRS object |\n","| get_geom_attrs | Returns base geometry attributes from a HEC-RAS HDF file |\n","\n","| mesh_area_names | Returns a list of the 2D mesh area names of the RAS geometry |\n","| get_geom_2d_flow_area_attrs | Returns geometry 2d flow area attributes from a HEC-RAS HDF file |\n","| mesh_areas | Returns 2D flow area perimeter polygons |\n","| mesh_cell_polygons | Returns 2D flow mesh cell polygons |\n","| mesh_cell_points | Returns 2D flow mesh cell points |\n","| mesh_cell_faces | Returns 2D flow mesh cell faces |\n","\n","| get_geom_structures_attrs | Returns geometry structures attributes from a HEC-RAS HDF file |\n","\n","\n","\n","\n","| bc_lines | Returns 2D mesh area boundary condition lines |\n","| breaklines | Returns 2D mesh area breaklines |\n","\n","\n","\n","| refinement_regions | Returns 2D mesh area refinement regions |\n","| structures | Returns the model structures |\n","| reference_lines_names | Returns reference line names |\n","| reference_points_names | Returns reference point names |\n","| reference_lines | Returns the reference lines geometry and attributes |\n","| reference_points | Returns the reference points geometry and attributes |\n","| cross_sections | Returns the model 1D cross sections |\n","| river_reaches | Returns the model 1D river reach lines |\n","| cross_sections_elevations | Returns the model cross section elevation information |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n","print(geom_hdf_path)\n","\n","# For the example project, plan 02 is associated with geometry 09\n","# If you want to call the geometry by number, call RasHdfGeom functions with a number\n","# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Set the  to USA Contiguous Albers Equal Area Conic (USGS version)\n","# Note, we would usually call the projection function in HdfMesh but the projection is not set in this example project\n","projection = 'EPSG:5070'  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfPlan for geometry-related operations\n","print(\"\\nExample: Extracting Base Geometry Attributes\")\n","geom_attrs = HdfPlan.get_geom_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if geom_attrs:\n","    # Convert the dictionary to a DataFrame for better display\n","    geom_attrs_df = pd.DataFrame([geom_attrs])\n","    \n","    # Display the DataFrame\n","    print(\"Base Geometry Attributes:\")\n","    display(geom_attrs_df)\n","else:\n","    print(\"No base geometry attributes found.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["geom_attrs:\n","\n","| Complete Geometry | Extents | Geometry Time       | Land Cover Date Last Modified | Land Cover File Date | Land Cover Filename               | Land Cover Layername | SI Units | Sediment Bed Material Date Last Modified | Sediment Bed Material File Date | Sediment Bed Material Filename         | Sediment Bed Material Layername | Terrain File Date       | Terrain Filename                          | Terrain Layername | Title      | Version                  |\n","|-------------------|---------|---------------------|-------------------------------|----------------------|-----------------------------------|----------------------|----------|------------------------------------------|-------------------------------|-----------------------------------------|----------------------------------|-------------------------|------------------------------------------|-------------------|------------|--------------------------|\n","| True              | [1024276.82827958, 1027738.095898, 7850027.060...] | 01Jun2023 17:10:40 | 25FEB2022 10:39:08          | 25FEB2022 10:39:08   | ..\\Chippewa\\Mannings_n.hdf       | Mannings_n          | False    | 13OCT2020 17:40:32                      | 13OCT2020 17:40:32          | ..\\Chippewa\\Sediment Materials.hdf     | Sediment Materials              | 02JUL2020 09:03:32    | .\\External Dependencies\\100ft.hdf       | 100ft             | 100ft_Mod  | 1.0.20 (20Sep2024)      |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfMesh for geometry-related operations\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Attributes (get_geom_2d_flow_area_attrs)\n","print(\"\\nExample: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_df = pd.DataFrame([flow_area_attributes])\n","    \n","    # Display the DataFrame\n","    print(\"2D Flow Area Attributes:\")\n","    display(flow_area_df)\n","    \n","    # Optionally, you can access specific attributes\n","    print(\"\\nSpecific Attribute Examples:\")\n","    print(f\"Cell Average Size: {flow_area_attributes.get('Cell Average Size', 'N/A')}\")\n","    print(f\"Manning's n: {flow_area_attributes.get('Manning''s n', 'N/A')}\")\n","    print(f\"Terrain Filename: {flow_area_attributes.get('Terrain Filename', 'N/A')}\")\n","else:\n","    print(\"No 2D Flow Area attributes found.\")\n","\n","# Note: This example assumes that get_geom_2d_flow_area_attrs returns a dictionary.\n","# If it returns a different format, you may need to adjust the code accordingly.\n"]},{"cell_type":"markdown","metadata":{},"source":["flow_area_attributes:\n","\n","| Name             | Locked | Mann | Multiple Face Mann n | Composite LC | Cell Vol Tol | Cell Min Area Fraction | Face Profile Tol | Face Area Tol | Face Conv Ratio | Laminar Depth | Min Face Length Ratio | Spacing dx | Spacing dy | Shift dx | Shift dy | Cell Count |\n","|------------------|--------|------|-----------------------|--------------|---------------|------------------------|------------------|----------------|------------------|----------------|------------------------|------------|------------|----------|----------|------------|\n","| [b'Perimeter 1'] | [0]    | [0.06] | [1]                   | [1]          | [0.01]        | [0.01]                | [0.01]          | [0.01]        | [0.02]          | [0.2]          | [0.05]                | [600.0]    | [600.0]    | [nan]    | [nan]    | [354]      |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the 2D Flow Area Perimeter Polygons\n","import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(figsize=(12, 8))\n","mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none')\n","\n","# Add labels for each polygon\n","for idx, row in mesh_areas.iterrows():\n","    centroid = row.geometry.centroid\n","    # Check if 'Name' column exists, otherwise use a default label\n","    label = row.get('Name', f'Area {idx}')\n","    ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","\n","plt.title('2D Flow Area Perimeter Polygons')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract mesh cell faces\n","print(\"\\nExample: Extracting mesh cell faces\")\n","\n","# Get mesh cell faces\n","mesh_cell_faces = HdfMesh.mesh_cell_faces(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Display the first few rows of the mesh cell faces DataFrame\n","print(\"First few rows of mesh cell faces:\")\n","display(mesh_cell_faces.head())"]},{"cell_type":"markdown","metadata":{},"source":["mesh_cell_faces:\n","\n","| mesh_name   | face_id | geometry                                           |\n","|-------------|---------|----------------------------------------------------|\n","| Perimeter 1 | 0       | LINESTRING (1027231.594 7857846.138, 1026833.9... |\n","| Perimeter 1 | 1       | LINESTRING (1026833.966 7857797.923, 1026849.8... |\n","| Perimeter 1 | 2       | LINESTRING (1026849.886 7857613.488, 1027249.0... |\n","| Perimeter 1 | 3       | LINESTRING (1027249.03 7857618.591, 1027231.59... |\n","| Perimeter 1 | 4       | LINESTRING (1027231.594 7857846.138, 1027231.5... |"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Set the projection to USA Contiguous Albers Equal Area Conic (USGS version)\n","# Note, we would usually call the projection function in HdfMesh but the projection is not set in this example project\n","projection = 'EPSG:5070'  # NAD83 / Conus Albers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the mesh cell faces\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Set the projection for the plot\n","ax.set_aspect('equal', adjustable='datalim')\n","ax.set_title('Mesh Cell Faces', fontsize=16)\n","ax.set_xlabel('Easting', fontsize=12)\n","ax.set_ylabel('Northing', fontsize=12)\n","\n","# Plot all cell faces using the specified projection\n","for _, row in mesh_cell_faces.iterrows():\n","    ax.plot(*row['geometry'].xy, color='blue', linewidth=0.5, alpha=0.5)\n","\n","# Add a colorbar to show face IDs\n","scatter = ax.scatter(\n","    mesh_cell_faces.geometry.centroid.x,\n","    mesh_cell_faces.geometry.centroid.y,\n","    c=mesh_cell_faces['face_id'],\n","    cmap='viridis',\n","    s=1,\n","    alpha=0.5\n",")\n","plt.colorbar(scatter, label='Face ID')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calculate and display some statistics\n","print(\"\\nMesh Cell Faces Statistics:\")\n","print(f\"Total number of cell faces: {len(mesh_cell_faces)}\")\n","print(f\"Number of unique meshes: {mesh_cell_faces['mesh_name'].nunique()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to find the nearest cell face to a given point\n","def find_nearest_cell_face(point, cell_faces_df):\n","    \"\"\"\n","    Find the nearest cell face to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_faces_df (GeoDataFrame): DataFrame containing cell face linestrings.\n","\n","    Returns:\n","        int: The face_id of the nearest cell face.\n","        float: The distance to the nearest cell face.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell faces\n","    distances = cell_faces_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the face_id and distance of the nearest cell face\n","    nearest_face_id = cell_faces_df.loc[nearest_index, 'face_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_face_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell face to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Create the sample point with the same CRS as mesh_cell_faces\n","sample_point = GeoDataFrame(\n","    {'geometry': [Point(1025677, 7853731)]}, \n","    crs=mesh_cell_faces.crs\n",")\n","\n","if not mesh_cell_faces.empty and not sample_point.empty:\n","    nearest_face_id, distance = find_nearest_cell_face(sample_point.geometry.iloc[0], mesh_cell_faces)\n","    print(f\"Nearest cell face to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Face ID: {nearest_face_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell faces\n","    mesh_cell_faces.plot(ax=ax, color='blue', linewidth=0.5, alpha=0.5, label='Cell Faces')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell face\n","    nearest_face = mesh_cell_faces[mesh_cell_faces['face_id'] == nearest_face_id]\n","    nearest_face.plot(ax=ax, color='green', linewidth=2, alpha=0.7, label='Nearest Face')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell Face to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell face search due to missing data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Cell Polygons\n","print(\"\\nExample 6: Extracting Cell Polygons\")\n","cell_polygons_df = HdfMesh.mesh_cell_polygons(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_polygons_df.empty:\n","    display(cell_polygons_df.head())\n","else:\n","    print(\"No Cell Polygons found.\")\n","\n","# Plot cell polygons\n","if not cell_polygons_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell polygons\n","    cell_polygons_df.plot(ax=ax, edgecolor='blue', facecolor='none')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Polygons')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell polygon data available for plotting.\")"]},{"cell_type":"markdown","metadata":{},"source":["cell_polygons_df:\n","| mesh_name   | cell_id | geometry                             |\n","|-------------|---------|--------------------------------------|\n","| Perimeter 1 | 0       | POLYGON ((1026421.241 7857214.462, 1026297.261... |\n","| Perimeter 1 | 1       | POLYGON ((1026421.241 7857214.462, 1026454.941... |\n","| Perimeter 1 | 2       | POLYGON ((1026322.451 7856791.144, 1026329.012... |\n","| Perimeter 1 | 3       | POLYGON ((1026696.503 7856780.036, 1026591.883... |\n","| Perimeter 1 | 4       | POLYGON ((1026208.456 7855828.458, 1026126.864... |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 5: Extract Cell Info\n","print(\"\\nExample 5: Extracting Cell Info\")\n","cell_info_df = HdfMesh.mesh_cell_points(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_info_df.empty:\n","    display(cell_info_df.head())\n","else:\n","    print(\"No Cell Info found.\")\n","\n","# Plot cell centers\n","import matplotlib.pyplot as plt\n","\n","if not cell_info_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell centers\n","    cell_info_df.plot(ax=ax, color='red', markersize=5)\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Centers')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell data available for plotting.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["cell_info_df\n","\n","Extracting Cell Info\n","| mesh_name   | cell_id | geometry                             |\n","|-------------|---------|--------------------------------------|\n","| Perimeter 1 | 0       | POINT (1026293.682 7857287.293)     |\n","| Perimeter 1 | 1       | POINT (1026398.126 7857069.407)     |\n","| Perimeter 1 | 2       | POINT (1026433.246 7856847.728)     |\n","| Perimeter 1 | 3       | POINT (1026605.884 7856865.385)     |\n","| Perimeter 1 | 4       | POINT (1026084.887 7855780.411)     |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Provide function that will accept a geopandas point object and will find the nearest cell center\n","# Function to find the nearest cell center to a given point\n","def find_nearest_cell(point, cell_centers_df):\n","    \"\"\"\n","    Find the nearest cell center to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_centers_df (GeoDataFrame): DataFrame containing cell center points.\n","\n","    Returns:\n","        int: The cell_id of the nearest cell.\n","        float: The distance to the nearest cell center.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell centers\n","    distances = cell_centers_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the cell_id and distance of the nearest cell\n","    nearest_cell_id = cell_centers_df.loc[nearest_index, 'cell_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_cell_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Set the projection to USA Contiguous Albers Equal Area Conic (USGS version)\n","# Note, we would usually call the projection function in HdfMesh but the projection is not set in this example project\n","projection = 'EPSG:5070'  # NAD83 / Conus Albers\n","\n","# Create the sample point with the correct CRS\n","print(\"Create Sample Point\")\n","sample_point = GeoDataFrame({'geometry': [Point(1026614, 7854594)]}, crs=projection)\n","\n","\n","print(\"\")\n","if not cell_info_df.empty and not sample_point.empty:\n","    \n","    nearest_cell_id, distance = find_nearest_cell(sample_point.geometry.iloc[0], cell_info_df)\n","    print(f\"Nearest cell to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Cell ID: {nearest_cell_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell centers\n","    cell_info_df.plot(ax=ax, color='blue', markersize=5, alpha=0.5, label='Cell Centers')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell center\n","    nearest_cell = cell_info_df[cell_info_df['cell_id'] == nearest_cell_id]\n","    nearest_cell.plot(ax=ax, color='green', markersize=100, alpha=0.7, label='Nearest Cell')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell search due to missing data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Boundary Condition Lines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 7: Extracting Boundary Condition Lines and Plotting with 2D Flow Area Perimeter Polygons\")\n","bc_lines_df = HdfBndry.bc_lines(geom_hdf_path, ras_object=bald_eagle)\n","if not bc_lines_df.empty:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines found.\")\n","\n","# Plot if data exists\n","if not bc_lines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot boundary condition lines\n","    if not bc_lines_df.empty:\n","        bc_lines_df.plot(ax=ax, color='red', linewidth=2, label='Boundary Condition Lines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Boundary Condition Lines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"markdown","metadata":{},"source":["bc_lines_df:\n","\n","| bc_line_id | name       | mesh_name   | type     | geometry                                                       |\n","|-------------|------------|-------------|----------|---------------------------------------------------------------|\n","| 0           | Upstream   | Perimeter 1 | External | LINESTRING (1027205.957 7858200.238, 1025994.9...)          |\n","| 1           | Downstream | Perimeter 1 | External | LINESTRING (1026484.007 7850421.804, 1024446.2...)          |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Breaklines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 8: Extracting Breaklines and Plotting with 2D Flow Area Perimeter Polygons\")\n","breaklines_df = HdfBndry.breaklines(geom_hdf_path, ras_object=bald_eagle)\n","if not breaklines_df.empty:\n","    display(breaklines_df.head())\n","else:\n","    print(\"No Breaklines found.\")\n","\n","# Plot breaklines and 2D Flow Area Perimeter Polygons if they exist\n","if not breaklines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot breaklines\n","    if not breaklines_df.empty:\n","        breaklines_df.plot(ax=ax, color='blue', linewidth=2, label='Breaklines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Breaklines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load and plot data/profile_lines_chippewa2D.geojson \n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Load the GeoJSON file\n","geojson_path = r'data/profile_lines_chippewa2D.geojson'  # Update with the correct path\n","profile_lines_gdf = gpd.read_file(geojson_path)\n","\n","# Set the Coordinate Reference System (CRS) to EPSG:5070\n","profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n","\n","# Check the Coordinate Reference System (CRS)\n","if profile_lines_gdf.crs is None:\n","    print(\"Warning: The GeoDataFrame does not have a defined CRS.\")\n","else:\n","    print(f\"CRS of the profile lines GeoDataFrame: {profile_lines_gdf.crs}\")\n","\n","# Plot the profile lines\n","fig, ax = plt.subplots(figsize=(12, 8))\n","profile_lines_gdf.plot(ax=ax, color='orange', linewidth=2, label='Profile Lines')\n","\n","# Set labels and title\n","ax.set_xlabel('Easting')\n","ax.set_ylabel('Northing')\n","ax.set_title('Profile Lines')\n","\n","# Add grid and legend\n","ax.grid(True)\n","ax.legend()\n","\n","# Adjust layout and display\n","plt.tight_layout()\n","plt.show()\n","\n","print(profile_lines_gdf)"]},{"cell_type":"markdown","metadata":{},"source":["profile_lines_gdf:\n","\n","| Name            |                                           geometry                                           |\n","|-----------------|-----------------------------------------------------------------------------------------------|\n","| Profile Line 1  | LINESTRING (1027230.307 7853817.865, 1026824.3...)                                         |\n","| Profile Line 2  | LINESTRING (1027326.023 7857086.707, 1026860.8...)                                         |\n","| Profile Line 3  | LINESTRING (1026863.782 7851854.837, 1026156.6...)                                         |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract mesh cell faces and plot with profile lines\n","print(\"\\nExample: Extracting mesh cell faces and plotting with profile lines\")\n","\n","# Get mesh cell faces\n","mesh_cell_faces = HdfMesh.mesh_cell_faces(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Display the first few rows of the mesh cell faces DataFrame\n","print(\"First few rows of mesh cell faces:\")\n","display(mesh_cell_faces.head())\n","\n","# Load the GeoJSON file for profile lines\n","geojson_path = r'data/profile_lines_chippewa2D.geojson'  # Update with the correct path\n","profile_lines_gdf = gpd.read_file(geojson_path)\n","\n","# Set the Coordinate Reference System (CRS) to EPSG:5070\n","profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n","\n","# Plot the mesh cell faces and profile lines together\n","fig, ax = plt.subplots(figsize=(12, 8))\n","mesh_cell_faces.plot(ax=ax, color='blue', alpha=0.5, edgecolor='k', label='Mesh Cell Faces')\n","profile_lines_gdf.plot(ax=ax, color='orange', linewidth=2, label='Profile Lines')\n","\n","# Set labels and title\n","ax.set_xlabel('Easting')\n","ax.set_ylabel('Northing')\n","ax.set_title('Mesh Cell Faces and Profile Lines')\n","\n","# Add grid and legend\n","ax.grid(True)\n","ax.legend()\n","\n","# Adjust layout and display\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["\n","Identifying Sets of Cell Faces for each Profile Line\n","\n","- find all mesh faces whose points are within 10ft of the any profile line segment\n","- discard any mesh faces whose angle differs from the nearest profile line segment by more than 15 degrees\n","- For each profile line, provide mesh cell faces that meet the criteria.  Show a plot, with mesh cell faces and profile lines, with the selected set of mesh cell faces highlighted with a red dashed line.  Zoom level of plot should be slightly zoomed out from the profile line.  One list and one plot per profile line\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extracting mesh cell faces near profile lines\n","print(\"\\nExample: Extracting mesh cell faces near profile lines\")\n","\n","# Get mesh cell faces\n","mesh_cell_faces = HdfMesh.mesh_cell_faces(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Display the first few rows of the mesh cell faces DataFrame\n","print(\"First few rows of mesh cell faces:\")\n","display(mesh_cell_faces.head())\n","\n","# Load the GeoJSON file for profile lines\n","geojson_path = r'data/profile_lines_chippewa2D.geojson'  # Update with the correct path\n","profile_lines_gdf = gpd.read_file(geojson_path)\n","\n","# Set the Coordinate Reference System (CRS) to EPSG:5070\n","profile_lines_gdf = profile_lines_gdf.set_crs(epsg=5070, allow_override=True)\n","\n","# Initialize a dictionary to store faces near each profile line\n","faces_near_profile_lines = {}\n","\n","# Define distance threshold (10 ft converted to meters)\n","distance_threshold = 10\n","angle_threshold = 60  # degrees\n","\n","# Function to calculate the smallest angle between two lines or line segments.\n","# The angle is calculated in degrees relative to the positive x-axis.\n","# If the input is a LineString object, the angle is computed using the \n","# coordinates of the start and end points of the line.\n","# If the input is a list of two points, the angle is calculated \n","# directly from those points.\n","\n","def calculate_angle(line):\n","    if isinstance(line, LineString):\n","        x_diff = line.xy[0][-1] - line.xy[0][0]\n","        y_diff = line.xy[1][-1] - line.xy[1][0]\n","    else:\n","        x_diff = line[1][0] - line[0][0]\n","        y_diff = line[1][1] - line[0][1]\n","    \n","    angle = np.degrees(np.arctan2(y_diff, x_diff))\n","    return angle % 360 if angle >= 0 else (angle + 360) % 360\n","\n","# Function to break line into segments\n","def break_line_into_segments(line, segment_length):\n","    segments = []\n","    segment_angles = []\n","    \n","    distances = np.arange(0, line.length, segment_length)\n","    if distances[-1] != line.length:\n","        distances = np.append(distances, line.length)\n","        \n","    for i in range(len(distances)-1):\n","        point1 = line.interpolate(distances[i])\n","        point2 = line.interpolate(distances[i+1])\n","        segment = LineString([point1, point2])\n","        segments.append(segment)\n","        segment_angles.append(calculate_angle([point1.coords[0], point2.coords[0]]))\n","        \n","    return segments, segment_angles\n","\n","# Function to calculate angle difference accounting for 180 degree equivalence\n","def angle_difference(angle1, angle2):\n","    diff = abs(angle1 - angle2) % 180\n","    return min(diff, 180 - diff)\n","\n","# Function to order faces along profile line\n","def order_faces_along_profile(profile_line, faces_gdf):\n","    # Get start point of profile line\n","    profile_start = Point(profile_line.coords[0])\n","    \n","    # Calculate distance from each face's start point to profile start\n","    faces_with_dist = []\n","    for idx, face in faces_gdf.iterrows():\n","        face_start = Point(face.geometry.coords[0])\n","        dist = profile_start.distance(face_start)\n","        faces_with_dist.append((idx, dist))\n","    \n","    # Sort faces by distance\n","    faces_with_dist.sort(key=lambda x: x[1])\n","    \n","    # Return ordered face indices\n","    return [x[0] for x in faces_with_dist]\n","\n","# Function to combine ordered faces into single linestring\n","def combine_faces_to_linestring(ordered_faces_gdf):\n","    coords = []\n","    for _, face in ordered_faces_gdf.iterrows():\n","        if not coords:  # First face - add all coordinates\n","            coords.extend(list(face.geometry.coords))\n","        else:  # Subsequent faces - add only end coordinate\n","            coords.append(face.geometry.coords[-1])\n","    return LineString(coords)\n","\n","# Initialize GeoDataFrame for final profile-to-faceline results\n","profile_to_faceline = gpd.GeoDataFrame(columns=['profile_name', 'geometry'], crs=profile_lines_gdf.crs)\n","\n","# Iterate through each profile line\n","for index, profile_line in profile_lines_gdf.iterrows():\n","    profile_geom = profile_line.geometry\n","    \n","    # Break profile line into segments\n","    segments, segment_angles = break_line_into_segments(profile_geom, distance_threshold)\n","    \n","    # Initialize set to store nearby faces\n","    nearby_faces = set()\n","    \n","    # For each face, check distance to segments and angle difference\n","    for face_idx, face in mesh_cell_faces.iterrows():\n","        face_geom = face.geometry\n","        \n","        if isinstance(face_geom, LineString):\n","            face_angle = calculate_angle(face_geom)\n","            \n","            for segment, segment_angle in zip(segments, segment_angles):\n","                if face_geom.distance(segment) <= distance_threshold:\n","                    if angle_difference(face_angle, segment_angle) <= angle_threshold:\n","                        nearby_faces.add(face_idx)\n","                        break\n","    \n","    # Convert the set of indices back to a GeoDataFrame\n","    nearby_faces_gdf = mesh_cell_faces.loc[list(nearby_faces)]\n","    \n","    # Order faces along profile line\n","    ordered_indices = order_faces_along_profile(profile_geom, nearby_faces_gdf)\n","    ordered_faces_gdf = nearby_faces_gdf.loc[ordered_indices]\n","    \n","    # Combine ordered faces into single linestring\n","    combined_linestring = combine_faces_to_linestring(ordered_faces_gdf)\n","    \n","    # Add to profile_to_faceline GeoDataFrame\n","    new_row = gpd.GeoDataFrame({'profile_name': [profile_line['Name']], \n","                               'geometry': [combined_linestring]}, \n","                              crs=profile_lines_gdf.crs)\n","    profile_to_faceline = pd.concat([profile_to_faceline, new_row], ignore_index=True)\n","    \n","    # Store the ordered faces in the dictionary\n","    faces_near_profile_lines[profile_line['Name']] = ordered_faces_gdf\n","\n","# Plot the results\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Plot all mesh cell faces in light blue\n","mesh_cell_faces.plot(ax=ax, color='lightblue', alpha=0.3, edgecolor='k', label='All Mesh Faces')\n","\n","# Plot selected faces for each profile line with numbers\n","colors = ['red', 'green', 'blue']\n","for (profile_name, faces), color in zip(faces_near_profile_lines.items(), colors):\n","    if not faces.empty:\n","        faces.plot(ax=ax, color=color, alpha=0.6, label=f'Faces near {profile_name}')\n","        \n","        # Add numbers to faces\n","        for i, (idx, face) in enumerate(faces.iterrows()):\n","            midpoint = face.geometry.interpolate(0.5, normalized=True)\n","            ax.text(midpoint.x, midpoint.y, str(i+1), \n","                   color=color, fontweight='bold', ha='center', va='center')\n","\n","# Plot the combined linestrings\n","profile_to_faceline.plot(ax=ax, color='black', linewidth=2, \n","                        linestyle='--', label='Combined Face Lines')\n","\n","# Set labels and title\n","ax.set_xlabel('Easting')\n","ax.set_ylabel('Northing')\n","ax.set_title('Mesh Cell Faces and Profile Lines\\nNumbered in order along profile')\n","\n","# Add grid and legend\n","ax.grid(True)\n","ax.legend()\n","\n","# Adjust layout and display\n","plt.tight_layout()\n","plt.show()\n","\n","# Display the results\n","print(\"\\nOriginal ordered faces near profile lines:\")\n","display(faces_near_profile_lines)\n","\n","print(\"\\nCombined profile-to-faceline results:\")\n","display(profile_to_faceline)"]},{"cell_type":"markdown","metadata":{},"source":["# Identify the adjacent mesh cell \n","\n","# Original ordered faces near profile lines:\n","\n","faces_near_profile_lines\n","\n","| Profile Line     | mesh_name   | face_id | geometry                                           |\n","|------------------|-------------|---------|----------------------------------------------------|\n","| Profile Line 1   | Perimeter 1 | 272     | LINESTRING (1027033.379 7853915.407, 1027236.5...) |\n","|                  | Perimeter 1 | 280     | LINESTRING (1026828.547 7854023.197, 1027033.3...) |\n","|                  | Perimeter 1 | 788     | LINESTRING (1026679.152 7854178.914, 1026828.5...) |\n","|                  | Perimeter 1 | 497     | LINESTRING (1026514.717 7854204.236, 1026318.9...) |\n","|                  | Perimeter 1 | 786     | LINESTRING (1026514.717 7854204.236, 1026679.1...) |\n","|                  | Perimeter 1 | 362     | LINESTRING (1026318.937 7854241.964, 1026124.1...) |\n","|                  | Perimeter 1 | 370     | LINESTRING (1026124.125 7854277.676, 1025914.9...) |\n","|                  | Perimeter 1 | 232     | LINESTRING (1025697.135 7854288.241, 1025914.9...) |\n","|                  | Perimeter 1 | 747     | LINESTRING (1025492.697 7854295.877, 1025310.0...) |\n","|                  | Perimeter 1 | 216     | LINESTRING (1025492.697 7854295.877, 1025697.1...) |\n","|                  | Perimeter 1 | 184     | LINESTRING (1025310.011 7854309.329, 1025120.2...) |\n","|                  | Perimeter 1 | 181     | LINESTRING (1025120.253 7854326.58, 1024848.02...) |\n","| Profile Line 2   | Perimeter 1 | 52      | LINESTRING (1027100.412 7857052.854, 1027350.3...) |\n","|                  | Perimeter 1 | 92      | LINESTRING (1026851.383 7857008.101, 1027100.4...) |\n","|                  | Perimeter 1 | 548     | LINESTRING (1026641.354 7856996.257, 1026851.3...) |\n","|                  | Perimeter 1 | 691     | LINESTRING (1026641.354 7856996.257, 1026502.8...) |\n","|                  | Perimeter 1 | 78      | LINESTRING (1026502.841 7856972.375, 1026329.0...) |\n","|                  | Perimeter 1 | 79      | LINESTRING (1026329.012 7856944.836, 1026128.8...) |\n","|                  | Perimeter 1 | 697     | LINESTRING (1025929.132 7856985.559, 1026128.8...) |\n","| Profile Line 3   | Perimeter 1 | 532     | LINESTRING (1026498.193 7851901.653, 1026838.2...) |\n","|                  | Perimeter 1 | 341     | LINESTRING (1026498.193 7851901.653, 1026163.9...) |\n","|                  | Perimeter 1 | 349     | LINESTRING (1026163.923 7851921.349, 1025938.7...) |\n","|                  | Perimeter 1 | 455     | LINESTRING (1025734.076 7851837.786, 1025938.7...) |\n","|                  | Perimeter 1 | 469     | LINESTRING (1025531.838 7851798.217, 1025734.0...) |\n","|                  | Perimeter 1 | 416     | LINESTRING (1025333.4 7851765.372, 1025531.838...) |\n","|                  | Perimeter 1 | 437     | LINESTRING (1025107.276 7851731.39, 1025333.4...) |\n","|                  | Perimeter 1 | 480     | LINESTRING (1024765.061 7851691.548, 1025107.2...) |\n","\n","profile_to_faceline\n","\n","| profile_name     | geometry                                           |\n","|------------------|----------------------------------------------------|\n","| Profile Line 1   | LINESTRING (1027033.379 7853915.407, 1027236.5...) |\n","| Profile Line 2   | LINESTRING (1027100.412 7857052.854, 1027350.3...) |\n","| Profile Line 3   | LINESTRING (1026498.193 7851901.653, 1026838.2...) |\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["face_property_tables = HdfMesh.get_face_property_tables(geom_hdf_path)\n","\n","display(face_property_tables)"]},{"cell_type":"markdown","metadata":{},"source":["face_property_tables: \n","\n","face_property_tables: \n","\n","|   Face ID |         Z |       Area |  Wetted Perimeter |  Manning's n |\n","|-----------|-----------|------------|-------------------|---------------|\n","|         0 | 683.783142 |    0.000000 |          0.000000 |      0.066800 |\n","|         1 | 683.983154 |   25.314476 |        311.063843 |      0.066800 |\n","|         2 | 684.140930 |   77.886810 |        355.364807 |      0.066002 |\n","|         3 | 684.189270 |   98.404495 |        368.926331 |      0.065757 |\n","|         4 | 684.579102 | 249.174759 |        400.563110 |      0.065312 |\n","| ...       | ...       | ...        | ...               | ...           |\n","|      5183 | 683.024048 | 1228.016968 |        475.787079 |      0.063346 |\n","|      5184 | 683.636292 |    0.000000 |          0.000000 |      0.075398 |\n","|      5185 | 683.836304 |   13.135144 |        199.787888 |      0.075398 |\n","|      5186 | 683.945923 |   45.552128 |        391.646118 |      0.075415 |\n","|      5187 | 683.949463 |   51.697250 |        397.835114 |      0.075416 |\n","\n","[5188 rows x 5 columns]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Extract the face property table for the first Face ID\n","face_id = 4\n","face_properties = face_property_tables['Perimeter 1'][face_property_tables['Perimeter 1']['Face ID'] == face_id]\n","\n","# Create subplots arranged horizontally\n","fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n","\n","# Plot Z vs Area\n","axs[0].plot(face_properties['Z'], face_properties['Area'], marker='o', color='blue', label='Area')\n","axs[0].set_title(f'Face ID {face_id}: Z vs Area')\n","axs[0].set_xlabel('Z')\n","axs[0].set_ylabel('Area')\n","axs[0].grid(True)\n","axs[0].legend()\n","\n","# Plot Z vs Wetted Perimeter\n","axs[1].plot(face_properties['Z'], face_properties['Wetted Perimeter'], marker='o', color='green', label='Wetted Perimeter')\n","axs[1].set_title(f'Face ID {face_id}: Z vs Wetted Perimeter')\n","axs[1].set_xlabel('Z')\n","axs[1].set_ylabel('Wetted Perimeter')\n","axs[1].grid(True)\n","axs[1].legend()\n","\n","# Plot Z vs Manning's n\n","axs[2].plot(face_properties['Z'], face_properties[\"Manning's n\"], marker='o', color='red', label=\"Manning's n\")\n","axs[2].set_title(f'Face ID {face_id}: Z vs Manning\\'s n')\n","axs[2].set_xlabel('Z')\n","axs[2].set_ylabel(\"Manning's n\")\n","axs[2].grid(True)\n","axs[2].legend()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh timeseries output\n","\n","# Get mesh areas from previous code cell\n","mesh_areas = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","\n","if mesh_areas:\n","    mesh_name = mesh_areas[0]  # Use the first 2D flow area name\n","    timeseries_da = HdfResultsMesh.mesh_timeseries_output(plan_hdf_path, mesh_name, \"Water Surface\", ras_object=bald_eagle)\n","    print(f\"\\nMesh Timeseries Output (Water Surface) for {mesh_name}:\")\n","    print(timeseries_da)\n","else:\n","    print(\"No mesh areas found in the geometry file.\")\n","\n","# Get mesh cells timeseries output\n","cells_timeseries_ds = HdfResultsMesh.mesh_cells_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Cells Timeseries Output:\")\n","print(cells_timeseries_ds)\n","\n","# Get mesh faces timeseries output\n","faces_timeseries_ds = HdfResultsMesh.mesh_faces_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Faces Timeseries Output:\")\n","print(faces_timeseries_ds)\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","## Face Property Tables\n","\n","| Face ID |      Z      |      Area      | Wetted Perimeter | Manning's n |\n","|---------|-------------|----------------|------------------|-------------|\n","|    0    | 683.783142  |     0.000000   |      0.000000    |   0.066800  |\n","|    1    | 683.983154  |    25.314476   |    311.063843    |   0.066800  |\n","|    2    | 684.140930  |    77.886810   |    355.364807    |   0.066002  |\n","|    3    | 684.189270  |    98.404495   |    368.926331    |   0.065757  |\n","|    4    | 684.579102  |   249.174759   |    400.563110    |   0.065312  |\n","|   ...   |     ...     |       ...      |        ...       |     ...     |\n","|  5183   | 683.024048  |  1228.016968   |    475.787079    |   0.063346  |\n","|  5184   | 683.636292  |     0.000000   |      0.000000    |   0.075398  |\n","|  5185   | 683.836304  |    13.135144   |    199.787888    |   0.075398  |\n","|  5186   | 683.945923  |    45.552128   |    391.646118    |   0.075415  |\n","|  5187   | 683.949463  |    51.697250   |    397.835114    |   0.075416  |\n","\n","**[5188 rows x 5 columns]**\n","\n","## Cells Timeseries Dataset\n","\n","| Mesh Name   | Size  | Dimensions                     | Coordinates                                                                 | Data Variables                                                                                     | Attributes                     |\n","|-------------|-------|--------------------------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|--------------------------------|\n","| Perimeter 1 | 13MB  | (time: 1633, cell_id: 433, face_id: 814) | * time (time) datetime64[ns] <br> * cell_id (cell_id) int32 <br> * face_id (face_id) int32 | Water Surface (time, cell_id) float32 <br> Face Velocity (time, face_id) float32 <br> Face Flow (time, face_id) float32 | mesh_name: Perimeter 1 <br> start_time: 2019-04-02 00:00:00 |\n","\n","## Faces Timeseries Dataset\n","\n","| Mesh Name   | Size  | Dimensions                     | Coordinates                                                                 | Data Variables                                                                                     | Attributes                     |\n","|-------------|-------|--------------------------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|--------------------------------|\n","| Perimeter 1 | 11MB  | (time: 1633, face_id: 814)    | * time (time) datetime64[ns] <br> * face_id (face_id) int32              | face_velocity (time, face_id) float32 <br> face_flow (time, face_id) float32                     | units: ft/s <br> mesh_name: Perimeter 1 <br> variable: Face Velocity |"]},{"cell_type":"markdown","metadata":{},"source":["\n","Identifying Sets of Cell Faces for each Profile Line\n","\n","- find all mesh faces whose points are within 10ft of the any profile line segment\n","- discard any mesh faces whose angle differs from the nearest profile line segment by more than 15 degrees\n","- For each profile line, provide mesh cell faces that meet the criteria.  Show a plot, with mesh cell faces and profile lines, with the selected set of mesh cell faces highlighted with a red dashed line.  Zoom level of plot should be slightly zoomed out from the profile line.  One list and one plot per profile line\n","\n","\n","Face Results: Velocity and Face Flow\n","\n","    The Face Velocity and Face Flow for each face is provided in mesh_cells_timeseries_output\n","\n","\n","Face Property Table: \n","\n","    Faces Area Elevation Values:\n","\n","    For each face, there is a table with Z vs Area, Wetted Perimeter, and Mannings N\n","\n","\n","\n","\n","Faces Minimum Elevation\n","\n","    This will be useful when plotting a profile of the mesh cell faces, showing the variation and composite values for the string of cell faces\n","    because we don't have the terrain, we have to represent the profile using the length of each face, projected vertically from the water surface elevation to the minimum elevation.  \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert all face velocities and face flow values to positive\n","\n","# Function to process and convert face data to positive values\n","def convert_to_positive_values(faces_timeseries_ds, cells_timeseries_ds):\n","    \"\"\"\n","    Convert face velocities and flows to positive values while maintaining their relationships.\n","    \n","    Args:\n","        faces_timeseries_ds (xarray.Dataset): Dataset containing face timeseries data\n","        cells_timeseries_ds (xarray.Dataset): Dataset containing cell timeseries data\n","        \n","    Returns:\n","        xarray.Dataset: Modified dataset with positive values\n","    \"\"\"\n","    # Get the face velocity and flow variables\n","    face_velocity = faces_timeseries_ds['face_velocity']\n","    face_flow = faces_timeseries_ds['face_flow']\n","    \n","    # Calculate the sign of the velocity to maintain flow direction relationships\n","    velocity_sign = xr.where(face_velocity >= 0, 1, -1)\n","    \n","    # Convert velocities and flows to absolute values while maintaining their relationship\n","    faces_timeseries_ds['face_velocity'] = abs(face_velocity)\n","    faces_timeseries_ds['face_flow'] = abs(face_flow)\n","    \n","    # Store the original sign as a new variable for reference\n","    faces_timeseries_ds['velocity_direction'] = velocity_sign\n","    \n","    print(\"Conversion to positive values complete.\")\n","    print(f\"Number of faces processed: {len(faces_timeseries_ds.face_id)}\")\n","    \n","    return faces_timeseries_ds, cells_timeseries_ds\n","\n","# Convert the values in our datasets\n","faces_timeseries_ds_positive, cells_timeseries_ds_positive = convert_to_positive_values(\n","    faces_timeseries_ds, \n","    cells_timeseries_ds\n",")\n","\n","# Print summary statistics to verify the conversion\n","print(\"\\nSummary Statistics for Face Velocity:\")\n","print(f\"Min: {float(faces_timeseries_ds_positive.face_velocity.min()):.2f}\")\n","print(f\"Max: {float(faces_timeseries_ds_positive.face_velocity.max()):.2f}\")\n","print(f\"Mean: {float(faces_timeseries_ds_positive.face_velocity.mean()):.2f}\")\n","\n","print(\"\\nSummary Statistics for Face Flow:\")\n","print(f\"Min: {float(faces_timeseries_ds_positive.face_flow.min()):.2f}\")\n","print(f\"Max: {float(faces_timeseries_ds_positive.face_flow.max()):.2f}\")\n","print(f\"Mean: {float(faces_timeseries_ds_positive.face_flow.mean()):.2f}\")\n","\n","# Create a quick visualization to verify the conversion\n","plt.figure(figsize=(12, 8))\n","\n","# Plot face velocity\n","plt.subplot(2, 1, 1)\n","plt.plot(faces_timeseries_ds_positive['face_velocity'].time, faces_timeseries_ds_positive['face_velocity'].mean(dim='face_id'), label='Mean Face Velocity', color='blue')\n","plt.title('Mean Face Velocity Over Time')\n","plt.xlabel('Time')\n","plt.ylabel('Velocity (m/s)')\n","plt.legend()\n","plt.grid()\n","\n","# Plot face flow\n","plt.subplot(2, 1, 2)\n","plt.plot(faces_timeseries_ds_positive['face_flow'].time, faces_timeseries_ds_positive['face_flow'].mean(dim='face_id'), label='Mean Face Flow', color='green')\n","plt.title('Mean Face Flow Over Time')\n","plt.xlabel('Time')\n","plt.ylabel('Flow (m/s)')\n","plt.legend()\n","plt.grid()\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import xarray as xr\n","\n","# Function to process faces for a single profile line\n","def process_profile_line(profile_name, faces, cells_timeseries_ds, faces_timeseries_ds):\n","    face_ids = faces['face_id'].tolist()\n","    \n","    # Extract relevant data for these faces\n","    face_velocities = faces_timeseries_ds['face_velocity'].sel(face_id=face_ids)\n","    face_flows = faces_timeseries_ds['face_flow'].sel(face_id=face_ids)\n","    \n","    # Create a new dataset with calculated results\n","    results_ds = xr.Dataset({\n","        'face_velocity': face_velocities,\n","        'face_flow': face_flows\n","    })\n","    \n","    # Convert to dataframe for easier manipulation\n","    results_df = results_ds.to_dataframe().reset_index()\n","    \n","    # Add profile name and face order\n","    results_df['profile_name'] = profile_name\n","    results_df['face_order'] = results_df.groupby('time')['face_id'].transform(lambda x: pd.factorize(x)[0])\n","    \n","    return results_df\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# Calculate Vave = Sum Qn / Sum An for each profile line\n","# where Vave = the summation of face flow / flow area for all the faces in the profile line\n","\n","# Then, save the results to CSV"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Process all profile lines\n","all_results = []\n","for profile_name, faces in faces_near_profile_lines.items():\n","    profile_results = process_profile_line(profile_name, faces, cells_timeseries_ds, faces_timeseries_ds)\n","    all_results.append(profile_results)\n","\n","# Combine results from all profile lines\n","combined_results_df = pd.concat(all_results, ignore_index=True)\n","\n","# Display the first few rows of the combined results\n","print(combined_results_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["combined_results_df: \n","\n","\n","|    time    | face_id | face_velocity |  face_flow  |   profile_name   | face_order |\n","|------------|---------|---------------|-------------|------------------|------------|\n","| 2019-04-02 |   370   |    1.543974   | 961.118225  | Profile Line 1   |     0      |\n","| 2019-04-02 |   232   |    2.738194   | 5103.555176 | Profile Line 1   |     1      |\n","| 2019-04-02 |   747   |    3.109769   | 4777.513672 | Profile Line 1   |     2      |\n","| 2019-04-02 |   216   |    2.974400   | 5120.266113 | Profile Line 1   |     3      |\n","| 2019-04-02 |   184   |    0.924792   | 700.676697  | Profile Line 1   |     4      |\n"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate Face Area\n","\n","The **Face Area** can be calculated using the formula:\n","\n","\\[\n","\\text{Face Area} = \\frac{\\text{Face Flow}}{\\text{Face Velocity}}\n","\\]\n","\n","We'll add this as a new column to the `combined_results_df` dataframe.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Define unique colors for each face_id\n","unique_face_ids = combined_results_df['face_id'].unique()\n","colors = plt.cm.viridis(np.linspace(0, 1, len(unique_face_ids)))\n","\n","# Create a color mapping for face_ids\n","color_mapping = dict(zip(unique_face_ids, colors))\n","\n","# Scatter plot for Face Velocity\n","plt.figure(figsize=(12, 6))\n","for face_id in unique_face_ids:\n","    face_data = combined_results_df[combined_results_df['face_id'] == face_id]\n","    plt.scatter(face_data['time'], face_data['face_velocity'].abs(), \n","                label=f'Face ID {face_id}', color=color_mapping[face_id], s=1, linewidth=0.5)\n","plt.title('Face Velocity Time Series')\n","plt.xlabel('Time')\n","plt.ylabel('Face Velocity (m/s)')\n","plt.grid()\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","\n","# Scatter plot for Face Flow\n","plt.figure(figsize=(12, 6))\n","for face_id in unique_face_ids:\n","    face_data = combined_results_df[combined_results_df['face_id'] == face_id]\n","    plt.scatter(face_data['time'], face_data['face_flow'].abs(),\n","                label=f'Face ID {face_id}', color=color_mapping[face_id], s=1, linewidth=0.5)\n","plt.title('Face Flow Time Series')\n","plt.xlabel('Time')\n","plt.ylabel('Face Flow (m/s)')\n","plt.grid()\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["-----"]},{"cell_type":"markdown","metadata":{},"source":["### Create New Time Series DataFrame for Each Profile Line\n","\n","We'll create a dictionary where each key is a profile line name and the value is its corresponding time series dataframe containing only the relevant face cells.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["profile_time_series = {}\n","\n","# Iterate through each profile line and extract its corresponding data\n","for profile_name, faces_gdf in faces_near_profile_lines.items():\n","    # Get the list of face_ids for this profile line\n","    face_ids = faces_gdf['face_id'].tolist()\n","    \n","    # Filter the combined_results_df for these face_ids\n","    profile_df = combined_results_df[combined_results_df['face_id'].isin(face_ids)].copy()\n","    \n","    # Add the profile name as a column\n","    profile_df['profile_name'] = profile_name\n","    \n","    # Reset index for cleanliness\n","    profile_df.reset_index(drop=True, inplace=True)\n","    \n","    # Store in the dictionary\n","    profile_time_series[profile_name] = profile_df\n","    \n","    # Display a preview\n","    print(f\"\\nTime Series DataFrame for {profile_name}:\")\n","    display(profile_df.head())\n","\n","# Optionally, display all profile names\n","print(\"\\nProfile Lines Processed:\")\n","print(list(profile_time_series.keys()))\n"]},{"cell_type":"markdown","metadata":{},"source":["| Time       | face_id | face_velocity | face_flow   | profile_name   | face_order |\n","|------------|---------|---------------|-------------|----------------|------------|\n","| 2019-04-02 | 370     | 1.543974      | 961.118225  | Profile Line 1 | 0          |\n","| 2019-04-02 | 232     | 2.738194      | 5103.555176 | Profile Line 1 | 1          |\n","| 2019-04-02 | 747     | 3.109769      | 4777.513672 | Profile Line 1 | 2          |\n","| 2019-04-02 | 216     | 2.974400      | 5120.266113 | Profile Line 1 | 3          |\n","| 2019-04-02 | 184     | 0.924792      | 700.676697  | Profile Line 1 | 4          |  \n","  \n","\n","\n","| Time       | face_id | face_velocity | face_flow   | profile_name   | face_order |\n","|------------|---------|---------------|-------------|----------------|------------|\n","| 2019-04-02 | 52      | 0.000000      | 0.000000    | Profile Line 2 | 0          |\n","| 2019-04-02 | 92      | 0.000000      | 0.000000    | Profile Line 2 | 1          |\n","| 2019-04-02 | 548     | 1.018038      | 353.129822  | Profile Line 2 | 2          |\n","| 2019-04-02 | 691     | 2.106394      | 2195.409912 | Profile Line 2 | 3          |\n","| 2019-04-02 | 78      | 2.376904      | 3600.228760 | Profile Line 2 | 4          |  \n","  \n","\n","\n","| Time       | face_id | face_velocity | face_flow   | profile_name   | face_order |\n","|------------|---------|---------------|-------------|----------------|------------|\n","| 2019-04-02 | 532     | 0.000000      | 0.000000    | Profile Line 3 | 0          |\n","| 2019-04-02 | 341     | 0.000000      | 0.000000    | Profile Line 3 | 1          |\n","| 2019-04-02 | 349     | 1.962641      | 2601.644287 | Profile Line 3 | 2          |\n","| 2019-04-02 | 455     | 2.367594      | 4148.870605 | Profile Line 3 | 3          |\n","| 2019-04-02 | 469     | 2.515510      | 4458.292480 | Profile Line 3 | 4          |  \n","  \n","  \n"," \n","Profile Lines Processed:\n","['Profile Line 1', 'Profile Line 2', 'Profile Line 3']"]},{"cell_type":"markdown","metadata":{},"source":["### Combine All Profiles into a Single DataFrame\n","\n","This is useful for aggregated analysis or visualization.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","all_profiles_df = pd.concat(profile_time_series.values(), ignore_index=True)\n","\n","# Display the combined dataframe\n","print(\"Combined Time Series DataFrame for All Profiles:\")\n","display(all_profiles_df.head())\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["all_profiles_df:\n","\n","| time       | face_id | face_velocity | face_flow   | profile_name   | face_order |\n","|------------|---------|---------------|-------------|----------------|------------|\n","| 2019-04-02 | 370     | 1.543974      | 961.118225  | Profile Line 1 | 0          |\n","| 2019-04-02 | 232     | 2.738194      | 5103.555176 | Profile Line 1 | 1          |\n","| 2019-04-02 | 747     | 3.109769      | 4777.513672 | Profile Line 1 | 2          |\n","| 2019-04-02 | 216     | 2.974400      | 5120.266113 | Profile Line 1 | 3          |\n","| 2019-04-02 | 184     | 0.924792      | 700.676697  | Profile Line 1 | 4          |\n"]},{"cell_type":"markdown","metadata":{},"source":["### Visualize All WSELs Together\n","\n","This helps in comparing the temporal variations across different profile lines.\n","\n","plt.figure(figsize=(16, 8))\n","\n","# Iterate through each profile line and plot WSEL\n","for profile_name, profile_df in profile_time_series.items():\n","    plt.plot(\n","        profile_df['time'],\n","        profile_df['wsel'],\n","        marker='o',\n","        label=profile_name\n","    )\n","\n","plt.title('Water Surface Elevation (WSEL) Over Time for All Profile Lines')\n","plt.xlabel('Time')\n","plt.ylabel('WSEL (Z)')\n","plt.legend(title='Profile Lines')\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Recursively explore the 2D Flow Areas structure in the geometry HDF file\n","import h5py\n","\n","def print_hdf_structure(name, obj):\n","    \"\"\"Print information about HDF5 object\"\"\"\n","    print(f\"\\nPath: {name}\")\n","    print(f\"Type: {type(obj).__name__}\")\n","    \n","    if isinstance(obj, h5py.Dataset):\n","        print(f\"Shape: {obj.shape}\")\n","        print(f\"Dtype: {obj.dtype}\")\n","        print(\"Attributes:\")\n","        for key, value in obj.attrs.items():\n","            print(f\"  {key}: {value}\")\n","\n","def explore_flow_areas(file_path):\n","    \"\"\"\n","    Recursively explore and print 2D Flow Areas structure in HDF5 file\n","    \n","    :param file_path: Path to the HDF5 file\n","    \"\"\"\n","    try:\n","        with h5py.File(file_path, 'r') as hdf_file:\n","            if '/Geometry/2D Flow Areas' in hdf_file:\n","                flow_areas_group = hdf_file['/Geometry/2D Flow Areas']\n","                flow_areas_group.visititems(print_hdf_structure)\n","            else:\n","                print(\"2D Flow Areas group not found in geometry file\")\n","    except Exception as e:\n","        print(f\"Error exploring HDF file: {e}\")\n","\n","print(\"\\nExploring 2D Flow Areas structure in geometry file:\")\n","print(\"HDF Base Path: /Geometry/2D Flow Areas \")\n","explore_flow_areas(geom_hdf_path)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Extract Breakline as Reference Line\n","\n","We can't use a profile line, because the mesh orientation may be quite different than the direction of flow.  \n","\n","Instead, use a breakline - the one named \"SayersDam\" should work\n","\n","We can find the information specific to faces: \n","\n","\n","\n","\n","\n","\n","# Extract Composite Results for 2D at Profile Lines to simulate Reference Lines\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate average velocity (Vave) for each profile line\n","def calculate_profile_averages(profile_df):\n","    \"\"\"\n","    Calculate average velocity (Vave) for a profile line using Sum(Qn)/Sum(An)\n","    \n","    Args:\n","        profile_df: DataFrame containing face flow data for a profile line\n","    \n","    Returns:\n","        DataFrame with time series of average velocities\n","    \"\"\"\n","    # Group by time to calculate sums for each timestep\n","    time_groups = profile_df.groupby('time').agg({\n","        'face_flow': 'sum'  # Sum of all face flows (Qn)\n","    })\n","    \n","    # Calculate Vave = Sum(Qn)/Sum(An) - Note: face_area is no longer used\n","    time_groups['vave'] = time_groups['face_flow']  # Vave is now just face_flow since face_area is removed\n","    \n","    return time_groups\n","\n","# Calculate averages for each profile line\n","profile_averages = {}\n","for profile_name, profile_df in profile_time_series.items():\n","    averages = calculate_profile_averages(profile_df)\n","    profile_averages[profile_name] = averages\n","    \n","    # Print summary statistics\n","    print(f\"\\nSummary for {profile_name}:\")\n","    print(f\"Mean Vave: {averages['vave'].mean():.2f} ft/s\")\n","    print(f\"Mean Flow: {averages['face_flow'].mean():.2f} cfs\")\n","\n","# Combine all profile averages into a single DataFrame\n","combined_averages = pd.DataFrame()\n","for profile_name, averages in profile_averages.items():\n","    # Add profile name as a column\n","    profile_data = averages.copy()\n","    profile_data['profile_name'] = profile_name\n","    combined_averages = pd.concat([combined_averages, profile_data])\n","\n","# Reset index to make time a column\n","combined_averages = combined_averages.reset_index()\n","\n","# Save to CSV\n","output_file = 'profile_line_averages.csv'\n","combined_averages.to_csv(output_file, index=False)\n","print(f\"\\nResults saved to {output_file}\")\n","\n","# Create visualization of Vave over time for all profile lines\n","plt.figure(figsize=(12, 6))\n","for profile_name, averages in profile_averages.items():\n","    plt.plot(averages.index, averages['vave'], label=profile_name)\n","\n","plt.title('Average Velocity (Vave) Over Time by Profile Line')\n","plt.xlabel('Time')\n","plt.ylabel('Velocity (ft/s)')\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create separate plots for each profile line showing Vave and individual face velocities\n","for profile_name, profile_df in profile_time_series.items():\n","    # Calculate averages for this profile\n","    averages = profile_averages[profile_name]\n","    \n","    # Create figure\n","    plt.figure(figsize=(12, 6))\n","    \n","    # Get ordered faces for this profile from faces_near_profile_lines\n","    ordered_faces = faces_near_profile_lines[profile_name]\n","    \n","    # Plot individual face velocities\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        face_id = face_row['face_id']\n","        face_data = profile_df[profile_df['face_id'] == face_id]\n","        plt.plot(face_data['time'], \n","                face_data['face_velocity'], \n","                alpha=0.3, \n","                linestyle='-',\n","                label=f'Face #{idx} (ID: {face_id})')\n","    \n","    # Plot average velocity\n","    plt.plot(averages.index, \n","            averages['vave'], \n","            color='red', \n","            linewidth=2, \n","            label='Average Velocity (Vave)')\n","    \n","    plt.title(f'Velocities Over Time - {profile_name}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Velocity (ft/s)')\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.grid(True)\n","    \n","    # Adjust layout to prevent legend overlap\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    # Print summary statistics for this profile\n","    print(f\"\\nSummary Statistics for {profile_name}:\")\n","    print(f\"Number of faces: {len(ordered_faces)}\")\n","    print(f\"Mean Vave: {averages['vave'].mean():.2f} ft/s\")\n","    print(f\"Max Vave: {averages['vave'].max():.2f} ft/s\")\n","    print(f\"Min Vave: {averages['vave'].min():.2f} ft/s\")\n","    \n","    # Print face mapping\n","    print(\"\\nFace Mapping:\")\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        print(f\"Face #{idx} = Face ID {face_row['face_id']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create separate plots for each profile line showing total flow and individual face flows\n","for profile_name, profile_df in profile_time_series.items():\n","    # Calculate averages for this profile\n","    averages = profile_averages[profile_name]\n","    \n","    # Create figure\n","    plt.figure(figsize=(12, 6))\n","    \n","    # Get ordered faces for this profile from faces_near_profile_lines\n","    ordered_faces = faces_near_profile_lines[profile_name]\n","    \n","    # Plot individual face flows\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        face_id = face_row['face_id']\n","        face_data = profile_df[profile_df['face_id'] == face_id]\n","        plt.plot(face_data['time'], \n","                abs(face_data['face_flow']), \n","                alpha=0.3, \n","                linestyle='-',\n","                label=f'Face #{idx} (ID: {face_id})')\n","    \n","    # Calculate and plot total flow as sum of absolute face flows\n","    total_flows = []\n","    for time in averages.index:\n","        time_data = profile_df[profile_df['time'] == time]\n","        total_flow = abs(time_data['face_flow']).sum()\n","        total_flows.append(total_flow)\n","    \n","    plt.plot(averages.index, \n","            total_flows, \n","            color='red', \n","            linewidth=2, \n","            label='Total Flow')\n","    \n","    plt.title(f'Flow Over Time - {profile_name}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Flow (cfs)')\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.grid(True)\n","    \n","    # Adjust layout to prevent legend overlap\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    # Print summary statistics for this profile\n","    print(f\"\\nSummary Statistics for {profile_name}:\")\n","    print(f\"Number of faces: {len(ordered_faces)}\")\n","    print(f\"Mean Total Flow: {np.mean(total_flows):.2f} cfs\")\n","    print(f\"Max Total Flow: {np.max(total_flows):.2f} cfs\") \n","    print(f\"Min Total Flow: {np.min(total_flows):.2f} cfs\")\n","    \n","    # Print face mapping\n","    print(\"\\nFace Mapping:\")\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        print(f\"Face #{idx} = Face ID {face_row['face_id']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create separate plots for each profile line showing face flow\n","for profile_name, profile_df in profile_time_series.items():\n","    # Calculate averages for this profile\n","    averages = profile_averages[profile_name]\n","    \n","    # Create figure\n","    plt.figure(figsize=(12, 6))\n","    \n","    # Get ordered faces for this profile from faces_near_profile_lines\n","    ordered_faces = faces_near_profile_lines[profile_name]\n","    \n","    # Plot individual face flow\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        face_id = face_row['face_id']\n","        face_data = profile_df[profile_df['face_id'] == face_id]\n","        plt.plot(face_data['time'], \n","                abs(face_data['face_flow']), \n","                alpha=0.3, \n","                linestyle='-',\n","                label=f'Face #{idx} (ID: {face_id})')\n","    \n","    # Plot average flow\n","    plt.plot(averages.index, \n","            abs(averages['face_flow']), \n","            color='red', \n","            linewidth=2, \n","            label='Average Flow')\n","    \n","    plt.title(f'Flow Over Time - {profile_name}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Flow (cfs)')\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    plt.grid(True)\n","    \n","    # Adjust layout to prevent legend overlap\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    # Print summary statistics for this profile\n","    print(f\"\\nSummary Statistics for {profile_name}:\")\n","    print(f\"Number of faces: {len(ordered_faces)}\")\n","    print(f\"Mean Flow: {abs(averages['face_flow']).mean():.2f} cfs\")\n","    print(f\"Max Flow: {abs(averages['face_flow']).max():.2f} cfs\")\n","    print(f\"Min Flow: {abs(averages['face_flow']).min():.2f} cfs\")\n","    \n","    # Print face mapping\n","    print(\"\\nFace Mapping:\")\n","    for idx, (_, face_row) in enumerate(ordered_faces.iterrows(), 1):\n","        print(f\"Face #{idx} = Face ID {face_row['face_id']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check if we have the necessary variables\n","print(\"Available variables:\")\n","print(\"profile_time_series:\", 'profile_time_series' in locals())\n","print(\"faces_near_profile_lines:\", 'faces_near_profile_lines' in locals())\n","print(\"profile_averages:\", 'profile_averages' in locals())\n","\n","# Look at the structure of profile_time_series\n","if 'profile_time_series' in locals():\n","    for name, df in profile_time_series.items():\n","        print(f\"\\nColumns in {name}:\")\n","        print(df.columns.tolist())"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["def calculate_discharge_weighted_velocity(profile_df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Calculate discharge-weighted average velocity for a profile line\n","    Vw = Sum(|Qi|*Vi)/Sum(|Qi|) where Qi is face flow and Vi is face velocity\n","    \"\"\"\n","    print(\"Calculating discharge-weighted velocity...\")\n","    print(f\"Input DataFrame:\\n{profile_df.head()}\")\n","\n","    # Calculate weighted velocity for each timestep\n","    weighted_velocities = []\n","    for time in profile_df['time'].unique():\n","        time_data = profile_df[profile_df['time'] == time]\n","        abs_flows = np.abs(time_data['face_flow'])\n","        abs_velocities = np.abs(time_data['face_velocity'])\n","        weighted_vel = (abs_flows * abs_velocities).sum() / abs_flows.sum()\n","        weighted_velocities.append({\n","            'time': time,\n","            'weighted_velocity': weighted_vel\n","        })\n","    \n","    weighted_df = pd.DataFrame(weighted_velocities)\n","    print(f\"Calculated weighted velocities:\\n{weighted_df.head()}\")\n","    return weighted_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate for each profile line\n","\n","for profile_name, profile_df in profile_time_series.items():\n","    print(f\"\\nProcessing profile: {profile_name}\")\n","\n","    # Calculate discharge-weighted velocity\n","    weighted_velocities = calculate_discharge_weighted_velocity(profile_df)\n","    \n","    print(\"Weighted velocities calculated.\")\n","    display(weighted_velocities)\n","    \n","    # Convert time to datetime if it isn't already\n","    weighted_velocities['time'] = pd.to_datetime(weighted_velocities['time'])\n","    print(\"Converted time to datetime format.\")\n","\n","    # Get ordered faces for this profile\n","    ordered_faces = faces_near_profile_lines[profile_name]\n","    print(f\"Number of ordered faces: {len(ordered_faces)}\")\n","    \n","    # Save dataframes as profile_name + \"_discharge_weighted_velocity.csv\"\n","    # Save weighted velocities to CSV\n","    output_file = f\"{profile_name}_discharge_weighted_velocity.csv\"\n","    weighted_velocities.to_csv(output_file, index=False)\n","    print(f\"Saved weighted velocities to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create scatter plots for discharge-weighted velocity timeseries for each profile line\n","\n","for profile_name, profile_df in profile_time_series.items():\n","    \n","    print(f\"\\nGenerating scatter plot for profile: {profile_name}\")\n","    \n","    # Calculate discharge-weighted velocity\n","    weighted_velocities = calculate_discharge_weighted_velocity(profile_df)\n","    \n","    # Convert time to datetime if it isn't already\n","    weighted_velocities['time'] = pd.to_datetime(weighted_velocities['time'])\n","    \n","    # Create figure for scatter plot\n","    plt.figure(figsize=(12, 6))\n","    plt.scatter(weighted_velocities['time'], \n","                weighted_velocities['weighted_velocity'], \n","                color='blue', \n","                alpha=0.6, \n","                label='Discharge-Weighted Velocity')\n","    \n","    # Configure plot\n","    plt.title(f'Discharge-Weighted Velocity Timeseries - {profile_name}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Discharge-Weighted Velocity (ft/s)')\n","    plt.grid(True)\n","    plt.legend()\n","    \n","    # Show plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create scatter plots for discharge-weighted velocity timeseries for each profile line\n","\n","for profile_name, profile_df in profile_time_series.items():\n","    \n","    print(f\"\\nGenerating scatter plot for profile: {profile_name}\")\n","    \n","    # Calculate discharge-weighted velocity\n","    weighted_velocities = calculate_discharge_weighted_velocity(profile_df)\n","    \n","    # Convert time to datetime if it isn't already\n","    weighted_velocities['time'] = pd.to_datetime(weighted_velocities['time'])\n","    \n","    # Create figure for scatter plot\n","    plt.figure(figsize=(12, 6))\n","    \n","    # Plot individual face velocities with thinner lines and no markers\n","    for face_id in profile_df['face_id'].unique():\n","        face_data = profile_df[profile_df['face_id'] == face_id]\n","        plt.plot(face_data['time'], \n","                 face_data['face_velocity'], \n","                 alpha=0.3, \n","                 linewidth=1,  # Thinner line\n","                 label=f'Face ID {face_id}')\n","    \n","    # Plot discharge-weighted velocity with thinner line and no marker\n","    plt.plot(weighted_velocities['time'], \n","             weighted_velocities['weighted_velocity'], \n","             color='red', \n","             alpha=0.8, \n","             linewidth=2,  # Thinner line\n","             label='Discharge-Weighted Velocity')\n","    \n","    # Configure plot\n","    plt.title(f'Face Velocities and Discharge-Weighted Velocity Timeseries - {profile_name}')\n","    plt.xlabel('Time')\n","    plt.ylabel('Velocity (ft/s)')\n","    plt.grid(True)\n","    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n","    \n","    # Show plot\n","    plt.tight_layout()\n","    plt.show()\n","    \n","    # Print summary statistics\n","    print(f\"\\nSummary Statistics for {profile_name}:\")\n","    print(f\"Number of faces: {profile_df['face_id'].nunique()}\")\n","    print(f\"Mean Weighted Velocity: {weighted_velocities['weighted_velocity'].mean():.2f} ft/s\")\n","    print(f\"Max Weighted Velocity: {weighted_velocities['weighted_velocity'].max():.2f} ft/s\")\n","    print(f\"Min Weighted Velocity: {weighted_velocities['weighted_velocity'].min():.2f} ft/s\")\n","    \n","    # Print face mapping\n","    print(\"\\nFace Mapping:\")\n","    for idx, face_id in enumerate(profile_df['face_id'].unique(), 1):\n","        print(f\"Face #{idx} = Face ID {face_id}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\23_generating_aep_hyetographs_from_atlas_14.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2.4 Homework and Advanced Applications (AEP Event Modeling)\n",
    "\n",
    "## Created For: AI in H&H Modeling Webinar - October 24, 2024\n",
    "\n",
    "In this session we will modify the Infiltration data for the Davis project, and extract 2D results data from HDF to plot and compare. \n",
    "- Accessing and Modifying Infiltration HDF Data\n",
    "- Scaling Infiltration Rates\n",
    "- Running Multiple Scenarios\n",
    "- Extracting and Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan:\n",
    "1. Utilize GPT o1-mini to generate a hyetograph for a 24-hour storm event from readily available NOAA Atlas 14 CSV data. \n",
    "\n",
    "\n",
    "\n",
    "This data can also be accessed programmatically, or can be averaged for a particular watershed area.  \n",
    " https://github.com/billk-FM/HEC-Commander/tree/main/RAS-Commander/Atlas_14_Variance  \n",
    "\n",
    "Downloading the CSV data from NOAA Atlas 14 is a good middle ground for data entry.  We can utilize the CSV for input into our script, and the location is easily changed for new locations covered by NOAA Atlas 14. \n",
    "\n",
    "### Providing Context to GPT o1-mini\n",
    "\n",
    "The following pages were copied and pasted into the context window of GPT o1-mini, with clear separators between each data source.  \n",
    "\n",
    "- CSV File from NOAA Atlas 14\n",
    "- NOAA Atlas 14 Data Source (Link etc)\n",
    "- Text from the HEC-HMS Technical Reference Manual, \"Frequency Storm\" Section\n",
    "https://www.hec.usace.army.mil/confluence/hmsdocs/hmstrm/meteorology/precipitation/frequency-storm  \n",
    "(omitting the storm area sections since this does not apply)\n",
    "\n",
    "Follow-ups:\n",
    "\n",
    "The follow-ups are documented in the chat conversation linked below.  \n",
    " - The first script was provided as python, not a notebook cell.  I requested a notebook cell. \n",
    " - Several errors were fed back to o1-mini, which were corrected in the final version. These were generally minor errosrs (number of fields/datetime)\n",
    " - A final request to provide plots, which were worked without error\n",
    "\n",
    "For this task, o1's tendency to overthink, revise liberally and provide a lot of output was helpful.  \n",
    "\n",
    "I was able quickly provide a working script based on established and well documented methods that still may not be conveniently accessible in python and would traditionally require a lot of manual coding or an excel spreadsheet.  \n",
    "\n",
    "ChatGPT o1-mini conversation: https://chatgpt.com/share/67152f62-d648-8010-ada7-2ddbf500cb4b   \n",
    "\n",
    "Now, we can focus on getting these hyetographs into HEC-RAS and running the model with these revised inputs, and comparing the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final o1-mini generated code for generating hyetographs is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from math import log, exp\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to parse duration strings and convert them to hours\n",
    "def parse_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Parses a duration string and converts it to hours.\n",
    "    Examples:\n",
    "        \"5-min:\" -> 0.0833 hours\n",
    "        \"2-hr:\" -> 2 hours\n",
    "        \"2-day:\" -> 48 hours\n",
    "    \"\"\"\n",
    "    match = re.match(r'(\\d+)-(\\w+):', duration_str.strip())\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid duration format: {duration_str}\")\n",
    "    value, unit = match.groups()\n",
    "    value = int(value)\n",
    "    unit = unit.lower()\n",
    "    if unit in ['min', 'minute', 'minutes']:\n",
    "        hours = value / 60.0\n",
    "    elif unit in ['hr', 'hour', 'hours']:\n",
    "        hours = value\n",
    "    elif unit in ['day', 'days']:\n",
    "        hours = value * 24\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown time unit in duration: {unit}\")\n",
    "    return hours\n",
    "\n",
    "# Function to read and process the precipitation frequency CSV\n",
    "def read_precipitation_data(csv_file):\n",
    "    \"\"\"\n",
    "    Reads the precipitation frequency CSV and returns a DataFrame\n",
    "    with durations in hours as the index and ARIs as columns.\n",
    "    This function dynamically locates the header line for the data table.\n",
    "    \"\"\"\n",
    "    with open(csv_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    header_line_idx = None\n",
    "    header_pattern = re.compile(r'^by duration for ari', re.IGNORECASE)\n",
    "\n",
    "    # Locate the header line\n",
    "    for idx, line in enumerate(lines):\n",
    "        if header_pattern.match(line.strip().lower()):\n",
    "            header_line_idx = idx\n",
    "            break\n",
    "\n",
    "    if header_line_idx is None:\n",
    "        raise ValueError('Header line for precipitation frequency estimates not found in CSV file.')\n",
    "\n",
    "    # Extract the ARI headers from the header line\n",
    "    header_line = lines[header_line_idx].strip()\n",
    "    headers = [item.strip() for item in header_line.split(',')]\n",
    "    \n",
    "    if len(headers) < 2:\n",
    "        raise ValueError('Insufficient number of ARI columns found in the header line.')\n",
    "\n",
    "    aris = headers[1:]  # Exclude the first column which is the duration\n",
    "\n",
    "    # Define the pattern for data lines (e.g., \"5-min:\", \"10-min:\", etc.)\n",
    "    duration_pattern = re.compile(r'^\\d+-(min|hr|day):')\n",
    "\n",
    "    # Initialize lists to store durations and corresponding depths\n",
    "    durations = []\n",
    "    depths = {ari: [] for ari in aris}\n",
    "\n",
    "    # Iterate over the lines following the header to extract data\n",
    "    for line in lines[header_line_idx + 1:]:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "        if not duration_pattern.match(line):\n",
    "            break  # Stop if the line does not match the duration pattern\n",
    "        parts = [part.strip() for part in line.split(',')]\n",
    "        if len(parts) != len(headers):\n",
    "            raise ValueError(f\"Data row does not match header columns: {line}\")\n",
    "        duration_str = parts[0]\n",
    "        try:\n",
    "            duration_hours = parse_duration(duration_str)\n",
    "        except ValueError as ve:\n",
    "            print(f\"Skipping line due to error: {ve}\")\n",
    "            continue  # Skip lines with invalid duration formats\n",
    "        durations.append(duration_hours)\n",
    "        for ari, depth_str in zip(aris, parts[1:]):\n",
    "            try:\n",
    "                depth = float(depth_str)\n",
    "            except ValueError:\n",
    "                depth = np.nan  # Assign NaN for invalid depth values\n",
    "            depths[ari].append(depth)\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(depths, index=durations)\n",
    "    df.index.name = 'Duration_hours'\n",
    "\n",
    "    # Drop any rows with NaN values (optional, based on data quality)\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to perform log-log linear interpolation for each ARI\n",
    "def interpolate_depths(df, total_duration):\n",
    "    \"\"\"\n",
    "    Interpolates precipitation depths for each ARI on a log-log scale\n",
    "    for each hour up to the total storm duration.\n",
    "    \"\"\"\n",
    "    T = total_duration\n",
    "    t_hours = np.arange(1, T+1)\n",
    "    D = {}\n",
    "    for ari in df.columns:\n",
    "        durations = df.index.values\n",
    "        depths = df[ari].values\n",
    "        # Ensure all depths are positive\n",
    "        if np.any(depths <= 0):\n",
    "            raise ValueError(f\"Non-positive depth value in ARI {ari}\")\n",
    "        # Log-log interpolation\n",
    "        log_durations = np.log(durations)\n",
    "        log_depths = np.log(depths)\n",
    "        log_t = np.log(t_hours)\n",
    "        log_D_t = np.interp(log_t, log_durations, log_depths)\n",
    "        D_t = np.exp(log_D_t)\n",
    "        D[ari] = D_t\n",
    "    return D\n",
    "\n",
    "# Function to compute incremental precipitation depths\n",
    "def compute_incremental_depths(D, total_duration):\n",
    "    \"\"\"\n",
    "    Computes incremental precipitation depths for each hour.\n",
    "    I(t) = D(t) - D(t-1), with D(0) = 0.\n",
    "    \"\"\"\n",
    "    incremental_depths = {}\n",
    "    for ari, D_t in D.items():\n",
    "        I_t = np.empty(total_duration)\n",
    "        I_t[0] = D_t[0]  # I(1) = D(1) - D(0) = D(1)\n",
    "        I_t[1:] = D_t[1:] - D_t[:-1]\n",
    "        incremental_depths[ari] = I_t\n",
    "    return incremental_depths\n",
    "\n",
    "# Function to assign incremental depths using the Alternating Block Method\n",
    "def assign_alternating_block(sorted_depths, max_depth, central_index, T):\n",
    "    \"\"\"\n",
    "    Assigns incremental depths to the hyetograph using the Alternating Block Method.\n",
    "    \"\"\"\n",
    "    hyetograph = [0.0] * T\n",
    "    hyetograph[central_index] = max_depth\n",
    "    remaining_depths = sorted_depths.copy()\n",
    "    remaining_depths.remove(max_depth)\n",
    "    left = central_index - 1\n",
    "    right = central_index + 1\n",
    "    toggle = True  # Start assigning to the right\n",
    "    for depth in remaining_depths:\n",
    "        if toggle and right < T:\n",
    "            hyetograph[right] = depth\n",
    "            right += 1\n",
    "        elif not toggle and left >= 0:\n",
    "            hyetograph[left] = depth\n",
    "            left -= 1\n",
    "        elif right < T:\n",
    "            hyetograph[right] = depth\n",
    "            right += 1\n",
    "        elif left >= 0:\n",
    "            hyetograph[left] = depth\n",
    "            left -= 1\n",
    "        else:\n",
    "            print(\"Warning: Not all incremental depths assigned.\")\n",
    "            break\n",
    "        toggle = not toggle\n",
    "    return hyetograph\n",
    "\n",
    "# Function to generate the hyetograph for a given ARI\n",
    "def generate_hyetograph(incremental_depths, position_percent, T):\n",
    "    \"\"\"\n",
    "    Generates the hyetograph for a given ARI using the Alternating Block Method.\n",
    "    \"\"\"\n",
    "    max_depth = np.max(incremental_depths)\n",
    "    incremental_depths_list = incremental_depths.tolist()\n",
    "    central_index = int(round(T * position_percent / 100)) - 1\n",
    "    central_index = max(0, min(central_index, T - 1))\n",
    "    sorted_depths = sorted(incremental_depths_list, reverse=True)\n",
    "    hyetograph = assign_alternating_block(sorted_depths, max_depth, central_index, T)\n",
    "    return hyetograph\n",
    "\n",
    "# Function to save the hyetograph to a CSV file\n",
    "def save_hyetograph(hyetograph, ari, output_dir, position_percent, total_duration):\n",
    "    \"\"\"\n",
    "    Saves the hyetograph to a CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'Time_hour': np.arange(1, total_duration + 1),\n",
    "        'Precipitation_in': hyetograph\n",
    "    })\n",
    "    filename = f'hyetograph_ARI_{ari}_years_pos{position_percent}pct_{total_duration}hr.csv'\n",
    "    output_file = os.path.join(output_dir, filename)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Hyetograph for ARI {ari} years saved to {output_file}\")\n",
    "\n",
    "# User Inputs\n",
    "# --------------------\n",
    "# Set the path to your input CSV file from NOAA Atlas 14\n",
    "input_csv = 'PF_Depth_English_PDS_DavisCA.csv'  # Update this path if necessary\n",
    "\n",
    "# Set the output directory where hyetograph CSV files will be saved\n",
    "output_dir = 'hyetographs'\n",
    "\n",
    "# Set the position percentage for the maximum incremental depth block\n",
    "# Choose from 25, 33, 50, 67, or 75\n",
    "position_percent = 50  # Default is 50\n",
    "\n",
    "# Set the total storm duration in hours\n",
    "total_duration = 24  # Default is 24 hours\n",
    "\n",
    "# Ensure the output directory exists\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Output directory is set to: {output_dir}\")\n",
    "\n",
    "# Read precipitation data\n",
    "try:\n",
    "    df = read_precipitation_data(input_csv)\n",
    "    print(\"Successfully read the input CSV file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading input CSV: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(\"\\nPrecipitation Frequency Data:\")\n",
    "display(df.head())\n",
    "\n",
    "# Interpolate depths\n",
    "try:\n",
    "    D = interpolate_depths(df, total_duration)\n",
    "    print(\"Successfully interpolated precipitation depths.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during interpolation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Display interpolated depths for the first ARI\n",
    "first_ari = df.columns[0]\n",
    "print(f\"\\nInterpolated Depths for ARI {first_ari} years:\")\n",
    "print(D[first_ari])\n",
    "\n",
    "# Compute incremental depths\n",
    "I = compute_incremental_depths(D, total_duration)\n",
    "print(\"Successfully computed incremental depths.\")\n",
    "\n",
    "# Generate and save hyetographs for each ARI\n",
    "for ari, incremental_depths in I.items():\n",
    "    hyetograph = generate_hyetograph(incremental_depths, position_percent, total_duration)\n",
    "    save_hyetograph(hyetograph, ari, output_dir, position_percent, total_duration)\n",
    "\n",
    "print(\"\\nAll hyetographs have been generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the hyetographs (final request from o1-mini)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot multiple hyetographs on the same plot\n",
    "def plot_multiple_hyetographs(aris, position_percent, total_duration, output_dir='hyetographs'):\n",
    "    \"\"\"\n",
    "    Plots multiple hyetographs for specified ARIs on the same figure for comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    - aris (list of str or int): List of Annual Recurrence Intervals to plot (e.g., [1, 2, 5, 10])\n",
    "    - position_percent (int): Position percentage for the maximum incremental depth block (25, 33, 50, 67, or 75)\n",
    "    - total_duration (int): Total storm duration in hours\n",
    "    - output_dir (str): Directory where hyetograph CSV files are saved\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    for ari in aris:\n",
    "        # Ensure ARI is a string for consistent filename formatting\n",
    "        ari_str = str(ari)\n",
    "        \n",
    "        # Construct the filename based on the naming convention\n",
    "        filename = f'hyetograph_ARI_{ari_str}_years_pos{position_percent}pct_{total_duration}hr.csv'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Warning: File '{filename}' does not exist in the directory '{output_dir}'. Skipping this ARI.\")\n",
    "            continue\n",
    "        \n",
    "        # Read the hyetograph data\n",
    "        try:\n",
    "            hyetograph_df = pd.read_csv(filepath)\n",
    "            print(f\"Successfully read the hyetograph data from '{filename}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading the hyetograph CSV file '{filename}': {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Plot the hyetograph\n",
    "        plt.bar(hyetograph_df['Time_hour'], hyetograph_df['Precipitation_in'], \n",
    "                width=0.8, edgecolor='black', alpha=0.5, label=f'ARI {ari_str} years')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel('Time (Hour)', fontsize=14)\n",
    "    plt.ylabel('Incremental Precipitation (inches)', fontsize=14)\n",
    "    plt.title(f'Comparison of Hyetographs for ARIs {aris}\\nPosition: {position_percent}% | Duration: {total_duration} Hours', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.xticks(range(1, total_duration + 1, max(1, total_duration // 24)))  # Adjust x-ticks based on duration\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# User Inputs for Multiple ARIs\n",
    "# --------------------\n",
    "# Set the Annual Recurrence Intervals you want to plot\n",
    "aris_to_plot = [1, 2, 5, 10, 25, 50, 100, 200, 500, 1000]  # Example: Multiple ARIs\n",
    "\n",
    "# Set the position percentage for the maximum incremental depth block\n",
    "position_percent = 50  # Example: 50%\n",
    "\n",
    "# Set the total storm duration in hours\n",
    "total_duration = 24  # Example: 24 hours\n",
    "\n",
    "# Set the output directory where hyetograph CSV files are saved\n",
    "output_dir = 'hyetographs'  # Ensure this matches the output directory used previously\n",
    "\n",
    "# Plot the multiple hyetographs\n",
    "plot_multiple_hyetographs(aris=aris_to_plot, \n",
    "                           position_percent=position_percent, \n",
    "                           total_duration=total_duration, \n",
    "                           output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: REVISE BELOW TO RUN DAVIS AND EXTRACT RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_oct16_webinar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\24_fluvial_pluvial_delineation.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delineate Fluvial and Pluvial Areas using RAS-Commander\n",
    "\n",
    "We will leverage the HEC RAS Summary Outputs to delineate the Fluvial and Pluvial Areas\n",
    "\n",
    "Maximum Water Surface Elevation (WSEL) for each cell is recorded, along with the timestamps of when the maximum WSEL occurs.\n",
    "\n",
    "By locating adjacent cells with dissimilar timestamps, we can delineate the Fluvial and Pluvial Areas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about datframe types: \n",
    "\n",
    "Information from the HEC-RAS plan files are generally dataframes.  The text file interface is for the 32-bit side of HEC-RAS and all spatial data is most easily accessed in the HDF files.  This includes plan_df, geom_df, hdf_paths_df\n",
    "\n",
    "Geometry elements (Mesh Faces and Nodes) are provided as Geodataframes (cell_polygons_gdf, boundary_gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Libraries\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def install_module(module_name):\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "    except ImportError:\n",
    "        print(f\"{module_name} not found. Installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n",
    "\n",
    "# List of modules to check and install if necessary\n",
    "modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray', 'rtree']\n",
    "for module in modules:\n",
    "    install_module(module)\n",
    "\n",
    "# Import the rest of the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation \n",
    "#  ** Use this version with Jupyter Notebooks **\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import (init_ras_project, HdfBase, HdfFluvialPluvial, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n",
    "    from ras_commander.Decorators import standardize_input, log_call\n",
    "    from ras_commander.LoggingConfig import setup_logging, get_logger\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    print(\"Importing from local ras_commander directory\")\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import (init_ras_project, HdfBase, HdfFluvialPluvial, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, HdfResultsXsec, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras)\n",
    "    from ras_commander.Decorators import standardize_input, log_call\n",
    "    from ras_commander.LoggingConfig import setup_logging, get_logger\n",
    "\n",
    "print(\"ras_commander imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the BaldEagleCrkMulti2D project from HEC and run plan 06\n",
    "\n",
    "# Define the path to the BaldEagleCrkMulti2D project\n",
    "current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n",
    "bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
    "import logging\n",
    "\n",
    "# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n",
    "hdf_file = bald_eagle_path / \"BaldEagleDamBrk.p06.hdf\"\n",
    "\n",
    "if not hdf_file.exists():\n",
    "    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
    "    ras_examples = RasExamples()\n",
    "    ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
    "\n",
    "    # Initialize custom Ras object\n",
    "    bald_eagle = RasPrj()\n",
    "\n",
    "    # Initialize the RAS project using the custom ras object\n",
    "    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n",
    "    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n",
    "    \n",
    "    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n",
    "    \n",
    "    # Define the plan number to execute\n",
    "    plan_number = \"06\"\n",
    "\n",
    "    # Set plan keys for the project\n",
    "    RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=bald_eagle)\n",
    "    RasPlan.update_plan_value(plan_number, \"Run UNet\", 1, ras_object=bald_eagle)\n",
    "    RasPlan.update_plan_value(plan_number, \"Run PostProcess\", 1, ras_object=bald_eagle)\n",
    "    RasPlan.update_plan_value(plan_number, \"Run RASMapper\", 0, ras_object=bald_eagle)\n",
    "\n",
    "    # Execute Plan 06 using RasCmdr for Bald Eagle\n",
    "    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n",
    "    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n",
    "    if success_bald_eagle:\n",
    "        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n",
    "    else:\n",
    "        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n",
    "else:\n",
    "    print(\"BaldEagleCrkMulti2D.p06.hdf already exists. Skipping project extraction and plan execution.\")\n",
    "    # Initialize the RAS project using the custom ras object\n",
    "    bald_eagle = RasPrj()\n",
    "    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n",
    "    plan_number = \"06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n",
    "\n",
    "# Display plan_df for bald_eagle project\n",
    "print(\"Plan DataFrame for bald_eagle project:\")\n",
    "display(bald_eagle.plan_df)\n",
    "\n",
    "# Display geom_df for bald_eagle project\n",
    "print(\"\\nGeometry DataFrame for bald_eagle project:\")\n",
    "display(bald_eagle.geom_df)\n",
    "\n",
    "# Get the plan HDF path\n",
    "plan_number = \"06\"  # Assuming we're using plan 01 as in the previous code\n",
    "plan_hdf_path = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n",
    "\n",
    "# Get the geometry file number from the plan DataFrame\n",
    "geom_file = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n",
    "geom_number = geom_file[1:]  # Remove the 'g' prefix\n",
    "\n",
    "# Get the geometry HDF path\n",
    "geom_hdf_path = bald_eagle.geom_df.loc[bald_eagle.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n",
    "\n",
    "print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n",
    "print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")\n",
    "\n",
    "\n",
    "# Get HDF Paths with Properties (For Exploring HDF Files)\n",
    "hdf_paths_df = HdfUtils.get_hdf_paths_with_properties(plan_number, ras_object=bald_eagle)\n",
    "display(hdf_paths_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using mesh_max_ws, get the cell coordinates and plot the max water surface as a map\n",
    "import matplotlib.pyplot as plt\n",
    "from ras_commander.HdfMesh import HdfMesh\n",
    "from ras_commander.HdfResultsMesh import HdfResultsMesh\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Get mesh max water surface\n",
    "max_ws_df = HdfResultsMesh.mesh_max_ws(plan_hdf_path, ras_object=bald_eagle)\n",
    "\n",
    "print(\"max_ws_df\")\n",
    "print(max_ws_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot\n",
    "HdfFluvialPluvial.plot_max_water_surface(max_ws_df)\n",
    "\n",
    "# Plot the time of maximum water surface elevation\n",
    "HdfFluvialPluvial.plot_max_wsel_time(max_ws_df)\n",
    "\n",
    "# Print the first few rows of the merged dataframe for verification\n",
    "print(\"\\nFirst few rows of the merged dataframe:\")\n",
    "display(max_ws_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use HdfUtils for extracting projection\n",
    "print(\"\\nExtracting Projection from HDF\")\n",
    "projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n",
    "if projection:\n",
    "    print(f\"Projection: {projection}\")\n",
    "else:\n",
    "    print(\"No projection information found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract Cell Polygons\n",
    "print(\"\\nExample 6: Extracting Cell Polygons\")\n",
    "cell_polygons_gdf = HdfMesh.mesh_cell_polygons(geom_hdf_path, ras_object=bald_eagle)\n",
    "\n",
    "\n",
    "# Call the function to plot cell polygons\n",
    "#cell_polygons_gdf = HdfFluvialPluvial.plot_cell_polygons(cell_polygons_gdf, projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import LineString, Polygon, MultiLineString\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from rtree import index\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "boundary_gdf = HdfFluvialPluvial.calculate_fluvial_pluvial_boundary(cell_polygons_gdf, max_ws_df)\n",
    "\n",
    "# Print general information about the boundary GeoDataFrame\n",
    "print(\"\\nBoundary GeoDataFrame info:\")\n",
    "print(boundary_gdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics about the boundary line lengths\n",
    "boundary_lengths = boundary_gdf.geometry.length\n",
    "\n",
    "print(\"Boundary line length statistics:\")\n",
    "print(f\"Max length: {boundary_lengths.max():.2f}\")\n",
    "print(f\"Min length: {boundary_lengths.min():.2f}\")\n",
    "print(f\"Average length: {boundary_lengths.mean():.2f}\")\n",
    "print(f\"Median length: {boundary_lengths.median():.2f}\")\n",
    "\n",
    "# Print general information about the boundary GeoDataFrame\n",
    "print(\"\\nBoundary GeoDataFrame info:\")\n",
    "print(boundary_gdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "cell_polygons_gdf.plot(ax=ax, edgecolor='gray', facecolor='none', alpha=0.5)\n",
    "boundary_gdf.plot(ax=ax, color='red', linewidth=2)\n",
    "plt.title('Fluvial-Pluvial Boundary')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_threshold = 50 #in same units as X and Y coordinates\n",
    "\n",
    "# Filter out boundary lines below the length threshold\n",
    "filtered_boundary_gdf = boundary_gdf[boundary_lengths >= length_threshold]\n",
    "highlighted_boundary_gdf = boundary_gdf[boundary_lengths < length_threshold]\n",
    "\n",
    "# Visualize the results with highlighted boundaries below the threshold\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "cell_polygons_gdf.plot(ax=ax, edgecolor='gray', facecolor='none', alpha=0.5)\n",
    "filtered_boundary_gdf.plot(ax=ax, color='red', linewidth=2, label='Valid Boundaries')\n",
    "highlighted_boundary_gdf.plot(ax=ax, color='blue', linewidth=2, linestyle='--', label='Highlighted Boundaries Below Threshold')\n",
    "plt.title('Fluvial-Pluvial Boundary with Length Threshold')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to GeoJSON\n",
    "boundary_gdf.to_file('fluvial_pluvial_boundary.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdrwksp311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

Folder: c:\GH\ras-commander\examples\data
==================================================

Folder: c:\GH\ras-commander\examples\img
==================================================

File: c:\GH\ras-commander\examples\xx_edge_cases.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

example_projects_folder = Path(__file__).parent.parent / "example_projects"

# delete the folder if it exists
if example_projects_folder.exists():
    shutil.rmtree(example_projects_folder)


# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan using compute_test_mode
    print("Example 1: Executing a single plan using compute_test_mode")
    single_plan = "01"
    dest_folder_suffix = "[SinglePlanTest]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number=single_plan,
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print(f"Execution of plan {single_plan} completed using compute_test_mode")
    print()

    # Example 2: Execute a single plan using compute_parallel
    print("Example 2: Executing a single plan using compute_parallel")
    parallel_result_folder = project_path.parent / "parallel_single_plan_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number=single_plan,
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute a single plan using compute_test_mode with a string input
    print("Example 3: Executing a single plan using compute_test_mode with a string input")
    dest_folder_suffix = "[SinglePlanTestString]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number="02",
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print("Execution of plan 02 completed using compute_test_mode with string input")
    print()

    # Example 4: Execute a single plan using compute_parallel with a string input
    print("Example 4: Executing a single plan using compute_parallel with a string input")
    parallel_result_folder = project_path.parent / "parallel_single_plan_string_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number="01",  # Changed from "03" to "01"
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan (string input) results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 5: Attempt to execute with an empty plan list
    print("Example 5: Attempting to execute with an empty plan list")
    dest_folder_suffix = "[EmptyPlanList]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=[], dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

    # Example 6: Attempt to execute with a non-existent plan number
    print("Example 6: Attempting to execute with a non-existent plan number")
    non_existent_plan = "99"
    dest_folder_suffix = "[NonExistentPlan]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=non_existent_plan, dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\data\PF_Depth_English_PDS_DavisCA.csv
==================================================
Point precipitation frequency estimates (inches)
NOAA Atlas 14 Volume 6 Version 2
Data type: Precipitation depth
Time series type: Partial duration
Project area: Southwest
Location name (ESRI Maps): Davis, California, USA
Station Name: -
Latitude: 38.5467 Degree
Longitude: -121.7443 Degree
Elevation (USGS): 46 ft


PRECIPITATION FREQUENCY ESTIMATES
by duration for ARI (years):, 1,2,5,10,25,50,100,200,500,1000
5-min:, 0.112,0.137,0.174,0.207,0.257,0.299,0.347,0.400,0.479,0.548
10-min:, 0.161,0.197,0.250,0.297,0.368,0.429,0.497,0.573,0.687,0.785
15-min:, 0.194,0.238,0.302,0.359,0.446,0.519,0.601,0.693,0.830,0.949
30-min:, 0.297,0.364,0.461,0.548,0.680,0.792,0.917,1.06,1.27,1.45
60-min:, 0.387,0.474,0.601,0.714,0.886,1.03,1.20,1.38,1.65,1.89
2-hr:, 0.565,0.696,0.880,1.04,1.27,1.47,1.67,1.90,2.23,2.50
3-hr:, 0.698,0.861,1.09,1.28,1.56,1.79,2.03,2.29,2.66,2.96
6-hr:, 1.00,1.24,1.57,1.84,2.22,2.53,2.85,3.19,3.66,4.04
12-hr:, 1.34,1.68,2.13,2.50,3.01,3.41,3.83,4.26,4.86,5.33
24-hr:, 1.77,2.23,2.84,3.34,4.02,4.55,5.09,5.66,6.43,7.03
2-day:, 2.26,2.85,3.62,4.26,5.13,5.80,6.49,7.20,8.16,8.91
3-day:, 2.57,3.25,4.14,4.87,5.87,6.63,7.41,8.22,9.32,10.2
4-day:, 2.81,3.55,4.53,5.33,6.42,7.26,8.11,9.00,10.2,11.1
7-day:, 3.42,4.33,5.53,6.51,7.84,8.86,9.91,11.0,12.4,13.6
10-day:, 3.76,4.77,6.10,7.18,8.65,9.78,10.9,12.1,13.7,15.0
20-day:, 4.88,6.21,7.94,9.34,11.2,12.7,14.1,15.6,17.6,19.2
30-day:, 5.85,7.46,9.53,11.2,13.4,15.1,16.8,18.5,20.7,22.5
45-day:, 7.12,9.08,11.6,13.6,16.2,18.1,20.0,22.0,24.5,26.4
60-day:, 8.41,10.7,13.7,15.9,18.9,21.1,23.2,25.4,28.1,30.1

Date/time (GMT):  Sat Oct 19 21:42:50 2024
pyRunTime:  0.01979207992553711

==================================================

File: c:\GH\ras-commander\examples\data\profile_lines_chippewa2D.geojson
==================================================
{"type":"FeatureCollection","features":[{"type":"Feature","geometry":{"type":"LineString","coordinates":[[1026088.3876320078,7854277.0586871468],[1025906.2217006071,7854271.41852398],[1025310.0176824491,7854307.99545761],[1025121.2715620827,7854322.0960578574]]},"properties":{"Name":"Profile Line 1"}},{"type":"Feature","geometry":{"type":"LineString","coordinates":[[1027326.0231635921,7857086.7069512205],[1026860.8742986278,7857009.6759289969],[1026327.5826063121,7856947.4585648933],[1025933.5393003232,7856977.0858811326]]},"properties":{"Name":"Profile Line 2"}},{"type":"Feature","geometry":{"type":"LineString","coordinates":[[1026841.9610010353,7851873.6222630516],[1026156.6278684236,7851923.9267237745],[1025938.0125029876,7851866.9268233795],[1025107.6308135941,7851731.4566988265],[1024770.768494245,7851688.2087070523]]},"properties":{"Name":"Profile Line 3"}}]}
==================================================

