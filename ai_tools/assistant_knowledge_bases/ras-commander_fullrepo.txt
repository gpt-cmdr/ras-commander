File: C:\GH\ras-commander\.cursorrules
==================================================
# RAS Commander (ras-commander) Coding Assistant

## Overview

This Assistant helps you write efficient Python code for HEC-RAS projects using the RAS Commander library. It automates tasks, provides a Pythonic interface, supports flexible execution modes, and offers built-in examples.

**Core Concepts:** RAS Objects, Project Initialization, File Handling (pathlib.Path), Data Management (Pandas), Execution Modes, Utility Functions.

## Classes, Functions and Arguments

Class/Function | Required Arguments | Optional Arguments
---------------|--------------------|--------------------|
RasPrj | | |
init_ras_project | ras_project_folder, ras_version | ras_instance
RasPlan | | |
set_geom, set_steady, set_unsteady, set_num_cores | plan_number, new_value | ras_object
clone_plan | template_plan | new_plan_shortid, ras_object
RasGeo | | |
clear_geompre_files | | plan_files, ras_object
RasUnsteady | | |
update_unsteady_parameters | unsteady_file, modifications | ras_object
RasCmdr | | |
compute_plan, compute_parallel, compute_test_mode | plan_number | various optional args
RasUtils | | |
create_backup, restore_from_backup, update_plan_file | various | ras_object
RasExamples | | |
extract_project | project_names | -
RasHdf | | |
get_hdf_paths_with_properties, get_runtime_data | hdf_input | ras_object
get_2d_flow_area_names, get_2d_flow_area_attributes | hdf_input | ras_object
get_cell_info, get_cell_points | hdf_input | ras_object
get_polygon_info_and_parts, get_polygon_points | hdf_input | area_name, ras_object
get_cells_center_data, get_faces_area_elevation_data | hdf_input | area_name, ras_object
load_2d_area_solutions | hdf_input | ras_object

## Coding Assistance Rules:

1. Use default libraries, especially pathlib for file operations.
2. Use r-strings for paths, f-strings for formatting.
3. Always use pathlib over os for file/directory operations.
4. Include comments and use logging for output.
5. Follow PEP 8 conventions.
6. Provide clear error handling and user feedback.
7. Explain RAS Commander function purposes and key arguments.
8. Use either global 'ras' object or custom instances consistently.
9. Highlight parallel execution best practices.
10. Suggest RasExamples for testing when appropriate.
11. Utilize RasHdf for HDF file operations and data extraction.

When revising, label planning steps as:
## Explicit Planning and Reasoning for Revisions

Use 'union_all()' for geodataframes. For pandas >= 2.0, use pd.concat instead of append.

Provide full code segments or scripts with no elides.
==================================================

Folder: C:\GH\ras-commander\.gitignore
==================================================

File: C:\GH\ras-commander\Comprehensive_Library_Guide.md
==================================================
# Comprehensive RAS-Commander Library Guide

## Introduction

RAS-Commander (`ras_commander`) is a Python library designed to automate and streamline operations with HEC-RAS projects. It provides a suite of tools for managing projects, executing simulations, and handling results. This guide offers a comprehensive overview of the library's key concepts, modules, best practices, and advanced usage patterns. RAS-Commander is designed to be flexible, robust, and AI-accessible, making it an ideal tool for both manual and automated HEC-RAS workflows.

RAS-Commander can be installed with the following commands:
```
pip install h5py numpy pandas requests tqdm scipy
pip install ras-commander
```

---

## Table of Contents

- [Key Concepts](#key-concepts)
- [Core Features](#core-features)
- [Module Overview](#module-overview)
- [Best Practices](#best-practices)
- [Usage Patterns](#usage-patterns)
  - [Initializing a Project](#initializing-a-project)
  - [Cloning a Plan](#cloning-a-plan)
  - [Executing Plans](#executing-plans)
  - [Working with Multiple Projects](#working-with-multiple-projects)
  - [Performance Optimization](#performance-optimization)
  - [Working with Boundary Conditions](#working-with-boundary-conditions)
  - [Using RasUtils Statistical Methods](#using-rasutils-statistical-methods)
- [Advanced Usage](#advanced-usage)
  - [RasExamples](#rasexamples)
  - [RasUtils](#rasutils)
  - [Artifact System](#artifact-system)
  - [AI-Driven Coding Tools](#ai-driven-coding-tools)
  - [Working with Boundary Conditions](#working-with-boundary-conditions-1)
  - [Advanced Data Processing with RasUtils](#advanced-data-processing-with-rasutils)
- [RasHdf](#rashdf)
- [Troubleshooting](#troubleshooting)
- [Conclusion](#conclusion)

---

## Key Concepts

1. **RAS Objects**:
   - Represent HEC-RAS projects containing information about plans, geometries, and flow files.
   - Support both a global `ras` object and custom `RasPrj` instances for different projects.

2. **Project Initialization**:
   - Use `init_ras_project()` to initialize projects and set up RAS objects.
   - Handles project file discovery and data structure setup.

3. **File Handling**:
   - Utilizes `pathlib.Path` for consistent, platform-independent file paths.
   - Adheres to HEC-RAS file naming conventions (`.prj`, `.p01`, `.g01`, `.f01`, `.u01`).

4. **Data Management**:
   - Employs Pandas DataFrames to manage structured data about plans, geometries, and flow files.
   - Provides methods for accessing and updating these DataFrames.

5. **Execution Modes**:
   - **Single Plan Execution**: Run individual plans.
   - **Sequential Execution**: Run multiple plans in sequence.
   - **Parallel Execution**: Run multiple plans concurrently for improved performance.

6. **Example Projects**:
   - The `RasExamples` class offers functionality to download and manage HEC-RAS example projects for testing and learning.

7. **Utility Functions**:
   - `RasUtils` provides common utility functions for file operations, backups, error handling, and statistical analysis.

8. **Artifact System**:
   - Handles substantial, self-contained content that users might modify or reuse, displayed in a separate UI window.

9. **AI-Driven Coding Tools**:
   - Integrates AI-powered tools like ChatGPT Assistant, LLM Summaries, Cursor IDE Integration, and Jupyter Notebook Assistant.

10. **Boundary Conditions**:
    - Represent the input conditions for HEC-RAS simulations, including flow hydrographs, stage hydrographs, and other hydraulic inputs.
    - The `RasPrj` class provides functionality to extract and manage boundary conditions from unsteady flow files.

11. **Flexibility and Modularity**:
    - All classes are designed to work with either a global 'ras' object + a plan number, or with custom project instances.
    - Clear separation of concerns between project management (RasPrj), execution (RasCmdr), and results data retrieval (RasHdf).

12. **Error Handling and Logging**:
    - Emphasis on robust error checking and informative logging throughout the library.
    - Utilizes the `logging_config` module for consistent logging configuration.
    - `@log_call` decorator applied to relevant functions for logging function calls.

13. **AI-Accessibility**:
    - Structured, consistent codebase with clear documentation to facilitate easier learning and usage by AI models.

---


## Module Overview

1. **RasPrj**: Manages HEC-RAS project initialization and data, including boundary conditions.
2. **RasCmdr**: Handles execution of HEC-RAS simulations.
3. **RasPlan**: Provides functions for plan file operations.
4. **RasGeo**: Manages geometry file operations.
5. **RasUnsteady**: Handles unsteady flow file operations.
6. **RasUtils**: Offers utility functions for common tasks and statistical analysis.
7. **RasExamples**: Manages example HEC-RAS projects.
8. **RasHdf**: Provides utilities for working with HDF files in HEC-RAS projects.

---

## Best Practices

### 1. RAS Object Usage

- **Single Project Scripts**:
  - Use the global `ras` object for simplicity.
    ```python
    from ras_commander import ras, init_ras_project

    init_ras_project("/path/to/project", "6.5")
    # Use ras object for operations
    ```

- **Multiple Projects**:
  - Create separate `RasPrj` instances for each project.
    ```python
    from ras_commander import RasPrj, init_ras_project

    project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
    project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())
    ```

- **Consistency**:
  - Avoid mixing global and custom RAS objects in the same script.

### 2. Plan Specification

- Use plan numbers as strings (e.g., `"01"`, `"02"`) for consistency.
  ```python
  RasCmdr.compute_plan("01")
  ```

- Check available plans before specifying plan numbers.
  ```python
  print(ras.plan_df)  # Displays available plans
  ```

### 3. Geometry Preprocessor Files

- Clear geometry preprocessor files before significant changes.
  ```python
  RasGeo.clear_geompre_files()
  ```

- Use `clear_geompre=True` for a clean computation environment.
  ```python
  RasCmdr.compute_plan("01", clear_geompre=True)
  ```

### 4. Parallel Execution

- Adjust `max_workers` and `num_cores` based on system capabilities.
  ```python
  RasCmdr.compute_parallel(max_workers=4, num_cores=2)
  ```

- Use `dest_folder` to organize outputs and prevent conflicts.
  ```python
  RasCmdr.compute_parallel(dest_folder="/path/to/results")
  ```

### 5. Error Handling

- Implement try-except blocks to handle potential errors.
  ```python
  try:
      RasCmdr.compute_plan("01")
  except FileNotFoundError:
      print("Plan file not found")
  ```

- Utilize logging for informative output.
  ```python
  import logging
  logging.basicConfig(level=logging.INFO)
  ```

### 6. File Path Handling

- Use `pathlib.Path` for robust file and directory operations.
  ```python
  from pathlib import Path
  project_path = Path("/path/to/project")
  ```

### 7. Type Hinting

- Apply type hints to improve code readability and IDE support.
  ```python
  def compute_plan(plan_number: str, clear_geompre: bool = False) -> bool:
      ...
  ```

---

## Usage Patterns

### Initializing a Project
```python
from ras_commander import init_ras_project, ras

init_ras_project("/path/to/project", "6.5")
print(f"Working with project: {ras.project_name}")
```

### Cloning a Plan

```python
from ras_commander import RasPlan

new_plan_number = RasPlan.clone_plan("01")
print(f"Created new plan: {new_plan_number}")
```

### Executing Plans

- **Single Plan Execution**:
  ```python
  from ras_commander import RasCmdr

  success = RasCmdr.compute_plan("01", num_cores=2)
  print(f"Plan execution {'successful' if success else 'failed'}")
  ```

- **Parallel Execution of Multiple Plans**:
  ```python
  from ras_commander import RasCmdr

  results = RasCmdr.compute_parallel(
      plan_numbers=["01", "02", "03"],
      max_workers=3,
      num_cores=4,
      dest_folder="/path/to/results",
      clear_geompre=True
  )

  for plan, success in results.items():
      print(f"Plan {plan}: {'Successful' if success else 'Failed'}")
  ```

### Working with Multiple Projects

```python
from ras_commander import RasPrj, init_ras_project, RasCmdr

# Initialize two separate projects
project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

# Perform operations on each project
RasCmdr.compute_plan("01", ras_object=project1)
RasCmdr.compute_plan("02", ras_object=project2)

# Compare results
results1 = project1.get_hdf_entries()
results2 = project2.get_hdf_entries()
```

### Performance Optimization

```python
from ras_commander import RasCmdr

results = RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03"],
    max_workers=3,
    num_cores=4,
    dest_folder="/path/to/results",
    clear_geompre=True
)

for plan, success in results.items():
    print(f"Plan {plan}: {'Successful' if success else 'Failed'}")
```

- **Best Practices**:
  - Use `compute_parallel()` for concurrent plan execution.
  - Adjust `max_workers` and `num_cores` based on system capabilities.
  - Organize outputs with `dest_folder`.
  - Use `clear_geompre=True` for clean computations.

### Working with Boundary Conditions

```python
from ras_commander import init_ras_project

# Initialize a project
project = init_ras_project("/path/to/project", "6.5")

# Access boundary conditions
boundary_conditions = project.boundaries_df

# Display boundary condition information
print(boundary_conditions)

# Filter boundary conditions for a specific river
river_boundaries = boundary_conditions[boundary_conditions['river_reach_name'] == 'Main River']
print(river_boundaries)
```

### Using RasUtils Statistical Methods

```python
from ras_commander import RasUtils
import numpy as np

# Example observed and predicted values
observed = np.array([100, 120, 140, 160, 180])
predicted = np.array([105, 125, 135, 165, 175])

# Calculate error metrics
metrics = RasUtils.calculate_error_metrics(observed, predicted)

print(f"Correlation: {metrics['cor']:.4f}")
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"Percent Bias: {metrics['pb']:.4f}")

# Calculate individual metrics
rmse = RasUtils.calculate_rmse(observed, predicted)
percent_bias = RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)

print(f"RMSE: {rmse:.4f}")
print(f"Percent Bias: {percent_bias:.2f}%")
```

---

## Advanced Usage

### RasExamples

The `RasExamples` class provides functionality for managing HEC-RAS example projects. This is particularly useful for testing, learning, and development purposes.

#### Key Concepts

- **Example Project Management**: Access and manipulate example projects.
- **Automatic Downloading and Extraction**: Fetches projects from official sources.
- **Project Categorization**: Organizes projects into categories for easy navigation.

#### Usage Patterns

```python
from ras_commander import RasExamples

# Initialize RasExamples
ras_examples = RasExamples()

# Download example projects (if not already present)
ras_examples.get_example_projects()

# List available categories
categories = ras_examples.list_categories()
print(f"Available categories: {categories}")

# List projects in a specific category
steady_flow_projects = ras_examples.list_projects("Steady Flow")
print(f"Steady Flow projects: {steady_flow_projects}")

# Extract specific projects
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
for path in extracted_paths:
    print(f"Extracted project to: {path}")

# Clean up extracted projects when done
ras_examples.clean_projects_directory()
```

### RasUtils

The `RasUtils` class provides utility functions for common tasks in the `ras_commander` library.

#### Key Concepts

- **File and Directory Operations**: Create, delete, and manage files and directories.
- **Backup and Restoration**: Safeguard original files with backups.
- **Error Handling and Retries**: Robust methods to handle common file system errors.
- **Statistical Analysis**: Perform calculations such as RMSE, correlation, and percent bias.

#### Usage Patterns

```python
from ras_commander import RasUtils
from pathlib import Path

# Create a backup of a file
original_file = Path("project.prj")
backup_file = RasUtils.create_backup(original_file)

# Ensure a directory exists
output_dir = RasUtils.create_directory(Path("output"))

# Find files by extension
prj_files = RasUtils.find_files_by_extension(".prj")

# Get file information
file_size = RasUtils.get_file_size(original_file)
mod_time = RasUtils.get_file_modification_time(original_file)

# Update a plan file
RasUtils.update_plan_file("01", "Geom", 2)

# Remove a file or folder with retry logic
RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
```

Certainly! I'll expand the Comprehensive Library Guide with more detailed information on RAS Objects, project initialization, file handling, and consistent file path management. Here's an enhanced version of those sections:

# Comprehensive RAS-Commander Library Guide

## Key Concepts

### RAS Objects

RAS Objects are central to the ras-commander library. They represent HEC-RAS projects and contain all the necessary information about plans, geometries, flow files, and other project components.

1. **Global 'ras' Object**: 
   - By default, the library uses a global 'ras' object.
   - This object is automatically initialized when you call `init_ras_project()`.
   - Suitable for simple scripts working with a single project.

2. **Custom RAS Objects**:
   - For more complex scenarios or when working with multiple projects, you can create custom RAS objects.
   - These are instances of the `RasPrj` class.
   - Allow you to manage multiple projects simultaneously.

3. **Key Attributes of RAS Objects**:
   - `project_folder`: Path to the project folder
   - `prj_file`: Path to the project file
   - `project_name`: Name of the project
   - `ras_exe_path`: Path to the HEC-RAS executable
   - `plan_df`: DataFrame containing plan information
   - `geom_df`: DataFrame containing geometry information
   - `flow_df`: DataFrame containing flow information
   - `unsteady_df`: DataFrame containing unsteady flow information

4. **Importance of Initialization**:
   - RAS objects must be initialized before use.
   - Initialization loads all project data and sets up necessary attributes.
   - Always check if a RAS object is initialized before performing operations.

Example of using custom RAS objects:

```python
from ras_commander import init_ras_project, RasPrj

project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

# Now you can work with project1 and project2 independently
```

### Project Initialization and File Handling

Proper project initialization is crucial for the correct functioning of the ras-commander library. The `init_ras_project()` function is the primary method for setting up a project.

1. **Project Initialization Process**:
   - Locates the project folder and HEC-RAS executable
   - Finds the main project file (.prj)
   - Loads all plan, geometry, and flow file information
   - Sets up DataFrames for easy access to project components

2. **File Discovery**:
   - The library automatically scans the project folder for relevant files
   - Files are categorized based on their extensions (e.g., .p* for plans, .g* for geometries)
   - File information is stored in respective DataFrames (plan_df, geom_df, etc.)

3. **Error Handling During Initialization**:
   - Checks for the existence of the project folder and necessary files
   - Raises informative errors if critical components are missing

4. **Post-Initialization**:
   - After initialization, you can access project information through the RAS object
   - Always check if the RAS object is initialized before performing operations

Example of project initialization:

```python
from ras_commander import init_ras_project, ras

init_ras_project("/path/to/project", "6.5")

# Now you can use the global 'ras' object
print(ras.project_name)
print(ras.plan_df)
```

### Consistent File Path Management

Consistent file path management is critical for reliable operation across different operating systems and environments. The ras-commander library uses `pathlib.Path` for all file and directory operations.

1. **Why Use pathlib.Path**:
   - Operating system independent
   - Provides an object-oriented interface for file path operations
   - Simplifies path manipulation and file operations

2. **Best Practices**:
   - Always use `Path` objects for file and directory paths
   - Use forward slashes ('/') in path strings, which work across all operating systems
   - Use relative paths when possible for better portability

3. **Path Resolution**:
   - The library resolves relative paths to absolute paths during initialization
   - Always work with absolute paths after initialization to avoid ambiguity

4. **Examples from the Library**:

```python
from pathlib import Path

# In RasPrj.py
self.project_folder = Path(project_folder)
self.prj_file = self.find_ras_prj(self.project_folder)

# In RasUtils.py
def create_backup(file_path: Path, backup_suffix: str = "_backup") -> Path:
    original_path = Path(file_path)
    backup_path = original_path.with_name(f"{original_path.stem}{backup_suffix}{original_path.suffix}")
    # ... rest of the function

# In user scripts
from ras_commander import init_ras_project, RasUtils

init_ras_project(Path("/path/to/project"), "6.5")
RasUtils.create_backup(Path("project.prj"))
```

5. **Handling User Input**:
   - When accepting file paths from users, always convert them to Path objects
   - Use `Path(user_input).resolve()` to get the absolute path

6. **Working with Multiple Projects**:
   - Keep paths relative to each project's base directory
   - Use `Path.relative_to()` when needed to get relative paths

By following these practices for file path management, you ensure that your scripts using the ras-commander library will work consistently across different systems and project structures.










### AI-Driven Coding Tools

`ras_commander` integrates several AI-powered tools to enhance the coding experience.

#### Tools and Features

1. **ChatGPT Assistant**:
   - Use for general questions about the library and its usage.
   - Provides code suggestions and explanations.

2. **LLM Summaries**:
   - Utilize large language models for up-to-date context on the codebase.
   - Available in two versions: full codebase and examples/docstrings only.

3. **Cursor IDE Integration**:
   - Offers context-aware suggestions and documentation.
   - Automatically includes a `.cursorrules` file when opening the `ras_commander` folder.

4. **Jupyter Notebook Assistant**:
   - Dynamic code summarization and API interaction.
   - Allows for real-time querying and exploration of the library.

#### Best Practices

- **Documentation First**: Start with the provided documentation and examples.
- **Specific Queries**: Use the ChatGPT Assistant for specific questions or clarifications.
- **LLM Summaries**: Leverage when working with external AI models.
- **IDE Integration**: Use Cursor IDE for the most integrated coding experience.
- **Interactive Learning**: Explore the Jupyter Notebook Assistant for experimentation.


## Approaching Your End User Needs with Ras Commander

### Understanding Data Sources and Strategies

RAS Commander is designed to work efficiently with HEC-RAS projects by focusing on easily accessible data sources. This approach allows for powerful automation while avoiding some of the complexities inherent in HEC-RAS data management. Here's what you need to know:

1. **Data Sources in HEC-RAS Projects**:
   - ASCII input files (plan files, unsteady files, boundary conditions)
   - DSS (Data Storage System) files for inputs
   - HDF (Hierarchical Data Format) files for outputs

2. **RAS Commander's Focus**:
   - Primarily works with plain text inputs and HDF outputs
   - Avoids direct manipulation of DSS files due to their complexity

3. **Strategy for Handling DSS Inputs**:
   - Run the plan or preprocess geometry and event conditions
   - Access the resulting HDF tables, which contain the DSS inputs in an accessible format
   - Define time series directly in the ASCII file instead of as DSS inputs

4. **Accessing Project Data**:
   - Basic project data is loaded from ASCII text files by the RasPrj routines
   - Plan details are available in the HDF file
   - Geometry data is in the dynamically generated geometry HDF file

### Working with RAS Commander

1. **Initialization and Data Loading**:
   - Use `init_ras_project()` to load project data from ASCII files
   - Access plan information from HDF files using provided functions

2. **Handling Geometry Data**:
   - Geometry data is dynamically generated in HDF format
   - Focus on working with the HDF geometry data rather than plain text editing

3. **Workflow for Complex Operations**:
   - Perform the desired operation manually once
   - Provide an example to RAS Commander's AI GPT of what you're changing and why
   - Use this example to develop project-specific functions and code

4. **Example: Replacing DSS-defined Boundary Conditions**:
   - Open the data in HDF View
   - Extract the relevant dataset
   - Manually enter the time series based on the HDF dataset
   - Verify the model works with this change
   - Use this example to create an automated function for similar operations

### Best Practices

1. **Understanding Your Data**:
   - Familiarize yourself with the structure of your HEC-RAS project
   - Identify which data is stored in ASCII, DSS, and HDF formats

2. **Leveraging HDF Outputs**:
   - Whenever possible, use HDF outputs for data analysis and manipulation
   - This approach provides easy access to data without DSS complexities

3. **Iterative Development**:
   - Start with manual operations to understand the process
   - Gradually automate these processes using RAS Commander functions
   - Always check with the HEC-RAS GUI to verify the changes before finalizing the automation

4. **Documentation**:
   - Keep detailed notes on your workflow and changes
   - This documentation will be invaluable for creating automated processes

5. **Flexibility**:
   - Be prepared to adapt your approach based on specific project needs
   - RAS Commander provides a framework, but project-specific solutions will always require custom scripting
   - With an AI assistant, you can quickly leverage this library or your own custom functions to automate your workflows.

By following these strategies and best practices, you can effectively use RAS Commander to automate and streamline your HEC-RAS workflows, working around limitations and leveraging the strengths of the library's approach to data management.


### Working with Boundary Conditions

The `RasPrj` class now provides detailed information about boundary conditions in HEC-RAS projects. This can be particularly useful for advanced analysis and automation tasks.

```python
from ras_commander import init_ras_project

project = init_ras_project("/path/to/project", "6.5")

# Get all boundary conditions
all_boundaries = project.boundaries_df

# Filter for specific boundary condition types
flow_hydrographs = all_boundaries[all_boundaries['bc_type'] == 'Flow Hydrograph']
stage_hydrographs = all_boundaries[all_boundaries['bc_type'] == 'Stage Hydrograph']

# Analyze boundary conditions
for _, boundary in flow_hydrographs.iterrows():
    print(f"River: {boundary['river_reach_name']}")
    print(f"Station: {boundary['river_station']}")
    print(f"Number of values: {boundary['hydrograph_num_values']}")
    print("---")

# Access specific boundary condition details
if 'hydrograph_values' in flow_hydrographs.columns:
    first_hydrograph = flow_hydrographs.iloc[0]['hydrograph_values']
    print("First 5 values of the first flow hydrograph:")
    print(first_hydrograph[:5])
```

### Advanced Data Processing with RasUtils

RasUtils now includes methods for data conversion and statistical analysis, which can be useful for post-processing HEC-RAS results.

```python
from ras_commander import RasUtils
from pathlib import Path
import pandas as pd
import numpy as np

# Convert various data sources to DataFrame
csv_data = RasUtils.convert_to_dataframe(Path("results.csv"))
excel_data = RasUtils.convert_to_dataframe(Path("data.xlsx"), sheet_name="Sheet1")

# Combine data from different sources
combined_data = pd.concat([csv_data, excel_data])

# Perform statistical analysis
observed = combined_data['observed_values'].values
predicted = combined_data['predicted_values'].values

metrics = RasUtils.calculate_error_metrics(observed, predicted)
print("Error Metrics:", metrics)

# Save results to Excel with retry functionality
results_df = pd.DataFrame({
    'Metric': ['Correlation', 'RMSE', 'Percent Bias'],
    'Value': [metrics['cor'], metrics['rmse'], metrics['pb']]
})
RasUtils.save_to_excel(results_df, Path("analysis_results.xlsx"))
```

---

## RasHdf

The `RasHdf` class provides utilities for working with HDF (Hierarchical Data Format) files in HEC-RAS projects. HDF files are commonly used in HEC-RAS for storing large datasets and simulation results.

### Key Features of `RasHdf`:

1. **Reading HDF Tables**: Convert HDF5 datasets to pandas DataFrames.
2. **Writing DataFrames to HDF**: Save pandas DataFrames as HDF5 datasets.
3. **Spatial Operations**: Perform KDTree queries and find nearest neighbors.
4. **Data Consolidation**: Merge duplicate values in DataFrames.
5. **Byte String Handling**: Decode byte strings in DataFrames.

### Example Usage:

```python
from ras_commander import RasHdf
import h5py
import pandas as pd

# Read an HDF table
with h5py.File('results.hdf', 'r') as f:
    dataset = f['water_surface_elevations']
    df = RasHdf.read_hdf_to_dataframe(dataset)

print(df.head())

# Save a DataFrame to HDF
new_data = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
with h5py.File('new_results.hdf', 'w') as f:
    group = f.create_group('my_results')
    RasHdf.save_dataframe_to_hdf(new_data, group, 'my_dataset')

# Perform a KDTree query
import numpy as np
reference_points = np.array([[0, 0], [1, 1], [2, 2]])
query_points = np.array([[0.5, 0.5], [1.5, 1.5]])
results = RasHdf.perform_kdtree_query(reference_points, query_points)
print("KDTree query results:", results)
```




## HDF Paths Supported

This is a list of HDF paths that are directly supported by specialized library functions: 


1. General Paths:
   - '/Results/Summary/Compute Messages (text)'
   - '/Plan Data/Plan Parameters'
   - '/Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D'

2. Geometry Paths:
   - '/Geometry/2D Flow Areas'
   - '/Geometry/2D Flow Areas/{area_name}/Cell Info'
   - '/Geometry/2D Flow Areas/{area_name}/Cell Points'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Info'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Parts'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Points'
   - '/Geometry/2D Flow Areas/{area_name}/Cells Center Coordinate'
   - '/Geometry/2D Flow Areas/{area_name}/Cells Center Manning\'s n'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Area Elevation Values'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Cell Indexes'
   - '/Geometry/2D Flow Areas/{area_name}/Faces FacePoint Indexes'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Low Elevation Centroid'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Minimum Elevation'
   - '/Geometry/2D Flow Areas/{area_name}/Faces NormalUnitVector and Length'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Perimeter Info'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Perimeter Values'
   - '/Geometry/2D Flow Areas/{area_name}/Face Points Coordinates'
   - '/Geometry/2D Flow Areas/{area_name}/Perimeter'
   - '/Geometry/Boundary Condition Lines/Attributes'

3. Results Paths:
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time'
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp'
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area_name}/Water Surface'  # PLACEHOLDER ONLY, DOES NOT WORK
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area_name}/Face Velocity'  # PLACEHOLDER ONLY, DOES NOT WORK
   - '/Results/Summary/Compute Processes'

4. Infiltration Paths:
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Cell Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Face Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Initial Deficit'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Maximum Deficit'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Potential Percolation Rate'

5. Percent Impervious Paths:
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Cell Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Face Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Percent Impervious'


## RasHdf class structure, methods, decorators, and their significance:

1. Class Structure:
   - RasHdf is a utility class designed to work with HDF files produced by HEC-RAS.
   - It contains only static methods, meaning no instance of the class needs to be created to use its functionality.
   - The class serves as a namespace for grouping related HDF file operations.

2. Primary Decorator:
   - @staticmethod: Used on all methods in the class.
   - Significance: Allows methods to be called on the class itself rather than an instance, fitting the utility nature of the class.

3. Custom Decorator:
   - @hdf_operation: A custom decorator defined within the RasHdf class.
   - Purpose: Provides a consistent way to handle HDF file operations, including error handling and file opening/closing.
   - Significance: Centralizes common HDF file handling logic, reducing code duplication and ensuring consistent error handling across methods.

4. Key Methods and Their Purposes:
   a. get_hdf_paths_with_properties(): Lists all paths in the HDF file with their properties.
   b. get_runtime_data(): Extracts runtime and compute time data.
   c. get_2d_flow_area_names(): Lists 2D Flow Area names.
   d. get_2d_flow_area_attributes(): Extracts 2D Flow Area attributes.
   e. get_cell_info(), get_cell_points(): Extract cell-related information.
   f. get_polygon_info_and_parts(), get_polygon_points(): Handle polygon data.
   g. get_cells_center_data(): Extracts cell center coordinates and Manning's n values.
   h. get_faces_area_elevation_data(): Extracts face area elevation data.
   i. load_2d_area_solutions(): Loads 2D area solutions including water surface elevations and velocities.
   j. Methods for infiltration and percent impervious data extraction.

5. Method Structure:
   - Most methods follow a pattern of accepting an hdf_input (which can be a plan number or file path) and an optional ras_object.
   - This structure allows flexibility in how the methods are called, supporting both plan-based and direct file path-based access.

6. Error Handling:
   - Centralized in the @hdf_operation decorator.
   - Catches and logs exceptions, returning None on failure.
   - Provides consistent error reporting across all HDF operations.

7. Flexibility in Usage:
   - Methods can be used with either a global RAS object, a custom RAS object, or by directly providing an HDF file path.
   - This flexibility allows the class to be used in various contexts within the larger ras-commander library.

8. Integration with RasPrj:
   - Many methods rely on the RasPrj class to resolve plan numbers to actual file paths.
   - This integration allows for a high-level, project-oriented approach to working with HDF data.

9. Data Extraction and Conversion:
   - Most methods extract data from the HDF file and convert it to pandas DataFrames.
   - This approach makes the extracted data easily manipulable using standard pandas operations.

10. Significance within the Library:
    - RasHdf serves as the primary interface for extracting and analyzing HEC-RAS output data.
    - It bridges the gap between raw HDF files and usable Python data structures.
    - Enables advanced analysis and post-processing of HEC-RAS results within the ras-commander ecosystem.

11. Extensibility:
    - The class structure allows for easy addition of new methods to support additional HDF data extraction as needed.
    - The @hdf_operation decorator makes it straightforward to add new HDF file operations while maintaining consistent error handling and file management.

12. Performance Considerations:
    - Methods are designed to work with potentially large datasets.
    - Some methods (like load_2d_area_solutions) may be memory-intensive for large models and may require optimization for very large datasets.

This structure makes RasHdf a powerful and flexible tool for working with HEC-RAS output data, providing a pythonic interface to the complex structure of HEC-RAS HDF files. Its integration with the broader ras-commander library allows for seamless incorporation of data analysis into HEC-RAS automation workflows.



---


## Optimizing Parallel Execution with RAS Commander

Efficient parallel execution is crucial for maximizing the performance of HEC-RAS simulations, especially when dealing with multiple plans or large models. RAS Commander offers several strategies for optimizing parallel execution based on your specific needs and system resources.  For more information about these strategies and how to optimize your hardware for HEC-RAS CPU based simulations, see the following blog posts: 

- [10x Engineering in Water Resources with AI](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/1.%2010x%20Engineering%20in%20Water%20Resources%20with%20AI.md)
- [10X Engineering By The Numbers](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/2.%2010XEngineering_By_The_Numbers.md)
- [Think Like A Bootlegger for HEC-RAS Modeling Machines](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/4._Think_Like_A_Bootlegger_for_HEC-RAS_Modeling_Machines.md)
- [Benchmarking Is All You Need](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/7._Benchmarking_Is_All_You_Need.md)
- [Avoiding The Bitter Lesson In RAS Modeling](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/9.Avoiding_The_Bitter_Lesson_In_RAS_Modeling.md)


### Strategy 1: Efficiency Mode for Multiple Plans

This strategy maximizes overall throughput and efficiency when running multiple plans, although individual plan turnaround times may be longer.

**Key Points:**
- Use 2 real cores per plan
- Utilize only physical cores, not hyperthreaded cores

**Example:**
```python
from ras_commander import RasCmdr

# Assuming 8 physical cores on the system
RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03", "04"],
    max_workers=4,  # 8 cores / 2 cores per plan
    num_cores=2
)
```

### Strategy 2: Performance Mode for Single Plans

This strategy maximizes single plan performance by using more cores. It results in less overall efficiency but shortens single plan runtime, making it optimal for situations where individual plan performance is critical.

**Key Points:**
- Use 8-16 cores per plan, depending on system capabilities
- Suitable for running a single plan or a small number of high-priority plans

**Example:**
```python
from ras_commander import RasCmdr

RasCmdr.compute_plan(
    plan_number="01",
    num_cores=12  # Adjust based on your system's capabilities
)
```

### Strategy 3: Background Run Operation

This strategy balances performance and system resource usage, allowing for other operations to be performed concurrently.

**Key Points:**
- Limit total core usage to 50-80% of physical cores
- Combines aspects of Strategies 1 and 2
- Allows overhead for user to complete other operations while calculations are running

**Example:**
```python
import psutil
from ras_commander import RasCmdr

physical_cores = psutil.cpu_count(logical=False)
max_cores_to_use = int(physical_cores * 0.7)  # Using 70% of physical cores

RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03"],
    max_workers=max_cores_to_use // 2,
    num_cores=2
)
```

### Optimizing Geometry Preprocessing

To avoid repeated geometry preprocessing for each run, follow these steps:

1. **Preprocess Geometry:**
   ```python
   from ras_commander import RasPlan
   
   # For each plan you want to preprocess
   RasPlan.update_plan_value(plan_number, "Run HTab", 1)
   RasPlan.update_plan_value(plan_number, "Run UNet", -1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", -1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", -1)
   
   # Run the plan to preprocess geometry
   RasCmdr.compute_plan(plan_number)
   ```

2. **Run Simulations:**
   After preprocessing, update the flags for actual simulations:
   ```python
   RasPlan.update_plan_value(plan_number, "Run HTab", -1)
   RasPlan.update_plan_value(plan_number, "Run UNet", 1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", 1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", 0)
   ```

This approach preprocesses the geometry once, preventing redundant preprocessing when multiple plans use the same geometry.

### Best Practices for Parallel Execution

**Balance Cores:** Find the right balance between the number of parallel plans and cores per plan based on your system's capabilities.
**Consider I/O Operations:** Be aware that disk I/O can become a bottleneck in highly parallel operations.
**Test and Iterate:** Experiment with different configurations to find the optimal setup for your specific models and system.

By leveraging these strategies and best practices, you can significantly improve the performance and efficiency of your HEC-RAS simulations using RAS Commander.





## Troubleshooting

### 1. Project Initialization Issues

- **Ensure Correct Paths**: Verify that the project path is accurate and the `.prj` file exists.
- **HEC-RAS Version**: Confirm that the specified HEC-RAS version is installed on your system.

### 2. Execution Failures

- **File Existence**: Check that all referenced plan, geometry, and flow files exist.
- **Executable Path**: Ensure the HEC-RAS executable path is correctly set.
- **Log Files**: Review HEC-RAS log files for specific error messages.

### 3. Parallel Execution Problems

- **Resource Allocation**: Reduce `max_workers` if encountering memory issues.
- **System Capabilities**: Adjust `num_cores` based on your system's capacity.
- **Clean Environment**: Use `clear_geompre=True` to prevent conflicts.

### 4. File Access Errors

- **Permissions**: Verify read/write permissions for the project directory.
- **File Locks**: Close any open HEC-RAS instances that might lock files.

### 5. Inconsistent Results

- **Geometry Files**: Clear geometry preprocessor files when making changes.
- **Plan Parameters**: Ensure all plan parameters are correctly set before execution.

---

## Conclusion

The RAS-Commander (`ras_commander`) library provides a powerful set of tools for automating HEC-RAS operations. By following the best practices outlined in this guide and leveraging the library's features, you can efficiently manage and execute complex HEC-RAS projects programmatically.

Remember to refer to the latest documentation and the library's source code for up-to-date information. As you become more familiar with `ras_commander`, you'll discover more ways to optimize your HEC-RAS workflows and increase productivity.

For further assistance, bug reports, or feature requests, please refer to the library's [GitHub repository](https://github.com/billk-FM/ras-commander) and issue tracker.

---

**Happy Modeling!**
==================================================

Folder: C:\GH\ras-commander\examples
==================================================

File: C:\GH\ras-commander\LICENSE
==================================================
MIT License

Copyright (c) 2024 William M. Katzenmeyer

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so.

==================================================

File: C:\GH\ras-commander\pyproject.toml
==================================================
[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta:__legacy__"

==================================================

Folder: C:\GH\ras-commander\ras_commander
==================================================

File: C:\GH\ras-commander\README.md
==================================================
# RAS Commander (ras-commander)

RAS Commander is a Python library for automating HEC-RAS operations, providing a set of tools to interact with HEC-RAS project files, execute simulations, and manage project data. This library is an evolution of the RASCommander 1.0 Python Notebook Application previously released under the [HEC-Commander tools repository](https://github.com/billk-FM/HEC-Commander).

## Contributors:
William Katzenmeyer, P.E., C.F.M. 

Sean Micek, P.E., C.F.M. 

Aaron Nichols, P.E., C.F.M. 

(Additional Contributors Here)  

## Don't Ask Me, Ask ChatGPT!

Before you read any further, you can [chat directly with ChatGPT on this topic.](https://chatgpt.com/g/g-TZRPR3oAO-ras-commander-library-assistant)  Ask it anything, and it will use its tools to answer your questions and help you learn.  You can even upload your own plan, unsteady and HDF files to inspect and help determine how to automate your workflows or visualize your results. 

There are also [AI Assistant Knowledge Bases](https://github.com/billk-FM/ras-commander/tree/main/ai_tools/assistant_knowledge_bases) with various versions available to directly use with large context LLM models such as Anthropic's Claude, Google Gemini and OpenAI's GPT4o and o1 models.  

FUTURE:  TEMPLATES are available to use with AI Assistant Notebooks to build your own automation tools.  When used with large context models, these templates allow you to ask GPT to build a workflow from scratch to automate your projects. 

## Background
The ras-commander library emerged from the initial test-bed of AI-driven coding represented by the HEC-Commander tools Python notebooks. These notebooks served as a proof of concept, demonstrating the value proposition of automating HEC-RAS operations. The transition from notebooks to a structured library aims to provide a more robust, maintainable, and extensible solution for water resources engineers.

## Features

- Automate HEC-RAS project management and simulations
- Support for both single and multiple project instances
- Parallel execution of HEC-RAS plans
- Utilities for managing geometry, plan, and unsteady flow files
- Example project management for testing and development
- Two primary operation modes: "Run Missing" and "Build from DSS"

## AI-Driven Coding Experience

ras-commander provides several AI-powered tools to enhance the coding experience:

1. **ChatGPT Assistant: [RAS Commander Library Assistant](https://chatgpt.com/g/g-TZRPR3oAO-ras-commander-library-assistant)**: A specialized GPT model trained on the ras-commander codebase, available for answering queries and providing code suggestions.

2. **[Purpose-Built Knowledge Base Summaries](https://github.com/billk-FM/ras-commander/tree/main/ai_tools/assistant_knowledge_bases)**: Up-to-date compilations of the documentation and codebase for use with large language models like Claude or GPT-4. Look in 'ai_tools/assistant_knowledge_bases/' in the repo.

3. **[Cursor IDE Integration](https://github.com/billk-FM/ras-commander/blob/main/.cursorrules)**: Custom rules for the Cursor IDE to provide context-aware suggestions and documentation.  Just open the repository folder in Cursor.  You can create your own folders "/workspace/, "/projects/", or "my_projects/" as these are already in the .gitignore, and place your custom scripts there for your projects.  This will allow easy referencing of the ras-commander documents and individual repo files, the automatic loading of the .cursorrules file.  Alternatvely, download the github repo into your projects folder to easily load documents and use cursor rules files.  
4. **[AI Assistant Notebook](https://github.com/billk-FM/ras-commander/blob/main/ai_tools/rascommander_code_assistant.ipynb)**: A notebook for dynamic code summarization and API interaction (bring your own API Key).  Currently, this only does a single-shot message on the Claude Sonnet 3.5 API, which can be up to 50 cents per request.  Future revisions will include the ability to select which knowledge base file to include, a choice of SOTA models + multi turn conversations to build automation notebooks interactively.  

These tools aim to streamline development and provide intelligent assistance when modeling with, and working with and revising the ras-commander library.

## Installation

Create a virtual environment with conda or venv (ask ChatGPT if you need help)

In your virtual environment, install ras-commander using pip:
```
pip install h5py numpy pandas requests tqdm scipy
pip install ras-commander
```

If you have dependency issues with pip (especially if you have errors with numpy), try clearing your local pip packages 'C:\Users\your_username\AppData\Roaming\Python\' and then creating a new virtual environment.  
   

## Requirements

- Tested with Python 3.11
- HEC-RAS 6.2 or later (other versions may work, all testing was done with version 6.2 and above)
- Detailed project workflows and/or existing libraries and code where ras-commander can be integrated.

For a full list of dependencies, see the `requirements.txt` file.

## Quick Start
```
from ras_commander import init_ras_project, RasCmdr, RasPlan
```

# Initialize a project
```
init_ras_project(r"/path/to/project", "6.5")
```

# Execute a single plan
```
RasCmdr.compute_plan("01", dest_folder=r"/path/to/results", overwrite_dest=True)
```

# Execute plans in parallel
```
results = RasCmdr.compute_parallel(
    plan_numbers=["01", "02"],
    max_workers=2,
    cores_per_run=2,
    dest_folder=r"/path/to/results",
    overwrite_dest=True
)
```

# Modify a plan
```
RasPlan.set_geom("01", "02")
```

Certainly! I'll provide you with an updated Key Components section and Project Organization diagram based on the current structure of the ras-commander library.

## Key Components

- `RasPrj`: Manages HEC-RAS projects, handling initialization and data loading
- `RasCmdr`: Handles execution of HEC-RAS simulations
- `RasPlan`: Provides functions for modifying and updating plan files
- `RasGeo`: Handles operations related to geometry files
- `RasUnsteady`: Manages unsteady flow file operations
- `RasUtils`: Contains utility functions for file operations and data management
- `RasExamples`: Manages and loads HEC-RAS example projects
- `RasHdf`: Provides utilities for working with HDF files in HEC-RAS projects

## Project Organization Diagram

```
ras_commander
├── .github
│   └── workflows
│       └── python-package.yml
├── ras_commander
│   ├── __init__.py
│   ├── _version.py
│   ├── RasCmdr.py
│   ├── RasExamples.py
│   ├── RasGeo.py
│   ├── RasHdf.py
│   ├── RasPlan.py
│   ├── RasPrj.py
│   ├── RasUnsteady.py
│   └── RasUtils.py
├── examples
│   ├── 01_project_initialization.py
│   ├── 02_plan_operations.py
│   ├── 03_geometry_operations.py
│   ├── 04_unsteady_flow_operations.py
│   ├── 05_utility_functions.py
│   ├── 06_single_plan_execution.py
│   ├── 07_sequential_plan_execution.py
│   ├── 08_parallel_execution.py
│   ├── 09_specifying_plans.py
│   ├── 10_arguments_for_compute.py
│   ├── 11_Using_RasExamples.ipynb
│   ├── 12_plan_set_execution.py
│   ├── 13_multiple_project_operations.py
│   ├── 14_Core_Sensitivity.ipynb
│   ├── 15_plan_key_operations.py
│   ├── 16_scanning_ras_project_info.py
│   ├── 17_parallel_execution_ble.py
│   └── HEC_RAS_2D_HDF_Analysis.ipynb
├── tests
│   └── ... (test files)
├── .gitignore
├── LICENSE
├── README.md
├── STYLE_GUIDE.md
├── Comprehensive_Library_Guide.md
├── pyproject.toml
├── setup.cfg
├── setup.py
└── requirements.txt
```

## Accessing HEC Examples through RasExamples

The `RasExamples` class provides functionality for quickly loading and managing HEC-RAS example projects. This is particularly useful for testing and development purposes.

Key features:
- Download and extract HEC-RAS example projects
- List available project categories and projects
- Extract specific projects for use
- Manage example project data efficiently

Example usage:
from ras_commander import RasExamples

```
ras_examples = RasExamples()
ras_examples.get_example_projects()  # Downloads example projects if not already present
categories = ras_examples.list_categories()
projects = ras_examples.list_projects("Steady Flow")
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
```

## RasPrj

The `RasPrj` class is central to managing HEC-RAS projects within the ras-commander library. It handles project initialization, data loading, and provides access to project components.

Key features:
- Initialize HEC-RAS projects
- Load and manage project data (plans, geometries, flows, etc.)
- Provide easy access to project files and information

Note: While a global `ras` object is available for convenience, you can create multiple `RasPrj` instances to manage several projects simultaneously.

Example usage:
```
from ras_commander import RasPrj, init_ras_project
```

### Using the global ras object
```
init_ras_project("/path/to/project", "6.5")
```

### Creating a custom RasPrj instance
```
custom_project = RasPrj()
init_ras_project("/path/to/another_project", "6.5", ras_instance=custom_project)
```

## RasHdf

The `RasHdf` class provides utilities for working with HDF files in HEC-RAS projects, enabling easy access to simulation results and model data.

Example usage:

```python
from ras_commander import RasHdf, init_ras_project, RasPrj

# Initialize project with a custom ras object
custom_ras = RasPrj()
init_ras_project("/path/to/project", "6.5", ras_instance=custom_ras)

# Get runtime data for a specific plan
plan_number = "01"
runtime_data = RasHdf.get_runtime_data(plan_number, ras_object=custom_ras)
print(runtime_data)
```

This class simplifies the process of extracting and analyzing data from HEC-RAS HDF output files, supporting tasks such as post-processing and result visualization.


## Documentation

For detailed usage instructions and API documentation, please refer to the [Comprehensive Library Guide](Comprehensive_Library_Guide.md).

## Examples

Check out the `examples/` directory for sample scripts demonstrating various features of ras-commander.

## Future Development

The ras-commander library is an ongoing project. Future plans include:
- Integration of more advanced AI-driven features
- Expansion of HMS and DSS functionalities
- Enhanced GPU support for computational tasks
- Community-driven development of new modules and features

## Related Resources

- [HEC-Commander Blog](https://github.com/billk-FM/HEC-Commander/tree/main/Blog)
- [GPT-Commander YouTube Channel](https://www.youtube.com/@GPT_Commander)
- [ChatGPT Examples for Water Resources Engineers](https://github.com/billk-FM/HEC-Commander/tree/main/ChatGPT%20Examples)


## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on how to submit pull requests, report issues, and suggest improvements.

## Style Guide

This project follows a specific style guide to maintain consistency across the codebase. Please refer to the [Style Guide](STYLE_GUIDE.md) for details on coding conventions, documentation standards, and best practices.

## License

ras-commander is released under the MIT License. See the license file for details.

## Acknowledgments

RAS Commander is based on the HEC-Commander project's "Command Line is All You Need" approach, leveraging the HEC-RAS command-line interface for automation. The initial development of this library was presented in the HEC-Commander Tools repository. In a 2024 Australian Water School webinar, Bill demonstrated the derivation of basic HEC-RAS automation functions from plain language instructions. Leveraging the previously developed code and AI tools, the library was created. The primary tools used for this initial development were Anthropic's Claude, GPT-4, Google's Gemini Experimental models, and the Cursor AI Coding IDE.

Additionally, we would like to acknowledge the following notable contributions and attributions for open source projects which significantly influenced the development of RAS Commander:

1. Contributions: Sean Micek's [`funkshuns`](https://github.com/openSourcerer9000/funkshuns), [`TXTure`](https://github.com/openSourcerer9000/TXTure), and [`RASmatazz`](https://github.com/openSourcerer9000/RASmatazz) libraries provided inspiration, code examples and utility functions which were adapted with AI for use in RAS Commander. Sean has also contributed heavily to 

- Development of additional HDF functions for detailed analysis and mapping of HEC-RAS results within the RasHdf class.
- Development of the prototype `RasCmdr` class for executing HEC-RAS simulations.
- Optimization examples and methods from (INSERT REFERENCE) for use in the Ras-Commander library examples

2. Attribution: The [`pyHMT2D`](https://github.com/psu-efd/pyHMT2D/) project by Xiaofeng Liu, which provided insights into HDF file handling methods for HEC-RAS outputs.  Many of the functions in the [Ras_2D_Data.py](https://github.com/psu-efd/pyHMT2D/blob/main/pyHMT2D/Hydraulic_Models_Data/RAS_2D/RAS_2D_Data.py) file were adapted with AI for use in RAS Commander. 

   Xiaofeng Liu, Ph.D., P.E.,    Associate Professor, Department of Civil and Environmental Engineering
   Institute of Computational and Data Sciences, Penn State University

These acknowledgments recognize the contributions and inspirations that have helped shape RAS Commander, ensuring proper attribution for the ideas and code that have influenced its development.

3. Chris Goodell, "Breaking the HEC-RAS Code" - Studied and used as a reference for understanding the inner workings of HEC-RAS, providing valuable insights into the software's functionality and structure.

4. [HEC-Commander Tools](https://github.com/billk-FM/HEC-Commander) - Inspiration and initial code base for the development of RAS Commander.


## Contact

For questions, suggestions, or support, please contact:
William Katzenmeyer, P.E., C.F.M. - billk@fenstermaker.com

==================================================

File: C:\GH\ras-commander\requirements.txt
==================================================
aider-chat @ git+https://github.com/paul-gauthier/aider.git@00d5348ee6295662c78a8ece31d71632145d9746
alabaster==0.7.16
annotated-types==0.6.0
anyio==3.7.1
asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work
attrs==23.1.0
babel==2.16.0
backoff==2.2.1
backports.tarfile==1.2.0
black==24.8.0
boto3==1.35.25
botocore==1.35.25
certifi==2023.11.17
cffi==1.16.0
charset-normalizer==3.3.2
click==8.1.7
colorama==0.4.6
comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work
ConfigArgParse==1.7
contourpy==1.3.0
cycler==0.12.1
debugpy @ file:///D:/bld/debugpy_1725269345345/work
decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work
diff-match-patch==20230430
diskcache==5.6.3
distro==1.8.0
docutils==0.20.1
exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1720869315914/work
executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1725214404607/work
flake8==7.1.1
fonttools==4.53.1
geopandas==1.0.1
gitdb==4.0.11
GitPython==3.1.40
grep-ast==0.2.4
h11==0.14.0
h5py==3.11.0
httpcore==1.0.2
idna==3.6
imagesize==1.4.1
importlib_metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1726082825846/work
iniconfig==2.0.0
ipykernel @ file:///D:/bld/ipykernel_1719845595208/work
ipython @ file:///D:/bld/ipython_1725050320818/work
jaraco.classes==3.4.0
jaraco.context==6.0.1
jaraco.functools==4.1.0
jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work
Jinja2==3.1.4
jmespath==1.0.1
jsonschema==4.20.0
jsonschema-specifications==2023.11.2
jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1726610684920/work
jupyter_core @ file:///D:/bld/jupyter_core_1710257313664/work
keyring==25.4.1
kiwisolver==1.4.7
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib==3.9.2
matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work
mccabe==0.7.0
mdurl==0.1.2
more-itertools==10.5.0
mypy-extensions==1.0.0
nest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work
networkx==3.2.1
nh3==0.2.18
numpy==1.26.2
packaging==23.2
pandas==2.2.3
parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work
pathlib==1.0.1
pathspec==0.11.2
pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work
pillow==10.4.0
pkginfo==1.10.0
platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1726613481435/work
pluggy==1.5.0
prompt-toolkit==3.0.41
psutil @ file:///D:/bld/psutil_1725737996000/work
pure_eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1721585709575/work
pycodestyle==2.12.1
pycparser==2.21
pydantic==2.5.2
pydantic_core==2.14.5
pyflakes==3.2.0
Pygments==2.17.2
pyogrio==0.9.0
pyparsing==3.1.4
pyproj==3.6.1
pytest==8.3.3
python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work
pytz==2024.2
pywin32==306
pywin32-ctypes==0.2.3
PyYAML==6.0.1
pyzmq @ file:///D:/bld/pyzmq_1725449086441/work
readme_renderer==43.0
referencing==0.31.1
regex==2023.10.3
requests==2.32.3
requests-toolbelt==1.0.0
rfc3986==2.0.0
rich==13.7.0
rpds-py==0.13.2
s3transfer==0.10.2
scipy==1.11.4
shapely==2.0.6
six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work
smmap==5.0.1
sniffio==1.3.0
snowballstemmer==2.2.0
sounddevice==0.4.6
soundfile==0.12.1
Sphinx==7.4.7
sphinx-rtd-theme==2.0.0
sphinxcontrib-applehelp==2.0.0
sphinxcontrib-devhelp==2.0.0
sphinxcontrib-htmlhelp==2.1.0
sphinxcontrib-jquery==4.1
sphinxcontrib-jsmath==1.0.1
sphinxcontrib-qthelp==2.0.0
sphinxcontrib-serializinghtml==2.0.0
stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work
tornado @ file:///D:/bld/tornado_1724956185692/work
tqdm==4.66.1
traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1713535121073/work
tree-sitter==0.20.4
tree-sitter-languages==1.8.0
twine==5.1.1
typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1717802530399/work
tzdata==2024.1
urllib3==2.2.3
wcwidth==0.2.12
zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1726248574750/work

==================================================

File: C:\GH\ras-commander\setup.py
==================================================
from setuptools import setup, find_packages
from setuptools.command.build_py import build_py
import subprocess
from pathlib import Path

class CustomBuildPy(build_py):
    def run(self):
        # Run the summary_knowledge_bases.py script
        script_path = Path(__file__).parent / 'ai_tools' / 'summary_knowledge_bases.py'
        subprocess.run(['python', str(script_path)], check=True)
        
        # Continue with the regular build process
        super().run()

setup(
    name="ras-commander",
    version="0.42.0",
    packages=["ras_commander"],
    include_package_data=True,
    python_requires='>=3.10',
    author="William M. Katzenmeyer",
    author_email="billk@fenstermaker.com",
    description="A Python library for automating HEC-RAS operations",
    long_description=open('README.md').read(),
    long_description_content_type="text/markdown",
    url="https://github.com/billk-FM/ras-commander",
    cmdclass={
        'build_py': CustomBuildPy,
    },
)

"""
ras-commander setup.py

This file is used to build and publish the ras-commander package to PyPI.

To build and publish this package, follow these steps:

1. Ensure you have the latest versions of setuptools, wheel, and twine installed:
   pip install --upgrade setuptools wheel twine

2. Update the version number in ras_commander/__init__.py (if not using automatic versioning)

3. Create source distribution and wheel:
   python setup.py sdist bdist_wheel

4. Check the distribution:
   twine check dist/*

5. Upload to Test PyPI (optional):
   twine upload --repository testpypi dist/*

6. Install from Test PyPI to verify (optional):
   pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ras-commander

7. Upload to PyPI:
   twine upload dist/* --username __token__ --password <your_api_key>


8. Install from PyPI to verify:
   pip install ras-commander

Note: Ensure you have the necessary credentials and access rights to upload to PyPI.
For more information, visit: https://packaging.python.org/tutorials/packaging-projects/

"""

==================================================

File: C:\GH\ras-commander\STYLE_GUIDE.md
==================================================
# RAS Commander (ras-commander) Style Guide

## Table of Contents
1. [Naming Conventions](#1-naming-conventions)
2. [Code Structure and Organization](#2-code-structure-and-organization)
3. [Documentation and Comments](#3-documentation-and-comments)
4. [Code Style](#4-code-style)
5. [Error Handling](#5-error-handling)
6. [Testing](#6-testing)
7. [Version Control](#7-version-control)
8. [Type Hinting](#8-type-hinting)
9. [Project-Specific Conventions](#9-project-specific-conventions)
10. [Inheritance](#10-inheritance)
11. [RasUtils Usage](#11-rasutils-usage)
12. [Working with RasExamples](#12-working-with-rasexamples)

## 1. Naming Conventions

### 1.1 General Rules
- Use `snake_case` for all function and variable names
- Use `PascalCase` for class names
- Use `UPPER_CASE` for constants

### 1.2 Library-Specific Naming
- Informal Name: RAS Commander
- Package Name and GitHub Library Name: ras-commander (with a hyphen)
- Import Name: ras_commander (with an underscore)
- Main Class of functions for HEC-RAS Automation: RasCmdr

### 1.3 Function Naming
- Start function names with a verb describing the action
- Use clear, descriptive names
- Common verbs and their uses:
  - `get_`: retrieve data
  - `set_`: set values or properties
  - `compute_`: execute or calculate
  - `clone_`: copy
  - `clear_`: remove or reset data
  - `find_`: search
  - `update_`: modify existing data

### 1.4 Abbreviations
Use the following abbreviations consistently throughout the codebase:

- ras: HEC-RAS
- prj: Project
- geom: Geometry
- pre: Preprocessor
- geompre: Geometry Preprocessor
- num: Number
- init: Initialize
- XS: Cross Section
- DSS: Data Storage System
- GIS: Geographic Information System
- BC: Boundary Condition
- IC: Initial Condition
- TW: Tailwater

Use these abbreviations in lowercase for function and variable names (e.g., `geom`, not `Geom` or `GEOM`).

### 1.5 Class Naming
- Use `PascalCase` for class names (e.g., `FileOperations`, `PlanOperations`, `RasCmdr`)
- Class names should be nouns or noun phrases

### 1.6 Variable Naming
- Use descriptive names indicating purpose or content
- Prefix boolean variables with `is_`, `has_`, or similar

## 2. Code Structure and Organization

### 2.1 File Organization
- Group related functions into appropriate classes
- Keep each class in its own file, named after the class

### 2.2 Function Organization
- Order functions logically within a class
- Place common or important functions at the top of the class

### 2.3 Module Structure
- Use the following order for module contents:
  1. Module-level docstring
  2. Imports (grouped and ordered)
  3. Constants
  4. Classes
  5. Functions

## 3. Documentation and Comments

### 3.1 Docstrings
- Use docstrings for all modules, classes, methods, and functions
- Follow Google Python Style Guide format
- Include parameters, return values, and a brief description
- For complex functions, include examples in the docstring

### 3.2 Comments
- Use inline comments sparingly, only for complex logic
- Keep comments up-to-date with code changes
- Use TODO comments for future work, formatted as: `# TODO: description`

## 4. Code Style

### 4.1 Imports
- Order imports as follows:
  1. Standard library imports
  2. Third-party library imports
  3. Local application imports
- Use absolute imports
- Use `import ras_commander as ras` for shortening the library name in examples

### 4.2 Whitespace
- Follow PEP 8 guidelines
- Use 4 spaces for indentation (no tabs)
- Use blank lines to separate logical sections of code

### 4.3 Line Length
- Limit lines to 79 characters for code, 72 for comments and docstrings
- Use parentheses for line continuation in long expressions

## 5. Error Handling

**Use Logging Instead of Prints**
Ensure that every operation that can fail or needs to provide feedback to the user is logged instead of using `print`. This will help in debugging and improve monitoring during execution.

   ```python
   logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
   ```

   Example of replacing a `print` with logging:
   ```python
   logging.info('Starting HEC-RAS simulation...')
   ```

- Use explicit exception handling with try/except blocks
- Raise custom exceptions when appropriate, with descriptive messages
- Use logging for error reporting and debugging information
- Use specific exception types when raising errors (e.g., `ValueError`, `FileNotFoundError`)
- Provide informative error messages that include relevant details
- Implement proper cleanup in finally blocks when necessary
- For user-facing functions, consider wrapping internal exceptions in custom exceptions specific to ras-commander

Example:
```python
try:
    result = compute_plan(plan_number)
except FileNotFoundError as e:
    raise RasCommanderError(f"Plan file not found: {e}")
except ValueError as e:
    raise RasCommanderError(f"Invalid plan parameter: {e}")
except Exception as e:
    raise RasCommanderError(f"Unexpected error during plan computation: {e}")
```

## 6. Testing

- Write unit tests for all functions and methods
- Use the `unittest` framework
- Aim for high test coverage, especially for critical functionality
- Include tests for both single-project and multi-project scenarios
- Write clear and descriptive test names
- Use setUp and tearDown methods for common test preparations and cleanups
- Use mock objects when appropriate to isolate units under test

## 7. Version Control

- Use meaningful commit messages that clearly describe the changes made
- Create feature branches for new features or significant changes
- Submit pull requests for code review before merging into the main branch
- Keep commits focused and atomic (one logical change per commit)
- Use git tags for marking releases
- Follow semantic versioning for release numbering

## 8. Type Hinting

- Use type hints for all function parameters and return values
- Use the `typing` module for complex types (e.g., `List`, `Dict`, `Optional`)
- Include type hints in function signatures and docstrings
- Use `Union` for parameters that can accept multiple types
- For methods that don't return a value, use `-> None`

Example:
```python
from typing import List, Optional

def process_plans(plan_numbers: List[str], max_workers: Optional[int] = None) -> bool:
    # Function implementation
    return True
```

## 9. Project-Specific Conventions

### 9.1 RAS Instance Handling
- Design functions to accept an optional `ras_object` parameter:
  ```python
  def some_function(param1, param2, ras_object=None):
      ras_obj = ras_object or ras
      ras_obj.check_initialized()
      # Function implementation
  ```

### 9.2 File Path Handling
- Use `pathlib.Path` for file and directory path manipulations
- Convert string paths to Path objects at the beginning of functions

### 9.3 DataFrame Handling
- Use pandas for data manipulation and storage where appropriate
- Prefer method chaining for pandas operations to improve readability

### 9.4 Parallel Execution
- Follow the guidelines in the "Benchmarking is All You Need" blog post for optimal core usage in parallel plan execution

### 9.5 Function Return Values
- Prefer returning meaningful values over modifying global state
- Use tuple returns for multiple values instead of modifying input parameters

## 10. Inheritance

### 10.1 General Principles

- Prioritize composition over inheritance when appropriate
- Design base classes for extension
- Clearly document the public API and subclass API using docstrings

### 10.2 Naming Conventions

- Public API: No leading underscores
- Subclass API: Single leading underscore (e.g., `_prepare_for_execution`)
- Internal attributes and methods: Single leading underscore
- Name mangling (double leading underscores): Use sparingly and document the decision clearly

### 10.3 Template Method Pattern

Consider using the template method pattern in base classes to define a high-level algorithm structure. Subclasses can then override specific steps to customize behavior.

### 10.4 Dataframe Access Control

Use properties to control access and modification of dataframes, providing a controlled interface for subclasses.

## 11. RasUtils Usage

- Use RasUtils for general-purpose utility functions that don't fit into other specific classes
- When adding new utility functions, ensure they are static methods of the RasUtils class
- Keep utility functions focused and single-purpose
- Document utility functions thoroughly, including examples of usage

Example:
```python
class RasUtils:
    @staticmethod
    def create_backup(file_path: Path, backup_suffix: str = "_backup") -> Path:
        """
        Create a backup of the specified file.

        Args:
            file_path (Path): Path to the file to be backed up
            backup_suffix (str): Suffix to append to the backup file name

        Returns:
            Path: Path to the created backup file

        Example:
            >>> backup_path = RasUtils.create_backup(Path("project.prj"))
            >>> print(f"Backup created at: {backup_path}")
        """
        # Function implementation
```

## 12. Working with RasExamples

- Use RasExamples for managing and loading example HEC-RAS projects
- Always check if example projects are already downloaded before attempting to download them again
- Use the `list_categories()` and `list_projects()` methods to explore available examples
- When extracting projects, use meaningful names and keep track of extracted paths
- Clean up extracted projects when they are no longer needed using `clean_projects_directory()`

Example:
```python
ras_examples = RasExamples()
if not ras_examples.is_project_extracted("Bald Eagle Creek"):
    extracted_path = ras_examples.extract_project("Bald Eagle Creek")[0]
    # Use the extracted project
    # ...
    # Clean up when done
    RasUtils.remove_with_retry(extracted_path, is_folder=True)
```

Remember, consistency is key. When in doubt, prioritize readability and clarity in your code. Always consider the maintainability and extensibility of the codebase when making design decisions.


13. Logging

Instructions for setting up a minimal logging decorator and applying it to functions:

1. Create logging_config.py:
```python
import logging
import functools

def setup_logging(level=logging.INFO):
    logging.basicConfig(level=level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def log_call(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        logger = logging.getLogger(func.__module__)
        logger.info(f"Calling {func.__name__}")
        return func(*args, **kwargs)
    return wrapper

setup_logging()
```

2. In each module file (e.g., RasPrj.py, RasPlan.py):
   - Add at the top: `from ras_commander.logging_config import log_call`
   - Remove all existing logging configurations and logger instantiations

3. Apply the decorator to functions:
   - Replace existing logging statements with the `@log_call` decorator
   - Remove any manual logging within the function body

Example changes to functions:

Before:
```python
def compute_plan(plan_number, dest_folder=None, ras_object=None, clear_geompre=False, num_cores=None):
    logging.info(f"Computing plan {plan_number}")
    # ... function logic ...
    logging.info(f"Plan {plan_number} computation complete")
    return result
```

After:
```python
@log_call
def compute_plan(plan_number, dest_folder=None, ras_object=None, clear_geompre=False, num_cores=None):
    # ... function logic ...
    return result
```

Apply this pattern across all functions in the library. This approach will significantly reduce the code footprint while maintaining basic logging functionality.
==================================================

File: C:\GH\ras-commander\.gitignore\.gitignore
==================================================
# Ignore the example_projects folder and all its subfolders
examples/example_projects/

# Ignore workspace, projects, and my_projects folders
workspace/
projects/
my_projects/

# Ignore FEMA BLE Models
examples/FEMA_BLE_Models/
examples/hdf_example_data/

# Ignore Python egg info
*.egg-info/
.eggs/

# Ignore the Example_Projects_6_5.zip file
Example_Projects_6_5.zip

# Ignore the misc folder and all its subfolders
misc/

# Ignore Python cache files
__pycache__/
*.py[cod]

# Ignore compiled Python files
*.so

# Ignore distribution / packaging
dist/
build/

# Ignore test cache
.pytest_cache/

# Ignore virtual environments
.venv/
venv/

# Ignore IDE-specific files (optional, uncomment if needed)
# .vscode/
# .idea/

# Ignore OS-specific files
.DS_Store
Thumbs.db
==================================================

File: C:\GH\ras-commander\examples\01_project_initialization.py
==================================================
# 01_project_initialization.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example demonstrates both the default global 'ras' object and custom ras objects.
# 2. The global 'ras' object is suitable for simple scripts working with a single project.
# 3. Custom ras objects are recommended for complex scripts or when working with multiple projects.
# 4. The init_ras_project function initializes a project and sets up the ras object.
# 5. Each ras object contains comprehensive information about its project, including plan, geometry, flow files, and boundary conditions.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Use descriptive names for custom ras objects to clearly identify different projects.

def print_ras_object_data(ras_obj, project_name):
    print(f"\n{project_name} Project Data:")
    print("=" * 50)
    print(f"Project Name: {ras_obj.get_project_name()}")
    print(f"Project Folder: {ras_obj.project_folder}")
    print(f"PRJ File: {ras_obj.prj_file}")
    print(f"HEC-RAS Executable Path: {ras_obj.ras_exe_path}")
    
    print("\nPlan Files DataFrame:")
    print(ras_obj.plan_df)
    
    print("\nFlow Files DataFrame:")
    print(ras_obj.flow_df)
    
    print("\nUnsteady Flow Files DataFrame:")
    print(ras_obj.unsteady_df)
    
    print("\nGeometry Files DataFrame:")
    print(ras_obj.geom_df)
    
    print("\nHDF Entries DataFrame:")
    print(ras_obj.get_hdf_entries())
    
    print("\nBoundary Conditions DataFrame:")
    print(ras_obj.get_boundary_conditions())
    
    print("\nMeteorological Data:")
    for attr in ['precipitation_mode', 'wind_mode', 'precipitation_metadata', 'evapotranspiration_metadata']:
        if hasattr(ras_obj, attr):
            print(f"{attr.capitalize().replace('_', ' ')}: {getattr(ras_obj, attr)}")
        else:
            print(f"{attr.capitalize().replace('_', ' ')}: Not available")

def main():
    # Get the current script's directory
    current_dir = Path(__file__).parent
    
    # Define paths to example projects
    bald_eagle_path = current_dir.parent / "examples" / "example_projects" / "Balde Eagle Creek"
    multi_2d_path = current_dir.parent / "examples" / "example_projects" / "BaldEagleCrkMulti2D"
    muncie_path = current_dir.parent / "examples" / "example_projects" / "Muncie"

    print("Example Set 1: Using the default global 'ras' object")
    print("-----------------------------------------------------")

    # Initialize using the global RAS instance
    print("Step 1: Initializing with global RAS instance")
    init_ras_project(bald_eagle_path, "6.5") # This will set the global 'ras' object
    print_ras_object_data(ras, "Global RAS Instance (Bald Eagle Creek)")

    print("\nExample Set 2: Using custom ras objects")
    print("-----------------------------------------------------")

    # Initialize multiple project instances
    print("Step 1: Initializing multiple project instances")
    multi_2d_project = init_ras_project(multi_2d_path, "6.5")
    muncie_project = init_ras_project(muncie_path, "6.5")

    print_ras_object_data(multi_2d_project, "Multi2D Project")
    print_ras_object_data(muncie_project, "Muncie Project")

    print("\nExample of simplified import (not recommended for complex scripts)")
    print("-----------------------------------------------------")
    print("from ras_commander import *")
    print("# This allows you to use all functions and classes without prefixes")
    print("# For example: compute_plan() instead of RasCmdr.compute_plan()")
    print("# Note: This approach can lead to naming conflicts and is generally not recommended for larger scripts")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\02_plan_operations.py
==================================================
# 02_plan_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on plans, geometries, and unsteady flows using the functions within the RasPlan Class.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Geometry Cloning: Clone a geometry associated with the original plan, generating a new geometry entry.
4. Unsteady Flow Cloning: Clone an unsteady flow, creating a new unsteady flow entry.
5. Plan Configuration:
   a. Set the cloned geometry for the new plan.
   b. Set the cloned unsteady flow for the new plan.
   c. Update the number of cores to be used for the new plan.
   d. Configure geometry preprocessor options for the new plan.
6. Plan Computation: Compute the new plan and verify successful execution.
7. Results Verification: Check the HDF entries to confirm that results were written.

Additional operations that could be demonstrated:
8. Plan Modification: Update specific parameters in the plan file (e.g., simulation time, output intervals).
9. Geometry Editing: Modify cross-sections, manning's n values, or other geometry data.
10. Unsteady Flow Modification: Adjust boundary conditions or initial conditions.
11. Batch Operations: Perform operations on multiple plans simultaneously.
12. Error Handling: Demonstrate how to handle and report errors during plan operations.
13. Results Analysis: Extract and analyze key output values from the computed plan.
"""

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()
    
    # Step 2: Clone a geometry
    print("Step 2: Cloning a geometry")
    new_geo_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geo_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()
    
    # Step 3: Clone an unsteady flow
    print("Step 3: Cloning an unsteady flow")
    new_unsteady_number = RasPlan.clone_unsteady("02")
    print(f"New unsteady flow created: {new_unsteady_number}")
    print("Updated unsteady flow files:")
    print(ras.unsteady_df)
    print()

    # Step 4: Set geometry for the cloned plan
    print("Step 4: Setting geometry for a plan")
    RasPlan.set_geom(new_plan_number, new_geo_number)
    plan_path = RasPlan.get_plan_path(new_plan_number)
    print(f"Updated geometry for plan {new_plan_number}")
    print(f"Plan file path: {plan_path}")
    print()

    # Step 5: Set unsteady flow for the cloned plan
    print("Step 5: Setting unsteady flow for a plan")
    RasPlan.set_unsteady(new_plan_number, new_unsteady_number)
    print(f"Updated unsteady flow for plan {new_plan_number}")
    print()

    # Step 6: Set the number of cores for the cloned plan
    print("Step 6: Setting the number of cores for a plan")
    RasPlan.set_num_cores(new_plan_number, 2)
    print(f"Updated number of cores for plan {new_plan_number}")
    print()

    # Step 7: Set geometry preprocessor options for the cloned plan
    print("Step 7: Setting geometry preprocessor options")
    RasPlan.set_geom_preprocessor(plan_path, run_htab=-1, use_ib_tables=-1)
    print(f"Updated geometry preprocessor options for plan {new_plan_number}")
    
    # Step 8: Compute the cloned plan
    print("Step 8: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
    print()
    
    # Step 9: Get the HDF entries for the cloned plan to prove that the results were written
    print("Step 9: Retrieving HDF entries for the cloned plan")
    # Refresh the plan entries to ensure we have the latest data
    ras.plan_df = ras.get_plan_entries()
    hdf_entries = ras.get_hdf_entries()
    if not hdf_entries.empty:
        print("HDF entries for the cloned plan:")
        print(hdf_entries)
    else:
        print("No HDF entries found. This could mean the plan hasn't been computed successfully or the results haven't been written yet.")
    
    # Display the plan entries to see if the HDF path is populated
    print("\nCurrent plan entries:")
    print(ras.plan_df)
    
if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\03_geometry_operations.py
==================================================
# 03_geometry_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasGeo class provides methods for working with geometry files and preprocessor operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Always clear geometry preprocessor files before making significant changes to ensure clean results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Muncie"
    init_ras_project(project_path, "6.6")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()

    # Step 2: Clone a geometry file and assign it to the cloned plan
    print("Step 2: Cloning a geometry file and assigning it to the cloned plan")
    new_geom_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geom_number}")
    print(f"Now set the new geometry to the new plan")
    RasPlan.set_geom(new_plan_number, new_geom_number)
    print(f"New geometry {new_geom_number} assigned to plan {new_plan_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()

    # Step 3: Clear geometry preprocessor files for the cloned plan
    print("Step 3: Clearing geometry preprocessor files for the cloned plan")
    plan_path = RasPlan.get_plan_path(new_plan_number)
    RasGeo.clear_geompre_files(plan_path)
    print(f"Cleared geometry preprocessor files for plan {new_plan_number}")
    print()

    # Step 4: Clear geometry preprocessor files for all plans
    print("Step 4: Clearing geometry preprocessor files for all plans")
    RasGeo.clear_geompre_files()
    print("Cleared geometry preprocessor files for all plans")
    print()

    # Step 5: Print the updated plan information
    print("Step 5: Updated plan information")
    plan_df = ras.get_plan_entries()
    print(plan_df)
    print()

    # Step 6: Compute the cloned plan with new geometry and core count
    print("Step 6: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
        
    # Step 7: Get and print results paths
    print("\nStep 7: Getting results paths")
    for plan_number in [new_plan_number, "01"]:  # Check both the new plan and the original plan
        results_path = RasPlan.get_results_path(plan_number)
        if results_path:
            print(f"Results for plan {plan_number} are located at: {results_path}")
        else:
            print(f"No results found for plan {plan_number}")
        

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\04_unsteady_flow_operations.py
==================================================
# 04_unsteady_flow_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on unsteady flow plans using the ras-commander library.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Unsteady Flow Parameter Updates: Modify various unsteady flow parameters in the new plan.
4. Plan Computation: Compute the new plan and verify successful execution.

Note: This example uses the default global 'ras' object for simplicity. For complex scripts or when working with
multiple projects, it's recommended to create and use separate ras objects.
"""

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()

    # Step 2: Get the plan file path
    plan_path = RasPlan.get_plan_path(new_plan_number)

    # Step 3: Update unsteady flow parameters individually
    print("Step 3: Updating unsteady flow parameters individually")
    RasUnsteady.update_unsteady_parameters(plan_path, {"Simulation Date": "01JAN2023,0000,05JAN2023,2400"})
    RasUnsteady.update_unsteady_parameters(plan_path, {"Computation Interval": "1MIN"})
    RasUnsteady.update_unsteady_parameters(plan_path, {"Output Interval": "15MIN"})
    print("Updated parameters individually")
    print()

    # Step 4: Update unsteady flow parameters in batch
    print("Step 4: Updating unsteady flow parameters in batch")
    batch_modifications = {
        "Mapping Interval": "30MIN",
        "Hydrograph Output Interval": "1HOUR",
        "Detailed Output Interval": "1HOUR"
    }
    RasUnsteady.update_unsteady_parameters(plan_path, batch_modifications)
    print("Updated parameters in batch")
    print()

    # Step 5: Verify changes
    print("Step 5: Verifying changes")
    with open(plan_path, 'r') as f:
        content = f.read()
        for param in ["Simulation Date", "Computation Interval", "Output Interval", 
                      "Mapping Interval", "Hydrograph Output Interval", "Detailed Output Interval"]:
            for line in content.split('\n'):
                if line.startswith(param):
                    print(f"Updated {line}")
                    break
    print()

    # Step 6: Compute the updated plan
    print("Step 6: Computing the updated plan")
    success = RasCmdr.compute_plan(new_plan_number)
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\05_utility_functions.py
==================================================
# 05_utility_functions.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasUtils class provides various utility functions for working with HEC-RAS projects.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")
    plan_number = "01"

    # Example 1: Get plan path using RasUtils
    print("Example 1: Getting plan path")
    plan_path = RasUtils.get_plan_path(plan_number)
    print(f"Path for plan {plan_number} is: {plan_path}")
    
    # Example 2: Get geometry path using RasPlan
    print("\nExample 2: Getting geometry path")
    geom_number = "01"
    geom_path = RasPlan.get_geom_path(geom_number)
    print(f"Path for geometry {geom_number} is: {geom_path}")
    
    # Example 3: Get unsteady flow path using RasPlan
    print("\nExample 3: Getting unsteady flow path")
    unsteady_number = "01"
    unsteady_path = RasPlan.get_unsteady_path(unsteady_number)
    print(f"Path for unsteady flow {unsteady_number} is: {unsteady_path}")
    
    # Example 4: Get project name
    print("\nExample 4: Getting project name")
    project_name = ras.get_project_name()
    print(f"Project name: {project_name}")


if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\06_single_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Define the "example_projects" folder in the same directory as the script
examples_path = Path(__file__).parent / "example_projects"

# Delete the project if it exists
if examples_path.exists():
    import shutil
    shutil.rmtree(examples_path)

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan
    print("Example 1: Executing a single plan")
    plan_number = "01"
    success = RasCmdr.compute_plan(plan_number)
    if success:
        print(f"Plan {plan_number} executed successfully")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 2: Execute a plan in a separate destination folder
    print("Example 2: Executing a plan in a separate destination folder")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder)
    if success:
        print(f"Plan {plan_number} executed successfully in {dest_folder}")
    else:
        print(f"Plan {plan_number} execution failed in {dest_folder}")
    print()

    # Example 3: Get and print results path
    print("Example 3: Getting results path")
    results_path = RasPlan.get_results_path(plan_number)
    if results_path:
        print(f"Results for plan {plan_number} are located at: {results_path}")
    else:
        print(f"No results found for plan {plan_number}")
    print()    

    # Example 4: Execute a plan with cleared geometry preprocessor files
    print("Example 4: Executing a plan with cleared geometry preprocessor files")
    plan_number = "03"
    dest_folder = project_path.parent / "compute_test_3"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, clear_geompre=True)
    if success:
        print(f"Plan {plan_number} executed successfully with cleared geometry preprocessor files")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 5: Execute a plan with a specified number of cores, overwriting compute_test_3
    print("Example 5: Executing a plan with a specified number of cores, overwriting compute_test_3")
    plan_number = "01"
    num_cores = 2  # Specify the number of cores to use
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=num_cores, overwrite_dest=True)
    if success:
        print(f"Plan {plan_number} executed successfully using {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 6: Execute a plan with all new options combined
    print("Example 6: Executing a plan with all new options combined")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_all_options"
    num_cores = 4
    
    success = RasCmdr.compute_plan(
        plan_number,
        dest_folder=dest_folder,
        clear_geompre=True,
        num_cores=num_cores
    )
    if success:
        print(f"Plan {plan_number} executed successfully with all options:")
        print(f"- Destination folder: {dest_folder}")
        print(f"- Cleared geometry preprocessor files")
        print(f"- Used {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\07_sequential_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path
# Define the keys to search for in folder names
# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of all plans with overwrite_dest
    print("Example 1: Sequential execution of all plans with overwrite_dest")
    RasCmdr.compute_test_mode(
        dest_folder_suffix="[AllSequential]",
        overwrite_dest=True
    )
    print("Sequential execution of all plans completed with overwrite_dest")
    print()
    
    # Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest
    print("Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest")
    RasCmdr.compute_test_mode(
        plan_number=["01", "02"],
        dest_folder_suffix="[SpecificSequentialClearGeompre]",
        clear_geompre=True,
        overwrite_dest=True
    )
    print("Sequential execution of specific plans completed with clearing geompre files and overwrite_dest")
    print()

    # Example 3: Demonstrate clearing geompre files for specific plans
    print("Example 3: Clearing geompre files for specific plans")
    plan_files = [RasPlan.get_plan_path("01"), RasPlan.get_plan_path("02")]
    RasGeo.clear_geompre_files(plan_files)
    print("Geometry preprocessor files cleared for specific plans")
    print()

    # Example 4: Demonstrate clearing all geompre files
    print("Example 4: Clearing all geompre files")
    RasGeo.clear_geompre_files()
    print("All geometry preprocessor files cleared")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\08_parallel_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Initialize the project using a new RasPrj object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    source_project = init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(source_project.plan_df)
    print()

    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel"
    results_all = RasCmdr.compute_parallel(
        max_workers=3,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.6")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()

    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores)
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.6")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\09_specifying_plans.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path

# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides methods for executing plans in various ways.
# 5. You can specify individual plans or lists of plans for batch operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. When specifying plans, use plan numbers as strings (e.g., "01", "02") for consistency.
# 5. Always check the available plans in the project before specifying plan numbers for execution.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of specific plans
    print("Example 1: Sequential execution of specific plans (1 and 3)")
    RasCmdr.compute_test_mode(plan_number=["01", "03"], dest_folder_suffix="[SpecificSequential]", num_cores=6)
    print("Sequential execution of specific plans completed")
    print()

    # Example 2: Parallel execution of specific plans
    print("Example 2: Parallel execution of specific plans")
    results_specific = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute all plans
    print("Example 3: Execute all plans")
    all_plan_numbers = ras.plan_df['plan_number'].tolist()
    RasCmdr.compute_test_mode(plan_number=all_plan_numbers, dest_folder_suffix="[AllPlans]")
    print("Execution of all plans completed")
    print()

if __name__ == "__main__":
    main()

==================================================

File: C:\GH\ras-commander\examples\10_arguments_for_compute.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides various arguments for fine-tuning plan computation:
#    - plan_number: String representing the plan number to compute (e.g., "01")
#    - dest_folder: Path object specifying the destination folder for computation results
#    - clear_geompre: Boolean to clear geometry preprocessor files before computation
#    - num_cores: Integer specifying the number of cores to use
#    - overwrite_dest: Boolean to determine if existing destination folders should be overwritten

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Utilize the various arguments in compute functions to customize plan execution.
# 5. Always consider your system's capabilities when setting num_cores.
# 6. Use clear_geompre=True when you want to ensure a clean computation environment.
# 7. Specify dest_folder to keep your project folder organized and prevent overwriting previous results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution (compute_test_mode) with various arguments
    print("Example 1: Sequential execution with various arguments")
    for plan_number in ["01", "02"]:
        # Put dest_folder in the parent directory of the project folder (placing it horizontally with the project folder)
        # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory. 
        # So instead of building the full folder name or path, we only define the suffix. 
        dest_folder_suffix = f"_{plan_number}_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number=plan_number,
            dest_folder_suffix=dest_folder_suffix,  # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=True
        )
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print("Sequential execution completed")
    print()
    
    # This variation will fail, as the folder already exists and overwrite_dest is False.  
    # Be sure to think step by step about folder management in your multi-folder automation workflows:
    # Also, try to run the same thing with compute_parallel, but with overwrite_dest=False
    # Since we just created these folders, they are not empty, so this should generate an error message on the terminal
    # Put in Try-Except block:
    try:
        dest_folder = project_path.parent / f"{ras.project_name}_compute_test_01_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number="01",
            dest_folder_suffix=dest_folder_suffix,
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=False
        )
    except ValueError as e:
        print(f"If the example operates successfully (it is meant to generate an error above), you will not see this message.")

    # Example 2: Parallel execution (compute_parallel) with various arguments
    print("Example 2: Parallel execution with various arguments")
    results = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2,
        dest_folder=project_path.parent / "parallel_results",
        clear_geompre=True
    )
    print("Parallel execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Single plan execution (compute_plan) with specific arguments
    print("Example 3: Single plan execution with specific arguments")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=2, clear_geompre=True, overwrite_dest=True)
    print(f"Single plan execution: {'Successful' if success else 'Failed'}")

if __name__ == "__main__":
    main()

==================================================

File: C:\GH\ras-commander\examples\12_plan_set_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

import pandas as pd


def create_plan_set(base_plan, base_geom, num_copies):
    plan_set = []
    for i in range(num_copies):
        new_plan = RasPlan.clone_plan(base_plan)
        new_geom = RasPlan.clone_geom(base_geom)
        RasPlan.set_geom(new_plan, new_geom)
        plan_set.append({
            'plan_number': new_plan,
            'geom_number': new_geom
        })
    return pd.DataFrame(plan_set)

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.6")

    print("Available plans:")
    print(ras.plan_df)
    print("\nAvailable geometries:")
    print(ras.geom_df)
    print()

    # Create a plan set
    base_plan = "01"
    base_geom = "01"
    num_copies = 5
    plan_set = create_plan_set(base_plan, base_geom, num_copies)
    
    print("Created plan set:")
    print(plan_set)
    print()

    # Placeholder for user to insert code that makes programmatic changes to the model
    # For example:
    # for index, row in plan_set.iterrows():
    #     plan_path = RasPlan.get_plan_path(row['plan_number'])
    #     geom_path = RasPlan.get_geom_path(row['geom_number'])
    #     # Make changes to the plan or geometry file here
    #     # For example, you could modify Manning's n values, cross-section data, etc.

    # Execute the plan set in parallel
    print("Executing plan set in parallel")
    results = RasCmdr.compute_parallel(
        plan_number=plan_set['plan_number'].tolist(),
        max_workers=3,
        num_cores=2
    )

    # Add execution results to the plan_set DataFrame
    plan_set['execution_success'] = plan_set['plan_number'].map(results)

    print("\nPlan set execution results:")
    print(plan_set)

    # Here you could add code to analyze the results, such as:
    # - Extracting key output values from each simulation
    # - Comparing results across different plans
    # - Creating visualizations of the results

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\13_multiple_project_operations.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "Muncie"])

#### --- START OF SCRIPT --- ####

def execute_plan(plan_number, ras_object, compute_folder):
    # Set the number of cores to 2 before executing the plan
    RasPlan.set_num_cores(plan_number, 2, ras_object=ras_object)
    
    # Execute the plan in the compute folder
    success = RasCmdr.compute_plan(plan_number, ras_object=ras_object, dest_folder=compute_folder)
    
    return plan_number, success

def main():
    # Initialize two projects
    current_dir = Path(__file__).parent
    bald_eagle_path = current_dir / "example_projects" / "Balde Eagle Creek"
    muncie_path = current_dir / "example_projects" / "Muncie"
    
    bald_eagle = init_ras_project(bald_eagle_path, "6.6")
    muncie = init_ras_project(muncie_path, "6.6")

    print("Available plans in Bald Eagle Creek project:")
    print(bald_eagle.plan_df)
    print("\nAvailable plans in Muncie project:")
    print(muncie.plan_df)
    print()

    # Example 1: Clone plans with custom short identifiers
    print("Example 1: Cloning plans with custom short identifiers")
    new_bald_eagle_plan = RasPlan.clone_plan("01", new_plan_shortid="BECustom", ras_object=bald_eagle)
    new_muncie_plan = RasPlan.clone_plan("01", new_plan_shortid="MunCustom", ras_object=muncie)
    print(f"Created new plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Created new plan {new_muncie_plan} in Muncie project")
    print()

    # Example 2: Set geometry for the new plans
    print("Example 2: Setting geometry for the new plans")
    RasPlan.set_geom(new_bald_eagle_plan, "01", ras_object=bald_eagle)
    RasPlan.set_geom(new_muncie_plan, "01", ras_object=muncie)
    print(f"Set geometry for plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Set geometry for plan {new_muncie_plan} in Muncie project")
    print()

    # Example 3: Update unsteady flow parameters for both projects
    print("Example 3: Updating unsteady flow parameters")
    bald_eagle_plan_file = RasPlan.get_plan_path(new_bald_eagle_plan, ras_object=bald_eagle)
    muncie_plan_file = RasPlan.get_plan_path(new_muncie_plan, ras_object=muncie)

    modifications = {
        "Computation Interval": "2MIN",
        "Output Interval": "30MIN",
        "Mapping Interval": "1HOUR"
    }

    RasUnsteady.update_unsteady_parameters(bald_eagle_plan_file, modifications, ras_object=bald_eagle)
    RasUnsteady.update_unsteady_parameters(muncie_plan_file, modifications, ras_object=muncie)
    print("Updated unsteady flow parameters for both projects")
    print()

    # Example 4: Execute plans for both projects simultaneously in separate compute folders
    print("Example 4: Executing plans for both projects simultaneously in separate compute folders")
    
    # Create compute folders
    bald_eagle_compute_folder = bald_eagle_path.parent / "compute_bald_eagle"
    muncie_compute_folder = muncie_path.parent / "compute_muncie"
    
    # Remove existing compute folders if they exist
    for folder in [bald_eagle_compute_folder, muncie_compute_folder]:
        if folder.exists():
            shutil.rmtree(folder)
        folder.mkdir(parents=True, exist_ok=True)
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(execute_plan, new_bald_eagle_plan, bald_eagle, bald_eagle_compute_folder),
            executor.submit(execute_plan, new_muncie_plan, muncie, muncie_compute_folder)
        ]
        
        results = {}
        for future in futures:
            plan_number, success = future.result()
            results[plan_number] = success

    print("Execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print()

    # Example 5: Get and print results paths
    print("Example 5: Getting results paths")
    bald_eagle_results = RasPlan.get_results_path(new_bald_eagle_plan, ras_object=bald_eagle)
    muncie_results = RasPlan.get_results_path(new_muncie_plan, ras_object=muncie)

    if bald_eagle_results:
        print(f"Results for Bald Eagle Creek plan {new_bald_eagle_plan} are located at: {bald_eagle_results}")
    else:
        print(f"No results found for Bald Eagle Creek plan {new_bald_eagle_plan}")

    if muncie_results:
        print(f"Results for Muncie plan {new_muncie_plan} are located at: {muncie_results}")
    else:
        print(f"No results found for Muncie plan {new_muncie_plan}")

    print("\nNote: The original project folders can now be edited while the compute operations are running in separate folders.")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\14_Core_Sensitivity.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ras-commander pandas requests pathlib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14_Core_Sensitivity.ipynb\n",
    "Testing Core Sensitivity for RAS using the Bald Eagle Creek Multi-Gage 2D project.  \n",
    "\n",
    "\n",
    "This should take around 15-45 minutes to run depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "\n",
    "print(\"ras_commander imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, RasGeo\n",
    "\n",
    "# Step 1: Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
    "\n",
    "# Use Path.cwd() to get the current working directory in a Jupyter Notebook\n",
    "current_directory = Path.cwd()\n",
    "project_path = current_directory / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
    "\n",
    "# Step 2: Initialize the Muncie Project using init_ras_project (from ras_commander)\n",
    "muncie_project = init_ras_project(project_path, \"6.6\")\n",
    "\n",
    "# Step 3: Initialize a DataFrame to store execution results\n",
    "results = []\n",
    "\n",
    "# Step 4: Run sensitivity analysis for Plan 03 with core counts 1-8\n",
    "plan_number = '03'\n",
    "print(f\"Running sensitivity analysis for Plan {plan_number}\")\n",
    "\n",
    "# Clear geompre files before running the plan\n",
    "plan_path = RasPlan.get_plan_path(plan_number)\n",
    "RasGeo.clear_geompre_files(plan_path)\n",
    "\n",
    "for cores in range(1, 9):\n",
    "    print(f\"Running with {cores} core(s)\")\n",
    "    # Set core count for this plan\n",
    "    RasPlan.set_num_cores(plan_number, cores)\n",
    "    \n",
    "    # Time the execution of the plan\n",
    "    start_time = time.time()\n",
    "    RasCmdr.compute_plan(plan_number)\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"plan_number\": plan_number,\n",
    "        \"cores\": cores,\n",
    "        \"execution_time\": execution_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "print(\"Sensitivity analysis complete\")\n",
    "\n",
    "# Step 5: Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv(\"core_sensitivity_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FOR REVISIONS:\n",
    "- Use HDF compute summary to show the time for each preproces/unsteady compute/postprocess step. \n",
    "- First, run preprocessor and then toggle options to only run unsteady compute and postprocess. \n",
    "- Plot each step separately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, load the results from a CSV file\n",
    "results_df = pd.read_csv(\"core_sensitivity_results.csv\")\n",
    "\n",
    "# Display the results dataframe for verification\n",
    "print(\"results_df DataFrame:\")\n",
    "display(results_df)\n",
    "\n",
    "# Step 6: Calculate unit runtime (based on 1 core execution time)\n",
    "results_df['unit_runtime'] = results_df.groupby('plan_number')['execution_time'].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "# Get the project name from the ras object\n",
    "project_name = ras.project_name\n",
    "\n",
    "# Step 7: Plot a line chart for unit runtime vs. cores for each plan\n",
    "plt.figure(figsize=(10, 6))\n",
    "for plan in results_df['plan_number'].unique():\n",
    "    plan_data = results_df[results_df['plan_number'] == plan]\n",
    "    plt.plot(plan_data['cores'], plan_data['unit_runtime'], label=f\"Plan {plan}\")\n",
    "\n",
    "plt.xlabel(\"Number of Cores\")\n",
    "plt.ylabel(\"Unit Runtime (Relative to 1 Core)\")\n",
    "plt.title(f\"{project_name} (HEC Example Project)\\nCore Count Sensitivity Analysis\")\n",
    "plt.legend(title=\"Plan Number\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "summary_stats = results_df.groupby('cores')['execution_time'].agg(['mean', 'min', 'max'])\n",
    "display(summary_stats)\n",
    "\n",
    "# Calculate and print speedup\n",
    "speedup = results_df[results_df['cores'] == 1]['execution_time'].mean() / results_df[results_df['cores'] == 8]['execution_time'].mean()\n",
    "print(f\"\\nAverage speedup from 1 to 8 cores: {speedup:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "releasecmdr311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: C:\GH\ras-commander\examples\15_plan_key_operations.py
==================================================
# 15_plan_key_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    ras_obj = init_ras_project(project_path, "6.6")

    print("Example 15: Getting and Setting Plan Keys")
    print("------------------------------------------")

    # Get the first plan number
    plan_number = ras_obj.plan_df['plan_number'].iloc[0]
    print(f"Working with Plan: {plan_number}")

    # 1. Get and print multiple plan values
    keys_to_check = ['Computation Interval', 'Simulation Date', 'Short Identifier', 'UNET D1 Cores']
    print("\n1. Current Plan Values:")
    for key in keys_to_check:
        value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {value}")

    # 2. Update plan values
    print("\n2. Updating Plan Values:")
    updates = {
        'Computation Interval': '30SEC',
        'Short Identifier': 'Updated_Plan',
        'UNET D1 Cores': '4'
    }
    for key, value in updates.items():
        RasPlan.update_plan_value(plan_number, key, value, ras_object=ras_obj)
        print(f"  Updated {key} to: {value}")

    # 3. Verify updates
    print("\n3. Verifying Updates:")
    for key in updates.keys():
        new_value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {new_value}")

    # 4. Get description
    print("\n4. Plan Description:")
    current_description = RasPlan.get_plan_value(plan_number, 'Description', ras_object=ras_obj)
    print(f"  Current description: {current_description}")
    # Updating descriptions is a multi-line operation that will need additional logic in update_plan_value

    # 5. Attempt to get and set an invalid key
    print("\n5. Handling Invalid Keys:")
    RasPlan.get_plan_value(plan_number, 'Invalid Key', ras_object=ras_obj)

    RasPlan.update_plan_value(plan_number, 'Invalid Key', 'some_value', ras_object=ras_obj)

    print("\nExample 15 completed.")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\16_scanning_ras_project_info.py
==================================================
import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    from ras_commander import init_ras_project, RasPrj, RasExamples
except ImportError:
    sys.path.append(str(parent_directory))
    from ras_commander import init_ras_project, RasPrj, RasExamples

import logging

def generate_category_summary(category_path):
    summary = []
    summary.append(f"RAS-Commander Example Projects Summary for Category: {category_path.name}\n")
    summary.append("=" * 80 + "\n\n")

    for project_path in category_path.iterdir():
        if project_path.is_dir():
            summary.append(f"Project Folder: {project_path.name}")
            summary.append(f"Full Path: {project_path.resolve()}\n")

            try:
                ras_project = init_ras_project(project_path, "6.6", ras_instance=RasPrj())
                
                summary.append(f"Project Name: {ras_project.get_project_name()}")
                summary.append(f"PRJ File: {ras_project.prj_file}")
                summary.append(f"RAS Executable: {ras_project.ras_exe_path}\n")

                summary.append("Plan Files:")
                summary.append(ras_project.plan_df.to_string())
                summary.append("\n")

                summary.append("Flow Files:")
                summary.append(ras_project.flow_df.to_string())
                summary.append("\n")

                summary.append("Geometry Files:")
                summary.append(ras_project.geom_df.to_string())
                summary.append("\n")

                summary.append("Unsteady Flow Files:")
                summary.append(ras_project.unsteady_df.to_string())
                summary.append("\n")

                summary.append("Boundary Conditions:")
                summary.append(ras_project.boundaries_df.to_string())
                summary.append("\n")

                # Add unparsed lines for each boundary condition
                summary.append("Unparsed Boundary Condition Lines:")
                for _, row in ras_project.boundaries_df.iterrows():
                    bc_number = row['boundary_condition_number']
                    unsteady_number = row['unsteady_number']
                    unparsed_lines = ras_project._parse_boundary_condition(
                        ras_project._get_boundary_condition_block(unsteady_number, bc_number),
                        unsteady_number,
                        bc_number
                    )[1]
                    if unparsed_lines:
                        summary.append(f"BC {bc_number} in Unsteady File {unsteady_number}:")
                        summary.append(unparsed_lines)
                        summary.append("\n")
                summary.append("\n")

            except Exception as e:
                summary.append(f"Error initializing RAS project: {str(e)}\n")

            summary.append("-" * 80 + "\n\n")

    return "\n".join(summary)

def main():
    # Set logging level to DEBUG to capture unparsed lines
    logging.getLogger().setLevel(logging.DEBUG)

    ras_examples = RasExamples()
    selected_categories = ["1D Unsteady Flow Hydraulics", "2D Unsteady Flow Hydraulics"]

    base_dir = Path.cwd() / "ras_example_categories"
    base_dir.mkdir(exist_ok=True)

    for category in selected_categories:
        category_dir = base_dir / category
        category_dir.mkdir(exist_ok=True)

        projects = ras_examples.list_projects(category)
        extracted_paths = ras_examples.extract_project(projects)

        # Move extracted projects to the category directory
        for path in extracted_paths:
            new_path = category_dir / path.name
            path.rename(new_path)

        # Generate and save summary for this category
        summary_text = generate_category_summary(category_dir)
        output_file = base_dir / f"ras-commander {category} summary.txt"
        with open(output_file, "w") as f:
            f.write(summary_text)

        print(f"Summary for category '{category}' has been written to: {output_file}")

    print("All category summaries have been generated.")

    # Clean up extracted projects
    ras_examples.clean_projects_directory()
    print("Cleaned up original extracted example projects.")

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\examples\17_parallel_execution_ble.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math
import logging

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

# Initialize RasExamples
ras_examples = RasExamples()

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

##  WHISKY CHITTO DOES NOT WORK - BLE MODEL IS BROKEN AND REQUIRED FIXING BEFORE RUNNING

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Define paths
    current_dir = Path(__file__).parent
    csv_directory = current_dir / "FEMA_BLE_Models"
    csv_file = csv_directory / "08080204_WhiskyChitto_DownloadIndex.csv"
    
    # Download FEMA BLE Models (specifically WhiskyChitto)
    ras_examples.download_fema_ble_model(csv_file=csv_file)
    
    
    # Initialize the RasPrj object for WhiskyChitto
    project_path = csv_directory / "WhiskyChitto" / "HECRAS_Models" / "Model" / "Input"
    logging.info(f"Initializing RasPrj for project at: {project_path}")
    whisky_project = init_ras_project(project_path, "5.0.7")
    
    print("Available plans:")
    print(whisky_project.plan_df)
    print()
    
    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel_whisky"
    results_all = RasCmdr.compute_parallel(
        max_workers=2,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.6")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()
    
    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific_whisky"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores) if num_cores > 0 else 1
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic_whisky"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.6")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()


==================================================

File: C:\GH\ras-commander\examples\18_2d_hdf_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 2D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the RasHdf and RasUtils classes to streamline data extraction, processing, and visualization."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ras_commander imported successfully\n"]}],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, RasGpt, ras\n","\n","print(\"ras_commander imported successfully\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:33,226 - ras_commander.RasPrj - INFO - HEC-RAS executable found at default path: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n","2024-10-07 17:57:33,241 - ras_commander.RasPrj - INFO - Initialization complete for project: Muncie\n","2024-10-07 17:57:33,241 - ras_commander.RasPrj - INFO - Plan entries: 3, Flow entries: 1, Unsteady entries: 1, Geometry entries: 3, Boundary conditions: 2\n","2024-10-07 17:57:33,242 - ras_commander.RasPrj - INFO - Project initialized. ras_instance project folder: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\n","2024-10-07 17:57:33,244 - ras_commander.RasPrj - INFO - HEC-RAS executable found at default path: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.6\\Ras.exe\n","2024-10-07 17:57:33,271 - ras_commander.RasPrj - INFO - Initialization complete for project: BaldEagleDamBrk\n","2024-10-07 17:57:33,272 - ras_commander.RasPrj - INFO - Plan entries: 11, Flow entries: 0, Unsteady entries: 10, Geometry entries: 10, Boundary conditions: 51\n","2024-10-07 17:57:33,273 - ras_commander.RasPrj - INFO - Project initialized. ras_instance project folder: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\n"]},{"name":"stdout","output_type":"stream","text":["Muncie.p03.hdf already exists. Skipping project extraction and plan execution.\n"]}],"source":["# Define the path to the Muncie project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","muncie_path = current_dir / \"example_projects\" / \"Muncie\"\n","bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n","import logging\n","# Check if Muncie.p03.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = muncie_path / \"Muncie.p03.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the Muncie project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"Muncie\", \"BaldEagleCrkMulti2D\"])\n","\n","    # Initialize custom Ras objects\n","    muncie = RasPrj()\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS projects using the custom ras objects\n","    muncie = init_ras_project(muncie_path, \"6.6\", ras_instance=muncie)\n","    logging.info(f\"Muncie project initialized with folder: {muncie.project_folder}\")\n","\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Muncie object id: {id(muncie)}\")\n","    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"03\"\n","\n","    # Set plan keys for both projects\n","    for project in [muncie, bald_eagle]:\n","        RasPlan.update_plan_value(plan_number, \"run_htab\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"run_unet\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"run_postProcess\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"run_rasmapper\", 0, ras_object=project)\n","\n","    # Execute Plan 03 using RasCmdr for Muncie\n","    print(f\"Executing Plan {plan_number} for the Muncie project...\")\n","    success_muncie = RasCmdr.compute_plan(plan_number, ras_object=muncie)\n","    if success_muncie:\n","        print(f\"Plan {plan_number} executed successfully for Muncie.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Muncie.\\n\")\n","    \n","    # Execute Plan 03 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"Muncie.p03.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    muncie = RasPrj()\n","    bald_eagle = RasPrj()\n","    muncie = init_ras_project(muncie_path, \"6.6\", ras_instance=muncie)\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    plan_number = \"03\""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Results for Plan 03 are located at: c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p03.hdf\n","\n","Results for Plan 03 are located at: c:\\GH\\ras-commander\\examples\\example_projects\\BaldEagleCrkMulti2D\\BaldEagleDamBrk.p03.hdf\n","\n"]}],"source":["# Retrieve the HDF file path for Plan 03\n","results_path_muncie = RasPlan.get_results_path(plan_number, ras_object=muncie)\n","if results_path_muncie:\n","    print(f\"Results for Plan {plan_number} are located at: {results_path_muncie}\\n\")\n","else:\n","    print(f\"No results found for Plan {plan_number}.\\n\")\n","    \n","results_path_baldeagle = RasPlan.get_results_path(plan_number, ras_object=bald_eagle)\n","if results_path_baldeagle:\n","    print(f\"Results for Plan {plan_number} are located at: {results_path_baldeagle}\\n\")\n","else:\n","    print(f\"No results found for Plan {plan_number}.\\n\")    "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Define the HDF input path as Plan Number\n","hdf_input = plan_number\n","\n","# Initialize RasHdf handler\n","hdf_handler = RasHdf()\n","\n","# The remainder of the examples only use muncie, so let's set results_path to muncie\n","results_path = results_path_muncie\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Example 1: Listing all HDF paths with properties\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HDF_Path</th>\n","      <th>Type</th>\n","      <th>Shape</th>\n","      <th>Size</th>\n","      <th>Dtype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Event Conditions</td>\n","      <td>Group</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Event Conditions/Unsteady</td>\n","      <td>Group</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Event Conditions/Unsteady/Boundary Conditions</td>\n","      <td>Group</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Event Conditions/Unsteady/Boundary Conditions/...</td>\n","      <td>Group</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Event Conditions/Unsteady/Boundary Conditions/...</td>\n","      <td>Dataset</td>\n","      <td>(25, 2)</td>\n","      <td>50.0</td>\n","      <td>float32</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            HDF_Path     Type    Shape  Size  \\\n","0                                   Event Conditions    Group     None   NaN   \n","1                          Event Conditions/Unsteady    Group     None   NaN   \n","2      Event Conditions/Unsteady/Boundary Conditions    Group     None   NaN   \n","3  Event Conditions/Unsteady/Boundary Conditions/...    Group     None   NaN   \n","4  Event Conditions/Unsteady/Boundary Conditions/...  Dataset  (25, 2)  50.0   \n","\n","     Dtype  \n","0     None  \n","1     None  \n","2     None  \n","3     None  \n","4  float32  "]},"metadata":{},"output_type":"display_data"}],"source":["# Example 1: List all HDF paths with properties\n","print(\"Example 1: Listing all HDF paths with properties\")\n","hdf_paths_df = RasHdf.get_hdf_paths_with_properties(hdf_input, ras_object=muncie)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:33,511 - ras_commander.RasHdf - INFO - Extracting Plan Information from: Muncie.p03.hdf\n","2024-10-07 17:57:33,513 - ras_commander.RasHdf - INFO - Plan Name: Unsteady Run with 2D 50ft Grid\n","2024-10-07 17:57:33,515 - ras_commander.RasHdf - INFO - Simulation Start Time: 02Jan1900 00:00:00\n","2024-10-07 17:57:33,516 - ras_commander.RasHdf - INFO - Simulation End Time: 03Jan1900 00:00:00\n","2024-10-07 17:57:33,516 - ras_commander.RasHdf - INFO - Simulation Duration (hours): 24.0\n"]},{"name":"stdout","output_type":"stream","text":["\n","Example 2: Extracting runtime and compute time data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Plan Name</th>\n","      <th>File Name</th>\n","      <th>Simulation Start Time</th>\n","      <th>Simulation End Time</th>\n","      <th>Simulation Duration (s)</th>\n","      <th>Simulation Time (hr)</th>\n","      <th>Completing Geometry (hr)</th>\n","      <th>Preprocessing Geometry (hr)</th>\n","      <th>Completing Event Conditions (hr)</th>\n","      <th>Unsteady Flow Computations (hr)</th>\n","      <th>Complete Process (hr)</th>\n","      <th>Unsteady Flow Speed (hr/hr)</th>\n","      <th>Complete Process Speed (hr/hr)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Unsteady Run with 2D 50ft Grid</td>\n","      <td>Muncie.p03.hdf</td>\n","      <td>02Jan1900 00:00:00</td>\n","      <td>03Jan1900 00:00:00</td>\n","      <td>86400.0</td>\n","      <td>24.0</td>\n","      <td>N/A</td>\n","      <td>0.000373</td>\n","      <td>N/A</td>\n","      <td>0.011337</td>\n","      <td>0.014089</td>\n","      <td>2116.972533</td>\n","      <td>1703.503618</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        Plan Name       File Name Simulation Start Time  \\\n","0  Unsteady Run with 2D 50ft Grid  Muncie.p03.hdf    02Jan1900 00:00:00   \n","\n","  Simulation End Time  Simulation Duration (s)  Simulation Time (hr)  \\\n","0  03Jan1900 00:00:00                  86400.0                  24.0   \n","\n","  Completing Geometry (hr)  Preprocessing Geometry (hr)  \\\n","0                      N/A                     0.000373   \n","\n","  Completing Event Conditions (hr)  Unsteady Flow Computations (hr)  \\\n","0                              N/A                         0.011337   \n","\n","   Complete Process (hr)  Unsteady Flow Speed (hr/hr)  \\\n","0               0.014089                  2116.972533   \n","\n","   Complete Process Speed (hr/hr)  \n","0                     1703.503618  "]},"metadata":{},"output_type":"display_data"}],"source":["# Example 2: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = RasHdf.get_runtime_data(hdf_input, ras_object=muncie)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:33,547 - ras_commander.RasHdf - INFO - Found 1 2D Flow Areas\n"]},{"name":"stdout","output_type":"stream","text":["\n","Example 3: Listing 2D Flow Area Names\n","2D Flow Area Names: ['2D Interior Area']\n"]}],"source":["# Example 3: Get 2D Flow Area Names\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = RasHdf.get_2d_flow_area_names(hdf_input, ras_object=muncie)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 4: Extracting 2D Flow Area Attributes\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Locked</th>\n","      <th>Mann</th>\n","      <th>Multiple Face Mann n</th>\n","      <th>Composite LC</th>\n","      <th>Cell Vol Tol</th>\n","      <th>Cell Min Area Fraction</th>\n","      <th>Face Profile Tol</th>\n","      <th>Face Area Tol</th>\n","      <th>Face Conv Ratio</th>\n","      <th>Laminar Depth</th>\n","      <th>Min Face Length Ratio</th>\n","      <th>Spacing dx</th>\n","      <th>Spacing dy</th>\n","      <th>Shift dx</th>\n","      <th>Shift dy</th>\n","      <th>Cell Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>b'2D Interior Area'</td>\n","      <td>0</td>\n","      <td>0.06</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.02</td>\n","      <td>0.2</td>\n","      <td>0.05</td>\n","      <td>50.0</td>\n","      <td>50.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5391</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Name  Locked  Mann  Multiple Face Mann n  Composite LC  \\\n","0  b'2D Interior Area'       0  0.06                     0             0   \n","\n","   Cell Vol Tol  Cell Min Area Fraction  Face Profile Tol  Face Area Tol  \\\n","0          0.01                    0.01              0.01           0.01   \n","\n","   Face Conv Ratio  Laminar Depth  Min Face Length Ratio  Spacing dx  \\\n","0             0.02            0.2                   0.05        50.0   \n","\n","   Spacing dy  Shift dx  Shift dy  Cell Count  \n","0        50.0       NaN       NaN        5391  "]},"metadata":{},"output_type":"display_data"}],"source":["# Example 4: Extract 2D Flow Area Attributes\n","print(\"\\nExample 4: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes_df = RasHdf.get_2d_flow_area_attributes(hdf_input, ras_object=muncie)\n","if flow_area_attributes_df is not None:\n","    display(flow_area_attributes_df.head())\n","else:\n","    print(\"No 2D Flow Area attributes found.\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 5: Extracting Cell Info\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Start</th>\n","      <th>End</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5391</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Start   End\n","0      0  5391"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 5: Extract Cell Info\n","print(\"\\nExample 5: Extracting Cell Info\")\n","cell_info_df = RasHdf.get_cell_info(hdf_input, ras_object=muncie)\n","if cell_info_df is not None:\n","    display(cell_info_df.head())\n","else:\n","    print(\"No Cell Info found.\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 6: Extracting Cell Points\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>406000.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>406050.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>406100.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>406150.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>406200.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          X          Y\n","0  406000.0  1805000.0\n","1  406050.0  1805000.0\n","2  406100.0  1805000.0\n","3  406150.0  1805000.0\n","4  406200.0  1805000.0"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 6: Extract Cell Points\n","print(\"\\nExample 6: Extracting Cell Points\")\n","cell_points_df = RasHdf.get_cell_points(hdf_input, ras_object=muncie)\n","if cell_points_df is not None:\n","    display(cell_points_df.head())\n","else:\n","    print(\"No Cell Points found.\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 7: Extracting Polygon Info and Parts\n","Polygon Info:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Column1</th>\n","      <th>Column2</th>\n","      <th>Column3</th>\n","      <th>Column4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>170</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Column1  Column2  Column3  Column4\n","0        0      170        0        1"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Polygon Parts:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Start</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>170</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Start  Count\n","0      0    170"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 7: Extract Polygon Info and Parts\n","print(\"\\nExample 7: Extracting Polygon Info and Parts\")\n","polygon_info_df, polygon_parts_df = RasHdf.get_polygon_info_and_parts(hdf_input, ras_object=muncie)\n","print(\"Polygon Info:\")\n","if polygon_info_df is not None:\n","    display(polygon_info_df.head())\n","else:\n","    print(\"No Polygon Info found.\")\n","print(\"\\nPolygon Parts:\")\n","if polygon_parts_df is not None:\n","    display(polygon_parts_df.head())\n","else:\n","    print(\"No Polygon Parts found.\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 8: Extracting Polygon Points\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>409537.1821</td>\n","      <td>1802597.314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>409645.1430</td>\n","      <td>1802591.258</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>409737.8005</td>\n","      <td>1802600.670</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>409762.3667</td>\n","      <td>1802605.741</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>409846.7495</td>\n","      <td>1802629.917</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             X            Y\n","0  409537.1821  1802597.314\n","1  409645.1430  1802591.258\n","2  409737.8005  1802600.670\n","3  409762.3667  1802605.741\n","4  409846.7495  1802629.917"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 8: Extract Polygon Points\n","print(\"\\nExample 8: Extracting Polygon Points\")\n","polygon_points_df = RasHdf.get_polygon_points(hdf_input, ras_object=muncie)\n","if polygon_points_df is not None:\n","    display(polygon_points_df.head())\n","else:\n","    print(\"No Polygon Points found.\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 9: Extracting Cells Center Coordinates and Manning's n\n","Cells Center Coordinates:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>406000.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>406050.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>406100.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>406150.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>406200.0</td>\n","      <td>1805000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          X          Y\n","0  406000.0  1805000.0\n","1  406050.0  1805000.0\n","2  406100.0  1805000.0\n","3  406150.0  1805000.0\n","4  406200.0  1805000.0"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Cells Manning's n:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Manning's n</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Manning's n\n","0         0.06\n","1         0.06\n","2         0.06\n","3         0.06\n","4         0.06"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 9: Extract Cells Center Coordinates and Manning's n\n","print(\"\\nExample 9: Extracting Cells Center Coordinates and Manning's n\")\n","cells_center_coord_df, cells_manning_n_df = RasHdf.get_cells_center_data(hdf_input, ras_object=muncie)\n","print(\"Cells Center Coordinates:\")\n","if cells_center_coord_df is not None:\n","    display(cells_center_coord_df.head())\n","else:\n","    print(\"No Cells Center Coordinates found.\")\n","print(\"\\nCells Manning's n:\")\n","if cells_manning_n_df is not None:\n","    display(cells_manning_n_df.head())\n","else:\n","    print(\"No Cells Manning's n found.\")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 10: Extracting Faces Area Elevation Data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Elevation</th>\n","      <th>Area</th>\n","      <th>Wetted Perimeter</th>\n","      <th>Manning's n</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>939.428467</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>939.628479</td>\n","      <td>0.314608</td>\n","      <td>3.152243</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>939.756226</td>\n","      <td>0.838549</td>\n","      <td>5.068435</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>939.760376</td>\n","      <td>0.859697</td>\n","      <td>5.130248</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>939.979004</td>\n","      <td>2.336330</td>\n","      <td>8.406319</td>\n","      <td>0.06</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Elevation      Area  Wetted Perimeter  Manning's n\n","0  939.428467  0.000000          0.000000         0.06\n","1  939.628479  0.314608          3.152243         0.06\n","2  939.756226  0.838549          5.068435         0.06\n","3  939.760376  0.859697          5.130248         0.06\n","4  939.979004  2.336330          8.406319         0.06"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 10: Extract Faces Area Elevation Data\n","print(\"\\nExample 10: Extracting Faces Area Elevation Data\")\n","faces_elev_df = RasHdf.get_faces_area_elevation_data(hdf_input, ras_object=muncie)\n","if faces_elev_df is not None:\n","    display(faces_elev_df.head())\n","else:\n","    print(\"No Faces Area Elevation Data found.\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 11: Extracting Compute Messages\n","Compute Messages:\n","['Plan: \\'Unsteady Run with 2D 50ft Grid\\' (Muncie.p03)\\r\\nSimulation started at: 07Oct2024 05:39:28 PM\\r\\n\\r\\nWriting Plan GIS Data...\\r\\nCompleted Writing Plan GIS Data\\r\\nWriting Geometry...\\r\\nComputing Bank Lines\\r\\nBank lines generated in 99 ms\\r\\nComputing Edge Lines\\r\\nEdge Lines generated in 64 ms\\r\\nComputing XS Interpolation Surface\\r\\nXS Interpolation Surface generated in 120 ms\\r\\nGeometry \\'Geometry\\' association was set to the first valid terrain layer (Terrain)\\r\\nComputing 2D Flow Area \\'2D Interior Area\\' tables: Property tables do not exist.\\r\\n2D Flow Area \\'2D Interior Area\\' tables complete 3.08 sec\\r\\nCompleted Writing Geometry\\r\\nWriting Event Conditions ...\\r\\nCompleted Writing Event Condition Data\\r\\n\\r\\n\\t\\r\\nGeometric Preprocessor HEC-RAS 6.6 September 2024\\r\\n \\r\\n\\r\\nFinished Processing Geometry\\r\\n\\r\\n\\r\\nPerforming Unsteady Flow Simulation  HEC-RAS 6.6 September 2024\\r\\n \\r\\n\\t\\r\\nUnsteady Input Summary:\\r\\n     1D Unsteady Finite Difference Numerical Solution\\r\\n     Number of warm up time steps:   20\\r\\n     2D Unsteady Diffusion Wave Equation Set (fastest)\\r\\n     2D number of Solver Cores:    4\\r\\nBreach at   White Muncie 13214   at   02JAN1900 02:56:00\\r\\n\\r\\nOverall Volume Accounting Error in Acre Feet:     -2.0404039154\\r\\nOverall Volume Accounting Error as percentage:          0.005519\\r\\nPlease review \"Computational Log File\" output for volume accounting details\\r\\n\\r\\nWriting Results to DSS\\r\\n\\r\\nFinished Unsteady Flow Simulation\\r\\n\\r\\nReading Unsteady Data for Post Process...\\r\\nCompleted Reading Unsteady Data for Post Process\\r\\n\\r\\n\\t\\r\\nRunning Post Processor  HEC-RAS 6.6 September 2024\\r\\n \\r\\n\\r\\nFinished Post Processing\\r\\n\\r\\n\\r\\nGenerating Time Series Post Process File ...\\r\\nWriting 1D Data: Water-Surface\\r\\nWriting 1D Data: Flow\\r\\nWriting 2D Data: Water-Surface\\r\\nWriting 2D Data: Velocity\\r\\nTime Series Post Process file generated [1254 ms]\\r\\n\\r\\nComputations Summary\\r\\n\\r\\nComputation Task\\tTime(hh:mm:ss)\\r\\nCompleting Geometry, Flow and Plan\\t       5\\r\\nPreprocessing Geometry\\t       1\\r\\nUnsteady Flow Computations\\t      40\\r\\nPost-Processing\\t       1\\r\\nGenerating Time Series Post Process\\t       1\\r\\nComplete Process\\t      50\\r\\n\\r\\nComputation Speed\\tSimulation/Runtime\\r\\nUnsteady Flow Computations\\t2117x\\r\\nComplete Process\\t1696x\\r\\n']\n"]}],"source":["# Example 11: Extract Compute Messages as String\n","print(\"\\nExample 11: Extracting Compute Messages\")\n","compute_messages = RasHdf.extract_string_from_hdf(hdf_input, '/Results/Summary/Compute Messages (text)', ras_object=muncie)\n","print(\"Compute Messages:\")\n","print(compute_messages)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 12: Extracting Plan Parameters and Volume Accounting Data\n","Plan Parameters Group Attributes:\n","\n","Plan Parameters DataFrame:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Attribute</th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1D Cores</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1D Flow Tolerance</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1D Maximum Iterations</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1D Maximum Iterations Without Improvement</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1D Maximum Water Surface Error To Abort</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1D Methodology</td>\n","      <td>b'Finite Difference'</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1D Storage Area Elevation Tolerance</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1D Theta</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1D Theta Warmup</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1D Water Surface Elevation Tolerance</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1D-2D Flow Tolerance</td>\n","      <td>0.1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1D-2D Gate Flow Submergence Decay Exponent</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1D-2D IS Stablity Factor</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1D-2D LS Stablity Factor</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>1D-2D Maximum Iterations</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1D-2D Maximum Number of Time Slices</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1D-2D Minimum Flow Tolerance</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1D-2D Minimum Time Step for Slicing(hours)</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1D-2D Number of Warmup Steps</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1D-2D Warmup Time Step (hours)</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>1D-2D Water Surface Tolerance</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>1D-2D Weir Flow Submergence Decay Exponent</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>2D Advanced Convergence</td>\n","      <td>[0]</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>2D Boundary Condition Ramp Up Fraction</td>\n","      <td>[0.5]</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>2D Boundary Condition Volume Check</td>\n","      <td>[b'False']</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>2D Cores (per mesh)</td>\n","      <td>[4]</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>2D Coriolis</td>\n","      <td>b'False'</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>2D Equation Set</td>\n","      <td>[b'Diffusion Wave']</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>2D Initial Conditions Ramp Up Time (hrs)</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>2D Latitude for Coriolis</td>\n","      <td>[3.4028235e+38]</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>2D Longitudinal Mixing Coefficient</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>2D Matrix Solver</td>\n","      <td>[b'Pardiso']</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>2D Maximum Iterations</td>\n","      <td>[20]</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>2D Names</td>\n","      <td>[b'2D Interior Area']</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>2D Number of Time Slices</td>\n","      <td>[1]</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>2D Only</td>\n","      <td>b'False'</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>2D Smagorinsky Mixing Coefficient</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>2D Theta</td>\n","      <td>[1.0]</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>2D Theta Warmup</td>\n","      <td>[1.0]</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>2D Transverse Mixing Coefficient</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>2D Turbulence Formulation</td>\n","      <td>[b'None']</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>2D Volume Tolerance</td>\n","      <td>[0.01]</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>2D WS Max Tolerance</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>2D WS RMS Tolerance</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>2D WS Stalling Tolerance</td>\n","      <td>[0.0]</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>2D Water Surface Tolerance</td>\n","      <td>[0.01]</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Friction Slope Average Method (BR)</td>\n","      <td>b'Average Conveyance'</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>Friction Slope Average Method (XS)</td>\n","      <td>b'Average Friction Slope'</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>Gravity</td>\n","      <td>32.174049</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>HDF Chunk Size</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>HDF Compression</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>HDF Fixed Rows</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>HDF Flush Buffer</td>\n","      <td>b'False'</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>HDF Spatial Parts</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>HDF Use Max Rows</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>HDF Write Time Slices</td>\n","      <td>b'False'</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>HDF Write Warmup</td>\n","      <td>b'False'</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Pardiso Solver</td>\n","      <td>b'False'</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     Attribute                      Value\n","0                                     1D Cores                          0\n","1                            1D Flow Tolerance                        NaN\n","2                        1D Maximum Iterations                         20\n","3    1D Maximum Iterations Without Improvement                          0\n","4      1D Maximum Water Surface Error To Abort                      100.0\n","5                               1D Methodology       b'Finite Difference'\n","6          1D Storage Area Elevation Tolerance                       0.01\n","7                                     1D Theta                        1.0\n","8                              1D Theta Warmup                        1.0\n","9         1D Water Surface Elevation Tolerance                       0.01\n","10                        1D-2D Flow Tolerance                        0.1\n","11  1D-2D Gate Flow Submergence Decay Exponent                        1.0\n","12                    1D-2D IS Stablity Factor                        1.0\n","13                    1D-2D LS Stablity Factor                        2.0\n","14                    1D-2D Maximum Iterations                          0\n","15         1D-2D Maximum Number of Time Slices                         20\n","16                1D-2D Minimum Flow Tolerance                        1.0\n","17  1D-2D Minimum Time Step for Slicing(hours)                        0.0\n","18                1D-2D Number of Warmup Steps                         20\n","19              1D-2D Warmup Time Step (hours)                        0.0\n","20               1D-2D Water Surface Tolerance                       0.01\n","21  1D-2D Weir Flow Submergence Decay Exponent                        3.0\n","22                     2D Advanced Convergence                        [0]\n","23      2D Boundary Condition Ramp Up Fraction                      [0.5]\n","24          2D Boundary Condition Volume Check                 [b'False']\n","25                         2D Cores (per mesh)                        [4]\n","26                                 2D Coriolis                   b'False'\n","27                             2D Equation Set        [b'Diffusion Wave']\n","28    2D Initial Conditions Ramp Up Time (hrs)                      [0.0]\n","29                    2D Latitude for Coriolis            [3.4028235e+38]\n","30          2D Longitudinal Mixing Coefficient                      [0.0]\n","31                            2D Matrix Solver               [b'Pardiso']\n","32                       2D Maximum Iterations                       [20]\n","33                                    2D Names      [b'2D Interior Area']\n","34                    2D Number of Time Slices                        [1]\n","35                                     2D Only                   b'False'\n","36           2D Smagorinsky Mixing Coefficient                      [0.0]\n","37                                    2D Theta                      [1.0]\n","38                             2D Theta Warmup                      [1.0]\n","39            2D Transverse Mixing Coefficient                      [0.0]\n","40                   2D Turbulence Formulation                  [b'None']\n","41                         2D Volume Tolerance                     [0.01]\n","42                         2D WS Max Tolerance                      [0.0]\n","43                         2D WS RMS Tolerance                      [0.0]\n","44                    2D WS Stalling Tolerance                      [0.0]\n","45                  2D Water Surface Tolerance                     [0.01]\n","46          Friction Slope Average Method (BR)      b'Average Conveyance'\n","47          Friction Slope Average Method (XS)  b'Average Friction Slope'\n","48                                     Gravity                  32.174049\n","49                              HDF Chunk Size                        1.0\n","50                             HDF Compression                          1\n","51                              HDF Fixed Rows                          1\n","52                            HDF Flush Buffer                   b'False'\n","53                           HDF Spatial Parts                          1\n","54                            HDF Use Max Rows                          0\n","55                       HDF Write Time Slices                   b'False'\n","56                            HDF Write Warmup                   b'False'\n","57                              Pardiso Solver                   b'False'"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Volume Accounting DataFrame:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Attribute</th>\n","      <th>Value</th>\n","      <th>Type</th>\n","      <th>Shape</th>\n","      <th>Size</th>\n","      <th>Dtype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Vol Accounting in</td>\n","      <td>Acre Feet</td>\n","      <td>bytes_</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Attribute      Value    Type Shape  Size Dtype\n","0  Vol Accounting in  Acre Feet  bytes_  None  None  None"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 12: Extract Plan Parameters and Volume Accounting\n","print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n","import h5py\n","import numpy as np\n","\n","# Extract plan parameters\n","with h5py.File(str(results_path), 'r') as hdf_file:\n","    plan_parameters = hdf_file['Plan Data/Plan Parameters']\n","    \n","    # List group attributes\n","    print(\"Plan Parameters Group Attributes:\")\n","    #for attr_name, attr_value in plan_parameters.attrs.items():\n","        #print(f\"{attr_name}: {attr_value}\")\n","    \n","    # Extract plan parameters as a DataFrame\n","    plan_parameters_df = pd.DataFrame([(attr_name, attr_value) for attr_name, attr_value in plan_parameters.attrs.items()], columns=['Attribute', 'Value'])\n","\n","# Construct the group path for volume accounting data\n","group_to_list = \"Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D\"\n","\n","# Extract volume accounting data as a DataFrame\n","volume_accounting_df = RasHdf.get_group_attributes_as_df(results_path, group_to_list)\n","\n","print(\"\\nPlan Parameters DataFrame:\")\n","display(plan_parameters_df)\n","\n","print(\"\\nVolume Accounting DataFrame:\")\n","display(volume_accounting_df)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example: Listing 2D Flow Area Groups\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:33,847 - ras_commander.RasHdf - INFO - Found 1 2D Flow Areas\n"]},{"name":"stdout","output_type":"stream","text":["2D Flow Area Groups:\n","- 2D Interior Area\n","\n","Detailed information for the first group: 2D Interior Area\n","Datasets in this group:\n","- Cells Center Coordinate: Shape (5765, 2), Dtype float64\n","- Cells Center Manning's n: Shape (5765,), Dtype float32\n","- Cells Face and Orientation Info: Shape (5765, 2), Dtype int32\n","- Cells Face and Orientation Values: Shape (22328, 2), Dtype int32\n","- Cells FacePoint Indexes: Shape (5765, 7), Dtype int32\n","- Cells Minimum Elevation: Shape (5765,), Dtype float32\n","- Cells Surface Area: Shape (5765,), Dtype float32\n","- Cells Volume Elevation Info: Shape (5765, 2), Dtype int32\n","- Cells Volume Elevation Values: Shape (37912, 2), Dtype float32\n","- FacePoints Cell Index Values: Shape (22702,), Dtype int32\n","- FacePoints Cell Info: Shape (5774, 2), Dtype int32\n","- FacePoints Coordinate: Shape (5774, 2), Dtype float64\n","- FacePoints Face and Orientation Info: Shape (5774, 2), Dtype int32\n","- FacePoints Face and Orientation Values: Shape (22328, 2), Dtype int32\n","- FacePoints Is Perimeter: Shape (5774,), Dtype int32\n","- Faces Area Elevation Info: Shape (11164, 2), Dtype int32\n","- Faces Area Elevation Values: Shape (47055, 4), Dtype float32\n","- Faces Cell Indexes: Shape (11164, 2), Dtype int32\n","- Faces FacePoint Indexes: Shape (11164, 2), Dtype int32\n","- Faces Low Elevation Centroid: Shape (11164,), Dtype float32\n","- Faces Minimum Elevation: Shape (11164,), Dtype float32\n","- Faces NormalUnitVector and Length: Shape (11164, 3), Dtype float32\n","- Faces Perimeter Info: Shape (11164, 2), Dtype int32\n","- Faces Perimeter Values: Shape (201, 2), Dtype float64\n","- Perimeter: Shape (170, 2), Dtype float64\n"]}],"source":["# Example 13: Listing 2D Flow Area Groups\n","print(\"\\nExample: Listing 2D Flow Area Groups\")\n","\n","# Get the names of all 2D Flow Area groups\n","flow_area_group_names = RasHdf.get_2d_flow_area_names(hdf_input, ras_object=muncie)\n","\n","print(\"2D Flow Area Groups:\")\n","if flow_area_group_names:\n","    for name in flow_area_group_names:\n","        print(f\"- {name}\")\n","else:\n","    print(\"No 2D Flow Area groups found in the HDF file.\")\n","\n","import h5py\n","\n","# Additional information about the first group (if any)\n","if flow_area_group_names:\n","    first_group = flow_area_group_names[0]\n","    print(f\"\\nDetailed information for the first group: {first_group}\")\n","    \n","    # Remember, use results_path because we are accessing the hdf file and hdf_input is the plan number\n","    with h5py.File(str(results_path), 'r') as hdf_file:\n","        group = hdf_file[f'Geometry/2D Flow Areas/{first_group}']\n","        print(\"Datasets in this group:\")\n","        for name, item in group.items():\n","            if isinstance(item, h5py.Dataset):\n","                print(f\"- {name}: Shape {item.shape}, Dtype {item.dtype}\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 13: Extracting Faces Indexes\n","Faces Cell Indexes:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Left Cell</th>\n","      <th>Right Cell</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>5391</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Left Cell  Right Cell\n","0          1           2\n","1          1        5391\n","2          1           0\n","3          1          13\n","4          2          14"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Faces FacePoint Indexes:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Start FacePoint</th>\n","      <th>End FacePoint</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Start FacePoint  End FacePoint\n","0                4              5\n","1                5              1\n","2                1              0\n","3                0              4\n","4                4              6"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 14: Extract Faces Indexes\n","print(\"\\nExample 13: Extracting Faces Indexes\")\n","cell_indexes_df, facepoint_indexes_df = RasHdf.get_faces_indexes(hdf_input, ras_object=muncie)\n","print(\"Faces Cell Indexes:\")\n","if cell_indexes_df is not None:\n","    display(cell_indexes_df.head())\n","else:\n","    print(\"No Faces Cell Indexes found.\")\n","print(\"\\nFaces FacePoint Indexes:\")\n","if facepoint_indexes_df is not None:\n","    display(facepoint_indexes_df.head())\n","else:\n","    print(\"No Faces FacePoint Indexes found.\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 14: Extracting Faces Elevation Data\n","Faces Low Elevation Centroid:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Low Elevation Centroid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.450514</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18.177126</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36.361233</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>44.354172</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37.621490</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Low Elevation Centroid\n","0                1.450514\n","1               18.177126\n","2               36.361233\n","3               44.354172\n","4               37.621490"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Faces Minimum Elevation:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Minimum Elevation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>939.428467</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>940.156250</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>940.156250</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>939.428467</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>939.091248</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Minimum Elevation\n","0         939.428467\n","1         940.156250\n","2         940.156250\n","3         939.428467\n","4         939.091248"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 15: Extract Faces Elevation Data\n","print(\"\\nExample 14: Extracting Faces Elevation Data\")\n","low_elev_centroid_df, min_elevation_df = RasHdf.get_faces_elevation_data(hdf_input, ras_object=muncie)\n","print(\"Faces Low Elevation Centroid:\")\n","if low_elev_centroid_df is not None:\n","    display(low_elev_centroid_df.head())\n","else:\n","    print(\"No Faces Low Elevation Centroid found.\")\n","print(\"\\nFaces Minimum Elevation:\")\n","if min_elevation_df is not None:\n","    display(min_elevation_df.head())\n","else:\n","    print(\"No Faces Minimum Elevation found.\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 15: Extracting Faces Vector Data\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>NormalX</th>\n","      <th>NormalY</th>\n","      <th>Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.00000</td>\n","      <td>-0.000000</td>\n","      <td>43.544975</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.06601</td>\n","      <td>0.997819</td>\n","      <td>50.109291</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.00000</td>\n","      <td>-0.000000</td>\n","      <td>40.237263</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.00000</td>\n","      <td>-1.000000</td>\n","      <td>50.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.00000</td>\n","      <td>-1.000000</td>\n","      <td>50.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   NormalX   NormalY     Length\n","0  1.00000 -0.000000  43.544975\n","1 -0.06601  0.997819  50.109291\n","2 -1.00000 -0.000000  40.237263\n","3 -0.00000 -1.000000  50.000000\n","4 -0.00000 -1.000000  50.000000"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 16: Extract Faces Vector Data\n","print(\"\\nExample 15: Extracting Faces Vector Data\")\n","faces_vector_df = RasHdf.get_faces_vector_data(hdf_input, ras_object=muncie)\n","if faces_vector_df is not None:\n","    display(faces_vector_df.head())\n","else:\n","    print(\"No Faces Vector Data found.\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 16: Extracting Faces Perimeter Data\n","Faces Perimeter Info:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Start</th>\n","      <th>Count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Start  Count\n","0      0      0\n","1      0      0\n","2      0      0\n","3      0      0\n","4      0      0"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Faces Perimeter Values:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>407715.3687</td>\n","      <td>1804189.615</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>407784.1551</td>\n","      <td>1804114.051</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>407778.0565</td>\n","      <td>1804118.342</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>407773.5300</td>\n","      <td>1804118.765</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>406001.1427</td>\n","      <td>1805013.659</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             X            Y\n","0  407715.3687  1804189.615\n","1  407784.1551  1804114.051\n","2  407778.0565  1804118.342\n","3  407773.5300  1804118.765\n","4  406001.1427  1805013.659"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 17: Extract Faces Perimeter Data\n","print(\"\\nExample 16: Extracting Faces Perimeter Data\")\n","perimeter_info_df, perimeter_values_df = RasHdf.get_faces_perimeter_data(hdf_input, ras_object=muncie)\n","print(\"Faces Perimeter Info:\")\n","if perimeter_info_df is not None:\n","    display(perimeter_info_df.head())\n","else:\n","    print(\"No Faces Perimeter Info found.\")\n","print(\"\\nFaces Perimeter Values:\")\n","if perimeter_values_df is not None:\n","    display(perimeter_values_df.head())\n","else:\n","    print(\"No Faces Perimeter Values found.\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 17: Extracting Infiltration Data\n","Infiltration - Cell Classifications:\n","No Infiltration Cell Classifications found.\n","\n","Infiltration - Face Classifications:\n","No Infiltration Face Classifications found.\n","\n","Infiltration - Initial Deficit:\n","No Infiltration Initial Deficit found.\n","\n","Infiltration - Maximum Deficit:\n","No Infiltration Maximum Deficit found.\n","\n","Infiltration - Potential Percolation Rate:\n","No Infiltration Potential Percolation Rate found.\n"]}],"source":["# Example 18: Extract Infiltration Data\n","print(\"\\nExample 17: Extracting Infiltration Data\")\n","cell_classifications_df, face_classifications_df, initial_deficit_df, maximum_deficit_df, potential_percolation_rate_df = RasHdf.get_infiltration_data(hdf_input, ras_object=muncie)\n","print(\"Infiltration - Cell Classifications:\")\n","if cell_classifications_df is not None:\n","    display(cell_classifications_df.head())\n","else:\n","    print(\"No Infiltration Cell Classifications found.\")\n","print(\"\\nInfiltration - Face Classifications:\")\n","if face_classifications_df is not None:\n","    display(face_classifications_df.head())\n","else:\n","    print(\"No Infiltration Face Classifications found.\")\n","print(\"\\nInfiltration - Initial Deficit:\")\n","if initial_deficit_df is not None:\n","    display(initial_deficit_df.head())\n","else:\n","    print(\"No Infiltration Initial Deficit found.\")\n","print(\"\\nInfiltration - Maximum Deficit:\")\n","if maximum_deficit_df is not None:\n","    display(maximum_deficit_df.head())\n","else:\n","    print(\"No Infiltration Maximum Deficit found.\")\n","print(\"\\nInfiltration - Potential Percolation Rate:\")\n","if potential_percolation_rate_df is not None:\n","    display(potential_percolation_rate_df.head())\n","else:\n","    print(\"No Infiltration Potential Percolation Rate found.\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 18: Extracting Percent Impervious Data\n","Percent Impervious - Cell Classifications:\n","No Percent Impervious Cell Classifications found.\n","\n","Percent Impervious - Face Classifications:\n","No Percent Impervious Face Classifications found.\n","\n","Percent Impervious:\n","No Percent Impervious data found.\n"]}],"source":["# Example 19: Extract Percent Impervious Data\n","print(\"\\nExample 18: Extracting Percent Impervious Data\")\n","cell_classifications_df, face_classifications_df, percent_impervious_df = RasHdf.get_percent_impervious_data(hdf_input, ras_object=muncie)\n","print(\"Percent Impervious - Cell Classifications:\")\n","if cell_classifications_df is not None:\n","    display(cell_classifications_df.head())\n","else:\n","    print(\"No Percent Impervious Cell Classifications found.\")\n","print(\"\\nPercent Impervious - Face Classifications:\")\n","if face_classifications_df is not None:\n","    display(face_classifications_df.head())\n","else:\n","    print(\"No Percent Impervious Face Classifications found.\")\n","print(\"\\nPercent Impervious:\")\n","if percent_impervious_df is not None:\n","    display(percent_impervious_df.head())\n","else:\n","    print(\"No Percent Impervious data found.\")\n","    \n","    # Note: Does not exist in the Muncie Plan 3 example used. "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 19: Extracting Perimeter Data\n","Perimeter Data:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>409537.1821</td>\n","      <td>1802597.314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>409426.1403</td>\n","      <td>1802614.326</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>409315.2430</td>\n","      <td>1802638.443</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>409133.8857</td>\n","      <td>1802742.001</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>409053.8968</td>\n","      <td>1802841.512</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             X            Y\n","0  409537.1821  1802597.314\n","1  409426.1403  1802614.326\n","2  409315.2430  1802638.443\n","3  409133.8857  1802742.001\n","4  409053.8968  1802841.512"]},"metadata":{},"output_type":"display_data"}],"source":["# Example 20: Extract Perimeter Data\n","print(\"\\nExample 19: Extracting Perimeter Data\")\n","perimeter_df = RasHdf.get_perimeter_data(hdf_input, ras_object=muncie)\n","print(\"Perimeter Data:\")\n","if perimeter_df is not None:\n","    display(perimeter_df.head())\n","else:\n","    print(\"No Perimeter Data found.\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:34,060 - ras_commander.RasHdf - CRITICAL - Group path '/Geometry/Boundary Condition Lines/Attributes' not found in HDF file 'c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p03.hdf'\n"]},{"name":"stdout","output_type":"stream","text":["\n","Example 20: Extracting Boundary Condition Lines Attributes\n","No Boundary Condition Lines Attributes found.\n"]}],"source":["# Example 21: Extract Boundary Condition Lines Attributes\n","print(\"\\nExample 20: Extracting Boundary Condition Lines Attributes\")\n","bc_lines_df = RasHdf.get_group_attributes_as_df(hdf_input, '/Geometry/Boundary Condition Lines/Attributes', ras_object=muncie)\n","if bc_lines_df is not None:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines Attributes found.\")\n","    \n","# None in Muncie plan 3, no output expected."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 22: Extracting Boundary Condition Time Series Data\n"]},{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:34,077 - ras_commander.RasHdf - CRITICAL - Group path '/Geometry/Boundary Condition Lines/Attributes' not found in HDF file 'c:\\GH\\ras-commander\\examples\\example_projects\\Muncie\\Muncie.p03.hdf'\n"]},{"name":"stdout","output_type":"stream","text":["No Boundary Condition Time Series Data found.\n","\n","All RasHdf functions have been executed on Plan 03 HDF file.\n"]}],"source":["# Example 22: Extract Boundary Condition Time Series Data\n","print(\"\\nExample 22: Extracting Boundary Condition Time Series Data\")\n","bc_time_series_df = RasHdf.get_group_attributes_as_df(hdf_input, '/Geometry/Boundary Condition Lines/Attributes', ras_object=muncie)\n","if bc_time_series_df is not None:\n","    display(bc_time_series_df.head())\n","else:\n","    print(\"No Boundary Condition Time Series Data found.\")\n","\n","print(\"\\nAll RasHdf functions have been executed on Plan 03 HDF file.\")\n","\n","\n","# NOTE: Muncie does not have boundary conditions in the HDF file - see how errors are handled. "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Example 23: Retrieving 2D Flow Area Solution Times\n","Retrieved 289 solution times:\n","[0.         0.00347222 0.00694444 0.01041667 0.01388889 0.01736111\n"," 0.02083333 0.02430556 0.02777778 0.03125    0.03472222 0.03819444\n"," 0.04166667 0.04513889 0.04861111 0.05208333 0.05555556 0.05902778\n"," 0.0625     0.06597222 0.06944444 0.07291667 0.07638889 0.07986111\n"," 0.08333333 0.08680556 0.09027778 0.09375    0.09722222 0.10069444\n"," 0.10416667 0.10763889 0.11111111 0.11458333 0.11805556 0.12152778\n"," 0.125      0.12847222 0.13194444 0.13541667 0.13888889 0.14236111\n"," 0.14583333 0.14930556 0.15277778 0.15625    0.15972222 0.16319444\n"," 0.16666667 0.17013889 0.17361111 0.17708333 0.18055556 0.18402778\n"," 0.1875     0.19097222 0.19444444 0.19791667 0.20138889 0.20486111\n"," 0.20833333 0.21180556 0.21527778 0.21875    0.22222222 0.22569444\n"," 0.22916667 0.23263889 0.23611111 0.23958333 0.24305556 0.24652778\n"," 0.25       0.25347222 0.25694444 0.26041667 0.26388889 0.26736111\n"," 0.27083333 0.27430556 0.27777778 0.28125    0.28472222 0.28819444\n"," 0.29166667 0.29513889 0.29861111 0.30208333 0.30555556 0.30902778\n"," 0.3125     0.31597222 0.31944444 0.32291667 0.32638889 0.32986111\n"," 0.33333333 0.33680556 0.34027778 0.34375    0.34722222 0.35069444\n"," 0.35416667 0.35763889 0.36111111 0.36458333 0.36805556 0.37152778\n"," 0.375      0.37847222 0.38194444 0.38541667 0.38888889 0.39236111\n"," 0.39583333 0.39930556 0.40277778 0.40625    0.40972222 0.41319444\n"," 0.41666667 0.42013889 0.42361111 0.42708333 0.43055556 0.43402778\n"," 0.4375     0.44097222 0.44444444 0.44791667 0.45138889 0.45486111\n"," 0.45833333 0.46180556 0.46527778 0.46875    0.47222222 0.47569444\n"," 0.47916667 0.48263889 0.48611111 0.48958333 0.49305556 0.49652778\n"," 0.5        0.50347222 0.50694444 0.51041667 0.51388889 0.51736111\n"," 0.52083333 0.52430556 0.52777778 0.53125    0.53472222 0.53819444\n"," 0.54166667 0.54513889 0.54861111 0.55208333 0.55555556 0.55902778\n"," 0.5625     0.56597222 0.56944444 0.57291667 0.57638889 0.57986111\n"," 0.58333333 0.58680556 0.59027778 0.59375    0.59722222 0.60069444\n"," 0.60416667 0.60763889 0.61111111 0.61458333 0.61805556 0.62152778\n"," 0.625      0.62847222 0.63194444 0.63541667 0.63888889 0.64236111\n"," 0.64583333 0.64930556 0.65277778 0.65625    0.65972222 0.66319444\n"," 0.66666667 0.67013889 0.67361111 0.67708333 0.68055556 0.68402778\n"," 0.6875     0.69097222 0.69444444 0.69791667 0.70138889 0.70486111\n"," 0.70833333 0.71180556 0.71527778 0.71875    0.72222222 0.72569444\n"," 0.72916667 0.73263889 0.73611111 0.73958333 0.74305556 0.74652778\n"," 0.75       0.75347222 0.75694444 0.76041667 0.76388889 0.76736111\n"," 0.77083333 0.77430556 0.77777778 0.78125    0.78472222 0.78819444\n"," 0.79166667 0.79513889 0.79861111 0.80208333 0.80555556 0.80902778\n"," 0.8125     0.81597222 0.81944444 0.82291667 0.82638889 0.82986111\n"," 0.83333333 0.83680556 0.84027778 0.84375    0.84722222 0.85069444\n"," 0.85416667 0.85763889 0.86111111 0.86458333 0.86805556 0.87152778\n"," 0.875      0.87847222 0.88194444 0.88541667 0.88888889 0.89236111\n"," 0.89583333 0.89930556 0.90277778 0.90625    0.90972222 0.91319444\n"," 0.91666667 0.92013889 0.92361111 0.92708333 0.93055556 0.93402778\n"," 0.9375     0.94097222 0.94444444 0.94791667 0.95138889 0.95486111\n"," 0.95833333 0.96180556 0.96527778 0.96875    0.97222222 0.97569444\n"," 0.97916667 0.98263889 0.98611111 0.98958333 0.99305556 0.99652778\n"," 1.        ]\n"]}],"source":["# Example 23: Retrieving 2D Flow Area Solution Times\n","print(\"Example 23: Retrieving 2D Flow Area Solution Times\")\n","\n","solution_times = RasHdf.get_2d_area_solution_times(hdf_input, ras_object=muncie)\n","\n","if solution_times is not None:\n","    print(f\"Retrieved {len(solution_times)} solution times:\")\n","    print(solution_times)\n","else:\n","    print(\"No solution times found.\")\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 24: Retrieving 2D Flow Area Solution Time Dates\n","Retrieved 289 solution time dates:\n","[b'02JAN1900 00:00:00' b'02JAN1900 00:05:00' b'02JAN1900 00:10:00'\n"," b'02JAN1900 00:15:00' b'02JAN1900 00:20:00' b'02JAN1900 00:25:00'\n"," b'02JAN1900 00:30:00' b'02JAN1900 00:35:00' b'02JAN1900 00:40:00'\n"," b'02JAN1900 00:45:00' b'02JAN1900 00:50:00' b'02JAN1900 00:55:00'\n"," b'02JAN1900 01:00:00' b'02JAN1900 01:05:00' b'02JAN1900 01:10:00'\n"," b'02JAN1900 01:15:00' b'02JAN1900 01:20:00' b'02JAN1900 01:25:00'\n"," b'02JAN1900 01:30:00' b'02JAN1900 01:35:00' b'02JAN1900 01:40:00'\n"," b'02JAN1900 01:45:00' b'02JAN1900 01:50:00' b'02JAN1900 01:55:00'\n"," b'02JAN1900 02:00:00' b'02JAN1900 02:05:00' b'02JAN1900 02:10:00'\n"," b'02JAN1900 02:15:00' b'02JAN1900 02:20:00' b'02JAN1900 02:25:00'\n"," b'02JAN1900 02:30:00' b'02JAN1900 02:35:00' b'02JAN1900 02:40:00'\n"," b'02JAN1900 02:45:00' b'02JAN1900 02:50:00' b'02JAN1900 02:55:00'\n"," b'02JAN1900 03:00:00' b'02JAN1900 03:05:00' b'02JAN1900 03:10:00'\n"," b'02JAN1900 03:15:00' b'02JAN1900 03:20:00' b'02JAN1900 03:25:00'\n"," b'02JAN1900 03:30:00' b'02JAN1900 03:35:00' b'02JAN1900 03:40:00'\n"," b'02JAN1900 03:45:00' b'02JAN1900 03:50:00' b'02JAN1900 03:55:00'\n"," b'02JAN1900 04:00:00' b'02JAN1900 04:05:00' b'02JAN1900 04:10:00'\n"," b'02JAN1900 04:15:00' b'02JAN1900 04:20:00' b'02JAN1900 04:25:00'\n"," b'02JAN1900 04:30:00' b'02JAN1900 04:35:00' b'02JAN1900 04:40:00'\n"," b'02JAN1900 04:45:00' b'02JAN1900 04:50:00' b'02JAN1900 04:55:00'\n"," b'02JAN1900 05:00:00' b'02JAN1900 05:05:00' b'02JAN1900 05:10:00'\n"," b'02JAN1900 05:15:00' b'02JAN1900 05:20:00' b'02JAN1900 05:25:00'\n"," b'02JAN1900 05:30:00' b'02JAN1900 05:35:00' b'02JAN1900 05:40:00'\n"," b'02JAN1900 05:45:00' b'02JAN1900 05:50:00' b'02JAN1900 05:55:00'\n"," b'02JAN1900 06:00:00' b'02JAN1900 06:05:00' b'02JAN1900 06:10:00'\n"," b'02JAN1900 06:15:00' b'02JAN1900 06:20:00' b'02JAN1900 06:25:00'\n"," b'02JAN1900 06:30:00' b'02JAN1900 06:35:00' b'02JAN1900 06:40:00'\n"," b'02JAN1900 06:45:00' b'02JAN1900 06:50:00' b'02JAN1900 06:55:00'\n"," b'02JAN1900 07:00:00' b'02JAN1900 07:05:00' b'02JAN1900 07:10:00'\n"," b'02JAN1900 07:15:00' b'02JAN1900 07:20:00' b'02JAN1900 07:25:00'\n"," b'02JAN1900 07:30:00' b'02JAN1900 07:35:00' b'02JAN1900 07:40:00'\n"," b'02JAN1900 07:45:00' b'02JAN1900 07:50:00' b'02JAN1900 07:55:00'\n"," b'02JAN1900 08:00:00' b'02JAN1900 08:05:00' b'02JAN1900 08:10:00'\n"," b'02JAN1900 08:15:00' b'02JAN1900 08:20:00' b'02JAN1900 08:25:00'\n"," b'02JAN1900 08:30:00' b'02JAN1900 08:35:00' b'02JAN1900 08:40:00'\n"," b'02JAN1900 08:45:00' b'02JAN1900 08:50:00' b'02JAN1900 08:55:00'\n"," b'02JAN1900 09:00:00' b'02JAN1900 09:05:00' b'02JAN1900 09:10:00'\n"," b'02JAN1900 09:15:00' b'02JAN1900 09:20:00' b'02JAN1900 09:25:00'\n"," b'02JAN1900 09:30:00' b'02JAN1900 09:35:00' b'02JAN1900 09:40:00'\n"," b'02JAN1900 09:45:00' b'02JAN1900 09:50:00' b'02JAN1900 09:55:00'\n"," b'02JAN1900 10:00:00' b'02JAN1900 10:05:00' b'02JAN1900 10:10:00'\n"," b'02JAN1900 10:15:00' b'02JAN1900 10:20:00' b'02JAN1900 10:25:00'\n"," b'02JAN1900 10:30:00' b'02JAN1900 10:35:00' b'02JAN1900 10:40:00'\n"," b'02JAN1900 10:45:00' b'02JAN1900 10:50:00' b'02JAN1900 10:55:00'\n"," b'02JAN1900 11:00:00' b'02JAN1900 11:05:00' b'02JAN1900 11:10:00'\n"," b'02JAN1900 11:15:00' b'02JAN1900 11:20:00' b'02JAN1900 11:25:00'\n"," b'02JAN1900 11:30:00' b'02JAN1900 11:35:00' b'02JAN1900 11:40:00'\n"," b'02JAN1900 11:45:00' b'02JAN1900 11:50:00' b'02JAN1900 11:55:00'\n"," b'02JAN1900 12:00:00' b'02JAN1900 12:05:00' b'02JAN1900 12:10:00'\n"," b'02JAN1900 12:15:00' b'02JAN1900 12:20:00' b'02JAN1900 12:25:00'\n"," b'02JAN1900 12:30:00' b'02JAN1900 12:35:00' b'02JAN1900 12:40:00'\n"," b'02JAN1900 12:45:00' b'02JAN1900 12:50:00' b'02JAN1900 12:55:00'\n"," b'02JAN1900 13:00:00' b'02JAN1900 13:05:00' b'02JAN1900 13:10:00'\n"," b'02JAN1900 13:15:00' b'02JAN1900 13:20:00' b'02JAN1900 13:25:00'\n"," b'02JAN1900 13:30:00' b'02JAN1900 13:35:00' b'02JAN1900 13:40:00'\n"," b'02JAN1900 13:45:00' b'02JAN1900 13:50:00' b'02JAN1900 13:55:00'\n"," b'02JAN1900 14:00:00' b'02JAN1900 14:05:00' b'02JAN1900 14:10:00'\n"," b'02JAN1900 14:15:00' b'02JAN1900 14:20:00' b'02JAN1900 14:25:00'\n"," b'02JAN1900 14:30:00' b'02JAN1900 14:35:00' b'02JAN1900 14:40:00'\n"," b'02JAN1900 14:45:00' b'02JAN1900 14:50:00' b'02JAN1900 14:55:00'\n"," b'02JAN1900 15:00:00' b'02JAN1900 15:05:00' b'02JAN1900 15:10:00'\n"," b'02JAN1900 15:15:00' b'02JAN1900 15:20:00' b'02JAN1900 15:25:00'\n"," b'02JAN1900 15:30:00' b'02JAN1900 15:35:00' b'02JAN1900 15:40:00'\n"," b'02JAN1900 15:45:00' b'02JAN1900 15:50:00' b'02JAN1900 15:55:00'\n"," b'02JAN1900 16:00:00' b'02JAN1900 16:05:00' b'02JAN1900 16:10:00'\n"," b'02JAN1900 16:15:00' b'02JAN1900 16:20:00' b'02JAN1900 16:25:00'\n"," b'02JAN1900 16:30:00' b'02JAN1900 16:35:00' b'02JAN1900 16:40:00'\n"," b'02JAN1900 16:45:00' b'02JAN1900 16:50:00' b'02JAN1900 16:55:00'\n"," b'02JAN1900 17:00:00' b'02JAN1900 17:05:00' b'02JAN1900 17:10:00'\n"," b'02JAN1900 17:15:00' b'02JAN1900 17:20:00' b'02JAN1900 17:25:00'\n"," b'02JAN1900 17:30:00' b'02JAN1900 17:35:00' b'02JAN1900 17:40:00'\n"," b'02JAN1900 17:45:00' b'02JAN1900 17:50:00' b'02JAN1900 17:55:00'\n"," b'02JAN1900 18:00:00' b'02JAN1900 18:05:00' b'02JAN1900 18:10:00'\n"," b'02JAN1900 18:15:00' b'02JAN1900 18:20:00' b'02JAN1900 18:25:00'\n"," b'02JAN1900 18:30:00' b'02JAN1900 18:35:00' b'02JAN1900 18:40:00'\n"," b'02JAN1900 18:45:00' b'02JAN1900 18:50:00' b'02JAN1900 18:55:00'\n"," b'02JAN1900 19:00:00' b'02JAN1900 19:05:00' b'02JAN1900 19:10:00'\n"," b'02JAN1900 19:15:00' b'02JAN1900 19:20:00' b'02JAN1900 19:25:00'\n"," b'02JAN1900 19:30:00' b'02JAN1900 19:35:00' b'02JAN1900 19:40:00'\n"," b'02JAN1900 19:45:00' b'02JAN1900 19:50:00' b'02JAN1900 19:55:00'\n"," b'02JAN1900 20:00:00' b'02JAN1900 20:05:00' b'02JAN1900 20:10:00'\n"," b'02JAN1900 20:15:00' b'02JAN1900 20:20:00' b'02JAN1900 20:25:00'\n"," b'02JAN1900 20:30:00' b'02JAN1900 20:35:00' b'02JAN1900 20:40:00'\n"," b'02JAN1900 20:45:00' b'02JAN1900 20:50:00' b'02JAN1900 20:55:00'\n"," b'02JAN1900 21:00:00' b'02JAN1900 21:05:00' b'02JAN1900 21:10:00'\n"," b'02JAN1900 21:15:00' b'02JAN1900 21:20:00' b'02JAN1900 21:25:00'\n"," b'02JAN1900 21:30:00' b'02JAN1900 21:35:00' b'02JAN1900 21:40:00'\n"," b'02JAN1900 21:45:00' b'02JAN1900 21:50:00' b'02JAN1900 21:55:00'\n"," b'02JAN1900 22:00:00' b'02JAN1900 22:05:00' b'02JAN1900 22:10:00'\n"," b'02JAN1900 22:15:00' b'02JAN1900 22:20:00' b'02JAN1900 22:25:00'\n"," b'02JAN1900 22:30:00' b'02JAN1900 22:35:00' b'02JAN1900 22:40:00'\n"," b'02JAN1900 22:45:00' b'02JAN1900 22:50:00' b'02JAN1900 22:55:00'\n"," b'02JAN1900 23:00:00' b'02JAN1900 23:05:00' b'02JAN1900 23:10:00'\n"," b'02JAN1900 23:15:00' b'02JAN1900 23:20:00' b'02JAN1900 23:25:00'\n"," b'02JAN1900 23:30:00' b'02JAN1900 23:35:00' b'02JAN1900 23:40:00'\n"," b'02JAN1900 23:45:00' b'02JAN1900 23:50:00' b'02JAN1900 23:55:00'\n"," b'03JAN1900 00:00:00']\n"]}],"source":["# Example 24: Retrieving 2D Flow Area Solution Time Dates\n","print(\"\\nExample 24: Retrieving 2D Flow Area Solution Time Dates\")\n","\n","solution_time_dates = RasHdf.get_2d_area_solution_time_dates(hdf_input, ras_object=muncie)\n","\n","if solution_time_dates is not None:\n","    print(f\"Retrieved {len(solution_time_dates)} solution time dates:\")\n","    print(solution_time_dates)\n","else:\n","    print(\"No solution time dates found.\")\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Example 25: Loading 2D Flow Area Solutions\n","No solutions loaded.\n"]}],"source":["# Example 25: Loading 2D Flow Area Solutions\n","print(\"\\nExample 25: Loading 2D Flow Area Solutions\")\n","\n","# Load 2D area solutions using the revised method\n","solutions = RasHdf.load_2d_area_solutions(hdf_input, ras_object=muncie)\n","\n","# Check if solutions were successfully loaded\n","if solutions:\n","    # Access and display solution times\n","    solution_times_df = solutions.get('solution_times')\n","    if solution_times_df is not None:\n","        print(\"Solution Times:\")\n","        print(solution_times_df.head())\n","    else:\n","        print(\"Solution times not found.\")\n","    \n","    # Iterate through each 2D Flow Area and display sample data\n","    for key in solutions:\n","        if key != 'solution_times':\n","            print(f\"\\nData for {key}:\")\n","            area_df = solutions[key]\n","            print(area_df.head(10))  # Display first 10 records\n","else:\n","    print(\"No solutions loaded.\")\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-10-07 17:57:34,152 - ras_commander.RasHdf - INFO - Found 1 2D Flow Areas\n"]},{"name":"stdout","output_type":"stream","text":["\n","Example 29: Building Face FacePoints\n","FacePoints Indexes for the first face of the first 2D Flow Area:\n","[4 5]\n"]}],"source":["# Example 29: Building Face FacePoints\n","print(\"\\nExample 29: Building Face FacePoints\")\n","\n","face_facepoints_list = RasHdf.build_face_facepoints(hdf_input, ras_object=muncie)\n","\n","if face_facepoints_list:\n","    # Displaying face points indexes for the first face of the first 2D Flow Area\n","    print(\"FacePoints Indexes for the first face of the first 2D Flow Area:\")\n","    print(face_facepoints_list[0][0])  # Assuming at least one area and one face\n","else:\n","    print(\"No face facepoints built.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: C:\GH\ras-commander\examples\19_benchmarking_version_6.6.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasHdf, RasUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 16:34:37,515 - ras_commander.RasExamples - INFO - Example projects folder: c:\\AutoRAS_Temp\\Benchmarking 6.6\\example_projects\n",
      "2024-10-07 16:34:37,516 - ras_commander.RasExamples - INFO - Found zip file: c:\\AutoRAS_Temp\\Benchmarking 6.6\\Example_Projects_6_5.zip\n",
      "2024-10-07 16:34:37,516 - ras_commander.RasExamples - INFO - Loading project data from CSV...\n",
      "2024-10-07 16:34:37,518 - ras_commander.RasExamples - INFO - Loaded 66 projects from CSV. Use list_categories() and list_projects() to explore them.\n",
      "2024-10-07 16:34:37,518 - ras_commander.RasExamples - INFO - ----- RasExamples Extracting Project -----\n",
      "2024-10-07 16:34:37,518 - ras_commander.RasExamples - INFO - Extracting project 'BaldEagleCrkMulti2D'\n",
      "2024-10-07 16:34:37,519 - ras_commander.RasExamples - INFO - Project 'BaldEagleCrkMulti2D' already exists. Deleting existing folder...\n",
      "2024-10-07 16:34:37,553 - ras_commander.RasExamples - INFO - Existing folder for project 'BaldEagleCrkMulti2D' has been deleted.\n",
      "2024-10-07 16:34:38,681 - ras_commander.RasExamples - INFO - Successfully extracted project 'BaldEagleCrkMulti2D' to c:\\AutoRAS_Temp\\Benchmarking 6.6\\example_projects\\BaldEagleCrkMulti2D\n",
      "2024-10-07 16:34:38,682 - ras_commander.RasExamples - INFO - ----- RasExamples Extraction Complete -----\n"
     ]
    }
   ],
   "source": [
    "# Define versions to compare\n",
    "versions = ['6.6', '6.5', '6.4.1', '6.3.1', '6.2', '6.1', '5.0.7']\n",
    "\n",
    "# Extract BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "project_path = ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 16:34:38,687 - ras_commander.RasPrj - INFO - HEC-RAS executable found at default path: C:\\Program Files (x86)\\HEC\\HEC-RAS\\6.5\\Ras.exe\n",
      "2024-10-07 16:34:38,687 - ras_commander.RasPrj - INFO - Initializing global 'ras' object via init_ras_project function.\n",
      "2024-10-07 16:34:38,700 - ras_commander.RasPrj - INFO - Initialization complete for project: BaldEagleDamBrk\n",
      "2024-10-07 16:34:38,700 - ras_commander.RasPrj - INFO - Plan entries: 11, Flow entries: 0, Unsteady entries: 10, Geometry entries: 10, Boundary conditions: 51\n",
      "2024-10-07 16:34:38,700 - ras_commander.RasPrj - INFO - Project initialized. ras_instance project folder: c:\\AutoRAS_Temp\\Benchmarking 6.6\\example_projects\\BaldEagleCrkMulti2D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ras_commander.RasPrj.RasPrj object at 0x000001A1CFAD3810>\n",
      "['13', '15', '17', '18', '19', '03', '04', '02', '01', '05', '06']\n"
     ]
    }
   ],
   "source": [
    "# Get all plan numbers\n",
    "ras_project = init_ras_project(project_path, \"6.5\")\n",
    "print(ras_project)\n",
    "plan_numbers = ras_project.plan_df['plan_number'].tolist()\n",
    "print(plan_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for Version 6.6, Plan 13\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'default_path' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plan \u001b[38;5;129;01min\u001b[39;00m plan_numbers:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning simulation for Version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Plan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m     57\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m, in \u001b[0;36mrun_simulation\u001b[1;34m(version, plan_number)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_simulation\u001b[39m(version, plan_number):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Initialize project for the specific version\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     ras_project \u001b[38;5;241m=\u001b[39m \u001b[43minit_ras_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Clear geometry preprocessor files\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     plan_path \u001b[38;5;241m=\u001b[39m RasPlan\u001b[38;5;241m.\u001b[39mget_plan_path(plan_number, ras_object\u001b[38;5;241m=\u001b[39mras_project)\n",
      "File \u001b[1;32mc:\\Users\\billk\\AppData\\Local\\anaconda3\\envs\\fffff\\Lib\\site-packages\\ras_commander\\logging_config.py:69\u001b[0m, in \u001b[0;36mlog_call.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m log \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[0;32m     68\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\billk\\AppData\\Local\\anaconda3\\envs\\fffff\\Lib\\site-packages\\ras_commander\\RasPrj.py:722\u001b[0m, in \u001b[0;36minit_ras_project\u001b[1;34m(ras_project_folder, ras_version, ras_instance)\u001b[0m\n\u001b[0;32m    719\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified RAS project folder does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mras_project_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified RAS project folder does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mras_project_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please check the path and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 722\u001b[0m ras_exe_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_ras_exe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mras_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ras_instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    725\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing global \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mras\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object via init_ras_project function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\billk\\AppData\\Local\\anaconda3\\envs\\fffff\\Lib\\site-packages\\ras_commander\\logging_config.py:69\u001b[0m, in \u001b[0;36mlog_call.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m log \u001b[38;5;241m=\u001b[39m get_logger()\n\u001b[0;32m     68\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\billk\\AppData\\Local\\anaconda3\\envs\\fffff\\Lib\\site-packages\\ras_commander\\RasPrj.py:806\u001b[0m, in \u001b[0;36mget_ras_exe\u001b[1;34m(ras_version)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HEC-RAS version or path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mras_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, returning default path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdefault_path\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m#raise ValueError(f\"Invalid HEC-RAS version or path: {ras_version}\") # don't raise an error here, just return the default path\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(default_path)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'default_path' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from ras_commander import RasGeo\n",
    "\n",
    "def run_simulation(version, plan_number):\n",
    "    # Initialize project for the specific version\n",
    "    ras_project = init_ras_project(project_path, str(version))\n",
    "    \n",
    "    # Clear geometry preprocessor files\n",
    "    plan_path = RasPlan.get_plan_path(plan_number, ras_object=ras_project)\n",
    "    RasGeo.clear_geompre_files(plan_path, ras_object=ras_project)\n",
    "    \n",
    "    # Set number of cores to 6\n",
    "    RasPlan.set_num_cores(plan_number, \"6\", ras_object=ras_project)\n",
    "    \n",
    "    # Ensure geometry preprocessing is done\n",
    "    RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=ras_project)\n",
    "    \n",
    "    # Compute the plan\n",
    "    start_time = time.time()\n",
    "    success = RasCmdr.compute_plan(plan_number, ras_object=ras_project)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    if success:\n",
    "        # Get HDF file path\n",
    "        hdf_path = RasPlan.get_results_path(plan_number, ras_object=ras_project)\n",
    "        \n",
    "        # Extract data from HDF file\n",
    "        runtime_data = RasHdf.get_runtime_data(hdf_path, ras_object=ras_project)\n",
    "        \n",
    "        # Extract required information\n",
    "        preprocessor_time = runtime_data['Preprocessing Geometry (hr)'].values[0]\n",
    "        unsteady_compute_time = runtime_data['Unsteady Flow Computations (hr)'].values[0]\n",
    "        \n",
    "        # Get volume accounting data\n",
    "        volume_accounting = RasHdf.get_group_attributes_as_df(hdf_path, \"Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D\", ras_object=ras_project)\n",
    "        volume_error = volume_accounting['Volume Error (%)'].values[0]\n",
    "        \n",
    "        return {\n",
    "            'Version': version,\n",
    "            'Plan': plan_number,\n",
    "            'Preprocessor Time (hr)': preprocessor_time,\n",
    "            'Unsteady Compute Time (hr)': unsteady_compute_time,\n",
    "            'Volume Error (%)': volume_error,\n",
    "            'Total Time (hr)': total_time / 3600  # Convert seconds to hours\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run simulations for all versions and plans sequentially\n",
    "results = []\n",
    "for version in versions:\n",
    "    for plan in plan_numbers:\n",
    "        print(f\"Running simulation for Version {version}, Plan {plan}\")\n",
    "        result = run_simulation(version, plan)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"Completed: Version {version}, Plan {plan}\")\n",
    "        else:\n",
    "            print(f\"Failed: Version {version}, Plan {plan}\")\n",
    "\n",
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save initial results to CSV\n",
    "df.to_csv('save_initial_results.csv', index=False)\n",
    "\n",
    "print(\"Initial results saved to 'save_initial_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages across plans for each version\n",
    "df_avg = df.groupby('Version').mean().reset_index()\n",
    "\n",
    "# Create line graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Unsteady Runtime vs Version\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_avg['Version'], df_avg['Unsteady Compute Time (hr)'], marker='o')\n",
    "plt.title('Average Unsteady Runtime vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Unsteady Runtime (hours)')\n",
    "\n",
    "# Volume Error vs Version\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_avg['Version'], df_avg['Volume Error (%)'], marker='o')\n",
    "plt.title('Average Volume Error vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Volume Error (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "df.to_csv('hecras_version_comparison.csv', index=False)\n",
    "df_avg.to_csv('hecras_version_comparison_averages.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'hecras_version_comparison.csv' and 'hecras_version_comparison_averages.csv'\")\n",
    "print(\"Graphs have been displayed. Please check the output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fffff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: C:\GH\ras-commander\examples\run_all_HEC_example_projects.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation \n",
    "#  ** Use this version with Jupyter Notebooks **\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, ras\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, ras\n",
    "\n",
    "print(\"ras_commander imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "from ras_commander import RasExamples, RasCmdr, init_ras_project, RasPrj, RasUtils, ras\n",
    "\n",
    "# Load the list of projects from the CSV file\n",
    "projects_df = pd.read_csv(\"example_projects.csv\")\n",
    "\n",
    "# Initialize the RasExamples instance\n",
    "ras_examples = RasExamples()\n",
    "\n",
    "# Function to process a single project\n",
    "def process_project(project_name):\n",
    "    # Extract the project using RasExamples\n",
    "    extracted_paths = ras_examples.extract_project([project_name])\n",
    "    if not extracted_paths:\n",
    "        raise ValueError(f\"Failed to extract project: {project_name}\")\n",
    "    extracted_path = extracted_paths[0]\n",
    "    # Initialize the project\n",
    "    try:\n",
    "        project = RasPrj()\n",
    "        project = init_ras_project(ras_project_folder=Path(extracted_path), ras_version=\"6.5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize project {project_name}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Determine optimal core usage\n",
    "    physical_cores = psutil.cpu_count(logical=False)\n",
    "    print(f\"Physical cores: {physical_cores}\")\n",
    "    print(f\"Adjust the number of cores per plan and max workers as needed.\")\n",
    "\n",
    "    # Run all plans in parallel\n",
    "    try:\n",
    "        results = RasCmdr.compute_parallel(\n",
    "            max_workers=2,\n",
    "            num_cores=2,\n",
    "            ras_object=project,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run plans for project {project_name}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Log the results\n",
    "    for plan, success in results.items():\n",
    "        print(f\"Project: {project_name}, Plan: {plan}, Success: {success}\")\n",
    "\n",
    "    # Clean up extracted project\n",
    "    RasUtils.remove_with_retry(Path(extracted_path), is_folder=True)\n",
    "\n",
    "# Process each project listed in the CSV\n",
    "for _, row in projects_df.iterrows():\n",
    "    project_name = row['Project']\n",
    "\n",
    "    process_project(project_name)\n",
    "    print(f\"Processed project: {project_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "from ras_commander import RasCmdr, init_ras_project, RasPrj, RasUtils, ras\n",
    "\n",
    "print(\"Starting script execution\")\n",
    "\n",
    "# Function to process a single project\n",
    "def process_project(project_path):\n",
    "    project_name = project_path.name\n",
    "    print(f\"Processing project: {project_name}\")\n",
    "    # Initialize the project\n",
    "    try:\n",
    "        print(f\"Initializing project: {project_name}\")\n",
    "        project = RasPrj()\n",
    "        project = init_ras_project(ras_project_folder=project_path, ras_version=\"6.5\")\n",
    "        print(f\"Project {project_name} initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize project {project_name}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Determine optimal core usage\n",
    "    physical_cores = psutil.cpu_count(logical=False)\n",
    "    print(f\"Physical cores: {physical_cores}\")\n",
    "    print(f\"Adjust the number of cores per plan and max workers as needed.\")\n",
    "\n",
    "    # Run all plans in parallel\n",
    "    try:\n",
    "        print(f\"Starting parallel computation for project: {project_name}\")\n",
    "        results = RasCmdr.compute_parallel(\n",
    "            max_workers=2,\n",
    "            num_cores=2,\n",
    "            ras_object=project,\n",
    "        )\n",
    "        print(f\"Parallel computation completed for project: {project_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run plans for project {project_name}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Log the results\n",
    "    print(f\"Logging results for project: {project_name}\")\n",
    "    for plan, success in results.items():\n",
    "        print(f\"Project: {project_name}, Plan: {plan}, Success: {success}\")\n",
    "\n",
    "# Get user input for the parent folder\n",
    "parent_folder = Path(r\"C:\\GH\\ras-commander\\examples\\example_projects\")\n",
    "print(f\"Parent folder set to: {parent_folder}\")\n",
    "\n",
    "# Process each second-level subfolder as a project\n",
    "print(\"Starting to process projects\")\n",
    "for category_folder in parent_folder.iterdir():\n",
    "    if category_folder.is_dir():\n",
    "        print(f\"Processing category: {category_folder.name}\")\n",
    "        for project_folder in category_folder.iterdir():\n",
    "            if project_folder.is_dir():\n",
    "                print(f\"Found project folder: {project_folder}\")\n",
    "                process_project(project_folder)\n",
    "                print(f\"Processed project: {project_folder.name}\")\n",
    "\n",
    "print(\"Script execution completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdrnopip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: C:\GH\ras-commander\examples\xx_edge_cases.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

example_projects_folder = Path(__file__).parent.parent / "example_projects"

# delete the folder if it exists
if example_projects_folder.exists():
    shutil.rmtree(example_projects_folder)


# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan using compute_test_mode
    print("Example 1: Executing a single plan using compute_test_mode")
    single_plan = "01"
    dest_folder_suffix = "[SinglePlanTest]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number=single_plan,
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print(f"Execution of plan {single_plan} completed using compute_test_mode")
    print()

    # Example 2: Execute a single plan using compute_parallel
    print("Example 2: Executing a single plan using compute_parallel")
    parallel_result_folder = project_path.parent / "parallel_single_plan_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number=single_plan,
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute a single plan using compute_test_mode with a string input
    print("Example 3: Executing a single plan using compute_test_mode with a string input")
    dest_folder_suffix = "[SinglePlanTestString]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number="02",
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print("Execution of plan 02 completed using compute_test_mode with string input")
    print()

    # Example 4: Execute a single plan using compute_parallel with a string input
    print("Example 4: Executing a single plan using compute_parallel with a string input")
    parallel_result_folder = project_path.parent / "parallel_single_plan_string_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number="01",  # Changed from "03" to "01"
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan (string input) results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 5: Attempt to execute with an empty plan list
    print("Example 5: Attempting to execute with an empty plan list")
    dest_folder_suffix = "[EmptyPlanList]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=[], dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

    # Example 6: Attempt to execute with a non-existent plan number
    print("Example 6: Attempting to execute with a non-existent plan number")
    non_existent_plan = "99"
    dest_folder_suffix = "[NonExistentPlan]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=non_existent_plan, dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

if __name__ == "__main__":
    main()
==================================================

File: C:\GH\ras-commander\ras_commander\logging_config.py
==================================================
# logging_config.py

import logging
import logging.handlers
from pathlib import Path
import functools

# Define log levels
DEBUG = logging.DEBUG
INFO = logging.INFO
WARNING = logging.WARNING
ERROR = logging.ERROR
CRITICAL = logging.CRITICAL


_logging_setup_done = False

def setup_logging(log_file=None, log_level=logging.INFO):
    """Set up logging configuration for the ras-commander library."""
    global _logging_setup_done
    if _logging_setup_done:
        return
    
    # Define log format
    log_format = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Configure console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_format)

    # Set up root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(log_level)
    root_logger.addHandler(console_handler)

    # Configure file handler if log_file is provided
    if log_file:
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        log_file_path = log_dir / log_file

        file_handler = logging.handlers.RotatingFileHandler(
            log_file_path, maxBytes=10*1024*1024, backupCount=5
        )
        file_handler.setFormatter(log_format)
        root_logger.addHandler(file_handler)
    
    _logging_setup_done = True

def get_logger(name):
    """Get a logger for a specific module."""
    return logging.getLogger(name)

def log_call(logger=None):
    """Decorator to log function calls."""
    def get_logger():
        # Check if logger is None or doesn't have a debug method
        if logger is None or not hasattr(logger, 'debug'):
            return logging.getLogger(__name__)
        return logger

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            log = get_logger()
            log.debug(f"Calling {func.__name__}")
            result = func(*args, **kwargs)
            log.debug(f"Finished {func.__name__}")
            return result
        return wrapper
    
    # Check if we're being called as @log_call or @log_call()
    if callable(logger):
        return decorator(logger)
    return decorator

# Set up logging when this module is imported
setup_logging()
==================================================

File: C:\GH\ras-commander\ras_commander\RasCmdr.py
==================================================
"""
RasCmdr - Execution operations for running HEC-RAS simulations

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).

Example:
    @log_call
    def my_function():
        
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
import subprocess
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from .RasPrj import ras, RasPrj, init_ras_project, get_ras_exe
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUtils import RasUtils
import logging
import time
import queue
from threading import Thread, Lock
from typing import Union, List, Optional, Dict
from pathlib import Path
import shutil
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Thread
from itertools import cycle
from ras_commander.RasPrj import RasPrj  # Ensure RasPrj is imported
from threading import Lock, Thread, current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import cycle
from typing import Union, List, Optional, Dict
from ras_commander.logging_config import get_logger, log_call

logger = get_logger(__name__)

# Module code starts here

# TODO: Future Enhancements
# 1. Alternate Run Mode for compute_plan and compute_parallel:
#    - Use Powershell to execute HEC-RAS command
#    - Hide RAS window and all child windows
#    - Note: This mode may prevent execution if the plan has a popup
#    - Intended for background runs or popup-free scenarios
#    - Limit to non-commercial use
#
# 2. Implement compute_plan_remote:
#    - Execute compute_plan on a remote machine via psexec
#    - Use keyring package for secure credential storage
#    - Implement psexec command for remote HEC-RAS execution
#    - Create remote_worker objects to store machine details:
#      (machine name, username, password, ras_exe_path, local folder path, etc.)
#    - Develop RasRemote class for remote_worker management and abstractions
#    - Implement compute_plan_remote in RasCmdr as a thin wrapper around RasRemote
#      (similar to existing compute_plan functions but for remote execution)


class RasCmdr:
    
    @staticmethod
    @log_call
    def compute_plan(
        plan_number,
        dest_folder=None, 
        ras_object=None,
        clear_geompre=False,
        num_cores=None,
        overwrite_dest=False
    ):
        """
        Execute a HEC-RAS plan.

        Args:
            plan_number (str, Path): The plan number to execute (e.g., "01", "02") or the full path to the plan file.
            dest_folder (str, Path, optional): Name of the folder or full path for computation.
                If a string is provided, it will be created in the same parent directory as the project folder.
                If a full path is provided, it will be used as is.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files. Defaults to False.
            num_cores (int, optional): Number of cores to use for the plan execution. If None, the current setting is not changed.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            bool: True if the execution was successful, False otherwise.

        Raises:
            ValueError: If the specified dest_folder already exists and is not empty, and overwrite_dest is False.
        """
        try:
            ras_obj = ras_object if ras_object is not None else ras
            logger.info(f"Using ras_object with project folder: {ras_obj.project_folder}")
            ras_obj.check_initialized()
            
            if dest_folder is not None:
                dest_folder = Path(ras_obj.project_folder).parent / dest_folder if isinstance(dest_folder, str) else Path(dest_folder)
                
                if dest_folder.exists():
                    if overwrite_dest:
                        shutil.rmtree(dest_folder)
                        logger.info(f"Destination folder '{dest_folder}' exists. Overwriting as per overwrite_dest=True.")
                    elif any(dest_folder.iterdir()):
                        error_msg = f"Destination folder '{dest_folder}' exists and is not empty. Use overwrite_dest=True to overwrite."
                        logger.error(error_msg)
                        raise ValueError(error_msg)
                
                dest_folder.mkdir(parents=True, exist_ok=True)
                shutil.copytree(ras_obj.project_folder, dest_folder, dirs_exist_ok=True)
                logger.info(f"Copied project folder to destination: {dest_folder}")
                
                compute_ras = RasPrj()
                compute_ras.initialize(dest_folder, ras_obj.ras_exe_path)
                compute_prj_path = compute_ras.prj_file
            else:
                compute_ras = ras_obj
                compute_prj_path = ras_obj.prj_file

            # Determine the plan path
            compute_plan_path = Path(plan_number) if isinstance(plan_number, (str, Path)) and Path(plan_number).is_file() else RasPlan.get_plan_path(plan_number, compute_ras)

            if not compute_prj_path or not compute_plan_path:
                logger.error(f"Could not find project file or plan file for plan {plan_number}")
                return False

            # Clear geometry preprocessor files if requested
            if clear_geompre:
                try:
                    RasGeo.clear_geompre_files(compute_plan_path, ras_object=compute_ras)
                    logger.info(f"Cleared geometry preprocessor files for plan: {plan_number}")
                except Exception as e:
                    logger.error(f"Error clearing geometry preprocessor files for plan {plan_number}: {str(e)}")

            # Set the number of cores if specified
            if num_cores is not None:
                try:
                    RasPlan.set_num_cores(compute_plan_path, num_cores=num_cores, ras_object=compute_ras)
                    logger.info(f"Set number of cores to {num_cores} for plan: {plan_number}")
                except Exception as e:
                    logger.error(f"Error setting number of cores for plan {plan_number}: {str(e)}")

            # Prepare the command for HEC-RAS execution
            cmd = f'"{compute_ras.ras_exe_path}" -c "{compute_prj_path}" "{compute_plan_path}"'
            logger.info("Running HEC-RAS from the Command Line:")
            logger.info(f"Running command: {cmd}")

            # Execute the HEC-RAS command
            start_time = time.time()
            try:
                subprocess.run(cmd, check=True, shell=True, capture_output=True, text=True)
                end_time = time.time()
                run_time = end_time - start_time
                logger.info(f"HEC-RAS execution completed for plan: {plan_number}")
                logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
                return True
            except subprocess.CalledProcessError as e:
                end_time = time.time()
                run_time = end_time - start_time
                logger.error(f"Error running plan: {plan_number}")
                logger.error(f"Error message: {e.output}")
                logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
                return False
        except Exception as e:
            logger.critical(f"Error in compute_plan: {str(e)}")
            return False
        finally:
            # Update the RAS object's dataframes
            if ras_obj:
                ras_obj.plan_df = ras_obj.get_plan_entries()
                ras_obj.geom_df = ras_obj.get_geom_entries()
                ras_obj.flow_df = ras_obj.get_flow_entries()
                ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    


    @staticmethod
    @log_call
    @staticmethod
    @log_call
    def compute_parallel(
        plan_number: Union[str, List[str], None] = None,
        max_workers: int = 2,
        num_cores: int = 2,
        clear_geompre: bool = False,
        ras_object: Optional['RasPrj'] = None,
        dest_folder: Union[str, Path, None] = None,
        overwrite_dest: bool = False
    ) -> Dict[str, bool]:
        """
        Compute multiple HEC-RAS plans in parallel.

        Args:
            plan_number (Union[str, List[str], None]): Plan number(s) to compute. If None, all plans are computed.
            max_workers (int): Maximum number of parallel workers.
            num_cores (int): Number of cores to use per plan computation.
            clear_geompre (bool): Whether to clear geometry preprocessor files.
            ras_object (Optional[RasPrj]): RAS project object. If None, uses global instance.
            dest_folder (Union[str, Path, None]): Destination folder for computed results.
            overwrite_dest (bool): Whether to overwrite existing destination folder.

        Returns:
            Dict[str, bool]: Dictionary of plan numbers and their execution success status.
        """
        try:
            ras_obj = ras_object or ras
            ras_obj.check_initialized()

            project_folder = Path(ras_obj.project_folder)

            if dest_folder is not None:
                dest_folder_path = Path(dest_folder)
                if dest_folder_path.exists():
                    if overwrite_dest:
                        shutil.rmtree(dest_folder_path)
                        logger.info(f"Destination folder '{dest_folder_path}' exists. Overwriting as per overwrite_dest=True.")
                    elif any(dest_folder_path.iterdir()):
                        error_msg = f"Destination folder '{dest_folder_path}' exists and is not empty. Use overwrite_dest=True to overwrite."
                        logger.error(error_msg)
                        raise ValueError(error_msg)
                dest_folder_path.mkdir(parents=True, exist_ok=True)
                shutil.copytree(project_folder, dest_folder_path, dirs_exist_ok=True)
                logger.info(f"Copied project folder to destination: {dest_folder_path}")
                project_folder = dest_folder_path

            if plan_number:
                if isinstance(plan_number, str):
                    plan_number = [plan_number]
                ras_obj.plan_df = ras_obj.plan_df[ras_obj.plan_df['plan_number'].isin(plan_number)]
                logger.info(f"Filtered plans to execute: {plan_number}")

            num_plans = len(ras_obj.plan_df)
            max_workers = min(max_workers, num_plans) if num_plans > 0 else 1
            logger.info(f"Adjusted max_workers to {max_workers} based on the number of plans: {num_plans}")

            worker_ras_objects = {}
            for worker_id in range(1, max_workers + 1):
                worker_folder = project_folder.parent / f"{project_folder.name} [Worker {worker_id}]"
                if worker_folder.exists():
                    shutil.rmtree(worker_folder)
                    logger.info(f"Removed existing worker folder: {worker_folder}")
                shutil.copytree(project_folder, worker_folder)
                logger.info(f"Created worker folder: {worker_folder}")

                try:
                    ras_instance = RasPrj()
                    worker_ras_instance = init_ras_project(
                        ras_project_folder=worker_folder,
                        ras_version=ras_obj.ras_exe_path,
                        ras_instance=ras_instance
                    )
                    worker_ras_objects[worker_id] = worker_ras_instance
                except Exception as e:
                    logger.critical(f"Failed to initialize RAS project for worker {worker_id}: {str(e)}")
                    worker_ras_objects[worker_id] = None

            worker_cycle = cycle(range(1, max_workers + 1))
            plan_assignments = [(next(worker_cycle), plan_num) for plan_num in ras_obj.plan_df['plan_number']]

            execution_results: Dict[str, bool] = {}

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(
                        RasCmdr.compute_plan,
                        plan_num, 
                        ras_object=worker_ras_objects[worker_id], 
                        clear_geompre=clear_geompre,
                        num_cores=num_cores
                    )
                    for worker_id, plan_num in plan_assignments
                ]

                for future, (worker_id, plan_num) in zip(as_completed(futures), plan_assignments):
                    try:
                        success = future.result()
                        execution_results[plan_num] = success
                        logger.info(f"Plan {plan_num} executed in worker {worker_id}: {'Successful' if success else 'Failed'}")
                    except Exception as e:
                        execution_results[plan_num] = False
                        logger.error(f"Plan {plan_num} failed in worker {worker_id}: {str(e)}")

            final_dest_folder = dest_folder_path if dest_folder is not None else project_folder.parent / f"{project_folder.name} [Computed]"
            final_dest_folder.mkdir(parents=True, exist_ok=True)
            logger.info(f"Final destination for computed results: {final_dest_folder}")

            for worker_ras in worker_ras_objects.values():
                if worker_ras is None:
                    continue
                worker_folder = Path(worker_ras.project_folder)
                try:
                    for item in worker_folder.iterdir():
                        dest_path = final_dest_folder / item.name
                        if dest_path.exists():
                            if dest_path.is_dir():
                                shutil.rmtree(dest_path)
                                logger.debug(f"Removed existing directory at {dest_path}")
                            else:
                                dest_path.unlink()
                                logger.debug(f"Removed existing file at {dest_path}")
                        shutil.move(str(item), final_dest_folder)
                        logger.debug(f"Moved {item} to {final_dest_folder}")
                    shutil.rmtree(worker_folder)
                    logger.info(f"Removed worker folder: {worker_folder}")
                except Exception as e:
                    logger.error(f"Error moving results from {worker_folder} to {final_dest_folder}: {str(e)}")

            try:
                final_dest_folder_ras_obj = RasPrj()
                final_dest_folder_ras_obj = init_ras_project(
                    ras_project_folder=final_dest_folder, 
                    ras_version=ras_obj.ras_exe_path,
                    ras_instance=final_dest_folder_ras_obj
                )
                final_dest_folder_ras_obj.check_initialized()
            except Exception as e:
                logger.critical(f"Failed to initialize RasPrj for final destination: {str(e)}")

            logger.info("\nExecution Results:")
            for plan_num, success in execution_results.items():
                status = 'Successful' if success else 'Failed'
                logger.info(f"Plan {plan_num}: {status}")

            ras_obj = ras_object or ras
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

            return execution_results

        except Exception as e:
            logger.critical(f"Error in compute_parallel: {str(e)}")
            return {}

    @staticmethod
    @log_call
    def compute_test_mode(
        plan_number=None, 
        dest_folder_suffix="[Test]", 
        clear_geompre=False, 
        num_cores=None, 
        ras_object=None,
        overwrite_dest=False
    ):
        """
        Execute HEC-RAS plans in test mode. This is a re-creation of the HEC-RAS command line -test flag, 
        which does not work in recent versions of HEC-RAS.
        
        As a special-purpose function that emulates the original -test flag, it operates differently than the 
        other two compute_ functions. Per the original HEC-RAS test flag, it creates a separate test folder,
        copies the project there, and executes the specified plans in sequential order.
        
        For most purposes, just copying a the project folder, initing that new folder, then running each plan 
        with compute_plan is a simpler and more flexible approach.  This is shown in the examples provided
        in the ras-commander library.

        Args:
            plan_number (str, list[str], optional): Plan number or list of plan numbers to execute. 
                If None, all plans will be executed. Default is None.
            dest_folder_suffix (str, optional): Suffix to append to the test folder name to create dest_folder. 
                Defaults to "[Test]".
                dest_folder is always created in the project folder's parent directory.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files.
                Defaults to False.
            num_cores (int, optional): Maximum number of cores to use for each plan.
                If None, the current setting is not changed. Default is None.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            Dict[str, bool]: Dictionary of plan numbers and their execution success status.

        Example:
            Run all plans: RasCommander.compute_test_mode()
            Run a specific plan: RasCommander.compute_test_mode(plan_number="01")
            Run multiple plans: RasCommander.compute_test_mode(plan_number=["01", "03", "05"])
            Run plans with a custom folder suffix: RasCommander.compute_test_mode(dest_folder_suffix="[TestRun]")
            Run plans and clear geometry preprocessor files: RasCommander.compute_test_mode(clear_geompre=True)
            Run plans with a specific number of cores: RasCommander.compute_test_mode(num_cores=4)
            
        Notes:
            - This function executes plans in a separate folder for isolated testing.
            - If plan_number is not provided, all plans in the project will be executed.
            - The function does not change the geometry preprocessor and IB tables settings.  
                - To force recomputing of geometry preprocessor and IB tables, use the clear_geompre=True option.
            - Plans are executed sequentially.
            - Because copying the project is implicit, only a dest_folder_suffix option is provided.
            - For more flexible run management, use the compute_parallel or compute_sequential functions.
        """
        try:
            ras_obj = ras_object or ras
            ras_obj.check_initialized()
            
            logger.info("Starting the compute_test_mode...")
               
            project_folder = Path(ras_obj.project_folder)

            if not project_folder.exists():
                logger.error(f"Project folder '{project_folder}' does not exist.")
                return {}

            compute_folder = project_folder.parent / f"{project_folder.name} {dest_folder_suffix}"
            logger.info(f"Creating the test folder: {compute_folder}...")

            if compute_folder.exists():
                if overwrite_dest:
                    shutil.rmtree(compute_folder)
                    logger.info(f"Compute folder '{compute_folder}' exists. Overwriting as per overwrite_dest=True.")
                elif any(compute_folder.iterdir()):
                    error_msg = (
                        f"Compute folder '{compute_folder}' exists and is not empty. "
                        "Use overwrite_dest=True to overwrite."
                    )
                    logger.error(error_msg)
                    raise ValueError(error_msg)

            try:
                shutil.copytree(project_folder, compute_folder)
                logger.info(f"Copied project folder to compute folder: {compute_folder}")
            except Exception as e:
                logger.critical(f"Error occurred while copying project folder: {str(e)}")
                return {}

            try:
                compute_ras = RasPrj()
                compute_ras.initialize(compute_folder, ras_obj.ras_exe_path)
                compute_prj_path = compute_ras.prj_file
                logger.info(f"Initialized RAS project in compute folder: {compute_prj_path}")
            except Exception as e:
                logger.critical(f"Error initializing RAS project in compute folder: {str(e)}")
                return {}

            if not compute_prj_path:
                logger.error("Project file not found.")
                return {}

            logger.info("Getting plan entries...")
            try:
                ras_compute_plan_entries = compute_ras.plan_df
                logger.info("Retrieved plan entries successfully.")
            except Exception as e:
                logger.critical(f"Error retrieving plan entries: {str(e)}")
                return {}

            if plan_number:
                if isinstance(plan_number, str):
                    plan_number = [plan_number]
                ras_compute_plan_entries = ras_compute_plan_entries[
                    ras_compute_plan_entries['plan_number'].isin(plan_number)
                ]
                logger.info(f"Filtered plans to execute: {plan_number}")

            execution_results = {}
            logger.info("Running selected plans sequentially...")
            for _, plan in ras_compute_plan_entries.iterrows():
                plan_number = plan["plan_number"]
                start_time = time.time()
                try:
                    success = RasCmdr.compute_plan(
                        plan_number,
                        ras_object=compute_ras,
                        clear_geompre=clear_geompre,
                        num_cores=num_cores
                    )
                    execution_results[plan_number] = success
                    if success:
                        logger.info(f"Successfully computed plan {plan_number}")
                    else:
                        logger.error(f"Failed to compute plan {plan_number}")
                except Exception as e:
                    execution_results[plan_number] = False
                    logger.error(f"Error computing plan {plan_number}: {str(e)}")
                finally:
                    end_time = time.time()
                    run_time = end_time - start_time
                    logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")

            logger.info("All selected plans have been executed.")
            logger.info("compute_test_mode completed.")

            logger.info("\nExecution Results:")
            for plan_num, success in execution_results.items():
                status = 'Successful' if success else 'Failed'
                logger.info(f"Plan {plan_num}: {status}")

            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

            return execution_results

        except Exception as e:
            logger.critical(f"Error in compute_test_mode: {str(e)}")
            return {}
==================================================

File: C:\GH\ras-commander\ras_commander\RasExamples.py
==================================================
"""
RasExamples - Manage and load HEC-RAS example projects for testing and development

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function():
        logger = logging.getLogger(__name__)
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
import requests
import zipfile
import pandas as pd
from pathlib import Path
import shutil
from typing import Union, List
import csv
from datetime import datetime
import logging
import re
from tqdm import tqdm
from ras_commander import get_logger
from ras_commander.logging_config import log_call

logger = get_logger(__name__)

class RasExamples:
    """
    A class for quickly loading HEC-RAS example projects for testing and development of ras-commander.

    This class provides functionality to download, extract, and manage HEC-RAS example projects.
    It supports both default HEC-RAS example projects and custom projects from user-provided URLs.
    Additionally, it includes functionality to download FEMA's Base Level Engineering (BLE) models
    from CSV files provided by the FEMA Estimated Base Flood Elevation (BFE) Viewer.
    """
    @log_call
    def __init__(self):
        """
        Initialize the RasExamples class.
        """
        self.base_url = 'https://github.com/HydrologicEngineeringCenter/hec-downloads/releases/download/'
        self.valid_versions = [
            "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
            "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
            "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
        ]
        self.base_dir = Path.cwd()
        self.examples_dir = self.base_dir
        self.projects_dir = self.examples_dir / 'example_projects'
        self.zip_file_path = None
        self.folder_df = None
        self.csv_file_path = self.examples_dir / 'example_projects.csv'

        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"Example projects folder: {self.projects_dir}")
        self._load_project_data()

    @log_call
    def _load_project_data(self):
        """
        Load project data from CSV if up-to-date, otherwise extract from zip.
        """
        self._find_zip_file()
        
        if not self.zip_file_path:
            logger.info("No example projects zip file found. Downloading...")
            self.get_example_projects()
        
        try:
            zip_modified_time = os.path.getmtime(self.zip_file_path)
        except FileNotFoundError:
            logger.error(f"Zip file not found at {self.zip_file_path}.")
            return
        
        if self.csv_file_path.exists():
            csv_modified_time = os.path.getmtime(self.csv_file_path)
            
            if csv_modified_time >= zip_modified_time:
                logger.info("Loading project data from CSV...")
                try:
                    self.folder_df = pd.read_csv(self.csv_file_path)
                    logger.info(f"Loaded {len(self.folder_df)} projects from CSV. Use list_categories() and list_projects() to explore them.")
                except Exception as e:
                    logger.error(f"Failed to read CSV file: {e}")
                    self.folder_df = None
                return

        logger.info("Extracting folder structure from zip file...")
        self._extract_folder_structure()
        self._save_to_csv()

    @log_call
    def _find_zip_file(self):
        """Locate the example projects zip file in the examples directory."""
        for version in self.valid_versions:
            potential_zip = self.examples_dir / f"Example_Projects_{version.replace('.', '_')}.zip"
            if potential_zip.exists():
                self.zip_file_path = potential_zip
                logger.info(f"Found zip file: {self.zip_file_path}")
                break
        else:
            logger.warning("No existing example projects zip file found.")

    @log_call
    def _extract_folder_structure(self):
        """
        Extract folder structure from the zip file.

        Populates folder_df with category and project information.
        """
        folder_data = []
        try:
            with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                for file in zip_ref.namelist():
                    parts = Path(file).parts
                    if len(parts) > 2:
                        folder_data.append({
                            'Category': parts[1],
                            'Project': parts[2]
                        })
        
            self.folder_df = pd.DataFrame(folder_data).drop_duplicates()
            logger.info(f"Extracted {len(self.folder_df)} projects.")
            logger.debug(f"folder_df:\n{self.folder_df}")
        except zipfile.BadZipFile:
            logger.error(f"The file {self.zip_file_path} is not a valid zip file.")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])
        except Exception as e:
            logger.error(f"An error occurred while extracting the folder structure: {str(e)}")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])

    @log_call
    def _save_to_csv(self):
        """Save the extracted folder structure to CSV file."""
        if self.folder_df is not None and not self.folder_df.empty:
            try:
                self.folder_df.to_csv(self.csv_file_path, index=False)
                logger.info(f"Saved project data to {self.csv_file_path}")
            except Exception as e:
                logger.error(f"Failed to save project data to CSV: {e}")
        else:
            logger.warning("No folder data to save to CSV.")

    @log_call
    def get_example_projects(self, version_number='6.5'):
        """
        Download and extract HEC-RAS example projects for a specified version.
        """
        logger.info(f"Getting example projects for version {version_number}")
        if version_number not in self.valid_versions:
            error_msg = f"Invalid version number. Valid versions are: {', '.join(self.valid_versions)}"
            logger.error(error_msg)
            raise ValueError(error_msg)

        zip_url = f"{self.base_url}1.0.31/Example_Projects_{version_number.replace('.', '_')}.zip"
        
        self.examples_dir.mkdir(parents=True, exist_ok=True)
        
        self.zip_file_path = self.examples_dir / f"Example_Projects_{version_number.replace('.', '_')}.zip"

        if not self.zip_file_path.exists():
            logger.info(f"Downloading HEC-RAS Example Projects from {zip_url}. \nThe file is over 400 MB, so it may take a few minutes to download....")
            try:
                response = requests.get(zip_url, stream=True)
                response.raise_for_status()
                with open(self.zip_file_path, 'wb') as file:
                    shutil.copyfileobj(response.raw, file)
                logger.info(f"Downloaded to {self.zip_file_path}")
            except requests.exceptions.RequestException as e:
                logger.error(f"Failed to download the zip file: {e}")
                raise
        else:
            logger.info("HEC-RAS Example Projects zip file already exists. Skipping download.")

        self._load_project_data()
        return self.projects_dir

    @log_call
    def list_categories(self):
        """
        List all categories of example projects.
        """
        if self.folder_df is None or 'Category' not in self.folder_df.columns:
            logger.warning("No categories available. Make sure the zip file is properly loaded.")
            return []
        categories = self.folder_df['Category'].unique()
        logger.info(f"Available categories: {', '.join(categories)}")
        return categories.tolist()

    @log_call
    def list_projects(self, category=None):
        """
        List all projects or projects in a specific category.
        """
        if self.folder_df is None:
            logger.warning("No projects available. Make sure the zip file is properly loaded.")
            return []
        if category:
            projects = self.folder_df[self.folder_df['Category'] == category]['Project'].unique()
            logger.info(f"Projects in category '{category}': {', '.join(projects)}")
        else:
            projects = self.folder_df['Project'].unique()
            logger.info(f"All available projects: {', '.join(projects)}")
        return projects.tolist()

    @log_call
    def extract_project(self, project_names: Union[str, List[str]]):
        """
        Extract one or more specific HEC-RAS projects from the zip file.
        """
        if isinstance(project_names, str):
            project_names = [project_names]

        extracted_paths = []

        for project_name in project_names:
            logger.info("----- RasExamples Extracting Project -----")
            logger.info(f"Extracting project '{project_name}'")
            project_path = self.projects_dir / project_name

            if project_path.exists():
                logger.info(f"Project '{project_name}' already exists. Deleting existing folder...")
                try:
                    shutil.rmtree(project_path)
                    logger.info(f"Existing folder for project '{project_name}' has been deleted.")
                except Exception as e:
                    logger.error(f"Failed to delete existing project folder '{project_name}': {e}")
                    continue

            if self.folder_df is None or self.folder_df.empty:
                error_msg = "No project information available. Make sure the zip file is properly loaded."
                logger.error(error_msg)
                raise ValueError(error_msg)

            project_info = self.folder_df[self.folder_df['Project'] == project_name]
            if project_info.empty:
                error_msg = f"Project '{project_name}' not found in the zip file."
                logger.error(error_msg)
                raise ValueError(error_msg)

            category = project_info['Category'].iloc[0]
            
            # Ensure the project directory exists
            project_path.mkdir(parents=True, exist_ok=True)

            try:
                with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                    for file in zip_ref.namelist():
                        parts = Path(file).parts
                        if len(parts) > 2 and parts[2] == project_name:
                            # Remove the first two levels (category and project name)
                            relative_path = Path(*parts[3:])
                            extract_path = project_path / relative_path
                            if file.endswith('/'):
                                extract_path.mkdir(parents=True, exist_ok=True)
                            else:
                                extract_path.parent.mkdir(parents=True, exist_ok=True)
                                with zip_ref.open(file) as source, open(extract_path, "wb") as target:
                                    shutil.copyfileobj(source, target)

                logger.info(f"Successfully extracted project '{project_name}' to {project_path}")
                extracted_paths.append(project_path)
            except zipfile.BadZipFile:
                logger.error(f"Error: The file {self.zip_file_path} is not a valid zip file.")
            except FileNotFoundError:
                logger.error(f"Error: The file {self.zip_file_path} was not found.")
            except Exception as e:
                logger.error(f"An unexpected error occurred while extracting the project: {str(e)}")
            logger.info("----- RasExamples Extraction Complete -----")
        return extracted_paths

    @log_call
    def is_project_extracted(self, project_name):
        """
        Check if a specific project is already extracted.
        """
        project_path = self.projects_dir / project_name
        is_extracted = project_path.exists()
        logger.info(f"Project '{project_name}' extracted: {is_extracted}")
        return is_extracted

    @log_call
    def clean_projects_directory(self):
        """Remove all extracted projects from the example_projects directory."""
        logger.info(f"Cleaning projects directory: {self.projects_dir}")
        if self.projects_dir.exists():
            try:
                shutil.rmtree(self.projects_dir)
                logger.info("All projects have been removed.")
            except Exception as e:
                logger.error(f"Failed to remove projects directory: {e}")
        else:
            logger.warning("Projects directory does not exist.")
        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logger.info("Projects directory cleaned and recreated.")


    @log_call
    def download_fema_ble_model(self, huc8, output_dir=None):
        """
        Download a FEMA Base Level Engineering (BLE) model for a given HUC8.

        Args:
            huc8 (str): The 8-digit Hydrologic Unit Code (HUC) for the desired watershed.
            output_dir (str, optional): The directory to save the downloaded files. If None, uses the current working directory.

        Returns:
            str: The path to the downloaded and extracted model directory.

        Note:
            This method downloads the BLE model from the FEMA website and extracts it to the specified directory.
        """
        # Method implementation...

    @log_call
    def _make_safe_folder_name(self, name: str) -> str:
        """
        Convert a string to a safe folder name by replacing unsafe characters with underscores.
        """
        safe_name = re.sub(r'[^a-zA-Z0-9_\-]', '_', name)
        logger.debug(f"Converted '{name}' to safe folder name '{safe_name}'")
        return safe_name

    @log_call
    def _download_file_with_progress(self, url: str, dest_folder: Path, file_size: int) -> Path:
        """
        Download a file from a URL to a specified destination folder with progress bar.
        """
        local_filename = dest_folder / url.split('/')[-1]
        try:
            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(local_filename, 'wb') as f, tqdm(
                    desc=local_filename.name,
                    total=file_size,
                    unit='iB',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as progress_bar:
                    for chunk in r.iter_content(chunk_size=8192):
                        size = f.write(chunk)
                        progress_bar.update(size)
            logger.info(f"Successfully downloaded {url} to {local_filename}")
            return local_filename
        except requests.exceptions.RequestException as e:
            logger.error(f"Request failed for {url}: {e}")
            raise
        except Exception as e:
            logger.error(f"Failed to write file {local_filename}: {e}")
            raise

    @log_call
    def _convert_size_to_bytes(self, size_str: str) -> int:
        """
        Convert a human-readable file size to bytes.
        """
        units = {'B': 1, 'KB': 1024, 'MB': 1024**2, 'GB': 1024**3, 'TB': 1024**4}
        size_str = size_str.upper().replace(' ', '')
        if not re.match(r'^\d+(\.\d+)?[BKMGT]B?$', size_str):
            raise ValueError(f"Invalid size string: {size_str}")
        
        number, unit = float(re.findall(r'[\d\.]+', size_str)[0]), re.findall(r'[BKMGT]B?', size_str)[0]
        return int(number * units[unit])

    # Example usage:
    # ras_examples = RasExamples()
    # ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
    # extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
    # for path in extracted_paths:
    #     logger.info(f"Extracted to: {path}")


"""
### How to Use the Revised `RasExamples` Class

1. **Instantiate the Class:**
   ```python
   ras_examples = RasExamples()
   ```

2. **Download FEMA BLE Models:**
   - Ensure you have the required CSV files by visiting [FEMA's Estimated Base Flood Elevation (BFE) Viewer](https://webapps.usgs.gov/infrm/estBFE/) and using the "Download as Table" option for each BLE model you wish to access.
   - Call the `download_fema_ble_models` method with the appropriate paths:
     ```python
     ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
     ```
     - Replace `'/path/to/csv/files'` with the directory containing your CSV files.
     - Replace `'/path/to/output/folder'` with the directory where you want the BLE models to be downloaded and organized.

3. **Extract Projects (If Needed):**
   - After downloading, you can extract specific projects using the existing `extract_project` method:
     ```python
     extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
     for path in extracted_paths:
         logging.info(f"Extracted to: {path}")
     ```

4. **Explore Projects and Categories:**
   - List available categories:
     ```python
     categories = ras_examples.list_categories()
     ```
   - List projects within a specific category:
     ```python
     projects = ras_examples.list_projects(category='SomeCategory')
     ```

5. **Clean Projects Directory (If Needed):**
   - To remove all extracted projects:
     ```python
     ras_examples.clean_projects_directory()
     ```

### Dependencies

Ensure that the following Python packages are installed:

- `pandas`
- `requests`

You can install them using `pip`:

```bash
pip install pandas requests
```

### Notes

- The class uses Python's `logging` module to provide detailed information about its operations. Ensure that the logging level is set appropriately to capture the desired amount of detail.
- The `download_fema_ble_models` method handles large file downloads by streaming data in chunks, which is memory-efficient.
- All folder names are sanitized to prevent filesystem errors due to unsafe characters.
"""
==================================================

File: C:\GH\ras-commander\ras_commander\RasGeo.py
==================================================
"""
RasGeo - Operations for handling geometry files in HEC-RAS projects

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function():
        logger = logging.getLogger(__name__)
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
from pathlib import Path
from typing import List, Union
from .RasPlan import RasPlan
from .RasPrj import ras
from ras_commander import get_logger
from ras_commander.logging_config import log_call

logger = get_logger(__name__)

class RasGeo:
    """
    A class for operations on HEC-RAS geometry files.
    """
    
    @staticmethod
    @log_call
    def clear_geompre_files(
        plan_files: Union[str, Path, List[Union[str, Path]]] = None,
        ras_object = None
    ) -> None:
        """
        Clear HEC-RAS geometry preprocessor files for specified plan files or all plan files in the project directory.
        
        Limitations/Future Work:
        - This function only deletes the geometry preprocessor file.
        - It does not clear the IB tables.
        - It also does not clear geometry preprocessor tables from the geometry HDF.
        - All of these features will need to be added to reliably remove geometry preprocessor files for 1D and 2D projects.
        
        Parameters:
            plan_files (Union[str, Path, List[Union[str, Path]]], optional): 
                Full path(s) to the HEC-RAS plan file(s) (.p*).
                If None, clears all plan files in the project directory.
            ras_object: An optional RAS object instance.
        
        Returns:
            None
        
        Examples:
            # Clear all geometry preprocessor files in the project directory
            RasGeo.clear_geompre_files()
            
            # Clear a single plan file
            RasGeo.clear_geompre_files(r'path/to/plan.p01')
            
            # Clear multiple plan files
            RasGeo.clear_geompre_files([r'path/to/plan1.p01', r'path/to/plan2.p02'])

        Note:
            This function updates the ras object's geometry dataframe after clearing the preprocessor files.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        def clear_single_file(plan_file: Union[str, Path], ras_obj) -> None:
            plan_path = Path(plan_file)
            geom_preprocessor_suffix = '.c' + ''.join(plan_path.suffixes[1:]) if plan_path.suffixes else '.c'
            geom_preprocessor_file = plan_path.with_suffix(geom_preprocessor_suffix)
            if geom_preprocessor_file.exists():
                try:
                    geom_preprocessor_file.unlink()
                    logger.info(f"Deleted geometry preprocessor file: {geom_preprocessor_file}")
                except PermissionError:
                    logger.error(f"Permission denied: Unable to delete geometry preprocessor file: {geom_preprocessor_file}")
                    raise PermissionError(f"Unable to delete geometry preprocessor file: {geom_preprocessor_file}. Permission denied.")
                except OSError as e:
                    logger.error(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
                    raise OSError(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
            else:
                logger.warning(f"No geometry preprocessor file found for: {plan_file}")
        
        if plan_files is None:
            logger.info("Clearing all geometry preprocessor files in the project directory.")
            plan_files_to_clear = list(ras_obj.project_folder.glob(r'*.p*'))
        elif isinstance(plan_files, (str, Path)):
            plan_files_to_clear = [plan_files]
            logger.info(f"Clearing geometry preprocessor file for single plan: {plan_files}")
        elif isinstance(plan_files, list):
            plan_files_to_clear = plan_files
            logger.info(f"Clearing geometry preprocessor files for multiple plans: {plan_files}")
        else:
            logger.error("Invalid input type for plan_files.")
            raise ValueError("Invalid input. Please provide a string, Path, list of paths, or None.")
        
        for plan_file in plan_files_to_clear:
            clear_single_file(plan_file, ras_obj)
        
        try:
            ras_obj.geom_df = ras_obj.get_geom_entries()
            logger.info("Geometry dataframe updated successfully.")
        except Exception as e:
            logger.error(f"Failed to update geometry dataframe: {str(e)}")
            raise









==================================================

File: C:\GH\ras-commander\ras_commander\RasGpt.py
==================================================
import os
from pathlib import Path
from typing import Optional
from ras_commander import get_logger, log_call

logger = get_logger(__name__)

class RasGpt:
    """
    A class containing helper functions for the RAS Commander GPT.
    """
    
    # READ Functions to allow GPT to read library files quickly 

    @classmethod
    @log_call
    def read_library_guide(cls) -> Optional[str]:
        """
        Reads and returns the contents of the Comprehensive_Library_Guide.md file.

        Returns:
            Optional[str]: The contents of the file, or None if the file is not found.
        """
        file_path = Path(__file__).parent.parent / "docs" / "Comprehensive_Library_Guide.md"
        return cls._read_file(file_path)


    # ADD FOR read_reaadme and read_function_list
    # Need to add a function list separate from the Library Guide
    
    # ADD for read_example_list which will read the example folder README.ModuleNotFoundError





    @classmethod
    @log_call
    def read_style_guide(cls) -> Optional[str]:
        """
        Reads and returns the contents of the STYLE_GUIDE.md file.

        Returns:
            Optional[str]: The contents of the file, or None if the file is not found.
        """
        file_path = Path(__file__).parent.parent / "docs" / "STYLE_GUIDE.md"
        return cls._read_file(file_path)
    
    
    # READ CLASS FILE FUNCTIONS: 

    @classmethod
    @log_call
    def read_class_rascmdr(cls) -> Optional[str]:
        """
        Reads and returns the contents of the RasCmdr.py file.

        Returns:
            Optional[str]: The contents of the file, or None if the file is not found.
        """
        file_path = Path(__file__).parent / "RasCmdr.py"
        return cls._read_file(file_path)
    
    # add one for each class file 
    
    
    
    
    
    # Public Helper Functions: 
    
    
    @classmethod
    @log_call
    def get_file_structure(cls, directory: Optional[str] = None) -> str:
        """
        Returns a string representation of the file structure of the ras_commander package.

        Args:
            directory (Optional[str]): The directory to start from. If None, uses the package root.

        Returns:
            str: A string representation of the file structure.
        """
        if directory is None:
            directory = Path(__file__).parent

        return cls._get_directory_structure(directory)
    
    
      
    
    # Private Helper Functions: 
    
    @staticmethod
    def _read_file(file_path: Path) -> Optional[str]:
        """
        Helper method to read the contents of a file.

        Args:
            file_path (Path): The path to the file to be read.

        Returns:
            Optional[str]: The contents of the file, or None if the file is not found.
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except FileNotFoundError:
            logger.error(f"File not found: {file_path}")
            return None
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {str(e)}")
            return None


    @staticmethod
    def _get_directory_structure(directory: Path, prefix: str = "") -> str:
        """
        Helper method to recursively build the directory structure string.

        Args:
            directory (Path): The directory to process.
            prefix (str): The prefix to use for the current level.

        Returns:
            str: A string representation of the directory structure.
        """
        if not directory.is_dir():
            return ""

        output = []
        for item in sorted(directory.iterdir()):
            if item.name.startswith('.'):
                continue
            if item.is_dir():
                output.append(f"{prefix}{item.name}/")
                output.append(RasGpt._get_directory_structure(item, prefix + "  "))
            else:
                output.append(f"{prefix}{item.name}")

        return "\n".join(output)

==================================================

File: C:\GH\ras-commander\ras_commander\RasHdf.py
==================================================
"""
RasHdf Module

This module provides utilities for working with HDF files in HEC-RAS projects.
It contains the RasHdf class, which offers various static methods for extracting,
analyzing, and manipulating data from HEC-RAS HDF files.

Note:
    This method is decorated with @hdf_operation, which handles the opening and closing of the HDF file.
    The decorator should be used for all methods that directly interact with HDF files.
    It ensures proper file handling and error management.

    When using the @hdf_operation decorator:
    - The method receives an open h5py.File object as its first argument after 'cls'.
    - Error handling for file operations is managed by the decorator.
    - The HDF file is automatically closed after the method execution.

    Methods without this decorator must manually handle file opening, closing, and error management.
    Failure to use the decorator or properly manage the file can lead to resource leaks or file access errors.

Example:
    @classmethod
    @hdf_operation
    def example_method(cls, hdf_file: h5py.File, other_args):
        # Method implementation using hdf_file
        
This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function():
        logger = logging.getLogger(__name__)
        logger.debug("Additional debug information")
        # Function logic here
"""
import h5py
import numpy as np
import pandas as pd
from typing import Union, List, Optional, Dict, Tuple, Any, Callable
from scipy.spatial import KDTree
from pathlib import Path
from datetime import datetime
import logging
from functools import wraps
from .RasPrj import RasPrj, ras, init_ras_project

# If you're using RasPrj in type hints, you might need to use string literals to avoid circular imports
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .RasPrj import RasPrj
from ras_commander import get_logger
from ras_commander.logging_config import log_call

logger = get_logger(__name__)

class RasHdf:
    """
    A utility class for working with HDF files in HEC-RAS projects.

    This class provides static methods for various operations on HDF files,
    including listing paths, extracting data, and performing analyses on
    HEC-RAS project data stored in HDF format.
    """
    
    
    @staticmethod
    def hdf_operation(func):
        """
        A decorator for HDF file operations in the RasHdf class.

        This decorator wraps methods that perform operations on HDF files. It handles:
        1. Resolving the HDF filename from various input types.
        2. Opening and closing the HDF file.
        3. Error handling and logging.
        4. Applying the decorated function as a class method.

        Args:
            func (Callable): The function to be decorated.

        Returns:
            Callable: A wrapped version of the input function as a class method.

        Raises:
            ValueError: If the HDF file is not found.

        Usage:
            @RasHdf.hdf_operation
            def some_hdf_method(cls, hdf_file, ...):
                # Method implementation
        """
        @wraps(func)
        def wrapper(cls, hdf_input: Union[str, Path], *args: Any, **kwargs: Any) -> Any:
            from ras_commander import ras  # Import here to avoid circular import
            ras_obj = kwargs.pop('ras_object', None) or ras
            try:
                hdf_filename = cls._get_hdf_filename(hdf_input, ras_obj)
                if hdf_filename is None:
                    raise ValueError(f"HDF file {hdf_input} not found. Use a try-except block to catch this error.")
                with h5py.File(hdf_filename, 'r') as hdf_file:
                    return func(cls, hdf_file, *args, **kwargs)
            except Exception as e:
                logger.error(f"Error in {func.__name__}: {e}")
                return None
        return classmethod(wrapper)

    
    @classmethod
    @log_call
    def get_runtime_data(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract runtime and compute time data from a single HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing runtime and compute time data, or None if data extraction fails.

        Example:
            >>> runtime_df = RasHdf.get_runtime_data("path/to/file.hdf")
            >>> if runtime_df is not None:
            ...     print(runtime_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            logger.info(f"Extracting Plan Information from: {Path(hdf_file.filename).name}")
            plan_info = hdf_file.get('/Plan Data/Plan Information')
            if plan_info is None:
                logger.warning("Group '/Plan Data/Plan Information' not found.")
                return None

            plan_name = plan_info.attrs.get('Plan Name', 'Unknown')
            plan_name = plan_name.decode('utf-8') if isinstance(plan_name, bytes) else plan_name
            logger.info(f"Plan Name: {plan_name}")

            start_time_str = plan_info.attrs.get('Simulation Start Time', 'Unknown')
            end_time_str = plan_info.attrs.get('Simulation End Time', 'Unknown')
            start_time_str = start_time_str.decode('utf-8') if isinstance(start_time_str, bytes) else start_time_str
            end_time_str = end_time_str.decode('utf-8') if isinstance(end_time_str, bytes) else end_time_str

            start_time = datetime.strptime(start_time_str, "%d%b%Y %H:%M:%S")
            end_time = datetime.strptime(end_time_str, "%d%b%Y %H:%M:%S")
            simulation_duration = end_time - start_time
            simulation_hours = simulation_duration.total_seconds() / 3600

            logger.info(f"Simulation Start Time: {start_time_str}")
            logger.info(f"Simulation End Time: {end_time_str}")
            logger.info(f"Simulation Duration (hours): {simulation_hours}")

            compute_processes = hdf_file.get('/Results/Summary/Compute Processes')
            if compute_processes is None:
                logger.warning("Dataset '/Results/Summary/Compute Processes' not found.")
                return None

            process_names = [name.decode('utf-8') for name in compute_processes['Process'][:]]
            filenames = [filename.decode('utf-8') for filename in compute_processes['Filename'][:]]
            completion_times = compute_processes['Compute Time (ms)'][:]

            compute_processes_df = pd.DataFrame({
                'Process': process_names,
                'Filename': filenames,
                'Compute Time (ms)': completion_times,
                'Compute Time (s)': completion_times / 1000,
                'Compute Time (hours)': completion_times / (1000 * 3600)
            })

            logger.debug("Compute processes DataFrame:")
            logger.debug(compute_processes_df)

            compute_processes_summary = {
                'Plan Name': [plan_name],
                'File Name': [Path(hdf_file.filename).name],
                'Simulation Start Time': [start_time_str],
                'Simulation End Time': [end_time_str],
                'Simulation Duration (s)': [simulation_duration.total_seconds()],
                'Simulation Time (hr)': [simulation_hours],
                'Completing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Geometry']['Compute Time (hours)'].values[0] if 'Completing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Preprocessing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Preprocessing Geometry']['Compute Time (hours)'].values[0] if 'Preprocessing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Completing Event Conditions (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Event Conditions']['Compute Time (hours)'].values[0] if 'Completing Event Conditions' in compute_processes_df['Process'].values else 'N/A'],
                'Unsteady Flow Computations (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Unsteady Flow Computations']['Compute Time (hours)'].values[0] if 'Unsteady Flow Computations' in compute_processes_df['Process'].values else 'N/A'],
                'Complete Process (hr)': [compute_processes_df['Compute Time (hours)'].sum()]
            }

            compute_processes_summary['Unsteady Flow Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Unsteady Flow Computations (hr)'][0] if compute_processes_summary['Unsteady Flow Computations (hr)'][0] != 'N/A' else 'N/A']
            compute_processes_summary['Complete Process Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Complete Process (hr)'][0] if compute_processes_summary['Complete Process (hr)'][0] != 'N/A' else 'N/A']

            compute_summary_df = pd.DataFrame(compute_processes_summary)
            logger.debug("Compute summary DataFrame:")
            logger.debug(compute_summary_df)

            return compute_summary_df

    # List 2D Flow Area Groups (needed for later functions that extract specific datasets)
    
    @classmethod
    @log_call
    def get_2d_flow_area_names(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[List[str]]:
        """
        List 2D Flow Area names from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[List[str]]: List of 2D Flow Area names, or None if no 2D Flow Areas are found.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas' in hdf_file:
                group = hdf_file['Geometry/2D Flow Areas']
                group_names = [name for name in group.keys() if isinstance(group[name], h5py.Group)]
                if not group_names:
                    logger.warning("No 2D Flow Areas found in the HDF file")
                    return None
                logger.info(f"Found {len(group_names)} 2D Flow Areas")
                return group_names
            else:
                logger.warning("No 2D Flow Areas found in the HDF file")
                return None
    @classmethod
    @log_call
    def get_2d_flow_area_attributes(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract 2D Flow Area Attributes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing 2D Flow Area Attributes, or None if attributes are not found.

        Example:
            >>> attributes_df = RasHdf.get_2d_flow_area_attributes("path/to/file.hdf")
            >>> if attributes_df is not None:
            ...     print(attributes_df.head())
            ... else:
            ...     print("No 2D Flow Area attributes found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas/Attributes' in hdf_file:
                attributes = hdf_file['Geometry/2D Flow Areas/Attributes'][()]
                attributes_df = pd.DataFrame(attributes)
                return attributes_df
            else:
                return None
            
    @classmethod
    @log_call
    def get_cell_info(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Info from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Info, or None if the data is not found.

        Example:
            >>> cell_info_df = RasHdf.get_cell_info("path/to/file.hdf")
            >>> if cell_info_df is not None:
            ...     print(cell_info_df.head())
            ... else:
            ...     print("No Cell Info found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_info_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Info', ['Start', 'End'])
            return cell_info_df
        
    @classmethod
    @log_call
    def get_cell_points(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Points, or None if the data is not found.

        Example:
            >>> cell_points_df = RasHdf.get_cell_points("path/to/file.hdf")
            >>> if cell_points_df is not None:
            ...     print(cell_points_df.head())
            ... else:
            ...     print("No Cell Points found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_points_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Points', ['X', 'Y'])
            return cell_points_df
    
    @classmethod
    @log_call
    def get_polygon_info_and_parts(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Polygon Info and Parts from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Polygon Info and Polygon Parts respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> polygon_info_df, polygon_parts_df = RasHdf.get_polygon_info_and_parts("path/to/file.hdf")
            >>> if polygon_info_df is not None and polygon_parts_df is not None:
            ...     print("Polygon Info:")
            ...     print(polygon_info_df.head())
            ...     print("Polygon Parts:")
            ...     print(polygon_parts_df.head())
            ... else:
            ...     print("Polygon data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            base_path = f'Geometry/2D Flow Areas'
            polygon_info_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Info', ['Column1', 'Column2', 'Column3', 'Column4'])
            polygon_parts_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Parts', ['Start', 'Count'])
            return polygon_info_df, polygon_parts_df

    @classmethod
    @log_call
    def get_polygon_points(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Polygon Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Polygon Points, or None if the data is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            polygon_points_path = f'Geometry/2D Flow Areas/Polygon Points'
            if polygon_points_path in hdf_file:
                polygon_points = hdf_file[polygon_points_path][()]
                polygon_points_df = pd.DataFrame(polygon_points, columns=['X', 'Y'])
                return polygon_points_df
            else:
                return None
            
    @classmethod
    @log_call
    def get_cells_center_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Cells Center Coordinates and Manning's n from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Cells Center Coordinates and Manning's n respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> coords_df, mannings_df = RasHdf.get_cells_center_data("path/to/file.hdf")
            >>> if coords_df is not None and mannings_df is not None:
            ...     print("Cell Center Coordinates:")
            ...     print(coords_df.head())
            ...     print("Manning's n:")
            ...     print(mannings_df.head())
            ... else:
            ...     print("Cell center data not found")
        """
        try:
            hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
            with h5py.File(hdf_filename, 'r') as hdf_file:
                area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
                base_path = f'Geometry/2D Flow Areas/{area_name}'
                cells_center_coord_path = f'{base_path}/Cells Center Coordinate'
                cells_manning_n_path = f'{base_path}/Cells Center Manning\'s n'
                cells_center_coord_df = cls._extract_dataset(hdf_file, cells_center_coord_path, ['X', 'Y'])
                cells_manning_n_df = cls._extract_dataset(hdf_file, cells_manning_n_path, ['Manning\'s n'])
                return cells_center_coord_df, cells_manning_n_df
        except Exception as e:
            return None, None

    @classmethod
    @log_call
    def get_faces_area_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Faces Area Elevation Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces Area Elevation Values, or None if the data is not found.

        Example:
            >>> elevation_df = RasHdf.get_faces_area_elevation_data("path/to/file.hdf")
            >>> if elevation_df is not None:
            ...     print(elevation_df.head())
            ... else:
            ...     print("No Faces Area Elevation data found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            base_path = f'Geometry/2D Flow Areas/{area_name}'
            area_elev_values_path = f'{base_path}/Faces Area Elevation Values'
            
            if area_elev_values_path in hdf_file:
                area_elev_values = hdf_file[area_elev_values_path][()]
                area_elev_values_df = pd.DataFrame(area_elev_values, columns=['Elevation', 'Area', 'Wetted Perimeter', 'Manning\'s n'])
                return area_elev_values_df
            else:
                return None

    @classmethod
    @log_call
    def get_faces_indexes(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Cell and FacePoint Indexes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Faces Cell Indexes and FacePoint Indexes respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> cell_indexes_df, facepoint_indexes_df = RasHdf.get_faces_indexes("path/to/file.hdf")
            >>> if cell_indexes_df is not None and facepoint_indexes_df is not None:
            ...     print("Faces Cell Indexes:")
            ...     print(cell_indexes_df.head())
            ...     print("Faces FacePoint Indexes:")
            ...     print(facepoint_indexes_df.head())
            ... else:
            ...     print("Faces indexes data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            cell_indexes_path = f'{base_path}/Faces Cell Indexes'
            facepoint_indexes_path = f'{base_path}/Faces FacePoint Indexes'
            
            cell_indexes_df = cls._extract_dataset(hdf_file, cell_indexes_path, ['Left Cell', 'Right Cell'])
            facepoint_indexes_df = cls._extract_dataset(hdf_file, facepoint_indexes_path, ['Start FacePoint', 'End FacePoint'])

            return cell_indexes_df, facepoint_indexes_df
        
    @classmethod
    @log_call
    def get_faces_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Low Elevation Centroid and Minimum Elevation from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Low Elevation Centroid and Minimum Elevation.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            low_elev_centroid = cls._extract_dataset(hdf_file, f'{base_path}/Faces Low Elevation Centroid', ['Low Elevation Centroid'])
            min_elevation = cls._extract_dataset(hdf_file, f'{base_path}/Faces Minimum Elevation', ['Minimum Elevation'])

            return low_elev_centroid, min_elevation
    
    @classmethod
    @log_call
    def get_faces_vector_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Faces NormalUnitVector and Length from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces NormalUnitVector and Length.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            vector_data = cls._extract_dataset(hdf_file, f'{base_path}/Faces NormalUnitVector and Length', ['NormalX', 'NormalY', 'Length'])

            return vector_data

    @classmethod
    @log_call
    def get_faces_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Perimeter Info and Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Perimeter Info and Values.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.

        Example:
            >>> perimeter_info_df, perimeter_values_df = RasHdf.get_faces_perimeter_data("path/to/file.hdf")
            >>> if perimeter_info_df is not None and perimeter_values_df is not None:
            ...     print("Perimeter Info:")
            ...     print(perimeter_info_df.head())
            ...     print("Perimeter Values:")
            ...     print(perimeter_values_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            perimeter_info = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Info', ['Start', 'Count'])
            perimeter_values = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Values', ['X', 'Y'])

            return perimeter_info, perimeter_values

    @classmethod
    @log_call
    def get_infiltration_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Infiltration Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing various Infiltration Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}/Infiltration'
            
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            initial_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Initial Deficit', ['Initial Deficit'])
            maximum_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Maximum Deficit', ['Maximum Deficit'])
            potential_percolation_rate = cls._extract_dataset(hdf_file, f'{base_path}/Potential Percolation Rate', ['Potential Percolation Rate'])

            return cell_classifications, face_classifications, initial_deficit, maximum_deficit, potential_percolation_rate
        
    @classmethod
    @log_call
    def get_percent_impervious_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Percent Impervious Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Cell Classifications, Face Classifications, and Percent Impervious Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}/Percent Impervious'
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            percent_impervious = cls._extract_dataset(hdf_file, f'{base_path}/Percent Impervious', ['Percent Impervious'])

            return cell_classifications, face_classifications, percent_impervious

    @classmethod
    @log_call
    def get_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Perimeter Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Perimeter Data

        Example:
            >>> perimeter_df = RasHdf.get_perimeter_data("path/to/file.hdf")
            >>> if perimeter_df is not None:
            ...     print(perimeter_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            perimeter_path = f'Geometry/2D Flow Areas/{area_name}/Perimeter'
            perimeter_df = cls._extract_dataset(hdf_file, perimeter_path, ['X', 'Y'])

            return perimeter_df

    @classmethod
    @log_call
    def _get_area_name(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> str:
        """
        Get the 2D Flow Area name from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): The provided area name, if any.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            str: The 2D Flow Area name.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file or if the specified area name is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if area_name is None:
                area_names = [name for name in hdf_file['Geometry/2D Flow Areas'].keys() if isinstance(hdf_file['Geometry/2D Flow Areas'][name], h5py.Group)]
                if not area_names:
                    raise ValueError("No 2D Flow Areas found in the HDF file")
                area_name = area_names[0]
            else:
                if area_name not in hdf_file['Geometry/2D Flow Areas']:
                    raise ValueError(f"2D Flow Area '{area_name}' not found in the HDF file")
        return area_name

    @classmethod
    @log_call
    def _extract_dataset(cls, hdf_input: Union[str, Path], dataset_path: str, column_names: List[str], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract a dataset from the HDF file and convert it to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            dataset_path (str): The path to the dataset within the HDF file.
            column_names (List[str]): The names to assign to the DataFrame columns.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: The extracted data as a DataFrame, or None if the dataset is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                dataset = hdf_file[dataset_path][()]
                df = pd.DataFrame(dataset, columns=column_names)
                return df
            except KeyError:
                return None

    @classmethod
    @log_call
    def read_hdf_to_dataframe(cls, hdf_input: Union[str, Path], dataset_path: str, fill_value: Union[int, float, str] = -9999, ras_object=None) -> pd.DataFrame:
        """
        Reads an HDF5 dataset and converts it into a pandas DataFrame, handling byte strings and missing values.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            dataset_path (str): Path to the dataset within the HDF file.
            fill_value (Union[int, float, str], optional): The value to use for filling missing data. Defaults to -9999.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: The resulting DataFrame with byte strings decoded and missing values replaced.

        Raises:
            KeyError: If the dataset is not found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_dataset = hdf_file[dataset_path]
                hdf_dataframe = cls.convert_to_dataframe_array(hdf_dataset)
                byte_columns = [col for col in hdf_dataframe.columns if isinstance(hdf_dataframe[col].iloc[0], (bytes, bytearray))]
                
                hdf_dataframe[byte_columns] = hdf_dataframe[byte_columns].applymap(lambda x: x.decode('utf-8') if isinstance(x, (bytes, bytearray)) else x)
                hdf_dataframe = hdf_dataframe.replace({fill_value: np.NaN})
                
                return hdf_dataframe
            except KeyError:
                raise
        
    @classmethod
    @log_call
    def get_group_attributes_as_df(cls, hdf_input: Union[str, Path], group_path: str, ras_object=None) -> pd.DataFrame:
        """
        Convert attributes inside a given HDF group to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            group_path (str): Path of the group in the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all attributes in the specified group with their properties.

        Raises:
            KeyError: If the specified group_path is not found in the file.

        Example:
            >>> attributes_df = RasHdf.get_group_attributes_as_df("path/to/file.hdf", "/Results/Unsteady/Output")
            >>> print(attributes_df.head())
        """
        hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
        
        with h5py.File(hdf_filename, 'r') as hdf_file:
            try:
                group = hdf_file[group_path]
                attributes = []
                for attr in group.attrs:
                    value = group.attrs[attr]
                    attr_info = {
                        'Attribute': attr,
                        'Value': value,
                        'Type': type(value).__name__,
                        'Shape': value.shape if isinstance(value, np.ndarray) else None,
                        'Size': value.size if isinstance(value, np.ndarray) else None,
                        'Dtype': value.dtype if isinstance(value, np.ndarray) else None
                    }
                    if isinstance(value, bytes):
                        attr_info['Value'] = value.decode('utf-8')
                    elif isinstance(value, np.ndarray):
                        if value.dtype.kind == 'S':
                            attr_info['Value'] = [v.decode('utf-8') for v in value]
                        elif value.dtype.kind in ['i', 'f', 'u']:
                            attr_info['Value'] = value.tolist()
                    attributes.append(attr_info)
                
                return pd.DataFrame(attributes)
            except KeyError:
                logger.critical(f"Group path '{group_path}' not found in HDF file '{hdf_filename}'")

    # Last functions from PyHMT2D:

    from ras_commander.logging_config import log_call

    @classmethod
    @log_call
    def get_2d_area_solution_times(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution times for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution times, or None if not found.
        
        Example:
            >>> solution_times = RasHdf.get_2d_area_solution_times("03", area_name="Area1")
            >>> print(solution_times)
            [0.0, 0.5, 1.0, ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_times = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time']
                )
                return solution_times
            except KeyError:
                return None

    @classmethod
    @log_call
    def get_2d_area_solution_time_dates(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution time dates for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution time dates, or None if not found.
        
        Example:
            >>> solution_time_dates = RasHdf.get_2d_area_solution_time_dates("03", area_name="Area1")
            >>> print(solution_time_dates)
            ['2024-01-01T00:00:00', '2024-01-01T00:30:00', ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_time_dates = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time Date Stamp']
                )
                return solution_time_dates
            except KeyError:
                return None

    @classmethod
    @log_call
    def load_2d_area_solutions(
        cls,
        hdf_file: h5py.File,
        ras_object=None
    ) -> Optional[Dict[str, pd.DataFrame]]:
        """
        Load 2D Area Solutions (Water Surface Elevation and Face Normal Velocity) from the HDF file
        and provide them as pandas DataFrames.

        **Note:** 
            - This function has only been tested with HEC-RAS version 6.5.
            - Ensure that the HDF file structure matches the expected paths.

        Args:
            hdf_file (h5py.File): An open HDF5 file object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[Dict[str, pd.DataFrame]]: A dictionary containing:
                - 'solution_times': DataFrame of solution times.
                - For each 2D Flow Area:
                    - '{Area_Name}_WSE': Water Surface Elevation DataFrame.
                    - '{Area_Name}_Face_Velocity': Face Normal Velocity DataFrame.
        """
        try:
            solution_times_path = '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time'
            if solution_times_path not in hdf_file:
                return None

            solution_times = hdf_file[solution_times_path][()]
            solution_times_df = pd.DataFrame({
                'Time_Step': solution_times
            })

            solutions_dict = {
                'solution_times': solution_times_df
            }

            two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
            if not two_d_area_names:
                return solutions_dict

            for area in two_d_area_names:
                wse_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Water Surface'
                face_velocity_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Face Velocity'

                if wse_path not in hdf_file:
                    continue

                wse_data = hdf_file[wse_path][()]
                cell_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Cell Center Coordinate'
                if cell_center_coords_path not in hdf_file:
                    continue

                cell_center_coords = hdf_file[cell_center_coords_path][()]
                if cell_center_coords.shape[0] != wse_data.shape[1]:
                    continue

                wse_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, wse_data.shape[1]),
                    'Cell_ID': np.tile(np.arange(wse_data.shape[1]), wse_data.shape[0]),
                    'X': cell_center_coords[:, 0].repeat(wse_data.shape[0]),
                    'Y': cell_center_coords[:, 1].repeat(wse_data.shape[0]),
                    'WSE': wse_data.flatten()
                })
                solutions_dict[f'{area}_WSE'] = wse_df

                if face_velocity_path not in hdf_file:
                    continue

                face_velocity_data = hdf_file[face_velocity_path][()]
                face_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Face Points Coordinates'
                if face_center_coords_path not in hdf_file:
                    continue

                face_center_coords = hdf_file[face_center_coords_path][()]
                if face_center_coords.shape[0] != face_velocity_data.shape[1]:
                    continue

                face_velocity_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, face_velocity_data.shape[1]),
                    'Face_ID': np.tile(np.arange(face_velocity_data.shape[1]), face_velocity_data.shape[0]),
                    'X': face_center_coords[:, 0].repeat(face_velocity_data.shape[0]),
                    'Y': face_center_coords[:, 1].repeat(face_velocity_data.shape[0]),
                    'Normal_Velocity_ft_s': face_velocity_data.flatten()
                })
                solutions_dict[f'{area}_Face_Velocity'] = face_velocity_df

            return solutions_dict

        except Exception as e:
            return None

    @classmethod
    @log_call
    def get_hdf_paths_with_properties(cls, hdf_input: Union[str, Path], ras_object=None) -> pd.DataFrame:
        """
        List all paths in the HDF file with their properties.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all paths and their properties in the HDF file.

        Example:
            >>> paths_df = RasHdf.get_hdf_paths_with_properties("path/to/file.hdf")
            >>> print(paths_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            paths = []
            def visitor_func(name: str, node: h5py.Group) -> None:
                path_info = {
                    "HDF_Path": name,
                    "Type": type(node).__name__,
                    "Shape": getattr(node, "shape", None),
                    "Size": getattr(node, "size", None),
                    "Dtype": getattr(node, "dtype", None)
                }
                paths.append(path_info)
            hdf_file.visititems(visitor_func)
            return pd.DataFrame(paths)
        
    @classmethod
    @log_call
    def build_2d_area_face_hydraulic_information(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[List[np.ndarray]]]:
        """
        Build face hydraulic information tables (elevation, area, wetted perimeter, Manning's n) for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[List[np.ndarray]]]: Nested lists containing hydraulic information for each face in each 2D Flow Area.
        
        Example:
            >>> hydraulic_info = RasHdf.build_2d_area_face_hydraulic_information("03")
            >>> print(hydraulic_info[0][0])  # First face of first area
            [[Elevation1, Area1, WettedPerim1, ManningN1],
             [Elevation2, Area2, WettedPerim2, ManningN2],
             ...]
        """
        try:
            ras_obj = ras_object if ras_object is not None else ras
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_obj), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                hydraulic_info_table = []

                for area in two_d_area_names:
                    face_elev_info = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Info'])
                    face_elev_values = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Values'])
                    
                    area_hydraulic_info = []
                    for face in face_elev_info:
                        start_row, count = face
                        face_data = face_elev_values[start_row:start_row + count].copy()
                        area_hydraulic_info.append(face_data)
                    
                    hydraulic_info_table.append(area_hydraulic_info)

                return hydraulic_info_table

        except KeyError:
            return None

    @classmethod
    @log_call
    def build_2d_area_face_point_coordinates_list(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build a list of face point coordinates for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point coordinates for each 2D Flow Area.
        
        Example:
            >>> face_coords_list = RasHdf.build_2d_area_face_point_coordinates_list("03")
            >>> print(face_coords_list[0])  # Coordinates for first area
            [[X1, Y1], [X2, Y2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_point_coords_list = []

                for area in two_d_area_names:
                    face_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    face_point_coords_list.append(face_points)

                return face_point_coords_list

        except KeyError:
            return None

    @classmethod
    @log_call
    def build_2d_area_face_profile(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None, n_face_profile_points: int = 10) -> Optional[List[np.ndarray]]:
        """
        Build face profiles representing sub-grid terrain for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
            n_face_profile_points (int): Number of points to interpolate along each face profile.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of profile points for each face in each 2D Flow Area.
        
        Example:
            >>> face_profiles = RasHdf.build_2d_area_face_profile("03", n_face_profile_points=20)
            >>> print(face_profiles[0][0])  # Profile points for first face of first area
            [[X1, Y1, Z1], [X2, Y2, Z2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_profiles = []

                for area in two_d_area_names:
                    face_faces = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_point_coords = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    profile_points_all_faces = []

                    for face in face_faces:
                        face_start, face_end = face
                        start_coords = face_point_coords[face_start]
                        end_coords = face_point_coords[face_end]
                        
                        length = cls.horizontal_distance(start_coords, end_coords)
                        stations = np.linspace(0, length, n_face_profile_points, endpoint=True)
                        
                        interpolated_points = np.array([
                            start_coords + (end_coords - start_coords) * i / (n_face_profile_points - 1)
                            for i in range(n_face_profile_points)
                        ])
                        
                        interpolated_points = cls.interpolate_z_coords(interpolated_points)
                        
                        profile_points_all_faces.append(interpolated_points)

                    face_profiles.append(profile_points_all_faces)

                return face_profiles

        except KeyError as e:
            logging.error(f"Error building face profiles: {e}")
            return None

    @classmethod
    @log_call
    def build_face_facepoints(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build face's facepoint list for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point indexes for each face in each 2D Flow Area.
        
        Example:
            >>> face_facepoints = RasHdf.build_face_facepoints("03")
            >>> print(face_facepoints[0][0])  # FacePoint indexes for first face of first area
            [start_idx, end_idx]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_facepoints_list = []

                for area in two_d_area_names:
                    face_facepoints = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_facepoints_list.append(face_facepoints)

                return face_facepoints_list

        except KeyError as e:
            logger = logging.getLogger(__name__)
            logger.error(f"Error building face facepoints list: {e}")
            return None

    @classmethod
    @log_call
    def build_2d_area_boundaries(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
        """
        Build boundaries with their point lists for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
                Tuple containing total boundaries, boundary IDs, boundary names, associated 2D Flow Area names, boundary types,
                total points per boundary, and boundary point lists.
        
        Example:
            >>> total_boundaries, boundary_ids, boundary_names, flow_area_names, boundary_types, total_points, boundary_points = RasHdf.build_2d_area_boundaries("03")
            >>> print(total_boundaries)
            5
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                total_boundaries = 0
                boundary_ids = []
                boundary_names = []
                flow_area_names = []
                boundary_types = []
                total_points_per_boundary = []
                boundary_points_list = []

                for area in two_d_area_names:
                    boundary_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Boundary Points'])
                    if boundary_points.size == 0:
                        logger = logging.getLogger(__name__)
                        logger.warning(f"No boundary points found for 2D Flow Area: {area}")
                        continue

                    current_boundary_id = boundary_points[0][0]
                    current_boundary_points = [boundary_points[0][2], boundary_points[0][3]]
                    boundary_id = current_boundary_id

                    for point in boundary_points[1:]:
                        if point[0] == current_boundary_id:
                            current_boundary_points.append(point[3])
                        else:
                            # Save the completed boundary
                            boundary_ids.append(current_boundary_id)
                            boundary_names.append(point[0])  # Assuming boundary name is stored here
                            flow_area_names.append(area)
                            boundary_types.append(point[2])  # Assuming boundary type is stored here
                            total_points_per_boundary.append(len(current_boundary_points))
                            boundary_points_list.append(np.array(current_boundary_points))
                            total_boundaries += 1

                            # Start a new boundary
                            current_boundary_id = point[0]
                            current_boundary_points = [point[2], point[3]]

                    # Save the last boundary
                    boundary_ids.append(current_boundary_id)
                    boundary_names.append(boundary_points[-1][0])  # Assuming boundary name is stored here
                    flow_area_names.append(area)
                    boundary_types.append(boundary_points[-1][2])  # Assuming boundary type is stored here
                    total_points_per_boundary.append(len(current_boundary_points))
                    boundary_points_list.append(np.array(current_boundary_points))
                    total_boundaries += 1

                return (total_boundaries, np.array(boundary_ids), boundary_names, flow_area_names, boundary_types, np.array(total_points_per_boundary), np.array(boundary_points_list))

        except KeyError as e:
            logger = logging.getLogger(__name__)
            logger.error(f"Error building boundaries: {e}")
            return None

    # Helper Methods for New Functionalities

    @classmethod
    @log_call
    def horizontal_distance(cls, coord1: np.ndarray, coord2: np.ndarray) -> float:
        """
        Calculate the horizontal distance between two coordinate points.
        
        Args:
            coord1 (np.ndarray): First coordinate point [X, Y].
            coord2 (np.ndarray): Second coordinate point [X, Y].
        
        Returns:
            float: Horizontal distance.
        
        Example:
            >>> distance = RasHdf.horizontal_distance([0, 0], [3, 4])
            >>> print(distance)
            5.0
        """
        return np.linalg.norm(coord2 - coord1)

    @classmethod
    @log_call
    def interpolate_z_coords(cls, points: np.ndarray) -> np.ndarray:
        """
        Interpolate Z coordinates for a set of points.
        
        Args:
            points (np.ndarray): Array of points with [X, Y].
        
        Returns:
            np.ndarray: Array of points with [X, Y, Z].
        
        Example:
            >>> interpolated = RasHdf.interpolate_z_coords(np.array([[0,0], [1,1]]))
            >>> print(interpolated)
            [[0, 0, Z0],
             [1, 1, Z1]]
        """
        # Placeholder for actual interpolation logic
        # This should be replaced with the appropriate interpolation method
        z_coords = np.zeros((points.shape[0], 1))  # Assuming Z=0 for simplicity
        return np.hstack((points, z_coords))

    @classmethod
    @log_call
    def extract_string_from_hdf(
        cls,
        hdf_input: Union[str, Path],
        hdf_path: str,
        ras_object: Optional["RasPrj"] = None
    ) -> str:
        """
        Extract string from HDF object at a given path.

        Args:
            hdf_input (Union[str, Path]): Either the plan number or the full path to the HDF file.
            hdf_path (str): Path of the object in the HDF file.
            ras_object (Optional["RasPrj"]): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            str: Extracted string from the specified HDF object.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.
            KeyError: If the specified hdf_path is not found in the file.

        Example:
            >>> result = RasHdf.extract_string_from_hdf("path/to/file.hdf", "/Results/Summary/Compute Messages (text)")
            >>> print(result)
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_object = hdf_file[hdf_path]
                if isinstance(hdf_object, h5py.Group):
                    return f"Group: {hdf_path}\nContents: {list(hdf_object.keys())}"
                elif isinstance(hdf_object, h5py.Dataset):
                    data = hdf_object[()]
                    if isinstance(data, bytes):
                        return data.decode('utf-8')
                    elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':
                        return [v.decode('utf-8') for v in data]
                    else:
                        return str(data)
                else:
                    return f"Unsupported object type: {type(hdf_object)}"
            except KeyError:
                logger = logging.getLogger(__name__)
                logger.error(f"Path not found: {hdf_path}")
                raise KeyError(f"Path not found: {hdf_path}")

    @classmethod
    @log_call
    def decode_byte_strings(dataframe: pd.DataFrame) -> pd.DataFrame:
        """
        Decodes byte strings in a DataFrame to regular string objects.

        This function converts columns with byte-encoded strings (e.g., b'string') into UTF-8 decoded strings.

        Args:
            dataframe (pd.DataFrame): The DataFrame containing byte-encoded string columns.

        Returns:
            pd.DataFrame: The DataFrame with byte strings decoded to regular strings.

        Example:
            >>> df = pd.DataFrame({'A': [b'hello', b'world'], 'B': [1, 2]})
            >>> decoded_df = RasHdf.decode_byte_strings(df)
            >>> print(decoded_df)
                A  B
            0  hello  1
            1  world  2
        """
        str_df = dataframe.select_dtypes(['object'])
        str_df = str_df.stack().str.decode('utf-8').unstack()
        for col in str_df:
            dataframe[col] = str_df[col]
        return dataframe

    @classmethod
    @log_call
    def perform_kdtree_query(
        reference_points: np.ndarray,
        query_points: np.ndarray,
        max_distance: float = 2.0
    ) -> np.ndarray:
        """
        Performs a KDTree query between two datasets and returns indices with distances exceeding max_distance set to -1.

        Args:
            reference_points (np.ndarray): The reference dataset for KDTree.
            query_points (np.ndarray): The query dataset to search against KDTree of reference_points.
            max_distance (float, optional): The maximum distance threshold. Indices with distances greater than this are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices from reference_points that are nearest to each point in query_points. 
                        Indices with distances > max_distance are set to -1.

        Example:
            >>> ref_points = np.array([[0, 0], [1, 1], [2, 2]])
            >>> query_points = np.array([[0.5, 0.5], [3, 3]])
            >>> result = RasHdf.perform_kdtree_query(ref_points, query_points)
            >>> print(result)
            array([ 0, -1])
        """
        dist, snap = KDTree(reference_points).query(query_points, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        return snap

    @classmethod
    @log_call
    def find_nearest_neighbors(points: np.ndarray, max_distance: float = 2.0) -> np.ndarray:
        """
        Creates a self KDTree for dataset points and finds nearest neighbors excluding self, 
        with distances above max_distance set to -1.

        Args:
            points (np.ndarray): The dataset to build the KDTree from and query against itself.
            max_distance (float, optional): The maximum distance threshold. Indices with distances 
                                            greater than max_distance are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices representing the nearest neighbor in points for each point in points. 
                        Indices with distances > max_distance or self-matches are set to -1.

        Example:
            >>> points = np.array([[0, 0], [1, 1], [2, 2], [10, 10]])
            >>> result = RasHdf.find_nearest_neighbors(points)
            >>> print(result)
            array([1, 0, 1, -1])
        """
        dist, snap = KDTree(points).query(points, k=2, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        
        snp = pd.DataFrame(snap, index=np.arange(len(snap)))
        snp = snp.replace(-1, np.nan)
        snp.loc[snp[0] == snp.index, 0] = np.nan
        snp.loc[snp[1] == snp.index, 1] = np.nan
        filled = snp[0].fillna(snp[1])
        snapped = filled.fillna(-1).astype(np.int64).to_numpy()
        return snapped

    @classmethod
    @log_call
    def consolidate_dataframe(
        dataframe: pd.DataFrame,
        group_by: Optional[Union[str, List[str]]] = None,
        pivot_columns: Optional[Union[str, List[str]]] = None,
        level: Optional[int] = None,
        n_dimensional: bool = False,
        aggregation_method: Union[str, Callable] = 'list'
    ) -> pd.DataFrame:
        """
        Consolidate rows in a DataFrame by merging duplicate values into lists or using a specified aggregation function.

        Args:
            dataframe (pd.DataFrame): The DataFrame to consolidate.
            group_by (Optional[Union[str, List[str]]]): Columns or indices to group by.
            pivot_columns (Optional[Union[str, List[str]]]): Columns to pivot.
            level (Optional[int]): Level of multi-index to group by.
            n_dimensional (bool): If True, use a pivot table for N-Dimensional consolidation.
            aggregation_method (Union[str, Callable]): Aggregation method, e.g., 'list' to aggregate into lists.

        Returns:
            pd.DataFrame: The consolidated DataFrame.

        Example:
            >>> df = pd.DataFrame({'A': [1, 1, 2], 'B': [4, 5, 6], 'C': [7, 8, 9]})
            >>> result = RasHdf.consolidate_dataframe(df, group_by='A')
            >>> print(result)
            B         C
            A            
            1  [4, 5]  [7, 8]
            2  [6]     [9]
        """
        if aggregation_method == 'list':
            agg_func = lambda x: tuple(x)
        else:
            agg_func = aggregation_method

        if n_dimensional:
            result = dataframe.pivot_table(group_by, pivot_columns, aggfunc=agg_func)
        else:
            result = dataframe.groupby(group_by, level=level).agg(agg_func).applymap(list)

        return result
    
    @classmethod
    @log_call
    def find_nearest_value(array: Union[list, np.ndarray], target_value: Union[int, float]) -> Union[int, float]:
        """
        Finds the nearest value in a NumPy array to the specified target value.

        Args:
            array (Union[list, np.ndarray]): The array to search within.
            target_value (Union[int, float]): The value to find the nearest neighbor to.

        Returns:
            Union[int, float]: The nearest value in the array to the specified target value.

        Example:
            >>> arr = np.array([1, 3, 5, 7, 9])
            >>> result = RasHdf.find_nearest_value(arr, 6)
            >>> print(result)
            5
        """
        array = np.asarray(array)
        idx = (np.abs(array - target_value)).argmin()
        return array[idx]
    
    @staticmethod
    @log_call
    def _get_hdf_filename(hdf_input: Union[str, Path, h5py.File], ras_object=None) -> Optional[Path]:
        """
        Get the HDF filename from the input.

        Args:
            hdf_input (Union[str, Path, h5py.File]): The plan number, full path to the HDF file as a string, a Path object, or an h5py.File object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[Path]: The full path to the HDF file as a Path object, or None if an error occurs.

        Note:
            This method logs critical errors instead of raising exceptions.
        """

        # If hdf_input is already an h5py.File object, return its filename
        if isinstance(hdf_input, h5py.File):
            return Path(hdf_input.filename)

        # Convert to Path object if it's a string
        if isinstance(hdf_input, str):
            hdf_input = Path(hdf_input)

        # If hdf_input is a file path, return it directly
        if isinstance(hdf_input, Path) and hdf_input.is_file():
            return hdf_input

        # If hdf_input is not a file path, assume it's a plan number and require ras_object
        ras_obj = ras_object or ras
        if not ras_obj.initialized:
            logger.critical("ras_object is not initialized. ras_object is required when hdf_input is not a direct file path.")
            return None

        plan_info = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == str(hdf_input)]
        if plan_info.empty:
            logger.critical(f"No HDF file found for plan number {hdf_input}")
            return None

        hdf_filename = plan_info.iloc[0]['HDF_Results_Path']
        if hdf_filename is None:
            logger.critical(f"HDF_Results_Path is None for plan number {hdf_input}")
            return None

        hdf_path = Path(hdf_filename)
        if not hdf_path.is_file():
            logger.critical(f"HDF file not found: {hdf_path}")
            return None

        return hdf_path



@log_call
def save_dataframe_to_hdf(
    dataframe: pd.DataFrame,
    hdf_parent_group: h5py.Group,
    dataset_name: str,
    attributes: Optional[Dict[str, Union[int, float, str]]] = None,
    fill_value: Union[int, float, str] = -9999,
    **kwargs: Any
) -> h5py.Dataset:
    """
    Save a pandas DataFrame to an HDF5 dataset within a specified parent group.

    This function addresses limitations of `pd.to_hdf()` by using h5py to create and save datasets.

    Args:
        dataframe (pd.DataFrame): The DataFrame to save.
        hdf_parent_group (h5py.Group): The parent HDF5 group where the dataset will be created.
        dataset_name (str): The name of the new dataset to add in the HDF5 parent group.
        attributes (Optional[Dict[str, Union[int, float, str]]]): A dictionary of attributes to add to the dataset.
        fill_value (Union[int, float, str]): The value to use for filling missing data.
        **kwargs: Additional keyword arguments passed to `hdf_parent_group.create_dataset()`.

    Returns:
        h5py.Dataset: The created HDF5 dataset within the parent group.

    Raises:
        ValueError: If the DataFrame columns are not consistent.

    Example:
        >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
        >>> with h5py.File('data.h5', 'w') as f:
        ...     group = f.create_group('my_group')
        ...     dataset = save_dataframe_to_hdf(df, group, 'my_dataset')
        >>> print(dataset)
    """
    df = dataframe.copy()

    # Replace '/' in column names with '-' to avoid issues in HDF5
    if df.columns.dtype == 'O':
        df.columns = df.columns.str.replace('/', '-', regex=False)
    
    # Fill missing values with the specified fill_value
    df = df.fillna(fill_value)
    
    # Identify string columns and ensure consistency
    string_cols = df.select_dtypes(include=['object']).columns
    if not string_cols.equals(df.select_dtypes(include=['object']).columns):
        logger.error("Inconsistent string columns detected")
        raise ValueError("Inconsistent string columns detected")
    
    # Encode string columns to bytes
    df[string_cols] = df[string_cols].applymap(lambda x: x.encode('utf-8')).astype('bytes')

    # Prepare data for HDF5 dataset creation
    arr = df.to_records(index=False) if not isinstance(df.columns, pd.RangeIndex) else df.values
    
    # Remove existing dataset if it exists
    if dataset_name in hdf_parent_group:
        logger.warning(f"Existing dataset {dataset_name} will be overwritten")
        del hdf_parent_group[dataset_name]
    
    # Create the dataset in the HDF5 file
    dataset = hdf_parent_group.create_dataset(dataset_name, data=arr, **kwargs)
    
    # Update dataset attributes if provided
    if attributes:
        dataset.attrs.update(attributes)
    
    logger.info(f"Successfully saved DataFrame to dataset: {dataset_name}")
    return dataset
==================================================

File: C:\GH\ras-commander\ras_commander\RasPlan.py
==================================================
"""
RasPlan - Operations for handling plan files in HEC-RAS projects

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function():
        logger = logging.getLogger(__name__)
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
import re
import logging
from pathlib import Path
import shutil
from typing import Union, Optional
import pandas as pd
from .RasPrj import RasPrj, ras
from .RasUtils import RasUtils
from pathlib import Path
from typing import Union, Any
import logging
import re
from ras_commander import get_logger
from ras_commander.logging_config import log_call

logger = get_logger(__name__)

class RasPlan:
    """
    A class for operations on HEC-RAS plan files.
    """
    
    @staticmethod
    @log_call
    def set_geom(plan_number: Union[str, int], new_geom: Union[str, int], ras_object=None) -> pd.DataFrame:
        """
        Set the geometry for the specified plan.

        Parameters:
            plan_number (Union[str, int]): The plan number to update.
            new_geom (Union[str, int]): The new geometry number to set.
            ras_object: An optional RAS object instance.

        Returns:
            pd.DataFrame: The updated geometry DataFrame.

        Example:
            updated_geom_df = RasPlan.set_geom('02', '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Ensure plan_number and new_geom are strings
        plan_number = str(plan_number).zfill(2)
        new_geom = str(new_geom).zfill(2)

        # Before doing anything, make sure the plan, geom, flow, and unsteady dataframes are current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        if new_geom not in ras_obj.geom_df['geom_number'].values:
            logger.error(f"Geometry {new_geom} not found in project.")
            raise ValueError(f"Geometry {new_geom} not found in project.")

        # Update the geometry for the specified plan
        ras_obj.plan_df.loc[ras_obj.plan_df['plan_number'] == plan_number, 'geom_number'] = new_geom

        logger.info(f"Geometry for plan {plan_number} set to {new_geom}")
        logger.debug("Updated plan DataFrame:")
        logger.debug(ras_obj.plan_df)

        # Update the project file
        prj_file_path = ras_obj.prj_file
        RasUtils.update_file(prj_file_path, RasPlan._update_geom_in_file, plan_number, new_geom)

        # Re-initialize the ras object to reflect changes
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        return ras_obj.plan_df

    @staticmethod
    def _update_geom_in_file(lines, plan_number, new_geom):
        plan_pattern = re.compile(rf"^Plan File=p{plan_number}", re.IGNORECASE)
        geom_pattern = re.compile(r"^Geom File=g\d+", re.IGNORECASE)
        
        for i, line in enumerate(lines):
            if plan_pattern.match(line):
                for j in range(i+1, len(lines)):
                    if geom_pattern.match(lines[j]):
                        lines[j] = f"Geom File=g{new_geom}\n"
                        logger.info(f"Updated Geom File in project file to g{new_geom} for plan {plan_number}")
                        break
                break
        return lines

    @staticmethod
    @log_call
    def set_steady(plan_number: str, new_steady_flow_number: str, ras_object=None):
        """
        Apply a steady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02')
        new_steady_flow_number (str): Steady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified steady flow number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_steady('02', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
                        
        # Update the flow dataframe in the ras instance to ensure it is current
        ras_obj.flow_df = ras_obj.get_flow_entries()
        
        if new_steady_flow_number not in ras_obj.flow_df['flow_number'].values:
            raise ValueError(f"Steady flow number {new_steady_flow_number} not found in project file.")
        
        # Resolve the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        RasUtils.update_file(plan_file_path, RasPlan._update_steady_in_file, new_steady_flow_number)

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def _update_steady_in_file(lines, new_steady_flow_number):
        return [f"Flow File=f{new_steady_flow_number}\n" if line.startswith("Flow File=f") else line for line in lines]

    @staticmethod
    @log_call
    def set_unsteady(plan_number: str, new_unsteady_flow_number: str, ras_object=None):
        """
        Apply an unsteady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '04')
        new_unsteady_flow_number (str): Unsteady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified unsteady number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_unsteady('04', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the unsteady dataframe in the ras instance to ensure it is current
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        if new_unsteady_flow_number not in ras_obj.unsteady_df['unsteady_number'].values:
            raise ValueError(f"Unsteady number {new_unsteady_flow_number} not found in project file.")
        
        # Get the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        try:
            RasUtils.update_file(plan_file_path, RasPlan._update_unsteady_in_file, new_unsteady_flow_number)
        except Exception as e:
            raise Exception(f"Failed to update unsteady flow file: {e}")

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def _update_unsteady_in_file(lines, new_unsteady_flow_number):
        return [f"Unsteady File=u{new_unsteady_flow_number}\n" if line.startswith("Unsteady File=u") else line for line in lines]
    @staticmethod
    @log_call
    def set_num_cores(plan_number, num_cores, ras_object=None):
        """
        Update the maximum number of cores to use in the HEC-RAS plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02') or full path to the plan file
        num_cores (int): Maximum number of cores to use
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Notes on setting num_cores in HEC-RAS:
        The recommended setting for num_cores is 2 (most efficient) to 8 (most performant)
        More details in the HEC-Commander Repository Blog "Benchmarking is All You Need"
        https://github.com/billk-FM/HEC-Commander/blob/main/Blog/7._Benchmarking_Is_All_You_Need.md
        
        Microsoft Windows has a maximum of 64 cores that can be allocated to a single Ras.exe process. 

        Example:
        >>> # Using plan number
        >>> RasPlan.set_num_cores('02', 4)
        >>> # Using full path to plan file
        >>> RasPlan.set_num_cores('/path/to/project.p02', 4)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        plan_file_path = RasUtils.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            raise FileNotFoundError(f"Plan file not found: {plan_number}. Please provide a valid plan number or path.")
        
        def update_num_cores(lines):
            updated_lines = []
            for line in lines:
                if "UNET D1 Cores=" in line:
                    parts = line.split("=")
                    updated_lines.append(f"{parts[0]}= {num_cores}\n")
                else:
                    updated_lines.append(line)
            return updated_lines
        
        try:
            RasUtils.update_file(plan_file_path, update_num_cores)
        except Exception as e:
            raise IOError(f"Failed to update number of cores in plan file: {e}")
        
        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    @log_call
    def set_geom_preprocessor(file_path, run_htab, use_ib_tables, ras_object=None):
        """
        Update the simulation plan file to modify the `Run HTab` and `UNET Use Existing IB Tables` settings.
        
        Parameters:
        file_path (str): Path to the simulation plan file (.p06 or similar) that you want to modify.
        run_htab (int): Value for the `Run HTab` setting:
            - `0` : Do not run the geometry preprocessor, use existing geometry tables.
            - `-1` : Run the geometry preprocessor, forcing a recomputation of the geometry tables.
        use_ib_tables (int): Value for the `UNET Use Existing IB Tables` setting:
            - `0` : Use existing interpolation/boundary (IB) tables without recomputing them.
            - `-1` : Do not use existing IB tables, force a recomputation.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If `run_htab` or `use_ib_tables` are not integers or not within the accepted values (`0` or `-1`).
        FileNotFoundError: If the specified file does not exist.
        IOError: If there is an error reading or writing the file.

        Example:
        >>> RasPlan.set_geom_preprocessor('/path/to/project.p06', run_htab=-1, use_ib_tables=0)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        if run_htab not in [-1, 0]:
            raise ValueError("Invalid value for `Run HTab`. Expected `0` or `-1`.")
        if use_ib_tables not in [-1, 0]:
            raise ValueError("Invalid value for `UNET Use Existing IB Tables`. Expected `0` or `-1`.")
        
        def update_geom_preprocessor(lines, run_htab, use_ib_tables):
            updated_lines = []
            for line in lines:
                if line.lstrip().startswith("Run HTab="):
                    updated_lines.append(f"Run HTab= {run_htab} \n")
                elif line.lstrip().startswith("UNET Use Existing IB Tables="):
                    updated_lines.append(f"UNET Use Existing IB Tables= {use_ib_tables} \n")
                else:
                    updated_lines.append(line)
            return updated_lines
        
        try:
            RasUtils.update_file(file_path, update_geom_preprocessor, run_htab, use_ib_tables)
        except FileNotFoundError:
            raise FileNotFoundError(f"The file '{file_path}' does not exist.")
        except IOError as e:
            raise IOError(f"An error occurred while reading or writing the file: {e}")

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    @log_call
    def get_results_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Retrieve the results file path for a given HEC-RAS plan number.

        Args:
            plan_number (str): The HEC-RAS plan number for which to find the results path.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            Optional[str]: The full path to the results file if found and the file exists, or None if not found.

        Raises:
            RuntimeError: If the project is not initialized.

        Example:
            >>> ras_plan = RasPlan()
            >>> results_path = ras_plan.get_results_path('01')
            >>> if results_path:
            ...     print(f"Results file found at: {results_path}")
            ... else:
            ...     print("Results file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the plan dataframe in the ras instance to ensure it is current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        
        # Ensure plan_number is a string
        plan_number = str(plan_number).zfill(2)
        
        plan_entry = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == plan_number]
        if not plan_entry.empty:
            results_path = plan_entry['HDF_Results_Path'].iloc[0]
            if results_path and Path(results_path).exists():
                return results_path
            else:
                return None
        else:
            return None

    @staticmethod
    @log_call
    def get_plan_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given plan number.
        
        This method ensures that the latest plan entries are included by refreshing
        the plan dataframe before searching for the requested plan number.
        
        Args:
        plan_number (str): The plan number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        Optional[str]: The full path of the plan file if found, None otherwise.
        
        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> plan_path = ras_plan.get_plan_path('01')
        >>> if plan_path:
        ...     print(f"Plan file found at: {plan_path}")
        ... else:
        ...     print("Plan file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated plan dataframe
        plan_df = ras_obj.get_plan_entries()
        
        plan_path = plan_df[plan_df['plan_number'] == plan_number]
        
        if not plan_path.empty:
            full_path = plan_path['full_path'].iloc[0]
            return full_path
        else:
            return None

    @staticmethod
    @log_call
    def get_flow_path(flow_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given flow number.

        Args:
        flow_number (str): The flow number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the flow file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> flow_path = ras_plan.get_flow_path('01')
        >>> if flow_path:
        ...     print(f"Flow file found at: {flow_path}")
        ... else:
        ...     print("Flow file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated flow dataframe
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')
        
        flow_path = ras_obj.flow_df[ras_obj.flow_df['flow_number'] == flow_number]
        if not flow_path.empty:
            full_path = flow_path['full_path'].iloc[0]
            return full_path
        else:
            return None

    @staticmethod
    @log_call
    def get_unsteady_path(unsteady_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given unsteady number.

        Args:
        unsteady_number (str): The unsteady number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the unsteady file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> unsteady_path = ras_plan.get_unsteady_path('01')
        >>> if unsteady_path:
        ...     print(f"Unsteady file found at: {unsteady_path}")
        ... else:
        ...     print("Unsteady file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated unsteady dataframe
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')
        
        unsteady_path = ras_obj.unsteady_df[ras_obj.unsteady_df['unsteady_number'] == unsteady_number]
        if not unsteady_path.empty:
            full_path = unsteady_path['full_path'].iloc[0]
            return full_path
        else:
            return None

    @staticmethod
    @log_call
    def get_geom_path(geom_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given geometry number.

        Args:
        geom_number (str): The geometry number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the geometry file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> geom_path = ras_plan.get_geom_path('01')
        >>> if geom_path:
        ...     print(f"Geometry file found at: {geom_path}")
        ... else:
        ...     print("Geometry file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated geom dataframe
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')
        
        geom_path = ras_obj.geom_df[ras_obj.geom_df['geom_number'] == geom_number]
        if not geom_path.empty:
            full_path = geom_path['full_path'].iloc[0]
            return full_path
        else:
            return None

    # Clone Functions to copy unsteady, flow, and geometry files from templates

    @staticmethod
    @log_call
    def clone_plan(template_plan, new_plan_shortid=None, ras_object=None):
        """
        Create a new plan file based on a template and update the project file.
        
        Parameters:
        template_plan (str): Plan number to use as template (e.g., '01')
        new_plan_shortid (str, optional): New short identifier for the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New plan number
        
        Example:
        >>> ras_plan = RasPlan()
        >>> new_plan_number = ras_plan.clone_plan('01', new_plan_shortid='New Plan')
        >>> print(f"New plan created with number: {new_plan_number}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update plan entries without reinitializing the entire project
        ras_obj.plan_df = ras_obj.get_prj_entries('Plan')

        new_plan_num = RasPlan.get_next_number(ras_obj.plan_df['plan_number'])
        template_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{template_plan}"
        new_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{new_plan_num}"

        def update_shortid(lines):
            shortid_pattern = re.compile(r'^Short Identifier=(.*)$', re.IGNORECASE)
            for i, line in enumerate(lines):
                match = shortid_pattern.match(line.strip())
                if match:
                    current_shortid = match.group(1)
                    if new_plan_shortid is None:
                        new_shortid = (current_shortid + "_copy")[:24]
                    else:
                        new_shortid = new_plan_shortid[:24]
                    lines[i] = f"Short Identifier={new_shortid}\n"
                    break
            return lines

        # Use RasUtils to clone the file and update the short identifier
        RasUtils.clone_file(template_plan_path, new_plan_path, update_shortid)

        # Use RasUtils to update the project file
        RasUtils.update_project_file(ras_obj.prj_file, 'Plan', new_plan_num, ras_object=ras_obj)

        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return new_plan_num

    @staticmethod
    @log_call
    def clone_unsteady(template_unsteady, ras_object=None):
        """
        Copy unsteady flow files from a template, find the next unsteady number,
        and update the project file accordingly.

        Parameters:
        template_unsteady (str): Unsteady flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        str: New unsteady flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_unsteady_num = ras_plan.clone_unsteady('01')
        >>> print(f"New unsteady flow file created: u{new_unsteady_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update unsteady entries without reinitializing the entire project
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')

        new_unsteady_num = RasPlan.get_next_number(ras_obj.unsteady_df['unsteady_number'])
        template_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}"
        new_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}"

        # Use RasUtils to clone the file
        RasUtils.clone_file(template_unsteady_path, new_unsteady_path)

        # Copy the corresponding .hdf file if it exists
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}.hdf"
        if template_hdf_path.exists():
            shutil.copy(template_hdf_path, new_hdf_path)

        # Use RasUtils to update the project file
        RasUtils.update_project_file(ras_obj.prj_file, 'Unsteady', new_unsteady_num, ras_object=ras_obj)

        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return new_unsteady_num


    @staticmethod
    @log_call
    def clone_steady(template_flow, ras_object=None):
        """
        Copy steady flow files from a template, find the next flow number,
        and update the project file accordingly.
        
        Parameters:
        template_flow (str): Flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_flow_num = ras_plan.clone_steady('01')
        >>> print(f"New steady flow file created: f{new_flow_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update flow entries without reinitializing the entire project
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')

        new_flow_num = RasPlan.get_next_number(ras_obj.flow_df['flow_number'])
        template_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{template_flow}"
        new_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{new_flow_num}"

        # Use RasUtils to clone the file
        RasUtils.clone_file(template_flow_path, new_flow_path)

        # Use RasUtils to update the project file
        RasUtils.update_project_file(ras_obj.prj_file, 'Flow', new_flow_num, ras_object=ras_obj)

        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)
        
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        return new_flow_num

    @staticmethod
    @log_call
    def clone_geom(template_geom, ras_object=None):
        """
        Copy geometry files from a template, find the next geometry number,
        and update the project file accordingly.
        
        Parameters:
        template_geom (str): Geometry number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New geometry number (e.g., '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update geometry entries without reinitializing the entire project
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')

        new_geom_num = RasPlan.get_next_number(ras_obj.geom_df['geom_number'])
        template_geom_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{template_geom}"
        new_geom_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{new_geom_num}"

        # Use RasUtils to clone the file
        RasUtils.clone_file(template_geom_path, new_geom_path)

        # Handle HDF file copy
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{template_geom}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{new_geom_num}.hdf"
        if template_hdf_path.is_file():
            RasUtils.clone_file(template_hdf_path, new_hdf_path)

        # Use RasUtils to update the project file
        RasUtils.update_project_file(ras_obj.prj_file, 'Geom', new_geom_num, ras_object=ras_obj)

        # Update all dataframes in the ras object
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return new_geom_num

    @staticmethod
    @log_call
    def get_next_number(existing_numbers):
        """
        Determine the next available number from a list of existing numbers.
        
        Parameters:
        existing_numbers (list): List of existing numbers as strings
        
        Returns:
        str: Next available number as a zero-padded string
        
        Example:
        >>> existing_numbers = ['01', '02', '04']
        >>> RasPlan.get_next_number(existing_numbers)
        '03'
        >>> existing_numbers = ['01', '02', '03']
        >>> RasPlan.get_next_number(existing_numbers)
        '04'
        """
        existing_numbers = sorted(int(num) for num in existing_numbers)
        next_number = 1
        for num in existing_numbers:
            if num == next_number:
                next_number += 1
            else:
                break
        return f"{next_number:02d}"

    @staticmethod
    @log_call
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading the plan file

        Available keys and their expected types:
        - 'Computation Interval' (str): Time value for computational time step (e.g., '5SEC', '2MIN')
        - 'DSS File' (str): Name of the DSS file used
        - 'Flow File' (str): Name of the flow input file
        - 'Friction Slope Method' (int): Method selection for friction slope (e.g., 1, 2)
        - 'Geom File' (str): Name of the geometry input file
        - 'Mapping Interval' (str): Time interval for mapping output
        - 'Plan File' (str): Name of the plan file
        - 'Plan Title' (str): Title of the simulation plan
        - 'Program Version' (str): Version number of HEC-RAS
        - 'Run HTAB' (int): Flag to run HTab module (-1 or 1)
        - 'Run Post Process' (int): Flag to run post-processing (-1 or 1)
        - 'Run Sediment' (int): Flag to run sediment transport module (0 or 1)
        - 'Run UNET' (int): Flag to run unsteady network module (-1 or 1)
        - 'Run WQNET' (int): Flag to run water quality module (0 or 1)
        - 'Short Identifier' (str): Short name or ID for the plan
        - 'Simulation Date' (str): Start and end dates/times for simulation
        - 'UNET D1 Cores' (int): Number of cores used in 1D calculations
        - 'UNET Use Existing IB Tables' (int): Flag for using existing internal boundary tables (-1, 0, or 1)
        - 'UNET 1D Methodology' (str): 1D calculation methodology
        - 'UNET D2 Solver Type' (str): 2D solver type
        - 'UNET D2 Name' (str): Name of the 2D area
        - 'Run RASMapper' (int): Flag to run RASMapper for floodplain mapping (-1 for off, 0 for on)
        
        
        Note: 
        Writing Multi line keys like 'Description' are not supported by this function.

        Example:
        >>> computation_interval = RasPlan.get_plan_value("01", "Computation Interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        supported_plan_keys = {
            'Description', 'Computation Interval', 'DSS File', 'Flow File', 'Friction Slope Method',
            'Geom File', 'Mapping Interval', 'Plan File', 'Plan Title', 'Program Version',
            'Run HTAB', 'Run Post Process', 'Run Sediment', 'Run UNET', 'Run WQNET',
            'Short Identifier', 'Simulation Date', 'UNET D1 Cores', 'UNET Use Existing IB Tables',
            'UNET 1D Methodology', 'UNET D2 Solver Type', 'UNET D2 Name', 'Run RASMapper'
        }

        if key not in supported_plan_keys:
            logger = logging.getLogger(__name__)
            logger.warning(f"Unknown key: {key}. Valid keys are: {', '.join(supported_plan_keys)}\n Add more keys and explanations in get_plan_value() as needed.")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object=ras_obj)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logger = logging.getLogger(__name__)
            logger.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'Description':
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key}=(.*)"
            match = re.search(pattern, content)
            if match:
                return match.group(1).strip()
            else:
                logger = logging.getLogger(__name__)
                logger.error(f"Key '{key}' not found in the plan file.")
                return None

    @staticmethod
    @log_call
    def update_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        value: Any,
        ras_object=None
    ) -> None:
        """
        Update a specific key-value pair in a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to update in the plan file
        value (Any): The new value to set for the key
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading or writing the plan file

        Note: See the docstring of get_plan_value for a full list of available keys and their types.

        Example:
        >>> RasPlan.update_plan_value("01", "computation_interval", "10SEC")
        >>> RasPlan.update_plan_value("/path/to/plan.p01", "run_htab", 1)
        >>> RasPlan.update_plan_value("01", "run_rasmapper", 0)  # Turn on Floodplain Mapping
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        supported_plan_keys = {
            'Description', 'Computation Interval', 'DSS File', 'Flow File', 'Friction Slope Method',
            'Geom File', 'Mapping Interval', 'Plan File', 'Plan Title', 'Program Version',
            'Run HTAB', 'Run Post Process', 'Run Sediment', 'Run UNET', 'Run WQNET',
            'Short Identifier', 'Simulation Date', 'UNET D1 Cores', 'UNET Use Existing IB Tables',
            'UNET 1D Methodology', 'UNET D2 Solver Type', 'UNET D2 Name', 'Run RASMapper'
        }
        logger = logging.getLogger(__name__)
        if key not in supported_plan_keys:
            logger.warning(f"Unknown key: {key}. Valid keys are: {', '.join(supported_plan_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                lines = file.readlines()
        except IOError as e:
            logger.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        # Special handling for description
        if key == 'description':
            description_start = None
            description_end = None
            for i, line in enumerate(lines):
                if line.strip() == 'Begin DESCRIPTION':
                    description_start = i
                elif line.strip() == 'END DESCRIPTION':
                    description_end = i
                    break
            if description_start is not None and description_end is not None:
                lines[description_start+1:description_end] = [f"{value}\n"]
            else:
                lines.append(f"Begin DESCRIPTION\n{value}\nEND DESCRIPTION\n")
        else:
            # For other keys
            pattern = f"{key.replace('_', ' ').title()}="
            updated = False
            for i, line in enumerate(lines):
                if line.startswith(pattern):
                    lines[i] = f"{pattern}{value}\n"
                    updated = True
                    break
            if not updated:
                logger.error(f"Key '{key}' not found in the plan file.")
                return

        try:
            with open(plan_file_path, 'w') as file:
                file.writelines(lines)
            logger.info(f"Updated {key} in plan file: {plan_file_path}")
        except IOError as e:
            logger.error(f"Error writing to plan file {plan_file_path}: {e}")
            raise

        # Refresh RasPrj dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
==================================================

File: C:\GH\ras-commander\ras_commander\RasPrj.py
==================================================
"""
RasPrj.py - Manages HEC-RAS projects within the ras-commander library

This module provides a class for managing HEC-RAS projects.

Classes:
    RasPrj: A class for managing HEC-RAS projects.

Functions:
    init_ras_project: Initialize a RAS project.
    get_ras_exe: Determine the HEC-RAS executable path based on the input.

DEVELOPER NOTE:
This class is used to initialize a RAS project and is used in conjunction with the RasCmdr class to manage the execution of RAS plans.
By default, the RasPrj class is initialized with the global 'ras' object.
However, you can create multiple RasPrj instances to manage multiple projects.
Do not mix and match global 'ras' object instances and custom instances of RasPrj - it will cause errors.

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).


Example:
    @log_call
    def my_function():
        
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
import re
from pathlib import Path
import pandas as pd
from typing import Union, Any, List, Dict, Tuple
import logging
from ras_commander.logging_config import get_logger, log_call

logger = get_logger(__name__)

class RasPrj:
    
    def __init__(self):
        self.initialized = False
        self.boundaries_df = None  # New attribute to store boundary conditions

    @log_call
    def initialize(self, project_folder, ras_exe_path):
        """
        Initialize a RasPrj instance.

        This method sets up the RasPrj instance with the given project folder and RAS executable path.
        It finds the project file, loads project data, sets the initialization flag, and now also
        extracts boundary conditions.

        Args:
            project_folder (str or Path): Path to the HEC-RAS project folder.
            ras_exe_path (str or Path): Path to the HEC-RAS executable.

        Raises:
            ValueError: If no HEC-RAS project file is found in the specified folder.

        Note:
            This method is intended for internal use. External users should use the init_ras_project function instead.
        """
        self.project_folder = Path(project_folder)
        self.prj_file = self.find_ras_prj(self.project_folder)
        if self.prj_file is None:
            logger.error(f"No HEC-RAS project file found in {self.project_folder}")
            raise ValueError(f"No HEC-RAS project file found in {self.project_folder}")
        self.project_name = Path(self.prj_file).stem
        self.ras_exe_path = ras_exe_path
        self._load_project_data()
        self.boundaries_df = self.get_boundary_conditions()  # Extract boundary conditions
        self.initialized = True
        logger.info(f"Initialization complete for project: {self.project_name}")
        logger.info(f"Plan entries: {len(self.plan_df)}, Flow entries: {len(self.flow_df)}, "
                     f"Unsteady entries: {len(self.unsteady_df)}, Geometry entries: {len(self.geom_df)}, "
                     f"Boundary conditions: {len(self.boundaries_df)}")

    @log_call
    def _load_project_data(self):
        """
        Load project data from the HEC-RAS project file.

        This method initializes DataFrames for plan, flow, unsteady, and geometry entries
        by calling the _get_prj_entries method for each entry type.
        """
        # Initialize DataFrames
        self.plan_df = self._get_prj_entries('Plan')
        self.flow_df = self._get_prj_entries('Flow')
        self.unsteady_df = self._get_prj_entries('Unsteady')
        self.geom_df = self._get_prj_entries('Geom')

    @log_call
    def _parse_plan_file(self, plan_file_path):
        """
        Parse a plan file and extract critical information.
        
        Args:
            plan_file_path (Path): Path to the plan file.
        
        Returns:
            dict: Dictionary containing extracted plan information.
        """
        plan_info = {}
        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
                
                # Extract description
                description_match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
                if description_match:
                    plan_info['description'] = description_match.group(1).strip()
                
                # BEGIN Exception to Style Guide, this is needed to keep the key names consistent with the plan file keys.
                
                # Extract other critical information
                supported_plan_keys = {
                    'Computation Interval': r'Computation Interval=(.+)',
                    'DSS File': r'DSS File=(.+)',
                    'Flow File': r'Flow File=(.+)',
                    'Friction Slope Method': r'Friction Slope Method=(.+)',
                    'Geom File': r'Geom File=(.+)',
                    'Mapping Interval': r'Mapping Interval=(.+)',
                    'Plan Title': r'Plan Title=(.+)',
                    'Program Version': r'Program Version=(.+)',
                    'Run HTab': r'Run HTab=(.+)',
                    'Run PostProcess': r'Run PostProcess=(.+)',
                    'Run Sediment': r'Run Sediment=(.+)',
                    'Run UNet': r'Run UNet=(.+)',
                    'Run WQNet': r'Run WQNet=(.+)',
                    'Short Identifier': r'Short Identifier=(.+)',
                    'Simulation Date': r'Simulation Date=(.+)',
                    'UNET D1 Cores': r'UNET D1 Cores=(.+)',
                    'UNET Use Existing IB Tables': r'UNET Use Existing IB Tables=(.+)',
                    'UNET 1D Methodology': r'UNET 1D Methodology=(.+)',
                    'UNET D2 SolverType': r'UNET D2 SolverType=(.+)',
                    'UNET D2 Name': r'UNET D2 Name=(.+)'
                }
                
                # END Exception to Style Guide
                
                for key, pattern in supported_plan_keys.items():
                    match = re.search(pattern, content)
                    if match:
                        plan_info[key] = match.group(1).strip()
            
            logger.debug(f"Parsed plan file: {plan_file_path}")
        except Exception as e:
            logger.exception(f"Error parsing plan file {plan_file_path}: {e}")
        
        return plan_info
    

    
    @log_call
    def _get_prj_entries(self, entry_type):
        """
        Extract entries of a specific type from the HEC-RAS project file.

        Args:
            entry_type (str): The type of entry to extract (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the extracted entries.

        Note:
            This method reads the project file and extracts entries matching the specified type.
            For 'Unsteady' entries, it parses additional information from the unsteady file.
        """
        entries = []
        pattern = re.compile(rf"{entry_type} File=(\w+)")

        try:
            with open(self.prj_file, 'r') as file:
                for line in file:
                    match = pattern.match(line.strip())
                    if match:
                        file_name = match.group(1)
                        full_path = str(self.project_folder / f"{self.project_name}.{file_name}")
                        entry = {
                            f'{entry_type.lower()}_number': file_name[1:],
                            'full_path': full_path
                        }

                        if entry_type == 'Plan':
                            plan_info = self._parse_plan_file(Path(full_path))
                            entry.update(plan_info)
                            
                            hdf_results_path = self.project_folder / f"{self.project_name}.p{file_name[1:]}.hdf"
                            entry['HDF_Results_Path'] = str(hdf_results_path) if hdf_results_path.exists() else None

                        if entry_type == 'Unsteady':
                            unsteady_info = self._parse_unsteady_file(Path(full_path))
                            entry.update(unsteady_info)

                        entries.append(entry)
        except Exception as e:
            raise

        return pd.DataFrame(entries)

    @log_call
    def _parse_unsteady_file(self, unsteady_file_path):
        """
        Parse an unsteady flow file and extract critical information.
        
        Args:
            unsteady_file_path (Path): Path to the unsteady flow file.
        
        Returns:
            dict: Dictionary containing extracted unsteady flow information.
        """
        unsteady_info = {}
        with open(unsteady_file_path, 'r') as file:
            content = file.read()
            
            # BEGIN Exception to Style Guide, this is needed to keep the key names consistent with the unsteady file keys.
                
            supported_unsteady_keys = {
                'Flow Title': r'Flow Title=(.+)',
                'Program Version': r'Program Version=(.+)',
                'Use Restart': r'Use Restart=(.+)',
                'Precipitation Mode': r'Precipitation Mode=(.+)',
                'Wind Mode': r'Wind Mode=(.+)',
                'Met BC=Precipitation|Mode': r'Met BC=Precipitation\|Mode=(.+)',
                'Met BC=Evapotranspiration|Mode': r'Met BC=Evapotranspiration\|Mode=(.+)',
                'Met BC=Precipitation|Expanded View': r'Met BC=Precipitation\|Expanded View=(.+)',
                'Met BC=Precipitation|Constant Units': r'Met BC=Precipitation\|Constant Units=(.+)',
                'Met BC=Precipitation|Gridded Source': r'Met BC=Precipitation\|Gridded Source=(.+)'
            }
            
            # END Exception to Style Guide
            
            for key, pattern in supported_unsteady_keys.items():
                match = re.search(pattern, content)
                if match:
                    unsteady_info[key] = match.group(1).strip()
        
        return unsteady_info

    @property
    def is_initialized(self):
        """
        Check if the RasPrj instance has been initialized.

        Returns:
            bool: True if the instance has been initialized, False otherwise.
        """
        return self.initialized

    @log_call
    def check_initialized(self):
        """
        Ensure that the RasPrj instance has been initialized.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        if not self.initialized:
            raise RuntimeError("Project not initialized. Call init_ras_project() first.")

    @staticmethod
    @log_call
    def find_ras_prj(folder_path):
        """
        Find the appropriate HEC-RAS project file (.prj) in the given folder.
        
        Parameters:
        folder_path (str or Path): Path to the folder containing HEC-RAS files.
        
        Returns:
        Path: The full path of the selected .prj file or None if no suitable file is found.
        """
        folder_path = Path(folder_path)
        prj_files = list(folder_path.glob("*.prj"))
        rasmap_files = list(folder_path.glob("*.rasmap"))
        if len(prj_files) == 1:
            return prj_files[0].resolve()
        if len(prj_files) > 1:
            if len(rasmap_files) == 1:
                base_filename = rasmap_files[0].stem
                prj_file = folder_path / f"{base_filename}.prj"
                if prj_file.exists():
                    return prj_file.resolve()
            for prj_file in prj_files:
                try:
                    with open(prj_file, 'r') as file:
                        content = file.read()
                        if "Proj Title=" in content:
                            return prj_file.resolve()
                except Exception:
                    continue
        return None


    @log_call
    def get_project_name(self):
        """
        Get the name of the HEC-RAS project.

        Returns:
            str: The name of the project.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self.project_name

    @log_call
    def get_prj_entries(self, entry_type):
        """
        Get entries of a specific type from the HEC-RAS project.

        Args:
            entry_type (str): The type of entry to retrieve (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the requested entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries(entry_type)

    @log_call
    def get_plan_entries(self):
        """
        Get all plan entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all plan entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Plan')

    @log_call
    def get_flow_entries(self):
        """
        Get all flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Flow')

    @log_call
    def get_unsteady_entries(self):
        """
        Get all unsteady flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all unsteady flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Unsteady')

    @log_call
    def get_geom_entries(self):
        """
        Get all geometry entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all geometry entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Geom')
    
    @log_call
    def get_hdf_entries(self):
        """
        Get HDF entries for plans that have results.
        
        Returns:
            pd.DataFrame: A DataFrame containing plan entries with HDF results.
                      Returns an empty DataFrame if no HDF entries are found.
        """
        self.check_initialized()
        
        hdf_entries = self.plan_df[self.plan_df['HDF_Results_Path'].notna()].copy()
        
        if hdf_entries.empty:
            return pd.DataFrame(columns=self.plan_df.columns)
        
        return hdf_entries
    
    
    @log_call
    def print_data(self):
        """Print all RAS Object data for this instance."""
        self.check_initialized()
        logger.info(f"--- Data for {self.project_name} ---")
        logger.info(f"Project folder: {self.project_folder}")
        logger.info(f"PRJ file: {self.prj_file}")
        logger.info(f"HEC-RAS executable: {self.ras_exe_path}")
        logger.info("Plan files:")
        logger.info(f"\n{self.plan_df}")
        logger.info("Flow files:")
        logger.info(f"\n{self.flow_df}")
        logger.info("Unsteady flow files:")
        logger.info(f"\n{self.unsteady_df}")
        logger.info("Geometry files:")
        logger.info(f"\n{self.geom_df}")
        logger.info("HDF entries:")
        logger.info(f"\n{self.get_hdf_entries()}")
        logger.info("Boundary conditions:")
        logger.info(f"\n{self.boundaries_df}")
        logger.info("----------------------------")

    @staticmethod
    @log_call
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If an invalid key is provided or if the plan file is not found
        IOError: If there's an error reading the plan file

        Note: See the docstring of update_plan_file for a full list of available keys and their types.

        Example:
        >>> computation_interval = RasUtils.get_plan_value("01", "computation_interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        logger = getLogger(__name__)
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name'
        }

        if key not in valid_keys:
            logger.error(f"Invalid key: {key}")
            raise ValueError(f"Invalid key: {key}. Valid keys are: {', '.join(valid_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                logger.error(f"Plan file not found: {plan_file_path}")
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logger.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'description':
            import re
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key.replace('_', ' ').title()}=(.*)"
            import re
            match = re.search(pattern, content)
            return match.group(1).strip() if match else None

    @log_call
    def get_boundary_conditions(self) -> pd.DataFrame:
        """
        Extract boundary conditions from unsteady flow files and create a DataFrame.

        This method parses unsteady flow files to extract boundary condition information.
        It creates a DataFrame with structured data for known boundary condition types
        and parameters, and associates this information with the corresponding unsteady flow file.

        Note:
        Any lines in the boundary condition blocks that are not explicitly parsed and
        incorporated into the DataFrame are captured in a multi-line string. This string
        is logged at the DEBUG level for each boundary condition. This feature is crucial
        for developers incorporating new boundary condition types or parameters, as it
        allows them to see what information might be missing from the current parsing logic.
        If no unsteady flow files are present, it returns an empty DataFrame.

        Returns:
            pd.DataFrame: A DataFrame containing detailed boundary condition information,
                                      linked to the unsteady flow files.

        Usage:
            To see the unparsed lines, set the logging level to DEBUG before calling this method:
            
            import logging
            getLogger().setLevel(logging.DEBUG)
            
            boundaries_df = ras_project.get_boundary_conditions()
                          linked to the unsteady flow files. Returns an empty DataFrame if
                          no unsteady flow files are present.
        """
        boundary_data = []
        
        # Check if unsteady_df is empty
        if self.unsteady_df.empty:
            logger.info("No unsteady flow files found in the project.")
            return pd.DataFrame()  # Return an empty DataFrame
        
        for _, row in self.unsteady_df.iterrows():
            unsteady_file_path = row['full_path']
            unsteady_number = row['unsteady_number']
            
            try:
                with open(unsteady_file_path, 'r') as file:
                    content = file.read()
            except IOError as e:
                logger.error(f"Error reading unsteady file {unsteady_file_path}: {e}")
                continue
                
            bc_blocks = re.split(r'(?=Boundary Location=)', content)[1:]
            
            for i, block in enumerate(bc_blocks, 1):
                bc_info, unparsed_lines = self._parse_boundary_condition(block, unsteady_number, i)
                boundary_data.append(bc_info)
                
                if unparsed_lines:
                    logger.debug(f"Unparsed lines for boundary condition {i} in unsteady file {unsteady_number}:\n{unparsed_lines}")
        
        if not boundary_data:
            logger.info("No boundary conditions found in unsteady flow files.")
            return pd.DataFrame()  # Return an empty DataFrame if no boundary conditions were found
        
        boundaries_df = pd.DataFrame(boundary_data)
        
        # Merge with unsteady_df to get relevant unsteady flow file information
        merged_df = pd.merge(boundaries_df, self.unsteady_df, 
                             left_on='unsteady_number', right_on='unsteady_number', how='left')
        
        return merged_df

    @log_call
    def _parse_boundary_condition(self, block: str, unsteady_number: str, bc_number: int) -> Tuple[Dict, str]:
        lines = block.split('\n')
        bc_info = {
            'unsteady_number': unsteady_number,
            'boundary_condition_number': bc_number
        }
        
        parsed_lines = set()
        
        # Parse Boundary Location
        boundary_location = lines[0].split('=')[1].strip()
        fields = [field.strip() for field in boundary_location.split(',')]
        bc_info.update({
            'river_reach_name': fields[0] if len(fields) > 0 else '',
            'river_station': fields[1] if len(fields) > 1 else '',
            'storage_area_name': fields[2] if len(fields) > 2 else '',
            'pump_station_name': fields[3] if len(fields) > 3 else ''
        })
        parsed_lines.add(0)
        
        # Determine BC Type
        bc_types = {
            'Flow Hydrograph=': 'Flow Hydrograph',
            'Lateral Inflow Hydrograph=': 'Lateral Inflow Hydrograph',
            'Uniform Lateral Inflow Hydrograph=': 'Uniform Lateral Inflow Hydrograph',
            'Stage Hydrograph=': 'Stage Hydrograph',
            'Friction Slope=': 'Normal Depth',
            'Gate Name=': 'Gate Opening'
        }
        
        bc_info['bc_type'] = 'Unknown'
        bc_info['hydrograph_type'] = None
        for i, line in enumerate(lines[1:], 1):
            for key, bc_type in bc_types.items():
                if line.startswith(key):
                    bc_info['bc_type'] = bc_type
                    if 'Hydrograph' in bc_type:
                        bc_info['hydrograph_type'] = bc_type
                    parsed_lines.add(i)
                    break
            if bc_info['bc_type'] != 'Unknown':
                break
        
        # Parse other fields
        known_fields = ['Interval', 'DSS Path', 'Use DSS', 'Use Fixed Start Time', 'Fixed Start Date/Time',
                        'Is Critical Boundary', 'Critical Boundary Flow', 'DSS File']
        for i, line in enumerate(lines):
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                if key in known_fields:
                    bc_info[key] = value.strip()
                    parsed_lines.add(i)
        
        # Handle hydrograph values
        bc_info['hydrograph_num_values'] = 0
        if bc_info['hydrograph_type']:
            hydrograph_key = f"{bc_info['hydrograph_type']}="
            hydrograph_line = next((line for i, line in enumerate(lines) if line.startswith(hydrograph_key)), None)
            if hydrograph_line:
                hydrograph_index = lines.index(hydrograph_line)
                values_count = int(hydrograph_line.split('=')[1].strip())
                bc_info['hydrograph_num_values'] = values_count
                if values_count > 0:
                    values = ' '.join(lines[hydrograph_index + 1:]).split()[:values_count]
                    bc_info['hydrograph_values'] = values
                    parsed_lines.update(range(hydrograph_index, hydrograph_index + (values_count // 5) + 2))
        
        # Collect unparsed lines
        unparsed_lines = '\n'.join(line for i, line in enumerate(lines) if i not in parsed_lines and line.strip())
        
        if unparsed_lines:
            logger.debug(f"Unparsed lines for boundary condition {bc_number} in unsteady file {unsteady_number}:\n{unparsed_lines}")
        
        return bc_info, unparsed_lines


# Create a global instance named 'ras'
# Defining the global instance allows the init_ras_project function to initialize the project.
# This only happens on the library initialization, not when the user calls init_ras_project.
ras = RasPrj()

# END OF CLASS DEFINITION


# START OF FUNCTION DEFINITIONS


@log_call
def init_ras_project(ras_project_folder, ras_version=None, ras_instance=None):
    """
    Initialize a RAS project.

    USE THIS FUNCTION TO INITIALIZE A RAS PROJECT, NOT THE INITIALIZE METHOD OF THE RasPrj CLASS.
    The initialize method of the RasPrj class only modifies the global 'ras' object.

    This function creates or initializes a RasPrj instance, providing a safer and more
    flexible interface than directly using the 'initialize' method.

    Parameters:
    -----------
    ras_project_folder : str
        The path to the RAS project folder.
    ras_version : str, optional
        The version of RAS to use (e.g., "6.6").
        The version can also be a full path to the Ras.exe file. (Useful when calling ras objects for folder copies.)
        If None, the function will attempt to use the version from the global 'ras' object or a default path.
        You MUST specify a version number via init at some point or ras will not run.  
        Once the ras_version is specified once it should auto-fill from the global 'ras' object.
        The RAS Commander Library Assistant can ignore this argument since it does not have Ras.exe present, but all of other operations are fully working.
    ras_instance : RasPrj, optional
        An instance of RasPrj to initialize. If None, the global 'ras' instance is used.

    Returns:
    --------
    RasPrj
        An initialized RasPrj instance.

    Usage:
    ------
    1. For general use with a single project:
        init_ras_project("/path/to/project")
        # Use the global 'ras' object after initialization

    2. For managing multiple projects:
        project1 = init_ras_project("/path/to/project1", "6.6", ras_instance=RasPrj())
        project2 = init_ras_project("/path/to/project2", ras_instance=RasPrj())

    Notes:
    ------
    - This function is preferred over directly calling the 'initialize' method.
    - It supports both the global 'ras' object and custom instances.
    - Be consistent in your approach: stick to either the global 'ras' object
      or custom instances throughout your script or application.
    - Document your choice of approach clearly in your code.
    - If ras_version is not provided, the function will attempt to use the version
      from the global 'ras' object or a default path.

    Warnings:
    ---------
    Avoid mixing use of the global 'ras' object and custom instances to prevent
    confusion and potential bugs.
    """
    if not Path(ras_project_folder).exists():
        logger.error(f"The specified RAS project folder does not exist: {ras_project_folder}")
        raise FileNotFoundError(f"The specified RAS project folder does not exist: {ras_project_folder}. Please check the path and try again.")

    ras_exe_path = get_ras_exe(ras_version)

    if ras_instance is None:
        logger.info("Initializing global 'ras' object via init_ras_project function.")
        ras_instance = ras
    elif not isinstance(ras_instance, RasPrj):
        logger.error("Provided ras_instance is not an instance of RasPrj.")
        raise TypeError("ras_instance must be an instance of RasPrj or None.")

    # Initialize the RasPrj instance
    ras_instance.initialize(ras_project_folder, ras_exe_path)
    
    logger.info(f"Project initialized. ras_instance project folder: {ras_instance.project_folder}")
    return ras_instance

@log_call
def get_ras_exe(ras_version=None):
    """
    Determine the HEC-RAS executable path based on the input.
    
    Args:
        ras_version (str, optional): Either a version number or a full path to the HEC-RAS executable.
                                     If None, the function will attempt to use the version from the global 'ras' object
                                     or a default path.
    
    Returns:
        str: The full path to the HEC-RAS executable.
    
    Raises:
        ValueError: If the input is neither a valid version number nor a valid file path.
    
    Notes:
        - If ras_version is not provided, the function will first check the global 'ras' object for a path.
        - If the global 'ras' object is not initialized or doesn't have a path, a default path will be used.
        - The default path allows the library to function in environments without HEC-RAS installed.
        - This enables the HEC-Commander GPT to operate without stopping, even if HEC-RAS is not present.
        - End users MUST use logging to check for operational errors, as full code stops prevent the GPT from running.
    """
    if ras_version is None:
        if hasattr(ras, 'ras_exe_path') and ras.ras_exe_path:
            logger.info(f"Using HEC-RAS executable from global 'ras' object: {ras.ras_exe_path}")
            return ras.ras_exe_path
        else:
            default_path = Path("Ras.exe")
            logger.warning(f"No HEC-RAS version specified and global 'ras' object not initialized or missing ras_exe_path. Using default path: {default_path}. The RAS Commander (ras-commander) Library Assistant can ignore this error since it does not have HEC-RAS installed.")
            return str(default_path)
    
    ras_version_numbers = [
        "6.6", "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
        "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
        "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
    ]
    
    hecras_path = Path(ras_version)
    
    if hecras_path.is_file() and hecras_path.suffix.lower() == '.exe':
        logger.info(f"HEC-RAS executable found at specified path: {hecras_path}")
        return str(hecras_path)
    
    if ras_version in ras_version_numbers:
        default_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
        if default_path.is_file():
            logger.info(f"HEC-RAS executable found at default path: {default_path}")
            return str(default_path)
        else:
            logger.critical(f"HEC-RAS executable not found at the expected path: {default_path}")
    
    try:
        version_float = float(ras_version)
        if version_float > max(float(v) for v in ras_version_numbers):
            newer_version_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
            if newer_version_path.is_file():
                logger.info(f"Newer version of HEC-RAS executable found at: {newer_version_path}")
                return str(newer_version_path)
            else:
                logger.critical("Newer version of HEC-RAS was specified, but the executable was not found.")
    except ValueError:
        pass
    
    logger.error(f"Invalid HEC-RAS version or path: {ras_version}, returning default path: {default_path}")
    #raise ValueError(f"Invalid HEC-RAS version or path: {ras_version}") # don't raise an error here, just return the default path
    return str(default_path)
    

==================================================

File: C:\GH\ras-commander\ras_commander\RasUnsteady.py
==================================================
"""
RasUnsteady - Operations for handling unsteady flow files in HEC-RAS projects.

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).


Example:
    @log_call
    def my_function():
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
from pathlib import Path
from .RasPrj import ras
from ras_commander.logging_config import get_logger, log_call

logger = get_logger(__name__)

# Module code starts here

class RasUnsteady:
    """
    Class for all operations related to HEC-RAS unsteady flow files.
    """
    
    @staticmethod
    @log_call
    def update_unsteady_parameters(unsteady_file, modifications, ras_object=None):
        """
        Modify parameters in an unsteady flow file.
        
        Parameters:
        unsteady_file (str): Full path to the unsteady flow file
        modifications (dict): Dictionary of modifications to apply, where keys are parameter names and values are new values
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Note:
            This function updates the ras object's unsteady dataframe after modifying the unsteady flow file.
        
        Example:
            from ras_commander import RasCmdr
            
            # Initialize RAS project
            ras_cmdr = RasCmdr()
            ras_cmdr.init_ras_project(project_folder, ras_version)
            
            # Update unsteady parameters
            unsteady_file = r"path/to/unsteady_file.u01"
            modifications = {"Parameter1": "NewValue1", "Parameter2": "NewValue2"}
            RasUnsteady.update_unsteady_parameters(unsteady_file, modifications, ras_object=ras_cmdr.ras)
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        unsteady_path = Path(unsteady_file)
        try:
            with open(unsteady_path, 'r') as f:
                lines = f.readlines()
            logger.debug(f"Successfully read unsteady flow file: {unsteady_path}")
        except FileNotFoundError:
            logger.error(f"Unsteady flow file not found: {unsteady_path}")
            raise FileNotFoundError(f"Unsteady flow file not found: {unsteady_path}")
        except PermissionError:
            logger.error(f"Permission denied when reading unsteady flow file: {unsteady_path}")
            raise PermissionError(f"Permission denied when reading unsteady flow file: {unsteady_path}")
        
        updated = False
        for i, line in enumerate(lines):
            for param, new_value in modifications.items():
                if line.startswith(f"{param}="):
                    old_value = line.strip().split('=')[1]
                    lines[i] = f"{param}={new_value}\n"
                    updated = True
                    logger.info(f"Updated {param} from {old_value} to {new_value}")
        
        if updated:
            try:
                with open(unsteady_path, 'w') as f:
                    f.writelines(lines)
                logger.debug(f"Successfully wrote modifications to unsteady flow file: {unsteady_path}")
            except PermissionError:
                logger.error(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
                raise PermissionError(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
            except IOError as e:
                logger.error(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
                raise IOError(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
            logger.info(f"Applied modifications to {unsteady_file}")
        else:
            logger.warning(f"No matching parameters found in {unsteady_file}")
    
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

==================================================

File: C:\GH\ras-commander\ras_commander\RasUtils.py
==================================================
"""
RasUtils - Utility functions for the ras-commander library

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).

Example:
    @log_call
    def my_function():
        logger.debug("Additional debug information")
        # Function logic here
"""
import os
from pathlib import Path
from .RasPrj import ras
from typing import Union, Optional, Dict, Callable
import pandas as pd
import numpy as np
import shutil
from ras_commander import get_logger
from ras_commander.logging_config import get_logger, log_call
import re

logger = get_logger(__name__)
# Module code starts here

class RasUtils:
    """
    A class containing utility functions for the ras-commander library.
    When integrating new functions that do not clearly fit into other classes, add them here.
    """

    @staticmethod
    @log_call
    def create_backup(file_path: Path, backup_suffix: str = "_backup", ras_object=None) -> Path:
        """
        Create a backup of the specified file.

        Parameters:
        file_path (Path): Path to the file to be backed up
        backup_suffix (str): Suffix to append to the backup file name
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the created backup file

        Example:
        >>> backup_path = RasUtils.create_backup(Path("project.prj"))
        >>> print(f"Backup created at: {backup_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        original_path = Path(file_path)
        backup_path = original_path.with_name(f"{original_path.stem}{backup_suffix}{original_path.suffix}")
        try:
            shutil.copy2(original_path, backup_path)
            logger.info(f"Backup created: {backup_path}")
        except Exception as e:
            logger.error(f"Failed to create backup for {original_path}: {e}")
            raise
        return backup_path

    @staticmethod
    @log_call
    def restore_from_backup(backup_path: Path, remove_backup: bool = True, ras_object=None) -> Path:
        """
        Restore a file from its backup.

        Parameters:
        backup_path (Path): Path to the backup file
        remove_backup (bool): Whether to remove the backup file after restoration
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the restored file

        Example:
        >>> restored_path = RasUtils.restore_from_backup(Path("project_backup.prj"))
        >>> print(f"File restored to: {restored_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        backup_path = Path(backup_path)
        if '_backup' not in backup_path.stem:
            logger.error(f"Backup suffix '_backup' not found in {backup_path.name}")
            raise ValueError(f"Backup suffix '_backup' not found in {backup_path.name}")
        
        original_stem = backup_path.stem.rsplit('_backup', 1)[0]
        original_path = backup_path.with_name(f"{original_stem}{backup_path.suffix}")
        try:
            shutil.copy2(backup_path, original_path)
            logger.info(f"File restored: {original_path}")
            if remove_backup:
                backup_path.unlink()
                logger.info(f"Backup removed: {backup_path}")
        except Exception as e:
            logger.error(f"Failed to restore from backup {backup_path}: {e}")
            raise
        return original_path

    @staticmethod
    @log_call
    def create_directory(directory_path: Path, ras_object=None) -> Path:
        """
        Ensure that a directory exists, creating it if necessary.

        Parameters:
        directory_path (Path): Path to the directory
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the ensured directory

        Example:
        >>> ensured_dir = RasUtils.create_directory(Path("output"))
        >>> print(f"Directory ensured: {ensured_dir}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(directory_path)
        try:
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Directory ensured: {path}")
        except Exception as e:
            logger.error(f"Failed to create directory {path}: {e}")
            raise
        return path

    @staticmethod
    @log_call
    def find_files_by_extension(extension: str, ras_object=None) -> list:
        """
        List all files in the project directory with a specific extension.

        Parameters:
        extension (str): File extension to filter (e.g., '.prj')
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        list: List of file paths matching the extension

        Example:
        >>> prj_files = RasUtils.find_files_by_extension('.prj')
        >>> print(f"Found {len(prj_files)} .prj files")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        try:
            files = list(ras_obj.project_folder.glob(f"*{extension}"))
            file_list = [str(file) for file in files]
            logger.info(f"Found {len(file_list)} files with extension '{extension}' in {ras_obj.project_folder}")
            return file_list
        except Exception as e:
            logger.error(f"Failed to find files with extension '{extension}': {e}")
            raise

    @staticmethod
    @log_call
    def get_file_size(file_path: Path, ras_object=None) -> Optional[int]:
        """
        Get the size of a file in bytes.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[int]: Size of the file in bytes, or None if the file does not exist

        Example:
        >>> size = RasUtils.get_file_size(Path("project.prj"))
        >>> print(f"File size: {size} bytes")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                size = path.stat().st_size
                logger.info(f"Size of {path}: {size} bytes")
                return size
            except Exception as e:
                logger.error(f"Failed to get size for {path}: {e}")
                raise
        else:
            logger.warning(f"File not found: {path}")
            return None

    @staticmethod
    @log_call
    def get_file_modification_time(file_path: Path, ras_object=None) -> Optional[float]:
        """
        Get the last modification time of a file.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[float]: Last modification time as a timestamp, or None if the file does not exist

        Example:
        >>> mtime = RasUtils.get_file_modification_time(Path("project.prj"))
        >>> print(f"Last modified: {mtime}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                mtime = path.stat().st_mtime
                logger.info(f"Last modification time of {path}: {mtime}")
                return mtime
            except Exception as e:
                logger.exception(f"Failed to get modification time for {path}")
                raise
        else:
            logger.warning(f"File not found: {path}")
            return None

    @staticmethod
    @log_call
    def get_plan_path(current_plan_number_or_path: Union[str, Path], ras_object=None) -> Path:
        """
        Get the path for a plan file with a given plan number or path.

        Parameters:
        current_plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Full path to the plan file

        Example:
        >>> plan_path = RasUtils.get_plan_path(1)
        >>> print(f"Plan file path: {plan_path}")
        >>> plan_path = RasUtils.get_plan_path("path/to/plan.p01")
        >>> print(f"Plan file path: {plan_path}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        plan_path = Path(current_plan_number_or_path)
        if plan_path.is_file():
            logger.info(f"Using provided plan file path: {plan_path}")
            return plan_path
        
        try:
            current_plan_number = f"{int(current_plan_number_or_path):02d}"  # Ensure two-digit format
            logger.debug(f"Converted plan number to two-digit format: {current_plan_number}")
        except ValueError:
            logger.error(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
            raise ValueError(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
        
        plan_name = f"{ras_obj.project_name}.p{current_plan_number}"
        full_plan_path = ras_obj.project_folder / plan_name
        logger.info(f"Constructed plan file path: {full_plan_path}")
        return full_plan_path

    @staticmethod
    @log_call
    def remove_with_retry(
        path: Path,
        max_attempts: int = 5,
        initial_delay: float = 1.0,
        is_folder: bool = True,
        ras_object=None
    ) -> bool:
        """
        Attempts to remove a file or folder with retry logic and exponential backoff.

        Parameters:
        path (Path): Path to the file or folder to be removed.
        max_attempts (int): Maximum number of removal attempts.
        initial_delay (float): Initial delay between attempts in seconds.
        is_folder (bool): If True, the path is treated as a folder; if False, it's treated as a file.
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        bool: True if the file or folder was successfully removed, False otherwise.

        Example:
        >>> success = RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
        >>> print(f"Removal successful: {success}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        path = Path(path)
        for attempt in range(1, max_attempts + 1):
            try:
                if path.exists():
                    if is_folder:
                        shutil.rmtree(path)
                        logger.info(f"Folder removed: {path}")
                    else:
                        path.unlink()
                        logger.info(f"File removed: {path}")
                else:
                    logger.info(f"Path does not exist, nothing to remove: {path}")
                return True
            except PermissionError as pe:
                if attempt < max_attempts:
                    delay = initial_delay * (2 ** (attempt - 1))  # Exponential backoff
                    logger.warning(
                        f"PermissionError on attempt {attempt} to remove {path}: {pe}. "
                        f"Retrying in {delay} seconds..."
                    )
                    time.sleep(delay)
                else:
                    logger.error(
                        f"Failed to remove {path} after {max_attempts} attempts due to PermissionError: {pe}. Skipping."
                    )
                    return False
            except Exception as e:
                logger.exception(f"Failed to remove {path} on attempt {attempt}")
                return False
        return False

    @staticmethod
    @log_call
    def update_plan_file(
        plan_number_or_path: Union[str, Path],
        file_type: str,
        entry_number: int,
        ras_object=None
    ) -> None:
        """
        Update a plan file with a new file reference.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        file_type (str): Type of file to update ('Geom', 'Flow', or 'Unsteady')
        entry_number (int): Number (from 1 to 99) to set
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Raises:
        ValueError: If an invalid file_type is provided
        FileNotFoundError: If the plan file doesn't exist

        Example:
        >>> RasUtils.update_plan_file(1, "Geom", 2)
        >>> RasUtils.update_plan_file("path/to/plan.p01", "Geom", 2)
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        valid_file_types = {'Geom': 'g', 'Flow': 'f', 'Unsteady': 'u'}
        if file_type not in valid_file_types:
            logger.error(
                f"Invalid file_type '{file_type}'. Expected one of: {', '.join(valid_file_types.keys())}"
            )
            raise ValueError(
                f"Invalid file_type. Expected one of: {', '.join(valid_file_types.keys())}"
            )

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                logger.error(f"Plan file not found: {plan_file_path}")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}")
        
        file_prefix = valid_file_types[file_type]
        search_pattern = f"{file_type} File="
        formatted_entry_number = f"{int(entry_number):02d}"  # Ensure two-digit format

        try:
            RasUtils.check_file_access(plan_file_path, 'r')
            with plan_file_path.open('r') as file:
                lines = file.readlines()
        except Exception as e:
            logger.exception(f"Failed to read plan file {plan_file_path}")
            raise

        updated = False
        for i, line in enumerate(lines):
            if line.startswith(search_pattern):
                lines[i] = f"{search_pattern}{file_prefix}{formatted_entry_number}\n"
                logger.info(
                    f"Updated {file_type} File in {plan_file_path} to {file_prefix}{formatted_entry_number}"
                )
                updated = True
                break

        if not updated:
            logger.warning(
                f"Search pattern '{search_pattern}' not found in {plan_file_path}. No update performed."
            )

        try:
            with plan_file_path.open('w') as file:
                file.writelines(lines)
            logger.info(f"Successfully updated plan file: {plan_file_path}")
        except Exception as e:
            logger.exception(f"Failed to write updates to plan file {plan_file_path}")
            raise

        # Refresh RasPrj dataframes
        try:
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
            logger.info("RAS object dataframes have been refreshed.")
        except Exception as e:
            logger.exception("Failed to refresh RasPrj dataframes")
            raise

    @staticmethod
    @log_call
    def check_file_access(file_path: Path, mode: str = 'r') -> None:
        """
        Check if the file can be accessed with the specified mode.

        Parameters:
        file_path (Path): Path to the file
        mode (str): Mode to check ('r' for read, 'w' for write, etc.)

        Raises:
        FileNotFoundError: If the file does not exist
        PermissionError: If the required permissions are not met
        """
        
        path = Path(file_path)
        if not path.exists():
            logger.error(f"File not found: {file_path}")
            raise FileNotFoundError(f"File not found: {file_path}")
        
        if mode in ('r', 'rb'):
            if not os.access(path, os.R_OK):
                logger.error(f"Read permission denied for file: {file_path}")
                raise PermissionError(f"Read permission denied for file: {file_path}")
            else:
                logger.debug(f"Read access granted for file: {file_path}")
        
        if mode in ('w', 'wb', 'a', 'ab'):
            parent_dir = path.parent
            if not os.access(parent_dir, os.W_OK):
                logger.error(f"Write permission denied for directory: {parent_dir}")
                raise PermissionError(f"Write permission denied for directory: {parent_dir}")
            else:
                logger.debug(f"Write access granted for directory: {parent_dir}")


    @staticmethod
    @log_call
    def convert_to_dataframe(data_source: Union[pd.DataFrame, Path], **kwargs) -> pd.DataFrame:
        """
        Converts input to a pandas DataFrame. Supports existing DataFrames or file paths (CSV, Excel, TSV, Parquet).

        Args:
            data_source (Union[pd.DataFrame, Path]): The input to convert to a DataFrame. Can be a file path or an existing DataFrame.
            **kwargs: Additional keyword arguments to pass to pandas read functions.

        Returns:
            pd.DataFrame: The resulting DataFrame.

        Raises:
            NotImplementedError: If the file type is unsupported or input type is invalid.

        Example:
            >>> df = RasUtils.convert_to_dataframe(Path("data.csv"))
            >>> print(type(df))
            <class 'pandas.core.frame.DataFrame'>
        """
        if isinstance(data_source, pd.DataFrame):
            logger.debug("Input is already a DataFrame, returning a copy.")
            return data_source.copy()
        elif isinstance(data_source, Path):
            ext = data_source.suffix.replace('.', '', 1)
            logger.info(f"Converting file with extension '{ext}' to DataFrame.")
            if ext == 'csv':
                return pd.read_csv(data_source, **kwargs)
            elif ext.startswith('x'):
                return pd.read_excel(data_source, **kwargs)
            elif ext == "tsv":
                return pd.read_csv(data_source, sep="\t", **kwargs)
            elif ext in ["parquet", "pq", "parq"]:
                return pd.read_parquet(data_source, **kwargs)
            else:
                logger.error(f"Unsupported file type: {ext}")
                raise NotImplementedError(f"Unsupported file type {ext}. Should be one of csv, tsv, parquet, or xlsx.")
        else:
            logger.error(f"Unsupported input type: {type(data_source)}")
            raise NotImplementedError(f"Unsupported type {type(data_source)}. Only file path / existing DataFrame supported at this time")

    @staticmethod
    @log_call
    def save_to_excel(dataframe: pd.DataFrame, excel_path: Path, **kwargs) -> None:
        """
        Saves a pandas DataFrame to an Excel file with retry functionality.

        Args:
            dataframe (pd.DataFrame): The DataFrame to save.
            excel_path (Path): The path to the Excel file where the DataFrame will be saved.
            **kwargs: Additional keyword arguments passed to `DataFrame.to_excel()`.

        Raises:
            IOError: If the file cannot be saved after multiple attempts.

        Example:
            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
            >>> RasUtils.save_to_excel(df, Path('output.xlsx'))
        """
        saved = False
        max_attempts = 3
        attempt = 0

        while not saved and attempt < max_attempts:
            try:
                dataframe.to_excel(excel_path, **kwargs)
                logger.info(f'DataFrame successfully saved to {excel_path}')
                saved = True
            except IOError as e:
                attempt += 1
                if attempt < max_attempts:
                    logger.warning(f"Error saving file. Attempt {attempt} of {max_attempts}. Please close the Excel document if it's open.")
                else:
                    logger.error(f"Failed to save {excel_path} after {max_attempts} attempts.")
                    raise IOError(f"Failed to save {excel_path} after {max_attempts} attempts. Last error: {str(e)}")

    @staticmethod
    @log_call
    def calculate_rmse(observed_values: np.ndarray, predicted_values: np.ndarray, normalized: bool = True) -> float:
        """
        Calculate the Root Mean Squared Error (RMSE) between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            normalized (bool, optional): Whether to normalize RMSE to a percentage of observed_values. Defaults to True.

        Returns:
            float: The calculated RMSE value.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_rmse(observed, predicted)
            0.06396394
        """
        rmse = np.sqrt(np.mean((predicted_values - observed_values) ** 2))
        
        if normalized:
            rmse = rmse / np.abs(np.mean(observed_values))
        
        logger.debug(f"Calculated RMSE: {rmse}")
        return rmse

    @staticmethod
    @log_call
    def calculate_percent_bias(observed_values: np.ndarray, predicted_values: np.ndarray, as_percentage: bool = False) -> float:
        """
        Calculate the Percent Bias between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            as_percentage (bool, optional): If True, return bias as a percentage. Defaults to False.

        Returns:
            float: The calculated Percent Bias.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)
            3.33333333
        """
        multiplier = 100 if as_percentage else 1
        
        percent_bias = multiplier * (np.mean(predicted_values) - np.mean(observed_values)) / np.mean(observed_values)
        
        logger.debug(f"Calculated Percent Bias: {percent_bias}")
        return percent_bias

    @staticmethod
    @log_call
    def calculate_error_metrics(observed_values: np.ndarray, predicted_values: np.ndarray) -> Dict[str, float]:
        """
        Compute a trio of error metrics: correlation, RMSE, and Percent Bias.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.

        Returns:
            Dict[str, float]: A dictionary containing correlation ('cor'), RMSE ('rmse'), and Percent Bias ('pb').

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_error_metrics(observed, predicted)
            {'cor': 0.9993, 'rmse': 0.06396, 'pb': 0.03333}
        """
        correlation = np.corrcoef(observed_values, predicted_values)[0, 1]
        rmse = RasUtils.calculate_rmse(observed_values, predicted_values)
        percent_bias = RasUtils.calculate_percent_bias(observed_values, predicted_values)
        
        metrics = {'cor': correlation, 'rmse': rmse, 'pb': percent_bias}
        logger.info(f"Calculated error metrics: {metrics}")
        return metrics

    
    @staticmethod
    @log_call
    def update_file(file_path: Path, update_function: Callable, *args) -> None:
        """
        Generic method to update a file.

        Parameters:
        file_path (Path): Path to the file to be updated
        update_function (Callable): Function to update the file contents
        *args: Additional arguments to pass to the update_function

        Raises:
        Exception: If there's an error updating the file

        Example:
        >>> def update_content(lines, new_value):
        ...     lines[0] = f"New value: {new_value}\\n"
        ...     return lines
        >>> RasUtils.update_file(Path("example.txt"), update_content, "Hello")
        """
        try:
            with open(file_path, 'r') as f:
                lines = f.readlines()
            
            updated_lines = update_function(lines, *args) if args else update_function(lines)
            
            with open(file_path, 'w') as f:
                f.writelines(updated_lines)
            logger.info(f"Successfully updated file: {file_path}")
        except Exception as e:
            logger.exception(f"Failed to update file {file_path}")
            raise

    @staticmethod
    @log_call
    def get_next_number(existing_numbers: list) -> str:
        """
        Determine the next available number from a list of existing numbers.

        Parameters:
        existing_numbers (list): List of existing numbers as strings

        Returns:
        str: Next available number as a zero-padded string

        Example:
        >>> RasUtils.get_next_number(["01", "02", "04"])
        "05"
        """
        existing_numbers = sorted(int(num) for num in existing_numbers)
        next_number = max(existing_numbers, default=0) + 1
        return f"{next_number:02d}"

    @staticmethod
    @log_call
    def clone_file(template_path: Path, new_path: Path, update_function: Optional[Callable] = None, *args) -> None:
        """
        Generic method to clone a file and optionally update it.

        Parameters:
        template_path (Path): Path to the template file
        new_path (Path): Path where the new file will be created
        update_function (Optional[Callable]): Function to update the cloned file
        *args: Additional arguments to pass to the update_function

        Raises:
        FileNotFoundError: If the template file doesn't exist

        Example:
        >>> def update_content(lines, new_value):
        ...     lines[0] = f"New value: {new_value}\\n"
        ...     return lines
        >>> RasUtils.clone_file(Path("template.txt"), Path("new.txt"), update_content, "Hello")
        """
        if not template_path.exists():
            logger.error(f"Template file '{template_path}' does not exist.")
            raise FileNotFoundError(f"Template file '{template_path}' does not exist.")

        shutil.copy(template_path, new_path)
        logger.info(f"File cloned from {template_path} to {new_path}")

        if update_function:
            RasUtils.update_file(new_path, update_function, *args)
    @staticmethod
    @log_call
    def update_project_file(prj_file: Path, file_type: str, new_num: str, ras_object=None) -> None:
        """
        Update the project file with a new entry.

        Parameters:
        prj_file (Path): Path to the project file
        file_type (str): Type of file being added (e.g., 'Plan', 'Geom')
        new_num (str): Number of the new file entry
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Example:
        >>> RasUtils.update_project_file(Path("project.prj"), "Plan", "02")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        try:
            with open(prj_file, 'r') as f:
                lines = f.readlines()
            
            new_line = f"{file_type} File={file_type[0].lower()}{new_num}\n"
            lines.append(new_line)
            
            with open(prj_file, 'w') as f:
                f.writelines(lines)
            logger.info(f"Project file updated with new {file_type} entry: {new_num}")
        except Exception as e:
            logger.exception(f"Failed to update project file {prj_file}")
            raise

==================================================

File: C:\GH\ras-commander\ras_commander\__init__.py
==================================================
from importlib.metadata import version, PackageNotFoundError
from .logging_config import setup_logging, get_logger, log_call

try:
    __version__ = version("ras-commander")
except PackageNotFoundError:
    # package is not installed
    __version__ = "unknown"

# Set up logging
setup_logging()

# Import all necessary functions and classes directly
from .RasPrj import ras, init_ras_project, get_ras_exe
from .RasPrj import RasPrj
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUnsteady import RasUnsteady
from .RasCmdr import RasCmdr
from .RasUtils import RasUtils
from .RasExamples import RasExamples
from .RasHdf import RasHdf
from .RasGpt import RasGpt

# Define __all__ to specify what should be imported when using "from ras_commander import *"
__all__ = [
    "ras",
    "init_ras_project",
    "get_ras_exe",
    "RasPrj",
    "RasPlan",
    "RasGeo",
    "RasUnsteady",
    "RasCmdr",
    "RasUtils",
    "RasExamples",
    "RasHdf",
    "RasGpt",
    "get_logger",
    "log_call"
]
==================================================

