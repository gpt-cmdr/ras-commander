File: c:\GH\ras-commander\.cursorrules
==================================================
# RAS Commander (ras-commander) Coding Assistant

## Overview

This Coding Assistant helps you write efficient and well-structured Python code for working with HEC-RAS projects using the RAS Commander (ras-commander) library.

**Key Features:**

* **Automates HEC-RAS tasks:** Streamlines project setup, plan execution, data management, and more.
* **Pythonic interface:** Leverages familiar Python libraries like pandas and pathlib for intuitive coding.
* **Flexible execution:** Supports single plan, sequential, and parallel execution modes.
* **Built-in examples:** Provides access to HEC-RAS example projects for learning and testing.

**Core Concepts:**

* **RAS Objects:** Represent HEC-RAS projects and their components (plans, geometry, flow files).
* **Project Initialization:** Use `init_ras_project()` to set up a project, choosing between global and custom instances.
* **File Handling:** pathlib.Path ensures consistent file path management across operating systems.
* **Data Management:** Pandas DataFrames organize project data for efficient manipulation.
* **Execution Modes:** Choose from single, sequential, or parallel execution based on project needs.
* **Utility Functions:** RasUtils provides common file operations and project management tasks.

## Classes, Functions and Arguments for ras_commander

Class/Function | Required Arguments | Optional Arguments
---------------|--------------------|--------------------|
RasPrj | | |
init_ras_project | ras_project_folder, ras_version | ras_instance
get_ras_exe | ras_version | - |
RasPlan | | |
set_geom | plan_number, new_geom | ras_object |
set_steady | plan_number, new_steady_flow_number | ras_object |
set_unsteady | plan_number, new_unsteady_flow_number | ras_object |
set_num_cores | plan_number, num_cores | ras_object |
clone_plan | template_plan | new_plan_shortid, ras_object |
RasGeo | | |
clear_geompre_files | | plan_files, ras_object |
RasUnsteady | | |
update_unsteady_parameters | unsteady_file, modifications | ras_object |
RasCmdr | | |
compute_plan | plan_number | dest_folder, ras_object, clear_geompre, num_cores, overwrite_dest |
compute_parallel | | plan_number, max_workers, num_cores, ras_object, dest_folder, overwrite_dest |
compute_test_mode | | plan_number, dest_folder_suffix, clear_geompre, num_cores, ras_object, overwrite_dest |
RasUtils | | |
create_backup | file_path | backup_suffix, ras_object |
restore_from_backup | backup_path | remove_backup, ras_object |
update_plan_file | plan_number_or_path, file_type, entry_number | ras_object |
RasExamples | | |
extract_project | project_names | - |

## Coding Assistance Rules:

Your role is building, refactoring and debugging Python scripts using Python 3.9+, focusing on automation tasks for HEC-RAS projects.

1. Prefer default libraries where possible, especially pathlib for file operations.
2. Use r-strings for file and directory path inputs.
3. Use f-strings for string formatting and concatenation.
4. Always use pathlib over os for manipulation of file and directory paths.
5. Print DataFrame names and variable names before displaying DataFrames.
6. Prefer pandas for data manipulation and analysis tasks.
7. Use matplotlib or bokeh for visualization when needed.
8. Always include comments for code readability and explain complex operations.
9. Use logging for informative output and debugging information.
10. Follow PEP 8 conventions for code style.
11. Provide clear error handling and user feedback.
12. When using RAS Commander functions, explain their purpose and key arguments.
13. Encourage consistent use of either global 'ras' object or custom instances throughout scripts.
14. Highlight best practices for parallel execution and performance optimization.
15. Suggest using RasExamples for testing and learning purposes when appropriate.

When revising code, write planning steps as comments before implementation, labeled as:
## Explicit Planning and Reasoning for Revisions

For geodataframes, use the 'union_all()' method instead of the deprecated 'unary_union' attribute.

Note for pandas >= 2.0: Use pd.concat instead of the removed append method.

Always provide full code segments or full script files with no elides.

==================================================

Folder: c:\GH\ras-commander\.gitignore
==================================================

File: c:\GH\ras-commander\Comprehensive_Library_Guide.md
==================================================
# Comprehensive RAS-Commander Library Guide

## Introduction

RAS-Commander (`ras_commander`) is a Python library designed to automate and streamline operations with HEC-RAS projects. It provides a suite of tools for managing projects, executing simulations, and handling results. This guide offers a comprehensive overview of the library's key concepts, modules, best practices, and advanced usage patterns. RAS-Commander is designed to be flexible, robust, and AI-accessible, making it an ideal tool for both manual and automated HEC-RAS workflows.

---

## Table of Contents

- [Key Concepts](#key-concepts)
- [Core Features](#core-features)
- [Module Overview](#module-overview)
- [Best Practices](#best-practices)
- [Usage Patterns](#usage-patterns)
  - [Initializing a Project](#initializing-a-project)
  - [Cloning a Plan](#cloning-a-plan)
  - [Executing Plans](#executing-plans)
  - [Working with Multiple Projects](#working-with-multiple-projects)
  - [Performance Optimization](#performance-optimization)
  - [Working with Boundary Conditions](#working-with-boundary-conditions)
  - [Using RasUtils Statistical Methods](#using-rasutils-statistical-methods)
- [Advanced Usage](#advanced-usage)
  - [RasExamples](#rasexamples)
  - [RasUtils](#rasutils)
  - [Artifact System](#artifact-system)
  - [AI-Driven Coding Tools](#ai-driven-coding-tools)
  - [Working with Boundary Conditions](#working-with-boundary-conditions-1)
  - [Advanced Data Processing with RasUtils](#advanced-data-processing-with-rasutils)
- [RasHdf](#rashdf)
- [Troubleshooting](#troubleshooting)
- [Conclusion](#conclusion)

---

## Key Concepts

1. **RAS Objects**:
   - Represent HEC-RAS projects containing information about plans, geometries, and flow files.
   - Support both a global `ras` object and custom `RasPrj` instances for different projects.

2. **Project Initialization**:
   - Use `init_ras_project()` to initialize projects and set up RAS objects.
   - Handles project file discovery and data structure setup.

3. **File Handling**:
   - Utilizes `pathlib.Path` for consistent, platform-independent file paths.
   - Adheres to HEC-RAS file naming conventions (`.prj`, `.p01`, `.g01`, `.f01`, `.u01`).

4. **Data Management**:
   - Employs Pandas DataFrames to manage structured data about plans, geometries, and flow files.
   - Provides methods for accessing and updating these DataFrames.

5. **Execution Modes**:
   - **Single Plan Execution**: Run individual plans.
   - **Sequential Execution**: Run multiple plans in sequence.
   - **Parallel Execution**: Run multiple plans concurrently for improved performance.

6. **Example Projects**:
   - The `RasExamples` class offers functionality to download and manage HEC-RAS example projects for testing and learning.

7. **Utility Functions**:
   - `RasUtils` provides common utility functions for file operations, backups, error handling, and statistical analysis.

8. **Artifact System**:
   - Handles substantial, self-contained content that users might modify or reuse, displayed in a separate UI window.

9. **AI-Driven Coding Tools**:
   - Integrates AI-powered tools like ChatGPT Assistant, LLM Summaries, Cursor IDE Integration, and Jupyter Notebook Assistant.

10. **Boundary Conditions**:
    - Represent the input conditions for HEC-RAS simulations, including flow hydrographs, stage hydrographs, and other hydraulic inputs.
    - The `RasPrj` class provides functionality to extract and manage boundary conditions from unsteady flow files.

11. **Flexibility and Modularity**:
    - All classes are designed to work with either a global 'ras' object + a plan number, or with custom project instances.
    - Clear separation of concerns between project management (RasPrj), execution (RasCmdr), and results data retrieval (RasHdf).

12. **Error Handling and Logging**:
    - Emphasis on robust error checking and informative logging throughout the library.

13. **AI-Accessibility**:
    - Structured, consistent codebase with clear documentation to facilitate easier learning and usage by AI models.

---


## Module Overview

1. **RasPrj**: Manages HEC-RAS project initialization and data, including boundary conditions.
2. **RasCmdr**: Handles execution of HEC-RAS simulations.
3. **RasPlan**: Provides functions for plan file operations.
4. **RasGeo**: Manages geometry file operations.
5. **RasUnsteady**: Handles unsteady flow file operations.
6. **RasUtils**: Offers utility functions for common tasks and statistical analysis.
7. **RasExamples**: Manages example HEC-RAS projects.
8. **RasHdf**: Provides utilities for working with HDF files in HEC-RAS projects.

---

## Best Practices

### 1. RAS Object Usage

- **Single Project Scripts**:
  - Use the global `ras` object for simplicity.
    ```python
    from ras_commander import ras, init_ras_project

    init_ras_project("/path/to/project", "6.5")
    # Use ras object for operations
    ```

- **Multiple Projects**:
  - Create separate `RasPrj` instances for each project.
    ```python
    from ras_commander import RasPrj, init_ras_project

    project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
    project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())
    ```

- **Consistency**:
  - Avoid mixing global and custom RAS objects in the same script.

### 2. Plan Specification

- Use plan numbers as strings (e.g., `"01"`, `"02"`) for consistency.
  ```python
  RasCmdr.compute_plan("01")
  ```

- Check available plans before specifying plan numbers.
  ```python
  print(ras.plan_df)  # Displays available plans
  ```

### 3. Geometry Preprocessor Files

- Clear geometry preprocessor files before significant changes.
  ```python
  RasGeo.clear_geompre_files()
  ```

- Use `clear_geompre=True` for a clean computation environment.
  ```python
  RasCmdr.compute_plan("01", clear_geompre=True)
  ```

### 4. Parallel Execution

- Adjust `max_workers` and `num_cores` based on system capabilities.
  ```python
  RasCmdr.compute_parallel(max_workers=4, num_cores=2)
  ```

- Use `dest_folder` to organize outputs and prevent conflicts.
  ```python
  RasCmdr.compute_parallel(dest_folder="/path/to/results")
  ```

### 5. Error Handling

- Implement try-except blocks to handle potential errors.
  ```python
  try:
      RasCmdr.compute_plan("01")
  except FileNotFoundError:
      print("Plan file not found")
  ```

- Utilize logging for informative output.
  ```python
  import logging
  logging.basicConfig(level=logging.INFO)
  ```

### 6. File Path Handling

- Use `pathlib.Path` for robust file and directory operations.
  ```python
  from pathlib import Path
  project_path = Path("/path/to/project")
  ```

### 7. Type Hinting

- Apply type hints to improve code readability and IDE support.
  ```python
  def compute_plan(plan_number: str, clear_geompre: bool = False) -> bool:
      ...
  ```

---

## Usage Patterns

### Initializing a Project
```python
from ras_commander import init_ras_project, ras

init_ras_project("/path/to/project", "6.5")
print(f"Working with project: {ras.project_name}")
```

### Cloning a Plan

```python
from ras_commander import RasPlan

new_plan_number = RasPlan.clone_plan("01")
print(f"Created new plan: {new_plan_number}")
```

### Executing Plans

- **Single Plan Execution**:
  ```python
  from ras_commander import RasCmdr

  success = RasCmdr.compute_plan("01", num_cores=2)
  print(f"Plan execution {'successful' if success else 'failed'}")
  ```

- **Parallel Execution of Multiple Plans**:
  ```python
  from ras_commander import RasCmdr

  results = RasCmdr.compute_parallel(
      plan_numbers=["01", "02", "03"],
      max_workers=3,
      num_cores=4,
      dest_folder="/path/to/results",
      clear_geompre=True
  )

  for plan, success in results.items():
      print(f"Plan {plan}: {'Successful' if success else 'Failed'}")
  ```

### Working with Multiple Projects

```python
from ras_commander import RasPrj, init_ras_project, RasCmdr

# Initialize two separate projects
project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

# Perform operations on each project
RasCmdr.compute_plan("01", ras_object=project1)
RasCmdr.compute_plan("02", ras_object=project2)

# Compare results
results1 = project1.get_hdf_entries()
results2 = project2.get_hdf_entries()
```

### Performance Optimization

```python
from ras_commander import RasCmdr

results = RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03"],
    max_workers=3,
    num_cores=4,
    dest_folder="/path/to/results",
    clear_geompre=True
)

for plan, success in results.items():
    print(f"Plan {plan}: {'Successful' if success else 'Failed'}")
```

- **Best Practices**:
  - Use `compute_parallel()` for concurrent plan execution.
  - Adjust `max_workers` and `num_cores` based on system capabilities.
  - Organize outputs with `dest_folder`.
  - Use `clear_geompre=True` for clean computations.

### Working with Boundary Conditions

```python
from ras_commander import init_ras_project

# Initialize a project
project = init_ras_project("/path/to/project", "6.5")

# Access boundary conditions
boundary_conditions = project.boundaries_df

# Display boundary condition information
print(boundary_conditions)

# Filter boundary conditions for a specific river
river_boundaries = boundary_conditions[boundary_conditions['river_reach_name'] == 'Main River']
print(river_boundaries)
```

### Using RasUtils Statistical Methods

```python
from ras_commander import RasUtils
import numpy as np

# Example observed and predicted values
observed = np.array([100, 120, 140, 160, 180])
predicted = np.array([105, 125, 135, 165, 175])

# Calculate error metrics
metrics = RasUtils.calculate_error_metrics(observed, predicted)

print(f"Correlation: {metrics['cor']:.4f}")
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"Percent Bias: {metrics['pb']:.4f}")

# Calculate individual metrics
rmse = RasUtils.calculate_rmse(observed, predicted)
percent_bias = RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)

print(f"RMSE: {rmse:.4f}")
print(f"Percent Bias: {percent_bias:.2f}%")
```

---

## Advanced Usage

### RasExamples

The `RasExamples` class provides functionality for managing HEC-RAS example projects. This is particularly useful for testing, learning, and development purposes.

#### Key Concepts

- **Example Project Management**: Access and manipulate example projects.
- **Automatic Downloading and Extraction**: Fetches projects from official sources.
- **Project Categorization**: Organizes projects into categories for easy navigation.

#### Usage Patterns

```python
from ras_commander import RasExamples

# Initialize RasExamples
ras_examples = RasExamples()

# Download example projects (if not already present)
ras_examples.get_example_projects()

# List available categories
categories = ras_examples.list_categories()
print(f"Available categories: {categories}")

# List projects in a specific category
steady_flow_projects = ras_examples.list_projects("Steady Flow")
print(f"Steady Flow projects: {steady_flow_projects}")

# Extract specific projects
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
for path in extracted_paths:
    print(f"Extracted project to: {path}")

# Clean up extracted projects when done
ras_examples.clean_projects_directory()
```

### RasUtils

The `RasUtils` class provides utility functions for common tasks in the `ras_commander` library.

#### Key Concepts

- **File and Directory Operations**: Create, delete, and manage files and directories.
- **Backup and Restoration**: Safeguard original files with backups.
- **Error Handling and Retries**: Robust methods to handle common file system errors.
- **Statistical Analysis**: Perform calculations such as RMSE, correlation, and percent bias.

#### Usage Patterns

```python
from ras_commander import RasUtils
from pathlib import Path

# Create a backup of a file
original_file = Path("project.prj")
backup_file = RasUtils.create_backup(original_file)

# Ensure a directory exists
output_dir = RasUtils.create_directory(Path("output"))

# Find files by extension
prj_files = RasUtils.find_files_by_extension(".prj")

# Get file information
file_size = RasUtils.get_file_size(original_file)
mod_time = RasUtils.get_file_modification_time(original_file)

# Update a plan file
RasUtils.update_plan_file("01", "Geom", 2)

# Remove a file or folder with retry logic
RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
```

Certainly! I'll expand the Comprehensive Library Guide with more detailed information on RAS Objects, project initialization, file handling, and consistent file path management. Here's an enhanced version of those sections:

# Comprehensive RAS-Commander Library Guide

## Key Concepts

### RAS Objects

RAS Objects are central to the ras-commander library. They represent HEC-RAS projects and contain all the necessary information about plans, geometries, flow files, and other project components.

1. **Global 'ras' Object**: 
   - By default, the library uses a global 'ras' object.
   - This object is automatically initialized when you call `init_ras_project()`.
   - Suitable for simple scripts working with a single project.

2. **Custom RAS Objects**:
   - For more complex scenarios or when working with multiple projects, you can create custom RAS objects.
   - These are instances of the `RasPrj` class.
   - Allow you to manage multiple projects simultaneously.

3. **Key Attributes of RAS Objects**:
   - `project_folder`: Path to the project folder
   - `prj_file`: Path to the project file
   - `project_name`: Name of the project
   - `ras_exe_path`: Path to the HEC-RAS executable
   - `plan_df`: DataFrame containing plan information
   - `geom_df`: DataFrame containing geometry information
   - `flow_df`: DataFrame containing flow information
   - `unsteady_df`: DataFrame containing unsteady flow information

4. **Importance of Initialization**:
   - RAS objects must be initialized before use.
   - Initialization loads all project data and sets up necessary attributes.
   - Always check if a RAS object is initialized before performing operations.

Example of using custom RAS objects:

```python
from ras_commander import init_ras_project, RasPrj

project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

# Now you can work with project1 and project2 independently
```

### Project Initialization and File Handling

Proper project initialization is crucial for the correct functioning of the ras-commander library. The `init_ras_project()` function is the primary method for setting up a project.

1. **Project Initialization Process**:
   - Locates the project folder and HEC-RAS executable
   - Finds the main project file (.prj)
   - Loads all plan, geometry, and flow file information
   - Sets up DataFrames for easy access to project components

2. **File Discovery**:
   - The library automatically scans the project folder for relevant files
   - Files are categorized based on their extensions (e.g., .p* for plans, .g* for geometries)
   - File information is stored in respective DataFrames (plan_df, geom_df, etc.)

3. **Error Handling During Initialization**:
   - Checks for the existence of the project folder and necessary files
   - Raises informative errors if critical components are missing

4. **Post-Initialization**:
   - After initialization, you can access project information through the RAS object
   - Always check if the RAS object is initialized before performing operations

Example of project initialization:

```python
from ras_commander import init_ras_project, ras

init_ras_project("/path/to/project", "6.5")

# Now you can use the global 'ras' object
print(ras.project_name)
print(ras.plan_df)
```

### Consistent File Path Management

Consistent file path management is critical for reliable operation across different operating systems and environments. The ras-commander library uses `pathlib.Path` for all file and directory operations.

1. **Why Use pathlib.Path**:
   - Operating system independent
   - Provides an object-oriented interface for file path operations
   - Simplifies path manipulation and file operations

2. **Best Practices**:
   - Always use `Path` objects for file and directory paths
   - Use forward slashes ('/') in path strings, which work across all operating systems
   - Use relative paths when possible for better portability

3. **Path Resolution**:
   - The library resolves relative paths to absolute paths during initialization
   - Always work with absolute paths after initialization to avoid ambiguity

4. **Examples from the Library**:

```python
from pathlib import Path

# In RasPrj.py
self.project_folder = Path(project_folder)
self.prj_file = self.find_ras_prj(self.project_folder)

# In RasUtils.py
def create_backup(file_path: Path, backup_suffix: str = "_backup") -> Path:
    original_path = Path(file_path)
    backup_path = original_path.with_name(f"{original_path.stem}{backup_suffix}{original_path.suffix}")
    # ... rest of the function

# In user scripts
from ras_commander import init_ras_project, RasUtils

init_ras_project(Path("/path/to/project"), "6.5")
RasUtils.create_backup(Path("project.prj"))
```

5. **Handling User Input**:
   - When accepting file paths from users, always convert them to Path objects
   - Use `Path(user_input).resolve()` to get the absolute path

6. **Working with Multiple Projects**:
   - Keep paths relative to each project's base directory
   - Use `Path.relative_to()` when needed to get relative paths

By following these practices for file path management, you ensure that your scripts using the ras-commander library will work consistently across different systems and project structures.










### AI-Driven Coding Tools

`ras_commander` integrates several AI-powered tools to enhance the coding experience.

#### Tools and Features

1. **ChatGPT Assistant**:
   - Use for general questions about the library and its usage.
   - Provides code suggestions and explanations.

2. **LLM Summaries**:
   - Utilize large language models for up-to-date context on the codebase.
   - Available in two versions: full codebase and examples/docstrings only.

3. **Cursor IDE Integration**:
   - Offers context-aware suggestions and documentation.
   - Automatically includes a `.cursorrules` file when opening the `ras_commander` folder.

4. **Jupyter Notebook Assistant**:
   - Dynamic code summarization and API interaction.
   - Allows for real-time querying and exploration of the library.

#### Best Practices

- **Documentation First**: Start with the provided documentation and examples.
- **Specific Queries**: Use the ChatGPT Assistant for specific questions or clarifications.
- **LLM Summaries**: Leverage when working with external AI models.
- **IDE Integration**: Use Cursor IDE for the most integrated coding experience.
- **Interactive Learning**: Explore the Jupyter Notebook Assistant for experimentation.


## Approaching Your End User Needs with Ras Commander

### Understanding Data Sources and Strategies

RAS Commander is designed to work efficiently with HEC-RAS projects by focusing on easily accessible data sources. This approach allows for powerful automation while avoiding some of the complexities inherent in HEC-RAS data management. Here's what you need to know:

1. **Data Sources in HEC-RAS Projects**:
   - ASCII input files (plan files, unsteady files, boundary conditions)
   - DSS (Data Storage System) files for inputs
   - HDF (Hierarchical Data Format) files for outputs

2. **RAS Commander's Focus**:
   - Primarily works with plain text inputs and HDF outputs
   - Avoids direct manipulation of DSS files due to their complexity

3. **Strategy for Handling DSS Inputs**:
   - Run the plan or preprocess geometry and event conditions
   - Access the resulting HDF tables, which contain the DSS inputs in an accessible format
   - Define time series directly in the ASCII file instead of as DSS inputs

4. **Accessing Project Data**:
   - Basic project data is loaded from ASCII text files by the RasPrj routines
   - Plan details are available in the HDF file
   - Geometry data is in the dynamically generated geometry HDF file

### Working with RAS Commander

1. **Initialization and Data Loading**:
   - Use `init_ras_project()` to load project data from ASCII files
   - Access plan information from HDF files using provided functions

2. **Handling Geometry Data**:
   - Geometry data is dynamically generated in HDF format
   - Focus on working with the HDF geometry data rather than plain text editing

3. **Workflow for Complex Operations**:
   - Perform the desired operation manually once
   - Provide an example to RAS Commander's AI GPT of what you're changing and why
   - Use this example to develop project-specific functions and code

4. **Example: Replacing DSS-defined Boundary Conditions**:
   - Open the data in HDF View
   - Extract the relevant dataset
   - Manually enter the time series based on the HDF dataset
   - Verify the model works with this change
   - Use this example to create an automated function for similar operations

### Best Practices

1. **Understanding Your Data**:
   - Familiarize yourself with the structure of your HEC-RAS project
   - Identify which data is stored in ASCII, DSS, and HDF formats

2. **Leveraging HDF Outputs**:
   - Whenever possible, use HDF outputs for data analysis and manipulation
   - This approach provides easy access to data without DSS complexities

3. **Iterative Development**:
   - Start with manual operations to understand the process
   - Gradually automate these processes using RAS Commander functions
   - Always check with the HEC-RAS GUI to verify the changes before finalizing the automation

4. **Documentation**:
   - Keep detailed notes on your workflow and changes
   - This documentation will be invaluable for creating automated processes

5. **Flexibility**:
   - Be prepared to adapt your approach based on specific project needs
   - RAS Commander provides a framework, but project-specific solutions will always require custom scripting
   - With an AI assistant, you can quickly leverage this library or your own custom functions to automate your workflows.

By following these strategies and best practices, you can effectively use RAS Commander to automate and streamline your HEC-RAS workflows, working around limitations and leveraging the strengths of the library's approach to data management.


### Working with Boundary Conditions

The `RasPrj` class now provides detailed information about boundary conditions in HEC-RAS projects. This can be particularly useful for advanced analysis and automation tasks.

```python
from ras_commander import init_ras_project

project = init_ras_project("/path/to/project", "6.5")

# Get all boundary conditions
all_boundaries = project.boundaries_df

# Filter for specific boundary condition types
flow_hydrographs = all_boundaries[all_boundaries['bc_type'] == 'Flow Hydrograph']
stage_hydrographs = all_boundaries[all_boundaries['bc_type'] == 'Stage Hydrograph']

# Analyze boundary conditions
for _, boundary in flow_hydrographs.iterrows():
    print(f"River: {boundary['river_reach_name']}")
    print(f"Station: {boundary['river_station']}")
    print(f"Number of values: {boundary['hydrograph_num_values']}")
    print("---")

# Access specific boundary condition details
if 'hydrograph_values' in flow_hydrographs.columns:
    first_hydrograph = flow_hydrographs.iloc[0]['hydrograph_values']
    print("First 5 values of the first flow hydrograph:")
    print(first_hydrograph[:5])
```

### Advanced Data Processing with RasUtils

RasUtils now includes methods for data conversion and statistical analysis, which can be useful for post-processing HEC-RAS results.

```python
from ras_commander import RasUtils
from pathlib import Path
import pandas as pd
import numpy as np

# Convert various data sources to DataFrame
csv_data = RasUtils.convert_to_dataframe(Path("results.csv"))
excel_data = RasUtils.convert_to_dataframe(Path("data.xlsx"), sheet_name="Sheet1")

# Combine data from different sources
combined_data = pd.concat([csv_data, excel_data])

# Perform statistical analysis
observed = combined_data['observed_values'].values
predicted = combined_data['predicted_values'].values

metrics = RasUtils.calculate_error_metrics(observed, predicted)
print("Error Metrics:", metrics)

# Save results to Excel with retry functionality
results_df = pd.DataFrame({
    'Metric': ['Correlation', 'RMSE', 'Percent Bias'],
    'Value': [metrics['cor'], metrics['rmse'], metrics['pb']]
})
RasUtils.save_to_excel(results_df, Path("analysis_results.xlsx"))
```

---

## RasHdf

The `RasHdf` class provides utilities for working with HDF (Hierarchical Data Format) files in HEC-RAS projects. HDF files are commonly used in HEC-RAS for storing large datasets and simulation results.

### Key Features of `RasHdf`:

1. **Reading HDF Tables**: Convert HDF5 datasets to pandas DataFrames.
2. **Writing DataFrames to HDF**: Save pandas DataFrames as HDF5 datasets.
3. **Spatial Operations**: Perform KDTree queries and find nearest neighbors.
4. **Data Consolidation**: Merge duplicate values in DataFrames.
5. **Byte String Handling**: Decode byte strings in DataFrames.

### Example Usage:

```python
from ras_commander import RasHdf
import h5py
import pandas as pd

# Read an HDF table
with h5py.File('results.hdf', 'r') as f:
    dataset = f['water_surface_elevations']
    df = RasHdf.read_hdf_to_dataframe(dataset)

print(df.head())

# Save a DataFrame to HDF
new_data = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
with h5py.File('new_results.hdf', 'w') as f:
    group = f.create_group('my_results')
    RasHdf.save_dataframe_to_hdf(new_data, group, 'my_dataset')

# Perform a KDTree query
import numpy as np
reference_points = np.array([[0, 0], [1, 1], [2, 2]])
query_points = np.array([[0.5, 0.5], [1.5, 1.5]])
results = RasHdf.perform_kdtree_query(reference_points, query_points)
print("KDTree query results:", results)
```




## HDF Paths Supported

This is a list of HDF paths that are directly supported by specialized library functions: 


1. General Paths:
   - '/Results/Summary/Compute Messages (text)'
   - '/Plan Data/Plan Parameters'
   - '/Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D'

2. Geometry Paths:
   - '/Geometry/2D Flow Areas'
   - '/Geometry/2D Flow Areas/{area_name}/Cell Info'
   - '/Geometry/2D Flow Areas/{area_name}/Cell Points'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Info'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Parts'
   - '/Geometry/2D Flow Areas/{area_name}/Polygon Points'
   - '/Geometry/2D Flow Areas/{area_name}/Cells Center Coordinate'
   - '/Geometry/2D Flow Areas/{area_name}/Cells Center Manning\'s n'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Area Elevation Values'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Cell Indexes'
   - '/Geometry/2D Flow Areas/{area_name}/Faces FacePoint Indexes'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Low Elevation Centroid'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Minimum Elevation'
   - '/Geometry/2D Flow Areas/{area_name}/Faces NormalUnitVector and Length'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Perimeter Info'
   - '/Geometry/2D Flow Areas/{area_name}/Faces Perimeter Values'
   - '/Geometry/2D Flow Areas/{area_name}/Face Points Coordinates'
   - '/Geometry/2D Flow Areas/{area_name}/Perimeter'
   - '/Geometry/Boundary Condition Lines/Attributes'

3. Results Paths:
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time'
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp'
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area_name}/Water Surface'  # PLACEHOLDER ONLY, DOES NOT WORK
   - '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area_name}/Face Velocity'  # PLACEHOLDER ONLY, DOES NOT WORK
   - '/Results/Summary/Compute Processes'

4. Infiltration Paths:
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Cell Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Face Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Initial Deficit'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Maximum Deficit'
   - '/Geometry/2D Flow Areas/{area_name}/Infiltration/Potential Percolation Rate'

5. Percent Impervious Paths:
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Cell Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Face Center Classifications'
   - '/Geometry/2D Flow Areas/{area_name}/Percent Impervious/Percent Impervious'


## RasHdf class structure, methods, decorators, and their significance:

1. Class Structure:
   - RasHdf is a utility class designed to work with HDF files produced by HEC-RAS.
   - It contains only static methods, meaning no instance of the class needs to be created to use its functionality.
   - The class serves as a namespace for grouping related HDF file operations.

2. Primary Decorator:
   - @staticmethod: Used on all methods in the class.
   - Significance: Allows methods to be called on the class itself rather than an instance, fitting the utility nature of the class.

3. Custom Decorator:
   - @hdf_operation: A custom decorator defined within the RasHdf class.
   - Purpose: Provides a consistent way to handle HDF file operations, including error handling and file opening/closing.
   - Significance: Centralizes common HDF file handling logic, reducing code duplication and ensuring consistent error handling across methods.

4. Key Methods and Their Purposes:
   a. get_hdf_paths_with_properties(): Lists all paths in the HDF file with their properties.
   b. get_runtime_data(): Extracts runtime and compute time data.
   c. get_2d_flow_area_names(): Lists 2D Flow Area names.
   d. get_2d_flow_area_attributes(): Extracts 2D Flow Area attributes.
   e. get_cell_info(), get_cell_points(): Extract cell-related information.
   f. get_polygon_info_and_parts(), get_polygon_points(): Handle polygon data.
   g. get_cells_center_data(): Extracts cell center coordinates and Manning's n values.
   h. get_faces_area_elevation_data(): Extracts face area elevation data.
   i. load_2d_area_solutions(): Loads 2D area solutions including water surface elevations and velocities.
   j. Methods for infiltration and percent impervious data extraction.

5. Method Structure:
   - Most methods follow a pattern of accepting an hdf_input (which can be a plan number or file path) and an optional ras_object.
   - This structure allows flexibility in how the methods are called, supporting both plan-based and direct file path-based access.

6. Error Handling:
   - Centralized in the @hdf_operation decorator.
   - Catches and logs exceptions, returning None on failure.
   - Provides consistent error reporting across all HDF operations.

7. Flexibility in Usage:
   - Methods can be used with either a global RAS object, a custom RAS object, or by directly providing an HDF file path.
   - This flexibility allows the class to be used in various contexts within the larger ras-commander library.

8. Integration with RasPrj:
   - Many methods rely on the RasPrj class to resolve plan numbers to actual file paths.
   - This integration allows for a high-level, project-oriented approach to working with HDF data.

9. Data Extraction and Conversion:
   - Most methods extract data from the HDF file and convert it to pandas DataFrames.
   - This approach makes the extracted data easily manipulable using standard pandas operations.

10. Significance within the Library:
    - RasHdf serves as the primary interface for extracting and analyzing HEC-RAS output data.
    - It bridges the gap between raw HDF files and usable Python data structures.
    - Enables advanced analysis and post-processing of HEC-RAS results within the ras-commander ecosystem.

11. Extensibility:
    - The class structure allows for easy addition of new methods to support additional HDF data extraction as needed.
    - The @hdf_operation decorator makes it straightforward to add new HDF file operations while maintaining consistent error handling and file management.

12. Performance Considerations:
    - Methods are designed to work with potentially large datasets.
    - Some methods (like load_2d_area_solutions) may be memory-intensive for large models and may require optimization for very large datasets.

This structure makes RasHdf a powerful and flexible tool for working with HEC-RAS output data, providing a pythonic interface to the complex structure of HEC-RAS HDF files. Its integration with the broader ras-commander library allows for seamless incorporation of data analysis into HEC-RAS automation workflows.



---


## Optimizing Parallel Execution with RAS Commander

Efficient parallel execution is crucial for maximizing the performance of HEC-RAS simulations, especially when dealing with multiple plans or large models. RAS Commander offers several strategies for optimizing parallel execution based on your specific needs and system resources.  For more information about these strategies and how to optimize your hardware for HEC-RAS CPU based simulations, see the following blog posts: 

- [10x Engineering in Water Resources with AI](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/1.%2010x%20Engineering%20in%20Water%20Resources%20with%20AI.md)
- [10X Engineering By The Numbers](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/2.%2010XEngineering_By_The_Numbers.md)
- [Think Like A Bootlegger for HEC-RAS Modeling Machines](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/4._Think_Like_A_Bootlegger_for_HEC-RAS_Modeling_Machines.md)
- [Benchmarking Is All You Need](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/7._Benchmarking_Is_All_You_Need.md)
- [Avoiding The Bitter Lesson In RAS Modeling](https://github.com/billk-FM/HEC-Commander/blob/main/Blog/9.Avoiding_The_Bitter_Lesson_In_RAS_Modeling.md)


### Strategy 1: Efficiency Mode for Multiple Plans

This strategy maximizes overall throughput and efficiency when running multiple plans, although individual plan turnaround times may be longer.

**Key Points:**
- Use 2 real cores per plan
- Utilize only physical cores, not hyperthreaded cores

**Example:**
```python
from ras_commander import RasCmdr

# Assuming 8 physical cores on the system
RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03", "04"],
    max_workers=4,  # 8 cores / 2 cores per plan
    num_cores=2
)
```

### Strategy 2: Performance Mode for Single Plans

This strategy maximizes single plan performance by using more cores. It results in less overall efficiency but shortens single plan runtime, making it optimal for situations where individual plan performance is critical.

**Key Points:**
- Use 8-16 cores per plan, depending on system capabilities
- Suitable for running a single plan or a small number of high-priority plans

**Example:**
```python
from ras_commander import RasCmdr

RasCmdr.compute_plan(
    plan_number="01",
    num_cores=12  # Adjust based on your system's capabilities
)
```

### Strategy 3: Background Run Operation

This strategy balances performance and system resource usage, allowing for other operations to be performed concurrently.

**Key Points:**
- Limit total core usage to 50-80% of physical cores
- Combines aspects of Strategies 1 and 2
- Allows overhead for user to complete other operations while calculations are running

**Example:**
```python
import psutil
from ras_commander import RasCmdr

physical_cores = psutil.cpu_count(logical=False)
max_cores_to_use = int(physical_cores * 0.7)  # Using 70% of physical cores

RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03"],
    max_workers=max_cores_to_use // 2,
    num_cores=2
)
```

### Optimizing Geometry Preprocessing

To avoid repeated geometry preprocessing for each run, follow these steps:

1. **Preprocess Geometry:**
   ```python
   from ras_commander import RasPlan
   
   # For each plan you want to preprocess
   RasPlan.update_plan_value(plan_number, "Run HTab", 1)
   RasPlan.update_plan_value(plan_number, "Run UNet", -1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", -1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", -1)
   
   # Run the plan to preprocess geometry
   RasCmdr.compute_plan(plan_number)
   ```

2. **Run Simulations:**
   After preprocessing, update the flags for actual simulations:
   ```python
   RasPlan.update_plan_value(plan_number, "Run HTab", -1)
   RasPlan.update_plan_value(plan_number, "Run UNet", 1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", 1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", 0)
   ```

This approach preprocesses the geometry once, preventing redundant preprocessing when multiple plans use the same geometry.

### Best Practices for Parallel Execution

**Balance Cores:** Find the right balance between the number of parallel plans and cores per plan based on your system's capabilities.
**Consider I/O Operations:** Be aware that disk I/O can become a bottleneck in highly parallel operations.
**Test and Iterate:** Experiment with different configurations to find the optimal setup for your specific models and system.

By leveraging these strategies and best practices, you can significantly improve the performance and efficiency of your HEC-RAS simulations using RAS Commander.





## Troubleshooting

### 1. Project Initialization Issues

- **Ensure Correct Paths**: Verify that the project path is accurate and the `.prj` file exists.
- **HEC-RAS Version**: Confirm that the specified HEC-RAS version is installed on your system.

### 2. Execution Failures

- **File Existence**: Check that all referenced plan, geometry, and flow files exist.
- **Executable Path**: Ensure the HEC-RAS executable path is correctly set.
- **Log Files**: Review HEC-RAS log files for specific error messages.

### 3. Parallel Execution Problems

- **Resource Allocation**: Reduce `max_workers` if encountering memory issues.
- **System Capabilities**: Adjust `num_cores` based on your system's capacity.
- **Clean Environment**: Use `clear_geompre=True` to prevent conflicts.

### 4. File Access Errors

- **Permissions**: Verify read/write permissions for the project directory.
- **File Locks**: Close any open HEC-RAS instances that might lock files.

### 5. Inconsistent Results

- **Geometry Files**: Clear geometry preprocessor files when making changes.
- **Plan Parameters**: Ensure all plan parameters are correctly set before execution.

---

## Conclusion

The RAS-Commander (`ras_commander`) library provides a powerful set of tools for automating HEC-RAS operations. By following the best practices outlined in this guide and leveraging the library's features, you can efficiently manage and execute complex HEC-RAS projects programmatically.

Remember to refer to the latest documentation and the library's source code for up-to-date information. As you become more familiar with `ras_commander`, you'll discover more ways to optimize your HEC-RAS workflows and increase productivity.

For further assistance, bug reports, or feature requests, please refer to the library's [GitHub repository](https://github.com/billk-FM/ras-commander) and issue tracker.

---

**Happy Modeling!**
==================================================

Folder: c:\GH\ras-commander\examples
==================================================

File: c:\GH\ras-commander\LICENSE
==================================================
MIT License

Copyright (c) 2024 William M. Katzenmeyer

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so.

==================================================

File: c:\GH\ras-commander\pyproject.toml
==================================================
[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta:__legacy__"

==================================================

Folder: c:\GH\ras-commander\ras_commander
==================================================

File: c:\GH\ras-commander\README.md
==================================================
# RAS Commander (ras-commander)

RAS Commander is a Python library for automating HEC-RAS operations, providing a set of tools to interact with HEC-RAS project files, execute simulations, and manage project data. This library is an evolution of the RASCommander 1.0 Python Notebook Application previously released under the [HEC-Commander tools repository](https://github.com/billk-FM/HEC-Commander).

## Contributors:
William Katzenmeyer, P.E., C.F.M. - billk@fenstermaker.com  

Sean Micek, P.E., C.F.M. - smicek@fenstermaker.com  

Aaron Nichols, P.E., C.F.M. - anichols@fenstermaker.com  

(Additional Contributors Here)  


## Background
The ras-commander library emerged from the initial test-bed of AI-driven coding represented by the HEC-Commander tools Python notebooks. These notebooks served as a proof of concept, demonstrating the value proposition of automating HEC-RAS operations. The transition from notebooks to a structured library aims to provide a more robust, maintainable, and extensible solution for water resources engineers.

## Features

- Automate HEC-RAS project management and simulations
- Support for both single and multiple project instances
- Parallel execution of HEC-RAS plans
- Utilities for managing geometry, plan, and unsteady flow files
- Example project management for testing and development
- Two primary operation modes: "Run Missing" and "Build from DSS"

## AI-Driven Coding Experience

ras-commander provides several AI-powered tools to enhance the coding experience:

1. **ChatGPT Assistant: [RAS Commander Library Assistant](https://chatgpt.com/g/g-TZRPR3oAO-ras-commander-library-assistant)**: A specialized GPT model trained on the ras-commander codebase, available for answering queries and providing code suggestions.

2. **[Purpose-Built Knowledge Base Summaries](https://github.com/billk-FM/ras-commander/tree/main/ai_tools/assistant_knowledge_bases)**: Up-to-date compilations of the documentation and codebase for use with large language models like Claude or GPT-4. Look in 'ai_tools/assistant_knowledge_bases/' in the repo.

3. **[Cursor IDE Integration](https://github.com/billk-FM/ras-commander/blob/main/.cursorrules)**: Custom rules for the Cursor IDE to provide context-aware suggestions and documentation.  Just open the repository folder in Cursor.  You can create your own folders "/workspace/, "/projects/", or "my_projects/" as these are already in the .gitignore, and place your custom scripts there for your projects.  This will allow easy referencing of the ras-commander documents and individual repo files, the automatic loading of the .cursorrules file.  Alternatvely, download the github repo into your projects folder to easily load documents and use cursor rules files.  
4. **[AI Assistant Notebook](https://github.com/billk-FM/ras-commander/blob/main/ai_tools/rascommander_code_assistant.ipynb)**: A notebook for dynamic code summarization and API interaction (bring your own API Key).  Currently, this only does a single-shot message on the Claude Sonnet 3.5 API, which can be up to 50 cents per request.  Future revisions will include the ability to select which knowledge base file to include, a choice of SOTA models + multi turn conversations to build automation notebooks interactively.  

These tools aim to streamline development and provide intelligent assistance when modeling with, and working with and revising the ras-commander library.

## Installation

Create a virtual environment with conda or venv (ask ChatGPT if you need help)

In your virtual environment, install ras-commander using pip:
```
pip install pandas requests pathlib
pip install ras-commander
```

   

## Requirements

- Tested with Python 3.11
- HEC-RAS 6.2 or later (other versions may work, all testing was done with version 6.2 and above)
- Detailed project workflows and/or existing libraries and code where ras-commander can be integrated.

For a full list of dependencies, see the `requirements.txt` file.

## Quick Start
```
from ras_commander import init_ras_project, RasCmdr, RasPlan
```

# Initialize a project
```
init_ras_project(r"/path/to/project", "6.5")
```

# Execute a single plan
```
RasCmdr.compute_plan("01", dest_folder=r"/path/to/results", overwrite_dest=True)
```

# Execute plans in parallel
```
results = RasCmdr.compute_parallel(
    plan_numbers=["01", "02"],
    max_workers=2,
    cores_per_run=2,
    dest_folder=r"/path/to/results",
    overwrite_dest=True
)
```

# Modify a plan
```
RasPlan.set_geom("01", "02")
```

Certainly! I'll provide you with an updated Key Components section and Project Organization diagram based on the current structure of the ras-commander library.

## Key Components

- `RasPrj`: Manages HEC-RAS projects, handling initialization and data loading
- `RasCmdr`: Handles execution of HEC-RAS simulations
- `RasPlan`: Provides functions for modifying and updating plan files
- `RasGeo`: Handles operations related to geometry files
- `RasUnsteady`: Manages unsteady flow file operations
- `RasUtils`: Contains utility functions for file operations and data management
- `RasExamples`: Manages and loads HEC-RAS example projects
- `RasHdf`: Provides utilities for working with HDF files in HEC-RAS projects

## Project Organization Diagram

```
ras_commander
├── .github
│   └── workflows
│       └── python-package.yml
├── ras_commander
│   ├── __init__.py
│   ├── _version.py
│   ├── RasCmdr.py
│   ├── RasExamples.py
│   ├── RasGeo.py
│   ├── RasHdf.py
│   ├── RasPlan.py
│   ├── RasPrj.py
│   ├── RasUnsteady.py
│   └── RasUtils.py
├── examples
│   ├── 01_project_initialization.py
│   ├── 02_plan_operations.py
│   ├── 03_geometry_operations.py
│   ├── 04_unsteady_flow_operations.py
│   ├── 05_utility_functions.py
│   ├── 06_single_plan_execution.py
│   ├── 07_sequential_plan_execution.py
│   ├── 08_parallel_execution.py
│   ├── 09_specifying_plans.py
│   ├── 10_arguments_for_compute.py
│   ├── 11_Using_RasExamples.ipynb
│   ├── 12_plan_set_execution.py
│   ├── 13_multiple_project_operations.py
│   ├── 14_Core_Sensitivity.ipynb
│   ├── 15_plan_key_operations.py
│   ├── 16_scanning_ras_project_info.py
│   ├── 17_parallel_execution_ble.py
│   └── HEC_RAS_2D_HDF_Analysis.ipynb
├── tests
│   └── ... (test files)
├── .gitignore
├── LICENSE
├── README.md
├── STYLE_GUIDE.md
├── Comprehensive_Library_Guide.md
├── pyproject.toml
├── setup.cfg
├── setup.py
└── requirements.txt
```

## Accessing HEC Examples through RasExamples

The `RasExamples` class provides functionality for quickly loading and managing HEC-RAS example projects. This is particularly useful for testing and development purposes.

Key features:
- Download and extract HEC-RAS example projects
- List available project categories and projects
- Extract specific projects for use
- Manage example project data efficiently

Example usage:
from ras_commander import RasExamples

```
ras_examples = RasExamples()
ras_examples.get_example_projects()  # Downloads example projects if not already present
categories = ras_examples.list_categories()
projects = ras_examples.list_projects("Steady Flow")
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
```

## RasPrj

The `RasPrj` class is central to managing HEC-RAS projects within the ras-commander library. It handles project initialization, data loading, and provides access to project components.

Key features:
- Initialize HEC-RAS projects
- Load and manage project data (plans, geometries, flows, etc.)
- Provide easy access to project files and information

Note: While a global `ras` object is available for convenience, you can create multiple `RasPrj` instances to manage several projects simultaneously.

Example usage:
```
from ras_commander import RasPrj, init_ras_project
```

### Using the global ras object
```
init_ras_project("/path/to/project", "6.5")
```

### Creating a custom RasPrj instance
```
custom_project = RasPrj()
init_ras_project("/path/to/another_project", "6.5", ras_instance=custom_project)
```

## RasHdf

The `RasHdf` class provides utilities for working with HDF files in HEC-RAS projects, enabling easy access to simulation results and model data.

Example usage:

```python
from ras_commander import RasHdf, init_ras_project, RasPrj

# Initialize project with a custom ras object
custom_ras = RasPrj()
init_ras_project("/path/to/project", "6.5", ras_instance=custom_ras)

# Get runtime data for a specific plan
plan_number = "01"
runtime_data = RasHdf.get_runtime_data(plan_number, ras_object=custom_ras)
print(runtime_data)
```

This class simplifies the process of extracting and analyzing data from HEC-RAS HDF output files, supporting tasks such as post-processing and result visualization.


## Documentation

For detailed usage instructions and API documentation, please refer to the [Comprehensive Library Guide](Comprehensive_Library_Guide.md).

## Examples

Check out the `examples/` directory for sample scripts demonstrating various features of ras-commander.

## Future Development

The ras-commander library is an ongoing project. Future plans include:
- Integration of more advanced AI-driven features
- Expansion of HMS and DSS functionalities
- Enhanced GPU support for computational tasks
- Community-driven development of new modules and features

## Related Resources

- [HEC-Commander Blog](https://github.com/billk-FM/HEC-Commander/tree/main/Blog)
- [GPT-Commander YouTube Channel](https://www.youtube.com/@GPT_Commander)
- [ChatGPT Examples for Water Resources Engineers](https://github.com/billk-FM/HEC-Commander/tree/main/ChatGPT%20Examples)


## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on how to submit pull requests, report issues, and suggest improvements.

## Style Guide

This project follows a specific style guide to maintain consistency across the codebase. Please refer to the [Style Guide](STYLE_GUIDE.md) for details on coding conventions, documentation standards, and best practices.

## License

ras-commander is released under the MIT License. See the license file for details.

## Acknowledgments

RAS Commander is based on the HEC-Commander project's "Command Line is All You Need" approach, leveraging the HEC-RAS command-line interface for automation. The initial development of this library was presented in the HEC-Commander Tools repository. In a 2024 Australian Water School webinar, Bill demonstrated the derivation of basic HEC-RAS automation functions from plain language instructions. Leveraging the previously developed code and AI tools, the library was created. The primary tools used for this initial development were Anthropic's Claude, GPT-4, Google's Gemini Experimental models, and the Cursor AI Coding IDE.

Additionally, we would like to acknowledge the following notable contributions and attributions for open source projects which significantly influenced the development of RAS Commander:

1. Contributions: Sean Micek's [`funkshuns`](https://github.com/openSourcerer9000/funkshuns), [`TXTure`](https://github.com/openSourcerer9000/TXTure), and [`RASmatazz`](https://github.com/openSourcerer9000/RASmatazz) libraries provided inspiration, code examples and utility functions which were adapted with AI for use in RAS Commander. Sean has also contributed heavily to 

- Development of additional HDF functions for detailed analysis and mapping of HEC-RAS results within the RasHdf class.
- Development of the prototype `RasCmdr` class for executing HEC-RAS simulations.
- Optimization examples and methods from (INSERT REFERENCE) for use in the Ras-Commander library examples

2. Attribution: The [`pyHMT2D`](https://github.com/psu-efd/pyHMT2D/) project by Xiaofeng Liu, which provided insights into HDF file handling methods for HEC-RAS outputs.  Many of the functions in the [Ras_2D_Data.py](https://github.com/psu-efd/pyHMT2D/blob/main/pyHMT2D/Hydraulic_Models_Data/RAS_2D/RAS_2D_Data.py) file were adapted with AI for use in RAS Commander. 

   Xiaofeng Liu, Ph.D., P.E.
   Associate Professor
   Department of Civil and Environmental Engineering
   Institute of Computational and Data Sciences
   Penn State University

These acknowledgments recognize the contributions and inspirations that have helped shape RAS Commander, ensuring proper attribution for the ideas and code that have influenced its development.

3. Chris Goodell, "Breaking the HEC-RAS Code" - Studied and used as a reference for understanding the inner workings of HEC-RAS, providing valuable insights into the software's functionality and structure.

4. [HEC-Commander Tools](https://github.com/billk-FM/HEC-Commander) - Inspiration and initial code base for the development of RAS Commander.


## Contact

For questions, suggestions, or support, please contact:
William Katzenmeyer, P.E., C.F.M. - billk@fenstermaker.com

==================================================

File: c:\GH\ras-commander\requirements.txt
==================================================
# Core dependencies
pandas>=1.0.0
numpy>=1.18.0
pathlib>=1.0.1
requests>=2.25.0

# Data handling and analysis
h5py>=3.1.0

# Plotting (if needed)
matplotlib>=3.3.0

# Development and testing
pytest>=6.2.0
flake8>=3.9.0
black>=21.5b1

# Documentation
sphinx>=3.5.0
sphinx-rtd-theme>=0.5.0

# Packaging and distribution
setuptools>=50.3.2
wheel>=0.35.1
twine>=3.3.0
==================================================

File: c:\GH\ras-commander\setup.py
==================================================
from setuptools import setup, find_packages
from setuptools.command.build_py import build_py
import subprocess
from pathlib import Path

class CustomBuildPy(build_py):
    def run(self):
        # Run the summary_knowledge_bases.py script
        script_path = Path(__file__).parent / 'ai_tools' / 'summary_knowledge_bases.py'
        subprocess.run(['python', str(script_path)], check=True)
        
        # Continue with the regular build process
        super().run()

setup(
    name="ras-commander",
    version="0.35.0",
    packages=["ras_commander"],
    include_package_data=True,
    install_requires=[
        'pandas>=1.0.0',
        'numpy>=1.18.0',
        'h5py>=3.1.0',
        'requests>=2.25.0',
        'scipy>=1.5.0',
        'matplotlib>=3.3.0',
        'tqdm>=4.50.0',
        'psutil>=5.7.0',
    ],
    extras_require={
        'dev': [
            'pytest>=6.2.0',
            'flake8>=3.9.0',
            'black>=21.5b1',
            'sphinx>=3.5.0',
            'sphinx-rtd-theme>=0.5.0',
            'twine>=3.3.0',
        ],
    },
    classifiers=[
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires='>=3.9',
    author="William M. Katzenmeyer",
    author_email="billk@fenstermaker.com",
    description="A Python library for automating HEC-RAS operations",
    long_description=open('README.md').read(),
    long_description_content_type="text/markdown",
    url="https://github.com/billk-FM/ras-commander",
    cmdclass={
        'build_py': CustomBuildPy,
    },
)

"""
ras-commander setup.py

This file is used to build and publish the ras-commander package to PyPI.

To build and publish this package, follow these steps:

1. Ensure you have the latest versions of setuptools, wheel, and twine installed:
   pip install --upgrade setuptools wheel twine

2. Update the version number in ras_commander/__init__.py (if not using automatic versioning)

3. Create source distribution and wheel:
   python setup.py sdist bdist_wheel

4. Check the distribution:
   twine check dist/*

5. Upload to Test PyPI (optional):
   twine upload --repository testpypi dist/*

6. Install from Test PyPI to verify (optional):
   pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ras-commander

7. Upload to PyPI:
   twine upload dist/*

8. Install from PyPI to verify:
   pip install ras-commander

Note: Ensure you have the necessary credentials and access rights to upload to PyPI.
For more information, visit: https://packaging.python.org/tutorials/packaging-projects/

"""

==================================================

File: c:\GH\ras-commander\STYLE_GUIDE.md
==================================================
# RAS Commander (ras-commander) Style Guide

## Table of Contents
1. [Naming Conventions](#1-naming-conventions)
2. [Code Structure and Organization](#2-code-structure-and-organization)
3. [Documentation and Comments](#3-documentation-and-comments)
4. [Code Style](#4-code-style)
5. [Error Handling](#5-error-handling)
6. [Testing](#6-testing)
7. [Version Control](#7-version-control)
8. [Type Hinting](#8-type-hinting)
9. [Project-Specific Conventions](#9-project-specific-conventions)
10. [Inheritance](#10-inheritance)
11. [RasUtils Usage](#11-rasutils-usage)
12. [Working with RasExamples](#12-working-with-rasexamples)

## 1. Naming Conventions

### 1.1 General Rules
- Use `snake_case` for all function and variable names
- Use `PascalCase` for class names
- Use `UPPER_CASE` for constants

### 1.2 Library-Specific Naming
- Informal Name: RAS Commander
- Package Name and GitHub Library Name: ras-commander (with a hyphen)
- Import Name: ras_commander (with an underscore)
- Main Class of functions for HEC-RAS Automation: RasCmdr

### 1.3 Function Naming
- Start function names with a verb describing the action
- Use clear, descriptive names
- Common verbs and their uses:
  - `get_`: retrieve data
  - `set_`: set values or properties
  - `compute_`: execute or calculate
  - `clone_`: copy
  - `clear_`: remove or reset data
  - `find_`: search
  - `update_`: modify existing data

### 1.4 Abbreviations
Use the following abbreviations consistently throughout the codebase:

- ras: HEC-RAS
- prj: Project
- geom: Geometry
- pre: Preprocessor
- geompre: Geometry Preprocessor
- num: Number
- init: Initialize
- XS: Cross Section
- DSS: Data Storage System
- GIS: Geographic Information System
- BC: Boundary Condition
- IC: Initial Condition
- TW: Tailwater

Use these abbreviations in lowercase for function and variable names (e.g., `geom`, not `Geom` or `GEOM`).

### 1.5 Class Naming
- Use `PascalCase` for class names (e.g., `FileOperations`, `PlanOperations`, `RasCmdr`)
- Class names should be nouns or noun phrases

### 1.6 Variable Naming
- Use descriptive names indicating purpose or content
- Prefix boolean variables with `is_`, `has_`, or similar

## 2. Code Structure and Organization

### 2.1 File Organization
- Group related functions into appropriate classes
- Keep each class in its own file, named after the class

### 2.2 Function Organization
- Order functions logically within a class
- Place common or important functions at the top of the class

### 2.3 Module Structure
- Use the following order for module contents:
  1. Module-level docstring
  2. Imports (grouped and ordered)
  3. Constants
  4. Classes
  5. Functions

## 3. Documentation and Comments

### 3.1 Docstrings
- Use docstrings for all modules, classes, methods, and functions
- Follow Google Python Style Guide format
- Include parameters, return values, and a brief description
- For complex functions, include examples in the docstring

### 3.2 Comments
- Use inline comments sparingly, only for complex logic
- Keep comments up-to-date with code changes
- Use TODO comments for future work, formatted as: `# TODO: description`

## 4. Code Style

### 4.1 Imports
- Order imports as follows:
  1. Standard library imports
  2. Third-party library imports
  3. Local application imports
- Use absolute imports
- Use `import ras_commander as ras` for shortening the library name in examples

### 4.2 Whitespace
- Follow PEP 8 guidelines
- Use 4 spaces for indentation (no tabs)
- Use blank lines to separate logical sections of code

### 4.3 Line Length
- Limit lines to 79 characters for code, 72 for comments and docstrings
- Use parentheses for line continuation in long expressions

## 5. Error Handling

**Use Logging Instead of Prints**
Ensure that every operation that can fail or needs to provide feedback to the user is logged instead of using `print`. This will help in debugging and improve monitoring during execution.

   ```python
   logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
   ```

   Example of replacing a `print` with logging:
   ```python
   logging.info('Starting HEC-RAS simulation...')
   ```

- Use explicit exception handling with try/except blocks
- Raise custom exceptions when appropriate, with descriptive messages
- Use logging for error reporting and debugging information
- Use specific exception types when raising errors (e.g., `ValueError`, `FileNotFoundError`)
- Provide informative error messages that include relevant details
- Implement proper cleanup in finally blocks when necessary
- For user-facing functions, consider wrapping internal exceptions in custom exceptions specific to ras-commander

Example:
```python
try:
    result = compute_plan(plan_number)
except FileNotFoundError as e:
    raise RasCommanderError(f"Plan file not found: {e}")
except ValueError as e:
    raise RasCommanderError(f"Invalid plan parameter: {e}")
except Exception as e:
    raise RasCommanderError(f"Unexpected error during plan computation: {e}")
```

## 6. Testing

- Write unit tests for all functions and methods
- Use the `unittest` framework
- Aim for high test coverage, especially for critical functionality
- Include tests for both single-project and multi-project scenarios
- Write clear and descriptive test names
- Use setUp and tearDown methods for common test preparations and cleanups
- Use mock objects when appropriate to isolate units under test

## 7. Version Control

- Use meaningful commit messages that clearly describe the changes made
- Create feature branches for new features or significant changes
- Submit pull requests for code review before merging into the main branch
- Keep commits focused and atomic (one logical change per commit)
- Use git tags for marking releases
- Follow semantic versioning for release numbering

## 8. Type Hinting

- Use type hints for all function parameters and return values
- Use the `typing` module for complex types (e.g., `List`, `Dict`, `Optional`)
- Include type hints in function signatures and docstrings
- Use `Union` for parameters that can accept multiple types
- For methods that don't return a value, use `-> None`

Example:
```python
from typing import List, Optional

def process_plans(plan_numbers: List[str], max_workers: Optional[int] = None) -> bool:
    # Function implementation
    return True
```

## 9. Project-Specific Conventions

### 9.1 RAS Instance Handling
- Design functions to accept an optional `ras_object` parameter:
  ```python
  def some_function(param1, param2, ras_object=None):
      ras_obj = ras_object or ras
      ras_obj.check_initialized()
      # Function implementation
  ```

### 9.2 File Path Handling
- Use `pathlib.Path` for file and directory path manipulations
- Convert string paths to Path objects at the beginning of functions

### 9.3 DataFrame Handling
- Use pandas for data manipulation and storage where appropriate
- Prefer method chaining for pandas operations to improve readability

### 9.4 Parallel Execution
- Follow the guidelines in the "Benchmarking is All You Need" blog post for optimal core usage in parallel plan execution

### 9.5 Function Return Values
- Prefer returning meaningful values over modifying global state
- Use tuple returns for multiple values instead of modifying input parameters

## 10. Inheritance

### 10.1 General Principles

- Prioritize composition over inheritance when appropriate
- Design base classes for extension
- Clearly document the public API and subclass API using docstrings

### 10.2 Naming Conventions

- Public API: No leading underscores
- Subclass API: Single leading underscore (e.g., `_prepare_for_execution`)
- Internal attributes and methods: Single leading underscore
- Name mangling (double leading underscores): Use sparingly and document the decision clearly

### 10.3 Template Method Pattern

Consider using the template method pattern in base classes to define a high-level algorithm structure. Subclasses can then override specific steps to customize behavior.

### 10.4 Dataframe Access Control

Use properties to control access and modification of dataframes, providing a controlled interface for subclasses.

## 11. RasUtils Usage

- Use RasUtils for general-purpose utility functions that don't fit into other specific classes
- When adding new utility functions, ensure they are static methods of the RasUtils class
- Keep utility functions focused and single-purpose
- Document utility functions thoroughly, including examples of usage

Example:
```python
class RasUtils:
    @staticmethod
    def create_backup(file_path: Path, backup_suffix: str = "_backup") -> Path:
        """
        Create a backup of the specified file.

        Args:
            file_path (Path): Path to the file to be backed up
            backup_suffix (str): Suffix to append to the backup file name

        Returns:
            Path: Path to the created backup file

        Example:
            >>> backup_path = RasUtils.create_backup(Path("project.prj"))
            >>> print(f"Backup created at: {backup_path}")
        """
        # Function implementation
```

## 12. Working with RasExamples

- Use RasExamples for managing and loading example HEC-RAS projects
- Always check if example projects are already downloaded before attempting to download them again
- Use the `list_categories()` and `list_projects()` methods to explore available examples
- When extracting projects, use meaningful names and keep track of extracted paths
- Clean up extracted projects when they are no longer needed using `clean_projects_directory()`

Example:
```python
ras_examples = RasExamples()
if not ras_examples.is_project_extracted("Bald Eagle Creek"):
    extracted_path = ras_examples.extract_project("Bald Eagle Creek")[0]
    # Use the extracted project
    # ...
    # Clean up when done
    RasUtils.remove_with_retry(extracted_path, is_folder=True)
```

Remember, consistency is key. When in doubt, prioritize readability and clarity in your code. Always consider the maintainability and extensibility of the codebase when making design decisions.
==================================================

File: c:\GH\ras-commander\.gitignore\.gitignore
==================================================
# Ignore the example_projects folder and all its subfolders
examples/example_projects/

# Ignore workspace, projects, and my_projects folders
workspace/
projects/
my_projects/

# Ignore FEMA BLE Models
examples/FEMA_BLE_Models/
examples/hdf_example_data/

# Ignore Python egg info
*.egg-info/
.eggs/

# Ignore the Example_Projects_6_5.zip file
Example_Projects_6_5.zip

# Ignore the misc folder and all its subfolders
misc/

# Ignore Python cache files
__pycache__/
*.py[cod]

# Ignore compiled Python files
*.so

# Ignore distribution / packaging
dist/
build/

# Ignore test cache
.pytest_cache/

# Ignore virtual environments
.venv/
venv/

# Ignore IDE-specific files (optional, uncomment if needed)
# .vscode/
# .idea/

# Ignore OS-specific files
.DS_Store
Thumbs.db
==================================================

File: c:\GH\ras-commander\examples\01_project_initialization.py
==================================================
# 01_project_initialization.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example demonstrates both the default global 'ras' object and custom ras objects.
# 2. The global 'ras' object is suitable for simple scripts working with a single project.
# 3. Custom ras objects are recommended for complex scripts or when working with multiple projects.
# 4. The init_ras_project function initializes a project and sets up the ras object.
# 5. Each ras object contains comprehensive information about its project, including plan, geometry, flow files, and boundary conditions.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Use descriptive names for custom ras objects to clearly identify different projects.

def print_ras_object_data(ras_obj, project_name):
    print(f"\n{project_name} Project Data:")
    print("=" * 50)
    print(f"Project Name: {ras_obj.get_project_name()}")
    print(f"Project Folder: {ras_obj.project_folder}")
    print(f"PRJ File: {ras_obj.prj_file}")
    print(f"HEC-RAS Executable Path: {ras_obj.ras_exe_path}")
    
    print("\nPlan Files DataFrame:")
    print(ras_obj.plan_df)
    
    print("\nFlow Files DataFrame:")
    print(ras_obj.flow_df)
    
    print("\nUnsteady Flow Files DataFrame:")
    print(ras_obj.unsteady_df)
    
    print("\nGeometry Files DataFrame:")
    print(ras_obj.geom_df)
    
    print("\nHDF Entries DataFrame:")
    print(ras_obj.get_hdf_entries())
    
    print("\nBoundary Conditions DataFrame:")
    print(ras_obj.get_boundary_conditions())
    
    print("\nMeteorological Data:")
    for attr in ['precipitation_mode', 'wind_mode', 'precipitation_metadata', 'evapotranspiration_metadata']:
        if hasattr(ras_obj, attr):
            print(f"{attr.capitalize().replace('_', ' ')}: {getattr(ras_obj, attr)}")
        else:
            print(f"{attr.capitalize().replace('_', ' ')}: Not available")

def main():
    # Get the current script's directory
    current_dir = Path(__file__).parent
    
    # Define paths to example projects
    bald_eagle_path = current_dir.parent / "examples" / "example_projects" / "Balde Eagle Creek"
    multi_2d_path = current_dir.parent / "examples" / "example_projects" / "BaldEagleCrkMulti2D"
    muncie_path = current_dir.parent / "examples" / "example_projects" / "Muncie"

    print("Example Set 1: Using the default global 'ras' object")
    print("-----------------------------------------------------")

    # Initialize using the global RAS instance
    print("Step 1: Initializing with global RAS instance")
    init_ras_project(bald_eagle_path, "6.5") # This will set the global 'ras' object
    print_ras_object_data(ras, "Global RAS Instance (Bald Eagle Creek)")

    print("\nExample Set 2: Using custom ras objects")
    print("-----------------------------------------------------")

    # Initialize multiple project instances
    print("Step 1: Initializing multiple project instances")
    multi_2d_project = init_ras_project(multi_2d_path, "6.5")
    muncie_project = init_ras_project(muncie_path, "6.5")

    print_ras_object_data(multi_2d_project, "Multi2D Project")
    print_ras_object_data(muncie_project, "Muncie Project")

    print("\nExample of simplified import (not recommended for complex scripts)")
    print("-----------------------------------------------------")
    print("from ras_commander import *")
    print("# This allows you to use all functions and classes without prefixes")
    print("# For example: compute_plan() instead of RasCmdr.compute_plan()")
    print("# Note: This approach can lead to naming conflicts and is generally not recommended for larger scripts")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\02_plan_operations.py
==================================================
# 02_plan_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on plans, geometries, and unsteady flows using the functions within the RasPlan Class.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Geometry Cloning: Clone a geometry associated with the original plan, generating a new geometry entry.
4. Unsteady Flow Cloning: Clone an unsteady flow, creating a new unsteady flow entry.
5. Plan Configuration:
   a. Set the cloned geometry for the new plan.
   b. Set the cloned unsteady flow for the new plan.
   c. Update the number of cores to be used for the new plan.
   d. Configure geometry preprocessor options for the new plan.
6. Plan Computation: Compute the new plan and verify successful execution.
7. Results Verification: Check the HDF entries to confirm that results were written.

Additional operations that could be demonstrated:
8. Plan Modification: Update specific parameters in the plan file (e.g., simulation time, output intervals).
9. Geometry Editing: Modify cross-sections, manning's n values, or other geometry data.
10. Unsteady Flow Modification: Adjust boundary conditions or initial conditions.
11. Batch Operations: Perform operations on multiple plans simultaneously.
12. Error Handling: Demonstrate how to handle and report errors during plan operations.
13. Results Analysis: Extract and analyze key output values from the computed plan.
"""

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()
    
    # Step 2: Clone a geometry
    print("Step 2: Cloning a geometry")
    new_geo_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geo_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()
    
    # Step 3: Clone an unsteady flow
    print("Step 3: Cloning an unsteady flow")
    new_unsteady_number = RasPlan.clone_unsteady("02")
    print(f"New unsteady flow created: {new_unsteady_number}")
    print("Updated unsteady flow files:")
    print(ras.unsteady_df)
    print()

    # Step 4: Set geometry for the cloned plan
    print("Step 4: Setting geometry for a plan")
    RasPlan.set_geom(new_plan_number, new_geo_number)
    plan_path = RasPlan.get_plan_path(new_plan_number)
    print(f"Updated geometry for plan {new_plan_number}")
    print(f"Plan file path: {plan_path}")
    print()

    # Step 5: Set unsteady flow for the cloned plan
    print("Step 5: Setting unsteady flow for a plan")
    RasPlan.set_unsteady(new_plan_number, new_unsteady_number)
    print(f"Updated unsteady flow for plan {new_plan_number}")
    print()

    # Step 6: Set the number of cores for the cloned plan
    print("Step 6: Setting the number of cores for a plan")
    RasPlan.set_num_cores(new_plan_number, 2)
    print(f"Updated number of cores for plan {new_plan_number}")
    print()

    # Step 7: Set geometry preprocessor options for the cloned plan
    print("Step 7: Setting geometry preprocessor options")
    RasPlan.set_geom_preprocessor(plan_path, run_htab=-1, use_ib_tables=-1)
    print(f"Updated geometry preprocessor options for plan {new_plan_number}")
    
    # Step 8: Compute the cloned plan
    print("Step 8: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
    print()
    
    # Step 9: Get the HDF entries for the cloned plan to prove that the results were written
    print("Step 9: Retrieving HDF entries for the cloned plan")
    # Refresh the plan entries to ensure we have the latest data
    ras.plan_df = ras.get_plan_entries()
    hdf_entries = ras.get_hdf_entries()
    if not hdf_entries.empty:
        print("HDF entries for the cloned plan:")
        print(hdf_entries)
    else:
        print("No HDF entries found. This could mean the plan hasn't been computed successfully or the results haven't been written yet.")
    
    # Display the plan entries to see if the HDF path is populated
    print("\nCurrent plan entries:")
    print(ras.plan_df)
    
if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\03_geometry_operations.py
==================================================
# 03_geometry_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasGeo class provides methods for working with geometry files and preprocessor operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Always clear geometry preprocessor files before making significant changes to ensure clean results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Muncie"
    init_ras_project(project_path, "6.5")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()

    # Step 2: Clone a geometry file and assign it to the cloned plan
    print("Step 2: Cloning a geometry file and assigning it to the cloned plan")
    new_geom_number = RasPlan.clone_geom("01")
    print(f"New geometry created: {new_geom_number}")
    print(f"Now set the new geometry to the new plan")
    RasPlan.set_geom(new_plan_number, new_geom_number)
    print(f"New geometry {new_geom_number} assigned to plan {new_plan_number}")
    print("Updated geometry files:")
    print(ras.geom_df)
    print()

    # Step 3: Clear geometry preprocessor files for the cloned plan
    print("Step 3: Clearing geometry preprocessor files for the cloned plan")
    plan_path = RasPlan.get_plan_path(new_plan_number)
    RasGeo.clear_geompre_files(plan_path)
    print(f"Cleared geometry preprocessor files for plan {new_plan_number}")
    print()

    # Step 4: Clear geometry preprocessor files for all plans
    print("Step 4: Clearing geometry preprocessor files for all plans")
    RasGeo.clear_geompre_files()
    print("Cleared geometry preprocessor files for all plans")
    print()

    # Step 5: Print the updated plan information
    print("Step 5: Updated plan information")
    plan_df = ras.get_plan_entries()
    print(plan_df)
    print()

    # Step 6: Compute the cloned plan with new geometry and core count
    print("Step 6: Computing the cloned plan")
    success = RasCmdr.compute_plan(new_plan_number)
    print(f"Computing plan {new_plan_number}")
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")
        
    # Step 7: Get and print results paths
    print("\nStep 7: Getting results paths")
    for plan_number in [new_plan_number, "01"]:  # Check both the new plan and the original plan
        results_path = RasPlan.get_results_path(plan_number)
        if results_path:
            print(f"Results for plan {plan_number} are located at: {results_path}")
        else:
            print(f"No results found for plan {plan_number}")
        

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\04_unsteady_flow_operations.py
==================================================
# 04_unsteady_flow_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on unsteady flow plans using the ras-commander library.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Unsteady Flow Parameter Updates: Modify various unsteady flow parameters in the new plan.
4. Plan Computation: Compute the new plan and verify successful execution.

Note: This example uses the default global 'ras' object for simplicity. For complex scripts or when working with
multiple projects, it's recommended to create and use separate ras objects.
"""

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Initial plan files:")
    print(ras.plan_df)
    print()

    # Step 1: Clone a plan
    print("Step 1: Cloning a plan")
    new_plan_number = RasPlan.clone_plan("01")
    print(f"New plan created: {new_plan_number}")
    print("Updated plan files:")
    print(ras.plan_df)
    print()

    # Step 2: Get the plan file path
    plan_path = RasPlan.get_plan_path(new_plan_number)

    # Step 3: Update unsteady flow parameters individually
    print("Step 3: Updating unsteady flow parameters individually")
    RasUnsteady.update_unsteady_parameters(plan_path, {"Simulation Date": "01JAN2023,0000,05JAN2023,2400"})
    RasUnsteady.update_unsteady_parameters(plan_path, {"Computation Interval": "1MIN"})
    RasUnsteady.update_unsteady_parameters(plan_path, {"Output Interval": "15MIN"})
    print("Updated parameters individually")
    print()

    # Step 4: Update unsteady flow parameters in batch
    print("Step 4: Updating unsteady flow parameters in batch")
    batch_modifications = {
        "Mapping Interval": "30MIN",
        "Hydrograph Output Interval": "1HOUR",
        "Detailed Output Interval": "1HOUR"
    }
    RasUnsteady.update_unsteady_parameters(plan_path, batch_modifications)
    print("Updated parameters in batch")
    print()

    # Step 5: Verify changes
    print("Step 5: Verifying changes")
    with open(plan_path, 'r') as f:
        content = f.read()
        for param in ["Simulation Date", "Computation Interval", "Output Interval", 
                      "Mapping Interval", "Hydrograph Output Interval", "Detailed Output Interval"]:
            for line in content.split('\n'):
                if line.startswith(param):
                    print(f"Updated {line}")
                    break
    print()

    # Step 6: Compute the updated plan
    print("Step 6: Computing the updated plan")
    success = RasCmdr.compute_plan(new_plan_number)
    if success:
        print(f"Plan {new_plan_number} computed successfully")
    else:
        print(f"Failed to compute plan {new_plan_number}")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\05_utility_functions.py
==================================================
# 05_utility_functions.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasUtils class provides various utility functions for working with HEC-RAS projects.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")
    plan_number = "01"

    # Example 1: Get plan path using RasUtils
    print("Example 1: Getting plan path")
    plan_path = RasUtils.get_plan_path(plan_number)
    print(f"Path for plan {plan_number} is: {plan_path}")
    
    # Example 2: Get geometry path using RasPlan
    print("\nExample 2: Getting geometry path")
    geom_number = "01"
    geom_path = RasPlan.get_geom_path(geom_number)
    print(f"Path for geometry {geom_number} is: {geom_path}")
    
    # Example 3: Get unsteady flow path using RasPlan
    print("\nExample 3: Getting unsteady flow path")
    unsteady_number = "01"
    unsteady_path = RasPlan.get_unsteady_path(unsteady_number)
    print(f"Path for unsteady flow {unsteady_number} is: {unsteady_path}")
    
    # Example 4: Get project name
    print("\nExample 4: Getting project name")
    project_name = ras.get_project_name()
    print(f"Project name: {project_name}")


if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\06_single_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Define the "example_projects" folder in the same directory as the script
examples_path = Path(__file__).parent / "example_projects"

# Delete the project if it exists
if examples_path.exists():
    import shutil
    shutil.rmtree(examples_path)

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan
    print("Example 1: Executing a single plan")
    plan_number = "01"
    success = RasCmdr.compute_plan(plan_number)
    if success:
        print(f"Plan {plan_number} executed successfully")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 2: Execute a plan in a separate destination folder
    print("Example 2: Executing a plan in a separate destination folder")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder)
    if success:
        print(f"Plan {plan_number} executed successfully in {dest_folder}")
    else:
        print(f"Plan {plan_number} execution failed in {dest_folder}")
    print()

    # Example 3: Get and print results path
    print("Example 3: Getting results path")
    results_path = RasPlan.get_results_path(plan_number)
    if results_path:
        print(f"Results for plan {plan_number} are located at: {results_path}")
    else:
        print(f"No results found for plan {plan_number}")
    print()    

    # Example 4: Execute a plan with cleared geometry preprocessor files
    print("Example 4: Executing a plan with cleared geometry preprocessor files")
    plan_number = "03"
    dest_folder = project_path.parent / "compute_test_3"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, clear_geompre=True)
    if success:
        print(f"Plan {plan_number} executed successfully with cleared geometry preprocessor files")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 5: Execute a plan with a specified number of cores, overwriting compute_test_3
    print("Example 5: Executing a plan with a specified number of cores, overwriting compute_test_3")
    plan_number = "01"
    num_cores = 2  # Specify the number of cores to use
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=num_cores, overwrite_dest=True)
    if success:
        print(f"Plan {plan_number} executed successfully using {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")
    print()
    

    # Example 6: Execute a plan with all new options combined
    print("Example 6: Executing a plan with all new options combined")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_all_options"
    num_cores = 4
    
    success = RasCmdr.compute_plan(
        plan_number,
        dest_folder=dest_folder,
        clear_geompre=True,
        num_cores=num_cores
    )
    if success:
        print(f"Plan {plan_number} executed successfully with all options:")
        print(f"- Destination folder: {dest_folder}")
        print(f"- Cleared geometry preprocessor files")
        print(f"- Used {num_cores} cores")
    else:
        print(f"Plan {plan_number} execution failed")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\07_sequential_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path
# Define the keys to search for in folder names
# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

def main():
    # Initialize the project using the global 'ras' object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of all plans with overwrite_dest
    print("Example 1: Sequential execution of all plans with overwrite_dest")
    RasCmdr.compute_test_mode(
        dest_folder_suffix="[AllSequential]",
        overwrite_dest=True
    )
    print("Sequential execution of all plans completed with overwrite_dest")
    print()
    
    # Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest
    print("Example 2: Sequential execution of specific plans with clearing geompre files and overwrite_dest")
    RasCmdr.compute_test_mode(
        plan_number=["01", "02"],
        dest_folder_suffix="[SpecificSequentialClearGeompre]",
        clear_geompre=True,
        overwrite_dest=True
    )
    print("Sequential execution of specific plans completed with clearing geompre files and overwrite_dest")
    print()

    # Example 3: Demonstrate clearing geompre files for specific plans
    print("Example 3: Clearing geompre files for specific plans")
    plan_files = [RasPlan.get_plan_path("01"), RasPlan.get_plan_path("02")]
    RasGeo.clear_geompre_files(plan_files)
    print("Geometry preprocessor files cleared for specific plans")
    print()

    # Example 4: Demonstrate clearing all geompre files
    print("Example 4: Clearing all geompre files")
    RasGeo.clear_geompre_files()
    print("All geometry preprocessor files cleared")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\08_parallel_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Initialize the project using a new RasPrj object
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    source_project = init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(source_project.plan_df)
    print()

    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel"
    results_all = RasCmdr.compute_parallel(
        max_workers=3,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.5")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()

    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores)
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=source_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.5")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\09_specifying_plans.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path

# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides methods for executing plans in various ways.
# 5. You can specify individual plans or lists of plans for batch operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. When specifying plans, use plan numbers as strings (e.g., "01", "02") for consistency.
# 5. Always check the available plans in the project before specifying plan numbers for execution.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution of specific plans
    print("Example 1: Sequential execution of specific plans (1 and 3)")
    RasCmdr.compute_test_mode(plan_number=["01", "03"], dest_folder_suffix="[SpecificSequential]", num_cores=6)
    print("Sequential execution of specific plans completed")
    print()

    # Example 2: Parallel execution of specific plans
    print("Example 2: Parallel execution of specific plans")
    results_specific = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute all plans
    print("Example 3: Execute all plans")
    all_plan_numbers = ras.plan_df['plan_number'].tolist()
    RasCmdr.compute_test_mode(plan_number=all_plan_numbers, dest_folder_suffix="[AllPlans]")
    print("Execution of all plans completed")
    print()

if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\10_arguments_for_compute.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides various arguments for fine-tuning plan computation:
#    - plan_number: String representing the plan number to compute (e.g., "01")
#    - dest_folder: Path object specifying the destination folder for computation results
#    - clear_geompre: Boolean to clear geometry preprocessor files before computation
#    - num_cores: Integer specifying the number of cores to use
#    - overwrite_dest: Boolean to determine if existing destination folders should be overwritten

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Utilize the various arguments in compute functions to customize plan execution.
# 5. Always consider your system's capabilities when setting num_cores.
# 6. Use clear_geompre=True when you want to ensure a clean computation environment.
# 7. Specify dest_folder to keep your project folder organized and prevent overwriting previous results.

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Sequential execution (compute_test_mode) with various arguments
    print("Example 1: Sequential execution with various arguments")
    for plan_number in ["01", "02"]:
        # Put dest_folder in the parent directory of the project folder (placing it horizontally with the project folder)
        # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory. 
        # So instead of building the full folder name or path, we only define the suffix. 
        dest_folder_suffix = f"_{plan_number}_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number=plan_number,
            dest_folder_suffix=dest_folder_suffix,  # Test mode only allows dest_folder_suffix, and always creates a copy in the project folder's parent directory
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=True
        )
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print("Sequential execution completed")
    print()
    
    # This variation will fail, as the folder already exists and overwrite_dest is False.  
    # Be sure to think step by step about folder management in your multi-folder automation workflows:
    # Also, try to run the same thing with compute_parallel, but with overwrite_dest=False
    # Since we just created these folders, they are not empty, so this should generate an error message on the terminal
    # Put in Try-Except block:
    try:
        dest_folder = project_path.parent / f"{ras.project_name}_compute_test_01_[SequentialWithArgs]"
        success = RasCmdr.compute_test_mode(
            plan_number="01",
            dest_folder_suffix=dest_folder_suffix,
            clear_geompre=True,
            num_cores=2,
            overwrite_dest=False
        )
    except ValueError as e:
        print(f"If the example operates successfully (it is meant to generate an error above), you will not see this message.")

    # Example 2: Parallel execution (compute_parallel) with various arguments
    print("Example 2: Parallel execution with various arguments")
    results = RasCmdr.compute_parallel(
        plan_number=["01", "02"],
        max_workers=2,
        num_cores=2,
        dest_folder=project_path.parent / "parallel_results",
        clear_geompre=True
    )
    print("Parallel execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Single plan execution (compute_plan) with specific arguments
    print("Example 3: Single plan execution with specific arguments")
    plan_number = "02"
    dest_folder = project_path.parent / "compute_test_2"
    success = RasCmdr.compute_plan(plan_number, dest_folder=dest_folder, num_cores=2, clear_geompre=True, overwrite_dest=True)
    print(f"Single plan execution: {'Successful' if success else 'Failed'}")

if __name__ == "__main__":
    main()

==================================================

File: c:\GH\ras-commander\examples\12_plan_set_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

import pandas as pd


def create_plan_set(base_plan, base_geom, num_copies):
    plan_set = []
    for i in range(num_copies):
        new_plan = RasPlan.clone_plan(base_plan)
        new_geom = RasPlan.clone_geom(base_geom)
        RasPlan.set_geom(new_plan, new_geom)
        plan_set.append({
            'plan_number': new_plan,
            'geom_number': new_geom
        })
    return pd.DataFrame(plan_set)

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print("\nAvailable geometries:")
    print(ras.geom_df)
    print()

    # Create a plan set
    base_plan = "01"
    base_geom = "01"
    num_copies = 5
    plan_set = create_plan_set(base_plan, base_geom, num_copies)
    
    print("Created plan set:")
    print(plan_set)
    print()

    # Placeholder for user to insert code that makes programmatic changes to the model
    # For example:
    # for index, row in plan_set.iterrows():
    #     plan_path = RasPlan.get_plan_path(row['plan_number'])
    #     geom_path = RasPlan.get_geom_path(row['geom_number'])
    #     # Make changes to the plan or geometry file here
    #     # For example, you could modify Manning's n values, cross-section data, etc.

    # Execute the plan set in parallel
    print("Executing plan set in parallel")
    results = RasCmdr.compute_parallel(
        plan_number=plan_set['plan_number'].tolist(),
        max_workers=3,
        num_cores=2
    )

    # Add execution results to the plan_set DataFrame
    plan_set['execution_success'] = plan_set['plan_number'].map(results)

    print("\nPlan set execution results:")
    print(plan_set)

    # Here you could add code to analyze the results, such as:
    # - Extracting key output values from each simulation
    # - Comparing results across different plans
    # - Creating visualizations of the results

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\13_multiple_project_operations.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "Muncie"])

#### --- START OF SCRIPT --- ####

def execute_plan(plan_number, ras_object, compute_folder):
    # Set the number of cores to 2 before executing the plan
    RasPlan.set_num_cores(plan_number, 2, ras_object=ras_object)
    
    # Execute the plan in the compute folder
    success = RasCmdr.compute_plan(plan_number, ras_object=ras_object, dest_folder=compute_folder)
    
    return plan_number, success

def main():
    # Initialize two projects
    current_dir = Path(__file__).parent
    bald_eagle_path = current_dir / "example_projects" / "Balde Eagle Creek"
    muncie_path = current_dir / "example_projects" / "Muncie"
    
    bald_eagle = init_ras_project(bald_eagle_path, "6.5")
    muncie = init_ras_project(muncie_path, "6.5")

    print("Available plans in Bald Eagle Creek project:")
    print(bald_eagle.plan_df)
    print("\nAvailable plans in Muncie project:")
    print(muncie.plan_df)
    print()

    # Example 1: Clone plans with custom short identifiers
    print("Example 1: Cloning plans with custom short identifiers")
    new_bald_eagle_plan = RasPlan.clone_plan("01", new_plan_shortid="BECustom", ras_object=bald_eagle)
    new_muncie_plan = RasPlan.clone_plan("01", new_plan_shortid="MunCustom", ras_object=muncie)
    print(f"Created new plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Created new plan {new_muncie_plan} in Muncie project")
    print()

    # Example 2: Set geometry for the new plans
    print("Example 2: Setting geometry for the new plans")
    RasPlan.set_geom(new_bald_eagle_plan, "01", ras_object=bald_eagle)
    RasPlan.set_geom(new_muncie_plan, "01", ras_object=muncie)
    print(f"Set geometry for plan {new_bald_eagle_plan} in Bald Eagle Creek project")
    print(f"Set geometry for plan {new_muncie_plan} in Muncie project")
    print()

    # Example 3: Update unsteady flow parameters for both projects
    print("Example 3: Updating unsteady flow parameters")
    bald_eagle_plan_file = RasPlan.get_plan_path(new_bald_eagle_plan, ras_object=bald_eagle)
    muncie_plan_file = RasPlan.get_plan_path(new_muncie_plan, ras_object=muncie)

    modifications = {
        "Computation Interval": "2MIN",
        "Output Interval": "30MIN",
        "Mapping Interval": "1HOUR"
    }

    RasUnsteady.update_unsteady_parameters(bald_eagle_plan_file, modifications, ras_object=bald_eagle)
    RasUnsteady.update_unsteady_parameters(muncie_plan_file, modifications, ras_object=muncie)
    print("Updated unsteady flow parameters for both projects")
    print()

    # Example 4: Execute plans for both projects simultaneously in separate compute folders
    print("Example 4: Executing plans for both projects simultaneously in separate compute folders")
    
    # Create compute folders
    bald_eagle_compute_folder = bald_eagle_path.parent / "compute_bald_eagle"
    muncie_compute_folder = muncie_path.parent / "compute_muncie"
    
    # Remove existing compute folders if they exist
    for folder in [bald_eagle_compute_folder, muncie_compute_folder]:
        if folder.exists():
            shutil.rmtree(folder)
        folder.mkdir(parents=True, exist_ok=True)
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        futures = [
            executor.submit(execute_plan, new_bald_eagle_plan, bald_eagle, bald_eagle_compute_folder),
            executor.submit(execute_plan, new_muncie_plan, muncie, muncie_compute_folder)
        ]
        
        results = {}
        for future in futures:
            plan_number, success = future.result()
            results[plan_number] = success

    print("Execution results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number} execution: {'Successful' if success else 'Failed'}")
    print()

    # Example 5: Get and print results paths
    print("Example 5: Getting results paths")
    bald_eagle_results = RasPlan.get_results_path(new_bald_eagle_plan, ras_object=bald_eagle)
    muncie_results = RasPlan.get_results_path(new_muncie_plan, ras_object=muncie)

    if bald_eagle_results:
        print(f"Results for Bald Eagle Creek plan {new_bald_eagle_plan} are located at: {bald_eagle_results}")
    else:
        print(f"No results found for Bald Eagle Creek plan {new_bald_eagle_plan}")

    if muncie_results:
        print(f"Results for Muncie plan {new_muncie_plan} are located at: {muncie_results}")
    else:
        print(f"No results found for Muncie plan {new_muncie_plan}")

    print("\nNote: The original project folders can now be edited while the compute operations are running in separate folders.")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\14_Core_Sensitivity.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ras-commander pandas requests pathlib matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCommander, RasPlan, RasGeo, RasUnsteady, RasUtils, ras\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCommander, RasPlan, RasGeo, RasUnsteady, RasUtils, ras\n",
    "\n",
    "print(\"ras_commander imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ras_commander import RasExamples, init_ras_project, RasCommander, RasPlan, RasGeo\n",
    "\n",
    "# Step 1: Initialize RasExamples and extract the Muncie project\n",
    "ras_examples = RasExamples()\n",
    "ras_examples.extract_project([\"Muncie\"])\n",
    "\n",
    "# Use Path.cwd() to get the current working directory in a Jupyter Notebook\n",
    "current_directory = Path.cwd()\n",
    "project_path = current_directory / \"example_projects\" / \"Muncie\"\n",
    "\n",
    "# Step 2: Initialize the Muncie Project using init_ras_project (from ras_commander)\n",
    "muncie_project = init_ras_project(project_path, \"6.5\")\n",
    "\n",
    "# Step 3: Initialize a DataFrame to store execution results\n",
    "results = []\n",
    "\n",
    "# Step 4: Iterate over each plan and core count\n",
    "for plan_number in muncie_project.plan_df['plan_number'].unique():\n",
    "    print(f\"Running sensitivity analysis for Plan {plan_number}\")\n",
    "    \n",
    "    # Clear geompre files before running the plan\n",
    "    plan_path = RasPlan.get_plan_path(plan_number)\n",
    "    RasGeo.clear_geompre_files(plan_path)\n",
    "    \n",
    "    for cores in range(1, 9):\n",
    "        # Set core count for this plan\n",
    "        RasPlan.set_num_cores(plan_number, cores)\n",
    "        \n",
    "        # Time the execution of the plan\n",
    "        start_time = time.time()\n",
    "        RasCommander.compute_plan(plan_number)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            \"plan_number\": plan_number,\n",
    "            \"cores\": cores,\n",
    "            \"execution_time\": execution_time\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Step 6: Extract plan title, shortid, and description\n",
    "plan_info_df = muncie_project.plan_df[['plan_number', 'title', 'shortid', 'description']]\n",
    "\n",
    "# Merge the execution results with the plan information\n",
    "merged_df = pd.merge(results_df, plan_info_df, on='plan_number')\n",
    "\n",
    "# Step 7: Calculate unit runtime (based on 1 core execution time)\n",
    "merged_df['unit_runtime'] = merged_df.groupby('plan_number')['execution_time'].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "# Display the results dataframe for verification\n",
    "print(\"merged_df DataFrame:\")\n",
    "print(merged_df)\n",
    "\n",
    "# Step 8: Plot a line chart for unit runtime vs. cores for each plan\n",
    "plt.figure(figsize=(10, 6))\n",
    "for plan in merged_df['plan_number'].unique():\n",
    "    plan_data = merged_df[merged_df['plan_number'] == plan]\n",
    "    plt.plot(plan_data['cores'], plan_data['unit_runtime'], label=f\"Plan {plan}\")\n",
    "\n",
    "plt.xlabel(\"Number of Cores\")\n",
    "plt.ylabel(\"Unit Runtime (Relative to 1 Core)\")\n",
    "plt.title(\"Core Count Sensitivity Analysis\")\n",
    "plt.legend(title=\"Plan Title\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "releasecmdr311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\15_plan_key_operations.py
==================================================
# 15_plan_key_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    ras_obj = init_ras_project(project_path, "6.5")

    print("Example 15: Getting and Setting Plan Keys")
    print("------------------------------------------")

    # Get the first plan number
    plan_number = ras_obj.plan_df['plan_number'].iloc[0]
    print(f"Working with Plan: {plan_number}")

    # 1. Get and print multiple plan values
    keys_to_check = ['computation_interval', 'simulation_date', 'short_identifier', 'unet_d1_cores']
    print("\n1. Current Plan Values:")
    for key in keys_to_check:
        value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {value}")

    # 2. Update plan values
    print("\n2. Updating Plan Values:")
    updates = {
        'computation_interval': '30SEC',
        'short_identifier': 'Updated_Plan',
        'unet_d1_cores': '4'
    }
    for key, value in updates.items():
        RasPlan.update_plan_value(plan_number, key, value, ras_object=ras_obj)
        print(f"  Updated {key} to: {value}")

    # 3. Verify updates
    print("\n3. Verifying Updates:")
    for key in updates.keys():
        new_value = RasPlan.get_plan_value(plan_number, key, ras_object=ras_obj)
        print(f"  {key}: {new_value}")

    # 4. Get and update description
    print("\n4. Plan Description:")
    current_description = RasPlan.get_plan_value(plan_number, 'description', ras_object=ras_obj)
    print(f"  Current description: {current_description}")

    new_description = "This is an updated plan description for Example 15."
    RasPlan.update_plan_value(plan_number, 'description', new_description, ras_object=ras_obj)
    print(f"  Updated description to: {new_description}")

    # Verify description update
    updated_description = RasPlan.get_plan_value(plan_number, 'description', ras_object=ras_obj)
    print(f"  Verified updated description: {updated_description}")

    # 5. Attempt to get and set an invalid key
    print("\n5. Handling Invalid Keys:")
    try:
        RasPlan.get_plan_value(plan_number, 'invalid_key', ras_object=ras_obj)
    except ValueError as e:
        print(f"  Error when getting invalid key: {e}")

    try:
        RasPlan.update_plan_value(plan_number, 'invalid_key', 'some_value', ras_object=ras_obj)
    except ValueError as e:
        print(f"  Error when updating invalid key: {e}")

    print("\nExample 15 completed.")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\16_scanning_ras_project_info.py
==================================================
import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    from ras_commander import init_ras_project, RasPrj, RasExamples
except ImportError:
    sys.path.append(str(parent_directory))
    from ras_commander import init_ras_project, RasPrj, RasExamples

import logging

def generate_category_summary(category_path):
    summary = []
    summary.append(f"RAS-Commander Example Projects Summary for Category: {category_path.name}\n")
    summary.append("=" * 80 + "\n\n")

    for project_path in category_path.iterdir():
        if project_path.is_dir():
            summary.append(f"Project Folder: {project_path.name}")
            summary.append(f"Full Path: {project_path.resolve()}\n")

            try:
                ras_project = init_ras_project(project_path, "6.5", ras_instance=RasPrj())
                
                summary.append(f"Project Name: {ras_project.get_project_name()}")
                summary.append(f"PRJ File: {ras_project.prj_file}")
                summary.append(f"RAS Executable: {ras_project.ras_exe_path}\n")

                summary.append("Plan Files:")
                summary.append(ras_project.plan_df.to_string())
                summary.append("\n")

                summary.append("Flow Files:")
                summary.append(ras_project.flow_df.to_string())
                summary.append("\n")

                summary.append("Geometry Files:")
                summary.append(ras_project.geom_df.to_string())
                summary.append("\n")

                summary.append("Unsteady Flow Files:")
                summary.append(ras_project.unsteady_df.to_string())
                summary.append("\n")

                summary.append("Boundary Conditions:")
                summary.append(ras_project.boundaries_df.to_string())
                summary.append("\n")

                # Add unparsed lines for each boundary condition
                summary.append("Unparsed Boundary Condition Lines:")
                for _, row in ras_project.boundaries_df.iterrows():
                    bc_number = row['boundary_condition_number']
                    unsteady_number = row['unsteady_number']
                    unparsed_lines = ras_project._parse_boundary_condition(
                        ras_project._get_boundary_condition_block(unsteady_number, bc_number),
                        unsteady_number,
                        bc_number
                    )[1]
                    if unparsed_lines:
                        summary.append(f"BC {bc_number} in Unsteady File {unsteady_number}:")
                        summary.append(unparsed_lines)
                        summary.append("\n")
                summary.append("\n")

            except Exception as e:
                summary.append(f"Error initializing RAS project: {str(e)}\n")

            summary.append("-" * 80 + "\n\n")

    return "\n".join(summary)

def main():
    # Set logging level to DEBUG to capture unparsed lines
    logging.getLogger().setLevel(logging.DEBUG)

    ras_examples = RasExamples()
    selected_categories = ["1D Unsteady Flow Hydraulics", "2D Unsteady Flow Hydraulics"]

    base_dir = Path.cwd() / "ras_example_categories"
    base_dir.mkdir(exist_ok=True)

    for category in selected_categories:
        category_dir = base_dir / category
        category_dir.mkdir(exist_ok=True)

        projects = ras_examples.list_projects(category)
        extracted_paths = ras_examples.extract_project(projects)

        # Move extracted projects to the category directory
        for path in extracted_paths:
            new_path = category_dir / path.name
            path.rename(new_path)

        # Generate and save summary for this category
        summary_text = generate_category_summary(category_dir)
        output_file = base_dir / f"ras-commander {category} summary.txt"
        with open(output_file, "w") as f:
            f.write(summary_text)

        print(f"Summary for category '{category}' has been written to: {output_file}")

    print("All category summaries have been generated.")

    # Clean up extracted projects
    ras_examples.clean_projects_directory()
    print("Cleaned up original extracted example projects.")

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\examples\17_parallel_execution_ble.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math
import logging

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

# Initialize RasExamples
ras_examples = RasExamples()

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

##  WHISKY CHITTO DOES NOT WORK - BLE MODEL IS BROKEN AND REQUIRED FIXING BEFORE RUNNING

def get_physical_core_count():
    return psutil.cpu_count(logical=False)

def main():
    # Define paths
    current_dir = Path(__file__).parent
    csv_directory = current_dir / "FEMA_BLE_Models"
    csv_file = csv_directory / "08080204_WhiskyChitto_DownloadIndex.csv"
    
    # Download FEMA BLE Models (specifically WhiskyChitto)
    ras_examples.download_fema_ble_model(csv_file=csv_file)
    
    
    # Initialize the RasPrj object for WhiskyChitto
    project_path = csv_directory / "WhiskyChitto" / "HECRAS_Models" / "Model" / "Input"
    logging.info(f"Initializing RasPrj for project at: {project_path}")
    whisky_project = init_ras_project(project_path, "5.0.7")
    
    print("Available plans:")
    print(whisky_project.plan_df)
    print()
    
    # Example 1: Parallel execution of all plans with overwrite_dest
    print("Example 1: Parallel execution of all plans with overwrite_dest")
    compute_folder = project_path.parent / "compute_test_parallel_whisky"
    results_all = RasCmdr.compute_parallel(
        max_workers=2,
        num_cores=2,
        dest_folder=compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of all plans results:")
    for plan_number, success in results_all.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Initialize a new RasPrj object for the compute_folder
    compute_source_project = init_ras_project(compute_folder, "6.5")
    print("Plan DataFrame after parallel execution of all plans:")
    print(compute_source_project.plan_df)
    print()
    
    # Example 2: Parallel execution of specific plans with overwrite_dest
    print("Example 2: Parallel execution of specific plans with overwrite_dest")
    specific_plans = ["01", "02"]
    specific_compute_folder = project_path.parent / "compute_test_parallel_specific_whisky"
    results_specific = RasCmdr.compute_parallel(
        plan_number=specific_plans,
        max_workers=2,
        num_cores=2,
        dest_folder=specific_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print("Parallel execution of specific plans results:")
    for plan_number, success in results_specific.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Example 3: Parallel execution with dynamic max_workers based on physical cores
    print("Example 3: Parallel execution with dynamic max_workers")
    num_cores = 2
    physical_cores = get_physical_core_count()
    max_workers = math.floor(physical_cores / num_cores) if num_cores > 0 else 1
    
    dynamic_compute_folder = project_path.parent / "compute_test_parallel_dynamic_whisky"
    results_dynamic = RasCmdr.compute_parallel(
        max_workers=max_workers,
        num_cores=num_cores,
        dest_folder=dynamic_compute_folder,
        overwrite_dest=True,
        ras_object=whisky_project
    )
    print(f"Parallel execution with {max_workers} workers and {num_cores} cores per worker:")
    for plan_number, success in results_dynamic.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()
    
    # Get and print results paths
    print("Results paths for dynamic execution:")
    dynamic_compute_source_project = init_ras_project(dynamic_compute_folder, "6.5")
    print(dynamic_compute_source_project.plan_df)

if __name__ == "__main__":
    main()


==================================================

File: c:\GH\ras-commander\examples\18_2d_hdf_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 2D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the RasHdf and RasUtils classes to streamline data extraction, processing, and visualization."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, ras\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import init_ras_project, RasHdf, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj, ras\n","\n","print(\"ras_commander imported successfully\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the path to the Muncie project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","muncie_path = current_dir / \"example_projects\" / \"Muncie\"\n","bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n","import logging\n","# Check if Muncie.p03.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = muncie_path / \"Muncie.p03.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the Muncie project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"Muncie\", \"BaldEagleCrkMulti2D\"])\n","\n","    # Initialize custom Ras objects\n","    muncie = RasPrj()\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS projects using the custom ras objects\n","    muncie = init_ras_project(muncie_path, \"6.5\", ras_instance=muncie)\n","    logging.info(f\"Muncie project initialized with folder: {muncie.project_folder}\")\n","\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.5\", ras_instance=bald_eagle)\n","    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Muncie object id: {id(muncie)}\")\n","    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"03\"\n","\n","    # Set plan keys for both projects\n","    for project in [muncie, bald_eagle]:\n","        RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"Run UNet\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"Run PostProcess\", 1, ras_object=project)\n","        RasPlan.update_plan_value(plan_number, \"Run RASMapper\", 0, ras_object=project)\n","\n","    # Execute Plan 03 using RasCmdr for Muncie\n","    print(f\"Executing Plan {plan_number} for the Muncie project...\")\n","    success_muncie = RasCmdr.compute_plan(plan_number, ras_object=muncie)\n","    if success_muncie:\n","        print(f\"Plan {plan_number} executed successfully for Muncie.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Muncie.\\n\")\n","    \n","    # Execute Plan 03 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    #success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"Muncie.p03.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    muncie = RasPrj()\n","    bald_eagle = RasPrj()\n","    muncie = init_ras_project(muncie_path, \"6.5\", ras_instance=muncie)\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.5\", ras_instance=bald_eagle)\n","    plan_number = \"03\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve the HDF file path for Plan 03\n","results_path_muncie = RasPlan.get_results_path(plan_number, ras_object=muncie)\n","if results_path_muncie:\n","    print(f\"Results for Plan {plan_number} are located at: {results_path_muncie}\\n\")\n","else:\n","    print(f\"No results found for Plan {plan_number}.\\n\")\n","    \n","results_path_baldeagle = RasPlan.get_results_path(plan_number, ras_object=bald_eagle)\n","if results_path_baldeagle:\n","    print(f\"Results for Plan {plan_number} are located at: {results_path_baldeagle}\\n\")\n","else:\n","    print(f\"No results found for Plan {plan_number}.\\n\")    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the HDF input path as Plan Number\n","hdf_input = plan_number\n","\n","# Initialize RasHdf handler\n","hdf_handler = RasHdf()\n","\n","# The remainder of the examples only use muncie, so let's set results_path to muncie\n","results_path = results_path_muncie\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 1: List all HDF paths with properties\n","print(\"Example 1: Listing all HDF paths with properties\")\n","hdf_paths_df = RasHdf.get_hdf_paths_with_properties(hdf_input, ras_object=muncie)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 2: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = RasHdf.get_runtime_data(hdf_input, ras_object=muncie)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 3: Get 2D Flow Area Names\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = RasHdf.get_2d_flow_area_names(hdf_input, ras_object=muncie)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 4: Extract 2D Flow Area Attributes\n","print(\"\\nExample 4: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes_df = RasHdf.get_2d_flow_area_attributes(hdf_input, ras_object=muncie)\n","if flow_area_attributes_df is not None:\n","    display(flow_area_attributes_df.head())\n","else:\n","    print(\"No 2D Flow Area attributes found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 5: Extract Cell Info\n","print(\"\\nExample 5: Extracting Cell Info\")\n","cell_info_df = RasHdf.get_cell_info(hdf_input, ras_object=muncie)\n","if cell_info_df is not None:\n","    display(cell_info_df.head())\n","else:\n","    print(\"No Cell Info found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 6: Extract Cell Points\n","print(\"\\nExample 6: Extracting Cell Points\")\n","cell_points_df = RasHdf.get_cell_points(hdf_input, ras_object=muncie)\n","if cell_points_df is not None:\n","    display(cell_points_df.head())\n","else:\n","    print(\"No Cell Points found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 7: Extract Polygon Info and Parts\n","print(\"\\nExample 7: Extracting Polygon Info and Parts\")\n","polygon_info_df, polygon_parts_df = RasHdf.get_polygon_info_and_parts(hdf_input, ras_object=muncie)\n","print(\"Polygon Info:\")\n","if polygon_info_df is not None:\n","    display(polygon_info_df.head())\n","else:\n","    print(\"No Polygon Info found.\")\n","print(\"\\nPolygon Parts:\")\n","if polygon_parts_df is not None:\n","    display(polygon_parts_df.head())\n","else:\n","    print(\"No Polygon Parts found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 8: Extract Polygon Points\n","print(\"\\nExample 8: Extracting Polygon Points\")\n","polygon_points_df = RasHdf.get_polygon_points(hdf_input, ras_object=muncie)\n","if polygon_points_df is not None:\n","    display(polygon_points_df.head())\n","else:\n","    print(\"No Polygon Points found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 9: Extract Cells Center Coordinates and Manning's n\n","print(\"\\nExample 9: Extracting Cells Center Coordinates and Manning's n\")\n","cells_center_coord_df, cells_manning_n_df = RasHdf.get_cells_center_data(hdf_input, ras_object=muncie)\n","print(\"Cells Center Coordinates:\")\n","if cells_center_coord_df is not None:\n","    display(cells_center_coord_df.head())\n","else:\n","    print(\"No Cells Center Coordinates found.\")\n","print(\"\\nCells Manning's n:\")\n","if cells_manning_n_df is not None:\n","    display(cells_manning_n_df.head())\n","else:\n","    print(\"No Cells Manning's n found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 10: Extract Faces Area Elevation Data\n","print(\"\\nExample 10: Extracting Faces Area Elevation Data\")\n","faces_elev_df = RasHdf.get_faces_area_elevation_data(hdf_input, ras_object=muncie)\n","if faces_elev_df is not None:\n","    display(faces_elev_df.head())\n","else:\n","    print(\"No Faces Area Elevation Data found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 11: Extract Compute Messages as String\n","print(\"\\nExample 11: Extracting Compute Messages\")\n","compute_messages = RasHdf.extract_string_from_hdf(hdf_input, '/Results/Summary/Compute Messages (text)')\n","print(\"Compute Messages:\")\n","print(compute_messages)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 12: Extract Plan Parameters and Volume Accounting\n","print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n","import h5py\n","import numpy as np\n","\n","# Extract plan parameters\n","with h5py.File(str(results_path), 'r') as hdf_file:\n","    plan_parameters = hdf_file['Plan Data/Plan Parameters']\n","    \n","    # List group attributes\n","    print(\"Plan Parameters Group Attributes:\")\n","    #for attr_name, attr_value in plan_parameters.attrs.items():\n","        #print(f\"{attr_name}: {attr_value}\")\n","    \n","    # Extract plan parameters as a DataFrame\n","    plan_parameters_df = pd.DataFrame([(attr_name, attr_value) for attr_name, attr_value in plan_parameters.attrs.items()], columns=['Attribute', 'Value'])\n","\n","# Construct the group path for volume accounting data\n","group_to_list = \"Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D\"\n","\n","# Extract volume accounting data as a DataFrame\n","volume_accounting_df = RasHdf.get_group_attributes_as_df(results_path, group_to_list)\n","\n","print(\"\\nPlan Parameters DataFrame:\")\n","display(plan_parameters_df)\n","\n","print(\"\\nVolume Accounting DataFrame:\")\n","display(volume_accounting_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 13: Listing 2D Flow Area Groups\n","print(\"\\nExample: Listing 2D Flow Area Groups\")\n","\n","# Get the names of all 2D Flow Area groups\n","flow_area_group_names = RasHdf.get_2d_flow_area_names(hdf_input, ras_object=muncie)\n","\n","print(\"2D Flow Area Groups:\")\n","if flow_area_group_names:\n","    for name in flow_area_group_names:\n","        print(f\"- {name}\")\n","else:\n","    print(\"No 2D Flow Area groups found in the HDF file.\")\n","\n","import h5py\n","\n","# Additional information about the first group (if any)\n","if flow_area_group_names:\n","    first_group = flow_area_group_names[0]\n","    print(f\"\\nDetailed information for the first group: {first_group}\")\n","    \n","    # Remember, use results_path because we are accessing the hdf file and hdf_input is the plan number\n","    with h5py.File(str(results_path), 'r') as hdf_file:\n","        group = hdf_file[f'Geometry/2D Flow Areas/{first_group}']\n","        print(\"Datasets in this group:\")\n","        for name, item in group.items():\n","            if isinstance(item, h5py.Dataset):\n","                print(f\"- {name}: Shape {item.shape}, Dtype {item.dtype}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 14: Extract Faces Indexes\n","print(\"\\nExample 13: Extracting Faces Indexes\")\n","cell_indexes_df, facepoint_indexes_df = RasHdf.get_faces_indexes(hdf_input, ras_object=muncie)\n","print(\"Faces Cell Indexes:\")\n","if cell_indexes_df is not None:\n","    display(cell_indexes_df.head())\n","else:\n","    print(\"No Faces Cell Indexes found.\")\n","print(\"\\nFaces FacePoint Indexes:\")\n","if facepoint_indexes_df is not None:\n","    display(facepoint_indexes_df.head())\n","else:\n","    print(\"No Faces FacePoint Indexes found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 15: Extract Faces Elevation Data\n","print(\"\\nExample 14: Extracting Faces Elevation Data\")\n","low_elev_centroid_df, min_elevation_df = RasHdf.get_faces_elevation_data(hdf_input, ras_object=muncie)\n","print(\"Faces Low Elevation Centroid:\")\n","if low_elev_centroid_df is not None:\n","    display(low_elev_centroid_df.head())\n","else:\n","    print(\"No Faces Low Elevation Centroid found.\")\n","print(\"\\nFaces Minimum Elevation:\")\n","if min_elevation_df is not None:\n","    display(min_elevation_df.head())\n","else:\n","    print(\"No Faces Minimum Elevation found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 16: Extract Faces Vector Data\n","print(\"\\nExample 15: Extracting Faces Vector Data\")\n","faces_vector_df = RasHdf.get_faces_vector_data(hdf_input, ras_object=muncie)\n","if faces_vector_df is not None:\n","    display(faces_vector_df.head())\n","else:\n","    print(\"No Faces Vector Data found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 17: Extract Faces Perimeter Data\n","print(\"\\nExample 16: Extracting Faces Perimeter Data\")\n","perimeter_info_df, perimeter_values_df = RasHdf.get_faces_perimeter_data(hdf_input, ras_object=muncie)\n","print(\"Faces Perimeter Info:\")\n","if perimeter_info_df is not None:\n","    display(perimeter_info_df.head())\n","else:\n","    print(\"No Faces Perimeter Info found.\")\n","print(\"\\nFaces Perimeter Values:\")\n","if perimeter_values_df is not None:\n","    display(perimeter_values_df.head())\n","else:\n","    print(\"No Faces Perimeter Values found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 18: Extract Infiltration Data\n","print(\"\\nExample 17: Extracting Infiltration Data\")\n","cell_classifications_df, face_classifications_df, initial_deficit_df, maximum_deficit_df, potential_percolation_rate_df = RasHdf.get_infiltration_data(hdf_input, ras_object=muncie)\n","print(\"Infiltration - Cell Classifications:\")\n","if cell_classifications_df is not None:\n","    display(cell_classifications_df.head())\n","else:\n","    print(\"No Infiltration Cell Classifications found.\")\n","print(\"\\nInfiltration - Face Classifications:\")\n","if face_classifications_df is not None:\n","    display(face_classifications_df.head())\n","else:\n","    print(\"No Infiltration Face Classifications found.\")\n","print(\"\\nInfiltration - Initial Deficit:\")\n","if initial_deficit_df is not None:\n","    display(initial_deficit_df.head())\n","else:\n","    print(\"No Infiltration Initial Deficit found.\")\n","print(\"\\nInfiltration - Maximum Deficit:\")\n","if maximum_deficit_df is not None:\n","    display(maximum_deficit_df.head())\n","else:\n","    print(\"No Infiltration Maximum Deficit found.\")\n","print(\"\\nInfiltration - Potential Percolation Rate:\")\n","if potential_percolation_rate_df is not None:\n","    display(potential_percolation_rate_df.head())\n","else:\n","    print(\"No Infiltration Potential Percolation Rate found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 19: Extract Percent Impervious Data\n","print(\"\\nExample 18: Extracting Percent Impervious Data\")\n","cell_classifications_df, face_classifications_df, percent_impervious_df = RasHdf.get_percent_impervious_data(hdf_input, ras_object=muncie)\n","print(\"Percent Impervious - Cell Classifications:\")\n","if cell_classifications_df is not None:\n","    display(cell_classifications_df.head())\n","else:\n","    print(\"No Percent Impervious Cell Classifications found.\")\n","print(\"\\nPercent Impervious - Face Classifications:\")\n","if face_classifications_df is not None:\n","    display(face_classifications_df.head())\n","else:\n","    print(\"No Percent Impervious Face Classifications found.\")\n","print(\"\\nPercent Impervious:\")\n","if percent_impervious_df is not None:\n","    display(percent_impervious_df.head())\n","else:\n","    print(\"No Percent Impervious data found.\")\n","    \n","    # Note: Does not exist in the Muncie Plan 3 example used. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 20: Extract Perimeter Data\n","print(\"\\nExample 19: Extracting Perimeter Data\")\n","perimeter_df = RasHdf.get_perimeter_data(hdf_input, ras_object=muncie)\n","print(\"Perimeter Data:\")\n","if perimeter_df is not None:\n","    display(perimeter_df.head())\n","else:\n","    print(\"No Perimeter Data found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 21: Extract Boundary Condition Lines Attributes\n","print(\"\\nExample 20: Extracting Boundary Condition Lines Attributes\")\n","bc_lines_df = RasHdf.get_group_attributes_as_df(hdf_input, '/Geometry/Boundary Condition Lines/Attributes', ras_object=muncie)\n","if bc_lines_df is not None:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines Attributes found.\")\n","    \n","# None in Muncie plan 3, no output expected."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 22: Extract Boundary Condition Time Series Data\n","print(\"\\nExample 22: Extracting Boundary Condition Time Series Data\")\n","bc_time_series_df = RasHdf.get_group_attributes_as_df(hdf_input, '/Geometry/Boundary Condition Lines/Attributes', ras_object=muncie)\n","if bc_time_series_df is not None:\n","    display(bc_time_series_df.head())\n","else:\n","    print(\"No Boundary Condition Time Series Data found.\")\n","\n","print(\"\\nAll RasHdf functions have been executed on Plan 03 HDF file.\")\n","\n","\n","# NOTE: Muncie does not have boundary conditions in the HDF file - see how errors are handled. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 23: Retrieving 2D Flow Area Solution Times\n","print(\"Example 23: Retrieving 2D Flow Area Solution Times\")\n","\n","solution_times = RasHdf.get_2d_area_solution_times(hdf_input, ras_object=muncie)\n","\n","if solution_times is not None:\n","    print(f\"Retrieved {len(solution_times)} solution times:\")\n","    print(solution_times)\n","else:\n","    print(\"No solution times found.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 24: Retrieving 2D Flow Area Solution Time Dates\n","print(\"\\nExample 24: Retrieving 2D Flow Area Solution Time Dates\")\n","\n","solution_time_dates = RasHdf.get_2d_area_solution_time_dates(hdf_input, ras_object=muncie)\n","\n","if solution_time_dates is not None:\n","    print(f\"Retrieved {len(solution_time_dates)} solution time dates:\")\n","    print(solution_time_dates)\n","else:\n","    print(\"No solution time dates found.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 25: Loading 2D Flow Area Solutions\n","print(\"\\nExample 25: Loading 2D Flow Area Solutions\")\n","\n","# Load 2D area solutions using the revised method\n","solutions = RasHdf.load_2d_area_solutions(hdf_input, ras_object=muncie)\n","\n","# Check if solutions were successfully loaded\n","if solutions:\n","    # Access and display solution times\n","    solution_times_df = solutions.get('solution_times')\n","    if solution_times_df is not None:\n","        print(\"Solution Times:\")\n","        print(solution_times_df.head())\n","    else:\n","        print(\"Solution times not found.\")\n","    \n","    # Iterate through each 2D Flow Area and display sample data\n","    for key in solutions:\n","        if key != 'solution_times':\n","            print(f\"\\nData for {key}:\")\n","            area_df = solutions[key]\n","            print(area_df.head(10))  # Display first 10 records\n","else:\n","    print(\"No solutions loaded.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 29: Building Face FacePoints\n","print(\"\\nExample 29: Building Face FacePoints\")\n","\n","face_facepoints_list = RasHdf.build_face_facepoints(hdf_input, ras_object=muncie)\n","\n","if face_facepoints_list:\n","    # Displaying face points indexes for the first face of the first 2D Flow Area\n","    print(\"FacePoints Indexes for the first face of the first 2D Flow Area:\")\n","    print(face_facepoints_list[0][0])  # Assuming at least one area and one face\n","else:\n","    print(\"No face facepoints built.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\xx_edge_cases.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

example_projects_folder = Path(__file__).parent.parent / "example_projects"

# delete the folder if it exists
if example_projects_folder.exists():
    shutil.rmtree(example_projects_folder)


# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main():
    # Initialize the project
    current_dir = Path(__file__).parent
    project_path = current_dir / "example_projects" / "Balde Eagle Creek"
    init_ras_project(project_path, "6.5")

    print("Available plans:")
    print(ras.plan_df)
    print()

    # Example 1: Execute a single plan using compute_test_mode
    print("Example 1: Executing a single plan using compute_test_mode")
    single_plan = "01"
    dest_folder_suffix = "[SinglePlanTest]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number=single_plan,
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print(f"Execution of plan {single_plan} completed using compute_test_mode")
    print()

    # Example 2: Execute a single plan using compute_parallel
    print("Example 2: Executing a single plan using compute_parallel")
    parallel_result_folder = project_path.parent / "parallel_single_plan_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number=single_plan,
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 3: Execute a single plan using compute_test_mode with a string input
    print("Example 3: Executing a single plan using compute_test_mode with a string input")
    dest_folder_suffix = "[SinglePlanTestString]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    # Delete the compute folder if it exists
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    RasCmdr.compute_test_mode(
        plan_number="02",
        dest_folder_suffix=dest_folder_suffix,
        clear_geompre=False,
        num_cores=2
    )
    print("Execution of plan 02 completed using compute_test_mode with string input")
    print()

    # Example 4: Execute a single plan using compute_parallel with a string input
    print("Example 4: Executing a single plan using compute_parallel with a string input")
    parallel_result_folder = project_path.parent / "parallel_single_plan_string_result"
    if parallel_result_folder.exists():
        shutil.rmtree(parallel_result_folder)
        print(f"Deleted existing result folder: {parallel_result_folder}")

    results = RasCmdr.compute_parallel(
        plan_number="01",  # Changed from "03" to "01"
        max_workers=1,
        num_cores=2,
        dest_folder=parallel_result_folder
    )
    print("Parallel execution of single plan (string input) results:")
    for plan_number, success in results.items():
        print(f"Plan {plan_number}: {'Successful' if success else 'Failed'}")
    print()

    # Example 5: Attempt to execute with an empty plan list
    print("Example 5: Attempting to execute with an empty plan list")
    dest_folder_suffix = "[EmptyPlanList]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=[], dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

    # Example 6: Attempt to execute with a non-existent plan number
    print("Example 6: Attempting to execute with a non-existent plan number")
    non_existent_plan = "99"
    dest_folder_suffix = "[NonExistentPlan]"
    compute_folder = project_path.parent / f"{project_path.name} {dest_folder_suffix}"
    
    if compute_folder.exists():
        shutil.rmtree(compute_folder)
        print(f"Deleted existing compute folder: {compute_folder}")

    try:
        RasCmdr.compute_test_mode(plan_number=non_existent_plan, dest_folder_suffix=dest_folder_suffix)
    except ValueError as e:
        print(f"Error caught: {e}")
    print()

if __name__ == "__main__":
    main()
==================================================

File: c:\GH\ras-commander\ras_commander\RasCmdr.py
==================================================
"""
Execution operations for running HEC-RAS simulations using subprocess.
Based on the HEC-Commander project's "Command Line is All You Need" approach, leveraging the -c compute flag to run HEC-RAS and orchestrating changes directly in the RAS input files to achieve automation outcomes. 
"""

import os
import subprocess
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from .RasPrj import ras, RasPrj, init_ras_project, get_ras_exe
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUtils import RasUtils
import logging
import time
import queue
from threading import Thread, Lock
from typing import Union, List, Optional, Dict
from pathlib import Path
import shutil
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Thread
from itertools import cycle
from ras_commander.RasPrj import RasPrj  # Ensure RasPrj is imported
from threading import Lock, Thread, current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import cycle
from typing import Union, List, Optional, Dict


# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# TO DO: 
# 1. Alternate Run Mode for compute_plan and compute_parallel:  Using Powershell to execute the HEC-RAS command and hide the RAS window and all child windows.
#    If this is implemented, and the plan has a popup, then the plan will not execute.  This is a deal breaker for many scenarios, and should only be used
#    as a special option for those who don't want to deal with the popups, or want to run in the background.  This option should be limited to non-commercial use.
# 2. Implment compute_plan_remote to go along with compute_plan.  This will be a compute_plan that is run on a remote machine via a psexec command.
#    First, we will use the keyring package to securely store the remote machine username and password.
#    Second, we will implement the psexec command to execute the HEC-RAS command on the remote machine.
#    Each machine will need to be initialized as a remote_worker object, which will store the machine name, username, password, ras_exe_path, local folder path and other relevant info.
#    A separate RasRemote class will be created to handle the creation of the remote_worker objects and the necessary abstractions. 
#    The compute_plan_remote function will live in RasCmdr, and will be a thin abstraction above the RasRemote class, since the functions will be simliar to the existing compute_plan functions, but specific to remote execution.  


class RasCmdr:
    @staticmethod
    def compute_plan(
        plan_number,
        dest_folder=None, 
        ras_object=None,
        clear_geompre=False,
        num_cores=None,
        overwrite_dest=False
    ):
        """
        Execute a HEC-RAS plan.

        Args:
            plan_number (str, Path): The plan number to execute (e.g., "01", "02") or the full path to the plan file.
            dest_folder (str, Path, optional): Name of the folder or full path for computation.
                If a string is provided, it will be created in the same parent directory as the project folder.
                If a full path is provided, it will be used as is.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files. Defaults to False.
            num_cores (int, optional): Number of cores to use for the plan execution. If None, the current setting is not changed.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            bool: True if the execution was successful, False otherwise.

        Raises:
            ValueError: If the specified dest_folder already exists and is not empty, and overwrite_dest is False.
        """
        ras_obj = ras_object if ras_object is not None else ras
        logging.info(f"Using ras_object with project folder: {ras_obj.project_folder}")
        ras_obj.check_initialized()
        
        if dest_folder is not None:
            dest_folder = Path(ras_obj.project_folder).parent / dest_folder if isinstance(dest_folder, str) else Path(dest_folder)
            
            if dest_folder.exists():
                if overwrite_dest:
                    shutil.rmtree(dest_folder)
                    logging.info(f"Destination folder '{dest_folder}' exists. Overwriting as per overwrite_dest=True.")
                elif any(dest_folder.iterdir()):
                    error_msg = f"Destination folder '{dest_folder}' exists and is not empty. Use overwrite_dest=True to overwrite."
                    logging.error(error_msg)
                    raise ValueError(error_msg)
            
            dest_folder.mkdir(parents=True, exist_ok=True)
            shutil.copytree(ras_obj.project_folder, dest_folder, dirs_exist_ok=True)
            logging.info(f"Copied project folder to destination: {dest_folder}")
            
            compute_ras = RasPrj()
            compute_ras.initialize(dest_folder, ras_obj.ras_exe_path)
            compute_prj_path = compute_ras.prj_file
        else:
            compute_ras = ras_obj
            compute_prj_path = ras_obj.prj_file

        # Determine the plan path
        compute_plan_path = Path(plan_number) if isinstance(plan_number, (str, Path)) and Path(plan_number).is_file() else RasPlan.get_plan_path(plan_number, compute_ras)

        if not compute_prj_path or not compute_plan_path:
            logging.error(f"Could not find project file or plan file for plan {plan_number}")
            return False

        # Clear geometry preprocessor files if requested
        if clear_geompre:
            try:
                RasGeo.clear_geompre_files(compute_plan_path, ras_object=compute_ras)
                logging.info(f"Cleared geometry preprocessor files for plan: {plan_number}")
            except Exception as e:
                logging.error(f"Error clearing geometry preprocessor files for plan {plan_number}: {str(e)}")

        # Set the number of cores if specified
        if num_cores is not None:
            try:
                RasPlan.set_num_cores(compute_plan_path, num_cores=num_cores, ras_object=compute_ras)
                logging.info(f"Set number of cores to {num_cores} for plan: {plan_number}")
            except Exception as e:
                logging.error(f"Error setting number of cores for plan {plan_number}: {str(e)}")

        # Prepare the command for HEC-RAS execution
        cmd = f'"{compute_ras.ras_exe_path}" -c "{compute_prj_path}" "{compute_plan_path}"'
        logging.info("Running HEC-RAS from the Command Line:")
        logging.info(f"Running command: {cmd}")

        # Execute the HEC-RAS command
        start_time = time.time()
        try:
            subprocess.run(cmd, check=True, shell=True, capture_output=True, text=True)
            end_time = time.time()
            run_time = end_time - start_time
            logging.info(f"HEC-RAS execution completed for plan: {plan_number}")
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
            return True
        except subprocess.CalledProcessError as e:
            end_time = time.time()
            run_time = end_time - start_time
            logging.error(f"Error running plan: {plan_number}")
            logging.error(f"Error message: {e.output}")
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
            return False
        finally:
            # Update the RAS object's dataframes
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    


    @staticmethod
    def compute_parallel(
        plan_number: Union[str, List[str], None] = None,
        max_workers: int = 2,
        num_cores: int = 2,
        clear_geompre: bool = False,
        ras_object: Optional['RasPrj'] = None,  # Type hinting as string to avoid NameError
        dest_folder: Union[str, Path, None] = None,
        overwrite_dest: bool = False
    ) -> Dict[str, bool]:
        """
        [Docstring remains unchanged]
        """
        ras_obj = ras_object or ras  # Assuming 'ras' is a global RasPrj instance
        ras_obj.check_initialized()

        project_folder = Path(ras_obj.project_folder)

        if dest_folder is not None:
            dest_folder_path = Path(dest_folder)
            if dest_folder_path.exists():
                if overwrite_dest:
                    shutil.rmtree(dest_folder_path)
                    logging.info(f"Destination folder '{dest_folder_path}' exists. Overwriting as per overwrite_dest=True.")
                elif any(dest_folder_path.iterdir()):
                    error_msg = f"Destination folder '{dest_folder_path}' exists and is not empty. Use overwrite_dest=True to overwrite."
                    logging.error(error_msg)
                    raise ValueError(error_msg)
            dest_folder_path.mkdir(parents=True, exist_ok=True)
            shutil.copytree(project_folder, dest_folder_path, dirs_exist_ok=True)
            logging.info(f"Copied project folder to destination: {dest_folder_path}")
            project_folder = dest_folder_path

        if plan_number:
            if isinstance(plan_number, str):
                plan_number = [plan_number]
            ras_obj.plan_df = ras_obj.plan_df[ras_obj.plan_df['plan_number'].isin(plan_number)]
            logging.info(f"Filtered plans to execute: {plan_number}")

        num_plans = len(ras_obj.plan_df)
        max_workers = min(max_workers, num_plans) if num_plans > 0 else 1
        logging.info(f"Adjusted max_workers to {max_workers} based on the number of plans: {num_plans}")

        # Clean up existing worker folders and create new ones
        worker_ras_objects = {}
        for worker_id in range(1, max_workers + 1):
            worker_folder = project_folder.parent / f"{project_folder.name} [Worker {worker_id}]"
            if worker_folder.exists():
                shutil.rmtree(worker_folder)
                logging.info(f"Removed existing worker folder: {worker_folder}")
            shutil.copytree(project_folder, worker_folder)
            logging.info(f"Created worker folder: {worker_folder}")

            # Instantiate RasPrj properly
            ras_instance = RasPrj()  # Add necessary parameters if required
            worker_ras_instance = init_ras_project(
                ras_project_folder=worker_folder,
                ras_version=ras_obj.ras_exe_path,
                ras_instance=ras_instance  # Pass the instance instead of a string
            )
            worker_ras_objects[worker_id] = worker_ras_instance

        # Distribute plans among workers in a round-robin fashion
        worker_cycle = cycle(range(1, max_workers + 1))
        plan_assignments = [(next(worker_cycle), plan_num) for plan_num in ras_obj.plan_df['plan_number']]

        # Initialize ThreadPoolExecutor without tracking individual plan success
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit all plan executions to the executor
            futures = [
                executor.submit(
                    RasCmdr.compute_plan,
                    plan_num, 
                    ras_object=worker_ras_objects[worker_id], 
                    clear_geompre=clear_geompre,
                    num_cores=num_cores
                )
                for worker_id, plan_num in plan_assignments
            ]

            # Optionally, you can log when each plan starts and completes
            for future, (worker_id, plan_num) in zip(as_completed(futures), plan_assignments):
                try:
                    future.result()  # We don't need the success flag here
                    logging.info(f"Plan {plan_num} executed in worker {worker_id}")
                except Exception as e:
                    logging.error(f"Plan {plan_num} failed in worker {worker_id}: {str(e)}")
                    # Depending on requirements, you might want to handle retries or mark these plans differently

        # Consolidate results
        final_dest_folder = dest_folder_path if dest_folder is not None else project_folder.parent / f"{project_folder.name} [Computed]"
        final_dest_folder.mkdir(parents=True, exist_ok=True)
        logging.info(f"Final destination for computed results: {final_dest_folder}")

        for worker_ras in worker_ras_objects.values():
            worker_folder = Path(worker_ras.project_folder)
            try:
                for item in worker_folder.iterdir():
                    dest_path = final_dest_folder / item.name
                    if dest_path.exists():
                        if dest_path.is_dir():
                            shutil.rmtree(dest_path)
                            logging.debug(f"Removed existing directory at {dest_path}")
                        else:
                            dest_path.unlink()
                            logging.debug(f"Removed existing file at {dest_path}")
                    shutil.move(str(item), final_dest_folder)
                    logging.debug(f"Moved {item} to {final_dest_folder}")
                shutil.rmtree(worker_folder)
                logging.info(f"Removed worker folder: {worker_folder}")
            except Exception as e:
                logging.error(f"Error moving results from {worker_folder} to {final_dest_folder}: {str(e)}")

        # Initialize a new RasPrj object for the final destination
        try:
            # Create a new RasPrj instance
            final_dest_folder_ras_obj = RasPrj()
            
            # Initialize it using init_ras_project
            final_dest_folder_ras_obj = init_ras_project(
                ras_project_folder=final_dest_folder, 
                ras_version=ras_obj.ras_exe_path,
                ras_instance=final_dest_folder_ras_obj
            )
            
            # Now we can check if it's initialized
            final_dest_folder_ras_obj.check_initialized()
        except Exception as e:
            logging.error(f"Failed to initialize RasPrj for final destination: {str(e)}")
            raise

        # Retrieve plan entries and check for HDF results
        try:
            plan_entries = final_dest_folder_ras_obj.get_prj_entries('Plan')
        except Exception as e:
            logging.error(f"Failed to retrieve plan entries from final RasPrj: {str(e)}")
            raise

        execution_results: Dict[str, bool] = {}
        for _, row in ras_obj.plan_df.iterrows():
            plan_num = row['plan_number']
            # Find the corresponding entry in plan_entries
            entry = plan_entries[plan_entries['plan_number'] == plan_num]
            if not entry.empty:
                hdf_path = entry.iloc[0].get('HDF_Results_Path')
                success = hdf_path is not None and Path(hdf_path).exists()
            else:
                success = False
            execution_results[plan_num] = success

        # Print execution results for each plan
        logging.info("\nExecution Results:")
        for plan_num, success in execution_results.items():
            status = 'Successful' if success else 'Failed'
            logging.info(f"Plan {plan_num}: {status} \n(HDF_Results_Path: {hdf_path})")
            
        ras_obj = ras_object or ras
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return execution_results
    

    @staticmethod
    def compute_test_mode(
        plan_number=None, 
        dest_folder_suffix="[Test]", 
        clear_geompre=False, 
        num_cores=None, 
        ras_object=None,
        overwrite_dest=False
    ):
        """
        Execute HEC-RAS plans in test mode.  This is a re-creation of the HEC-RAS command line -test flag, 
        which does not work in recent versions of HEC-RAS.
        
        As a special-purpose function that emulates the original -test flag, it operates differently than the 
        other two compute_ functions.  Per the original HEC-RAS test flag, it creates a separate test folder,
        copies the project there, and executes the specified plans in sequential order.
        
        For most purposes, just copying a the project folder, initing that new folder, then running each plan 
        with compute_plan is a simpler and more flexible approach.  This is shown in the examples provided
        in the ras-commander library.

        Args:
            plan_number (str, list[str], optional): Plan number or list of plan numbers to execute. 
                If None, all plans will be executed. Default is None.
            dest_folder_suffix (str, optional): Suffix to append to the test folder name to create dest_folder. 
                Defaults to "[Test]".
                dest_folder is always created in the project folder's parent directory.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files.
                Defaults to False.
            num_cores (int, optional): Maximum number of cores to use for each plan.
                If None, the current setting is not changed. Default is None.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            None

        Example:
            Run all plans: RasCommander.compute_test_mode()
            Run a specific plan: RasCommander.compute_test_mode(plan_number="01")
            Run multiple plans: RasCommander.compute_test_mode(plan_number=["01", "03", "05"])
            Run plans with a custom folder suffix: RasCommander.compute_test_mode(dest_folder_suffix="[TestRun]")
            Run plans and clear geometry preprocessor files: RasCommander.compute_test_mode(clear_geompre=True)
            Run plans with a specific number of cores: RasCommander.compute_test_mode(num_cores=4)
            
        Notes:
            - This function executes plans in a separate folder for isolated testing.
            - If plan_number is not provided, all plans in the project will be executed.
            - The function does not change the geometry preprocessor and IB tables settings.  
                - To force recomputing of geometry preprocessor and IB tables, use the clear_geompre=True option.
            - Plans are executed sequentially.
            - Because copying the project is implicit, only a dest_folder_suffix option is provided.
            - For more flexible run management, use the compute_parallel or compute_sequential functions.
        """
        
        # This line of code is used to initialize the RasPrj object with the default "ras" object if no specific object is provided.
        ras_obj = ras_object or ras
        # This line of code is used to check if the RasPrj object is initialized.
        ras_obj.check_initialized()
        
        logging.info("Starting the compute_test_mode...")
           
        # Use the project folder from the ras object
        project_folder = ras_obj.project_folder

        # Check if the project folder exists
        if not project_folder.exists():
            logging.error(f"Project folder '{project_folder}' does not exist.")
            return

        # Create test folder with the specified suffix in the same directory as the project folder
        compute_folder = project_folder.parent / f"{project_folder.name} {dest_folder_suffix}"
        logging.info(f"Creating the test folder: {compute_folder}...")

        # Check if the compute folder exists and is empty
        if compute_folder.exists():
            if overwrite_dest:
                shutil.rmtree(compute_folder)
                logging.info(f"Compute folder '{compute_folder}' exists. Overwriting as per overwrite_dest=True.")
            elif any(compute_folder.iterdir()):
                error_msg = (
                    f"Compute folder '{compute_folder}' exists and is not empty. "
                    "Use overwrite_dest=True to overwrite."
                )
                logging.error(error_msg)
                raise ValueError(error_msg)
        else:
            try:
                shutil.copytree(project_folder, compute_folder)
                logging.info(f"Copied project folder to compute folder: {compute_folder}")
            except FileNotFoundError:
                logging.error(f"Unable to copy project folder. Source folder '{project_folder}' not found.")
                return
            except PermissionError:
                logging.error(f"Permission denied when trying to create or copy to '{compute_folder}'.")
                return
            except Exception as e:
                logging.error(f"Error occurred while copying project folder: {str(e)}")
                return

        # Initialize a new RAS project in the compute folder
        try:
            compute_ras = RasPrj()
            compute_ras.initialize(compute_folder, ras_obj.ras_exe_path)
            compute_prj_path = compute_ras.prj_file
            logging.info(f"Initialized RAS project in compute folder: {compute_prj_path}")
        except Exception as e:
            logging.error(f"Error initializing RAS project in compute folder: {str(e)}")
            return

        if not compute_prj_path:
            logging.error("Project file not found.")
            return

        # Get plan entries
        logging.info("Getting plan entries...")
        try:
            ras_compute_plan_entries = compute_ras.plan_df
            logging.info("Retrieved plan entries successfully.")
        except Exception as e:
            logging.error(f"Error retrieving plan entries: {str(e)}")
            return

        if plan_number:
            if isinstance(plan_number, str):
                plan_number = [plan_number]
            ras_compute_plan_entries = ras_compute_plan_entries[
                ras_compute_plan_entries['plan_number'].isin(plan_number)
            ]
            logging.info(f"Filtered plans to execute: {plan_number}")

        logging.info("Running selected plans sequentially...")
        for _, plan in ras_compute_plan_entries.iterrows():
            plan_number = plan["plan_number"]
            start_time = time.time()
            try:
                success = RasCmdr.compute_plan(
                    plan_number,
                    ras_object=compute_ras,
                    clear_geompre=clear_geompre,
                    num_cores=num_cores
                )
                if success:
                    logging.info(f"Successfully computed plan {plan_number}")
                else:
                    logging.error(f"Failed to compute plan {plan_number}")
            except Exception as e:
                logging.error(f"Error computing plan {plan_number}: {str(e)}")
            end_time = time.time()
            run_time = end_time - start_time
            logging.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")

        logging.info("All selected plans have been executed.")
        logging.info("compute_test_mode completed.")

        ras_obj = ras_object or ras
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    
==================================================

File: c:\GH\ras-commander\ras_commander\RasExamples.py
==================================================
import os
import requests
import zipfile
import pandas as pd
from pathlib import Path
import shutil
from typing import Union, List
import csv
from datetime import datetime
import logging
import re
from tqdm import tqdm

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

class RasExamples:
    """
    A class for quickly loading HEC-RAS example projects for testing and development of ras-commander.

    This class provides functionality to download, extract, and manage HEC-RAS example projects.
    It supports both default HEC-RAS example projects and custom projects from user-provided URLs.
    Additionally, it includes functionality to download FEMA's Base Level Engineering (BLE) models
    from CSV files provided by the FEMA Estimated Base Flood Elevation (BFE) Viewer.

    [Documentation as previously provided]
    """

    def __init__(self):
        """
        Initialize the RasExamples class.
        """
        self.base_url = 'https://github.com/HydrologicEngineeringCenter/hec-downloads/releases/download/'
        self.valid_versions = [
            "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
            "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
            "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
        ]
        self.base_dir = Path.cwd()
        self.examples_dir = self.base_dir
        self.projects_dir = self.examples_dir / 'example_projects'
        self.zip_file_path = None
        self.folder_df = None
        self.csv_file_path = self.examples_dir / 'example_projects.csv'

        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logging.info(f"Example projects folder: {self.projects_dir}")
        self._load_project_data()

    def _load_project_data(self):
        """
        Load project data from CSV if up-to-date, otherwise extract from zip.
        """
        self._find_zip_file()
        
        if not self.zip_file_path:
            logging.info("No example projects zip file found. Downloading...")
            self.get_example_projects()
        
        try:
            zip_modified_time = os.path.getmtime(self.zip_file_path)
        except FileNotFoundError:
            logging.error(f"Zip file not found at {self.zip_file_path}.")
            return
        
        if self.csv_file_path.exists():
            csv_modified_time = os.path.getmtime(self.csv_file_path)
            
            if csv_modified_time >= zip_modified_time:
                logging.info("Loading project data from CSV...")
                try:
                    self.folder_df = pd.read_csv(self.csv_file_path)
                    logging.info(f"Loaded {len(self.folder_df)} projects from CSV. Use list_categories() and list_projects() to explore them.")
                except Exception as e:
                    logging.error(f"Failed to read CSV file: {e}")
                    self.folder_df = None
                return

        logging.info("Extracting folder structure from zip file...")
        self._extract_folder_structure()
        self._save_to_csv()

    def _find_zip_file(self):
        """Locate the example projects zip file in the examples directory."""
        for version in self.valid_versions:
            potential_zip = self.examples_dir / f"Example_Projects_{version.replace('.', '_')}.zip"
            if potential_zip.exists():
                self.zip_file_path = potential_zip
                logging.info(f"Found zip file: {self.zip_file_path}")
                break
        else:
            logging.warning("No existing example projects zip file found.")

    def _extract_folder_structure(self):
        """
        Extract folder structure from the zip file.

        Populates folder_df with category and project information.
        """
        folder_data = []
        try:
            with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                for file in zip_ref.namelist():
                    parts = Path(file).parts
                    if len(parts) > 2:
                        folder_data.append({
                            'Category': parts[1],
                            'Project': parts[2]
                        })
        
            self.folder_df = pd.DataFrame(folder_data).drop_duplicates()
            logging.info(f"Extracted {len(self.folder_df)} projects.")
            logging.debug(f"folder_df:\n{self.folder_df}")
        except zipfile.BadZipFile:
            logging.error(f"The file {self.zip_file_path} is not a valid zip file.")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])
        except Exception as e:
            logging.error(f"An error occurred while extracting the folder structure: {str(e)}")
            self.folder_df = pd.DataFrame(columns=['Category', 'Project'])

    def _save_to_csv(self):
        """Save the extracted folder structure to CSV file."""
        if self.folder_df is not None and not self.folder_df.empty:
            try:
                self.folder_df.to_csv(self.csv_file_path, index=False)
                logging.info(f"Saved project data to {self.csv_file_path}")
            except Exception as e:
                logging.error(f"Failed to save project data to CSV: {e}")
        else:
            logging.warning("No folder data to save to CSV.")

    def get_example_projects(self, version_number='6.5'):
        """
        Download and extract HEC-RAS example projects for a specified version.
        """
        logging.info(f"Getting example projects for version {version_number}")
        if version_number not in self.valid_versions:
            error_msg = f"Invalid version number. Valid versions are: {', '.join(self.valid_versions)}"
            logging.error(error_msg)
            raise ValueError(error_msg)

        zip_url = f"{self.base_url}1.0.31/Example_Projects_{version_number.replace('.', '_')}.zip"
        
        self.examples_dir.mkdir(parents=True, exist_ok=True)
        
        self.zip_file_path = self.examples_dir / f"Example_Projects_{version_number.replace('.', '_')}.zip"

        if not self.zip_file_path.exists():
            logging.info(f"Downloading HEC-RAS Example Projects from {zip_url}. \nThe file is over 400 MB, so it may take a few minutes to download....")
            try:
                response = requests.get(zip_url, stream=True)
                response.raise_for_status()
                with open(self.zip_file_path, 'wb') as file:
                    shutil.copyfileobj(response.raw, file)
                logging.info(f"Downloaded to {self.zip_file_path}")
            except requests.exceptions.RequestException as e:
                logging.error(f"Failed to download the zip file: {e}")
                raise
        else:
            logging.info("HEC-RAS Example Projects zip file already exists. Skipping download.")

        self._load_project_data()
        return self.projects_dir

    def list_categories(self):
        """
        List all categories of example projects.
        """
        if self.folder_df is None or 'Category' not in self.folder_df.columns:
            logging.warning("No categories available. Make sure the zip file is properly loaded.")
            return []
        categories = self.folder_df['Category'].unique()
        logging.info(f"Available categories: {', '.join(categories)}")
        return categories.tolist()

    def list_projects(self, category=None):
        """
        List all projects or projects in a specific category.
        """
        if self.folder_df is None:
            logging.warning("No projects available. Make sure the zip file is properly loaded.")
            return []
        if category:
            projects = self.folder_df[self.folder_df['Category'] == category]['Project'].unique()
            logging.info(f"Projects in category '{category}': {', '.join(projects)}")
        else:
            projects = self.folder_df['Project'].unique()
            logging.info(f"All available projects: {', '.join(projects)}")
        return projects.tolist()

    def extract_project(self, project_names: Union[str, List[str]]):
        """
        Extract one or more specific HEC-RAS projects from the zip file.
        """
        if isinstance(project_names, str):
            project_names = [project_names]

        extracted_paths = []

        for project_name in project_names:
            logging.info("----- RasExamples Extracting Project -----")
            logging.info(f"Extracting project '{project_name}'")
            project_path = self.projects_dir / project_name

            if project_path.exists():
                logging.info(f"Project '{project_name}' already exists. Deleting existing folder...")
                try:
                    shutil.rmtree(project_path)
                    logging.info(f"Existing folder for project '{project_name}' has been deleted.")
                except Exception as e:
                    logging.error(f"Failed to delete existing project folder '{project_name}': {e}")
                    continue

            if self.folder_df is None or self.folder_df.empty:
                error_msg = "No project information available. Make sure the zip file is properly loaded."
                logging.error(error_msg)
                raise ValueError(error_msg)

            project_info = self.folder_df[self.folder_df['Project'] == project_name]
            if project_info.empty:
                error_msg = f"Project '{project_name}' not found in the zip file."
                logging.error(error_msg)
                raise ValueError(error_msg)

            category = project_info['Category'].iloc[0]
            
            # Ensure the project directory exists
            project_path.mkdir(parents=True, exist_ok=True)

            try:
                with zipfile.ZipFile(self.zip_file_path, 'r') as zip_ref:
                    for file in zip_ref.namelist():
                        parts = Path(file).parts
                        if len(parts) > 2 and parts[2] == project_name:
                            # Remove the first two levels (category and project name)
                            relative_path = Path(*parts[3:])
                            extract_path = project_path / relative_path
                            if file.endswith('/'):
                                extract_path.mkdir(parents=True, exist_ok=True)
                            else:
                                extract_path.parent.mkdir(parents=True, exist_ok=True)
                                with zip_ref.open(file) as source, open(extract_path, "wb") as target:
                                    shutil.copyfileobj(source, target)

                logging.info(f"Successfully extracted project '{project_name}' to {project_path}")
                extracted_paths.append(project_path)
            except zipfile.BadZipFile:
                logging.error(f"Error: The file {self.zip_file_path} is not a valid zip file.")
            except FileNotFoundError:
                logging.error(f"Error: The file {self.zip_file_path} was not found.")
            except Exception as e:
                logging.error(f"An unexpected error occurred while extracting the project: {str(e)}")
            logging.info("----- RasExamples Extraction Complete -----")
        return extracted_paths

    def is_project_extracted(self, project_name):
        """
        Check if a specific project is already extracted.
        """
        project_path = self.projects_dir / project_name
        is_extracted = project_path.exists()
        logging.info(f"Project '{project_name}' extracted: {is_extracted}")
        return is_extracted

    def clean_projects_directory(self):
        """Remove all extracted projects from the example_projects directory."""
        logging.info(f"Cleaning projects directory: {self.projects_dir}")
        if self.projects_dir.exists():
            try:
                shutil.rmtree(self.projects_dir)
                logging.info("All projects have been removed.")
            except Exception as e:
                logging.error(f"Failed to remove projects directory: {e}")
        else:
            logging.warning("Projects directory does not exist.")
        self.projects_dir.mkdir(parents=True, exist_ok=True)
        logging.info("Projects directory cleaned and recreated.")
        
    def download_fema_ble_model(self, csv_file: Union[str, Path], output_base_dir: Union[str, Path] = None):
        """
        Download a single FEMA Base Level Engineering (BLE) model from a CSV file and organize it into folders.

        This function performs the following steps:
        1. Reads the specified CSV file to get the download URLs.
        2. Creates a folder for the region (e.g., `LowerPearl`, `BogueChitto`, etc.).
        3. Downloads the zip files to the same folder as the CSV.
        4. Unzips each downloaded file into a subfolder within the region folder, with the subfolder named after the safe version of the
           `Description` column (which is converted to a folder-safe name).
        5. Leaves the zip files in place in the CSV folder.
        6. Does not download files again if they already exist in the CSV folder.

        **Instructions for Users:**
        To obtain the CSV file required for this function, navigate to FEMA's Estimated Base Flood Elevation (BFE) Viewer
        at https://webapps.usgs.gov/infrm/estBFE/. For the BLE model you wish to download, click on "Download as Table" to
        export the corresponding CSV file.

        Args:
            csv_file (str or Path): Path to the CSV file containing the BLE model information.
            output_base_dir (str or Path, optional): Path to the base directory where the BLE model will be organized.
                                                     Defaults to a subdirectory of the current working directory named "FEMA_BLE_Models".

        Raises:
            FileNotFoundError: If the specified CSV file does not exist.
            Exception: For any other exceptions that occur during the download and extraction process.
        """
        csv_file = Path(csv_file)
        if output_base_dir is None:
            output_base_dir = Path.cwd() / "FEMA_BLE_Models"
        else:
            output_base_dir = Path(output_base_dir)

        if not csv_file.exists() or not csv_file.is_file():
            logging.error(f"The specified CSV file does not exist: {csv_file}")
            raise FileNotFoundError(f"The specified CSV file does not exist: {csv_file}")

        output_base_dir.mkdir(parents=True, exist_ok=True)
        logging.info(f"BLE model will be organized in: {output_base_dir}")

        try:
            # Extract region name from the filename (assuming format <AnyCharacters>_<Region>_DownloadIndex.csv)
            match = re.match(r'.+?_(.+?)_DownloadIndex\.csv', csv_file.name)
            if not match:
                logging.warning(f"Filename does not match expected pattern and will be skipped: {csv_file.name}")
                return
            region = match.group(1)
            logging.info(f"Processing region: {region}")

            # Create folder for this region
            region_folder = output_base_dir / region
            region_folder.mkdir(parents=True, exist_ok=True)
            logging.info(f"Created/verified region folder: {region_folder}")

            # Read the CSV file
            try:
                df = pd.read_csv(csv_file, comment='#')
            except pd.errors.ParserError as e:
                logging.error(f"Error parsing CSV file {csv_file.name}: {e}")
                return

            # Verify required columns exist
            required_columns = {'URL', 'FileName', 'FileSize', 'Description', 'Details'}
            if not required_columns.issubset(df.columns):
                logging.warning(f"CSV file {csv_file.name} is missing required columns and will be skipped.")
                return

            # Process each row in the CSV
            for index, row in tqdm(df.iterrows(), total=len(df), desc="Downloading files", unit="file"):
                description = row['Description']
                download_url = row['URL']
                file_name = row['FileName']
                file_size_str = row['FileSize']

                # Convert file size to bytes
                try:
                    file_size = self._convert_size_to_bytes(file_size_str)
                except ValueError as e:
                    logging.error(f"Error converting file size '{file_size_str}' to bytes: {e}")
                    continue

                # Create a subfolder based on the safe description name
                safe_description = self._make_safe_folder_name(description)
                description_folder = region_folder / safe_description

                # Download the file to the CSV folder if it does not already exist
                csv_folder = csv_file.parent
                downloaded_file = csv_folder / file_name
                if not downloaded_file.exists():
                    try:
                        logging.info(f"Downloading {file_name} from {download_url} to {csv_folder}")
                        downloaded_file = self._download_file_with_progress(download_url, csv_folder, file_size)
                        logging.info(f"Downloaded file to: {downloaded_file}")
                    except Exception as e:
                        logging.error(f"Failed to download {download_url}: {e}")
                        continue
                else:
                    logging.info(f"File {file_name} already exists in {csv_folder}, skipping download.")

                # If it's a zip file, unzip it to the description folder
                if downloaded_file.suffix == '.zip':
                    # If the folder exists, delete it
                    if description_folder.exists():
                        logging.info(f"Folder {description_folder} already exists. Deleting it.")
                        shutil.rmtree(description_folder)

                    description_folder.mkdir(parents=True, exist_ok=True)
                    logging.info(f"Created/verified description folder: {description_folder}")

                    logging.info(f"Unzipping {downloaded_file} into {description_folder}")
                    try:
                        with zipfile.ZipFile(downloaded_file, 'r') as zip_ref:
                            zip_ref.extractall(description_folder)
                        logging.info(f"Unzipped {downloaded_file} successfully.")
                    except Exception as e:
                        logging.error(f"Failed to extract {downloaded_file}: {e}")
        except Exception as e:
            logging.error(f"An error occurred while processing {csv_file.name}: {e}")

    def _make_safe_folder_name(self, name: str) -> str:
        """
        Convert a string to a safe folder name by replacing unsafe characters with underscores.
        """
        safe_name = re.sub(r'[^a-zA-Z0-9_\-]', '_', name)
        logging.debug(f"Converted '{name}' to safe folder name '{safe_name}'")
        return safe_name

    def _download_file_with_progress(self, url: str, dest_folder: Path, file_size: int) -> Path:
        """
        Download a file from a URL to a specified destination folder with progress bar.
        """
        local_filename = dest_folder / url.split('/')[-1]
        try:
            with requests.get(url, stream=True) as r:
                r.raise_for_status()
                with open(local_filename, 'wb') as f, tqdm(
                    desc=local_filename.name,
                    total=file_size,
                    unit='iB',
                    unit_scale=True,
                    unit_divisor=1024,
                ) as progress_bar:
                    for chunk in r.iter_content(chunk_size=8192):
                        size = f.write(chunk)
                        progress_bar.update(size)
            logging.info(f"Successfully downloaded {url} to {local_filename}")
            return local_filename
        except requests.exceptions.RequestException as e:
            logging.error(f"Request failed for {url}: {e}")
            raise
        except Exception as e:
            logging.error(f"Failed to write file {local_filename}: {e}")
            raise

    def _convert_size_to_bytes(self, size_str: str) -> int:
        """
        Convert a human-readable file size to bytes.
        """
        units = {'B': 1, 'KB': 1024, 'MB': 1024**2, 'GB': 1024**3, 'TB': 1024**4}
        size_str = size_str.upper().replace(' ', '')
        if not re.match(r'^\d+(\.\d+)?[BKMGT]B?$', size_str):
            raise ValueError(f"Invalid size string: {size_str}")
        
        number, unit = float(re.findall(r'[\d\.]+', size_str)[0]), re.findall(r'[BKMGT]B?', size_str)[0]
        return int(number * units[unit])

    # Example usage:
    # ras_examples = RasExamples()
    # ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
    # extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
    # for path in extracted_paths:
    #     logging.info(f"Extracted to: {path}")


"""
### How to Use the Revised `RasExamples` Class

1. **Instantiate the Class:**
   ```python
   ras_examples = RasExamples()
   ```

2. **Download FEMA BLE Models:**
   - Ensure you have the required CSV files by visiting [FEMA's Estimated Base Flood Elevation (BFE) Viewer](https://webapps.usgs.gov/infrm/estBFE/) and using the "Download as Table" option for each BLE model you wish to access.
   - Call the `download_fema_ble_models` method with the appropriate paths:
     ```python
     ras_examples.download_fema_ble_models('/path/to/csv/files', '/path/to/output/folder')
     ```
     - Replace `'/path/to/csv/files'` with the directory containing your CSV files.
     - Replace `'/path/to/output/folder'` with the directory where you want the BLE models to be downloaded and organized.

3. **Extract Projects (If Needed):**
   - After downloading, you can extract specific projects using the existing `extract_project` method:
     ```python
     extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])
     for path in extracted_paths:
         logging.info(f"Extracted to: {path}")
     ```

4. **Explore Projects and Categories:**
   - List available categories:
     ```python
     categories = ras_examples.list_categories()
     ```
   - List projects within a specific category:
     ```python
     projects = ras_examples.list_projects(category='SomeCategory')
     ```

5. **Clean Projects Directory (If Needed):**
   - To remove all extracted projects:
     ```python
     ras_examples.clean_projects_directory()
     ```

### Dependencies

Ensure that the following Python packages are installed:

- `pandas`
- `requests`

You can install them using `pip`:

```bash
pip install pandas requests
```

### Notes

- The class uses Python's `logging` module to provide detailed information about its operations. Ensure that the logging level is set appropriately to capture the desired amount of detail.
- The `download_fema_ble_models` method handles large file downloads by streaming data in chunks, which is memory-efficient.
- All folder names are sanitized to prevent filesystem errors due to unsafe characters.
"""
==================================================

File: c:\GH\ras-commander\ras_commander\RasGeo.py
==================================================
"""
Operations for handling geometry files in HEC-RAS projects.
"""
from pathlib import Path
from typing import List, Union
from .RasPlan import RasPlan
from .RasPrj import ras
import logging
import re

# Configure logging at the module level
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    # You can add a filename parameter here to log to a file
    # filename='rasgeo.log',
    # Uncomment the above line to enable file logging
)

class RasGeo:
    """
    A class for operations on HEC-RAS geometry files.
    """
    
    @staticmethod
    def clear_geompre_files(
        plan_files: Union[str, Path, List[Union[str, Path]]] = None,
        ras_object = None
    ) -> None:
        """
        Clear HEC-RAS geometry preprocessor files for specified plan files or all plan files in the project directory.
        
        Limitations/Future Work:
        - This function only deletes the geometry preprocessor file.
        - It does not clear the IB tables.
        - It also does not clear geometry preprocessor tables from the geometry HDF.
        - All of these features will need to be added to reliably remove geometry preprocessor files for 1D and 2D projects.
        
        Parameters:
            plan_files (Union[str, Path, List[Union[str, Path]]], optional): 
                Full path(s) to the HEC-RAS plan file(s) (.p*).
                If None, clears all plan files in the project directory.
            ras_object: An optional RAS object instance.
        
        Returns:
            None
        
        Examples:
            # Clear all geometry preprocessor files in the project directory
            RasGeo.clear_geompre_files()
            
            # Clear a single plan file
            RasGeo.clear_geompre_files(r'path/to/plan.p01')
            
            # Clear multiple plan files
            RasGeo.clear_geompre_files([r'path/to/plan1.p01', r'path/to/plan2.p02'])

        Note:
            This function updates the ras object's geometry dataframe after clearing the preprocessor files.
        """
        ## Explicit Function Steps
        # 1. Initialize the ras_object, defaulting to the global ras if not provided.
        # 2. Define a helper function to clear a single geometry preprocessor file.
        # 3. Determine the list of plan files to process based on the input.
        # 4. Iterate over each plan file and clear its geometry preprocessor file.
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        def clear_single_file(plan_file: Union[str, Path], ras_obj) -> None:
            plan_path = Path(plan_file)
            geom_preprocessor_suffix = '.c' + ''.join(plan_path.suffixes[1:]) if plan_path.suffixes else '.c'
            geom_preprocessor_file = plan_path.with_suffix(geom_preprocessor_suffix)
            if geom_preprocessor_file.exists():
                try:
                    logging.info(f"Deleting geometry preprocessor file: {geom_preprocessor_file}")
                    geom_preprocessor_file.unlink()
                    logging.info("File deletion completed successfully.")
                except PermissionError:
                    logging.error(f"Permission denied: Unable to delete geometry preprocessor file: {geom_preprocessor_file}.")
                    raise PermissionError(f"Unable to delete geometry preprocessor file: {geom_preprocessor_file}. Permission denied.")
                except OSError as e:
                    logging.error(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
                    raise OSError(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
            else:
                logging.warning(f"No geometry preprocessor file found for: {plan_file}")
        
        if plan_files is None:
            logging.info("Clearing all geometry preprocessor files in the project directory.")
            plan_files_to_clear = list(ras_obj.project_folder.glob(r'*.p*'))
        elif isinstance(plan_files, (str, Path)):
            plan_files_to_clear = [plan_files]
            logging.info(f"Clearing geometry preprocessor file for single plan: {plan_files}")
        elif isinstance(plan_files, list):
            plan_files_to_clear = plan_files
            logging.info(f"Clearing geometry preprocessor files for multiple plans: {plan_files}")
        else:
            logging.error("Invalid input type for plan_files.")
            raise ValueError("Invalid input. Please provide a string, Path, list of paths, or None.")
        
        for plan_file in plan_files_to_clear:
            clear_single_file(plan_file, ras_obj)
        
        # Update the geometry dataframe
        try:
            ras_obj.geom_df = ras_obj.get_geom_entries()
            logging.info("Geometry dataframe updated successfully.")
        except Exception as e:
            logging.error(f"Failed to update geometry dataframe: {str(e)}")
            raise

==================================================

File: c:\GH\ras-commander\ras_commander\RasHdf.py
==================================================
"""
RasHdf Module

This module provides utilities for working with HDF files in HEC-RAS projects.
It contains the RasHdf class, which offers various static methods for extracting,
analyzing, and manipulating data from HEC-RAS HDF files.

Note:
    This method is decorated with @hdf_operation, which handles the opening and closing of the HDF file.
    The decorator should be used for all methods that directly interact with HDF files.
    It ensures proper file handling and error management.

    When using the @hdf_operation decorator:
    - The method receives an open h5py.File object as its first argument after 'cls'.
    - Error handling for file operations is managed by the decorator.
    - The HDF file is automatically closed after the method execution.

    Methods without this decorator must manually handle file opening, closing, and error management.
    Failure to use the decorator or properly manage the file can lead to resource leaks or file access errors.

Example:
    @classmethod
    @hdf_operation
    def example_method(cls, hdf_file: h5py.File, other_args):
        # Method implementation using hdf_file
        

"""
import h5py
import numpy as np
import pandas as pd
from typing import Union, List, Optional, Dict, Tuple, Any, Callable
from scipy.spatial import KDTree
from pathlib import Path
from datetime import datetime
import logging
from functools import wraps
from .RasPrj import RasPrj, ras, init_ras_project

# If you're using RasPrj in type hints, you might need to use string literals to avoid circular imports
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .RasPrj import RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ])

class RasHdf:
    """
    A utility class for working with HDF files in HEC-RAS projects.

    This class provides static methods for various operations on HDF files,
    including listing paths, extracting data, and performing analyses on
    HEC-RAS project data stored in HDF format.
    """
        
    @staticmethod
    def hdf_operation(func):
        @wraps(func)
        def wrapper(cls, hdf_input: Union[str, Path], *args: Any, **kwargs: Any) -> Any:
            from ras_commander import ras  # Import here to avoid circular import
            ras_obj = kwargs.pop('ras_object', None) or ras
            try:
                hdf_filename = cls._get_hdf_filename(hdf_input, ras_obj)
                with h5py.File(hdf_filename, 'r') as hdf_file:
                    return func(cls, hdf_file, *args, **kwargs)
            except Exception as e:
                logging.error(f"Error in {func.__name__}: {e}")
                return None
        return classmethod(wrapper)
    
    @classmethod
    def get_hdf_paths_with_properties(cls, hdf_input: Union[str, Path], ras_object=None) -> pd.DataFrame:
        """
        List all paths in the HDF file with their properties.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all paths and their properties in the HDF file.

        Example:
            >>> paths_df = RasHdf.get_hdf_paths_with_properties("path/to/file.hdf")
            >>> print(paths_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            paths = []
            def visitor_func(name: str, node: h5py.Group) -> None:
                path_info = {
                    "HDF_Path": name,
                    "Type": type(node).__name__,
                    "Shape": getattr(node, "shape", None),
                    "Size": getattr(node, "size", None),
                    "Dtype": getattr(node, "dtype", None)
                }
                paths.append(path_info)
            hdf_file.visititems(visitor_func)
            return pd.DataFrame(paths)
    
    @classmethod
    def get_runtime_data(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract runtime and compute time data from a single HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing runtime and compute time data, or None if data extraction fails.

        Example:
            >>> runtime_df = RasHdf.get_runtime_data("path/to/file.hdf")
            >>> if runtime_df is not None:
            ...     print(runtime_df.head())
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            logging.info(f"Extracting Plan Information from: {Path(hdf_file.filename).name}")
            plan_info = hdf_file.get('/Plan Data/Plan Information')
            if plan_info is None:
                logging.warning("Group '/Plan Data/Plan Information' not found.")
                return None

            plan_name = plan_info.attrs.get('Plan Name', 'Unknown')
            plan_name = plan_name.decode('utf-8') if isinstance(plan_name, bytes) else plan_name
            logging.info(f"Plan Name: {plan_name}")

            start_time_str = plan_info.attrs.get('Simulation Start Time', 'Unknown')
            end_time_str = plan_info.attrs.get('Simulation End Time', 'Unknown')
            start_time_str = start_time_str.decode('utf-8') if isinstance(start_time_str, bytes) else start_time_str
            end_time_str = end_time_str.decode('utf-8') if isinstance(end_time_str, bytes) else end_time_str

            start_time = datetime.strptime(start_time_str, "%d%b%Y %H:%M:%S")
            end_time = datetime.strptime(end_time_str, "%d%b%Y %H:%M:%S")
            simulation_duration = end_time - start_time
            simulation_hours = simulation_duration.total_seconds() / 3600

            logging.info(f"Simulation Start Time: {start_time_str}")
            logging.info(f"Simulation End Time: {end_time_str}")
            logging.info(f"Simulation Duration (hours): {simulation_hours}")

            compute_processes = hdf_file.get('/Results/Summary/Compute Processes')
            if compute_processes is None:
                logging.warning("Dataset '/Results/Summary/Compute Processes' not found.")
                return None

            process_names = [name.decode('utf-8') for name in compute_processes['Process'][:]]
            filenames = [filename.decode('utf-8') for filename in compute_processes['Filename'][:]]
            completion_times = compute_processes['Compute Time (ms)'][:]

            compute_processes_df = pd.DataFrame({
                'Process': process_names,
                'Filename': filenames,
                'Compute Time (ms)': completion_times,
                'Compute Time (s)': completion_times / 1000,
                'Compute Time (hours)': completion_times / (1000 * 3600)
            })

            logging.debug("Compute processes DataFrame:")
            logging.debug(compute_processes_df)

            compute_processes_summary = {
                'Plan Name': [plan_name],
                'File Name': [Path(hdf_file.filename).name],
                'Simulation Start Time': [start_time_str],
                'Simulation End Time': [end_time_str],
                'Simulation Duration (s)': [simulation_duration.total_seconds()],
                'Simulation Time (hr)': [simulation_hours],
                'Completing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Geometry']['Compute Time (hours)'].values[0] if 'Completing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Preprocessing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Preprocessing Geometry']['Compute Time (hours)'].values[0] if 'Preprocessing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Completing Event Conditions (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Event Conditions']['Compute Time (hours)'].values[0] if 'Completing Event Conditions' in compute_processes_df['Process'].values else 'N/A'],
                'Unsteady Flow Computations (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Unsteady Flow Computations']['Compute Time (hours)'].values[0] if 'Unsteady Flow Computations' in compute_processes_df['Process'].values else 'N/A'],
                'Complete Process (hr)': [compute_processes_df['Compute Time (hours)'].sum()]
            }

            compute_processes_summary['Unsteady Flow Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Unsteady Flow Computations (hr)'][0] if compute_processes_summary['Unsteady Flow Computations (hr)'][0] != 'N/A' else 'N/A']
            compute_processes_summary['Complete Process Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Complete Process (hr)'][0] if compute_processes_summary['Complete Process (hr)'][0] != 'N/A' else 'N/A']

            compute_summary_df = pd.DataFrame(compute_processes_summary)
            logging.debug("Compute summary DataFrame:")
            logging.debug(compute_summary_df)

            return compute_summary_df

    # List 2D Flow Area Groups (needed for later functions that extract specific datasets)
    
    @classmethod
    @hdf_operation
    def get_2d_flow_area_names(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[List[str]]:
        """
        List 2D Flow Area names from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[List[str]]: List of 2D Flow Area names, or None if no 2D Flow Areas are found.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas' in hdf_file:
                group = hdf_file['Geometry/2D Flow Areas']
                group_names = [name for name in group.keys() if isinstance(group[name], h5py.Group)]
                if not group_names:
                    logging.warning("No 2D Flow Areas found in the HDF file")
                    return None
                logging.info(f"Found {len(group_names)} 2D Flow Areas")
                return group_names
            else:
                logging.warning("No 2D Flow Areas found in the HDF file")
                return None
            
    @classmethod
    @hdf_operation
    def get_2d_flow_area_attributes(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract 2D Flow Area Attributes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing 2D Flow Area Attributes, or None if attributes are not found.

        Example:
            >>> attributes_df = RasHdf.get_2d_flow_area_attributes("path/to/file.hdf")
            >>> if attributes_df is not None:
            ...     print(attributes_df.head())
            ... else:
            ...     print("No 2D Flow Area attributes found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if 'Geometry/2D Flow Areas/Attributes' in hdf_file:
                attributes = hdf_file['Geometry/2D Flow Areas/Attributes'][()]
                attributes_df = pd.DataFrame(attributes)
                logging.info(f"Extracted 2D Flow Area attributes: {attributes_df.shape[0]} rows, {attributes_df.shape[1]} columns")
                return attributes_df
            else:
                logging.warning("No 2D Flow Area attributes found in the HDF file")
                return None
            
    @classmethod
    @hdf_operation
    def get_cell_info(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Info from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Info, or None if the data is not found.

        Example:
            >>> cell_info_df = RasHdf.get_cell_info("path/to/file.hdf")
            >>> if cell_info_df is not None:
            ...     print(cell_info_df.head())
            ... else:
            ...     print("No Cell Info found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_info_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Info', ['Start', 'End'])
            if cell_info_df is not None:
                logging.info(f"Extracted Cell Info: {cell_info_df.shape[0]} rows, {cell_info_df.shape[1]} columns")
            else:
                logging.warning("No Cell Info found in the HDF file")
            return cell_info_df
        
    @classmethod
    @hdf_operation
    def get_cell_points(cls, hdf_input: Union[str, Path], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Cell Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Cell Points, or None if the data is not found.

        Example:
            >>> cell_points_df = RasHdf.get_cell_points("path/to/file.hdf")
            >>> if cell_points_df is not None:
            ...     print(cell_points_df.head())
            ... else:
            ...     print("No Cell Points found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            cell_points_df = cls._extract_dataset(hdf_file, 'Geometry/2D Flow Areas/Cell Points', ['X', 'Y'])
            if cell_points_df is not None:
                logging.info(f"Extracted Cell Points: {cell_points_df.shape[0]} rows, {cell_points_df.shape[1]} columns")
            else:
                logging.warning("No Cell Points found in the HDF file")
            return cell_points_df
    
    @classmethod
    @hdf_operation
    def get_polygon_info_and_parts(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Polygon Info and Parts from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Polygon Info and Polygon Parts respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> polygon_info_df, polygon_parts_df = RasHdf.get_polygon_info_and_parts("path/to/file.hdf")
            >>> if polygon_info_df is not None and polygon_parts_df is not None:
            ...     print("Polygon Info:")
            ...     print(polygon_info_df.head())
            ...     print("Polygon Parts:")
            ...     print(polygon_parts_df.head())
            ... else:
            ...     print("Polygon data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            # Retrieve the area name, defaulting to the first found if not provided
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            # Construct the base path for dataset extraction
            base_path = f'Geometry/2D Flow Areas'
            
            # Extract Polygon Info and Parts datasets
            polygon_info_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Info', ['Column1', 'Column2', 'Column3', 'Column4'])
            polygon_parts_df = cls._extract_dataset(hdf_file, f'{base_path}/Polygon Parts', ['Start', 'Count'])

            # Log warnings if no data is found
            if polygon_info_df is None and polygon_parts_df is None:
                logging.warning(f"No Polygon Info or Parts found for 2D Flow Area: {area_name}")

            return polygon_info_df, polygon_parts_df

    @classmethod
    @hdf_operation
    def get_polygon_points(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Polygon Points from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Polygon Points, or None if the data is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            # This path does not include the area name
            polygon_points_path = f'Geometry/2D Flow Areas/Polygon Points'
            if polygon_points_path in hdf_file:
                polygon_points = hdf_file[polygon_points_path][()]
                polygon_points_df = pd.DataFrame(polygon_points, columns=['X', 'Y'])
                logging.info(f"Extracted Polygon Points for 2D Flow Area {area_name}: {polygon_points_df.shape[0]} rows, {polygon_points_df.shape[1]} columns")
                return polygon_points_df
            else:
                logging.warning(f"No Polygon Points found for 2D Flow Area: {area_name}")
                return None
            
    @classmethod
    @hdf_operation
    def get_cells_center_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Cells Center Coordinates and Manning's n from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Cells Center Coordinates and Manning's n respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> coords_df, mannings_df = RasHdf.get_cells_center_data("path/to/file.hdf")
            >>> if coords_df is not None and mannings_df is not None:
            ...     print("Cell Center Coordinates:")
            ...     print(coords_df.head())
            ...     print("Manning's n:")
            ...     print(mannings_df.head())
            ... else:
            ...     print("Cell center data not found")
        """
        logging.info(f"Entering get_cells_center_data method")
        logging.info(f"Input parameters: hdf_input={hdf_input}, area_name={area_name}")
        
        try:
            hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
            logging.info(f"HDF filename: {hdf_filename}")
            
            with h5py.File(hdf_filename, 'r') as hdf_file:
                logging.info(f"Successfully opened HDF file: {hdf_filename}")
                
                logging.info(f"Getting Cells Center Data for 2D Flow Area: {area_name}")
                area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
                logging.info(f"Area Name: {area_name}")
                
                base_path = f'Geometry/2D Flow Areas/{area_name}'
                cells_center_coord_path = f'{base_path}/Cells Center Coordinate'
                cells_manning_n_path = f'{base_path}/Cells Center Manning\'s n'
                
                logging.info(f"Extracting dataset from path: {cells_center_coord_path}")
                cells_center_coord_df = cls._extract_dataset(hdf_file, cells_center_coord_path, ['X', 'Y'])
                
                logging.info(f"Extracting dataset from path: {cells_manning_n_path}")
                cells_manning_n_df = cls._extract_dataset(hdf_file, cells_manning_n_path, ['Manning\'s n'])

                if cells_center_coord_df is not None and cells_manning_n_df is not None:
                    logging.info(f"Extracted Cells Center Data for 2D Flow Area: {area_name}")
                    logging.info(f"Cells Center Coordinates shape: {cells_center_coord_df.shape}, dtype: {cells_center_coord_df.dtypes}")
                    logging.info(f"Cells Manning's n shape: {cells_manning_n_df.shape}, dtype: {cells_manning_n_df.dtypes}")
                else:
                    logging.warning(f"Cells Center Data not found for 2D Flow Area: {area_name}")

                return cells_center_coord_df, cells_manning_n_df
        
        except Exception as e:
            logging.error(f"Error in get_cells_center_data: {str(e)}", exc_info=True)
            return None, None

    @classmethod
    @hdf_operation
    def get_faces_area_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract Faces Area Elevation Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces Area Elevation Values, or None if the data is not found.

        Example:
            >>> elevation_df = RasHdf.get_faces_area_elevation_data("path/to/file.hdf")
            >>> if elevation_df is not None:
            ...     print(elevation_df.head())
            ... else:
            ...     print("No Faces Area Elevation data found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)
            base_path = f'Geometry/2D Flow Areas/{area_name}'
            area_elev_values_path = f'{base_path}/Faces Area Elevation Values'
            
            if area_elev_values_path in hdf_file:
                area_elev_values = hdf_file[area_elev_values_path][()]
                area_elev_values_df = pd.DataFrame(area_elev_values, columns=['Elevation', 'Area', 'Wetted Perimeter', 'Manning\'s n'])
                
                logging.info(f"Extracted Faces Area Elevation Values for 2D Flow Area: {area_name}")
                logging.info(f"Faces Area Elevation Values shape: {area_elev_values.shape}, dtype: {area_elev_values.dtype}")
                
                return area_elev_values_df
            else:
                logging.warning(f"Faces Area Elevation Values not found for 2D Flow Area: {area_name}")
                return None

    @classmethod
    @hdf_operation
    def get_faces_indexes(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Cell and FacePoint Indexes from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]: 
                Two DataFrames containing Faces Cell Indexes and FacePoint Indexes respectively, 
                or None for each if the corresponding data is not found.

        Example:
            >>> cell_indexes_df, facepoint_indexes_df = RasHdf.get_faces_indexes("path/to/file.hdf")
            >>> if cell_indexes_df is not None and facepoint_indexes_df is not None:
            ...     print("Faces Cell Indexes:")
            ...     print(cell_indexes_df.head())
            ...     print("Faces FacePoint Indexes:")
            ...     print(facepoint_indexes_df.head())
            ... else:
            ...     print("Faces indexes data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            cell_indexes_path = f'{base_path}/Faces Cell Indexes'
            facepoint_indexes_path = f'{base_path}/Faces FacePoint Indexes'
            
            cell_indexes_df = cls._extract_dataset(hdf_file, cell_indexes_path, ['Left Cell', 'Right Cell'])
            facepoint_indexes_df = cls._extract_dataset(hdf_file, facepoint_indexes_path, ['Start FacePoint', 'End FacePoint'])

            if cell_indexes_df is not None and facepoint_indexes_df is not None:
                logging.info(f"Extracted Faces Indexes for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Indexes not found for 2D Flow Area: {area_name}")

            return cell_indexes_df, facepoint_indexes_df
        
        
        
    @classmethod
    @hdf_operation
    def get_faces_elevation_data(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Low Elevation Centroid and Minimum Elevation from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Low Elevation Centroid and Minimum Elevation.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            low_elev_centroid = cls._extract_dataset(hdf_file, f'{base_path}/Faces Low Elevation Centroid', ['Low Elevation Centroid'])
            min_elevation = cls._extract_dataset(hdf_file, f'{base_path}/Faces Minimum Elevation', ['Minimum Elevation'])

            if low_elev_centroid is not None and min_elevation is not None:
                logging.info(f"Extracted Faces Elevation Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Elevation Data not found for 2D Flow Area: {area_name}")

            return low_elev_centroid, min_elevation
    
    @classmethod
    @hdf_operation
    def get_faces_vector_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Faces NormalUnitVector and Length from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Faces NormalUnitVector and Length.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            vector_data = cls._extract_dataset(hdf_file, f'{base_path}/Faces NormalUnitVector and Length', ['NormalX', 'NormalY', 'Length'])

            if vector_data is not None:
                logging.info(f"Extracted Faces Vector Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Vector Data not found for 2D Flow Area: {area_name}")

            return vector_data

    @classmethod
    @hdf_operation
    def get_faces_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Faces Perimeter Info and Values from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Faces Perimeter Info and Values.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.

        Example:
            >>> perimeter_info_df, perimeter_values_df = RasHdf.get_faces_perimeter_data("path/to/file.hdf")
            >>> if perimeter_info_df is not None and perimeter_values_df is not None:
            ...     print("Perimeter Info:")
            ...     print(perimeter_info_df.head())
            ...     print("Perimeter Values:")
            ...     print(perimeter_values_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}'
            perimeter_info = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Info', ['Start', 'Count'])
            perimeter_values = cls._extract_dataset(hdf_file, f'{base_path}/Faces Perimeter Values', ['X', 'Y'])

            if perimeter_info is not None and perimeter_values is not None:
                logging.info(f"Extracted Faces Perimeter Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Faces Perimeter Data not found for 2D Flow Area: {area_name}")

            return perimeter_info, perimeter_values

    @classmethod
    @hdf_operation
    def get_infiltration_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Infiltration Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing various Infiltration Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            # Retrieve the area name from the HDF file or use the first found
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            # Define the base path for the Infiltration data
            base_path = f'Geometry/2D Flow Areas/{area_name}/Infiltration'
            
            # Extract various datasets related to infiltration
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            initial_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Initial Deficit', ['Initial Deficit'])
            maximum_deficit = cls._extract_dataset(hdf_file, f'{base_path}/Maximum Deficit', ['Maximum Deficit'])
            potential_percolation_rate = cls._extract_dataset(hdf_file, f'{base_path}/Potential Percolation Rate', ['Potential Percolation Rate'])

            # Log the extraction status
            if all(df is not None for df in [cell_classifications, face_classifications, initial_deficit, maximum_deficit, potential_percolation_rate]):
                logging.info(f"Extracted Infiltration Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Some or all Infiltration Data not found for 2D Flow Area: {area_name}")

            return cell_classifications, face_classifications, initial_deficit, maximum_deficit, potential_percolation_rate
        
    @classmethod
    @hdf_operation
    def get_percent_impervious_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """
        Extract Percent Impervious Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame], Optional[pd.DataFrame]]:
                DataFrames containing Cell Classifications, Face Classifications, and Percent Impervious Data
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            base_path = f'Geometry/2D Flow Areas/{area_name}/Percent Impervious'
            cell_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Cell Center Classifications', ['Cell Classification'])
            face_classifications = cls._extract_dataset(hdf_file, f'{base_path}/Face Center Classifications', ['Face Classification'])
            percent_impervious = cls._extract_dataset(hdf_file, f'{base_path}/Percent Impervious', ['Percent Impervious'])

            if all([df is not None for df in [cell_classifications, face_classifications, percent_impervious]]):
                logging.info(f"Extracted Percent Impervious Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Some or all Percent Impervious Data not found for 2D Flow Area: {area_name}")

            return cell_classifications, face_classifications, percent_impervious

    @classmethod
    @hdf_operation
    def get_perimeter_data(
        cls,
        hdf_input: Union[str, Path],
        area_name: Optional[str] = None,
        ras_object=None
    ) -> Optional[pd.DataFrame]:
        """
        Extract Perimeter Data from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area to extract data from.
                If None, uses the first 2D Area Name found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing Perimeter Data

        Example:
            >>> perimeter_df = RasHdf.get_perimeter_data("path/to/file.hdf")
            >>> if perimeter_df is not None:
            ...     print(perimeter_df.head())
            ... else:
            ...     print("Perimeter data not found")
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            area_name = cls._get_area_name(hdf_file, area_name, hdf_file.filename)

            perimeter_path = f'Geometry/2D Flow Areas/{area_name}/Perimeter'
            perimeter_df = cls._extract_dataset(hdf_file, perimeter_path, ['X', 'Y'])

            if perimeter_df is not None:
                logging.info(f"Extracted Perimeter Data for 2D Flow Area: {area_name}")
            else:
                logging.warning(f"Perimeter Data not found for 2D Flow Area: {area_name}")

            return perimeter_df

# Private Class Methods (to save code duplication)


    @classmethod
    def _get_area_name(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> str:
        """
        Get the 2D Flow Area name from the HDF file.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): The provided area name, if any.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            str: The 2D Flow Area name.

        Raises:
            ValueError: If no 2D Flow Areas are found in the HDF file or if the specified area name is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            if area_name is None:
                area_names = [name for name in hdf_file['Geometry/2D Flow Areas'].keys() if isinstance(hdf_file['Geometry/2D Flow Areas'][name], h5py.Group)]
                if not area_names:
                    raise ValueError("No 2D Flow Areas found in the HDF file")
                area_name = area_names[0]
                logging.info(f"Using first 2D Flow Area found: {area_name}")
            else:
                if area_name not in hdf_file['Geometry/2D Flow Areas']:
                    raise ValueError(f"2D Flow Area '{area_name}' not found in the HDF file")
                logging.info(f"Using 2D Flow Area provided by user: {area_name}")
        return area_name

    @classmethod
    def _extract_dataset(cls, hdf_input: Union[str, Path], dataset_path: str, column_names: List[str], ras_object=None) -> Optional[pd.DataFrame]:
        """
        Extract a dataset from the HDF file and convert it to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            dataset_path (str): The path to the dataset within the HDF file.
            column_names (List[str]): The names to assign to the DataFrame columns.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[pd.DataFrame]: The extracted data as a DataFrame, or None if the dataset is not found.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                dataset = hdf_file[dataset_path][()]
                df = pd.DataFrame(dataset, columns=column_names)
                logging.info(f"Extracted dataset: {dataset_path}")
                return df
            except KeyError:
                logging.warning(f"Dataset not found: {dataset_path}")
                return None
    @classmethod
    @hdf_operation
    def read_hdf_to_dataframe(cls, hdf_input: Union[str, Path], dataset_path: str, fill_value: Union[int, float, str] = -9999, ras_object=None) -> pd.DataFrame:
        """
        Reads an HDF5 dataset and converts it into a pandas DataFrame, handling byte strings and missing values.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            dataset_path (str): Path to the dataset within the HDF file.
            fill_value (Union[int, float, str], optional): The value to use for filling missing data. Defaults to -9999.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: The resulting DataFrame with byte strings decoded and missing values replaced.

        Raises:
            KeyError: If the dataset is not found in the HDF file.
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_dataset = hdf_file[dataset_path]
                hdf_dataframe = cls.convert_to_dataframe_array(hdf_dataset)
                byte_columns = [col for col in hdf_dataframe.columns if isinstance(hdf_dataframe[col].iloc[0], (bytes, bytearray))]
                
                hdf_dataframe[byte_columns] = hdf_dataframe[byte_columns].applymap(lambda x: x.decode('utf-8') if isinstance(x, (bytes, bytearray)) else x)
                hdf_dataframe = hdf_dataframe.replace({fill_value: np.NaN})
                
                logging.info(f"Successfully read dataset: {dataset_path}")
                return hdf_dataframe
            except KeyError:
                logging.error(f"Dataset not found: {dataset_path}")
                raise
        
    @classmethod
    @hdf_operation
    def get_group_attributes_as_df(cls, hdf_input: Union[str, Path], group_path: str, ras_object=None) -> pd.DataFrame:
        """
        Convert attributes inside a given HDF group to a DataFrame.

        Args:
            hdf_input (Union[str, Path]): Path to the HDF file or plan number.
            group_path (str): Path of the group in the HDF file.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            pd.DataFrame: DataFrame of all attributes in the specified group with their properties.

        Raises:
            KeyError: If the specified group_path is not found in the file.

        Example:
            >>> attributes_df = RasHdf.get_group_attributes_as_df("path/to/file.hdf", "/Results/Unsteady/Output")
            >>> print(attributes_df.head())
        """
        hdf_filename = cls._get_hdf_filename(hdf_input, ras_object)
        
        with h5py.File(hdf_filename, 'r') as hdf_file:
            try:
                group = hdf_file[group_path]
                attributes = []
                for attr in group.attrs:
                    value = group.attrs[attr]
                    attr_info = {
                        'Attribute': attr,
                        'Value': value,
                        'Type': type(value).__name__,
                        'Shape': value.shape if isinstance(value, np.ndarray) else None,
                        'Size': value.size if isinstance(value, np.ndarray) else None,
                        'Dtype': value.dtype if isinstance(value, np.ndarray) else None
                    }
                    if isinstance(value, bytes):
                        attr_info['Value'] = value.decode('utf-8')
                    elif isinstance(value, np.ndarray):
                        if value.dtype.kind == 'S':
                            attr_info['Value'] = [v.decode('utf-8') for v in value]
                        elif value.dtype.kind in ['i', 'f', 'u']:
                            attr_info['Value'] = value.tolist()
                    attributes.append(attr_info)
                
                return pd.DataFrame(attributes)
            except KeyError:
                logging.error(f"Group not found: {group_path}")
                raise

    # Last functions from PyHMT2D:


    @classmethod
    @hdf_operation
    def get_2d_area_solution_times(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution times for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution times, or None if not found.
        
        Example:
            >>> solution_times = RasHdf.get_2d_area_solution_times("03", area_name="Area1")
            >>> print(solution_times)
            [0.0, 0.5, 1.0, ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_times = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time']
                )
                logging.info(f"Retrieved {len(solution_times)} solution times for 2D Flow Area: {area_name}")
                return solution_times
            except KeyError:
                logging.warning(f"Solution times not found for 2D Flow Area: {area_name}")
                return None
    @classmethod
    @hdf_operation
    def get_2d_area_solution_time_dates(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[np.ndarray]:
        """
        Retrieve solution time dates for a specified 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, uses the first area found.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[np.ndarray]: Array of solution time dates, or None if not found.
        
        Example:
            >>> solution_time_dates = RasHdf.get_2d_area_solution_time_dates("03", area_name="Area1")
            >>> print(solution_time_dates)
            ['2024-01-01T00:00:00', '2024-01-01T00:30:00', ...]
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                solution_time_dates = np.array(
                    hdf_file['Results']['Unsteady']['Output']['Output Blocks']
                    ['Base Output']['Unsteady Time Series']['Time Date Stamp']
                )
                logging.info(f"Retrieved {len(solution_time_dates)} solution time dates for 2D Flow Area: {area_name}")
                return solution_time_dates
            except KeyError:
                logging.warning(f"Solution time dates not found for 2D Flow Area: {area_name}")
                return None

    @classmethod
    @hdf_operation
    def load_2d_area_solutions(
        cls,
        hdf_file: h5py.File,
        ras_object=None
    ) -> Optional[Dict[str, pd.DataFrame]]:
        """
        Load 2D Area Solutions (Water Surface Elevation and Face Normal Velocity) from the HDF file
        and provide them as pandas DataFrames.

        **Note:** 
            - This function has only been tested with HEC-RAS version 6.5.
            - Ensure that the HDF file structure matches the expected paths.

        Args:
            hdf_file (h5py.File): An open HDF5 file object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[Dict[str, pd.DataFrame]]: A dictionary containing:
                - 'solution_times': DataFrame of solution times.
                - For each 2D Flow Area:
                    - '{Area_Name}_WSE': Water Surface Elevation DataFrame.
                    - '{Area_Name}_Face_Velocity': Face Normal Velocity DataFrame.
        """
        try:
            # Extract solution times
            solution_times_path = '/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time'
            if solution_times_path not in hdf_file:
                logging.error(f"Solution times dataset not found at path: {solution_times_path}")
                return None

            solution_times = hdf_file[solution_times_path][()]
            solution_times_df = pd.DataFrame({
                'Time_Step': solution_times
            })
            logging.info(f"Extracted Solution Times: {solution_times_df.shape[0]} time steps")

            # Initialize dictionary to hold all dataframes
            solutions_dict = {
                'solution_times': solution_times_df
            }

            # Get list of 2D Flow Areas
            two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
            if not two_d_area_names:
                logging.error("No 2D Flow Areas found in the HDF file.")
                return solutions_dict

            for area in two_d_area_names:
                logging.info(f"Processing 2D Flow Area: {area}")

                # Paths for WSE and Face Velocity datasets
                wse_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Water Surface'
                face_velocity_path = f'/Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{area}/Face Velocity'

                # Extract Water Surface Elevation (WSE)
                if wse_path not in hdf_file:
                    logging.warning(f"WSE dataset not found for area '{area}' at path: {wse_path}")
                    continue

                wse_data = hdf_file[wse_path][()]
                # Assuming cell center coordinates are required for WSE
                cell_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Cell Center Coordinate'
                if cell_center_coords_path not in hdf_file:
                    logging.warning(f"Cell Center Coordinate dataset not found for area '{area}' at path: {cell_center_coords_path}")
                    continue

                cell_center_coords = hdf_file[cell_center_coords_path][()]
                if cell_center_coords.shape[0] != wse_data.shape[1]:
                    logging.warning(f"Mismatch between Cell Center Coordinates and WSE data for area '{area}'.")
                    continue

                wse_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, wse_data.shape[1]),
                    'Cell_ID': np.tile(np.arange(wse_data.shape[1]), wse_data.shape[0]),
                    'X': cell_center_coords[:, 0].repeat(wse_data.shape[0]),
                    'Y': cell_center_coords[:, 1].repeat(wse_data.shape[0]),
                    'WSE': wse_data.flatten()
                })
                solutions_dict[f'{area}_WSE'] = wse_df
                logging.info(f"Extracted WSE for area '{area}': {wse_df.shape[0]} records")

                # Extract Face Normal Velocity
                if face_velocity_path not in hdf_file:
                    logging.warning(f"Face Velocity dataset not found for area '{area}' at path: {face_velocity_path}")
                    continue

                face_velocity_data = hdf_file[face_velocity_path][()]
                # Assuming face center points are required for velocities
                face_center_coords_path = f'/Geometry/2D Flow Areas/{area}/Face Points Coordinates'
                if face_center_coords_path not in hdf_file:
                    logging.warning(f"Face Points Coordinates dataset not found for area '{area}' at path: {face_center_coords_path}")
                    continue

                face_center_coords = hdf_file[face_center_coords_path][()]
                if face_center_coords.shape[0] != face_velocity_data.shape[1]:
                    logging.warning(f"Mismatch between Face Center Coordinates and Face Velocity data for area '{area}'.")
                    continue

                face_velocity_df = pd.DataFrame({
                    'Time_Step': np.repeat(solution_times, face_velocity_data.shape[1]),
                    'Face_ID': np.tile(np.arange(face_velocity_data.shape[1]), face_velocity_data.shape[0]),
                    'X': face_center_coords[:, 0].repeat(face_velocity_data.shape[0]),
                    'Y': face_center_coords[:, 1].repeat(face_velocity_data.shape[0]),
                    'Normal_Velocity_ft_s': face_velocity_data.flatten()
                })
                solutions_dict[f'{area}_Face_Velocity'] = face_velocity_df
                logging.info(f"Extracted Face Velocity for area '{area}': {face_velocity_df.shape[0]} records")

            return solutions_dict

        except Exception as e:
            logging.error(f"An error occurred while loading 2D area solutions: {e}", exc_info=True)
            return None


    @classmethod
    @hdf_operation
    def build_2d_area_face_hydraulic_information(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[List[np.ndarray]]]:
        """
        Build face hydraulic information tables (elevation, area, wetted perimeter, Manning's n) for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[List[np.ndarray]]]: Nested lists containing hydraulic information for each face in each 2D Flow Area.
        
        Example:
            >>> hydraulic_info = RasHdf.build_2d_area_face_hydraulic_information("03")
            >>> print(hydraulic_info[0][0])  # First face of first area
            [[Elevation1, Area1, WettedPerim1, ManningN1],
             [Elevation2, Area2, WettedPerim2, ManningN2],
             ...]
        """
        try:
            ras_obj = ras_object if ras_object is not None else ras
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_obj), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                hydraulic_info_table = []

                for area in two_d_area_names:
                    face_elev_info = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Info'])
                    face_elev_values = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces Area Elevation Values'])
                    
                    area_hydraulic_info = []
                    for face in face_elev_info:
                        start_row, count = face
                        face_data = face_elev_values[start_row:start_row + count].copy()
                        area_hydraulic_info.append(face_data)
                        logging.info(f"Processed hydraulic information for face {face} in 2D Flow Area: {area}")
                    
                    hydraulic_info_table.append(area_hydraulic_info)

                return hydraulic_info_table

        except KeyError as e:
            logging.error(f"Error building face hydraulic information: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_face_point_coordinates_list(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build a list of face point coordinates for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point coordinates for each 2D Flow Area.
        
        Example:
            >>> face_coords_list = RasHdf.build_2d_area_face_point_coordinates_list("03")
            >>> print(face_coords_list[0])  # Coordinates for first area
            [[X1, Y1], [X2, Y2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_point_coords_list = []

                for area in two_d_area_names:
                    face_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    face_point_coords_list.append(face_points)
                    logging.info(f"Built face point coordinates list for 2D Flow Area: {area}")

                return face_point_coords_list

        except KeyError as e:
            logging.error(f"Error building face point coordinates list: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_face_profile(cls, hdf_input: Union[str, Path, h5py.File], area_name: Optional[str] = None, ras_object=None, n_face_profile_points: int = 10) -> Optional[List[np.ndarray]]:
        """
        Build face profiles representing sub-grid terrain for each face in 2D Flow Areas.
        
        Args:
            hdf_input (Union[str, Path, h5py.File]): The HDF5 file path or open HDF5 file object.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
            n_face_profile_points (int): Number of points to interpolate along each face profile.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of profile points for each face in each 2D Flow Area.
        
        Example:
            >>> face_profiles = RasHdf.build_2d_area_face_profile("03", n_face_profile_points=20)
            >>> print(face_profiles[0][0])  # Profile points for first face of first area
            [[X1, Y1, Z1], [X2, Y2, Z2], ...]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                print(f"Building face profiles for {len(two_d_area_names)} 2D Flow Areas")
                print(f"Area names: {two_d_area_names}")
                face_profiles = []

                for area in two_d_area_names:
                    face_faces = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_point_coords = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Face Points Coordinates'])
                    profile_points_all_faces = []

                    for face in face_faces:
                        face_start, face_end = face
                        start_coords = face_point_coords[face_start]
                        end_coords = face_point_coords[face_end]
                        
                        length = cls.horizontal_distance(start_coords, end_coords)
                        stations = np.linspace(0, length, n_face_profile_points, endpoint=True)
                        
                        interpolated_points = np.array([
                            start_coords + (end_coords - start_coords) * i / (n_face_profile_points - 1)
                            for i in range(n_face_profile_points)
                        ])
                        
                        # Interpolate Z coordinates (assuming a method exists)
                        interpolated_points = cls.interpolate_z_coords(interpolated_points)
                        
                        profile_points_all_faces.append(interpolated_points)
                        logging.info(f"Built face profile for face {face} in 2D Flow Area: {area}")

                    face_profiles.append(profile_points_all_faces)

                return face_profiles

        except KeyError as e:
            logging.error(f"Error building face profiles: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_face_facepoints(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[List[np.ndarray]]:
        """
        Build face's facepoint list for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[List[np.ndarray]]: List containing arrays of face point indexes for each face in each 2D Flow Area.
        
        Example:
            >>> face_facepoints = RasHdf.build_face_facepoints("03")
            >>> print(face_facepoints[0][0])  # FacePoint indexes for first face of first area
            [start_idx, end_idx]
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                face_facepoints_list = []

                for area in two_d_area_names:
                    face_facepoints = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Faces FacePoint Indexes'])
                    face_facepoints_list.append(face_facepoints)
                    logging.info(f"Built face facepoints list for 2D Flow Area: {area}")

                return face_facepoints_list

        except KeyError as e:
            logging.error(f"Error building face facepoints list: {e}")
            return None

    @classmethod
    @hdf_operation
    def build_2d_area_boundaries(cls, hdf_input: Union[str, Path], area_name: Optional[str] = None, ras_object=None) -> Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
        """
        Build boundaries with their point lists for each 2D Flow Area.
        
        Args:
            hdf_input (Union[str, Path]): The plan number or full path to the HDF file.
            area_name (Optional[str]): Name of the 2D Flow Area. If None, builds for all areas.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.
        
        Returns:
            Optional[Tuple[int, np.ndarray, List[str], List[str], List[str], np.ndarray, np.ndarray]]:
                Tuple containing total boundaries, boundary IDs, boundary names, associated 2D Flow Area names, boundary types,
                total points per boundary, and boundary point lists.
        
        Example:
            >>> total_boundaries, boundary_ids, boundary_names, flow_area_names, boundary_types, total_points, boundary_points = RasHdf.build_2d_area_boundaries("03")
            >>> print(total_boundaries)
            5
        """
        try:
            with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
                two_d_area_names = cls.get_2d_flow_area_names(hdf_file, ras_object=ras_object)
                total_boundaries = 0
                boundary_ids = []
                boundary_names = []
                flow_area_names = []
                boundary_types = []
                total_points_per_boundary = []
                boundary_points_list = []

                for area in two_d_area_names:
                    boundary_points = np.array(hdf_file[f'Geometry/2D Flow Areas/{area}/Boundary Points'])
                    if boundary_points.size == 0:
                        logging.warning(f"No boundary points found for 2D Flow Area: {area}")
                        continue

                    current_boundary_id = boundary_points[0][0]
                    current_boundary_points = [boundary_points[0][2], boundary_points[0][3]]
                    boundary_id = current_boundary_id

                    for point in boundary_points[1:]:
                        if point[0] == current_boundary_id:
                            current_boundary_points.append(point[3])
                        else:
                            # Save the completed boundary
                            boundary_ids.append(current_boundary_id)
                            boundary_names.append(point[0])  # Assuming boundary name is stored here
                            flow_area_names.append(area)
                            boundary_types.append(point[2])  # Assuming boundary type is stored here
                            total_points_per_boundary.append(len(current_boundary_points))
                            boundary_points_list.append(np.array(current_boundary_points))
                            total_boundaries += 1

                            # Start a new boundary
                            current_boundary_id = point[0]
                            current_boundary_points = [point[2], point[3]]

                    # Save the last boundary
                    boundary_ids.append(current_boundary_id)
                    boundary_names.append(boundary_points[-1][0])  # Assuming boundary name is stored here
                    flow_area_names.append(area)
                    boundary_types.append(boundary_points[-1][2])  # Assuming boundary type is stored here
                    total_points_per_boundary.append(len(current_boundary_points))
                    boundary_points_list.append(np.array(current_boundary_points))
                    total_boundaries += 1

                    logging.info(f"Built boundaries for 2D Flow Area: {area}, Total Boundaries: {total_boundaries}")

                return (total_boundaries, np.array(boundary_ids), boundary_names, flow_area_names, boundary_types, np.array(total_points_per_boundary), np.array(boundary_points_list))

        except KeyError as e:
            logging.error(f"Error building boundaries: {e}")
            return None

    # Helper Methods for New Functionalities


    @classmethod
    def horizontal_distance(cls, coord1: np.ndarray, coord2: np.ndarray) -> float:
        """
        Calculate the horizontal distance between two coordinate points.
        
        Args:
            coord1 (np.ndarray): First coordinate point [X, Y].
            coord2 (np.ndarray): Second coordinate point [X, Y].
        
        Returns:
            float: Horizontal distance.
        
        Example:
            >>> distance = RasHdf.horizontal_distance([0, 0], [3, 4])
            >>> print(distance)
            5.0
        """
        return np.linalg.norm(coord2 - coord1)

    @classmethod
    def interpolate_z_coords(cls, points: np.ndarray) -> np.ndarray:
        """
        Interpolate Z coordinates for a set of points.
        
        Args:
            points (np.ndarray): Array of points with [X, Y].
        
        Returns:
            np.ndarray: Array of points with [X, Y, Z].
        
        Example:
            >>> interpolated = RasHdf.interpolate_z_coords(np.array([[0,0], [1,1]]))
            >>> print(interpolated)
            [[0, 0, Z0],
             [1, 1, Z1]]
        """
        # Placeholder for actual interpolation logic
        # This should be replaced with the appropriate interpolation method
        z_coords = np.zeros((points.shape[0], 1))  # Assuming Z=0 for simplicity
        return np.hstack((points, z_coords))
   







    @classmethod
    @hdf_operation
    def extract_string_from_hdf(
        cls,
        hdf_input: Union[str, Path],
        hdf_path: str,
        ras_object: Optional["RasPrj"] = None
    ) -> str:
        """
        Extract string from HDF object at a given path.

        Args:
            hdf_input (Union[str, Path]): Either the plan number or the full path to the HDF file.
            hdf_path (str): Path of the object in the HDF file.
            ras_object (Optional["RasPrj"]): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            str: Extracted string from the specified HDF object.

        Raises:
            ValueError: If no HDF file is found for the given plan number.
            FileNotFoundError: If the specified HDF file does not exist.
            KeyError: If the specified hdf_path is not found in the file.

        Example:
            >>> result = RasHdf.extract_string_from_hdf("path/to/file.hdf", "/Results/Summary/Compute Messages (text)")
            >>> print(result)
        """
        with h5py.File(cls._get_hdf_filename(hdf_input, ras_object), 'r') as hdf_file:
            try:
                hdf_object = hdf_file[hdf_path]
                if isinstance(hdf_object, h5py.Group):
                    return f"Group: {hdf_path}\nContents: {list(hdf_object.keys())}"
                elif isinstance(hdf_object, h5py.Dataset):
                    data = hdf_object[()]
                    if isinstance(data, bytes):
                        return data.decode('utf-8')
                    elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':
                        return [v.decode('utf-8') for v in data]
                    else:
                        return str(data)
                else:
                    return f"Unsupported object type: {type(hdf_object)}"
            except KeyError:
                raise KeyError(f"Path not found: {hdf_path}")

    @classmethod
    @staticmethod
    def decode_byte_strings(dataframe: pd.DataFrame) -> pd.DataFrame:
        """
        Decodes byte strings in a DataFrame to regular string objects.

        This function converts columns with byte-encoded strings (e.g., b'string') into UTF-8 decoded strings.

        Args:
            dataframe (pd.DataFrame): The DataFrame containing byte-encoded string columns.

        Returns:
            pd.DataFrame: The DataFrame with byte strings decoded to regular strings.

        Example:
            >>> df = pd.DataFrame({'A': [b'hello', b'world'], 'B': [1, 2]})
            >>> decoded_df = RasHdf.decode_byte_strings(df)
            >>> print(decoded_df)
                A  B
            0  hello  1
            1  world  2
        """
        str_df = dataframe.select_dtypes(['object'])
        str_df = str_df.stack().str.decode('utf-8').unstack()
        for col in str_df:
            dataframe[col] = str_df[col]
        return dataframe

    @classmethod
    @staticmethod
    def perform_kdtree_query(
        reference_points: np.ndarray,
        query_points: np.ndarray,
        max_distance: float = 2.0
    ) -> np.ndarray:
        """
        Performs a KDTree query between two datasets and returns indices with distances exceeding max_distance set to -1.

        Args:
            reference_points (np.ndarray): The reference dataset for KDTree.
            query_points (np.ndarray): The query dataset to search against KDTree of reference_points.
            max_distance (float, optional): The maximum distance threshold. Indices with distances greater than this are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices from reference_points that are nearest to each point in query_points. 
                        Indices with distances > max_distance are set to -1.

        Example:
            >>> ref_points = np.array([[0, 0], [1, 1], [2, 2]])
            >>> query_points = np.array([[0.5, 0.5], [3, 3]])
            >>> result = RasHdf.perform_kdtree_query(ref_points, query_points)
            >>> print(result)
            array([ 0, -1])
        """
        dist, snap = KDTree(reference_points).query(query_points, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        return snap

    @classmethod
    @staticmethod
    def find_nearest_neighbors(points: np.ndarray, max_distance: float = 2.0) -> np.ndarray:
        """
        Creates a self KDTree for dataset points and finds nearest neighbors excluding self, 
        with distances above max_distance set to -1.

        Args:
            points (np.ndarray): The dataset to build the KDTree from and query against itself.
            max_distance (float, optional): The maximum distance threshold. Indices with distances 
                                            greater than max_distance are set to -1. Defaults to 2.0.

        Returns:
            np.ndarray: Array of indices representing the nearest neighbor in points for each point in points. 
                        Indices with distances > max_distance or self-matches are set to -1.

        Example:
            >>> points = np.array([[0, 0], [1, 1], [2, 2], [10, 10]])
            >>> result = RasHdf.find_nearest_neighbors(points)
            >>> print(result)
            array([1, 0, 1, -1])
        """
        dist, snap = KDTree(points).query(points, k=2, distance_upper_bound=max_distance)
        snap[dist > max_distance] = -1
        
        snp = pd.DataFrame(snap, index=np.arange(len(snap)))
        snp = snp.replace(-1, np.nan)
        snp.loc[snp[0] == snp.index, 0] = np.nan
        snp.loc[snp[1] == snp.index, 1] = np.nan
        filled = snp[0].fillna(snp[1])
        snapped = filled.fillna(-1).astype(np.int64).to_numpy()
        return snapped

    @classmethod
    @staticmethod
    def consolidate_dataframe(
        dataframe: pd.DataFrame,
        group_by: Optional[Union[str, List[str]]] = None,
        pivot_columns: Optional[Union[str, List[str]]] = None,
        level: Optional[int] = None,
        n_dimensional: bool = False,
        aggregation_method: Union[str, Callable] = 'list'
    ) -> pd.DataFrame:
        """
        Consolidate rows in a DataFrame by merging duplicate values into lists or using a specified aggregation function.

        Args:
            dataframe (pd.DataFrame): The DataFrame to consolidate.
            group_by (Optional[Union[str, List[str]]]): Columns or indices to group by.
            pivot_columns (Optional[Union[str, List[str]]]): Columns to pivot.
            level (Optional[int]): Level of multi-index to group by.
            n_dimensional (bool): If True, use a pivot table for N-Dimensional consolidation.
            aggregation_method (Union[str, Callable]): Aggregation method, e.g., 'list' to aggregate into lists.

        Returns:
            pd.DataFrame: The consolidated DataFrame.

        Example:
            >>> df = pd.DataFrame({'A': [1, 1, 2], 'B': [4, 5, 6], 'C': [7, 8, 9]})
            >>> result = RasHdf.consolidate_dataframe(df, group_by='A')
            >>> print(result)
            B         C
            A            
            1  [4, 5]  [7, 8]
            2  [6]     [9]
        """
        if aggregation_method == 'list':
            agg_func = lambda x: tuple(x)
        else:
            agg_func = aggregation_method

        if n_dimensional:
            result = dataframe.pivot_table(group_by, pivot_columns, aggfunc=agg_func)
        else:
            result = dataframe.groupby(group_by, level=level).agg(agg_func).applymap(list)

        return result
    
    @classmethod
    @staticmethod
    def find_nearest_value(array: Union[list, np.ndarray], target_value: Union[int, float]) -> Union[int, float]:
        """
        Finds the nearest value in a NumPy array to the specified target value.

        Args:
            array (Union[list, np.ndarray]): The array to search within.
            target_value (Union[int, float]): The value to find the nearest neighbor to.

        Returns:
            Union[int, float]: The nearest value in the array to the specified target value.

        Example:
            >>> arr = np.array([1, 3, 5, 7, 9])
            >>> result = RasHdf.find_nearest_value(arr, 6)
            >>> print(result)
            5
        """
        array = np.asarray(array)
        idx = (np.abs(array - target_value)).argmin()
        return array[idx]
    
    @staticmethod
    def _get_hdf_filename(hdf_input: Union[str, Path, h5py.File], ras_object=None) -> Path:
        """
        Get the HDF filename from the input.

        Args:
            hdf_input (Union[str, Path, h5py.File]): The plan number, full path to the HDF file as a string, a Path object, or an h5py.File object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Path: The full path to the HDF file as a Path object.

        Raises:
            ValueError: If no HDF file is found for the given plan number or if the input type is invalid.
            FileNotFoundError: If the specified HDF file does not exist.
        """

        # If hdf_input is already an h5py.File object, return its filename
        if isinstance(hdf_input, h5py.File):
            return Path(hdf_input.filename)

        # Convert to Path object if it's a string
        hdf_input = Path(hdf_input)

        # If hdf_input is a file path, return it directly
        if hdf_input.is_file():
            return hdf_input

        # If hdf_input is not a file path, assume it's a plan number and require ras_object
        ras_obj = ras_object or ras
        if not ras_obj.initialized:
            raise ValueError("ras_object is not initialized. ras_object is required when hdf_input is not a direct file path.")

        plan_info = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == str(hdf_input)]
        if plan_info.empty:
            raise ValueError(f"No HDF file found for plan number {hdf_input}")

        hdf_filename = Path(plan_info.iloc[0]['HDF_Results_Path'])
        if not hdf_filename.is_file():
            raise FileNotFoundError(f"HDF file not found: {hdf_filename}")

        return hdf_filename




def save_dataframe_to_hdf(
    dataframe: pd.DataFrame,
    hdf_parent_group: h5py.Group,
    dataset_name: str,
    attributes: Optional[Dict[str, Union[int, float, str]]] = None,
    fill_value: Union[int, float, str] = -9999,
    **kwargs: Any
) -> h5py.Dataset:
    """
    Save a pandas DataFrame to an HDF5 dataset within a specified parent group.

    This function addresses limitations of `pd.to_hdf()` by using h5py to create and save datasets.

    Args:
        dataframe (pd.DataFrame): The DataFrame to save.
        hdf_parent_group (h5py.Group): The parent HDF5 group where the dataset will be created.
        dataset_name (str): The name of the new dataset to add in the HDF5 parent group.
        attributes (Optional[Dict[str, Union[int, float, str]]]): A dictionary of attributes to add to the dataset.
        fill_value (Union[int, float, str]): The value to use for filling missing data.
        **kwargs: Additional keyword arguments passed to `hdf_parent_group.create_dataset()`.

    Returns:
        h5py.Dataset: The created HDF5 dataset within the parent group.

    Raises:
        ValueError: If the DataFrame columns are not consistent.

    Example:
        >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
        >>> with h5py.File('data.h5', 'w') as f:
        ...     group = f.create_group('my_group')
        ...     dataset = save_dataframe_to_hdf(df, group, 'my_dataset')
        >>> print(dataset)
    """
    df = dataframe.copy()

    # Replace '/' in column names with '-' to avoid issues in HDF5
    if df.columns.dtype == 'O':
        df.columns = df.columns.str.replace('/', '-', regex=False)
    
    # Fill missing values with the specified fill_value
    df = df.fillna(fill_value)
    
    # Identify string columns and ensure consistency
    string_cols = df.select_dtypes(include=['object']).columns
    if not string_cols.equals(df.select_dtypes(include=['object']).columns):
        raise ValueError("Inconsistent string columns detected")
    
    # Encode string columns to bytes
    df[string_cols] = df[string_cols].applymap(lambda x: x.encode('utf-8')).astype('bytes')

    # Prepare data for HDF5 dataset creation
    arr = df.to_records(index=False) if not isinstance(df.columns, pd.RangeIndex) else df.values
    
    # Remove existing dataset if it exists
    if dataset_name in hdf_parent_group:
        del hdf_parent_group[dataset_name]
    
    # Create the dataset in the HDF5 file
    dataset = hdf_parent_group.create_dataset(dataset_name, data=arr, **kwargs)
    
    # Update dataset attributes if provided
    if attributes:
        dataset.attrs.update(attributes)
    
    logging.info(f"Successfully saved DataFrame to dataset: {dataset_name}")
    return dataset


==================================================

File: c:\GH\ras-commander\ras_commander\RasPlan.py
==================================================
import re
import logging
from pathlib import Path
import shutil
from typing import Union, Optional
import pandas as pd
from .RasPrj import RasPrj, ras
from .RasUtils import RasUtils


from pathlib import Path
from typing import Union, Any
import logging
import re


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class RasPlan:
    """
    A class for operations on HEC-RAS plan files.
    """

    @staticmethod
    def set_geom(plan_number: Union[str, int], new_geom: Union[str, int], ras_object=None) -> pd.DataFrame:
        """
        Set the geometry for the specified plan.

        Parameters:
            plan_number (Union[str, int]): The plan number to update.
            new_geom (Union[str, int]): The new geometry number to set.
            ras_object: An optional RAS object instance.

        Returns:
            pd.DataFrame: The updated geometry DataFrame.

        Example:
            updated_geom_df = RasPlan.set_geom('02', '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Ensure plan_number and new_geom are strings
        plan_number = str(plan_number).zfill(2)
        new_geom = str(new_geom).zfill(2)

        # Before doing anything, make sure the plan, geom, flow, and unsteady dataframes are current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        # Log the current geometry DataFrame for debugging
        logging.debug("Current geometry DataFrame within the function:")
        logging.debug(ras_obj.geom_df)

        if new_geom not in ras_obj.geom_df['geom_number'].values:
            logging.error(f"Geometry {new_geom} not found in project.")
            raise ValueError(f"Geometry {new_geom} not found in project.")

        # Update the geometry for the specified plan
        ras_obj.plan_df.loc[ras_obj.plan_df['plan_number'] == plan_number, 'geom_number'] = new_geom

        logging.info(f"Geometry for plan {plan_number} set to {new_geom}")
        logging.debug("Updated plan DataFrame:")
        logging.debug(ras_obj.plan_df)

        # Update the project file
        prj_file_path = ras_obj.prj_file
        try:
            with open(prj_file_path, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {prj_file_path}")
            raise

        plan_pattern = re.compile(rf"^Plan File=p{plan_number}", re.IGNORECASE)
        geom_pattern = re.compile(r"^Geom File=g\d+", re.IGNORECASE)
        
        for i, line in enumerate(lines):
            if plan_pattern.match(line):
                for j in range(i+1, len(lines)):
                    if geom_pattern.match(lines[j]):
                        lines[j] = f"Geom File=g{new_geom}\n"
                        logging.info(f"Updated Geom File in project file to g{new_geom} for plan {plan_number}")
                        break
                break

        try:
            with open(prj_file_path, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated project file with new geometry for plan {plan_number}")
        except IOError as e:
            logging.error(f"Failed to write to project file: {e}")
            raise

        # Re-initialize the ras object to reflect changes
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        return ras_obj.plan_df

    @staticmethod
    def set_steady(plan_number: str, new_steady_flow_number: str, ras_object=None):
        """
        Apply a steady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02')
        new_steady_flow_number (str): Steady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified steady flow number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_steady('02', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting steady flow file to {new_steady_flow_number} in Plan {plan_number}")
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
                        
        # Update the flow dataframe in the ras instance to ensure it is current
        ras_obj.flow_df = ras_obj.get_flow_entries()
        
        if new_steady_flow_number not in ras_obj.flow_df['flow_number'].values:
            logging.error(f"Steady flow number {new_steady_flow_number} not found in project file.")
            raise ValueError(f"Steady flow number {new_steady_flow_number} not found in project file.")
        
        # Resolve the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            logging.error(f"Plan file not found: {plan_number}")
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        try:
            with open(plan_file_path, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Plan file not found: {plan_file_path}")
            raise
        
        with open(plan_file_path, 'w') as f:
            for line in lines:
                if line.startswith("Flow File=f"):
                    f.write(f"Flow File=f{new_steady_flow_number}\n")
                    logging.info(f"Updated Flow File in {plan_file_path} to f{new_steady_flow_number}")
                else:
                    f.write(line)

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_unsteady(plan_number: str, new_unsteady_flow_number: str, ras_object=None):
        """
        Apply an unsteady flow file to a plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '04')
        new_unsteady_flow_number (str): Unsteady flow number to apply (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If the specified unsteady number is not found in the project file
        FileNotFoundError: If the specified plan file is not found

        Example:
        >>> RasPlan.set_unsteady('04', '01')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting unsteady flow file to {new_unsteady_flow_number} in Plan {plan_number}")
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the unsteady dataframe in the ras instance to ensure it is current
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        if new_unsteady_flow_number not in ras_obj.unsteady_df['unsteady_number'].values:
            logging.error(f"Unsteady number {new_unsteady_flow_number} not found in project file.")
            raise ValueError(f"Unsteady number {new_unsteady_flow_number} not found in project file.")
        
        # Get the full path of the plan file
        plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
        if not plan_file_path:
            logging.error(f"Plan file not found: {plan_number}")
            raise FileNotFoundError(f"Plan file not found: {plan_number}")
        
        try:
            RasUtils.update_plan_file(plan_file_path, 'Unsteady', new_unsteady_flow_number)
            logging.info(f"Updated unsteady flow file in {plan_file_path} to u{new_unsteady_flow_number}")
        except Exception as e:
            logging.error(f"Failed to update unsteady flow file: {e}")
            raise

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_num_cores(plan_number, num_cores, ras_object=None):
        """
        Update the maximum number of cores to use in the HEC-RAS plan file.
        
        Parameters:
        plan_number (str): Plan number (e.g., '02') or full path to the plan file
        num_cores (int): Maximum number of cores to use
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Notes on setting num_cores in HEC-RAS:
        The recommended setting for num_cores is 2 (most efficient) to 8 (most performant)
        More details in the HEC-Commander Repository Blog "Benchmarking is All You Need"
        https://github.com/billk-FM/HEC-Commander/blob/main/Blog/7._Benchmarking_Is_All_You_Need.md
        
        Microsoft Windows has a maximum of 64 cores that can be allocated to a single Ras.exe process. 

        Example:
        >>> # Using plan number
        >>> RasPlan.set_num_cores('02', 4)
        >>> # Using full path to plan file
        >>> RasPlan.set_num_cores('/path/to/project.p02', 4)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        logging.info(f"Setting num_cores to {num_cores} in Plan {plan_number}")
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Determine if plan_number is a path or a plan number
        if Path(plan_number).is_file():
            plan_file_path = Path(plan_number)
            if not plan_file_path.exists():
                logging.error(f"Plan file not found: {plan_file_path}. Please provide a valid plan number or path.")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}. Please provide a valid plan number or path.")
        else:
            # Update the plan dataframe in the ras instance to ensure it is current
            ras_obj.plan_df = ras_obj.get_prj_entries('Plan')
            
            # Get the full path of the plan file
            plan_file_path = RasPlan.get_plan_path(plan_number, ras_obj)
            if not plan_file_path:
                logging.error(f"Plan file not found: {plan_number}. Please provide a valid plan number or path.")
                raise FileNotFoundError(f"Plan file not found: {plan_number}. Please provide a valid plan number or path.")
        
        cores_pattern = re.compile(r"(UNET D1 Cores= )\d+")
        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except FileNotFoundError:
            logging.error(f"Plan file not found: {plan_file_path}")
            raise
        
        new_content = cores_pattern.sub(rf"\g<1>{num_cores}", content)
        try:
            with open(plan_file_path, 'w') as file:
                file.write(new_content)
            logging.info(f"Updated {plan_file_path} with {num_cores} cores.")
        except IOError as e:
            logging.error(f"Failed to write to plan file: {e}")
            raise
        
        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    @staticmethod
    def set_geom_preprocessor(file_path, run_htab, use_ib_tables, ras_object=None):
        """
        Update the simulation plan file to modify the `Run HTab` and `UNET Use Existing IB Tables` settings.
        
        Parameters:
        file_path (str): Path to the simulation plan file (.p06 or similar) that you want to modify.
        run_htab (int): Value for the `Run HTab` setting:
            - `0` : Do not run the geometry preprocessor, use existing geometry tables.
            - `-1` : Run the geometry preprocessor, forcing a recomputation of the geometry tables.
        use_ib_tables (int): Value for the `UNET Use Existing IB Tables` setting:
            - `0` : Use existing interpolation/boundary (IB) tables without recomputing them.
            - `-1` : Do not use existing IB tables, force a recomputation.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Raises:
        ValueError: If `run_htab` or `use_ib_tables` are not integers or not within the accepted values (`0` or `-1`).
        FileNotFoundError: If the specified file does not exist.
        IOError: If there is an error reading or writing the file.

        Example:
        >>> RasPlan.set_geom_preprocessor('/path/to/project.p06', run_htab=-1, use_ib_tables=0)

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        if run_htab not in [-1, 0]:
            logging.error("Invalid value for `Run HTab`. Expected `0` or `-1`.")
            raise ValueError("Invalid value for `Run HTab`. Expected `0` or `-1`.")
        if use_ib_tables not in [-1, 0]:
            logging.error("Invalid value for `UNET Use Existing IB Tables`. Expected `0` or `-1`.")
            raise ValueError("Invalid value for `UNET Use Existing IB Tables`. Expected `0` or `-1`.")
        try:
            logging.info(f"Reading the file: {file_path}")
            with open(file_path, 'r') as file:
                lines = file.readlines()
            logging.info("Updating the file with new settings...")
            updated_lines = []
            for line in lines:
                if line.lstrip().startswith("Run HTab="):
                    updated_line = f"Run HTab= {run_htab} \n"
                    updated_lines.append(updated_line)
                    logging.info(f"Updated 'Run HTab' to {run_htab}")
                elif line.lstrip().startswith("UNET Use Existing IB Tables="):
                    updated_line = f"UNET Use Existing IB Tables= {use_ib_tables} \n"
                    updated_lines.append(updated_line)
                    logging.info(f"Updated 'UNET Use Existing IB Tables' to {use_ib_tables}")
                else:
                    updated_lines.append(line)
            logging.info(f"Writing the updated settings back to the file: {file_path}")
            with open(file_path, 'w') as file:
                file.writelines(updated_lines)
            logging.info("File update completed successfully.")
        except FileNotFoundError:
            logging.error(f"The file '{file_path}' does not exist.")
            raise FileNotFoundError(f"The file '{file_path}' does not exist.")
        except IOError as e:
            logging.error(f"An error occurred while reading or writing the file: {e}")
            raise IOError(f"An error occurred while reading or writing the file: {e}")

        # Update the ras object's dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

    # Get Functions to retrieve file paths for plan, flow, unsteady, geometry and results files

    @staticmethod
    def get_results_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Retrieve the results file path for a given HEC-RAS plan number.

        Args:
            plan_number (str): The HEC-RAS plan number for which to find the results path.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
            Optional[str]: The full path to the results file if found and the file exists, or None if not found.

        Raises:
            RuntimeError: If the project is not initialized.

        Example:
            >>> ras_plan = RasPlan()
            >>> results_path = ras_plan.get_results_path('01')
            >>> if results_path:
            ...     print(f"Results file found at: {results_path}")
            ... else:
            ...     print("Results file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Update the plan dataframe in the ras instance to ensure it is current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        
        # Ensure plan_number is a string
        plan_number = str(plan_number).zfill(2)
        
        # Log the plan dataframe for debugging
        logging.debug("Plan DataFrame:")
        logging.debug(ras_obj.plan_df)
        
        plan_entry = ras_obj.plan_df[ras_obj.plan_df['plan_number'] == plan_number]
        if not plan_entry.empty:
            results_path = plan_entry['HDF_Results_Path'].iloc[0]
            if results_path and Path(results_path).exists():
                logging.info(f"Results file for Plan number {plan_number} exists at: {results_path}")
                return results_path
            else:
                logging.warning(f"Results file for Plan number {plan_number} does not exist.")
                return None
        else:
            logging.warning(f"Plan number {plan_number} not found in the entries.")
            return None

    @staticmethod
    def get_plan_path(plan_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given plan number.
        
        This method ensures that the latest plan entries are included by refreshing
        the plan dataframe before searching for the requested plan number.
        
        Args:
        plan_number (str): The plan number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        Optional[str]: The full path of the plan file if found, None otherwise.
        
        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> plan_path = ras_plan.get_plan_path('01')
        >>> if plan_path:
        ...     print(f"Plan file found at: {plan_path}")
        ... else:
        ...     print("Plan file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated plan dataframe
        plan_df = ras_obj.get_plan_entries()
        
        plan_path = plan_df[plan_df['plan_number'] == plan_number]
        
        if not plan_path.empty:
            full_path = plan_path['full_path'].iloc[0]
            logging.info(f"Plan file for Plan number {plan_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Plan number {plan_number} not found in the updated plan entries.")
            return None

    @staticmethod
    def get_flow_path(flow_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given flow number.

        Args:
        flow_number (str): The flow number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the flow file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> flow_path = ras_plan.get_flow_path('01')
        >>> if flow_path:
        ...     print(f"Flow file found at: {flow_path}")
        ... else:
        ...     print("Flow file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated flow dataframe
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')
        
        flow_path = ras_obj.flow_df[ras_obj.flow_df['flow_number'] == flow_number]
        if not flow_path.empty:
            full_path = flow_path['full_path'].iloc[0]
            logging.info(f"Flow file for Flow number {flow_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Flow number {flow_number} not found in the updated flow entries.")
            return None

    @staticmethod
    def get_unsteady_path(unsteady_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given unsteady number.

        Args:
        unsteady_number (str): The unsteady number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the unsteady file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> unsteady_path = ras_plan.get_unsteady_path('01')
        >>> if unsteady_path:
        ...     print(f"Unsteady file found at: {unsteady_path}")
        ... else:
        ...     print("Unsteady file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated unsteady dataframe
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')
        
        unsteady_path = ras_obj.unsteady_df[ras_obj.unsteady_df['unsteady_number'] == unsteady_number]
        if not unsteady_path.empty:
            full_path = unsteady_path['full_path'].iloc[0]
            logging.info(f"Unsteady file for Unsteady number {unsteady_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Unsteady number {unsteady_number} not found in the updated unsteady entries.")
            return None

    @staticmethod
    def get_geom_path(geom_number: str, ras_object=None) -> Optional[str]:
        """
        Return the full path for a given geometry number.

        Args:
        geom_number (str): The geometry number to search for.
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Optional[str]: The full path of the geometry file if found, None otherwise.

        Raises:
        RuntimeError: If the project is not initialized.

        Example:
        >>> ras_plan = RasPlan()
        >>> geom_path = ras_plan.get_geom_path('01')
        >>> if geom_path:
        ...     print(f"Geometry file found at: {geom_path}")
        ... else:
        ...     print("Geometry file not found.")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        # Use updated geom dataframe
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')
        
        geom_path = ras_obj.geom_df[ras_obj.geom_df['geom_number'] == geom_number]
        if not geom_path.empty:
            full_path = geom_path['full_path'].iloc[0]
            logging.info(f"Geometry file for Geom number {geom_number} found at: {full_path}")
            return full_path
        else:
            logging.warning(f"Geometry number {geom_number} not found in the updated geometry entries.")
            return None

    # Clone Functions to copy unsteady, flow, and geometry files from templates

    @staticmethod
    def clone_plan(template_plan, new_plan_shortid=None, ras_object=None):
        """
        Create a new plan file based on a template and update the project file.
        
        Parameters:
        template_plan (str): Plan number to use as template (e.g., '01')
        new_plan_shortid (str, optional): New short identifier for the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New plan number
        
        Example:
        >>> ras_plan = RasPlan()
        >>> new_plan_number = ras_plan.clone_plan('01', new_plan_shortid='New Plan')
        >>> print(f"New plan created with number: {new_plan_number}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update plan entries without reinitializing the entire project
        ras_obj.plan_df = ras_obj.get_prj_entries('Plan')

        new_plan_num = RasPlan.get_next_number(ras_obj.plan_df['plan_number'])
        template_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{template_plan}"
        new_plan_path = ras_obj.project_folder / f"{ras_obj.project_name}.p{new_plan_num}"
        
        if not template_plan_path.exists():
            logging.error(f"Template plan file '{template_plan_path}' does not exist.")
            raise FileNotFoundError(f"Template plan file '{template_plan_path}' does not exist.")

        shutil.copy(template_plan_path, new_plan_path)
        logging.info(f"Copied {template_plan_path} to {new_plan_path}")

        try:
            with open(new_plan_path, 'r') as f:
                plan_lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"New plan file not found after copying: {new_plan_path}")
            raise

        shortid_pattern = re.compile(r'^Short Identifier=(.*)$', re.IGNORECASE)
        for i, line in enumerate(plan_lines):
            match = shortid_pattern.match(line.strip())
            if match:
                current_shortid = match.group(1)
                if new_plan_shortid is None:
                    new_shortid = (current_shortid + "_copy")[:24]
                else:
                    new_shortid = new_plan_shortid[:24]
                plan_lines[i] = f"Short Identifier={new_shortid}\n"
                logging.info(f"Updated 'Short Identifier' to '{new_shortid}' in {new_plan_path}")
                break

        try:
            with open(new_plan_path, 'w') as f:
                f.writelines(plan_lines)
            logging.info(f"Updated short identifier in {new_plan_path}")
        except IOError as e:
            logging.error(f"Failed to write updated short identifier to {new_plan_path}: {e}")
            raise

        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Plan File entry line
        new_plan_line = f"Plan File=p{new_plan_num}\n"

        # Find the correct insertion point for the new Plan File entry
        plan_file_pattern = re.compile(r'^Plan File=p(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = plan_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_plan_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_plan_line)
            logging.info(f"Inserted new plan line at index {insertion_index}")
        else:
            # Try to insert after the last Plan File entry
            plan_indices = [i for i, line in enumerate(lines) if plan_file_pattern.match(line.strip())]
            if plan_indices:
                last_plan_index = plan_indices[-1]
                lines.insert(last_plan_index + 1, new_plan_line)
                logging.info(f"Inserted new plan line after index {last_plan_index}")
            else:
                # Append at the end if no Plan File entries exist
                lines.append(new_plan_line)
                logging.info(f"Appended new plan line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new plan p{new_plan_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_plan = new_plan_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        return new_plan

    @staticmethod
    def clone_unsteady(template_unsteady, ras_object=None):
        """
        Copy unsteady flow files from a template, find the next unsteady number,
        and update the project file accordingly.

        Parameters:
        template_unsteady (str): Unsteady flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        str: New unsteady flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_unsteady_num = ras_plan.clone_unsteady('01')
        >>> print(f"New unsteady flow file created: u{new_unsteady_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update unsteady entries without reinitializing the entire project
        ras_obj.unsteady_df = ras_obj.get_prj_entries('Unsteady')

        new_unsteady_num = RasPlan.get_next_number(ras_obj.unsteady_df['unsteady_number'])
        template_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}"
        new_unsteady_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}"

        if not template_unsteady_path.exists():
            logging.error(f"Template unsteady file '{template_unsteady_path}' does not exist.")
            raise FileNotFoundError(f"Template unsteady file '{template_unsteady_path}' does not exist.")

        shutil.copy(template_unsteady_path, new_unsteady_path)
        logging.info(f"Copied {template_unsteady_path} to {new_unsteady_path}")

        # Copy the corresponding .hdf file if it exists
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{template_unsteady}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.u{new_unsteady_num}.hdf"
        if template_hdf_path.exists():
            shutil.copy(template_hdf_path, new_hdf_path)
            logging.info(f"Copied {template_hdf_path} to {new_hdf_path}")
        else:
            logging.warning(f"No corresponding .hdf file found for '{template_unsteady_path}'. Skipping '.hdf' copy.")

        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Unsteady Flow File entry line
        new_unsteady_line = f"Unsteady File=u{new_unsteady_num}\n"

        # Find the correct insertion point for the new Unsteady Flow File entry
        unsteady_file_pattern = re.compile(r'^Unsteady File=u(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = unsteady_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_unsteady_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_unsteady_line)
            logging.info(f"Inserted new unsteady flow line at index {insertion_index}")
        else:
            # Try to insert after the last Unsteady Flow File entry
            unsteady_indices = [i for i, line in enumerate(lines) if unsteady_file_pattern.match(line.strip())]
            if unsteady_indices:
                last_unsteady_index = unsteady_indices[-1]
                lines.insert(last_unsteady_index + 1, new_unsteady_line)
                logging.info(f"Inserted new unsteady flow line after index {last_unsteady_index}")
            else:
                # Append at the end if no Unsteady Flow File entries exist
                lines.append(new_unsteady_line)
                logging.info(f"Appended new unsteady flow line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new unsteady flow file u{new_unsteady_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_unsteady = new_unsteady_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)
        
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        return new_unsteady

    @staticmethod
    def clone_steady(template_flow, ras_object=None):
        """
        Copy steady flow files from a template, find the next flow number,
        and update the project file accordingly.
        
        Parameters:
        template_flow (str): Flow number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New flow number (e.g., '03')

        Example:
        >>> ras_plan = RasPlan()
        >>> new_flow_num = ras_plan.clone_steady('01')
        >>> print(f"New steady flow file created: f{new_flow_num}")

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update flow entries without reinitializing the entire project
        ras_obj.flow_df = ras_obj.get_prj_entries('Flow')

        new_flow_num = RasPlan.get_next_number(ras_obj.flow_df['flow_number'])
        template_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{template_flow}"
        new_flow_path = ras_obj.project_folder / f"{ras_obj.project_name}.f{new_flow_num}"

        if not template_flow_path.exists():
            logging.error(f"Template steady flow file '{template_flow_path}' does not exist.")
            raise FileNotFoundError(f"Template steady flow file '{template_flow_path}' does not exist.")

        shutil.copy(template_flow_path, new_flow_path)
        logging.info(f"Copied {template_flow_path} to {new_flow_path}")

        # Read the contents of the project file
        try:
            with open(ras_obj.prj_file, 'r') as f:
                lines = f.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Steady Flow File entry line
        new_flow_line = f"Flow File=f{new_flow_num}\n"

        # Find the correct insertion point for the new Steady Flow File entry
        flow_file_pattern = re.compile(r'^Flow File=f(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = flow_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(new_flow_num):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_flow_line)
            logging.info(f"Inserted new steady flow line at index {insertion_index}")
        else:
            # Try to insert after the last Steady Flow File entry
            flow_indices = [i for i, line in enumerate(lines) if flow_file_pattern.match(line.strip())]
            if flow_indices:
                last_flow_index = flow_indices[-1]
                lines.insert(last_flow_index + 1, new_flow_line)
                logging.info(f"Inserted new steady flow line after index {last_flow_index}")
            else:
                # Append at the end if no Steady Flow File entries exist
                lines.append(new_flow_line)
                logging.info(f"Appended new steady flow line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as f:
                f.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new steady flow file f{new_flow_num}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_steady = new_flow_num
        
        # Re-initialize the ras global object
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)
        
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        return new_steady

    @staticmethod
    def clone_geom(template_geom, ras_object=None):
        """
        Copy geometry files from a template, find the next geometry number,
        and update the project file accordingly.
        
        Parameters:
        template_geom (str): Geometry number to be used as a template (e.g., '01')
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        str: New geometry number (e.g., '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Update geometry entries without reinitializing the entire project
        ras_obj.geom_df = ras_obj.get_prj_entries('Geom')
        logging.debug(f"Updated geometry entries:\n{ras_obj.geom_df}")

        template_geom_filename = f"{ras_obj.project_name}.g{template_geom}"
        template_geom_path = ras_obj.project_folder / template_geom_filename

        if not template_geom_path.is_file():
            logging.error(f"Template geometry file '{template_geom_path}' does not exist.")
            raise FileNotFoundError(f"Template geometry file '{template_geom_path}' does not exist.")

        next_geom_number = RasPlan.get_next_number(ras_obj.geom_df['geom_number'])

        new_geom_filename = f"{ras_obj.project_name}.g{next_geom_number}"
        new_geom_path = ras_obj.project_folder / new_geom_filename

        shutil.copyfile(template_geom_path, new_geom_path)
        logging.info(f"Copied '{template_geom_path}' to '{new_geom_path}'.")

        # Handle HDF file copy
        template_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{template_geom}.hdf"
        new_hdf_path = ras_obj.project_folder / f"{ras_obj.project_name}.g{next_geom_number}.hdf"
        if template_hdf_path.is_file():
            shutil.copyfile(template_hdf_path, new_hdf_path)
            logging.info(f"Copied '{template_hdf_path}' to '{new_hdf_path}'.")
        else:
            logging.warning(f"Template geometry HDF file '{template_hdf_path}' does not exist. Skipping '.hdf' copy.")

        try:
            with open(ras_obj.prj_file, 'r') as file:
                lines = file.readlines()
        except FileNotFoundError:
            logging.error(f"Project file not found: {ras_obj.prj_file}")
            raise

        # Prepare the new Geometry File entry line
        new_geom_line = f"Geom File=g{next_geom_number}\n"

        # Find the correct insertion point for the new Geometry File entry
        geom_file_pattern = re.compile(r'^Geom File=g(\d+)', re.IGNORECASE)
        insertion_index = None
        for i, line in enumerate(lines):
            match = geom_file_pattern.match(line.strip())
            if match:
                current_number = int(match.group(1))
                if current_number < int(next_geom_number):
                    continue
                else:
                    insertion_index = i
                    break

        if insertion_index is not None:
            lines.insert(insertion_index, new_geom_line)
            logging.info(f"Inserted new geometry line at index {insertion_index}")
        else:
            # Try to insert after the last Geometry File entry
            geom_indices = [i for i, line in enumerate(lines) if geom_file_pattern.match(line.strip())]
            if geom_indices:
                last_geom_index = geom_indices[-1]
                lines.insert(last_geom_index + 1, new_geom_line)
                logging.info(f"Inserted new geometry line after index {last_geom_index}")
            else:
                # Append at the end if no Geometry File entries exist
                lines.append(new_geom_line)
                logging.info(f"Appended new geometry line at the end of the project file")

        try:
            # Write the updated lines back to the project file
            with open(ras_obj.prj_file, 'w') as file:
                file.writelines(lines)
            logging.info(f"Updated {ras_obj.prj_file} with new geometry file g{next_geom_number}")
        except IOError as e:
            logging.error(f"Failed to write updated project file: {e}")
            raise

        new_geom = next_geom_number
        
        # Update all dataframes in the ras object
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

        logging.debug(f"Updated geometry entries:\n{ras_obj.geom_df}")

        return new_geom

    @staticmethod
    def get_next_number(existing_numbers):
        """
        Determine the next available number from a list of existing numbers.
        
        Parameters:
        existing_numbers (list): List of existing numbers as strings
        
        Returns:
        str: Next available number as a zero-padded string
        
        Example:
        >>> existing_numbers = ['01', '02', '04']
        >>> RasPlan.get_next_number(existing_numbers)
        '03'
        >>> existing_numbers = ['01', '02', '03']
        >>> RasPlan.get_next_number(existing_numbers)
        '04'
        """
        existing_numbers = sorted(int(num) for num in existing_numbers)
        next_number = 1
        for num in existing_numbers:
            if num == next_number:
                next_number += 1
            else:
                break
        return f"{next_number:02d}"


    @staticmethod
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading the plan file

        Available keys and their expected types:
        - 'description' (str): Plan description
        - 'computation_interval' (str): Time value for computational time step (e.g., '5SEC', '2MIN')
        - 'dss_file' (str): Name of the DSS file used
        - 'flow_file' (str): Name of the flow input file
        - 'friction_slope_method' (int): Method selection for friction slope (e.g., 1, 2)
        - 'geom_file' (str): Name of the geometry input file
        - 'mapping_interval' (str): Time interval for mapping output
        - 'plan_file' (str): Name of the plan file
        - 'plan_title' (str): Title of the simulation plan
        - 'program_version' (str): Version number of HEC-RAS
        - 'run_htab' (int): Flag to run HTab module (-1 or 1)
        - 'run_post_process' (int): Flag to run post-processing (-1 or 1)
        - 'run_sediment' (int): Flag to run sediment transport module (0 or 1)
        - 'run_unet' (int): Flag to run unsteady network module (-1 or 1)
        - 'run_wqnet' (int): Flag to run water quality module (0 or 1)
        - 'short_identifier' (str): Short name or ID for the plan
        - 'simulation_date' (str): Start and end dates/times for simulation
        - 'unet_d1_cores' (int): Number of cores used in 1D calculations
        - 'unet_use_existing_ib_tables' (int): Flag for using existing internal boundary tables (-1, 0, or 1)
        - 'unet_1d_methodology' (str): 1D calculation methodology
        - 'unet_d2_solver_type' (str): 2D solver type
        - 'unet_d2_name' (str): Name of the 2D area
        - 'run_rasmapper' (int): Flag to run RASMapper for floodplain mapping (-1 for off, 0 for on)

        Example:
        >>> computation_interval = RasPlan.get_plan_value("01", "computation_interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name', 'run_rasmapper'
        }

        if key not in valid_keys:
            logging.warning(f"Unknown key: {key}. Valid keys are: {', '.join(valid_keys)}\n Add more keys and explanations in get_plan_value() as needed.")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object=ras_obj)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'description':
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key.replace('_', ' ').title()}=(.*)"
            match = re.search(pattern, content)
            if match:
                return match.group(1).strip()
            else:
                logging.error(f"Key '{key}' not found in the plan file.")
                return None

    @staticmethod
    def update_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        value: Any,
        ras_object=None
    ) -> None:
        """
        Update a specific key-value pair in a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to update in the plan file
        value (Any): The new value to set for the key
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Raises:
        ValueError: If the plan file is not found
        IOError: If there's an error reading or writing the plan file

        Note: See the docstring of get_plan_value for a full list of available keys and their types.

        Example:
        >>> RasPlan.update_plan_value("01", "computation_interval", "10SEC")
        >>> RasPlan.update_plan_value("/path/to/plan.p01", "run_htab", 1)
        >>> RasPlan.update_plan_value("01", "run_rasmapper", 0)  # Turn on Floodplain Mapping
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name', 'run_rasmapper'
        }

        if key not in valid_keys:
            logging.warning(f"Unknown key: {key}. Valid keys are: {', '.join(valid_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasPlan.get_plan_path(plan_number_or_path, ras_object)
            if plan_file_path is None or not Path(plan_file_path).exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                lines = file.readlines()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        # Special handling for description
        if key == 'description':
            description_start = None
            description_end = None
            for i, line in enumerate(lines):
                if line.strip() == 'Begin DESCRIPTION':
                    description_start = i
                elif line.strip() == 'END DESCRIPTION':
                    description_end = i
                    break
            if description_start is not None and description_end is not None:
                lines[description_start+1:description_end] = [f"{value}\n"]
            else:
                lines.append(f"Begin DESCRIPTION\n{value}\nEND DESCRIPTION\n")
        else:
            # For other keys
            pattern = f"{key.replace('_', ' ').title()}="
            updated = False
            for i, line in enumerate(lines):
                if line.startswith(pattern):
                    lines[i] = f"{pattern}{value}\n"
                    updated = True
                    break
            if not updated:
                logging.error(f"Key '{key}' not found in the plan file.")
                return

        try:
            with open(plan_file_path, 'w') as file:
                file.writelines(lines)
            logging.info(f"Updated {key} in plan file: {plan_file_path}")
        except IOError as e:
            logging.error(f"Error writing to plan file {plan_file_path}: {e}")
            raise

        # Refresh RasPrj dataframes
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
==================================================

File: c:\GH\ras-commander\ras_commander\RasPrj.py
==================================================
"""RasPrj.py

This module provides a class for managing HEC-RAS projects.

Classes:
    RasPrj: A class for managing HEC-RAS projects.

Functions:
    init_ras_project: Initialize a RAS project.
    get_ras_exe: Determine the HEC-RAS executable path based on the input.

DEVELOPER NOTE:
This class is used to initialize a RAS project and is used in conjunction with the RasCmdr class to manage the execution of RAS plans.
By default, the RasPrj class is initialized with the global 'ras' object.
However, you can create multiple RasPrj instances to manage multiple projects.
Do not mix and match global 'ras' object instances and custom instances of RasPrj - it will cause errors.
"""

# Example Terminal Output for RasPrj Functions:
# logging.info("----- INSERT TEXT HERE -----")
import re
from pathlib import Path
import pandas as pd
import logging
from typing import Union, Any, List, Dict, Tuple


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class RasPrj:
    def __init__(self):
        self.initialized = False
        self.boundaries_df = None  # New attribute to store boundary conditions

    def initialize(self, project_folder, ras_exe_path):
        """
        Initialize a RasPrj instance.

        This method sets up the RasPrj instance with the given project folder and RAS executable path.
        It finds the project file, loads project data, sets the initialization flag, and now also
        extracts boundary conditions.

        Args:
            project_folder (str or Path): Path to the HEC-RAS project folder.
            ras_exe_path (str or Path): Path to the HEC-RAS executable.

        Raises:
            ValueError: If no HEC-RAS project file is found in the specified folder.

        Note:
            This method is intended for internal use. External users should use the init_ras_project function instead.
        """
        self.project_folder = Path(project_folder)
        self.prj_file = self.find_ras_prj(self.project_folder)
        if self.prj_file is None:
            logging.error(f"No HEC-RAS project file found in {self.project_folder}")
            raise ValueError(f"No HEC-RAS project file found in {self.project_folder}")
        self.project_name = Path(self.prj_file).stem
        self.ras_exe_path = ras_exe_path
        self._load_project_data()
        self.boundaries_df = self.get_boundary_conditions()  # Extract boundary conditions
        self.initialized = True
        logging.info(f"Initialization complete for project: {self.project_name}")
        logging.info(f"Plan entries: {len(self.plan_df)}, Flow entries: {len(self.flow_df)}, "
                     f"Unsteady entries: {len(self.unsteady_df)}, Geometry entries: {len(self.geom_df)}, "
                     f"Boundary conditions: {len(self.boundaries_df)}")

    def _load_project_data(self):
        """
        Load project data from the HEC-RAS project file.

        This method initializes DataFrames for plan, flow, unsteady, and geometry entries
        by calling the _get_prj_entries method for each entry type.
        """
        # Initialize DataFrames
        self.plan_df = self._get_prj_entries('Plan')
        self.flow_df = self._get_prj_entries('Flow')
        self.unsteady_df = self._get_prj_entries('Unsteady')
        self.geom_df = self._get_prj_entries('Geom')

    def _parse_plan_file(self, plan_file_path):
        """
        Parse a plan file and extract critical information.
        
        Args:
            plan_file_path (Path): Path to the plan file.
        
        Returns:
            dict: Dictionary containing extracted plan information.
        """
        plan_info = {}
        with open(plan_file_path, 'r') as file:
            content = file.read()
            
            # Extract description
            description_match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            if description_match:
                plan_info['description'] = description_match.group(1).strip()
            
            # Extract other critical information
            patterns = {
                'computation_interval': r'Computation Interval=(.+)',
                'dss_file': r'DSS File=(.+)',
                'flow_file': r'Flow File=(.+)',
                'friction_slope_method': r'Friction Slope Method=(.+)',
                'geom_file': r'Geom File=(.+)',
                'mapping_interval': r'Mapping Interval=(.+)',
                'plan_title': r'Plan Title=(.+)',
                'program_version': r'Program Version=(.+)',
                'run_htab': r'Run HTab=(.+)',
                'run_post_process': r'Run PostProcess=(.+)',
                'run_sediment': r'Run Sediment=(.+)',
                'run_unet': r'Run UNet=(.+)',
                'run_wqnet': r'Run WQNet=(.+)',
                'short_identifier': r'Short Identifier=(.+)',
                'simulation_date': r'Simulation Date=(.+)',
                'unet_d1_cores': r'UNET D1 Cores=(.+)',
                'unet_use_existing_ib_tables': r'UNET Use Existing IB Tables=(.+)',
                'unet_1d_methodology': r'UNET 1D Methodology=(.+)',
                'unet_d2_solver_type': r'UNET D2 SolverType=(.+)',
                'unet_d2_name': r'UNET D2 Name=(.+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    plan_info[key] = match.group(1).strip()
        
        return plan_info
    
    def _get_prj_entries(self, entry_type):
        """
        Extract entries of a specific type from the HEC-RAS project file.

        Args:
            entry_type (str): The type of entry to extract (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the extracted entries.

        Note:
            This method reads the project file and extracts entries matching the specified type.
            For 'Unsteady' entries, it parses additional information from the unsteady file.
        """
        entries = []
        pattern = re.compile(rf"{entry_type} File=(\w+)")

        try:
            with open(self.prj_file, 'r') as file:
                for line in file:
                    match = pattern.match(line.strip())
                    if match:
                        file_name = match.group(1)
                        full_path = str(self.project_folder / f"{self.project_name}.{file_name}")
                        entry = {
                            f'{entry_type.lower()}_number': file_name[1:],
                            'full_path': full_path
                        }

                        if entry_type == 'Plan':
                            plan_info = self._parse_plan_file(Path(full_path))
                            entry.update(plan_info)
                            
                            # Add HDF results path if it exists
                            hdf_results_path = self.project_folder / f"{self.project_name}.p{file_name[1:]}.hdf"
                            entry['HDF_Results_Path'] = str(hdf_results_path) if hdf_results_path.exists() else None

                        if entry_type == 'Unsteady':
                            unsteady_info = self._parse_unsteady_file(Path(full_path))
                            entry.update(unsteady_info)

                        entries.append(entry)
        except Exception as e:
            logging.exception(f"Failed to read project file {self.prj_file}: {e}")
            raise

        return pd.DataFrame(entries)

    def _parse_unsteady_file(self, unsteady_file_path):
        """
        Parse an unsteady flow file and extract critical information.
        
        Args:
            unsteady_file_path (Path): Path to the unsteady flow file.
        
        Returns:
            dict: Dictionary containing extracted unsteady flow information.
        """
        unsteady_info = {}
        with open(unsteady_file_path, 'r') as file:
            content = file.read()
            
            # Extract critical information
            patterns = {
                'flow_title': r'Flow Title=(.+)',
                'program_version': r'Program Version=(.+)',
                'use_restart': r'Use Restart=(.+)',
                'precipitation_mode': r'Precipitation Mode=(.+)',
                'wind_mode': r'Wind Mode=(.+)',
                'precipitation_bc_mode': r'Met BC=Precipitation\|Mode=(.+)',
                'evapotranspiration_bc_mode': r'Met BC=Evapotranspiration\|Mode=(.+)',
                'precipitation_expanded_view': r'Met BC=Precipitation\|Expanded View=(.+)',
                'precipitation_constant_units': r'Met BC=Precipitation\|Constant Units=(.+)',
                'precipitation_gridded_source': r'Met BC=Precipitation\|Gridded Source=(.+)'
            }
            
            for key, pattern in patterns.items():
                match = re.search(pattern, content)
                if match:
                    unsteady_info[key] = match.group(1).strip()
        
        return unsteady_info

    @property
    def is_initialized(self):
        """
        Check if the RasPrj instance has been initialized.

        Returns:
            bool: True if the instance has been initialized, False otherwise.
        """
        return self.initialized

    def check_initialized(self):
        """
        Ensure that the RasPrj instance has been initialized.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        if not self.initialized:
            logging.error("Project not initialized. Call init_ras_project() first.")
            raise RuntimeError("Project not initialized. Call init_ras_project() first.")

    @staticmethod
    def find_ras_prj(folder_path):
        """
        Find the appropriate HEC-RAS project file (.prj) in the given folder.
        
        Parameters:
        folder_path (str or Path): Path to the folder containing HEC-RAS files.
        
        Returns:
        Path: The full path of the selected .prj file or None if no suitable file is found.
        """
        folder_path = Path(folder_path)
        prj_files = list(folder_path.glob("*.prj"))
        rasmap_files = list(folder_path.glob("*.rasmap"))
        if len(prj_files) == 1:
            logging.info(f"Single .prj file found: {prj_files[0]}")
            return prj_files[0].resolve()
        if len(prj_files) > 1:
            if len(rasmap_files) == 1:
                base_filename = rasmap_files[0].stem
                prj_file = folder_path / f"{base_filename}.prj"
                if prj_file.exists():
                    logging.info(f"Matched .prj file based on .rasmap: {prj_file}")
                    return prj_file.resolve()
            for prj_file in prj_files:
                try:
                    with open(prj_file, 'r') as file:
                        content = file.read()
                        if "Proj Title=" in content:
                            logging.info(f".prj file with 'Proj Title=' found: {prj_file}")
                            return prj_file.resolve()
                except Exception as e:
                    logging.warning(f"Failed to read .prj file {prj_file}: {e}")
                    continue
        logging.warning("No suitable .prj file found after all checks.")
        return None

    def get_project_name(self):
        """
        Get the name of the HEC-RAS project.

        Returns:
            str: The name of the project.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self.project_name

    def get_prj_entries(self, entry_type):
        """
        Get entries of a specific type from the HEC-RAS project.

        Args:
            entry_type (str): The type of entry to retrieve (e.g., 'Plan', 'Flow', 'Unsteady', 'Geom').

        Returns:
            pd.DataFrame: A DataFrame containing the requested entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries(entry_type)

    def get_plan_entries(self):
        """
        Get all plan entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all plan entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Plan')

    def get_flow_entries(self):
        """
        Get all flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Flow')

    def get_unsteady_entries(self):
        """
        Get all unsteady flow entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all unsteady flow entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Unsteady')

    def get_geom_entries(self):
        """
        Get all geometry entries from the HEC-RAS project.

        Returns:
            pd.DataFrame: A DataFrame containing all geometry entries.

        Raises:
            RuntimeError: If the project has not been initialized.
        """
        self.check_initialized()
        return self._get_prj_entries('Geom')
    
    def get_hdf_entries(self):
        """
        Get HDF entries for plans that have results.
        
        Returns:
        pd.DataFrame: A DataFrame containing plan entries with HDF results.
                  Returns an empty DataFrame if no HDF entries are found.
        """
        self.check_initialized()
        
        # Filter the plan_df to include only entries with existing HDF results
        hdf_entries = self.plan_df[self.plan_df['HDF_Results_Path'].notna()].copy()
        
        # If no HDF entries are found, log the information
        if hdf_entries.empty:
            logging.info("No HDF entries found.")
            return pd.DataFrame(columns=self.plan_df.columns)
        
        logging.info(f"Found {len(hdf_entries)} HDF entries.")
        return hdf_entries
    
    def print_data(self):
        """Print all RAS Object data for this instance."""
        self.check_initialized()
        logging.info(f"--- Data for {self.project_name} ---")
        logging.info(f"Project folder: {self.project_folder}")
        logging.info(f"PRJ file: {self.prj_file}")
        logging.info(f"HEC-RAS executable: {self.ras_exe_path}")
        logging.info("Plan files:")
        logging.info(f"\n{self.plan_df}")
        logging.info("Flow files:")
        logging.info(f"\n{self.flow_df}")
        logging.info("Unsteady flow files:")
        logging.info(f"\n{self.unsteady_df}")
        logging.info("Geometry files:")
        logging.info(f"\n{self.geom_df}")
        logging.info("HDF entries:")
        logging.info(f"\n{self.get_hdf_entries()}")
        logging.info("Boundary conditions:")
        logging.info(f"\n{self.boundaries_df}")
        logging.info("----------------------------")


    @staticmethod
    def get_plan_value(
        plan_number_or_path: Union[str, Path],
        key: str,
        ras_object=None
    ) -> Any:
        """
        Retrieve a specific value from a HEC-RAS plan file.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        key (str): The key to retrieve from the plan file
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.

        Returns:
        Any: The value associated with the specified key

        Raises:
        ValueError: If an invalid key is provided or if the plan file is not found
        IOError: If there's an error reading the plan file

        Note: See the docstring of update_plan_file for a full list of available keys and their types.

        Example:
        >>> computation_interval = RasUtils.get_plan_value("01", "computation_interval")
        >>> print(f"Computation interval: {computation_interval}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        valid_keys = {
            'description', 'computation_interval', 'dss_file', 'flow_file', 'friction_slope_method',
            'geom_file', 'mapping_interval', 'plan_file', 'plan_title', 'program_version',
            'run_htab', 'run_post_process', 'run_sediment', 'run_unet', 'run_wqnet',
            'short_identifier', 'simulation_date', 'unet_d1_cores', 'unet_use_existing_ib_tables',
            'unet_1d_methodology', 'unet_d2_solver_type', 'unet_d2_name'
        }

        if key not in valid_keys:
            raise ValueError(f"Invalid key: {key}. Valid keys are: {', '.join(valid_keys)}")

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                raise ValueError(f"Plan file not found: {plan_file_path}")

        try:
            with open(plan_file_path, 'r') as file:
                content = file.read()
        except IOError as e:
            logging.error(f"Error reading plan file {plan_file_path}: {e}")
            raise

        if key == 'description':
            import re
            match = re.search(r'Begin DESCRIPTION(.*?)END DESCRIPTION', content, re.DOTALL)
            return match.group(1).strip() if match else None
        else:
            pattern = f"{key.replace('_', ' ').title()}=(.*)"
            import re
            match = re.search(pattern, content)
            return match.group(1).strip() if match else None

    def get_boundary_conditions(self) -> pd.DataFrame:
        """
        Extract boundary conditions from unsteady flow files and create a DataFrame.

        This method parses unsteady flow files to extract boundary condition information.
        It creates a DataFrame with structured data for known boundary condition types
        and parameters, and associates this information with the corresponding unsteady flow file.

        Note:
        Any lines in the boundary condition blocks that are not explicitly parsed and
        incorporated into the DataFrame are captured in a multi-line string. This string
        is logged at the DEBUG level for each boundary condition. This feature is crucial
        for developers incorporating new boundary condition types or parameters, as it
        allows them to see what information might be missing from the current parsing logic.

        Returns:
            pd.DataFrame: A DataFrame containing detailed boundary condition information,
                          linked to the unsteady flow files.

        Usage:
            To see the unparsed lines, set the logging level to DEBUG before calling this method:
            
            import logging
            logging.getLogger().setLevel(logging.DEBUG)
            
            boundaries_df = ras_project.get_boundary_conditions()
        """
        boundary_data = []
        
        for _, row in self.unsteady_df.iterrows():
            unsteady_file_path = row['full_path']
            unsteady_number = row['unsteady_number']
            
            with open(unsteady_file_path, 'r') as file:
                content = file.read()
                
            bc_blocks = re.split(r'(?=Boundary Location=)', content)[1:]
            
            for i, block in enumerate(bc_blocks, 1):
                bc_info, unparsed_lines = self._parse_boundary_condition(block, unsteady_number, i)
                boundary_data.append(bc_info)
                
                if unparsed_lines:
                    logging.debug(f"Unparsed lines for boundary condition {i} in unsteady file {unsteady_number}:\n{unparsed_lines}")
        
        boundaries_df = pd.DataFrame(boundary_data)
        
        # Merge with unsteady_df to get relevant unsteady flow file information
        merged_df = pd.merge(boundaries_df, self.unsteady_df, 
                             left_on='unsteady_number', right_on='unsteady_number', how='left')
        
        return merged_df

    def _parse_boundary_condition(self, block: str, unsteady_number: str, bc_number: int) -> Tuple[Dict, str]:
        lines = block.split('\n')
        bc_info = {
            'unsteady_number': unsteady_number,
            'boundary_condition_number': bc_number
        }
        
        parsed_lines = set()
        
        # Parse Boundary Location
        boundary_location = lines[0].split('=')[1].strip()
        fields = [field.strip() for field in boundary_location.split(',')]
        bc_info.update({
            'river_reach_name': fields[0] if len(fields) > 0 else '',
            'river_station': fields[1] if len(fields) > 1 else '',
            'storage_area_name': fields[2] if len(fields) > 2 else '',
            'pump_station_name': fields[3] if len(fields) > 3 else ''
        })
        parsed_lines.add(0)
        
        # Determine BC Type
        bc_types = {
            'Flow Hydrograph=': 'Flow Hydrograph',
            'Lateral Inflow Hydrograph=': 'Lateral Inflow Hydrograph',
            'Uniform Lateral Inflow Hydrograph=': 'Uniform Lateral Inflow Hydrograph',
            'Stage Hydrograph=': 'Stage Hydrograph',
            'Friction Slope=': 'Normal Depth',
            'Gate Name=': 'Gate Opening'
        }
        
        bc_info['bc_type'] = 'Unknown'
        bc_info['hydrograph_type'] = None
        for i, line in enumerate(lines[1:], 1):
            for key, bc_type in bc_types.items():
                if line.startswith(key):
                    bc_info['bc_type'] = bc_type
                    if 'Hydrograph' in bc_type:
                        bc_info['hydrograph_type'] = bc_type
                    parsed_lines.add(i)
                    break
            if bc_info['bc_type'] != 'Unknown':
                break
        
        # Parse other fields
        known_fields = ['Interval', 'DSS Path', 'Use DSS', 'Use Fixed Start Time', 'Fixed Start Date/Time',
                        'Is Critical Boundary', 'Critical Boundary Flow', 'DSS File']
        for i, line in enumerate(lines):
            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                if key in known_fields:
                    bc_info[key] = value.strip()
                    parsed_lines.add(i)
        
        # Handle hydrograph values
        bc_info['hydrograph_num_values'] = 0
        if bc_info['hydrograph_type']:
            hydrograph_key = f"{bc_info['hydrograph_type']}="
            hydrograph_line = next((line for i, line in enumerate(lines) if line.startswith(hydrograph_key)), None)
            if hydrograph_line:
                hydrograph_index = lines.index(hydrograph_line)
                values_count = int(hydrograph_line.split('=')[1].strip())
                bc_info['hydrograph_num_values'] = values_count
                if values_count > 0:
                    values = ' '.join(lines[hydrograph_index + 1:]).split()[:values_count]
                    bc_info['hydrograph_values'] = values
                    parsed_lines.update(range(hydrograph_index, hydrograph_index + (values_count // 5) + 2))
        
        # Collect unparsed lines
        unparsed_lines = '\n'.join(line for i, line in enumerate(lines) if i not in parsed_lines and line.strip())
        
        return bc_info, unparsed_lines


# Create a global instance named 'ras'
ras = RasPrj()

# END OF CLASS DEFINITION




# START OF FUNCTION DEFINITIONS


def init_ras_project(ras_project_folder, ras_version, ras_instance=None):
    """
    Initialize a RAS project.

    USE THIS FUNCTION TO INITIALIZE A RAS PROJECT, NOT THE INITIALIZE METHOD OF THE RasPrj CLASS.
    The initialize method of the RasPrj class only modifies the global 'ras' object.

    This function creates or initializes a RasPrj instance, providing a safer and more
    flexible interface than directly using the 'initialize' method.

    Parameters:
    -----------
    ras_project_folder : str
        The path to the RAS project folder.
    ras_version : str
        The version of RAS to use (e.g., "6.5").
        The version can also be a full path to the Ras.exe file. (Useful when calling ras objects for folder copies.)
    ras_instance : RasPrj, optional
        An instance of RasPrj to initialize. If None, the global 'ras' instance is used.

    Returns:
    --------
    RasPrj
        An initialized RasPrj instance.

    Usage:
    ------
    1. For general use with a single project:
        init_ras_project("/path/to/project", "6.5")
        # Use the global 'ras' object after initialization

    2. For managing multiple projects:
        project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
        project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

    Notes:
    ------
    - This function is preferred over directly calling the 'initialize' method.
    - It supports both the global 'ras' object and custom instances.
    - Be consistent in your approach: stick to either the global 'ras' object
      or custom instances throughout your script or application.
    - Document your choice of approach clearly in your code.

    Warnings:
    ---------
    Avoid mixing use of the global 'ras' object and custom instances to prevent
    confusion and potential bugs.
    """
    logging.info(f"Initializing project in folder: {ras_project_folder}")
    logging.info(f"Using ras_instance with id: {id(ras_instance)}")
    


    if not Path(ras_project_folder).exists():
        logging.error(f"The specified RAS project folder does not exist: {ras_project_folder}. Please check the path and try again.")
        raise FileNotFoundError(f"The specified RAS project folder does not exist: {ras_project_folder}. Please check the path and try again.")

    ras_exe_path = get_ras_exe(ras_version)

    if ras_instance is None:
        logging.info("Initializing global 'ras' object via init_ras_project function.")
        ras_instance = ras
    elif not isinstance(ras_instance, RasPrj):
        logging.error("Provided ras_instance is not an instance of RasPrj.")
        raise TypeError("ras_instance must be an instance of RasPrj or None.")

    # Initialize the RasPrj instance
    ras_instance.initialize(ras_project_folder, ras_exe_path)
    
    logging.info(f"Project initialized. ras_instance project folder: {ras_instance.project_folder}")
    return ras_instance


def get_ras_exe(ras_version):
    """
    Determine the HEC-RAS executable path based on the input.
    
    Args:
    ras_version (str): Either a version number or a full path to the HEC-RAS executable.
    
    Returns:
    str: The full path to the HEC-RAS executable.
    
    Raises:
    ValueError: If the input is neither a valid version number nor a valid file path.
    FileNotFoundError: If the executable file does not exist at the specified or constructed path.
    """
    ras_version_numbers = [
        "6.5", "6.4.1", "6.3.1", "6.3", "6.2", "6.1", "6.0",
        "5.0.7", "5.0.6", "5.0.5", "5.0.4", "5.0.3", "5.0.1", "5.0",
        "4.1", "4.0", "3.1.3", "3.1.2", "3.1.1", "3.0", "2.2"
    ]
    
    hecras_path = Path(ras_version)
    
    if hecras_path.is_file() and hecras_path.suffix.lower() == '.exe':
        logging.info(f"HEC-RAS executable found at specified path: {hecras_path}")
        return str(hecras_path)
    
    if ras_version in ras_version_numbers:
        default_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
        if default_path.is_file():
            logging.info(f"HEC-RAS executable found at default path: {default_path}")
            return str(default_path)
        else:
            logging.error(f"HEC-RAS executable not found at the expected path: {default_path}")
            raise FileNotFoundError(f"HEC-RAS executable not found at the expected path: {default_path}")
    
    try:
        version_float = float(ras_version)
        if version_float > max(float(v) for v in ras_version_numbers):
            newer_version_path = Path(f"C:/Program Files (x86)/HEC/HEC-RAS/{ras_version}/Ras.exe")
            if newer_version_path.is_file():
                logging.info(f"Newer version of HEC-RAS executable found at: {newer_version_path}")
                return str(newer_version_path)
            else:
                logging.error("Newer version of HEC-RAS was specified, but the executable was not found.")
                raise FileNotFoundError(
                    f"Newer version of HEC-RAS was specified. Check the version number or pass the full Ras.exe path as the function argument instead of the version number. The script looked for the executable at: {newer_version_path}"
                )
    except ValueError:
        pass
    
    logging.error(
        f"Invalid HEC-RAS version or path: {ras_version}. "
        f"Please provide a valid version number from {ras_version_numbers} "
        "or a full path to the HEC-RAS executable."
    )
    raise ValueError(
        f"Invalid HEC-RAS version or path: {ras_version}. "
        f"Please provide a valid version number from {ras_version_numbers} "
        "or a full path to the HEC-RAS executable."
    )
    
==================================================

File: c:\GH\ras-commander\ras_commander\RasUnsteady.py
==================================================
"""
Operations for handling unsteady flow files in HEC-RAS projects.
"""
from pathlib import Path
from .RasPrj import ras
import logging
import re

# Configure logging at the module level
logging.basicConfig(
    level=logging.INFO,  # Set to DEBUG for more detailed output
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # Logs to console
        # Uncomment the next line to enable logging to a file
        # logging.FileHandler('ras_unsteady.log')
    ]
)

class RasUnsteady:
    """
    Class for all operations related to HEC-RAS unsteady flow files.
    """
    
    @staticmethod
    def update_unsteady_parameters(unsteady_file, modifications, ras_object=None):
        """
        Modify parameters in an unsteady flow file.
        
        Parameters:
        unsteady_file (str): Full path to the unsteady flow file
        modifications (dict): Dictionary of modifications to apply, where keys are parameter names and values are new values
        ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
        
        Returns:
        None

        Note:
            This function updates the ras object's unsteady dataframe after modifying the unsteady flow file.
        
        Example:
            from ras_commander import RasCmdr
            
            # Initialize RAS project
            ras_cmdr = RasCmdr()
            ras_cmdr.init_ras_project(project_folder, ras_version)
            
            # Update unsteady parameters
            unsteady_file = r"path/to/unsteady_file.u01"
            modifications = {"Parameter1": "NewValue1", "Parameter2": "NewValue2"}
            RasUnsteady.update_unsteady_parameters(unsteady_file, modifications, ras_object=ras_cmdr.ras)
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        unsteady_path = Path(unsteady_file)
        try:
            with open(unsteady_path, 'r') as f:
                lines = f.readlines()
            logging.debug(f"Successfully read unsteady flow file: {unsteady_path}")
        except FileNotFoundError:
            logging.error(f"Unsteady flow file not found: {unsteady_path}")
            raise FileNotFoundError(f"Unsteady flow file not found: {unsteady_path}")
        except PermissionError:
            logging.error(f"Permission denied when reading unsteady flow file: {unsteady_path}")
            raise PermissionError(f"Permission denied when reading unsteady flow file: {unsteady_path}")
        
        updated = False
        for i, line in enumerate(lines):
            for param, new_value in modifications.items():
                if line.startswith(f"{param}="):
                    old_value = line.strip().split('=')[1]
                    lines[i] = f"{param}={new_value}\n"
                    updated = True
                    logging.info(f"Updated {param} from {old_value} to {new_value}")
        
        if updated:
            try:
                with open(unsteady_path, 'w') as f:
                    f.writelines(lines)
                logging.debug(f"Successfully wrote modifications to unsteady flow file: {unsteady_path}")
            except PermissionError:
                logging.error(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
                raise PermissionError(f"Permission denied when writing to unsteady flow file: {unsteady_path}")
            except IOError as e:
                logging.error(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
                raise IOError(f"Error writing to unsteady flow file: {unsteady_path}. {str(e)}")
            logging.info(f"Applied modifications to {unsteady_file}")
        else:
            logging.warning(f"No matching parameters found in {unsteady_file}")
    
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

==================================================

File: c:\GH\ras-commander\ras_commander\RasUtils.py
==================================================
"""
Utility functions for the ras-commander library.
"""
import os
import shutil
import logging
import time
from pathlib import Path
from .RasPrj import ras
from typing import Union, Optional, Dict
import pandas as pd
import numpy as np

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class RasUtils:
    """
    A class containing utility functions for the ras-commander library.
    When integrating new functions that do not clearly fit into other classes, add them here.
    """

    @staticmethod
    def create_backup(file_path: Path, backup_suffix: str = "_backup", ras_object=None) -> Path:
        """
        Create a backup of the specified file.

        Parameters:
        file_path (Path): Path to the file to be backed up
        backup_suffix (str): Suffix to append to the backup file name
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the created backup file

        Example:
        >>> backup_path = RasUtils.create_backup(Path("project.prj"))
        >>> print(f"Backup created at: {backup_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        original_path = Path(file_path)
        backup_path = original_path.with_name(f"{original_path.stem}{backup_suffix}{original_path.suffix}")
        try:
            shutil.copy2(original_path, backup_path)
            logging.info(f"Backup created: {backup_path}")
        except Exception as e:
            logging.error(f"Failed to create backup for {original_path}: {e}")
            raise
        return backup_path

    @staticmethod
    def restore_from_backup(backup_path: Path, remove_backup: bool = True, ras_object=None) -> Path:
        """
        Restore a file from its backup.

        Parameters:
        backup_path (Path): Path to the backup file
        remove_backup (bool): Whether to remove the backup file after restoration
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the restored file

        Example:
        >>> restored_path = RasUtils.restore_from_backup(Path("project_backup.prj"))
        >>> print(f"File restored to: {restored_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        backup_path = Path(backup_path)
        if '_backup' not in backup_path.stem:
            logging.error(f"Backup suffix '_backup' not found in {backup_path.name}")
            raise ValueError(f"Backup suffix '_backup' not found in {backup_path.name}")
        
        original_stem = backup_path.stem.rsplit('_backup', 1)[0]
        original_path = backup_path.with_name(f"{original_stem}{backup_path.suffix}")
        try:
            shutil.copy2(backup_path, original_path)
            logging.info(f"File restored: {original_path}")
            if remove_backup:
                backup_path.unlink()
                logging.info(f"Backup removed: {backup_path}")
        except Exception as e:
            logging.error(f"Failed to restore from backup {backup_path}: {e}")
            raise
        return original_path

    @staticmethod
    def create_directory(directory_path: Path, ras_object=None) -> Path:
        """
        Ensure that a directory exists, creating it if necessary.

        Parameters:
        directory_path (Path): Path to the directory
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the ensured directory

        Example:
        >>> ensured_dir = RasUtils.create_directory(Path("output"))
        >>> print(f"Directory ensured: {ensured_dir}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(directory_path)
        try:
            path.mkdir(parents=True, exist_ok=True)
            logging.info(f"Directory ensured: {path}")
        except Exception as e:
            logging.error(f"Failed to create directory {path}: {e}")
            raise
        return path

    @staticmethod
    def find_files_by_extension(extension: str, ras_object=None) -> list:
        """
        List all files in the project directory with a specific extension.

        Parameters:
        extension (str): File extension to filter (e.g., '.prj')
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        list: List of file paths matching the extension

        Example:
        >>> prj_files = RasUtils.find_files_by_extension('.prj')
        >>> print(f"Found {len(prj_files)} .prj files")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        try:
            files = list(ras_obj.project_folder.glob(f"*{extension}"))
            file_list = [str(file) for file in files]
            logging.info(f"Found {len(file_list)} files with extension '{extension}' in {ras_obj.project_folder}")
            return file_list
        except Exception as e:
            logging.error(f"Failed to find files with extension '{extension}': {e}")
            raise

    @staticmethod
    def get_file_size(file_path: Path, ras_object=None) -> Optional[int]:
        """
        Get the size of a file in bytes.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[int]: Size of the file in bytes, or None if the file does not exist

        Example:
        >>> size = RasUtils.get_file_size(Path("project.prj"))
        >>> print(f"File size: {size} bytes")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                size = path.stat().st_size
                logging.info(f"Size of {path}: {size} bytes")
                return size
            except Exception as e:
                logging.error(f"Failed to get size for {path}: {e}")
                raise
        else:
            logging.warning(f"File not found: {path}")
            return None

    @staticmethod
    def get_file_modification_time(file_path: Path, ras_object=None) -> Optional[float]:
        """
        Get the last modification time of a file.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[float]: Last modification time as a timestamp, or None if the file does not exist

        Example:
        >>> mtime = RasUtils.get_file_modification_time(Path("project.prj"))
        >>> print(f"Last modified: {mtime}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                mtime = path.stat().st_mtime
                logging.info(f"Last modification time of {path}: {mtime}")
                return mtime
            except Exception as e:
                logging.error(f"Failed to get modification time for {path}: {e}")
                raise
        else:
            logging.warning(f"File not found: {path}")
            return None

    @staticmethod
    def get_plan_path(current_plan_number_or_path: Union[str, Path], ras_object=None) -> Path:
        """
        Get the path for a plan file with a given plan number or path.

        Parameters:
        current_plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Full path to the plan file

        Example:
        >>> plan_path = RasUtils.get_plan_path(1)
        >>> print(f"Plan file path: {plan_path}")
        >>> plan_path = RasUtils.get_plan_path("path/to/plan.p01")
        >>> print(f"Plan file path: {plan_path}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        plan_path = Path(current_plan_number_or_path)
        if plan_path.is_file():
            logging.info(f"Using provided plan file path: {plan_path}")
            return plan_path
        
        try:
            current_plan_number = f"{int(current_plan_number_or_path):02d}"  # Ensure two-digit format
            logging.info(f"Converted plan number to two-digit format: {current_plan_number}")
        except ValueError:
            logging.error(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
            raise ValueError(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
        
        plan_name = f"{ras_obj.project_name}.p{current_plan_number}"
        full_plan_path = ras_obj.project_folder / plan_name
        logging.info(f"Constructed plan file path: {full_plan_path}")
        return full_plan_path

    @staticmethod
    def remove_with_retry(
        path: Path,
        max_attempts: int = 5,
        initial_delay: float = 1.0,
        is_folder: bool = True,
        ras_object=None
    ) -> bool:
        """
        Attempts to remove a file or folder with retry logic and exponential backoff.

        Parameters:
        path (Path): Path to the file or folder to be removed.
        max_attempts (int): Maximum number of removal attempts.
        initial_delay (float): Initial delay between attempts in seconds.
        is_folder (bool): If True, the path is treated as a folder; if False, it's treated as a file.
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        bool: True if the file or folder was successfully removed, False otherwise.

        Example:
        >>> success = RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
        >>> print(f"Removal successful: {success}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        path = Path(path)
        for attempt in range(1, max_attempts + 1):
            try:
                if path.exists():
                    if is_folder:
                        shutil.rmtree(path)
                        logging.info(f"Folder removed: {path}")
                    else:
                        path.unlink()
                        logging.info(f"File removed: {path}")
                else:
                    logging.info(f"Path does not exist, nothing to remove: {path}")
                return True
            except PermissionError as pe:
                if attempt < max_attempts:
                    delay = initial_delay * (2 ** (attempt - 1))  # Exponential backoff
                    logging.warning(
                        f"PermissionError on attempt {attempt} to remove {path}: {pe}. "
                        f"Retrying in {delay} seconds..."
                    )
                    time.sleep(delay)
                else:
                    logging.error(
                        f"Failed to remove {path} after {max_attempts} attempts due to PermissionError: {pe}. Skipping."
                    )
                    return False
            except Exception as e:
                logging.error(f"Failed to remove {path} on attempt {attempt}: {e}")
                return False
        return False

    @staticmethod
    def update_plan_file(
        plan_number_or_path: Union[str, Path],
        file_type: str,
        entry_number: int,
        ras_object=None
    ) -> None:
        """
        Update a plan file with a new file reference.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        file_type (str): Type of file to update ('Geom', 'Flow', or 'Unsteady')
        entry_number (int): Number (from 1 to 99) to set
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Raises:
        ValueError: If an invalid file_type is provided
        FileNotFoundError: If the plan file doesn't exist

        Example:
        >>> RasUtils.update_plan_file(1, "Geom", 2)
        >>> RasUtils.update_plan_file("path/to/plan.p01", "Geom", 2)
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        valid_file_types = {'Geom': 'g', 'Flow': 'f', 'Unsteady': 'u'}
        if file_type not in valid_file_types:
            logging.error(
                f"Invalid file_type '{file_type}'. Expected one of: {', '.join(valid_file_types.keys())}"
            )
            raise ValueError(
                f"Invalid file_type. Expected one of: {', '.join(valid_file_types.keys())}"
            )

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                logging.error(f"Plan file not found: {plan_file_path}")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}")
        
        file_prefix = valid_file_types[file_type]
        search_pattern = f"{file_type} File="
        formatted_entry_number = f"{int(entry_number):02d}"  # Ensure two-digit format

        try:
            RasUtils.check_file_access(plan_file_path, 'r')
            with plan_file_path.open('r') as file:
                lines = file.readlines()
        except Exception as e:
            logging.error(f"Failed to read plan file {plan_file_path}: {e}")
            raise

        updated = False
        for i, line in enumerate(lines):
            if line.startswith(search_pattern):
                lines[i] = f"{search_pattern}{file_prefix}{formatted_entry_number}\n"
                logging.info(
                    f"Updated {file_type} File in {plan_file_path} to {file_prefix}{formatted_entry_number}"
                )
                updated = True
                break

        if not updated:
            logging.warning(
                f"Search pattern '{search_pattern}' not found in {plan_file_path}. No update performed."
            )

        try:
            with plan_file_path.open('w') as file:
                file.writelines(lines)
            logging.info(f"Successfully updated plan file: {plan_file_path}")
        except Exception as e:
            logging.error(f"Failed to write updates to plan file {plan_file_path}: {e}")
            raise

        # Refresh RasPrj dataframes
        try:
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
            logging.info("RAS object dataframes have been refreshed.")
        except Exception as e:
            logging.error(f"Failed to refresh RasPrj dataframes: {e}")
            raise

    @staticmethod
    def check_file_access(file_path: Path, mode: str = 'r') -> None:
        """
        Check if the file can be accessed with the specified mode.

        Parameters:
        file_path (Path): Path to the file
        mode (str): Mode to check ('r' for read, 'w' for write, etc.)

        Raises:
        FileNotFoundError: If the file does not exist
        PermissionError: If the required permissions are not met
        """
        path = Path(file_path)
        if not path.exists():
            logging.error(f"File not found: {file_path}")
            raise FileNotFoundError(f"File not found: {file_path}")
        
        if mode in ('r', 'rb'):
            if not os.access(path, os.R_OK):
                logging.error(f"Read permission denied for file: {file_path}")
                raise PermissionError(f"Read permission denied for file: {file_path}")
            else:
                logging.debug(f"Read access granted for file: {file_path}")
        
        if mode in ('w', 'wb', 'a', 'ab'):
            parent_dir = path.parent
            if not os.access(parent_dir, os.W_OK):
                logging.error(f"Write permission denied for directory: {parent_dir}")
                raise PermissionError(f"Write permission denied for directory: {parent_dir}")
            else:
                logging.debug(f"Write access granted for directory: {parent_dir}")




#  --------------------------   Functions below were imported from funkshuns.py  --------------------------
#  --------------------------   Converted to ras-commander style guide   ----------------------------------




    @staticmethod
    def convert_to_dataframe(data_source: Union[pd.DataFrame, Path], **kwargs) -> pd.DataFrame:
        """
        Converts input to a pandas DataFrame. Supports existing DataFrames or file paths (CSV, Excel, TSV, Parquet).

        Args:
            data_source (Union[pd.DataFrame, Path]): The input to convert to a DataFrame. Can be a file path or an existing DataFrame.
            **kwargs: Additional keyword arguments to pass to pandas read functions.

        Returns:
            pd.DataFrame: The resulting DataFrame.

        Raises:
            NotImplementedError: If the file type is unsupported or input type is invalid.

        Example:
            >>> df = RasUtils.convert_to_dataframe(Path("data.csv"))
            >>> print(type(df))
            <class 'pandas.core.frame.DataFrame'>
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        if isinstance(data_source, pd.DataFrame):
            return data_source.copy()
        elif isinstance(data_source, Path):
            ext = data_source.suffix.replace('.', '', 1)
            if ext == 'csv':
                return pd.read_csv(data_source, **kwargs)
            elif ext.startswith('x'):
                return pd.read_excel(data_source, **kwargs)
            elif ext == "tsv":
                return pd.read_csv(data_source, sep="\t", **kwargs)
            elif ext in ["parquet", "pq", "parq"]:
                return pd.read_parquet(data_source, **kwargs)
            else:
                raise NotImplementedError(f"Unsupported file type {ext}. Should be one of csv, tsv, parquet, or xlsx.")
        else:
            raise NotImplementedError(f"Unsupported type {type(data_source)}. Only file path / existing DataFrame supported at this time")

    @staticmethod
    def save_to_excel(dataframe: pd.DataFrame, excel_path: Path, **kwargs) -> None:
        """
        Saves a pandas DataFrame to an Excel file with retry functionality.

        Args:
            dataframe (pd.DataFrame): The DataFrame to save.
            excel_path (Path): The path to the Excel file where the DataFrame will be saved.
            **kwargs: Additional keyword arguments passed to `DataFrame.to_excel()`.

        Raises:
            IOError: If the file cannot be saved after multiple attempts.

        Example:
            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
            >>> RasUtils.save_to_excel(df, Path('output.xlsx'))
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        saved = False
        max_attempts = 3
        attempt = 0

        while not saved and attempt < max_attempts:
            try:
                dataframe.to_excel(excel_path, **kwargs)
                print(f'DataFrame successfully saved to \n{excel_path}')
                saved = True
            except IOError as e:
                attempt += 1
                if attempt < max_attempts:
                    print(f"Error saving file. Attempt {attempt} of {max_attempts}. Please close the Excel document if it's open.")
                else:
                    raise IOError(f"Failed to save {excel_path} after {max_attempts} attempts. Last error: {str(e)}")










#####  Statistical Metrics #####


    @staticmethod
    def calculate_rmse(observed_values: np.ndarray, predicted_values: np.ndarray, normalized: bool = True) -> float:
        """
        Calculate the Root Mean Squared Error (RMSE) between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            normalized (bool, optional): Whether to normalize RMSE to a percentage of observed_values. Defaults to True.

        Returns:
            float: The calculated RMSE value.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_rmse(observed, predicted)
            0.06396394
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        rmse = np.sqrt(np.mean((predicted_values - observed_values) ** 2))
        
        if normalized:
            rmse = rmse / np.abs(np.mean(observed_values))
        
        return rmse

    @staticmethod
    def calculate_percent_bias(observed_values: np.ndarray, predicted_values: np.ndarray, as_percentage: bool = False) -> float:
        """
        Calculate the Percent Bias between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            as_percentage (bool, optional): If True, return bias as a percentage. Defaults to False.

        Returns:
            float: The calculated Percent Bias.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)
            3.33333333
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        multiplier = 100 if as_percentage else 1
        
        percent_bias = multiplier * (np.mean(predicted_values) - np.mean(observed_values)) / np.mean(observed_values)
        
        return percent_bias

    @staticmethod
    def calculate_error_metrics(observed_values: np.ndarray, predicted_values: np.ndarray) -> Dict[str, float]:
        """
        Compute a trio of error metrics: correlation, RMSE, and Percent Bias.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.

        Returns:
            Dict[str, float]: A dictionary containing correlation ('cor'), RMSE ('rmse'), and Percent Bias ('pb').

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_error_metrics(observed, predicted)
            {'cor': 0.9993, 'rmse': 0.06396, 'pb': 0.03333}
            
        Attribution Note: This function is sourced from funkshuns.py by Sean Micek, and converted to the ras-commander style guide.
        """
        correlation = np.corrcoef(observed_values, predicted_values)[0, 1]
        rmse = RasUtils.calculate_rmse(observed_values, predicted_values)
        percent_bias = RasUtils.calculate_percent_bias(observed_values, predicted_values)
        
        return {'cor': correlation, 'rmse': rmse, 'pb': percent_bias}





==================================================

File: c:\GH\ras-commander\ras_commander\_version.py
==================================================
# file generated by setuptools_scm
# don't change, don't track in version control
TYPE_CHECKING = False
if TYPE_CHECKING:
    from typing import Tuple, Union
    VERSION_TUPLE = Tuple[Union[int, str], ...]
else:
    VERSION_TUPLE = object

version: str
__version__: str
__version_tuple__: VERSION_TUPLE
version_tuple: VERSION_TUPLE

__version__ = version = '0.29.dev1+g22e75d4.d20240919'
__version_tuple__ = version_tuple = (0, 29, 'dev1', 'g22e75d4.d20240919')

==================================================

File: c:\GH\ras-commander\ras_commander\__init__.py
==================================================
from importlib.metadata import version, PackageNotFoundError

try:
    __version__ = version("ras-commander")
except PackageNotFoundError:
    # package is not installed
    __version__ = "unknown"

# Import all necessary functions and classes directly
from .RasPrj import ras, init_ras_project, get_ras_exe
from .RasPrj import RasPrj
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUnsteady import RasUnsteady
from .RasCmdr import RasCmdr
from .RasUtils import RasUtils
from .RasExamples import RasExamples
from .RasHdf import RasHdf  # Add this line

# Import all attributes from these modules
from .RasPrj import *
from .RasPlan import *
from .RasGeo import *
from .RasUnsteady import *
from .RasCmdr import *
from .RasUtils import *
from .RasExamples import *
from .RasHdf import *  # Add this line

# Define __all__ to specify what should be imported when using "from ras_commander import *"
__all__ = [
    "ras",
    "init_ras_project",
    "get_ras_exe",
    "RasPrj",
    "RasPlan",
    "RasGeo",
    "RasUnsteady",
    "RasCmdr",
    "RasUtils",
    "RasExamples",
    "RasHdf"  # Add this line
]

==================================================

