File: c:\GH\ras-commander\.cursorrules
==================================================
# RAS Commander (ras-commander) Coding Assistant

## Overview

This Assistant helps you write efficient Python code for HEC-RAS projects using the RAS Commander library. It automates tasks, provides a Pythonic interface, supports flexible execution modes, and offers built-in examples.

**Core Concepts:** RAS Objects, Project Initialization, File Handling (pathlib.Path), Data Management (Pandas), Execution Modes, Utility Functions.

## Classes, Functions and Arguments




Certainly! I'll summarize the decorators, provide tables for each class showing the decorators used and arguments, and give a summary of each class's function.

Decorator Summaries:

1. @log_call: Logs function calls, including entry and exit times, and any exceptions raised.
2. @standardize_input: Standardizes input for HDF file operations, handling different input types and ensuring consistent file paths.
3. @hdf_operation: Handles opening and closing of HDF files, and manages error handling for HDF operations.

Now, lets go through each class:


1. RasPrj Class:

| Function Name | @log_call | @standardize_input | @hdf_operation | Arguments |
|---------------|-----------|--------------------|--------------------|-----------|
| initialize | X | | | project_folder, ras_exe_path |
| _load_project_data | X | | | |
| _get_geom_file_for_plan | X | | | plan_number |
| _parse_plan_file | X | | | plan_file_path |
| _get_prj_entries | X | | | entry_type |
| _parse_unsteady_file | X | | | unsteady_file_path |
| check_initialized | X | | | |
| find_ras_prj | X | | | folder_path |
| get_project_name | X | | | |
| get_prj_entries | X | | | entry_type |
| get_plan_entries | X | | | |
| get_flow_entries | X |
1. RasPrj Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| initialize | X | | project_folder, ras_exe_path |
| _load_project_data | X | | |
| _get_geom_file_for_plan | X | | plan_number |
| _parse_plan_file | X | | plan_file_path |
| _get_prj_entries | X | | entry_type |
| _parse_unsteady_file | X | | unsteady_file_path |
| check_initialized | X | | |
| find_ras_prj | X | | folder_path |
| get_project_name | X | | |
| get_prj_entries | X | | entry_type |
| get_plan_entries | X | | |
| get_flow_entries | X | | |
| get_unsteady_entries | X | | |
| get_geom_entries | X | | |
| get_hdf_entries | X | | |
| print_data | X | | |
| get_plan_value | X | X | plan_number_or_path, key, ras_object |
| get_boundary_conditions | X | | |
| _parse_boundary_condition | X | | block, unsteady_number, bc_number |

2. RasPlan Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| set_geom | X | | plan_number, new_geom, ras_object |
| set_steady | X | | plan_number, new_steady_flow_number, ras_object |
| set_unsteady | X | | plan_number, new_unsteady_flow_number, ras_object |
| set_num_cores | X | | plan_number, num_cores, ras_object |
| set_geom_preprocessor | X | | file_path, run_htab, use_ib_tables, ras_object |
| get_results_path | X | X | plan_number, ras_object |
| get_plan_path | X | X | plan_number, ras_object |
| get_flow_path | X | X | flow_number, ras_object |
| get_unsteady_path | X | X | unsteady_number, ras_object |
| get_geom_path | X | X | geom_number, ras_object |
| clone_plan | X | | template_plan, new_plan_shortid, ras_object |
| clone_unsteady | X | | template_unsteady, ras_object |
| clone_steady | X | | template_flow, ras_object |
| clone_geom | X | | template_geom, ras_object |
| get_next_number | X | | existing_numbers |
| get_plan_value | X | X | plan_number_or_path, key, ras_object |
| update_plan_value | X | X | plan_number_or_path, key, value, ras_object |

3. RasGeo Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| clear_geompre_files | X | | plan_files, ras_object |

4. RasUnsteady Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| update_unsteady_parameters | X | | unsteady_file, modifications, ras_object |

5. RasCmdr Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| compute_plan | X | | plan_number, dest_folder, ras_object, clear_geompre, num_cores, overwrite_dest |
| compute_parallel | X | | plan_number, max_workers, num_cores, clear_geompre, ras_object, dest_folder, overwrite_dest |
| compute_test_mode | X | | plan_number, dest_folder_suffix, clear_geompre, num_cores, ras_object, overwrite_dest |

6. RasUtils Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| create_directory | X | | directory_path, ras_object |
| find_files_by_extension | X | | extension, ras_object |
| get_file_size | X | | file_path, ras_object |
| get_file_modification_time | X | | file_path, ras_object |
| get_plan_path | X | | current_plan_number_or_path, ras_object |
| remove_with_retry | X | | path, max_attempts, initial_delay, is_folder, ras_object |
| update_plan_file | X | | plan_number_or_path, file_type, entry_number, ras_object |
| check_file_access | X | | file_path, mode |
| convert_to_dataframe | X | | data_source, **kwargs |
| save_to_excel | X | | dataframe, excel_path, **kwargs |
| calculate_rmse | X | | observed_values, predicted_values, normalized |
| calculate_percent_bias | X | | observed_values, predicted_values, as_percentage |
| calculate_error_metrics | X | | observed_values, predicted_values |
| update_file | X | | file_path, update_function, *args |
| get_next_number | X | | existing_numbers |
| clone_file | X | | template_path, new_path, update_function, *args |
| update_project_file | X | | prj_file, file_type, new_num, ras_object |
| decode_byte_strings | X | | dataframe |
| perform_kdtree_query | X | | reference_points, query_points, max_distance |
| find_nearest_neighbors | X | | points, max_distance |
| consolidate_dataframe | X | | dataframe, group_by, pivot_columns, level, n_dimensional, aggregation_method |
| find_nearest_value | X | | array, target_value |
| horizontal_distance | X | | coord1, coord2 |

7. HdfBase Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| _get_simulation_start_time | | | hdf_file |
| _get_unsteady_datetimes | | | hdf_file |
| _get_2d_flow_area_names_and_counts | | | hdf_file |
| _parse_ras_datetime | | | datetime_str |
| _parse_ras_simulation_window_datetime | | | datetime_str |
| _parse_duration | | | duration_str |
| _parse_ras_datetime_ms | | | datetime_str |
| _convert_ras_hdf_string | | | value |

8. HdfBndry Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| bc_lines | | X (plan_hdf) | hdf_path |
| breaklines | | X (plan_hdf) | hdf_path |
| refinement_regions | | X (plan_hdf) | hdf_path |
| reference_lines_names | | X (plan_hdf) | hdf_path, mesh_name |
| reference_points_names | | X (plan_hdf) | hdf_path, mesh_name |
| reference_lines | | X (plan_hdf) | hdf_path |
| reference_points | | X (plan_hdf) | hdf_path |
| get_boundary_attributes | | X (plan_hdf) | hdf_path, boundary_type |
| get_boundary_count | | X (plan_hdf) | hdf_path, boundary_type |
| get_boundary_names | | X (plan_hdf) | hdf_path, boundary_type |

9. HdfMesh Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| mesh_area_names | | X (plan_hdf) | hdf_path |
| mesh_areas | | X (geom_hdf) | hdf_path |
| mesh_cell_polygons | | X (geom_hdf) | hdf_path |
| mesh_cell_points | | X (plan_hdf) | hdf_path |
| mesh_cell_faces | | X (plan_hdf) | hdf_path |
| get_geom_2d_flow_area_attrs | | X (geom_hdf) | hdf_path |

10. HdfPlan Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| get_simulation_start_time | X | X (plan_hdf) | hdf_path |
| get_simulation_end_time | X | X (plan_hdf) | hdf_path |
| get_unsteady_datetimes | X | X (plan_hdf) | hdf_path |
| get_plan_info_attrs | X | X (plan_hdf) | hdf_path |
| get_plan_param_attrs | X | X (plan_hdf) | hdf_path |
| get_meteorology_precip_attrs | X | X (plan_hdf) | hdf_path |
| get_geom_attrs | X | X (plan_hdf) | hdf_path |

11. HdfResultsMesh Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| mesh_summary_output | X | X (plan_hdf) | hdf_path, var, round_to |
| mesh_timeseries_output | X | X (plan_hdf) | hdf_path, mesh_name, var, truncate |
| mesh_faces_timeseries_output | X | X (plan_hdf) | hdf_path, mesh_name |
| mesh_cells_timeseries_output | X | X (plan_hdf) | hdf_path, mesh_names, var, truncate, ras_object |
| mesh_last_iter | X | X (plan_hdf) | hdf_path |
| mesh_max_ws | X | X (plan_hdf) | hdf_path, round_to |
| mesh_min_ws | X | X (plan_hdf) | hdf_path, round_to |
| mesh_max_face_v | X | X (plan_hdf) | hdf_path, round_to |
| mesh_min_face_v | X | X (plan_hdf) | hdf_path, round_to |
| mesh_max_ws_err | X | X (plan_hdf) | hdf_path, round_to |
| mesh_max_iter | X | X (plan_hdf) | hdf_path, round_to |

12. HdfResultsPlan Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| get_results_unsteady_attrs | X | X (plan_hdf) | hdf_path |
| get_results_unsteady_summary_attrs | X | X (plan_hdf) | hdf_path |
| get_results_volume_accounting_attrs | X | X (plan_hdf) | hdf_path |
| get_runtime_data | | X (plan_hdf) | hdf_path |
| reference_timeseries_output | X | X (plan_hdf) | hdf_path, reftype |
| reference_lines_timeseries_output | X | X (plan_hdf) | hdf_path |
| reference_points_timeseries_output | X | X (plan_hdf) | hdf_path |
| reference_summary_output | X | X (plan_hdf) | hdf_path, reftype |

13. HdfResultsXsec Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| steady_profile_xs_output | | X (plan_hdf) | hdf_path, var, round_to |
| cross_sections_wsel | | X (plan_hdf) | hdf_path |
| cross_sections_flow | | X (plan_hdf) | hdf_path |
| cross_sections_energy_grade | | X (plan_hdf) | hdf_path |
| cross_sections_additional_enc_station_left | | X (plan_hdf) | hdf_path |
| cross_sections_additional_enc_station_right | | X (plan_hdf) | hdf_path |
| cross_sections_additional_area_total | | X (plan_hdf) | hdf_path |
| cross_sections_additional_velocity_total | | X (plan_hdf) | hdf_path |

14. HdfStruc Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| structures | X | X (geom_hdf) | hdf_path, datetime_to_str |
| get_geom_structures_attrs | X | X (geom_hdf) | hdf_path |

15. HdfUtils Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| get_hdf_filename | | X (plan_hdf) | hdf_input, ras_object |
| get_root_attrs | | X (plan_hdf) | hdf_path |
| get_attrs | | X (plan_hdf) | hdf_path, attr_path |
| get_hdf_paths_with_properties | | X (plan_hdf) | hdf_path |
| get_group_attributes_as_df | | X (plan_hdf) | hdf_path, group_path |
| get_2d_flow_area_names_and_counts | | X (plan_hdf) | hdf_path |
| projection | | X (plan_hdf) | hdf_path |

16. HdfXsec Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| cross_sections | X | X (geom_hdf) | hdf_path, datetime_to_str |
| cross_sections_elevations | X | X (geom_hdf) | hdf_path, round_to |
| river_reaches | X | X (geom_hdf) | hdf_path, datetime_to_str |

17. RasExamples Class:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| __init__ | X | | |
| get_example_projects | X | | version_number |
| _load_project_data | X | | |
| _find_zip_file | X | | |
| _extract_folder_structure | X | | |
| _save_to_csv | X | | |
| list_categories | X | | |
| list_projects | X | | category |
| extract_project | X | | project_names |
| is_project_extracted | X | | project_name |
| clean_projects_directory | X | | |
| download_fema_ble_model | X | | huc8, output_dir |
| _make_safe_folder_name | X | | name |
| _download_file_with_progress | X | | url, dest_folder, file_size |
| _convert_size_to_bytes | X | | size_str |

18. RasGpt Class:

This class is mentioned in the code but has no implemented methods yet.

19. Standalone functions:

| Function Name | @log_call | @standardize_input | Arguments |
|---------------|-----------|--------------------|--------------------|
| init_ras_project | X | | ras_project_folder, ras_version, ras_instance |
| get_ras_exe | X | | ras_version |




Overall, the ras-commander library provides a comprehensive set of tools for working with HEC-RAS projects, including project management, file operations, data extraction, and simulation execution. The library makes extensive use of logging and input standardization through decorators, ensuring consistent behavior and traceability across its various components.


## Coding Assistance Rules:

1. Use default libraries, especially pathlib for file operations.
2. Use r-strings for paths, f-strings for formatting.
3. Always use pathlib over os for file/directory operations.
4. Include comments and use logging for output.
5. Follow PEP 8 conventions.
6. Provide clear error handling and user feedback.
7. Explain RAS Commander function purposes and key arguments.
8. Use either global 'ras' object or custom instances consistently.
9. Highlight parallel execution best practices.
10. Suggest RasExamples for testing when appropriate.
11. Utilize RasHdf for HDF file operations and data extraction.
12. Use type hints for function arguments and return values.
13. Apply the @log_call decorator for automatic function logging.
14. Emphasize proper error handling and logging in all functions.
15. When working with RasHdfGeom, always use the @standardize_input decorator for methods that interact with HDF files.
16. Remember that RasHdfGeom methods often return GeoDataFrames, which combine geometric data with attribute information.
17. When dealing with cross-sections or river reaches, consider using the datetime_to_str parameter to convert datetime objects to strings if needed.
18. For methods that accept a mesh_name parameter, remember that they can return either a dictionary of lists or a single list depending on whether a specific mesh is specified.
19. Use 'union_all()' for geodataframes. For pandas >= 2.0, use pd.concat instead of append.
20. Provide full code segments or scripts with no elides.
21. When importing from the Decorators module, use:
    ```python
    from .Decorators import standardize_input, log_call
    ```
22. When importing from the LoggingConfig module, use:
    ```python
    from .LoggingConfig import setup_logging, get_logger
    ```
23. Be aware that while the code will work with capitalized module names (Decorators.py and LoggingConfig.py), it's generally recommended to stick to lowercase names for modules as per PEP 8.
24. When revising code, label planning steps as:
    ## Explicit Planning and Reasoning for Revisions

25. Always consider the implications of file renaming on import statements throughout the project.
26. When working with GeoDataFrames, remember to use appropriate geometric operations and consider spatial relationships.
27. For HDF file operations, always use the standardize_input decorator to ensure consistent handling of file paths.
28. When dealing with large datasets, consider using chunking or iterative processing to manage memory usage.
29. Utilize the RasExamples class for testing and demonstrating functionality with sample projects.
30. When working with the RasGpt class, be aware that it's mentioned but currently has no implemented methods.
==================================================

Folder: c:\GH\ras-commander\.gitignore
==================================================

File: c:\GH\ras-commander\Comprehensive_Library_Guide.md
==================================================
# Comprehensive RAS-Commander Library Guide

## Introduction

RAS-Commander (`ras_commander`) is a Python library designed to automate and streamline operations with HEC-RAS projects. It provides a suite of tools for managing projects, executing simulations, and handling results. This guide offers a comprehensive overview of the library's key concepts, modules, best practices, and advanced usage patterns. RAS-Commander is designed to be flexible, robust, and AI-accessible, making it an ideal tool for both manual and automated HEC-RAS workflows.

RAS-Commander can be installed with the following commands:
```
pip install h5py numpy pandas requests tqdm scipy
pip install ras-commander
```

## Key Concepts

1. **RAS Objects**:
   - Represent HEC-RAS projects containing information about plans, geometries, and flow files.
   - Support both a global `ras` object and custom `RasPrj` instances for different projects.

2. **Project Initialization**:
   - Use `init_ras_project()` to initialize projects and set up RAS objects.
   - Handles project file discovery and data structure setup.

3. **File Handling**:
   - Utilizes `pathlib.Path` for consistent, platform-independent file paths.
   - Adheres to HEC-RAS file naming conventions (`.prj`, `.p01`, `.g01`, `.f01`, `.u01`).

4. **Data Management**:
   - Employs Pandas DataFrames to manage structured data about plans, geometries, and flow files.
   - Provides methods for accessing and updating these DataFrames.

5. **Execution Modes**:
   - **Single Plan Execution**: Run individual plans.
   - **Sequential Execution**: Run multiple plans in sequence.
   - **Parallel Execution**: Run multiple plans concurrently for improved performance.

6. **Example Projects**:
   - The `RasExamples` class offers functionality to download and manage HEC-RAS example projects for testing and learning.

7. **Utility Functions**:
   - `RasUtils` provides common utility functions for file operations, backups, error handling, and statistical analysis.

8. **Artifact System**:
   - Handles substantial, self-contained content that users might modify or reuse, displayed in a separate UI window.

9. **AI-Driven Coding Tools**:
   - Integrates AI-powered tools like ChatGPT Assistant, LLM Summaries, Cursor IDE Integration, and Jupyter Notebook Assistant.

10. **Boundary Conditions**:
    - Represent the input conditions for HEC-RAS simulations, including flow hydrographs, stage hydrographs, and other hydraulic inputs.
    - The `RasPrj` class provides functionality to extract and manage boundary conditions from unsteady flow files.

11. **Flexibility and Modularity**:
    - All classes are designed to work with either a global 'ras' object + a plan number, or with custom project instances.
    - Clear separation of concerns between project management (RasPrj), execution (RasCmdr), and results data retrieval (RasHdf).

12. **Error Handling and Logging**:
    - Emphasis on robust error checking and informative logging throughout the library.
    - Utilizes the `logging_config` module for consistent logging configuration.
    - `@log_call` decorator applied to relevant functions for logging function calls.

13. **AI-Accessibility**:
    - Structured, consistent codebase with clear documentation to facilitate easier learning and usage by AI models.

## Core Features

1. **Project Management**: Initialize, load, and manage HEC-RAS projects.
2. **Plan Execution**: Run single or multiple HEC-RAS plans with various execution modes.
3. **File Operations**: Handle HEC-RAS file types (plans, geometries, flows) with ease.
4. **Data Extraction**: Retrieve and process results from HDF files.
5. **Boundary Condition Management**: Extract and analyze boundary conditions.
6. **Parallel Processing**: Optimize performance with parallel plan execution.
7. **Example Project Handling**: Download and manage HEC-RAS example projects.
8. **Utility Functions**: Perform common tasks and statistical analyses.
9. **HDF File Handling**: Specialized classes for working with HEC-RAS HDF files.

## Module Overview

1. **RasPrj**: Manages HEC-RAS project initialization and data, including boundary conditions.
2. **RasCmdr**: Handles execution of HEC-RAS simulations.
3. **RasPlan**: Provides functions for plan file operations.
4. **RasGeo**: Manages geometry file operations.
5. **RasUnsteady**: Handles unsteady flow file operations.
6. **RasUtils**: Offers utility functions for common tasks and statistical analysis.
7. **RasExamples**: Manages example HEC-RAS projects.
8. **HdfBase**: Provides base functionality for HDF file operations.
9. **HdfBndry**: Handles boundary-related data in HDF files.
10. **HdfMesh**: Manages mesh-related data in HDF files.
11. **HdfPlan**: Handles plan-related data in HDF files.
12. **HdfResultsMesh**: Processes mesh results from HDF files.
13. **HdfResultsPlan**: Handles plan results from HDF files.
14. **HdfResultsXsec**: Processes cross-section results from HDF files.
15. **HdfStruc**: Manages structure data in HDF files.
16. **HdfUtils**: Provides utility functions for HDF file operations.
17. **HdfXsec**: Handles cross-section data in HDF files.

## Best Practices

### 1. RAS Object Usage

- **Single Project Scripts**:
  - Use the global `ras` object for simplicity.
    ```python
    from ras_commander import ras, init_ras_project

    init_ras_project("/path/to/project", "6.5")
    # Use ras object for operations
    ```

- **Multiple Projects**:
  - Create separate `RasPrj` instances for each project.
    ```python
    from ras_commander import RasPrj, init_ras_project

    project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
    project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())
    ```

- **Consistency**:
  - Avoid mixing global and custom RAS objects in the same script.

### 2. Plan Specification

- Use plan numbers as strings (e.g., `"01"`, `"02"`) for consistency.
  ```python
  RasCmdr.compute_plan("01")
  ```

- Check available plans before specifying plan numbers.
  ```python
  print(ras.plan_df)  # Displays available plans
  ```

### 3. Geometry Preprocessor Files

- Clear geometry preprocessor files before significant changes.
  ```python
  RasGeo.clear_geompre_files()
  ```

- Use `clear_geompre=True` for a clean computation environment.
  ```python
  RasCmdr.compute_plan("01", clear_geompre=True)
  ```

### 4. Parallel Execution

- Adjust `max_workers` and `num_cores` based on system capabilities.
  ```python
  RasCmdr.compute_parallel(max_workers=4, num_cores=2)
  ```

- Use `dest_folder` to organize outputs and prevent conflicts.
  ```python
  RasCmdr.compute_parallel(dest_folder="/path/to/results")
  ```

### 5. Error Handling and Logging

Proper error handling and logging are crucial for robust RAS Commander scripts. The library provides built-in logging functionality to help you track operations and diagnose issues.

1. **Logging Setup**:
   RAS Commander automatically sets up basic logging. You can adjust the log level:

   ```python
   import logging
   logging.getLogger('ras_commander').setLevel(logging.DEBUG)
   ```

2. **Using the @log_call Decorator**:
   The `@log_call` decorator automatically logs function calls:

   ```python
   from ras_commander.Decorators import log_call

   @log_call
   def my_function():
       # Function implementation
   ```

3. **Custom Logging**:
   For more detailed logging, use the logger directly:

   ```python
   from ras_commander.LoggingConfig import get_logger

   logger = get_logger(__name__)

   def my_function():
       logger.info("Starting operation")
       try:
           # Operation code
       except Exception as e:
           logger.error(f"Operation failed: {str(e)}")
   ```

4. **Error Handling Best Practices**:
   - Use specific exception types when possible.
   - Provide informative error messages.
   - Consider using custom exceptions for library-specific errors.

   ```python
   class RasCommanderError(Exception):
       pass

   def my_function():
       try:
           # Operation code
       except FileNotFoundError as e:
           raise RasCommanderError(f"Required file not found: {str(e)}")
       except ValueError as e:
           raise RasCommanderError(f"Invalid input: {str(e)}")
   ```

5. **Logging to File**:
   To save logs to a file, configure a file handler:

   ```python
   import logging
   from ras_commander.LoggingConfig import setup_logging

   setup_logging(log_file='ras_commander.log', log_level=logging.DEBUG)
   ```

### 6. File Path Handling

- Use `pathlib.Path` for robust file and directory operations.
  ```python
  from pathlib import Path
  project_path = Path("/path/to/project")
  ```

### 7. Type Hinting

- Apply type hints to improve code readability and IDE support.
  ```python
  def compute_plan(plan_number: str, clear_geompre: bool = False) -> bool:
      ...
  ```

## Usage Patterns

### Initializing a Project
```python
from ras_commander import init_ras_project, ras

init_ras_project("/path/to/project", "6.5")
print(f"Working with project: {ras.project_name}")
```

### Cloning a Plan

```python
from ras_commander import RasPlan

new_plan_number = RasPlan.clone_plan("01")
print(f"Created new plan: {new_plan_number}")
```


### Executing Plans

- **Single Plan Execution**:
  ```python
  from ras_commander import RasCmdr

  success = RasCmdr.compute_plan("01", num_cores=2)
  print(f"Plan execution {'successful' if success else 'failed'}")
  ```

- **Parallel Execution of Multiple Plans**:
  ```python
  from ras_commander import RasCmdr

  results = RasCmdr.compute_parallel(
      plan_numbers=["01", "02", "03"],
      max_workers=3,
      num_cores=4,
      dest_folder="/path/to/results",
      clear_geompre=True
  )

  for plan, success in results.items():
      print(f"Plan {plan}: {'Successful' if success else 'Failed'}")
  ```

### Working with Multiple Projects

```python
from ras_commander import RasPrj, init_ras_project, RasCmdr

# Initialize two separate projects
project1 = init_ras_project("/path/to/project1", "6.5", ras_instance=RasPrj())
project2 = init_ras_project("/path/to/project2", "6.5", ras_instance=RasPrj())

# Perform operations on each project
RasCmdr.compute_plan("01", ras_object=project1)
RasCmdr.compute_plan("02", ras_object=project2)

# Compare results
results1 = project1.get_hdf_entries()
results2 = project2.get_hdf_entries()
```

## Advanced Usage

### Working with HDF Files

RAS Commander provides extensive support for working with HDF files through various specialized classes. Here's an overview of key operations:

1. **Reading HDF Data**:
   Use `HdfUtils.get_hdf_paths_with_properties()` to explore the structure of an HDF file:

   ```python
   from ras_commander import HdfUtils

   hdf_paths = HdfUtils.get_hdf_paths_with_properties(hdf_path)
   print(hdf_paths)
   ```

2. **Extracting Mesh Results**:
   Use `HdfResultsMesh` to extract mesh-related results:

   ```python
   from ras_commander import HdfResultsMesh

   water_surface = HdfResultsMesh.mesh_timeseries_output(hdf_path, mesh_name, "Water Surface")
   print(water_surface)
   ```

3. **Working with Plan Results**:
   Use `HdfResultsPlan` for plan-specific results:

   ```python
   from ras_commander import HdfResultsPlan

   runtime_data = HdfResultsPlan.get_runtime_data(hdf_path)
   print(runtime_data)
   ```

4. **Cross-Section Results**:
   Extract cross-section data using `HdfResultsXsec`:

   ```python
   from ras_commander import HdfResultsXsec

   wsel_data = HdfResultsXsec.cross_sections_wsel(hdf_path)
   print(wsel_data)
   ```

These classes provide a high-level interface to HDF data, making it easier to extract and analyze HEC-RAS results programmatically.

### Performance Optimization

Optimizing performance in RAS Commander involves balancing between execution speed and resource utilization. Here are detailed strategies:

1. **Parallel Execution**:
   Use `RasCmdr.compute_parallel()` for running multiple plans concurrently:

   ```python
   from ras_commander import RasCmdr

   results = RasCmdr.compute_parallel(
       plan_numbers=["01", "02", "03"],
       max_workers=3,
       num_cores=4
   )
   ```

   - Adjust `max_workers` based on the number of plans and available system resources.
   - Set `num_cores` to balance between single-plan performance and overall throughput.

2. **Geometry Preprocessing**:
   Preprocess geometry to avoid redundant calculations:

   ```python
   from ras_commander import RasPlan

   RasPlan.set_geom_preprocessor(plan_path, run_htab=1, use_ib_tables=0)
   ```

   - Set `run_htab=1` to force geometry preprocessing.
   - Use `use_ib_tables=0` to recompute internal boundary tables.

3. **Memory Management**:
   When working with large datasets, use chunking and iterative processing:

   ```python
   import dask.array as da
   from ras_commander import HdfResultsMesh

   data = HdfResultsMesh.mesh_timeseries_output(hdf_path, mesh_name, "Water Surface")
   dask_array = da.from_array(data.values, chunks=(1000, 1000))
   ```

4. **I/O Optimization**:
   Minimize disk I/O by batching read/write operations:

   ```python
   from ras_commander import HdfUtils

   with h5py.File(hdf_path, 'r') as hdf_file:
       datasets = HdfUtils.get_hdf_paths_with_properties(hdf_file)
       # Process multiple datasets in a single file open operation
   ```

5. **Profiling and Monitoring**:
   Use Python's built-in profiling tools to identify performance bottlenecks:

   ```python
   import cProfile

   cProfile.run('RasCmdr.compute_plan("01")')
   ```

By applying these strategies, you can significantly improve the performance of your RAS Commander scripts, especially when dealing with large projects or multiple simulations.

### Working with Boundary Conditions

RAS Commander provides powerful tools for managing and analyzing boundary conditions in HEC-RAS projects. Here's how to work effectively with boundary conditions:

1. **Accessing Boundary Conditions**:
   Use the `boundaries_df` attribute of the RasPrj object:

   ```python
   from ras_commander import init_ras_project

   project = init_ras_project("/path/to/project", "6.5")
   boundary_conditions = project.boundaries_df
   print(boundary_conditions)
   ```

2. **Filtering Boundary Conditions**:
   You can easily filter boundary conditions by type or location:

   ```python
   # Get all flow hydrographs
   flow_hydrographs = boundary_conditions[boundary_conditions['bc_type'] == 'Flow Hydrograph']

   # Get boundary conditions for a specific river
   river_boundaries = boundary_conditions[boundary_conditions['river_reach_name'] == 'Main River']
   ```

3. **Analyzing Boundary Condition Data**:
   Extract detailed information from boundary conditions:

   ```python
   for _, bc in flow_hydrographs.iterrows():
       print(f"River: {bc['river_reach_name']}")
       print(f"Station: {bc['river_station']}")
       print(f"Number of values: {bc['hydrograph_num_values']}")
       print("---")
   ```

4. **Modifying Boundary Conditions**:
   While direct modification of boundary conditions is not supported, you can use RAS Commander to update unsteady flow files:

   ```python
   from ras_commander import RasUnsteady

   RasUnsteady.update_unsteady_parameters(unsteady_file_path, {"Parameter1": "NewValue1"})
   ```

5. **Visualizing Boundary Conditions**:
   Use pandas and matplotlib to visualize boundary condition data:

   ```python
   import matplotlib.pyplot as plt

   bc = flow_hydrographs.iloc[0]
   plt.plot(bc['hydrograph_values'])
   plt.title(f"Flow Hydrograph: {bc['name']}")
   plt.xlabel("Time Step")
   plt.ylabel("Flow")
   plt.show()
   ```

By leveraging these capabilities, you can effectively analyze and manage boundary conditions in your HEC-RAS projects using RAS Commander.

### Advanced Data Processing with RasUtils

RasUtils provides a set of powerful tools for data processing and analysis. Here are some advanced techniques:

1. **Data Conversion**:
   Convert various data sources to pandas DataFrames:

   ```python
   from ras_commander import RasUtils
   from pathlib import Path

   csv_data = RasUtils.convert_to_dataframe(Path("results.csv"))
   excel_data = RasUtils.convert_to_dataframe(Path("data.xlsx"), sheet_name="Sheet1")
   ```

2. **Statistical Analysis**:
   Perform statistical calculations on simulation results:

   ```python
   import numpy as np

   observed = np.array([100, 120, 140, 160, 180])
   predicted = np.array([105, 125, 135, 165, 175])

   rmse = RasUtils.calculate_rmse(observed, predicted)
   percent_bias = RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)
   metrics = RasUtils.calculate_error_metrics(observed, predicted)

   print(f"RMSE: {rmse}")
   print(f"Percent Bias: {percent_bias}%")
   print(f"Metrics: {metrics}")
   ```

3. **Spatial Operations**:
   Perform spatial queries and nearest neighbor searches:

   ```python
   import numpy as np

   points = np.array([[0, 0], [1, 1], [2, 2], [10, 10]])
   query_points = np.array([[0.5, 0.5], [5, 5]])

   nearest = RasUtils.perform_kdtree_query(points, query_points)
   neighbors = RasUtils.find_nearest_neighbors(points)

   print(f"Nearest points: {nearest}")
   print(f"Neighbors: {neighbors}")
   ```

4. **Data Consolidation**:
   Consolidate and pivot complex datasets:

   ```python
   import pandas as pd

   df = pd.DataFrame({'A': [1, 1, 2], 'B': [4, 5, 6], 'C': [7, 8, 9]})
   consolidated = RasUtils.consolidate_dataframe(df, group_by='A', aggregation_method='list')

   print(consolidated)
   ```

5. **File Operations**:
   Perform advanced file operations with built-in error handling:

   ```python
   from pathlib import Path

   directory = Path("output")
   RasUtils.create_directory(directory)

   file_path = directory / "data.txt"
   RasUtils.check_file_access(file_path, mode='w')

   # Perform file operation here

   RasUtils.remove_with_retry(file_path, is_folder=False)
   ```

By utilizing these advanced data processing capabilities of RasUtils, you can efficiently handle complex data manipulation tasks in your RAS Commander workflows.

### RasExamples

The `RasExamples` class provides functionality for managing HEC-RAS example projects. This is particularly useful for testing, learning, and development purposes.

#### Key Concepts

- **Example Project Management**: Access and manipulate example projects.
- **Automatic Downloading and Extraction**: Fetches projects from official sources.
- **Project Categorization**: Organizes projects into categories for easy navigation.

#### Usage Patterns

```python
from ras_commander import RasExamples

# Initialize RasExamples
ras_examples = RasExamples()

# Download example projects (if not already present)
ras_examples.get_example_projects()

# List available categories
categories = ras_examples.list_categories()
print(f"Available categories: {categories}")

# List projects in a specific category
steady_flow_projects = ras_examples.list_projects("Steady Flow")
print(f"Steady Flow projects: {steady_flow_projects}")

# Extract specific projects
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
for path in extracted_paths:
    print(f"Extracted project to: {path}")

# Clean up extracted projects when done
ras_examples.clean_projects_directory()
```

## RasHdf

The `RasHdf` class provides utilities for working with HDF (Hierarchical Data Format) files in HEC-RAS projects. HDF files are commonly used in HEC-RAS for storing large datasets and simulation results.

### Key Features of `RasHdf`:

1. **Reading HDF Tables**: Convert HDF5 datasets to pandas DataFrames.
2. **Writing DataFrames to HDF**: Save pandas DataFrames as HDF5 datasets.
3. **Spatial Operations**: Perform KDTree queries and find nearest neighbors.
4. **Data Consolidation**: Merge duplicate values in DataFrames.
5. **Byte String Handling**: Decode byte strings in DataFrames.

### Example Usage:

```python
from ras_commander import RasHdf
import h5py
import pandas as pd

# Read an HDF table
with h5py.File('results.hdf', 'r') as f:
    dataset = f['water_surface_elevations']
    df = RasHdf.read_hdf_to_dataframe(dataset)

print(df.head())

# Save a DataFrame to HDF
new_data = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})
with h5py.File('new_results.hdf', 'w') as f:
    group = f.create_group('my_results')
    RasHdf.save_dataframe_to_hdf(new_data, group, 'my_dataset')

# Perform a KDTree query
import numpy as np
reference_points = np.array([[0, 0], [1, 1], [2, 2]])
query_points = np.array([[0.5, 0.5], [1.5, 1.5]])
results = RasHdf.perform_kdtree_query(reference_points, query_points)
print("KDTree query results:", results)
```

## Optimizing Parallel Execution with RAS Commander

Efficient parallel execution is crucial for maximizing the performance of HEC-RAS simulations, especially when dealing with multiple plans or large models. RAS Commander offers several strategies for optimizing parallel execution based on your specific needs and system resources.

### Strategy 1: Efficiency Mode for Multiple Plans

This strategy maximizes overall throughput and efficiency when running multiple plans, although individual plan turnaround times may be longer.

**Key Points:**
- Use 2 real cores per plan
- Utilize only physical cores, not hyperthreaded cores

**Example:**
```python
from ras_commander import RasCmdr

# Assuming 8 physical cores on the system
RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03", "04"],
    max_workers=4,  # 8 cores / 2 cores per plan
    num_cores=2
)
```

### Strategy 2: Performance Mode for Single Plans

This strategy maximizes single plan performance by using more cores. It results in less overall efficiency but shortens single plan runtime, making it optimal for situations where individual plan performance is critical.

**Key Points:**
- Use 8-16 cores per plan, depending on system capabilities
- Suitable for running a single plan or a small number of high-priority plans

**Example:**
```python
from ras_commander import RasCmdr

RasCmdr.compute_plan(
    plan_number="01",
    num_cores=12  # Adjust based on your system's capabilities
)
```

### Strategy 3: Background Run Operation

This strategy balances performance and system resource usage, allowing for other operations to be performed concurrently.

**Key Points:**
- Limit total core usage to 50-80% of physical cores
- Combines aspects of Strategies 1 and 2
- Allows overhead for user to complete other operations while calculations are running

**Example:**
```python
import psutil
from ras_commander import RasCmdr

physical_cores = psutil.cpu_count(logical=False)
max_cores_to_use = int(physical_cores * 0.7)  # Using 70% of physical cores

RasCmdr.compute_parallel(
    plan_numbers=["01", "02", "03"],
    max_workers=max_cores_to_use // 2,
    num_cores=2
)
```

### Optimizing Geometry Preprocessing

To avoid repeated geometry preprocessing for each run, follow these steps:

1. **Preprocess Geometry:**
   ```python
   from ras_commander import RasPlan
   
   # For each plan you want to preprocess
   RasPlan.update_plan_value(plan_number, "Run HTab", 1)
   RasPlan.update_plan_value(plan_number, "Run UNet", -1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", -1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", -1)
   
   # Run the plan to preprocess geometry
   RasCmdr.compute_plan(plan_number)
   ```

2. **Run Simulations:**
   After preprocessing, update the flags for actual simulations:
   ```python
   RasPlan.update_plan_value(plan_number, "Run HTab", -1)
   RasPlan.update_plan_value(plan_number, "Run UNet", 1)
   RasPlan.update_plan_value(plan_number, "Run PostProcess", 1)
   RasPlan.update_plan_value(plan_number, "Run RASMapper", 0)
   ```

This approach preprocesses the geometry once, preventing redundant preprocessing when multiple plans use the same geometry.

### Best Practices for Parallel Execution

- **Balance Cores:** Find the right balance between the number of parallel plans and cores per plan based on your system's capabilities.
- **Consider I/O Operations:** Be aware that disk I/O can become a bottleneck in highly parallel operations.
- **Test and Iterate:** Experiment with different configurations to find the optimal setup for your specific models and system.

By leveraging these strategies and best practices, you can significantly improve the performance and efficiency of your HEC-RAS simulations using RAS Commander.

## Approaching Your End User Needs with Ras Commander

### Understanding Data Sources and Strategies

RAS Commander is designed to work efficiently with HEC-RAS projects by focusing on easily accessible data sources. This approach allows for powerful automation while avoiding some of the complexities inherent in HEC-RAS data management. Here's what you need to know:

1. **Data Sources in HEC-RAS Projects**:
   - ASCII input files (plan files, unsteady files, boundary conditions)
   - DSS (Data Storage System) files for inputs
   - HDF (Hierarchical Data Format) files for outputs

2. **RAS Commander's Focus**:
   - Primarily works with plain text inputs and HDF outputs
   - Avoids direct manipulation of DSS files due to their complexity

3. **Strategy for Handling DSS Inputs**:
   - Run the plan or preprocess geometry and event conditions
   - Access the resulting HDF tables, which contain the DSS inputs in an accessible format
   - Define time series directly in the ASCII file instead of as DSS inputs

4. **Accessing Project Data**:
   - Basic project data is loaded from ASCII text files by the RasPrj routines
   - Plan details are available in the HDF file
   - Geometry data is in the dynamically generated geometry HDF file

### Working with RAS Commander

1. **Initialization and Data Loading**:
   - Use `init_ras_project()` to load project data from ASCII files
   - Access plan information from HDF files using provided functions

2. **Handling Geometry Data**:
   - Geometry data is dynamically generated in HDF format
   - Focus on working with the HDF geometry data rather than plain text editing

3. **Workflow for Complex Operations**:
   - Perform the desired operation manually once
   - Provide an example to RAS Commander's AI GPT of what you're changing and why
   - Use this example to develop project-specific functions and code

4. **Example: Replacing DSS-defined Boundary Conditions**:
   - Open the data in HDF View
   - Extract the relevant dataset
   - Manually enter the time series based on the HDF dataset
   - Verify the model works with this change
   - Use this example to create an automated function for similar operations

### Best Practices

1. **Understanding Your Data**:
   - Familiarize yourself with the structure of your HEC-RAS project
   - Identify which data is stored in ASCII, DSS, and HDF formats

2. **Leveraging HDF Outputs**:
   - Whenever possible, use HDF outputs for data analysis and manipulation
   - This approach provides easy access to data without DSS complexities

3. **Iterative Development**:
   - Start with manual operations to understand the process
   - Gradually automate these processes using RAS Commander functions
   - Always check with the HEC-RAS GUI to verify the changes before finalizing the automation

4. **Documentation**:
   - Keep detailed notes on your workflow and changes
   - This documentation will be invaluable for creating automated processes

5. **Flexibility**:
   - Be prepared to adapt your approach based on specific project needs
   - RAS Commander provides a framework, but project-specific solutions will always require custom scripting
   - With an AI assistant, you can quickly leverage this library or your own custom functions to automate your workflows.

By following these strategies and best practices, you can effectively use RAS Commander to automate and streamline your HEC-RAS workflows, working around limitations and leveraging the strengths of the library's approach to data management.

## Troubleshooting

### 1. Project Initialization Issues

- **Ensure Correct Paths**: Verify that the project path is accurate and the `.prj` file exists.
- **HEC-RAS Version**: Confirm that the specified HEC-RAS version is installed on your system.

### 2. Execution Failures

- **File Existence**: Check that all referenced plan, geometry, and flow files exist.
- **Executable Path**: Ensure the HEC-RAS executable path is correctly set.
- **Log Files**: Review HEC-RAS log files for specific error messages.

### 3. Parallel Execution Problems

- **Resource Allocation**: Reduce `max_workers` if encountering memory issues.
- **System Capabilities**: Adjust `num_cores` based on your system's capacity.
- **Clean Environment**: Use `clear_geompre=True` to prevent conflicts.

### 4. File Access Errors

- **Permissions**: Verify read/write permissions for the project directory.
- **File Locks**: Close any open HEC-RAS instances that might lock files.

### 5. Inconsistent Results

- **Geometry Files**: Clear geometry preprocessor files when making changes.
- **Plan Parameters**: Ensure all plan parameters are correctly set before execution.

## Conclusion

The RAS-Commander (`ras_commander`) library provides a powerful set of tools for automating HEC-RAS operations. By following the best practices outlined in this guide and leveraging the library's features, you can efficiently manage and execute complex HEC-RAS projects programmatically.

Remember to refer to the latest documentation and the library's source code for up-to-date information. As you become more familiar with `ras_commander`, you'll discover more ways to optimize your HEC-RAS workflows and increase productivity.

For further assistance, bug reports, or feature requests, please refer to the library's [GitHub repository](https://github.com/billk-FM/ras-commander) and issue tracker.

**Happy Modeling!**








**Note on Module Naming Convention:**
While the library now uses capitalized names for the `Decorators.py` and `LoggingConfig.py` modules, it's worth noting that this deviates from the PEP 8 style guide, which recommends lowercase names for modules. Future versions of the library may revert to lowercase naming for consistency with Python conventions. Users should be aware of this potential change in future updates.
==================================================

Folder: c:\GH\ras-commander\examples
==================================================

File: c:\GH\ras-commander\LICENSE
==================================================
MIT License

Copyright (c) 2024 William M. Katzenmeyer

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so.

==================================================

File: c:\GH\ras-commander\pyproject.toml
==================================================
[build-system]
requires = ["setuptools>=45", "wheel"]
build-backend = "setuptools.build_meta:__legacy__"

==================================================

Folder: c:\GH\ras-commander\ras_commander
==================================================

File: c:\GH\ras-commander\README.md
==================================================
# RAS Commander (ras-commander)

RAS Commander is a Python library for automating HEC-RAS operations, providing a set of tools to interact with HEC-RAS project files, execute simulations, and manage project data. This library is an evolution of the RASCommander 1.0 Python Notebook Application previously released under the [HEC-Commander tools repository](https://github.com/billk-FM/HEC-Commander).

## Contributors:
William Katzenmeyer, P.E., C.F.M. 

Sean Micek, P.E., C.F.M. 

Aaron Nichols, P.E., C.F.M. 

(Additional Contributors Here)  

## Don't Ask Me, Ask ChatGPT!

Before you read any further, you can [chat directly with ChatGPT on this topic.](https://chatgpt.com/g/g-TZRPR3oAO-ras-commander-library-assistant)  Ask it anything, and it will use its tools to answer your questions and help you learn.  You can even upload your own plan, unsteady and HDF files to inspect and help determine how to automate your workflows or visualize your results. 

There are also [AI Assistant Knowledge Bases](https://github.com/billk-FM/ras-commander/tree/main/ai_tools/assistant_knowledge_bases) with various versions available to directly use with large context LLM models such as Anthropic's Claude, Google Gemini and OpenAI's GPT4o and o1 models.  

FUTURE:  TEMPLATES are available to use with AI Assistant Notebooks to build your own automation tools.  When used with large context models, these templates allow you to ask GPT to build a workflow from scratch to automate your projects. 

## Background
The ras-commander library emerged from the initial test-bed of AI-driven coding represented by the HEC-Commander tools Python notebooks. These notebooks served as a proof of concept, demonstrating the value proposition of automating HEC-RAS operations. The transition from notebooks to a structured library aims to provide a more robust, maintainable, and extensible solution for water resources engineers.

## Features

- Automate HEC-RAS project management and simulations
- Support for both single and multiple project instances
- Parallel execution of HEC-RAS plans
- Utilities for managing geometry, plan, and unsteady flow files
- Example project management for testing and development
- Two primary operation modes: "Run Missing" and "Build from DSS"

## AI-Driven Coding Experience

ras-commander provides several AI-powered tools to enhance the coding experience:

1. **ChatGPT Assistant: [RAS Commander Library Assistant](https://chatgpt.com/g/g-TZRPR3oAO-ras-commander-library-assistant)**: A specialized GPT model trained on the ras-commander codebase, available for answering queries and providing code suggestions.

2. **[Purpose-Built Knowledge Base Summaries](https://github.com/billk-FM/ras-commander/tree/main/ai_tools/assistant_knowledge_bases)**: Up-to-date compilations of the documentation and codebase for use with large language models like Claude or GPT-4. Look in 'ai_tools/assistant_knowledge_bases/' in the repo.

3. **[Cursor IDE Integration](https://github.com/billk-FM/ras-commander/blob/main/.cursorrules)**: Custom rules for the Cursor IDE to provide context-aware suggestions and documentation.  Just open the repository folder in Cursor.  You can create your own folders "/workspace/, "/projects/", or "my_projects/" as these are already in the .gitignore, and place your custom scripts there for your projects.  This will allow easy referencing of the ras-commander documents and individual repo files, the automatic loading of the .cursorrules file.  Alternatvely, download the github repo into your projects folder to easily load documents and use cursor rules files.  
4. **[AI Assistant Notebook](https://github.com/billk-FM/ras-commander/blob/main/ai_tools/rascommander_code_assistant.ipynb)**: A notebook for dynamic code summarization and API interaction (bring your own API Key).  Currently, this only does a single-shot message on the Claude Sonnet 3.5 API, which can be up to 50 cents per request.  Future revisions will include the ability to select which knowledge base file to include, a choice of SOTA models + multi turn conversations to build automation notebooks interactively.  

These tools aim to streamline development and provide intelligent assistance when modeling with, and working with and revising the ras-commander library.

## Installation

Create a virtual environment with conda or venv (ask ChatGPT if you need help)

In your virtual environment, install ras-commander using pip:
```
pip install h5py numpy pandas requests tqdm scipy
pip install --upgrade ras-commander
```

If you have dependency issues with pip (especially if you have errors with numpy), try clearing your local pip packages 'C:\Users\your_username\AppData\Roaming\Python\' and then creating a new virtual environment.  
   

## Requirements

- Tested with Python 3.11
- HEC-RAS 6.2 or later (other versions may work, all testing was done with version 6.2 and above)
- Detailed project workflows and/or existing libraries and code where ras-commander can be integrated.

For a full list of dependencies, see the `requirements.txt` file.

## Quick Start
```
from ras_commander import init_ras_project, RasCmdr, RasPlan
```

# Initialize a project
```
init_ras_project(r"/path/to/project", "6.5")
```

# Execute a single plan
```
RasCmdr.compute_plan("01", dest_folder=r"/path/to/results", overwrite_dest=True)
```

# Execute plans in parallel
```
results = RasCmdr.compute_parallel(
    plan_numbers=["01", "02"],
    max_workers=2,
    cores_per_run=2,
    dest_folder=r"/path/to/results",
    overwrite_dest=True
)
```

# Modify a plan
```
RasPlan.set_geom("01", "02")
```

Certainly! I'll provide you with an updated Key Components section and Project Organization diagram based on the current structure of the ras-commander library.

## Key Components

- `RasPrj`: Manages HEC-RAS projects, handling initialization and data loading
- `RasCmdr`: Handles execution of HEC-RAS simulations
- `RasPlan`: Provides functions for modifying and updating plan files
- `RasGeo`: Handles operations related to geometry files
- `RasUnsteady`: Manages unsteady flow file operations
- `RasUtils`: Contains utility functions for file operations and data management
- `RasExamples`: Manages and loads HEC-RAS example projects
- `RasHdf`: Provides utilities for working with HDF files in HEC-RAS projects

## Project Organization Diagram

```
ras_commander
├── .github
│   └── workflows
│       └── python-package.yml
├── ras_commander
│   ├── __init__.py
│   ├── _version.py
│   ├── RasCmdr.py
│   ├── RasExamples.py
│   ├── RasGeo.py
│   ├── RasHdf.py
│   ├── RasPlan.py
│   ├── RasPrj.py
│   ├── RasUnsteady.py
│   └── RasUtils.py
├── examples
│   ├── 01_project_initialization.py
│   ├── 02_plan_operations.py
│   ├── 03_geometry_operations.py
│   ├── 04_unsteady_flow_operations.py
│   ├── 05_utility_functions.py
│   ├── 06_single_plan_execution.py
│   ├── 07_sequential_plan_execution.py
│   ├── 08_parallel_execution.py
│   ├── 09_specifying_plans.py
│   ├── 10_arguments_for_compute.py
│   ├── 11_Using_RasExamples.ipynb
│   ├── 12_plan_set_execution.py
│   ├── 13_multiple_project_operations.py
│   ├── 14_Core_Sensitivity.ipynb
│   ├── 15_plan_key_operations.py
│   ├── 16_scanning_ras_project_info.py
│   ├── 17_parallel_execution_ble.py
│   └── HEC_RAS_2D_HDF_Analysis.ipynb
├── tests
│   └── ... (test files)
├── .gitignore
├── LICENSE
├── README.md
├── STYLE_GUIDE.md
├── Comprehensive_Library_Guide.md
├── pyproject.toml
├── setup.cfg
├── setup.py
└── requirements.txt
```

## Accessing HEC Examples through RasExamples

The `RasExamples` class provides functionality for quickly loading and managing HEC-RAS example projects. This is particularly useful for testing and development purposes.

Key features:
- Download and extract HEC-RAS example projects
- List available project categories and projects
- Extract specific projects for use
- Manage example project data efficiently

Example usage:
from ras_commander import RasExamples

```
ras_examples = RasExamples()
ras_examples.get_example_projects()  # Downloads example projects if not already present
categories = ras_examples.list_categories()
projects = ras_examples.list_projects("Steady Flow")
extracted_paths = ras_examples.extract_project(["Bald Eagle Creek", "Muncie"])
```

## RasPrj

The `RasPrj` class is central to managing HEC-RAS projects within the ras-commander library. It handles project initialization, data loading, and provides access to project components.

Key features:
- Initialize HEC-RAS projects
- Load and manage project data (plans, geometries, flows, etc.)
- Provide easy access to project files and information

Note: While a global `ras` object is available for convenience, you can create multiple `RasPrj` instances to manage several projects simultaneously.

Example usage:
```
from ras_commander import RasPrj, init_ras_project
```

### Using the global ras object
```
init_ras_project("/path/to/project", "6.5")
```

### Creating a custom RasPrj instance
```
custom_project = RasPrj()
init_ras_project("/path/to/another_project", "6.5", ras_instance=custom_project)
```

## RasHdf

The `RasHdf` class provides utilities for working with HDF files in HEC-RAS projects, enabling easy access to simulation results and model data.

Example usage:

```python
from ras_commander import RasHdf, init_ras_project, RasPrj

# Initialize project with a custom ras object
custom_ras = RasPrj()
init_ras_project("/path/to/project", "6.5", ras_instance=custom_ras)

# Get runtime data for a specific plan
plan_number = "01"
runtime_data = RasHdf.get_runtime_data(plan_number, ras_object=custom_ras)
print(runtime_data)
```

This class simplifies the process of extracting and analyzing data from HEC-RAS HDF output files, supporting tasks such as post-processing and result visualization.


## Documentation

For detailed usage instructions and API documentation, please refer to the [Comprehensive Library Guide](Comprehensive_Library_Guide.md).

## Examples

Check out the `examples/` directory for sample scripts demonstrating various features of ras-commander.

## Future Development

The ras-commander library is an ongoing project. Future plans include:
- Integration of more advanced AI-driven features
- Expansion of HMS and DSS functionalities
- Enhanced GPU support for computational tasks
- Community-driven development of new modules and features

## Related Resources

- [HEC-Commander Blog](https://github.com/billk-FM/HEC-Commander/tree/main/Blog)
- [GPT-Commander YouTube Channel](https://www.youtube.com/@GPT_Commander)
- [ChatGPT Examples for Water Resources Engineers](https://github.com/billk-FM/HEC-Commander/tree/main/ChatGPT%20Examples)


## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details on how to submit pull requests, report issues, and suggest improvements.

## Style Guide

This project follows a specific style guide to maintain consistency across the codebase. Please refer to the [Style Guide](STYLE_GUIDE.md) for details on coding conventions, documentation standards, and best practices.

## License

ras-commander is released under the MIT License. See the license file for details.

## Acknowledgments

RAS Commander is based on the HEC-Commander project's "Command Line is All You Need" approach, leveraging the HEC-RAS command-line interface for automation. The initial development of this library was presented in the HEC-Commander Tools repository. In a 2024 Australian Water School webinar, Bill demonstrated the derivation of basic HEC-RAS automation functions from plain language instructions. Leveraging the previously developed code and AI tools, the library was created. The primary tools used for this initial development were Anthropic's Claude, GPT-4, Google's Gemini Experimental models, and the Cursor AI Coding IDE.

Additionally, we would like to acknowledge the following notable contributions and attributions for open source projects which significantly influenced the development of RAS Commander:

1. Contributions: Sean Micek's [`funkshuns`](https://github.com/openSourcerer9000/funkshuns), [`TXTure`](https://github.com/openSourcerer9000/TXTure), and [`RASmatazz`](https://github.com/openSourcerer9000/RASmatazz) libraries provided inspiration, code examples and utility functions which were adapted with AI for use in RAS Commander. Sean has also contributed heavily to 

- Development of additional HDF functions for detailed analysis and mapping of HEC-RAS results within the RasHdf class.
- Development of the prototype `RasCmdr` class for executing HEC-RAS simulations.
- Optimization examples and methods from (INSERT REFERENCE) for use in the Ras-Commander library examples

2. Attribution: The [`pyHMT2D`](https://github.com/psu-efd/pyHMT2D/) project by Xiaofeng Liu, which provided insights into HDF file handling methods for HEC-RAS outputs.  Many of the functions in the [Ras_2D_Data.py](https://github.com/psu-efd/pyHMT2D/blob/main/pyHMT2D/Hydraulic_Models_Data/RAS_2D/RAS_2D_Data.py) file were adapted with AI for use in RAS Commander. 

   Xiaofeng Liu, Ph.D., P.E.,    Associate Professor, Department of Civil and Environmental Engineering
   Institute of Computational and Data Sciences, Penn State University

These acknowledgments recognize the contributions and inspirations that have helped shape RAS Commander, ensuring proper attribution for the ideas and code that have influenced its development.

3. Chris Goodell, "Breaking the HEC-RAS Code" - Studied and used as a reference for understanding the inner workings of HEC-RAS, providing valuable insights into the software's functionality and structure.

4. [HEC-Commander Tools](https://github.com/billk-FM/HEC-Commander) - Inspiration and initial code base for the development of RAS Commander.


## Official RAS Commander AI-Generated Songs:

[No More Wait and See (Bluegrass)](https://suno.com/song/16889f3e-50f1-4afe-b779-a41738d7617a)  

[No More Wait and See (Cajun Zydeco)](https://suno.com/song/4441c45d-f6cd-47b9-8fbc-1f7b277ee8ed)  


## Contact

For questions, suggestions, or support, please contact:
William Katzenmeyer, P.E., C.F.M. - billk@fenstermaker.com

==================================================

File: c:\GH\ras-commander\requirements.txt
==================================================
aider-chat @ git+https://github.com/paul-gauthier/aider.git@00d5348ee6295662c78a8ece31d71632145d9746
alabaster==0.7.16
annotated-types==0.6.0
anyio==3.7.1
asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1698341106958/work
attrs==23.1.0
babel==2.16.0
backoff==2.2.1
backports.tarfile==1.2.0
black==24.8.0
boto3==1.35.25
botocore==1.35.25
certifi==2023.11.17
cffi==1.16.0
charset-normalizer==3.3.2
click==8.1.7
colorama==0.4.6
comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1710320294760/work
ConfigArgParse==1.7
contourpy==1.3.0
cycler==0.12.1
debugpy @ file:///D:/bld/debugpy_1725269345345/work
decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work
diff-match-patch==20230430
diskcache==5.6.3
distro==1.8.0
docutils==0.20.1
exceptiongroup @ file:///home/conda/feedstock_root/build_artifacts/exceptiongroup_1720869315914/work
executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1725214404607/work
flake8==7.1.1
fonttools==4.53.1
geopandas==1.0.1
gitdb==4.0.11
GitPython==3.1.40
grep-ast==0.2.4
h11==0.14.0
h5py==3.11.0
httpcore==1.0.2
idna==3.6
imagesize==1.4.1
importlib_metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1726082825846/work
iniconfig==2.0.0
ipykernel @ file:///D:/bld/ipykernel_1719845595208/work
ipython @ file:///D:/bld/ipython_1725050320818/work
jaraco.classes==3.4.0
jaraco.context==6.0.1
jaraco.functools==4.1.0
jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1696326070614/work
Jinja2==3.1.4
jmespath==1.0.1
jsonschema==4.20.0
jsonschema-specifications==2023.11.2
jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1726610684920/work
jupyter_core @ file:///D:/bld/jupyter_core_1710257313664/work
keyring==25.4.1
kiwisolver==1.4.7
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib==3.9.2
matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1713250518406/work
mccabe==0.7.0
mdurl==0.1.2
more-itertools==10.5.0
mypy-extensions==1.0.0
nest_asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1705850609492/work
networkx==3.2.1
nh3==0.2.18
numpy==1.26.2
packaging==23.2
pandas==2.2.3
parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1712320355065/work
pathlib==1.0.1
pathspec==0.11.2
pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work
pillow==10.4.0
pkginfo==1.10.0
platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1726613481435/work
pluggy==1.5.0
prompt-toolkit==3.0.41
psutil @ file:///D:/bld/psutil_1725737996000/work
pure_eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1721585709575/work
pycodestyle==2.12.1
pycparser==2.21
pydantic==2.5.2
pydantic_core==2.14.5
pyflakes==3.2.0
Pygments==2.17.2
pyogrio==0.9.0
pyparsing==3.1.4
pyproj==3.6.1
pytest==8.3.3
python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1709299778482/work
pytz==2024.2
pywin32==306
pywin32-ctypes==0.2.3
PyYAML==6.0.1
pyzmq @ file:///D:/bld/pyzmq_1725449086441/work
readme_renderer==43.0
referencing==0.31.1
regex==2023.10.3
requests==2.32.3
requests-toolbelt==1.0.0
rfc3986==2.0.0
rich==13.7.0
rpds-py==0.13.2
s3transfer==0.10.2
scipy==1.11.4
shapely==2.0.6
six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work
smmap==5.0.1
sniffio==1.3.0
snowballstemmer==2.2.0
sounddevice==0.4.6
soundfile==0.12.1
Sphinx==7.4.7
sphinx-rtd-theme==2.0.0
sphinxcontrib-applehelp==2.0.0
sphinxcontrib-devhelp==2.0.0
sphinxcontrib-htmlhelp==2.1.0
sphinxcontrib-jquery==4.1
sphinxcontrib-jsmath==1.0.1
sphinxcontrib-qthelp==2.0.0
sphinxcontrib-serializinghtml==2.0.0
stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work
tornado @ file:///D:/bld/tornado_1724956185692/work
tqdm==4.66.1
traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1713535121073/work
tree-sitter==0.20.4
tree-sitter-languages==1.8.0
twine==5.1.1
typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1717802530399/work
tzdata==2024.1
urllib3==2.2.3
wcwidth==0.2.12
zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1726248574750/work

==================================================

File: c:\GH\ras-commander\setup.py
==================================================
from setuptools import setup, find_packages
from setuptools.command.build_py import build_py
import subprocess
from pathlib import Path

class CustomBuildPy(build_py):
    def run:
    """Docs only, see 'run.py' for full function code"""
)

"""
ras-commander setup.py

This file is used to build and publish the ras-commander package to PyPI.

To build and publish this package, follow these steps:

1. Ensure you have the latest versions of setuptools, wheel, and twine installed:
   pip install --upgrade setuptools wheel twine

2. Update the version number in ras_commander/__init__.py (if not using automatic versioning)

3. Create source distribution and wheel:
   python setup.py sdist bdist_wheel

4. Check the distribution:
   twine check dist/*

5. Upload to Test PyPI (optional):
   twine upload --repository testpypi dist/*

6. Install from Test PyPI to verify (optional):
   pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple ras-commander

7. Upload to PyPI:
   twine upload dist/* --username __token__ --password <your_api_key>


8. Install from PyPI to verify:
   pip install ras-commander

Note: Ensure you have the necessary credentials and access rights to upload to PyPI.
For more information, visit: https://packaging.python.org/tutorials/packaging-projects/

"""

==================================================

File: c:\GH\ras-commander\STYLE_GUIDE.md
==================================================
# RAS Commander (ras-commander) Style Guide

## Table of Contents
1. [Naming Conventions](#1-naming-conventions)
2. [Code Structure and Organization](#2-code-structure-and-organization)
3. [Documentation and Comments](#3-documentation-and-comments)
4. [Code Style](#4-code-style)
5. [Error Handling](#5-error-handling)
6. [Testing](#6-testing)
7. [Version Control](#7-version-control)
8. [Type Hinting](#8-type-hinting)
9. [Project-Specific Conventions](#9-project-specific-conventions)
10. [Inheritance](#10-inheritance)
11. [RasUtils Usage](#11-rasutils-usage)
12. [Working with RasExamples](#12-working-with-rasexamples)

## 1. Naming Conventions

### 1.1 General Rules
- Use `snake_case` for all function and variable names
- Use `PascalCase` for class names
- Use `UPPER_CASE` for constants

### 1.2 Library-Specific Naming
- Informal Name: RAS Commander
- Package Name and GitHub Library Name: ras-commander (with a hyphen)
- Import Name: ras_commander (with an underscore)
- Main Class of functions for HEC-RAS Automation: RasCmdr

### 1.3 Function Naming
- Start function names with a verb describing the action
- Use clear, descriptive names
- Common verbs and their uses:
  - `get_`: retrieve data
  - `set_`: set values or properties
  - `compute_`: execute or calculate
  - `clone_`: copy
  - `clear_`: remove or reset data
  - `find_`: search
  - `update_`: modify existing data

### 1.4 Abbreviations
Use the following abbreviations consistently throughout the codebase:

- ras: HEC-RAS
- prj: Project
- geom: Geometry
- pre: Preprocessor
- geompre: Geometry Preprocessor
- num: Number
- init: Initialize
- XS: Cross Section
- DSS: Data Storage System
- GIS: Geographic Information System
- BC: Boundary Condition
- IC: Initial Condition
- TW: Tailwater

Use these abbreviations in lowercase for function and variable names (e.g., `geom`, not `Geom` or `GEOM`).

### 1.5 Class Naming
- Use `PascalCase` for class names (e.g., `FileOperations`, `PlanOperations`, `RasCmdr`)
- Class names should be nouns or noun phrases

### 1.6 Variable Naming
- Use descriptive names indicating purpose or content
- Prefix boolean variables with `is_`, `has_`, or similar

## 2. Code Structure and Organization

### 2.1 File Organization
- Group related functions into appropriate classes
- Keep each class in its own file, named after the class

### 2.2 Function Organization
- Order functions logically within a class
- Place common or important functions at the top of the class

### 2.3 Module Structure
- Use the following order for module contents:
  1. Module-level docstring
  2. Imports (grouped and ordered)
  3. Constants
  4. Classes
  5. Functions

## 3. Documentation and Comments

### 3.1 Docstrings
- Use docstrings for all modules, classes, methods, and functions
- Follow Google Python Style Guide format
- Include parameters, return values, and a brief description
- For complex functions, include examples in the docstring

### 3.2 Comments
- Use inline comments sparingly, only for complex logic
- Keep comments up-to-date with code changes
- Use TODO comments for future work, formatted as: `# TODO: description`

## 4. Code Style

### 4.1 Imports
- Order imports as follows:
  1. Standard library imports
  2. Third-party library imports
  3. Local application imports
- Use absolute imports
- Use `import ras_commander as ras` for shortening the library name in examples

### 4.2 Whitespace
- Follow PEP 8 guidelines
- Use 4 spaces for indentation (no tabs)
- Use blank lines to separate logical sections of code

### 4.3 Line Length
- Limit lines to 79 characters for code, 72 for comments and docstrings
- Use parentheses for line continuation in long expressions

## 5. Error Handling

**Use Logging Instead of Prints**
Ensure that every operation that can fail or needs to provide feedback to the user is logged instead of using `print`. This will help in debugging and improve monitoring during execution.

   ```python
   logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
   ```

   Example of replacing a `print` with logging:
   ```python
   logging.info('Starting HEC-RAS simulation...')
   ```

- Use explicit exception handling with try/except blocks
- Raise custom exceptions when appropriate, with descriptive messages
- Use logging for error reporting and debugging information
- Use specific exception types when raising errors (e.g., `ValueError`, `FileNotFoundError`)
- Provide informative error messages that include relevant details
- Implement proper cleanup in finally blocks when necessary
- For user-facing functions, consider wrapping internal exceptions in custom exceptions specific to ras-commander

Example:
```python
try:
    result = compute_plan(plan_number)
except FileNotFoundError as e:
    raise RasCommanderError(f"Plan file not found: {e}")
except ValueError as e:
    raise RasCommanderError(f"Invalid plan parameter: {e}")
except Exception as e:
    raise RasCommanderError(f"Unexpected error during plan computation: {e}")
```

## 6. Testing

- Write unit tests for all functions and methods
- Use the `unittest` framework
- Aim for high test coverage, especially for critical functionality
- Include tests for both single-project and multi-project scenarios
- Write clear and descriptive test names
- Use setUp and tearDown methods for common test preparations and cleanups
- Use mock objects when appropriate to isolate units under test

## 7. Version Control

- Use meaningful commit messages that clearly describe the changes made
- Create feature branches for new features or significant changes
- Submit pull requests for code review before merging into the main branch
- Keep commits focused and atomic (one logical change per commit)
- Use git tags for marking releases
- Follow semantic versioning for release numbering

## 8. Type Hinting

- Use type hints for all function parameters and return values
- Use the `typing` module for complex types (e.g., `List`, `Dict`, `Optional`)
- Include type hints in function signatures and docstrings
- Use `Union` for parameters that can accept multiple types
- For methods that don't return a value, use `-> None`

Example:
```python
from typing import List, Optional

def process_plans(plan_numbers: List[str], max_workers: Optional[int] = None) -> bool:
    # Function implementation
    return True
```

## 9. Project-Specific Conventions

### 9.1 RAS Instance Handling
- Design functions to accept an optional `ras_object` parameter:
  ```python
  def some_function(param1, param2, ras_object=None):
      ras_obj = ras_object or ras
      ras_obj.check_initialized()
      # Function implementation
  ```

### 9.2 File Path Handling
- Use `pathlib.Path` for file and directory path manipulations
- Convert string paths to Path objects at the beginning of functions

### 9.3 DataFrame Handling
- Use pandas for data manipulation and storage where appropriate
- Prefer method chaining for pandas operations to improve readability

### 9.4 Parallel Execution
- Follow the guidelines in the "Benchmarking is All You Need" blog post for optimal core usage in parallel plan execution

### 9.5 Function Return Values
- Prefer returning meaningful values over modifying global state
- Use tuple returns for multiple values instead of modifying input parameters

## 10. Inheritance

### 10.1 General Principles

- Prioritize composition over inheritance when appropriate
- Design base classes for extension
- Clearly document the public API and subclass API using docstrings

### 10.2 Naming Conventions

- Public API: No leading underscores
- Subclass API: Single leading underscore (e.g., `_prepare_for_execution`)
- Internal attributes and methods: Single leading underscore
- Name mangling (double leading underscores): Use sparingly and document the decision clearly

### 10.3 Template Method Pattern

Consider using the template method pattern in base classes to define a high-level algorithm structure. Subclasses can then override specific steps to customize behavior.

### 10.4 Dataframe Access Control

Use properties to control access and modification of dataframes, providing a controlled interface for subclasses.

## 11. RasUtils Usage

- Use RasUtils for general-purpose utility functions that don't fit into other specific classes
- When adding new utility functions, ensure they are static methods of the RasUtils class
- Keep utility functions focused and single-purpose
- Document utility functions thoroughly, including examples of usage

Example:
```python
class RasUtils:
    @staticmethod
    def create_backup(file_path: Path, backup_suffix: str = "_backup") -> Path:
        """
        Create a backup of the specified file.

        Args:
            file_path (Path): Path to the file to be backed up
            backup_suffix (str): Suffix to append to the backup file name

        Returns:
            Path: Path to the created backup file

        Example:
            >>> backup_path = RasUtils.create_backup(Path("project.prj"))
            >>> print(f"Backup created at: {backup_path}")
        """
        # Function implementation
```

## 12. Working with RasExamples

- Use RasExamples for managing and loading example HEC-RAS projects
- Always check if example projects are already downloaded before attempting to download them again
- Use the `list_categories()` and `list_projects()` methods to explore available examples
- When extracting projects, use meaningful names and keep track of extracted paths
- Clean up extracted projects when they are no longer needed using `clean_projects_directory()`

Example:
```python
ras_examples = RasExamples()
if not ras_examples.is_project_extracted("Bald Eagle Creek"):
    extracted_path = ras_examples.extract_project("Bald Eagle Creek")[0]
    # Use the extracted project
    # ...
    # Clean up when done
    RasUtils.remove_with_retry(extracted_path, is_folder=True)
```

Remember, consistency is key. When in doubt, prioritize readability and clarity in your code. Always consider the maintainability and extensibility of the codebase when making design decisions.


13. Logging

Instructions for setting up a minimal logging decorator and applying it to functions:

1. Create logging_config.py:
```python
import logging
import functools

def setup_logging(level=logging.INFO):
    logging.basicConfig(level=level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

def log_call(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        logger = logging.getLogger(func.__module__)
        logger.info(f"Calling {func.__name__}")
        return func(*args, **kwargs)
    return wrapper

setup_logging()
```

2. In each module file (e.g., RasPrj.py, RasPlan.py):
   - Add at the top: `from ras_commander.logging_config import log_call`
   - Remove all existing logging configurations and logger instantiations

3. Apply the decorator to functions:
   - Replace existing logging statements with the `@log_call` decorator
   - Remove any manual logging within the function body

Example changes to functions:

Before:
```python
def compute_plan(plan_number, dest_folder=None, ras_object=None, clear_geompre=False, num_cores=None):
    logging.info(f"Computing plan {plan_number}")
    # ... function logic ...
    logging.info(f"Plan {plan_number} computation complete")
    return result
```

After:
```python
@log_call
def compute_plan(plan_number, dest_folder=None, ras_object=None, clear_geompre=False, num_cores=None):
    # ... function logic ...
    return result
```

Apply this pattern across all functions in the library. This approach will significantly reduce the code footprint while maintaining basic logging functionality.
==================================================

File: c:\GH\ras-commander\.gitignore\.gitignore
==================================================
# Ignore the example_projects folder and all its subfolders
examples/example_projects/

# Ignore workspace, projects, and my_projects folders
workspace/
projects/
my_projects/

# Ignore FEMA BLE Models
examples/FEMA_BLE_Models/
examples/hdf_example_data/


# Ignore library assistant config
library_assistant/config/

# Ignore Python egg info
*.egg-info/
.eggs/

# Ignore the Example_Projects_6_5.zip file
Example_Projects_6_5.zip

# Ignore the misc folder and all its subfolders
misc/

# Ignore Python cache files
__pycache__/
*.py[cod]

# Ignore compiled Python files
*.so

# Ignore distribution / packaging
dist/
build/

# Ignore test cache
.pytest_cache/

# Ignore virtual environments
.venv/
venv/

# Ignore IDE-specific files (optional, uncomment if needed)
# .vscode/
# .idea/

# Ignore OS-specific files
.DS_Store
Thumbs.db
==================================================

File: c:\GH\ras-commander\examples\01_project_initialization.py
==================================================
# 01_project_initialization.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "BaldEagleCrkMulti2D", "Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example demonstrates both the default global 'ras' object and custom ras objects.
# 2. The global 'ras' object is suitable for simple scripts working with a single project.
# 3. Custom ras objects are recommended for complex scripts or when working with multiple projects.
# 4. The init_ras_project function initializes a project and sets up the ras object.
# 5. Each ras object contains comprehensive information about its project, including plan, geometry, flow files, and boundary conditions.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Use descriptive names for custom ras objects to clearly identify different projects.

def print_ras_object_data:
    """Docs only, see 'print_ras_object_data.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\02_plan_operations.py
==================================================
# 02_plan_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on plans, geometries, and unsteady flows using the functions within the RasPlan Class.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Geometry Cloning: Clone a geometry associated with the original plan, generating a new geometry entry.
4. Unsteady Flow Cloning: Clone an unsteady flow, creating a new unsteady flow entry.
5. Plan Configuration:
   a. Set the cloned geometry for the new plan.
   b. Set the cloned unsteady flow for the new plan.
   c. Update the number of cores to be used for the new plan.
   d. Configure geometry preprocessor options for the new plan.
6. Plan Computation: Compute the new plan and verify successful execution.
7. Results Verification: Check the HDF entries to confirm that results were written.

Additional operations that could be demonstrated:
8. Plan Modification: Update specific parameters in the plan file (e.g., simulation time, output intervals).
9. Geometry Editing: Modify cross-sections, manning's n values, or other geometry data.
10. Unsteady Flow Modification: Adjust boundary conditions or initial conditions.
11. Batch Operations: Perform operations on multiple plans simultaneously.
12. Error Handling: Demonstrate how to handle and report errors during plan operations.
13. Results Analysis: Extract and analyze key output values from the computed plan.
"""

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\03_geometry_operations.py
==================================================
# 03_geometry_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Muncie"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasGeo class provides methods for working with geometry files and preprocessor operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Always clear geometry preprocessor files before making significant changes to ensure clean results.

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\04_unsteady_flow_operations.py
==================================================
# 04_unsteady_flow_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

"""
This script demonstrates the process of initializing a HEC-RAS project and performing various operations on unsteady flow plans using the ras-commander library.

Process Flow:
1. Project Initialization: Initialize a HEC-RAS project by specifying the project path and version.
2. Plan Cloning: Clone an existing plan, creating a new plan entry.
3. Unsteady Flow Parameter Updates: Modify various unsteady flow parameters in the new plan.
4. Plan Computation: Compute the new plan and verify successful execution.

Note: This example uses the default global 'ras' object for simplicity. For complex scripts or when working with
multiple projects, it's recommended to create and use separate ras objects.
"""

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\05_utility_functions.py
==================================================
# 05_utility_functions.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasUtils class provides various utility functions for working with HEC-RAS projects.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\06_single_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Define the "example_projects" folder in the same directory as the script
examples_path = Path(__file__).parent / "example_projects"

# Delete the project if it exists
if examples_path.exists():
    import shutil
    shutil.rmtree(examples_path)

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\07_sequential_plan_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path
# Define the keys to search for in folder names
# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\08_parallel_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

def get_physical_core_count:
    """Docs only, see 'get_physical_core_count.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\09_specifying_plans.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Housekeeping Note: 
# For all of the functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders
# So if you want your script to be repeatable, you need to make sure you delete the folders before running again.
# Otherwise an error will be raised to prevent overwriting any results from your previous runs.
# This will not be done by the example projects routines, which only overwrite the source folder for repeatability. 
    
import shutil
from pathlib import Path

# Delete example projects folder
current_file = Path(__file__).resolve()
current_dir = current_file.parent
delete_folder_path = current_dir / "example_projects"

if delete_folder_path.exists():
    print(f"Removing existing folder: {delete_folder_path}")
    shutil.rmtree(delete_folder_path)
else:
    print(f"Folder not found: {delete_folder_path}")

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander (ras-commander) Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides methods for executing plans in various ways.
# 5. You can specify individual plans or lists of plans for batch operations.

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. When specifying plans, use plan numbers as strings (e.g., "01", "02") for consistency.
# 5. Always check the available plans in the project before specifying plan numbers for execution.

def main:
    """Docs only, see 'main.py' for full function code"""

==================================================

File: c:\GH\ras-commander\examples\10_arguments_for_compute.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

# RAS Commander Library Notes:
# 1. This example uses the default global 'ras' object for simplicity.
# 2. If you need to work with multiple projects, use separate ras objects for each project.
# 3. Once you start using non-global ras objects, stick with that approach throughout your script.
# 4. The RasCmdr class provides various arguments for fine-tuning plan computation:
#    - plan_number: String representing the plan number to compute (e.g., "01")
#    - dest_folder: Path object specifying the destination folder for computation results
#    - clear_geompre: Boolean to clear geometry preprocessor files before computation
#    - num_cores: Integer specifying the number of cores to use
#    - overwrite_dest: Boolean to determine if existing destination folders should be overwritten

# Best Practices:
# 1. For simple scripts working with a single project, using the global 'ras' object is fine.
# 2. For complex scripts or when working with multiple projects, create and use separate ras objects.
# 3. Be consistent in your approach: don't mix global and non-global ras object usage in the same script.
# 4. Utilize the various arguments in compute functions to customize plan execution.
# 5. Always consider your system's capabilities when setting num_cores.
# 6. Use clear_geompre=True when you want to ensure a clean computation environment.
# 7. Specify dest_folder to keep your project folder organized and prevent overwriting previous results.

def main:
    """Docs only, see 'main.py' for full function code"""

==================================================

File: c:\GH\ras-commander\examples\12_plan_set_execution.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

import pandas as pd


def create_plan_set:
    """Docs only, see 'create_plan_set.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\13_multiple_project_operations.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek", "Muncie"])

#### --- START OF SCRIPT --- ####

def execute_plan:
    """Docs only, see 'execute_plan.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\14_Core_Sensitivity.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ras-commander pandas requests pathlib matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14_Core_Sensitivity.ipynb\n",
    "Testing Core Sensitivity for RAS using the Bald Eagle Creek Multi-Gage 2D project.  \n",
    "\n",
    "\n",
    "This should take around 15-45 minutes to run depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Flexible imports to allow for development without installation\n",
    "try:\n",
    "    # Try to import from the installed package\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "except ImportError:\n",
    "    # If the import fails, add the parent directory to the Python path\n",
    "    import os\n",
    "    current_file = Path(os.getcwd()).resolve()\n",
    "    parent_directory = current_file.parent\n",
    "    sys.path.append(str(parent_directory))\n",
    "    \n",
    "    # Now try to import again\n",
    "    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasHdf, ras\n",
    "\n",
    "print(\"ras_commander imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ras_commander import RasExamples, init_ras_project, RasCmdr, RasPlan, RasGeo\n",
    "\n",
    "# Step 1: Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n",
    "\n",
    "# Use Path.cwd() to get the current working directory in a Jupyter Notebook\n",
    "current_directory = Path.cwd()\n",
    "project_path = current_directory / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n",
    "\n",
    "# Step 2: Initialize the Muncie Project using init_ras_project (from ras_commander)\n",
    "muncie_project = init_ras_project(project_path, \"6.6\")\n",
    "\n",
    "# Step 3: Initialize a DataFrame to store execution results\n",
    "results = []\n",
    "\n",
    "# Step 4: Run sensitivity analysis for Plan 03 with core counts 1-8\n",
    "plan_number = '03'\n",
    "print(f\"Running sensitivity analysis for Plan {plan_number}\")\n",
    "\n",
    "# Clear geompre files before running the plan\n",
    "plan_path = RasPlan.get_plan_path(plan_number)\n",
    "RasGeo.clear_geompre_files(plan_path)\n",
    "\n",
    "for cores in range(1, 9):\n",
    "    print(f\"Running with {cores} core(s)\")\n",
    "    # Set core count for this plan\n",
    "    RasPlan.set_num_cores(plan_number, cores)\n",
    "    \n",
    "    # Time the execution of the plan\n",
    "    start_time = time.time()\n",
    "    RasCmdr.compute_plan(plan_number)\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"plan_number\": plan_number,\n",
    "        \"cores\": cores,\n",
    "        \"execution_time\": execution_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "print(\"Sensitivity analysis complete\")\n",
    "\n",
    "# Step 5: Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv(\"core_sensitivity_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FOR REVISIONS:\n",
    "- Use HDF compute summary to show the time for each preproces/unsteady compute/postprocess step. \n",
    "- First, run preprocessor and then toggle options to only run unsteady compute and postprocess. \n",
    "- Plot each step separately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, load the results from a CSV file\n",
    "results_df = pd.read_csv(\"core_sensitivity_results.csv\")\n",
    "\n",
    "# Display the results dataframe for verification\n",
    "print(\"results_df DataFrame:\")\n",
    "display(results_df)\n",
    "\n",
    "# Step 6: Calculate unit runtime (based on 1 core execution time)\n",
    "results_df['unit_runtime'] = results_df.groupby('plan_number')['execution_time'].transform(lambda x: x / x.iloc[0])\n",
    "\n",
    "# Get the project name from the ras object\n",
    "project_name = ras.project_name\n",
    "\n",
    "# Step 7: Plot a line chart for unit runtime vs. cores for each plan\n",
    "plt.figure(figsize=(10, 6))\n",
    "for plan in results_df['plan_number'].unique():\n",
    "    plan_data = results_df[results_df['plan_number'] == plan]\n",
    "    plt.plot(plan_data['cores'], plan_data['unit_runtime'], label=f\"Plan {plan}\")\n",
    "\n",
    "plt.xlabel(\"Number of Cores\")\n",
    "plt.ylabel(\"Unit Runtime (Relative to 1 Core)\")\n",
    "plt.title(f\"{project_name} (HEC Example Project)\\nCore Count Sensitivity Analysis\")\n",
    "plt.legend(title=\"Plan Number\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "summary_stats = results_df.groupby('cores')['execution_time'].agg(['mean', 'min', 'max'])\n",
    "display(summary_stats)\n",
    "\n",
    "# Calculate and print speedup\n",
    "speedup = results_df[results_df['cores'] == 1]['execution_time'].mean() / results_df[results_df['cores'] == 8]['execution_time'].mean()\n",
    "print(f\"\\nAverage speedup from 1 to 8 cores: {speedup:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "releasecmdr311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\15_plan_key_operations.py
==================================================
# 15_plan_key_operations.py

#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\16_scanning_ras_project_info.py
==================================================
import sys
from pathlib import Path

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    from ras_commander import init_ras_project, RasPrj, RasExamples
except ImportError:
    sys.path.append(str(parent_directory))
    from ras_commander import init_ras_project, RasPrj, RasExamples

import logging

def generate_category_summary:
    """Docs only, see 'generate_category_summary.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\examples\17_parallel_execution_ble.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil
import psutil
import math
import logging

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, RasPrj

# Configure logging
logging.basicConfig(
    level=logging.INFO,  # Set the logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',  # Log message format
    handlers=[
        logging.StreamHandler()  # Log to stderr
    ]
)

# Initialize RasExamples
ras_examples = RasExamples()

#### --- START OF SCRIPT --- ####

# ras-commander Library Notes:
# 1. This example uses separate RasPrj objects for each project/folder.
# 2. Using separate RasPrj objects allows working with multiple projects or folders.
# 3. We'll create new RasPrj objects for the original project and each output folder.
# 4. For functions that do batched execution (sequential or parallel), they are careful not to overwrite existing folders.
# 5. If you want your script to be repeatable, make sure to delete the folders before running again.

# Best Practices:
# 1. For complex scripts or when working with multiple projects/folders, create and use separate RasPrj objects.
# 2. Be consistent in your approach: use non-global RasPrj objects throughout the script.
# 3. When using parallel execution, consider the number of cores available on your machine.
# 4. Use the dest_folder argument to keep your project folder clean and organized.

##  WHISKY CHITTO DOES NOT WORK - BLE MODEL IS BROKEN AND REQUIRED FIXING BEFORE RUNNING

def get_physical_core_count:
    """Docs only, see 'get_physical_core_count.py' for full function code"""


==================================================

File: c:\GH\ras-commander\examples\18_2d_hdf_data_extraction.ipynb
==================================================
{"cells":[{"cell_type":"markdown","metadata":{},"source":["# HEC-RAS 2D HDF Data Analysis Notebook\n","\n","This notebook demonstrates how to manipulate and analyze HEC-RAS 2D HDF data using the ras-commander library. It leverages the HdfBase, HdfUtils, HdfStruc, HdfMesh, HdfXsec, HdfBndry, HdfPlan, HdfResultsPlan, HdfResultsMesh, and HdfResultsXsec classes to streamline data extraction, processing, and visualization.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import required Libraries\n","import subprocess\n","import sys\n","import os\n","from pathlib import Path\n","\n","def install_module(module_name):\n","    try:\n","        __import__(module_name)\n","    except ImportError:\n","        print(f\"{module_name} not found. Installing...\")\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", module_name])\n","\n","# List of modules to check and install if necessary\n","modules = ['h5py', 'numpy', 'requests', 'geopandas', 'matplotlib', 'pandas', 'pyproj', 'shapely', 'xarray']\n","for module in modules:\n","    install_module(module)\n","\n","# Import the rest of the required libraries\n","import pandas as pd\n","import numpy as np\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","import pyproj\n","from shapely.geometry import Point, LineString, Polygon\n","import xarray as xr\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Install ras-commander if you are not in a dev environment. \n","# install_module(ras-commander)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing ras-commander flexibly (from package or local dev copy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","from pathlib import Path\n","\n","# Flexible imports to allow for development without installation \n","#  ** Use this version with Jupyter Notebooks **\n","try:\n","    # Try to import from the installed package\n","    from ras_commander import (\n","        init_ras_project, \n","        HdfBase, \n","        HdfUtils, \n","        HdfStruc, \n","        HdfMesh, \n","        HdfXsec, \n","        HdfBndry, \n","        HdfPlan, \n","        HdfResultsPlan, \n","        HdfResultsMesh, \n","        HdfResultsXsec,\n","        RasExamples, \n","        RasCmdr, \n","        RasPlan, \n","        RasGeo, \n","        RasUnsteady, \n","        RasUtils, \n","        RasPrj, \n","        RasGpt, \n","        ras,\n","        XsSteadyOutputVar,\n","        SummaryOutputVar,\n","        TimeSeriesOutputVar\n","    )\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","except ImportError:\n","    # If the import fails, add the parent directory to the Python path\n","    import os\n","    current_file = Path(os.getcwd()).resolve()\n","    parent_directory = current_file.parent\n","    sys.path.append(str(parent_directory))\n","    \n","    # Now try to import again\n","    from ras_commander import (\n","        init_ras_project, \n","        HdfBase, \n","        HdfUtils, \n","        HdfStruc, \n","        HdfMesh, \n","        HdfXsec, \n","        HdfBndry, \n","        HdfPlan, \n","        HdfResultsPlan, \n","        HdfResultsMesh, \n","        HdfResultsXsec,\n","        RasExamples, \n","        RasCmdr, \n","        RasPlan, \n","        RasGeo, \n","        RasUnsteady, \n","        RasUtils, \n","        RasPrj, \n","        RasGpt, \n","        ras,\n","    )\n","    from ras_commander.Decorators import standardize_input, log_call\n","    from ras_commander.LoggingConfig import setup_logging, get_logger\n","\n","print(\"ras_commander imported successfully\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the BaldEagleCrkMulti2D project from HEC and run plan 01\n","\n","# Define the path to the BaldEagleCrkMulti2D project\n","current_dir = Path.cwd()  # Adjust if your notebook is in a different directory\n","bald_eagle_path = current_dir / \"example_projects\" / \"BaldEagleCrkMulti2D\"\n","import logging\n","\n","# Check if BaldEagleCrkMulti2D.p06.hdf exists (so we don't have to re-run the simulation when re-running or debugging)\n","hdf_file = bald_eagle_path / \"BaldEagleDamBrk.p06.hdf\"\n","\n","if not hdf_file.exists():\n","    # Initialize RasExamples and extract the BaldEagleCrkMulti2D project\n","    ras_examples = RasExamples()\n","    ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])\n","\n","    # Initialize custom Ras object\n","    bald_eagle = RasPrj()\n","\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    logging.info(f\"Bald Eagle project initialized with folder: {bald_eagle.project_folder}\")\n","    \n","    logging.info(f\"Bald Eagle object id: {id(bald_eagle)}\")\n","    \n","    # Define the plan number to execute\n","    plan_number = \"06\"\n","\n","    # Set plan keys for the project\n","    RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=bald_eagle)\n","    RasPlan.update_plan_value(plan_number, \"Run UNet\", 1, ras_object=bald_eagle)\n","    RasPlan.update_plan_value(plan_number, \"Run PostProcess\", 1, ras_object=bald_eagle)\n","    RasPlan.update_plan_value(plan_number, \"Run RASMapper\", 0, ras_object=bald_eagle)\n","\n","    # Execute Plan 06 using RasCmdr for Bald Eagle\n","    print(f\"Executing Plan {plan_number} for the Bald Eagle Creek project...\")\n","    success_bald_eagle = RasCmdr.compute_plan(plan_number, ras_object=bald_eagle)\n","    if success_bald_eagle:\n","        print(f\"Plan {plan_number} executed successfully for Bald Eagle.\\n\")\n","    else:\n","        print(f\"Plan {plan_number} execution failed for Bald Eagle.\\n\")\n","else:\n","    print(\"BaldEagleCrkMulti2D.p06.hdf already exists. Skipping project extraction and plan execution.\")\n","    # Initialize the RAS project using the custom ras object\n","    bald_eagle = RasPrj()\n","    bald_eagle = init_ras_project(bald_eagle_path, \"6.6\", ras_instance=bald_eagle)\n","    plan_number = \"06\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load Plan and Geometry Dataframes and find Plan and Geometry HDF Paths\n","\n","# Display plan_df for bald_eagle project\n","print(\"Plan DataFrame for bald_eagle project:\")\n","display(bald_eagle.plan_df)\n","\n","# Display geom_df for bald_eagle project\n","print(\"\\nGeometry DataFrame for bald_eagle project:\")\n","display(bald_eagle.geom_df)\n","\n","# Get the plan HDF path\n","plan_number = \"06\"  # Assuming we're using plan 01 as in the previous code\n","plan_hdf_path = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'HDF_Results_Path'].values[0]\n","\n","# Get the geometry file number from the plan DataFrame\n","geom_file = bald_eagle.plan_df.loc[bald_eagle.plan_df['plan_number'] == plan_number, 'Geom File'].values[0]\n","geom_number = geom_file[1:]  # Remove the 'g' prefix\n","\n","# Get the geometry HDF path\n","geom_hdf_path = bald_eagle.geom_df.loc[bald_eagle.geom_df['geom_number'] == geom_number, 'hdf_path'].values[0]\n","\n","print(f\"\\nPlan HDF path for Plan {plan_number}: {plan_hdf_path}\")\n","print(f\"Geometry HDF path for Plan {plan_number}: {geom_hdf_path}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Define the HDF input path as Plan Number\n","\n","plan_number = \"06\"  # Assuming we're using plan 01 as in the previous code\n"]},{"cell_type":"markdown","metadata":{},"source":["RasHdfUtils\n","| Method Name | Description |\n","|-------------|-------------|\n","| get_attrs | Converts attributes from a HEC-RAS HDF file into a Python dictionary for a given attribute path |\n","| get_root_attrs | Returns attributes at root level of HEC-RAS HDF file |\n","| get_hdf_paths_with_properties | Gets all paths in the HDF file with their properties |\n","| get_group_attributes_as_df | Gets attributes of a group in the HDF file as a DataFrame |\n","| get_hdf_filename | Gets the HDF filename from various input types |\n","| get_runtime_data | Extracts runtime and compute time data from a single HDF file |\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get HDF Paths with Properties (For Exploring HDF Files)\n","plan_number = \"06\"  # Assuming we're using plan 06 as in the previous code\n","hdf_paths_df = HdfUtils.get_hdf_paths_with_properties(plan_number, ras_object=bald_eagle)\n","display(hdf_paths_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract runtime and compute time data\n","print(\"\\nExample 2: Extracting runtime and compute time data\")\n","runtime_df = HdfResultsPlan.get_runtime_data(hdf_input=plan_number, ras_object=bald_eagle)\n","if runtime_df is not None:\n","    display(runtime_df)\n","else:\n","    print(\"No runtime data found.\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# TODO: Example for get_attrs"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# TODO: Example for get_root_attrs"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# TODO: Example for get_hdf_paths_with_properties"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# TODO: Example for get_group_attributes_as_df"]},{"cell_type":"markdown","metadata":{},"source":["Table of all the functions in the RasGeomHdf class from the ras_commander/RasGeomHdf.py file:\n","\n","| Function Name | Description |\n","|---------------|-------------|\n","| projection | Returns the projection of the RAS geometry as a pyproj.CRS object |\n","| get_geom_attrs | Returns base geometry attributes from a HEC-RAS HDF file |\n","\n","| mesh_area_names | Returns a list of the 2D mesh area names of the RAS geometry |\n","| get_geom_2d_flow_area_attrs | Returns geometry 2d flow area attributes from a HEC-RAS HDF file |\n","| mesh_areas | Returns 2D flow area perimeter polygons |\n","| mesh_cell_polygons | Returns 2D flow mesh cell polygons |\n","| mesh_cell_points | Returns 2D flow mesh cell points |\n","| mesh_cell_faces | Returns 2D flow mesh cell faces |\n","\n","| get_geom_structures_attrs | Returns geometry structures attributes from a HEC-RAS HDF file |\n","\n","\n","\n","\n","| bc_lines | Returns 2D mesh area boundary condition lines |\n","| breaklines | Returns 2D mesh area breaklines |\n","\n","\n","\n","| refinement_regions | Returns 2D mesh area refinement regions |\n","| structures | Returns the model structures |\n","| reference_lines_names | Returns reference line names |\n","| reference_points_names | Returns reference point names |\n","| reference_lines | Returns the reference lines geometry and attributes |\n","| reference_points | Returns the reference points geometry and attributes |\n","| cross_sections | Returns the model 1D cross sections |\n","| river_reaches | Returns the model 1D river reach lines |\n","| cross_sections_elevations | Returns the model cross section elevation information |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# For all of the RasGeomHdf Class Functions, we will use geom_hdf_path\n","print(geom_hdf_path)\n","\n","# For the example project, plan 06 is associated with geometry 09\n","# If you want to call the geometry by number, call RasHdfGeom functions with a number\n","# Otherwise, if you want to look up geometry hdf path by plan number, follow the logic in the previous code cells"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfUtils for extracting projection\n","print(\"\\nExtracting Projection from HDF\")\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Projection: {projection}\")\n","else:\n","    print(\"No projection information found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfPlan for geometry-related operations\n","print(\"\\nExample: Extracting Base Geometry Attributes\")\n","geom_attrs = HdfPlan.get_geom_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if geom_attrs:\n","    # Convert the dictionary to a DataFrame for better display\n","    geom_attrs_df = pd.DataFrame([geom_attrs])\n","    \n","    # Display the DataFrame\n","    print(\"Base Geometry Attributes:\")\n","    display(geom_attrs_df)\n","else:\n","    print(\"No base geometry attributes found.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use HdfMesh for geometry-related operations\n","print(\"\\nExample 3: Listing 2D Flow Area Names\")\n","flow_area_names = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"2D Flow Area Names:\", flow_area_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Attributes (get_geom_2d_flow_area_attrs)\n","print(\"\\nExample: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_df = pd.DataFrame([flow_area_attributes])\n","    \n","    # Display the DataFrame\n","    print(\"2D Flow Area Attributes:\")\n","    display(flow_area_df)\n","    \n","    # Optionally, you can access specific attributes\n","    print(\"\\nSpecific Attribute Examples:\")\n","    print(f\"Cell Average Size: {flow_area_attributes.get('Cell Average Size', 'N/A')}\")\n","    print(f\"Manning's n: {flow_area_attributes.get('Manning''s n', 'N/A')}\")\n","    print(f\"Terrain Filename: {flow_area_attributes.get('Terrain Filename', 'N/A')}\")\n","else:\n","    print(\"No 2D Flow Area attributes found.\")\n","\n","# Note: This example assumes that get_geom_2d_flow_area_attrs returns a dictionary.\n","# If it returns a different format, you may need to adjust the code accordingly.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the 2D Flow Area Perimeter Polygons\n","import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(figsize=(12, 8))\n","mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none')\n","\n","# Add labels for each polygon\n","for idx, row in mesh_areas.iterrows():\n","    centroid = row.geometry.centroid\n","    # Check if 'Name' column exists, otherwise use a default label\n","    label = row.get('Name', f'Area {idx}')\n","    ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","\n","plt.title('2D Flow Area Perimeter Polygons')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract 2D Flow Area Attributes \n","print(\"\\nExample 4: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_attributes_df = pd.DataFrame([flow_area_attributes])\n","    display(flow_area_attributes_df)\n","else:\n","    print(\"No 2D Flow Area attributes found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract mesh cell faces\n","print(\"\\nExample: Extracting mesh cell faces\")\n","\n","# Get mesh cell faces\n","mesh_cell_faces = HdfMesh.mesh_cell_faces(geom_hdf_path, ras_object=bald_eagle)\n","\n","# Display the first few rows of the mesh cell faces DataFrame\n","print(\"First few rows of mesh cell faces:\")\n","display(mesh_cell_faces.head())\n","\n","# Plot the mesh cell faces\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Plot all cell faces\n","for _, row in mesh_cell_faces.iterrows():\n","    ax.plot(*row['geometry'].xy, color='blue', linewidth=0.5, alpha=0.5)\n","\n","# Set plot title and labels\n","plt.title('Mesh Cell Faces')\n","plt.xlabel('Easting')\n","plt.ylabel('Northing')\n","\n","# Add a colorbar to show face IDs\n","scatter = ax.scatter(\n","    mesh_cell_faces.geometry.centroid.x,\n","    mesh_cell_faces.geometry.centroid.y,\n","    c=mesh_cell_faces['face_id'],\n","    cmap='viridis',\n","    s=1,\n","    alpha=0.5\n",")\n","plt.colorbar(scatter, label='Face ID')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calculate and display some statistics\n","print(\"\\nMesh Cell Faces Statistics:\")\n","print(f\"Total number of cell faces: {len(mesh_cell_faces)}\")\n","print(f\"Number of unique meshes: {mesh_cell_faces['mesh_name'].nunique()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to find the nearest cell face to a given point\n","def find_nearest_cell_face(point, cell_faces_df):\n","    \"\"\"\n","    Find the nearest cell face to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_faces_df (GeoDataFrame): DataFrame containing cell face linestrings.\n","\n","    Returns:\n","        int: The face_id of the nearest cell face.\n","        float: The distance to the nearest cell face.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell faces\n","    distances = cell_faces_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the face_id and distance of the nearest cell face\n","    nearest_face_id = cell_faces_df.loc[nearest_index, 'face_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_face_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell face to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Get the projection from the geometry file\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Using projection: {projection}\")\n","else:\n","    print(\"No projection information found. Using default CRS.\")\n","    projection = \"EPSG:4326\"  # Default to WGS84 if no projection is found\n","\n","# Create the sample point with the correct CRS\n","sample_point = GeoDataFrame({'geometry': [Point(2042250, 351750)]}, crs=projection)\n","\n","if not mesh_cell_faces.empty and not sample_point.empty:\n","    # Ensure the CRS of the sample point matches the mesh_cell_faces\n","    if sample_point.crs != mesh_cell_faces.crs:\n","        sample_point = sample_point.to_crs(mesh_cell_faces.crs)\n","    \n","    nearest_face_id, distance = find_nearest_cell_face(sample_point.geometry.iloc[0], mesh_cell_faces)\n","    print(f\"Nearest cell face to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Face ID: {nearest_face_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell faces\n","    mesh_cell_faces.plot(ax=ax, color='blue', linewidth=0.5, alpha=0.5, label='Cell Faces')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell face\n","    nearest_face = mesh_cell_faces[mesh_cell_faces['face_id'] == nearest_face_id]\n","    nearest_face.plot(ax=ax, color='green', linewidth=2, alpha=0.7, label='Nearest Face')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell Face to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell face search due to missing data.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Cell Polygons\n","print(\"\\nExample 6: Extracting Cell Polygons\")\n","cell_polygons_df = HdfMesh.mesh_cell_polygons(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_polygons_df.empty:\n","    display(cell_polygons_df.head())\n","else:\n","    print(\"No Cell Polygons found.\")\n","\n","# Plot cell polygons\n","if not cell_polygons_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell polygons\n","    cell_polygons_df.plot(ax=ax, edgecolor='blue', facecolor='none')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Polygons')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell polygon data available for plotting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 5: Extract Cell Info\n","print(\"\\nExample 5: Extracting Cell Info\")\n","cell_info_df = HdfMesh.mesh_cell_points(geom_hdf_path, ras_object=bald_eagle)\n","if not cell_info_df.empty:\n","    display(cell_info_df.head())\n","else:\n","    print(\"No Cell Info found.\")\n","\n","# Plot cell centers\n","import matplotlib.pyplot as plt\n","\n","if not cell_info_df.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot cell centers\n","    cell_info_df.plot(ax=ax, color='red', markersize=5)\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Cell Centers')\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No cell data available for plotting.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Provide function that will accept a geopandas point object and will find the nearest cell center\n","# Function to find the nearest cell center to a given point\n","def find_nearest_cell(point, cell_centers_df):\n","    \"\"\"\n","    Find the nearest cell center to a given point.\n","\n","    Args:\n","        point (shapely.geometry.Point): The input point.\n","        cell_centers_df (GeoDataFrame): DataFrame containing cell center points.\n","\n","    Returns:\n","        int: The cell_id of the nearest cell.\n","        float: The distance to the nearest cell center.\n","    \"\"\"\n","    # Calculate distances from the input point to all cell centers\n","    distances = cell_centers_df.geometry.distance(point)\n","\n","    # Find the index of the minimum distance\n","    nearest_index = distances.idxmin()\n","\n","    # Get the cell_id and distance of the nearest cell\n","    nearest_cell_id = cell_centers_df.loc[nearest_index, 'cell_id']\n","    nearest_distance = distances[nearest_index]\n","\n","    return nearest_cell_id, nearest_distance\n","\n","# Example usage\n","print(\"\\nExample: Finding the nearest cell to a given point\")\n","\n","# Create a sample point (you can replace this with any point of interest)\n","from shapely.geometry import Point\n","from geopandas import GeoDataFrame\n","\n","# Get the projection from the geometry file\n","projection = HdfUtils.projection(hdf_path=geom_hdf_path)\n","if projection:\n","    print(f\"Using projection: {projection}\")\n","else:\n","    print(\"No projection information found. Using default CRS.\")\n","    projection = \"EPSG:4326\"  # Default to WGS84 if no projection is found\n","\n","# Create the sample point with the correct CRS\n","sample_point = GeoDataFrame({'geometry': [Point(2083500, 370800)]}, crs=projection)\n","\n","if not cell_info_df.empty and not sample_point.empty:\n","    # Ensure the CRS of the sample point matches the cell_info_df\n","    if sample_point.crs != cell_info_df.crs:\n","        sample_point = sample_point.to_crs(cell_info_df.crs)\n","    \n","    nearest_cell_id, distance = find_nearest_cell(sample_point.geometry.iloc[0], cell_info_df)\n","    print(f\"Nearest cell to point {sample_point.geometry.iloc[0].coords[0]}:\")\n","    print(f\"Cell ID: {nearest_cell_id}\")\n","    print(f\"Distance: {distance:.2f} units\")\n","\n","    # Visualize the result\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot all cell centers\n","    cell_info_df.plot(ax=ax, color='blue', markersize=5, alpha=0.5, label='Cell Centers')\n","    \n","    # Plot the sample point\n","    sample_point.plot(ax=ax, color='red', markersize=100, alpha=0.7, label='Sample Point')\n","    \n","    # Plot the nearest cell center\n","    nearest_cell = cell_info_df[cell_info_df['cell_id'] == nearest_cell_id]\n","    nearest_cell.plot(ax=ax, color='green', markersize=100, alpha=0.7, label='Nearest Cell')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('Nearest Cell to Sample Point')\n","    \n","    # Add legend and grid\n","    ax.legend()\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"Unable to perform nearest cell search due to missing data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get geometry structures attributes\n","print(\"\\nGetting geometry structures attributes\")\n","geom_structures_attrs = HdfStruc.get_geom_structures_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if geom_structures_attrs:\n","    print(\"Geometry structures attributes:\")\n","    for key, value in geom_structures_attrs.items():\n","        print(f\"{key}: {value}\")\n","else:\n","    print(\"No geometry structures attributes found.\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# TODO: Paths and Functions for each type of structure: \n","\n","# Getting geometry structures attributes\n","# Geometry structures attributes:\n","# Bridge/Culvert Count: 0\n","# Connection Count: 4\n","# Has Bridge Opening (2D): 0\n","# Inline Structure Count: 0\n","# Lateral Structure Count: 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Boundary Condition Lines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 7: Extracting Boundary Condition Lines and Plotting with 2D Flow Area Perimeter Polygons\")\n","bc_lines_df = HdfBndry.bc_lines(geom_hdf_path, ras_object=bald_eagle)\n","if not bc_lines_df.empty:\n","    display(bc_lines_df.head())\n","else:\n","    print(\"No Boundary Condition Lines found.\")\n","\n","# Plot if data exists\n","if not bc_lines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot boundary condition lines\n","    if not bc_lines_df.empty:\n","        bc_lines_df.plot(ax=ax, color='red', linewidth=2, label='Boundary Condition Lines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Boundary Condition Lines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Breaklines and Plot with 2D Flow Area Perimeter Polygons\n","print(\"\\nExample 8: Extracting Breaklines and Plotting with 2D Flow Area Perimeter Polygons\")\n","breaklines_df = HdfBndry.breaklines(geom_hdf_path, ras_object=bald_eagle)\n","if not breaklines_df.empty:\n","    display(breaklines_df.head())\n","else:\n","    print(\"No Breaklines found.\")\n","\n","# Plot breaklines and 2D Flow Area Perimeter Polygons if they exist\n","if not breaklines_df.empty or not mesh_areas.empty:\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot 2D Flow Area Perimeter Polygons\n","    if not mesh_areas.empty:\n","        mesh_areas.plot(ax=ax, edgecolor='black', facecolor='none', alpha=0.7, label='2D Flow Area')\n","        \n","        # Add labels for each polygon\n","        for idx, row in mesh_areas.iterrows():\n","            centroid = row.geometry.centroid\n","            label = row.get('Name', f'Area {idx}')\n","            ax.annotate(label, (centroid.x, centroid.y), ha='center', va='center')\n","    \n","    # Plot breaklines\n","    if not breaklines_df.empty:\n","        breaklines_df.plot(ax=ax, color='blue', linewidth=2, label='Breaklines')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.set_title('2D Flow Area Perimeter Polygons and Breaklines')\n","    \n","    # Add grid and legend\n","    ax.grid(True)\n","    ax.legend()\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No data available for plotting.\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# INSTEAD OF hdf_input, USE plan_hdf_path or geom_hdf_path as appropriate "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get structures\n","structures_gdf = HdfStruc.structures(geom_hdf_path, ras_object=bald_eagle)\n","print(\"Structures:\")\n","if not structures_gdf.empty:\n","    display(structures_gdf.head())\n","else:\n","    print(\"No structures found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference line names\n","ref_line_names = HdfBndry.reference_lines_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Line Names:\")\n","print(ref_line_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference point names\n","ref_point_names = HdfBndry.reference_points_names(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Point Names:\")\n","print(ref_point_names)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference lines\n","ref_lines_gdf = HdfBndry.reference_lines(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines:\")\n","if not ref_lines_gdf.empty:\n","    display(ref_lines_gdf.head())\n","else:\n","    print(\"No reference lines found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get reference points\n","ref_points_gdf = HdfBndry.reference_points(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points:\")\n","if not ref_points_gdf.empty:\n","    display(ref_points_gdf.head())\n","else:\n","    print(\"No reference points found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get cross sections\n","cross_sections_gdf = HdfXsec.cross_sections(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross Sections:\")\n","if not cross_sections_gdf.empty:\n","    display(cross_sections_gdf.head())\n","else:\n","    print(\"No cross sections found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get river reaches\n","river_reaches_gdf = HdfXsec.river_reaches(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nRiver Reaches:\")\n","if not river_reaches_gdf.empty:\n","    display(river_reaches_gdf.head())\n","else:\n","    print(\"No river reaches found in the geometry file.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get cross sections elevations\n","cross_sections_elevations_df = HdfXsec.cross_sections_elevations(geom_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross Sections Elevations:\")\n","if not cross_sections_elevations_df.empty:\n","    display(cross_sections_elevations_df.head())\n","else:\n","    print(\"No cross section elevation data found in the geometry file.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract Refinement Regions\n","print(\"\\nExample: Extracting Refinement Regions\")\n","\n","# Make sure to pass the bald_eagle object as the ras_object parameter\n","refinement_regions_df = HdfBndry.refinement_regions(geom_hdf_path, ras_object=bald_eagle)\n","\n","if not refinement_regions_df.empty:\n","    print(\"Refinement Regions DataFrame:\")\n","    display(refinement_regions_df.head())\n","    \n","    # Plot refinement regions\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    refinement_regions_df.plot(ax=ax, column='CellSize', legend=True, \n","                               legend_kwds={'label': 'Cell Size', 'orientation': 'horizontal'},\n","                               cmap='viridis')\n","    ax.set_title('2D Mesh Area Refinement Regions')\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No refinement regions found in the geometry file.\")\n","\n","# Example: Analyze Refinement Regions\n","if not refinement_regions_df.empty:\n","    print(\"\\nRefinement Regions Analysis:\")\n","    print(f\"Total number of refinement regions: {len(refinement_regions_df)}\")\n","    print(\"\\nCell Size Statistics:\")\n","    print(refinement_regions_df['CellSize'].describe())\n","    \n","    # Group by Shape Type\n","    shape_type_counts = refinement_regions_df['ShapeType'].value_counts()\n","    print(\"\\nRefinement Region Shape Types:\")\n","    print(shape_type_counts)\n","    \n","    # Plot Shape Type distribution\n","    plt.figure(figsize=(10, 6))\n","    shape_type_counts.plot(kind='bar')\n","    plt.title('Distribution of Refinement Region Shape Types')\n","    plt.xlabel('Shape Type')\n","    plt.ylabel('Count')\n","    plt.xticks(rotation=45)\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract Compute Messages as String\n","print(\"Extracting Compute Messages\")\n","\n","import h5py\n","import numpy as np\n","\n","def extract_string_from_hdf(results_hdf_filename: str, hdf_path: str) -> str:\n","    \"\"\"\n","    Extract string from HDF object at a given path\n","\n","    Parameters\n","    ----------\n","    results_hdf_filename : str\n","        Name of the HDF file\n","    hdf_path : str\n","        Path of the object in the HDF file\n","\n","    Returns\n","    -------\n","    str\n","        Extracted string from the specified HDF object\n","    \"\"\"\n","    with h5py.File(results_hdf_filename, 'r') as hdf_file:\n","        try:\n","            hdf_object = hdf_file[hdf_path]\n","            if isinstance(hdf_object, h5py.Group):\n","                return f\"Group: {hdf_path}\\nContents: {list(hdf_object.keys())}\"\n","            elif isinstance(hdf_object, h5py.Dataset):\n","                data = hdf_object[()]\n","                if isinstance(data, bytes):\n","                    return data.decode('utf-8')\n","                elif isinstance(data, np.ndarray) and data.dtype.kind == 'S':\n","                    return [v.decode('utf-8') for v in data]\n","                else:\n","                    return str(data)\n","            else:\n","                return f\"Unsupported object type: {type(hdf_object)}\"\n","        except KeyError:\n","            return f\"Path not found: {hdf_path}\"\n","\n","try:\n","    results_summary_string = extract_string_from_hdf(plan_hdf_path, '/Results/Summary/Compute Messages (text)')\n","    print(\"Compute Messages:\")\n","    \n","    # Parse and print the compute messages in a more visually friendly way\n","    messages = results_summary_string[0].split('\\r\\n')\n","    \n","    for message in messages:\n","        if message.strip():  # Skip empty lines\n","            if ':' in message:\n","                key, value = message.split(':', 1)\n","                print(f\"{key.strip():40} : {value.strip()}\")\n","            else:\n","                print(f\"\\n{message.strip()}\")\n","    \n","    # Print computation summary in a table format\n","    print(\"\\nComputation Summary:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Computation Task':<30} {'Time':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Task' in line:\n","            task, time = line.split('\\t')\n","            print(f\"{task:<30} {time:<20}\")\n","    \n","    print(\"\\nComputation Speed:\")\n","    print(\"-\" * 50)\n","    print(f\"{'Task':<30} {'Simulation/Runtime':<20}\")\n","    print(\"-\" * 50)\n","    for line in messages:\n","        if 'Computation Speed' in line:\n","            task, speed = line.split('\\t')\n","            print(f\"{task:<30} {speed:<20}\")\n","\n","except Exception as e:\n","    print(f\"Error extracting compute messages: {str(e)}\")\n","    print(\"\\nNote: If 'Results/Summary Output' is not in the file structure, it might indicate that the simulation didn't complete successfully or the results weren't saved properly.\")\n","\n"," \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Advanced Compute Messages Example - TODO: Move this function into a class of the library \n","import pandas as pd\n","import re\n","import matplotlib.pyplot as plt\n","import geopandas as gpd\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","\n","def parse_2d_compute_messages(compute_messages):\n","    \"\"\"\n","    Parse 2D compute messages to extract data lines, clean the data, \n","    and retrieve top 20 cells with the highest error.\n","\n","    Parameters:\n","        compute_messages (list or str): The raw compute messages.\n","\n","    Returns:\n","        tuple: A tuple containing the parsed compute messages string and the main DataFrame.\n","    \"\"\"\n","    try:\n","        # Handle both list and string inputs\n","        if isinstance(compute_messages, list):\n","            compute_messages = '\\n'.join(compute_messages)\n","        elif not isinstance(compute_messages, str):\n","            logging.error(f\"Unexpected type for compute_messages: {type(compute_messages)}\")\n","            return \"\", pd.DataFrame()\n","\n","        # Split the message into lines\n","        lines = compute_messages.split('\\n')\n","        logging.info(\"Successfully split compute messages into lines.\")\n","        \n","        # Initialize lists to store parsed data\n","        data_lines = []\n","        header_lines = []\n","        footer_lines = []\n","        \n","        # Regular expression to match timestamp lines\n","        timestamp_pattern = re.compile(r'^\\d{2}[A-Z]{3}\\d{4}\\s+\\d{2}:\\d{2}:\\d{2}')\n","        logging.debug(\"Compiled timestamp regular expression.\")\n","        \n","        data_started = False\n","        for line in lines:\n","            stripped_line = line.strip()\n","            if timestamp_pattern.match(stripped_line):\n","                data_started = True\n","                # Split the line and add to data_lines\n","                parts = stripped_line.split()\n","                if len(parts) >= 8:  # Ensure we have all expected columns\n","                    # Combine Date and Time into 'Date and Time'\n","                    date_time = f\"{parts[0]} {parts[1]}\"\n","                    location = parts[2]\n","                    cell_type = f\"{parts[3]} {parts[4]}\"\n","                    cell_number = parts[5]\n","                    wsel = parts[6]\n","                    error = parts[7]\n","                    iterations = parts[8] if len(parts) > 8 else None\n","                    data_lines.append([date_time, location, cell_type, cell_number, wsel, error, iterations])\n","                    logging.debug(f\"Parsed data line: {data_lines[-1]}\")\n","                else:\n","                    logging.warning(f\"Line skipped due to insufficient parts: {stripped_line}\")\n","            elif not data_started:\n","                header_lines.append(stripped_line)\n","            elif data_started and not stripped_line:\n","                data_started = False\n","            elif not data_started:\n","                footer_lines.append(stripped_line)\n","        \n","        # Create DataFrame from data lines\n","        df = pd.DataFrame(\n","            data_lines, \n","            columns=['Date and Time', 'Location', 'Cell Type', 'Cell Number', 'WSEL', 'ERROR', 'ITERATIONS']\n","        )\n","        logging.info(\"Created DataFrame from parsed data lines.\")\n","        \n","        # Clean and convert columns to appropriate types\n","        df['Cell Number'] = (\n","            pd.to_numeric(df['Cell Number'].replace('#', pd.NA), errors='coerce')\n","            .fillna(-1)\n","            .astype('Int64')\n","        )\n","        df['WSEL'] = pd.to_numeric(df['WSEL'], errors='coerce')\n","        df['ERROR'] = pd.to_numeric(df['ERROR'], errors='coerce')\n","        df['ITERATIONS'] = pd.to_numeric(df['ITERATIONS'], errors='coerce').astype('Int64')\n","        logging.info(\"Converted DataFrame columns to appropriate types.\")\n","        \n","        # Get top 20 cells with highest error\n","        top_20_cells = (\n","            df.sort_values('ERROR', ascending=False)\n","            .drop_duplicates('Cell Number')\n","            .head(20)\n","        )\n","        \n","        # Construct the reordered message\n","        reordered_message = '\\n'.join(header_lines + \n","                                      ['\\nTop 20 Cells with Highest Error:'] + \n","                                      [' '.join(map(str, row)) for row in top_20_cells.values] + \n","                                      ['\\n'] + footer_lines)\n","        \n","        logging.info(\"Reordered compute messages.\")\n","        \n","        return reordered_message, df\n","    except Exception as e:\n","        logging.error(f\"Error parsing compute messages: {e}\")\n","        return \"\", pd.DataFrame()\n","\n","# Use the function to parse compute messages\n","parsed_messages, df = parse_2d_compute_messages(results_summary_string)\n","\n","print(parsed_messages)\n","print(df)\n","\n","# Get top 20 cells with highest error\n","if not df.empty and 'ERROR' in df.columns:\n","    top_20_cells = (\n","        df.sort_values('ERROR', ascending=False)\n","        .drop_duplicates('Cell Number')\n","        .head(20)\n","    )\n","else:\n","    logging.warning(\"Unable to get top 20 cells with highest error. DataFrame is empty or 'ERROR' column is missing.\")\n","    top_20_cells = pd.DataFrame()\n","\n","# Example: Get 2D Flow Area Perimeter Polygons (mesh_areas)\n","print(\"\\nExample: Extracting 2D Flow Area Perimeter Polygons\")\n","mesh_areas = HdfMesh.mesh_areas(geom_hdf_path, ras_object=bald_eagle)\n","\n","print(\"\\n2D Flow Area Groups and Perimeters:\")\n","if not mesh_areas.empty:\n","    print(\"Available columns:\", mesh_areas.columns.tolist())\n","    \n","    # Display the first few rows of the mesh_areas DataFrame\n","    print(\"\\nFirst few rows of mesh_areas DataFrame:\")\n","    display(mesh_areas.head())\n","else:\n","    print(\"No 2D Flow Area groups found in the HDF file.\")\n","\n","# Use the previously extracted cell_polygons_df\n","print(\"\\nTop 20 Cell Polygons:\")\n","if 'cell_polygons_df' in locals() and not cell_polygons_df.empty and not top_20_cells.empty:\n","    # Get the cell numbers from top_20_cells\n","    top_20_cell_numbers = top_20_cells['Cell Number'].tolist()\n","    \n","    # Filter cell_polygons_df to only include top 20 cells\n","    top_20_cell_polygons = cell_polygons_df[cell_polygons_df['cell_id'].isin(top_20_cell_numbers)]\n","    \n","    display(top_20_cell_polygons)\n","\n","    # Plot top 20 cell polygons and mesh areas\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot mesh areas\n","    mesh_areas.plot(ax=ax, edgecolor='red', facecolor='none', alpha=0.5, label='Mesh Areas')\n","    \n","    # Plot top 20 cell polygons\n","    top_20_cell_polygons.plot(ax=ax, edgecolor='blue', facecolor='none', alpha=0.7, label='Top 20 Error Cells')\n","    \n","    # Set labels and title\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    ax.set_title('2D Flow Area Perimeters and Top 20 Cell Polygons')\n","    \n","    # Add legend\n","    ax.legend()\n","    \n","    # Add grid\n","    ax.grid(True)\n","    \n","    # Adjust layout and display\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"No Cell Polygons found or no top 20 cells with highest error available.\")\n","    print(\"Unable to plot cell polygons.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Exploratory Example for Debugging or New Features: List all paths, groups, and attributes under \"/Results/Unsteady/Summary/Volume Accounting\"\n","print(\"\\nListing paths, groups, and attributes under '/Results/Unsteady/Summary/Volume Accounting'\")\n","\n","from ras_commander import HdfUtils\n","\n","def list_hdf_structure(hdf_path: str, group_path: str) -> None:\n","    with h5py.File(hdf_path, 'r') as hdf:\n","        if group_path not in hdf:\n","            print(f\"Group '{group_path}' not found in the HDF file.\")\n","            return\n","\n","        def print_group_structure(name: str, obj: h5py.Group) -> None:\n","            indent = '  ' * name.count('/')\n","            if isinstance(obj, h5py.Group):\n","                print(f\"{indent}{name} (Group)\")\n","                for attr_name, attr_value in obj.attrs.items():\n","                    print(f\"{indent}  Attribute: {attr_name} = {attr_value}\")\n","            elif isinstance(obj, h5py.Dataset):\n","                print(f\"{indent}{name} (Dataset)\")\n","                for attr_name, attr_value in obj.attrs.items():\n","                    print(f\"{indent}  Attribute: {attr_name} = {attr_value}\")\n","\n","        hdf[group_path].visititems(print_group_structure)\n","\n","try:\n","    list_hdf_structure(plan_hdf_path, \"/Results/Unsteady/Summary/Volume Accounting\")\n","except Exception as e:\n","    print(f\"An error occurred while listing HDF structure: {str(e)}\")\n","\n","# Additional error handling and logging\n","logger = logging.getLogger(__name__)\n","logger.info(\"Finished listing HDF structure for Volume Accounting\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example 12: Extract Plan Parameters and Volume Accounting\n","print(\"\\nExample 12: Extracting Plan Parameters and Volume Accounting Data\")\n","\n","# Extract plan parameters\n","plan_parameters_df = HdfPlan.get_plan_param_attrs(plan_hdf_path)\n","\n","# Extract volume accounting data\n","volume_accounting_df = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path)\n","\n","print(\"\\nPlan Parameters DataFrame:\")\n","display(plan_parameters_df)\n","\n","print(\"\\nVolume Accounting DataFrame:\")\n","display(volume_accounting_df)"]},{"cell_type":"markdown","metadata":{},"source":["# RasPlanHdf Class Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation start time\n","start_time = HdfPlan.get_simulation_start_time(plan_hdf_path)\n","print(f\"Simulation start time: {start_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get simulation end time\n","end_time = HdfPlan.get_simulation_end_time(plan_hdf_path)\n","print(f\"Simulation end time: {end_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Extract 2D Flow Area Attributes \n","print(\"\\nExample 4: Extracting 2D Flow Area Attributes\")\n","flow_area_attributes = HdfMesh.get_geom_2d_flow_area_attrs(geom_hdf_path, ras_object=bald_eagle)\n","if flow_area_attributes:\n","    # Convert the dictionary to a DataFrame for better display\n","    flow_area_attributes_df = pd.DataFrame([flow_area_attributes])\n","    display(flow_area_attributes_df)\n","else:\n","    print(\"No 2D Flow Area attributes found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max iterations\n","max_iter_df = HdfResultsMesh.mesh_max_iter(plan_hdf_path)\n","print(\"\\nMesh Max Iterations:\")\n","print(max_iter_df.attrs)\n","display(max_iter_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using mesh_max_iter, get the cell coordinates and plot the max iterations as a map\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max iterations\n","max_iter_df = HdfResultsMesh.mesh_max_iter(plan_hdf_path)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max iterations with cell coordinates\n","merged_df = pd.merge(max_iter_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['cell_last_iteration'], cmap='viridis', s=1)\n","\n","    # Customize the plot\n","    ax.set_title('Max Iterations per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Iterations')\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max water surface\n","max_ws_df = HdfResultsMesh.mesh_max_ws(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Max Water Surface:\")\n","print(max_ws_df.attrs)\n","display(max_ws_df.head())"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# Show some statistics for the max_ws_df dataframe\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using mesh_max_ws, get the cell coordinates and plot the max water surface as a map\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max water surface\n","max_ws_df = HdfResultsMesh.mesh_max_ws(plan_hdf_path, ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max water surface with cell coordinates\n","merged_df = pd.merge(max_ws_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['maximum_water_surface'], cmap='viridis', s=10)\n","\n","    # Customize the plot\n","    ax.set_title('Max Water Surface per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Water Surface (ft)')\n","\n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Increase font size for better readability\n","    plt.rcParams.update({'font.size': 12})\n","\n","    # Adjust layout to prevent cutting off labels\n","    plt.tight_layout()\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the time of the max water surface elevation (WSEL)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","from datetime import datetime\n","\n","# Convert the 'maximum_water_surface_time' to datetime objects first\n","merged_df['max_wsel_time'] = pd.to_datetime(merged_df['maximum_water_surface_time'])\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Convert datetime to hours since the start for colormap\n","min_time = merged_df['max_wsel_time'].min()\n","color_values = (merged_df['max_wsel_time'] - min_time).dt.total_seconds() / 3600  # Convert to hours\n","\n","scatter = ax.scatter(merged_df['x'], merged_df['y'], \n","                     c=color_values, \n","                     cmap='viridis', \n","                     s=10)\n","\n","# Customize the plot\n","ax.set_title('Time of Maximum Water Surface Elevation per Cell')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","\n","# Set up the colorbar\n","cbar = plt.colorbar(scatter)\n","cbar.set_label('Hours since simulation start')\n","\n","# Format the colorbar ticks to show hours\n","cbar.set_ticks(range(0, int(color_values.max()) + 1, 6))  # Set ticks every 6 hours\n","cbar.set_ticklabels([f'{h}h' for h in range(0, int(color_values.max()) + 1, 6)])\n","\n","# Add grid lines\n","ax.grid(True, linestyle='--', alpha=0.7)\n","\n","# Increase font size for better readability\n","plt.rcParams.update({'font.size': 12})\n","\n","# Adjust layout to prevent cutting off labels\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()\n","\n","\n","# Find the overall maximum WSEL and its time\n","max_wsel_row = merged_df.loc[merged_df['maximum_water_surface'].idxmax()]\n","hours_since_start = (max_wsel_row['max_wsel_time'] - min_time).total_seconds() / 3600\n","print(f\"\\nOverall Maximum WSEL: {max_wsel_row['maximum_water_surface']:.2f} ft\")\n","print(f\"Time of Overall Maximum WSEL: {max_wsel_row['max_wsel_time']}\")\n","print(f\"Hours since simulation start: {hours_since_start:.2f} hours\")\n","print(f\"Location of Overall Maximum WSEL: X={max_wsel_row['x']}, Y={max_wsel_row['y']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh min water surface\n","min_ws_df = HdfResultsMesh.mesh_min_ws(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Min Water Surface:\")\n","display(min_ws_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max face velocity\n","max_face_v_df = HdfResultsMesh.mesh_max_face_v(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Max Face Velocity:\")\n","display(max_face_v_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max face velocity\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max face velocity\n","max_face_v_df = HdfResultsMesh.mesh_max_face_v(plan_hdf_path, ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max face velocity with cell coordinates\n","merged_df = pd.merge(max_face_v_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['maximum_face_velocity'].abs(), cmap='viridis', s=10)\n","\n","    # Customize the plot\n","    ax.set_title('Max Face Velocity per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Face Velocity (ft/s)')\n","\n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Increase font size for better readability\n","    plt.rcParams.update({'font.size': 12})\n","\n","    # Adjust layout to prevent cutting off labels\n","    plt.tight_layout()\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh min face velocity\n","min_face_v_df = HdfResultsMesh.mesh_min_face_v(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Min Face Velocity:\")\n","display(min_face_v_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh max water surface error\n","try:\n","    max_ws_err_df = HdfResultsMesh.mesh_max_ws_err(plan_hdf_path, ras_object=bald_eagle)\n","    print(\"\\nMesh Max Water Surface Error:\")\n","    display(max_ws_err_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh max water surface error: {str(e)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max water surface error\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max water surface error\n","max_ws_err_df = HdfResultsMesh.mesh_max_ws_err(plan_hdf_path, ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max water surface error with cell coordinates\n","merged_df = pd.merge(max_ws_err_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['cell_maximum_water_surface_error'], cmap='viridis', s=10)\n","\n","    # Customize the plot\n","    ax.set_title('Max Water Surface Error per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Water Surface Error (ft)')\n","\n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Increase font size for better readability\n","    plt.rcParams.update({'font.size': 12})\n","\n","    # Adjust layout to prevent cutting off labels\n","    plt.tight_layout()\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["### Need to add this to the ras-commander library"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant)\n","try:\n","    max_courant_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Courant\", ras_object=bald_eagle)\n","    print(\"\\nMesh Summary Output (Maximum Courant):\")\n","    print(max_courant_df.attrs)\n","    display(max_courant_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh summary output: {str(e)}\")\n","    # Additional error handling or logging can be added here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max Courant number\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max Courant number\n","max_courant_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Courant\", ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max Courant number with cell coordinates\n","merged_df = pd.merge(max_courant_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['maximum_face_courant'], cmap='viridis', s=10)\n","\n","    # Customize the plot\n","    ax.set_title('Max Courant Number per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Courant Number')\n","\n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Increase font size for better readability\n","    plt.rcParams.update({'font.size': 12})\n","\n","    # Adjust layout to prevent cutting off labels\n","    plt.tight_layout()\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for other Datasets (here we retrieve Maximum Face Courant)\n","try:\n","    max_face_shear_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Shear Stress\", ras_object=bald_eagle)\n","    print(\"\\nMesh Summary Output (Maximum Face Shear Stress:\")\n","    print(max_face_shear_df.attrs)\n","    display(max_face_shear_df.head())\n","except Exception as e:\n","    print(f\"Error: {str(e)}\")\n","    logger.error(f\"Failed to get mesh summary output: {str(e)}\")\n","    # Additional error handling or logging can be added here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot max face shear stress\n","import matplotlib.pyplot as plt\n","from ras_commander.HdfMesh import HdfMesh\n","from ras_commander.HdfResultsMesh import HdfResultsMesh\n","from shapely.geometry import Point\n","\n","# Get mesh max face shear stress\n","max_shear_df = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Maximum Face Shear Stress\", ras_object=bald_eagle)\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Merge max face shear stress with cell coordinates\n","merged_df = pd.merge(max_shear_df, cell_coords, on=['mesh_name', 'cell_id'])\n","\n","# Extract x and y coordinates from the geometry column\n","merged_df['x'] = merged_df['geometry'].apply(lambda geom: geom.x)\n","merged_df['y'] = merged_df['geometry'].apply(lambda geom: geom.y)\n","\n","# Check if 'x' and 'y' columns exist in merged_df\n","if 'x' not in merged_df.columns or 'y' not in merged_df.columns:\n","    print(\"Error: 'x' or 'y' columns not found in the merged dataframe.\")\n","    print(\"Available columns:\", merged_df.columns.tolist())\n","else:\n","    # Create the plot\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    scatter = ax.scatter(merged_df['x'], merged_df['y'], c=merged_df['maximum_face_shear_stress'], cmap='viridis', s=10)\n","\n","    # Customize the plot\n","    ax.set_title('Max Face Shear Stress per Cell')\n","    ax.set_xlabel('X Coordinate')\n","    ax.set_ylabel('Y Coordinate')\n","    plt.colorbar(scatter, label='Max Face Shear Stress (PSF)')\n","\n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","\n","    # Increase font size for better readability\n","    plt.rcParams.update({'font.size': 12})\n","\n","    # Adjust layout to prevent cutting off labels\n","    plt.tight_layout()\n","\n","    # Show the plot\n","    plt.show()\n","\n","# Print the first few rows of the merged dataframe for verification\n","print(\"\\nFirst few rows of the merged dataframe:\")\n","display(merged_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh summary output for Minimum Water Surface\n","summary_df_min_ws = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Minimum Water Surface\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Minimum Water Surface):\")\n","display(summary_df_min_ws.head())\n","\n","# Example: Get mesh summary output for Minimum Face Velocity\n","summary_df_min_fv = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Minimum Face Velocity\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Minimum Face Velocity):\")\n","display(summary_df_min_fv.head())\n","\n","# Example: Get mesh summary output for Cell Cumulative Iteration\n","summary_df_cum_iter = HdfResultsMesh.mesh_summary_output(plan_hdf_path, var=\"Cell Cumulative Iteration\", ras_object=bald_eagle)\n","print(\"\\nMesh Summary Output (Cell Cumulative Iteration):\")\n","display(summary_df_cum_iter.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get mesh faces summary output\n","faces_summary_df = HdfMesh.mesh_cell_faces(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Faces Summary Output:\")\n","display(faces_summary_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh cell polygons using the updated HdfMesh class\n","cell_polygons_gdf = HdfMesh.mesh_cell_polygons(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Cell Polygons:\")\n","display(cell_polygons_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh cell faces using the updated HdfMesh class\n","cell_faces_gdf = HdfMesh.mesh_cell_faces(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMesh Cell Faces:\")\n","display(cell_faces_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Mesh Cell Faces\n","\n","import matplotlib.pyplot as plt\n","import logging\n","\n","def plot_mesh_cell_faces(gdf, title=\"Mesh Cell Faces\"):\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    \n","    # Plot the linestrings\n","    gdf.plot(ax=ax, color='blue', linewidth=0.5)\n","    \n","    # Customize the plot\n","    ax.set_title(title)\n","    ax.set_xlabel('Easting')\n","    ax.set_ylabel('Northing')\n","    ax.axis('equal')\n","    \n","    # Add grid lines\n","    ax.grid(True, linestyle='--', alpha=0.7)\n","    \n","    plt.tight_layout()\n","    plt.show()\n","\n","# Plot the mesh cell faces\n","plot_mesh_cell_faces(cell_faces_gdf)\n","\n","# Log the plotting action\n","logging.info(f\"Plotted {len(cell_faces_gdf)} mesh cell faces.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get simulation start time\n","simulation_start_time = HdfPlan.get_simulation_start_time(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nSimulation Start Time:\")\n","print(simulation_start_time)\n","\n","# Get simulation end time\n","simulation_end_time = HdfPlan.get_simulation_end_time(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nSimulation End Time:\")\n","print(simulation_end_time)\n","\n","# Calculate simulation duration\n","simulation_duration = simulation_end_time - simulation_start_time\n","print(\"\\nSimulation Duration:\")\n","print(simulation_duration)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh timeseries output\n","\n","# Get mesh areas from previous code cell\n","mesh_areas = HdfMesh.mesh_area_names(geom_hdf_path, ras_object=bald_eagle)\n","\n","if mesh_areas:\n","    mesh_name = mesh_areas[0]  # Use the first 2D flow area name\n","    timeseries_da = HdfResultsMesh.mesh_timeseries_output(plan_hdf_path, mesh_name, \"Water Surface\", ras_object=bald_eagle)\n","    print(f\"\\nMesh Timeseries Output (Water Surface) for {mesh_name}:\")\n","    print(timeseries_da)\n","else:\n","    print(\"No mesh areas found in the geometry file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create an animation of the water surface elevation over time\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import numpy as np\n","from ras_commander.HdfMesh import HdfMesh\n","\n","# Extract data from the DataArray\n","time = timeseries_da.time.values\n","water_surface = timeseries_da.values\n","\n","# Get cell coordinates\n","cell_coords = HdfMesh.mesh_cell_points(plan_hdf_path)\n","\n","# Extract x and y coordinates from the geometry column\n","x = np.array([geom.x for geom in cell_coords['geometry']])\n","y = np.array([geom.y for geom in cell_coords['geometry']])\n","\n","# Ensure water_surface data matches the number of cells\n","if water_surface.shape[1] != len(x):\n","    print(f\"Warning: Number of cells in water_surface ({water_surface.shape[1]}) doesn't match number of coordinates ({len(x)})\")\n","    print(\"Attempting to reshape water_surface data...\")\n","    water_surface = water_surface[:, :len(x)]\n","\n","# Create the figure and axis\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Initialize the scatter plot\n","scatter = ax.scatter(x, y, c=water_surface[0], cmap='viridis', s=10)\n","plt.colorbar(scatter, label='Water Surface Elevation (ft)')\n","\n","# Set title and labels\n","ax.set_title(f'Water Surface Elevation Over Time for {mesh_name}')\n","ax.set_xlabel('X Coordinate')\n","ax.set_ylabel('Y Coordinate')\n","\n","# Animation update function\n","def update(frame):\n","    scatter.set_array(water_surface[frame])\n","    ax.set_title(f'Water Surface Elevation at {time[frame]} for {mesh_name}')\n","    return scatter,\n","\n","# Create the animation\n","anim = animation.FuncAnimation(fig, update, frames=len(time), interval=200, blit=True)\n","\n","# Save the animation (optional)\n","# anim.save('water_surface_animation.gif', writer='pillow', fps=5)\n","\n","# Display the animation\n","plt.tight_layout()\n","plt.show()\n","\n","# Log the animation creation\n","logging.info(f\"Created water surface elevation animation for {mesh_name}\")\n","\n","# Print debug information\n","print(f\"Shape of water_surface array: {water_surface.shape}\")\n","print(f\"Number of x coordinates: {len(x)}\")\n","print(f\"Number of y coordinates: {len(y)}\")\n","print(f\"Number of time steps: {len(time)}\")"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# Time Series Output Variables for Cells\n","# \n","# Variable Name: Description\n","# Water Surface: Water surface elevation\n","# Depth: Water depth\n","# Velocity: Magnitude of velocity\n","# Velocity X: X-component of velocity\n","# Velocity Y: Y-component of velocity\n","# Froude Number: Froude number\n","# Courant Number: Courant number\n","# Shear Stress: Shear stress on the bed\n","# Bed Elevation: Elevation of the bed\n","# Precipitation Rate: Rate of precipitation\n","# Infiltration Rate: Rate of infiltration\n","# Evaporation Rate: Rate of evaporation\n","# Percolation Rate: Rate of percolation\n","# Groundwater Elevation: Elevation of groundwater\n","# Groundwater Depth: Depth to groundwater\n","# Groundwater Flow: Groundwater flow rate\n","# Groundwater Velocity: Magnitude of groundwater velocity\n","# Groundwater Velocity X: X-component of groundwater velocity\n","# Groundwater Velocity Y: Y-component of groundwater velocity\n","# \n","# These variables are available for time series output at the cell level in 2D flow areas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh cells timeseries output\n","cells_timeseries_ds = HdfResultsMesh.mesh_cells_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Cells Timeseries Output:\")\n","print(cells_timeseries_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Cell Time Series Data (Random Cell ID)\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","\n","# Extract Water Surface data\n","water_surface = cells_timeseries_ds['BaldEagleCr']['Water Surface']\n","\n","# Get the time values\n","time_values = water_surface.coords['time'].values\n","\n","# Pick a random cell_id\n","random_cell_id = random.choice(water_surface.coords['cell_id'].values)\n","\n","# Extract the water surface elevation time series for the random cell\n","wsel_timeseries = water_surface.sel(cell_id=random_cell_id)\n","\n","# Find the peak value and its index\n","peak_value = wsel_timeseries.max().item()\n","peak_index = wsel_timeseries.argmax().item()\n","\n","# Create the plot\n","plt.figure(figsize=(12, 6))\n","plt.plot(time_values, wsel_timeseries, label=f'Cell ID: {random_cell_id}')\n","plt.scatter(time_values[peak_index], peak_value, color='red', s=100, zorder=5)\n","plt.annotate(f'Peak: {peak_value:.2f} ft', \n","             (time_values[peak_index], peak_value),\n","             xytext=(10, 10), textcoords='offset points',\n","             ha='left', va='bottom',\n","             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n","             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n","\n","plt.title(f'Water Surface Elevation Time Series for Random Cell (ID: {random_cell_id})')\n","plt.xlabel('Time')\n","plt.ylabel('Water Surface Elevation (ft)')\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","\n","# Log the plotting action\n","logging.info(f\"Plotted water surface elevation time series for random cell ID: {random_cell_id}\")\n","\n","# Display the plot\n","plt.show()\n","\n","# Print some statistics\n","print(f\"Statistics for Cell ID {random_cell_id}:\")\n","print(f\"Minimum WSEL: {wsel_timeseries.min().item():.2f} ft\")\n","print(f\"Maximum WSEL: {peak_value:.2f} ft\")\n","print(f\"Mean WSEL: {wsel_timeseries.mean().item():.2f} ft\")\n","print(f\"Time of peak: {time_values[peak_index]}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get mesh faces timeseries output\n","faces_timeseries_ds = HdfResultsMesh.mesh_faces_timeseries_output(plan_hdf_path, mesh_name, ras_object=bald_eagle)\n","print(\"\\nMesh Faces Timeseries Output:\")\n","print(faces_timeseries_ds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Random Cell Results and Label Peak\n","\n","# Step 1: Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Step 2: Select a random valid cell number\n","# Use .sizes instead of .dims to avoid FutureWarning\n","random_cell = np.random.randint(0, faces_timeseries_ds.sizes['cell'])\n","\n","# Step 3: Extract time series data for the selected cell\n","variable = 'face_velocity'  # We could also use 'face_flow'\n","cell_data = faces_timeseries_ds[variable].sel(cell=random_cell)\n","\n","# Step 4: Find peak value and its corresponding time\n","peak_value = cell_data.max().item()\n","peak_time = cell_data.idxmax().values\n","\n","# Step 5: Create the plot\n","plt.figure(figsize=(12, 6))\n","plt.plot(faces_timeseries_ds.time, cell_data)\n","plt.title(f'{variable.capitalize()} Time Series for Cell {random_cell}')\n","plt.xlabel('Time')\n","plt.ylabel(f'{variable.capitalize()} ({faces_timeseries_ds.attrs[\"units\"]})')\n","plt.grid(True)\n","\n","# Step 6: Annotate the peak point\n","plt.annotate(f'Peak: ({peak_time}, {peak_value:.2f})', \n","             (peak_time, peak_value),\n","             xytext=(10, 10), textcoords='offset points',\n","             arrowprops=dict(arrowstyle=\"->\"))\n","\n","# Step 7: Check for negative values and label the minimum if present\n","min_value = cell_data.min().item()\n","if min_value < 0:\n","    min_time = cell_data.idxmin().values\n","    plt.annotate(f'Min: ({min_time}, {min_value:.2f})', \n","                 (min_time, min_value),\n","                 xytext=(10, -10), textcoords='offset points',\n","                 arrowprops=dict(arrowstyle=\"->\"))\n","\n","# Step 8: Display the plot\n","plt.tight_layout()\n","plt.show()\n","\n","# Step 9: Print summary information\n","print(f\"Random Cell: {random_cell}\")\n","print(f\"Peak Value: {peak_value:.2f} {faces_timeseries_ds.attrs['units']} at {peak_time}\")\n","if min_value < 0:\n","    print(f\"Minimum Value: {min_value:.2f} {faces_timeseries_ds.attrs['units']} at {min_time}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference lines\n","ref_lines_gdf = HdfBndry.reference_lines(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines:\")\n","display(ref_lines_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference points\n","ref_points_gdf = HdfBndry.reference_points(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points:\")\n","display(ref_points_gdf.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference timeseries output\n","ref_timeseries_ds = HdfResultsPlan.reference_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Timeseries Output:\")\n","print(ref_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference lines timeseries output\n","ref_lines_timeseries_ds = HdfResultsPlan.reference_lines_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Lines Timeseries Output:\")\n","print(ref_lines_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference points timeseries output\n","ref_points_timeseries_ds = HdfResultsPlan.reference_points_timeseries_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Points Timeseries Output:\")\n","print(ref_points_timeseries_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get reference summary output\n","ref_summary_df = HdfResultsPlan.reference_summary_output(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nReference Summary Output:\")\n","display(ref_summary_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get meteorology precipitation attributes\n","meteo_precip_attrs = HdfPlan.get_meteorology_precip_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nMeteorology Precipitation Attributes:\")\n","for key, value in meteo_precip_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady attributes\n","results_unsteady_attrs = HdfResultsPlan.get_results_unsteady_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Attributes:\")\n","for key, value in results_unsteady_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get results unsteady summary attributes\n","results_unsteady_summary_attrs = HdfResultsPlan.get_results_unsteady_summary_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nResults Unsteady Summary Attributes:\")\n","for key, value in results_unsteady_summary_attrs.items():\n","    print(f\"{key}: {value}\")\n","\n","# Get results volume accounting attributes\n","volume_accounting_attrs = HdfResultsPlan.get_results_volume_accounting_attrs(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nVolume Accounting Attributes:\")\n","for key, value in volume_accounting_attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get steady profile cross-section output\n","steady_xs_df = HdfResultsXsec.steady_profile_xs_output(plan_hdf_path, \"Water Surface\", ras_object=bald_eagle)\n","print(\"\\nSteady Profile Cross-Section Output (Water Surface):\")\n","display(steady_xs_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections water surface elevation\n","xs_wsel_df = HdfResultsXsec.cross_sections_wsel(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Water Surface Elevation:\")\n","display(xs_wsel_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections flow\n","xs_flow_df = HdfResultsXsec.cross_sections_flow(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Flow:\")\n","display(xs_flow_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections energy grade\n","xs_energy_grade_df = HdfResultsXsec.cross_sections_energy_grade(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Energy Grade:\")\n","display(xs_energy_grade_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections additional encroachment station left\n","xs_enc_left_df = HdfResultsXsec.cross_sections_additional_enc_station_left(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Additional Encroachment Station Left:\")\n","display(xs_enc_left_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections additional encroachment station right\n","xs_enc_right_df = HdfResultsXsec.cross_sections_additional_enc_station_right(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Additional Encroachment Station Right:\")\n","display(xs_enc_right_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections additional area total\n","xs_area_total_df = HdfResultsXsec.cross_sections_additional_area_total(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Additional Area Total:\")\n","display(xs_area_total_df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get cross-sections additional velocity total\n","xs_velocity_total_df = HdfResultsXsec.cross_sections_additional_velocity_total(plan_hdf_path, ras_object=bald_eagle)\n","print(\"\\nCross-Sections Additional Velocity Total:\")\n","display(xs_velocity_total_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# HdfUtils Examples\n","\n","# Example: Get attributes for a specific path\n","attrs = HdfUtils.get_attrs(plan_hdf_path, attr_path=\"/Results/Unsteady\")\n","print(\"\\nAttributes for /Results/Unsteady:\")\n","for key, value in attrs.items():\n","    print(f\"{key}: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Get root attributes\n","root_attrs = HdfUtils.get_root_attrs(plan_hdf_path)\n","print(\"\\nRoot Attributes:\")\n","for key, value in root_attrs.items():\n","    print(f\"{key}: {value}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}

==================================================

File: c:\GH\ras-commander\examples\19_benchmarking_version_6.6.ipynb
==================================================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasHdf, RasUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define versions to compare\n",
    "versions = ['6.6', '6.5', '6.4.1', '6.3.1', '6.2', '6.1', '5.0.7']\n",
    "\n",
    "# Extract BaldEagleCrkMulti2D project\n",
    "ras_examples = RasExamples()\n",
    "project_path = ras_examples.extract_project([\"BaldEagleCrkMulti2D\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all plan numbers\n",
    "ras_project = init_ras_project(project_path, \"6.5\")\n",
    "print(ras_project)\n",
    "plan_numbers = ras_project.plan_df['plan_number'].tolist()\n",
    "print(plan_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from ras_commander import RasGeo\n",
    "\n",
    "def run_simulation(version, plan_number):\n",
    "    # Initialize project for the specific version\n",
    "    ras_project = init_ras_project(project_path, str(version))\n",
    "    \n",
    "    # Clear geometry preprocessor files\n",
    "    plan_path = RasPlan.get_plan_path(plan_number, ras_object=ras_project)\n",
    "    RasGeo.clear_geompre_files(plan_path, ras_object=ras_project)\n",
    "    \n",
    "    # Set number of cores to 6\n",
    "    RasPlan.set_num_cores(plan_number, \"6\", ras_object=ras_project)\n",
    "    \n",
    "    # Ensure geometry preprocessing is done\n",
    "    RasPlan.update_plan_value(plan_number, \"Run HTab\", 1, ras_object=ras_project)\n",
    "    \n",
    "    # Compute the plan\n",
    "    start_time = time.time()\n",
    "    success = RasCmdr.compute_plan(plan_number, ras_object=ras_project)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    if success:\n",
    "        # Get HDF file path\n",
    "        hdf_path = RasPlan.get_results_path(plan_number, ras_object=ras_project)\n",
    "        \n",
    "        # Extract data from HDF file\n",
    "        runtime_data = RasHdf.get_runtime_data(hdf_path, ras_object=ras_project)\n",
    "        \n",
    "        # Extract required information\n",
    "        preprocessor_time = runtime_data['Preprocessing Geometry (hr)'].values[0]\n",
    "        unsteady_compute_time = runtime_data['Unsteady Flow Computations (hr)'].values[0]\n",
    "        \n",
    "        # Get volume accounting data\n",
    "        volume_accounting = RasHdf.get_group_attributes_as_df(hdf_path, \"Results/Unsteady/Summary/Volume Accounting/Volume Accounting 2D\", ras_object=ras_project)\n",
    "        volume_error = volume_accounting['Volume Error (%)'].values[0]\n",
    "        \n",
    "        return {\n",
    "            'Version': version,\n",
    "            'Plan': plan_number,\n",
    "            'Preprocessor Time (hr)': preprocessor_time,\n",
    "            'Unsteady Compute Time (hr)': unsteady_compute_time,\n",
    "            'Volume Error (%)': volume_error,\n",
    "            'Total Time (hr)': total_time / 3600  # Convert seconds to hours\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run simulations for all versions and plans sequentially\n",
    "results = []\n",
    "for version in versions:\n",
    "    for plan in plan_numbers:\n",
    "        print(f\"Running simulation for Version {version}, Plan {plan}\")\n",
    "        result = run_simulation(version, plan)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"Completed: Version {version}, Plan {plan}\")\n",
    "        else:\n",
    "            print(f\"Failed: Version {version}, Plan {plan}\")\n",
    "\n",
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save initial results to CSV\n",
    "df.to_csv('save_initial_results.csv', index=False)\n",
    "\n",
    "print(\"Initial results saved to 'save_initial_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages across plans for each version\n",
    "df_avg = df.groupby('Version').mean().reset_index()\n",
    "\n",
    "# Create line graphs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Unsteady Runtime vs Version\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(df_avg['Version'], df_avg['Unsteady Compute Time (hr)'], marker='o')\n",
    "plt.title('Average Unsteady Runtime vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Unsteady Runtime (hours)')\n",
    "\n",
    "# Volume Error vs Version\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(df_avg['Version'], df_avg['Volume Error (%)'], marker='o')\n",
    "plt.title('Average Volume Error vs HEC-RAS Version')\n",
    "plt.xlabel('HEC-RAS Version')\n",
    "plt.ylabel('Volume Error (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results to CSV\n",
    "df.to_csv('hecras_version_comparison.csv', index=False)\n",
    "df_avg.to_csv('hecras_version_comparison_averages.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'hecras_version_comparison.csv' and 'hecras_version_comparison_averages.csv'\")\n",
    "print(\"Graphs have been displayed. Please check the output.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fffff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

==================================================

File: c:\GH\ras-commander\examples\xx_edge_cases.py
==================================================
#### --- IMPORTS AND EXAMPLE PROJECT SETUP --- ####

import sys
from pathlib import Path
import shutil

# Add the parent directory to the Python path
current_file = Path(__file__).resolve()
parent_directory = current_file.parent.parent
sys.path.append(str(parent_directory))

# Flexible imports to allow for development without installation
try:
    # Try to import from the installed package
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras
except ImportError:
    # If the import fails, add the parent directory to the Python path
    current_file = Path(__file__).resolve()
    parent_directory = current_file.parent.parent
    sys.path.append(str(parent_directory))
    
    # Now try to import again
    from ras_commander import init_ras_project, RasExamples, RasCmdr, RasPlan, RasGeo, RasUnsteady, RasUtils, ras

example_projects_folder = Path(__file__).parent.parent / "example_projects"

# delete the folder if it exists
if example_projects_folder.exists():
    shutil.rmtree(example_projects_folder)


# Extract specific projects
ras_examples = RasExamples()
ras_examples.extract_project(["Balde Eagle Creek"])

#### --- START OF SCRIPT --- ####

def main:
    """Docs only, see 'main.py' for full function code"""
    main()
==================================================

File: c:\GH\ras-commander\ras_commander\Decorators.py
==================================================
from functools import wraps
from pathlib import Path
from typing import Union
import logging
import h5py
import inspect


def log_call:
    """Docs only, see 'log_call.py' for full function code"""
    return decorator
==================================================

File: c:\GH\ras-commander\ras_commander\HdfBase.py
==================================================
"""
Class: HdfBase

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""
import re
from datetime import datetime, timedelta
import h5py
import numpy as np
import pandas as pd
import xarray as xr  # Added import for xarray
from typing import List, Tuple, Union, Optional, Dict
from pathlib import Path
import logging

from .HdfUtils import HdfUtils
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)

class HdfBase:
    """
    Base class for HEC-RAS HDF file operations.

    This class provides fundamental methods for interacting with HEC-RAS HDF files,
    including time-related operations and mesh data retrieval. It serves as a foundation
    for more specialized HDF classes.

    The methods in this class are designed to work with both plan and geometry HDF files,
    providing low-level access to file structure and content.

    Note:
    - All methods in this class are static, allowing for use without instantiation.
    - This class is not meant to be used directly in most cases, but rather as a base
      for more specialized HDF classes.
    """

    @staticmethod
    def _get_simulation_start_time(hdf_file: h5py.File) -> datetime:
        """
        Get the simulation start time from the HDF file.

        Args:
            hdf_file (h5py.File): Open HDF file object.

        Returns:
            datetime: The simulation start time.

        Raises:
            ValueError: If Plan Information is not found in the HDF file.
        """
        plan_info = hdf_file.get("Plan Data/Plan Information")
        if plan_info is None:
            raise ValueError("Plan Information not found in HDF file")
        time_str = plan_info.attrs.get('Simulation Start Time')
        return datetime.strptime(time_str.decode('utf-8'), "%d%b%Y %H:%M:%S")

    @staticmethod
    def _get_unsteady_datetimes(hdf_file: h5py.File) -> List[datetime]:
        """
        Get the list of unsteady datetimes from the HDF file.

        Args:
            hdf_file (h5py.File): Open HDF file object.

        Returns:
            List[datetime]: A list of datetime objects representing the unsteady timestamps.
        """
        group_path = "Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Time Date Stamp (ms)"
        raw_datetimes = hdf_file[group_path][:]
        return [HdfBase._parse_ras_datetime_ms(x.decode("utf-8")) for x in raw_datetimes]
    

    @staticmethod
    def _get_2d_flow_area_names_and_counts(hdf_file: h5py.File) -> List[Tuple[str, int]]:
        """
        Get the names and cell counts of 2D flow areas from the HDF file.

        Args:
            hdf_file (h5py.File): Open HDF file object.

        Returns:
            List[Tuple[str, int]]: A list of tuples containing the name and cell count of each 2D flow area.
        """
        d2_flow_areas = hdf_file.get("Geometry/2D Flow Areas/Attributes")
        if d2_flow_areas is None:
            return []
        return [(HdfBase._convert_ras_hdf_string(d2_flow_area[0]), d2_flow_area[-1]) for d2_flow_area in d2_flow_areas[:]]

    @staticmethod
    def _parse_ras_datetime(datetime_str: str) -> datetime:
        """
        Parse a datetime string from a RAS file into a datetime object.

        Args:
            datetime_str (str): The datetime string to parse.

        Returns:
            datetime: The parsed datetime object.
        """
        return datetime.strptime(datetime_str, "%d%b%Y %H:%M:%S")

    @staticmethod
    def _parse_ras_simulation_window_datetime(datetime_str: str) -> datetime:
        """
        Parse a datetime string from a RAS simulation window into a datetime object.

        Args:
            datetime_str (str): The datetime string to parse.

        Returns:
            datetime: The parsed datetime object.
        """
        return datetime.strptime(datetime_str, "%d%b%Y %H%M")

    @staticmethod
    def _parse_duration(duration_str: str) -> timedelta:
        """
        Parse a duration string into a timedelta object.

        Args:
            duration_str (str): The duration string to parse.

        Returns:
            timedelta: The parsed duration as a timedelta object.
        """
        hours, minutes, seconds = map(int, duration_str.split(':'))
        return timedelta(hours=hours, minutes=minutes, seconds=seconds)

    @staticmethod
    def _parse_ras_datetime_ms(datetime_str: str) -> datetime:
        """
        Parse a datetime string with milliseconds from a RAS file.

        Args:
            datetime_str (str): The datetime string to parse.

        Returns:
            datetime: The parsed datetime object.
        """
        milliseconds = int(datetime_str[-3:])
        microseconds = milliseconds * 1000
        parsed_dt = HdfBase._parse_ras_datetime(datetime_str[:-4]).replace(microsecond=microseconds)
        return parsed_dt

    @staticmethod
    def _convert_ras_hdf_string(value: Union[str, bytes]) -> Union[bool, datetime, List[datetime], timedelta, str]:
        """
        Convert a string value from an HEC-RAS HDF file into a Python object.

        Args:
            value (Union[str, bytes]): The value to convert.

        Returns:
            Union[bool, datetime, List[datetime], timedelta, str]: The converted value.
        """
        if isinstance(value, bytes):
            s = value.decode("utf-8")
        else:
            s = value

        if s == "True":
            return True
        elif s == "False":
            return False
        
        ras_datetime_format1_re = r"\d{2}\w{3}\d{4} \d{2}:\d{2}:\d{2}"
        ras_datetime_format2_re = r"\d{2}\w{3}\d{4} \d{2}\d{2}"
        ras_duration_format_re = r"\d{2}:\d{2}:\d{2}"

        if re.match(rf"^{ras_datetime_format1_re}", s):
            if re.match(rf"^{ras_datetime_format1_re} to {ras_datetime_format1_re}$", s):
                split = s.split(" to ")
                return [
                    HdfBase._parse_ras_datetime(split[0]),
                    HdfBase._parse_ras_datetime(split[1]),
                ]
            return HdfBase._parse_ras_datetime(s)
        elif re.match(rf"^{ras_datetime_format2_re}", s):
            if re.match(rf"^{ras_datetime_format2_re} to {ras_datetime_format2_re}$", s):
                split = s.split(" to ")
                return [
                    HdfBase._parse_ras_simulation_window_datetime(split[0]),
                    HdfBase._parse_ras_simulation_window_datetime(split[1]),
                ]
            return HdfBase._parse_ras_simulation_window_datetime(s)
        elif re.match(rf"^{ras_duration_format_re}$", s):
            return HdfBase._parse_duration(s)
        return s




==================================================

File: c:\GH\ras-commander\ras_commander\HdfBndry.py
==================================================
"""
Class: HdfBndry

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""
from pathlib import Path
from typing import Dict, List, Optional, Union, Any
import h5py
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import LineString, MultiLineString, Polygon, MultiPolygon, Point
from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .HdfMesh import HdfMesh
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)


class HdfBndry:
    """
    A class for handling boundary-related data from HEC-RAS HDF files.

    This class provides methods to extract and process various boundary elements
    such as boundary condition lines, breaklines, refinement regions, and reference
    lines/points from HEC-RAS geometry HDF files.

    Methods in this class return data primarily as GeoDataFrames, making it easy
    to work with spatial data in a geospatial context.

    Note:
        This class relies on the HdfBase and HdfUtils classes for some of its
        functionality. Ensure these classes are available in the same package.
    """

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def bc_lines(hdf_path: Path) -> gpd.GeoDataFrame:
        """
        Return 2D mesh area boundary condition lines.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        gpd.GeoDataFrame
            A GeoDataFrame containing the boundary condition lines.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                bc_lines_path = "Geometry/Boundary Condition Lines"
                if bc_lines_path not in hdf_file:
                    return gpd.GeoDataFrame()
                bc_line_data = hdf_file[bc_lines_path]
                bc_line_ids = range(bc_line_data["Attributes"][()].shape[0])
                v_conv_str = np.vectorize(HdfUtils.convert_ras_hdf_string)
                names = v_conv_str(bc_line_data["Attributes"][()]["Name"])
                mesh_names = v_conv_str(bc_line_data["Attributes"][()]["SA-2D"])
                types = v_conv_str(bc_line_data["Attributes"][()]["Type"])
                geoms = HdfBndry._get_polylines(hdf_file, bc_lines_path)
                return gpd.GeoDataFrame(
                    {
                        "bc_line_id": bc_line_ids,
                        "name": names,
                        "mesh_name": mesh_names,
                        "type": types,
                        "geometry": geoms,
                    },
                    geometry="geometry",
                    crs=HdfUtils.projection(hdf_file),
                )
        except Exception as e:
            print(f"Error reading boundary condition lines: {str(e)}")
            return gpd.GeoDataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def breaklines(hdf_path: Path) -> gpd.GeoDataFrame:
        """
        Return 2D mesh area breaklines.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        gpd.GeoDataFrame
            A GeoDataFrame containing the breaklines.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                breaklines_path = "Geometry/2D Flow Area Break Lines"
                if breaklines_path not in hdf_file:
                    return gpd.GeoDataFrame()
                bl_line_data = hdf_file[breaklines_path]
                bl_line_ids = range(bl_line_data["Attributes"][()].shape[0])
                names = np.vectorize(HdfUtils.convert_ras_hdf_string)(
                    bl_line_data["Attributes"][()]["Name"]
                )
                geoms = HdfBndry._get_polylines(hdf_file, breaklines_path)
                return gpd.GeoDataFrame(
                    {"bl_id": bl_line_ids, "name": names, "geometry": geoms},
                    geometry="geometry",
                    crs=HdfUtils.projection(hdf_file),
                )
        except Exception as e:
            print(f"Error reading breaklines: {str(e)}")
            return gpd.GeoDataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def refinement_regions(hdf_path: Path) -> gpd.GeoDataFrame:
        """
        Return 2D mesh area refinement regions.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        gpd.GeoDataFrame
            A GeoDataFrame containing the refinement regions.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                refinement_regions_path = "/Geometry/2D Flow Area Refinement Regions"
                if refinement_regions_path not in hdf_file:
                    return gpd.GeoDataFrame()
                rr_data = hdf_file[refinement_regions_path]
                rr_ids = range(rr_data["Attributes"][()].shape[0])
                names = np.vectorize(HdfUtils.convert_ras_hdf_string)(rr_data["Attributes"][()]["Name"])
                geoms = list()
                for pnt_start, pnt_cnt, part_start, part_cnt in rr_data["Polygon Info"][()]:
                    points = rr_data["Polygon Points"][()][pnt_start : pnt_start + pnt_cnt]
                    if part_cnt == 1:
                        geoms.append(Polygon(points))
                    else:
                        parts = rr_data["Polygon Parts"][()][part_start : part_start + part_cnt]
                        geoms.append(
                            MultiPolygon(
                                list(
                                    points[part_pnt_start : part_pnt_start + part_pnt_cnt]
                                    for part_pnt_start, part_pnt_cnt in parts
                                )
                            )
                        )
                return gpd.GeoDataFrame(
                    {"rr_id": rr_ids, "name": names, "geometry": geoms},
                    geometry="geometry",
                    crs=HdfUtils.projection(hdf_file),
                )
        except Exception as e:
            print(f"Error reading refinement regions: {str(e)}")
            return gpd.GeoDataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def reference_lines_names(hdf_path: Path, mesh_name: Optional[str] = None) -> Union[Dict[str, List[str]], List[str]]:
        """
        Return reference line names.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        mesh_name : Optional[str], optional
            Name of the mesh to filter by. Default is None.

        Returns
        -------
        Union[Dict[str, List[str]], List[str]]
            A dictionary of mesh names to reference line names, or a list of reference line names if mesh_name is provided.
        """
        return HdfBndry._get_reference_lines_points_names(hdf_path, "lines", mesh_name)

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def reference_points_names(hdf_path: Path, mesh_name: Optional[str] = None) -> Union[Dict[str, List[str]], List[str]]:
        """
        Return reference point names.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        mesh_name : Optional[str], optional
            Name of the mesh to filter by. Default is None.

        Returns
        -------
        Union[Dict[str, List[str]], List[str]]
            A dictionary of mesh names to reference point names, or a list of reference point names if mesh_name is provided.
        """
        return HdfBndry._get_reference_lines_points_names(hdf_path, "points", mesh_name)

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def reference_lines(hdf_path: Path) -> gpd.GeoDataFrame:
        """
        Return the reference lines geometry and attributes.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        gpd.GeoDataFrame
            A GeoDataFrame containing the reference lines.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                reference_lines_path = "Geometry/Reference Lines"
                attributes_path = f"{reference_lines_path}/Attributes"
                if attributes_path not in hdf_file:
                    return gpd.GeoDataFrame()
                attributes = hdf_file[attributes_path][()]
                refline_ids = range(attributes.shape[0])
                v_conv_str = np.vectorize(HdfUtils.convert_ras_hdf_string)
                names = v_conv_str(attributes["Name"])
                mesh_names = v_conv_str(attributes["SA-2D"])
                try:
                    types = v_conv_str(attributes["Type"])
                except ValueError:
                    # "Type" field doesn't exist -- observed in some RAS HDF files
                    types = np.array([""] * attributes.shape[0])
                geoms = HdfBndry._get_polylines(hdf_file, reference_lines_path)
                return gpd.GeoDataFrame(
                    {
                        "refln_id": refline_ids,
                        "refln_name": names,
                        "mesh_name": mesh_names,
                        "type": types,
                        "geometry": geoms,
                    },
                    geometry="geometry",
                    crs=HdfUtils.projection(hdf_file),
                )
        except Exception as e:
            print(f"Error reading reference lines: {str(e)}")
            return gpd.GeoDataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def reference_points(hdf_path: Path) -> gpd.GeoDataFrame:
        """
        Return the reference points geometry and attributes.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        gpd.GeoDataFrame
            A GeoDataFrame containing the reference points.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                reference_points_path = "Geometry/Reference Points"
                attributes_path = f"{reference_points_path}/Attributes"
                if attributes_path not in hdf_file:
                    return gpd.GeoDataFrame()
                ref_points_group = hdf_file[reference_points_path]
                attributes = ref_points_group["Attributes"][:]
                v_conv_str = np.vectorize(HdfUtils.convert_ras_hdf_string)
                names = v_conv_str(attributes["Name"])
                mesh_names = v_conv_str(attributes["SA/2D"])
                cell_id = attributes["Cell Index"]
                points = ref_points_group["Points"][()]
                return gpd.GeoDataFrame(
                    {
                        "refpt_id": range(attributes.shape[0]),
                        "refpt_name": names,
                        "mesh_name": mesh_names,
                        "cell_id": cell_id,
                        "geometry": list(map(Point, points)),
                    },
                    geometry="geometry",
                    crs=HdfUtils.projection(hdf_file),
                )
        except Exception as e:
            print(f"Error reading reference points: {str(e)}")
            return gpd.GeoDataFrame()

    @staticmethod
    def _get_reference_lines_points_names(hdf_path: Path, reftype: str = "lines", mesh_name: Optional[str] = None) -> Union[Dict[str, List[str]], List[str]]:
        """
        Get the names of reference lines or points.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        reftype : str, optional
            Type of reference, either "lines" or "points" (default "lines").
        mesh_name : Optional[str], optional
            Name of the mesh to filter by. Default is None.

        Returns
        -------
        Union[Dict[str, List[str]], List[str]]
            A dictionary of mesh names to reference names, or a list of reference names if mesh_name is provided.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if reftype == "lines":
                    path = "Geometry/Reference Lines"
                    sa_2d_field = "SA-2D"
                elif reftype == "points":
                    path = "Geometry/Reference Points"
                    sa_2d_field = "SA/2D"
                else:
                    raise ValueError(
                        f"Invalid reference type: {reftype} -- must be 'lines' or 'points'."
                    )
                attributes_path = f"{path}/Attributes"
                if mesh_name is None and attributes_path not in hdf_file:
                    return {m: [] for m in HdfMesh.mesh_area_names(hdf_file)}
                if mesh_name is not None and attributes_path not in hdf_file:
                    return []
                attributes = hdf_file[attributes_path][()]
                v_conv_str = np.vectorize(HdfUtils.convert_ras_hdf_string)
                names = v_conv_str(attributes["Name"])
                if mesh_name is not None:
                    return names[v_conv_str(attributes[sa_2d_field]) == mesh_name].tolist()
                mesh_names = v_conv_str(attributes[sa_2d_field])
                return {m: names[mesh_names == m].tolist() for m in np.unique(mesh_names)}
        except Exception as e:
            print(f"Error reading reference lines/points names: {str(e)}")
            return {} if mesh_name is None else []

    @staticmethod
    def _get_polylines(hdf_file: h5py.File, path: str, info_name: str = "Polyline Info", parts_name: str = "Polyline Parts", points_name: str = "Polyline Points") -> List[Union[LineString, MultiLineString]]:
        """
        Get polyline geometries from HDF file.

        Parameters
        ----------
        hdf_file : h5py.File
            Open HDF file object.
        path : str
            Path to the polyline data in the HDF file.
        info_name : str, optional
            Name of the info dataset (default "Polyline Info").
        parts_name : str, optional
            Name of the parts dataset (default "Polyline Parts").
        points_name : str, optional
            Name of the points dataset (default "Polyline Points").

        Returns
        -------
        List[Union[LineString, MultiLineString]]
            A list of polyline geometries.
        """
        polyline_info_path = f"{path}/{info_name}"
        polyline_parts_path = f"{path}/{parts_name}"
        polyline_points_path = f"{path}/{points_name}"

        polyline_info = hdf_file[polyline_info_path][()]
        polyline_parts = hdf_file[polyline_parts_path][()]
        polyline_points = hdf_file[polyline_points_path][()]

        geoms = []
        for pnt_start, pnt_cnt, part_start, part_cnt in polyline_info:
            points = polyline_points[pnt_start : pnt_start + pnt_cnt]
            if part_cnt == 1:
                geoms.append(LineString(points))
            else:
                parts = polyline_parts[part_start : part_start + part_cnt]
                geoms.append(
                    MultiLineString(
                        list(
                            points[part_pnt_start : part_pnt_start + part_pnt_cnt]
                            for part_pnt_start, part_pnt_cnt in parts
                        )
                    )
                )
        return geoms
    
    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_boundary_attributes(hdf_path: Path, boundary_type: str) -> pd.DataFrame:
        """
        Get attributes of boundary elements.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        boundary_type : str
            Type of boundary element ('bc_lines', 'breaklines', 'refinement_regions', 'reference_lines', 'reference_points').

        Returns
        -------
        pd.DataFrame
            A DataFrame containing the attributes of the specified boundary element.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if boundary_type == 'bc_lines':
                    path = "Geometry/Boundary Condition Lines/Attributes"
                elif boundary_type == 'breaklines':
                    path = "Geometry/2D Flow Area Break Lines/Attributes"
                elif boundary_type == 'refinement_regions':
                    path = "Geometry/2D Flow Area Refinement Regions/Attributes"
                elif boundary_type == 'reference_lines':
                    path = "Geometry/Reference Lines/Attributes"
                elif boundary_type == 'reference_points':
                    path = "Geometry/Reference Points/Attributes"
                else:
                    raise ValueError(f"Invalid boundary type: {boundary_type}")

                if path not in hdf_file:
                    return pd.DataFrame()

                attributes = hdf_file[path][()]
                return pd.DataFrame(attributes)
        except Exception as e:
            print(f"Error reading {boundary_type} attributes: {str(e)}")
            return pd.DataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_boundary_count(hdf_path: Path, boundary_type: str) -> int:
        """
        Get the count of boundary elements.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        boundary_type : str
            Type of boundary element ('bc_lines', 'breaklines', 'refinement_regions', 'reference_lines', 'reference_points').

        Returns
        -------
        int
            The count of the specified boundary element.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if boundary_type == 'bc_lines':
                    path = "Geometry/Boundary Condition Lines/Attributes"
                elif boundary_type == 'breaklines':
                    path = "Geometry/2D Flow Area Break Lines/Attributes"
                elif boundary_type == 'refinement_regions':
                    path = "Geometry/2D Flow Area Refinement Regions/Attributes"
                elif boundary_type == 'reference_lines':
                    path = "Geometry/Reference Lines/Attributes"
                elif boundary_type == 'reference_points':
                    path = "Geometry/Reference Points/Attributes"
                else:
                    raise ValueError(f"Invalid boundary type: {boundary_type}")

                if path not in hdf_file:
                    return 0

                return hdf_file[path].shape[0]
        except Exception as e:
            print(f"Error getting {boundary_type} count: {str(e)}")
            return 0

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_boundary_names(hdf_path: Path, boundary_type: str) -> List[str]:
        """
        Get the names of boundary elements.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        boundary_type : str
            Type of boundary element ('bc_lines', 'breaklines', 'refinement_regions', 'reference_lines', 'reference_points').

        Returns
        -------
        List[str]
            A list of names for the specified boundary element.
        """
        try:
            df = HdfBndry.get_boundary_attributes(hdf_path, boundary_type)
            if 'Name' in df.columns:
                return df['Name'].tolist()
            else:
                return []
        except Exception as e:
            print(f"Error getting {boundary_type} names: {str(e)}")
            return []
==================================================

File: c:\GH\ras-commander\ras_commander\HdfMesh.py
==================================================
"""
Class: HdfMesh

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""
from pathlib import Path
import h5py
import numpy as np
import pandas as pd
from geopandas import GeoDataFrame
from shapely.geometry import Polygon, Point, LineString, MultiLineString, MultiPolygon
from shapely.ops import polygonize  # Importing polygonize to resolve the undefined name error
from typing import List, Tuple, Optional, Dict, Any
import logging
from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)


class HdfMesh:
    """
    A class for handling mesh-related operations on HEC-RAS HDF files.

    This class provides methods to extract and analyze mesh data from HEC-RAS HDF files,
    including mesh area names, mesh areas, cell polygons, cell points, cell faces, and
    2D flow area attributes.

    Methods in this class are designed to work with the mesh geometry data stored in
    HEC-RAS HDF files, providing functionality to retrieve and process various aspects
    of the 2D flow areas and their associated mesh structures.

    Note: This class relies on HdfBase and HdfUtils for some underlying operations.
    """

    FLOW_AREA_2D_PATH = "Geometry/2D Flow Areas"

    def __init__:
    """Docs only, see '__init__.py' for full function code"""

==================================================

File: c:\GH\ras-commander\ras_commander\HdfPlan.py
==================================================
"""
Class: HdfPlan

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""

import h5py
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)


class HdfPlan:
    """
    A class for handling operations on HEC-RAS plan HDF files.

    This class provides methods for extracting and analyzing data from HEC-RAS plan HDF files,
    including simulation times, plan information, and geometry attributes.

    Methods in this class use the @standardize_input decorator to handle different input types
    (e.g., plan number, file path) and the @log_call decorator for logging method calls.

    Attributes:
        None

    Methods:
        get_simulation_start_time: Get the simulation start time.
        get_simulation_end_time: Get the simulation end time.
        get_unsteady_datetimes: Get a list of unsteady datetimes.
        get_plan_info_attrs: Get plan information attributes.
        get_plan_param_attrs: Get plan parameter attributes.
        get_meteorology_precip_attrs: Get precipitation attributes.
        get_geom_attrs: Get geometry attributes.
    """

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_simulation_start_time(hdf_path: Path) -> datetime:
        """
        Get the simulation start time from the plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            datetime: The simulation start time.

        Raises:
            ValueError: If there's an error reading the simulation start time.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfBase._get_simulation_start_time(hdf_file)
        except Exception as e:
            raise ValueError(f"Failed to get simulation start time: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_simulation_end_time(hdf_path: Path) -> datetime:
        """
        Get the simulation end time from the plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            datetime: The simulation end time.

        Raises:
            ValueError: If there's an error reading the simulation end time.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                plan_info = hdf_file.get('Plan Data/Plan Information')
                if plan_info is None:
                    raise ValueError("Plan Information not found in HDF file")
                time_str = plan_info.attrs.get('Simulation End Time')
                return datetime.strptime(time_str.decode('utf-8'), "%d%b%Y %H:%M:%S")
        except Exception as e:
            raise ValueError(f"Failed to get simulation end time: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_unsteady_datetimes(hdf_path: Path) -> List[datetime]:
        """
        Get the list of unsteady datetimes from the HDF file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            List[datetime]: A list of datetime objects representing the unsteady timestamps.

        Raises:
            ValueError: If there's an error retrieving the unsteady datetimes.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfBase._get_unsteady_datetimes(hdf_file)
        except Exception as e:
            raise ValueError(f"Failed to get unsteady datetimes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_plan_info_attrs(hdf_path: Path) -> Dict:
        """
        Get plan information attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the plan information attributes.

        Raises:
            ValueError: If there's an error retrieving the plan information attributes.
        """
        try:
            return HdfUtils.get_attrs(hdf_path, "Plan Data/Plan Information")
        except Exception as e:
            raise ValueError(f"Failed to get plan information attributes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_plan_param_attrs(hdf_path: Path) -> Dict:
        """
        Get plan parameter attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the plan parameter attributes.

        Raises:
            ValueError: If there's an error retrieving the plan parameter attributes.
        """
        try:
            return HdfUtils.get_attrs(hdf_path, "Plan Data/Plan Parameters")
        except Exception as e:
            raise ValueError(f"Failed to get plan parameter attributes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_meteorology_precip_attrs(hdf_path: Path) -> Dict:
        """
        Get precipitation attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the precipitation attributes.

        Raises:
            ValueError: If there's an error retrieving the precipitation attributes.
        """
        try:
            return HdfUtils.get_attrs(hdf_path, "Event Conditions/Meteorology/Precipitation")
        except Exception as e:
            raise ValueError(f"Failed to get precipitation attributes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_geom_attrs(hdf_path: Path) -> Dict:
        """
        Get geometry attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the geometry attributes.

        Raises:
            ValueError: If there's an error retrieving the geometry attributes.
        """
        try:
            return HdfUtils.get_attrs(hdf_path, "Geometry")
        except Exception as e:
            raise ValueError(f"Failed to get geometry attributes: {str(e)}")

==================================================

File: c:\GH\ras-commander\ras_commander\HdfResultsMesh.py
==================================================
"""
Class: HdfResultsMesh

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""

import numpy as np
import pandas as pd
import xarray as xr
from pathlib import Path
import h5py
from typing import Union, List, Optional, Dict, Any, Tuple

from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .Decorators import log_call, standardize_input
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)

class HdfResultsMesh:
    """
    A class for handling mesh-related results from HEC-RAS HDF files.

    This class provides methods to extract and analyze mesh summary outputs,
    timeseries data, and various mesh-specific results such as water surface
    elevations, velocities, and errors.

    The class works with HEC-RAS plan HDF files and uses HdfBase and HdfUtils
    for common operations and utilities.

    Methods in this class use the @log_call decorator for logging and the
    @standardize_input decorator to handle different input types (e.g., 
    plan number, file path).

    Attributes:
        None

    Note:
        This class is designed to work with HEC-RAS version 6.0 and later.
    """

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_summary_output(hdf_path: Path, var: str, round_to: str = "100ms") -> pd.DataFrame:
        """
        Return the summary output data for a given variable.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.
            var (str): The summary output variable to retrieve.
            round_to (str): The time unit to round the datetimes to. Default: "100ms" (100 milliseconds).

        Returns:
            pd.DataFrame: DataFrame containing the summary output data.

        Raises:
            ValueError: If there's an error processing the summary output data.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, var, round_to)
        except Exception as e:
            logger.error(f"Error in mesh_summary_output: {str(e)}")
            logger.error(f"Variable: {var}")
            raise ValueError(f"Failed to get summary output: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_timeseries_output(hdf_path: Path, mesh_name: str, var: str, truncate: bool = True) -> xr.DataArray:
        """
        Get timeseries output for a specific mesh and variable.

        Args:
            hdf_path (Path): Path to the HDF file.
            mesh_name (str): Name of the mesh.
            var (str): Variable to retrieve. Valid options include:
                "Water Surface", "Face Velocity", "Cell Velocity X", "Cell Velocity Y",
                "Face Flow", "Face Water Surface", "Cell Volume", "Cell Volume Error",
                "Cell Water Surface Error", "Cell Courant", "Face Courant",
                "Cell Hydraulic Depth", "Cell Invert Depth",
                "Cell Cumulative Precipitation Depth", "Cell Divergence Term",
                "Cell Eddy Viscosity X", "Cell Eddy Viscosity Y", "Cell Flow Balance",
                "Cell Storage Term", "Cell Water Source Term", "Face Cumulative Volume",
                "Face Eddy Viscosity", "Face Flow Period Average", "Face Friction Term",
                "Face Pressure Gradient Term", "Face Shear Stress", "Face Tangential Velocity"
            truncate (bool): Whether to truncate the output (default True).

        Returns:
            xr.DataArray: DataArray containing the timeseries output.
        """
        with h5py.File(hdf_path, 'r') as hdf_file:
            return HdfResultsMesh._get_mesh_timeseries_output(hdf_file, mesh_name, var, truncate)

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_faces_timeseries_output(hdf_path: Path, mesh_name: str) -> xr.Dataset:
        """
        Get timeseries output for all face-based variables of a specific mesh.

        Args:
            hdf_path (Path): Path to the HDF file.
            mesh_name (str): Name of the mesh.

        Returns:
            xr.Dataset: Dataset containing the timeseries output for all face-based variables.
        """
        face_vars = ["Face Velocity", "Face Flow"]
        datasets = []
        
        for var in face_vars:
            try:
                da = HdfResultsMesh.mesh_timeseries_output(hdf_path, mesh_name, var)
                # Assign the variable name as the DataArray name
                da.name = var.lower().replace(' ', '_')
                datasets.append(da)
            except Exception as e:
                logger.warning(f"Failed to process {var} for mesh {mesh_name}: {str(e)}")
        
        if not datasets:
            logger.error(f"No valid data found for mesh {mesh_name}")
            return xr.Dataset()
        
        try:
            return xr.merge(datasets)
        except Exception as e:
            logger.error(f"Failed to merge datasets: {str(e)}")
            return xr.Dataset()

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_cells_timeseries_output(hdf_path: Path, mesh_names: Optional[Union[str, List[str]]] = None, var: Optional[str] = None, truncate: bool = False, ras_object: Optional[Any] = None) -> Dict[str, xr.Dataset]:
        """
        Get mesh cells timeseries output for specified meshes and variables.

        Args:
            hdf_path (Union[str, Path]): Path to the HDF file.
            mesh_names (Optional[Union[str, List[str]]]): Name(s) of the mesh(es). If None, processes all available meshes.
            var (Optional[str]): Name of the variable to retrieve. If None, retrieves all variables.
            truncate (bool): If True, truncates the output to remove trailing zeros.
            ras_object (Optional[Any]): RAS object, if available.

        Returns:
            Dict[str, xr.Dataset]: A dictionary of xarray Datasets, one for each mesh, containing the mesh cells timeseries output.

        Raises:
            ValueError: If there's an error processing the timeseries output data.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._mesh_cells_timeseries_output(hdf_file, mesh_names, var, truncate)
        except Exception as e:
            logger.error(f"Error in mesh_cells_timeseries_output: {str(e)}")
            raise ValueError(f"Error processing timeseries output data: {e}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_last_iter(hdf_path: Path) -> pd.DataFrame:
        """
        Get last iteration count for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.

        Returns:
            pd.DataFrame: DataFrame containing last iteration counts.
        """
        return HdfResultsMesh._get_mesh_summary_output(hdf_path, "Cell Last Iteration")


    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_max_ws(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get maximum iteration count for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing maximum iteration counts.

        Raises:
            ValueError: If there's an error processing the maximum iteration data.
            
        Note: The Maximum Iteration is labeled as "Cell Last Iteration" in the HDF file 
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Maximum Water Surface", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_max_ws: {str(e)}")
            raise ValueError(f"Failed to get maximum water surface: {str(e)}")
        




    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_min_ws(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get minimum water surface elevation for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing minimum water surface elevations.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Minimum Water Surface", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_min_ws: {str(e)}")
            raise ValueError(f"Failed to get minimum water surface: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_max_face_v(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get maximum face velocity for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing maximum face velocities.

        Raises:
            ValueError: If there's an error processing the maximum face velocity data.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Maximum Face Velocity", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_max_face_v: {str(e)}")
            raise ValueError(f"Failed to get maximum face velocity: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_min_face_v(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get minimum face velocity for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing minimum face velocities.

        Raises:
            ValueError: If there's an error processing the minimum face velocity data.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Minimum Face Velocity", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_min_face_v: {str(e)}")
            raise ValueError(f"Failed to get minimum face velocity: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_max_ws_err(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get maximum water surface error for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing maximum water surface errors.

        Raises:
            ValueError: If there's an error processing the maximum water surface error data.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Cell Maximum Water Surface Error", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_max_ws_err: {str(e)}")
            raise ValueError(f"Failed to get maximum water surface error: {str(e)}")


    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def mesh_max_iter(hdf_path: Path, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get maximum iteration count for each mesh cell.

        Args:
            hdf_path (Path): Path to the HDF file.
            round_to (str): Time rounding specification (default "100ms").

        Returns:
            pd.DataFrame: DataFrame containing maximum iteration counts.

        Raises:
            ValueError: If there's an error processing the maximum iteration data.
            
        Note: The Maximum Iteration is labeled as "Cell Last Iteration" in the HDF file 
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsMesh._get_mesh_summary_output(hdf_file, "Cell Last Iteration", round_to)
        except Exception as e:
            logger.error(f"Error in mesh_max_iter: {str(e)}")
            raise ValueError(f"Failed to get maximum iteration count: {str(e)}")
        
        
        


    @staticmethod
    def _get_mesh_timeseries_output_path(mesh_name: str, var_name: str) -> str:
        """
        Get the HDF path for mesh timeseries output.

        Args:
            mesh_name (str): Name of the mesh.
            var_name (str): Name of the variable.

        Returns:
            str: The HDF path for the specified mesh and variable.
        """
        return f"Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/2D Flow Areas/{mesh_name}/{var_name}"


    @staticmethod
    def _mesh_cells_timeseries_output(hdf_file: h5py.File, mesh_names: Optional[Union[str, List[str]]] = None, var: Optional[str] = None, truncate: bool = False) -> Dict[str, xr.Dataset]:
        """
        Get mesh cells timeseries output for specified meshes and variables.

        Args:
            hdf_file (h5py.File): Open HDF file object.
            mesh_names (Optional[Union[str, List[str]]]): Name(s) of the mesh(es). If None, processes all available meshes.
            var (Optional[str]): Name of the variable to retrieve. If None, retrieves all variables.
            truncate (bool): If True, truncates the output to remove trailing zeros.

        Returns:
            Dict[str, xr.Dataset]: A dictionary of xarray Datasets, one for each mesh, containing the mesh cells timeseries output.

        Raises:
            ValueError: If there's an error processing the timeseries output data.
        """
        TIME_SERIES_OUTPUT_VARS_CELLS = [
            "Water Surface",
            "Depth",
            "Velocity",
            "Velocity X",
            "Velocity Y",
            "Froude Number",
            "Courant Number",
            "Shear Stress",
            "Bed Elevation",
            "Precipitation Rate",
            "Infiltration Rate",
            "Evaporation Rate",
            "Percolation Rate",
            "Groundwater Elevation",
            "Groundwater Depth",
            "Groundwater Flow",
            "Groundwater Velocity",
            "Groundwater Velocity X",
            "Groundwater Velocity Y",
        ]

        try:
            start_time = HdfBase._get_simulation_start_time(hdf_file)
            time_stamps = HdfBase._get_unsteady_datetimes(hdf_file)

            if mesh_names is None:
                mesh_names = HdfResultsMesh._get_available_meshes(hdf_file)
            elif isinstance(mesh_names, str):
                mesh_names = [mesh_names]

            if var:
                variables = [var]
            else:
                variables = TIME_SERIES_OUTPUT_VARS_CELLS

            datasets = {}
            for mesh_name in mesh_names:
                data_vars = {}
                for variable in variables:
                    try:
                        path = HdfResultsMesh._get_mesh_timeseries_output_path(mesh_name, variable)
                        dataset = hdf_file[path]
                        values = dataset[:]
                        units = dataset.attrs.get("Units", "").decode("utf-8")

                        if truncate:
                            last_nonzero = np.max(np.nonzero(values)[1]) + 1 if values.size > 0 else 0
                            values = values[:, :last_nonzero]
                            truncated_time_stamps = time_stamps[:last_nonzero]
                        else:
                            truncated_time_stamps = time_stamps

                        if values.shape[0] != len(truncated_time_stamps):
                            logger.warning(f"Mismatch between number of time steps ({len(truncated_time_stamps)}) and data shape ({values.shape}) for variable {variable}")
                            continue

                        data_vars[variable] = xr.DataArray(
                            data=values,
                            dims=['time', 'cell_id'],
                            coords={'time': truncated_time_stamps, 'cell_id': np.arange(values.shape[1])},
                            attrs={'units': units}
                        )
                    except KeyError:
                        logger.warning(f"Variable '{variable}' not found in the HDF file for mesh '{mesh_name}'. Skipping.")
                    except Exception as e:
                        logger.error(f"Error processing variable '{variable}' for mesh '{mesh_name}': {str(e)}")

                if data_vars:
                    datasets[mesh_name] = xr.Dataset(
                        data_vars=data_vars,
                        attrs={'mesh_name': mesh_name, 'start_time': start_time}
                    )
                else:
                    logger.warning(f"No valid data variables found for mesh '{mesh_name}'")

            return datasets
        except Exception as e:
            logger.error(f"Error in _mesh_cells_timeseries_output: {str(e)}")
            raise ValueError(f"Error processing timeseries output data: {e}")



    @staticmethod
    def _get_mesh_timeseries_output(hdf_file: h5py.File, mesh_name: str, var: str, truncate: bool = True) -> xr.DataArray:
        """
        Get timeseries output for a specific mesh and variable.

        Args:
            hdf_file (h5py.File): Open HDF file object.
            mesh_name (str): Name of the mesh.
            var (str): Variable name to retrieve. Valid options include:
                "Water Surface", "Face Velocity", "Cell Velocity X", "Cell Velocity Y",
                "Face Flow", "Face Water Surface", "Cell Volume", "Cell Volume Error",
                "Cell Water Surface Error", "Cell Courant", "Face Courant",
                "Cell Hydraulic Depth", "Cell Invert Depth",
                "Cell Cumulative Precipitation Depth", "Cell Divergence Term",
                "Cell Eddy Viscosity X", "Cell Eddy Viscosity Y", "Cell Flow Balance",
                "Cell Storage Term", "Cell Water Source Term", "Face Cumulative Volume",
                "Face Eddy Viscosity", "Face Flow Period Average", "Face Friction Term",
                "Face Pressure Gradient Term", "Face Shear Stress", "Face Tangential Velocity"
            truncate (bool): Whether to truncate the output to remove trailing zeros (default True).

        Returns:
            xr.DataArray: DataArray containing the timeseries output.

        Raises:
            ValueError: If the specified path is not found in the HDF file or if there's an error processing the data.
        """
        try:
            path = HdfResultsMesh._get_mesh_timeseries_output_path(mesh_name, var)
            
            if path not in hdf_file:
                raise ValueError(f"Path {path} not found in HDF file")

            # Use h5py to get the dataset
            dataset = hdf_file[path]
            values = dataset[:]
            units = dataset.attrs.get("Units", "").decode("utf-8")
            times = HdfBase._get_unsteady_datetimes(hdf_file)

            if truncate:
                non_zero = np.nonzero(values)[0]
                if len(non_zero) > 0:
                    start, end = non_zero[0], non_zero[-1] + 1
                    values = values[start:end]
                    times = times[start:end]

            # Create xarray DataArray
            dims = ["time", "cell"] if values.ndim == 2 else ["time"]
            coords = {"time": times}
            if values.ndim == 2:
                coords["cell"] = np.arange(values.shape[1])

            return xr.DataArray(
                values,
                coords=coords,
                dims=dims,
                attrs={"units": units, "mesh_name": mesh_name, "variable": var},
            )
        except Exception as e:
            logger.error(f"Error in get_mesh_timeseries_output: {str(e)}")
            raise ValueError(f"Failed to get timeseries output: {str(e)}")


    @staticmethod
    def _get_mesh_timeseries_output_values_units(hdf_file: h5py.File, mesh_name: str, var: str) -> Tuple[np.ndarray, str]:
        """
        Get the mesh timeseries output values and units for a specific variable from the HDF file.

        Args:
            hdf_file (h5py.File): Open HDF file object.
            mesh_name (str): Name of the mesh.
            var (str): Variable name to retrieve.

        Returns:
            Tuple[np.ndarray, str]: A tuple containing the output values and units.
        """
        path = HdfResultsMesh._get_mesh_timeseries_output_path(mesh_name, var)
        group = hdf_file[path]
        values = group[:]
        units = group.attrs.get("Units")
        if units is not None:
            units = units.decode("utf-8")
        return values, units


    @staticmethod
    def _get_available_meshes(hdf_file: h5py.File) -> List[str]:
        """
        Get the names of all available meshes in the HDF file.

        Args:
            hdf_file (h5py.File): Open HDF file object.

        Returns:
            List[str]: A list of mesh names.
        """
        mesh_names = []
        base_path = "Geometry/2D Flow Areas"
        if base_path in hdf_file:
            for name in hdf_file[base_path]:
                if isinstance(hdf_file[f"{base_path}/{name}"], h5py.Group):
                    mesh_names.append(name)
        return mesh_names

    @staticmethod
    def _get_mesh_summary_output(hdf_file: h5py.File, var: str, round_to: str = "100ms") -> pd.DataFrame:
        """
        Get the summary output data for a given variable from the HDF file.

        This method retrieves summary output data for all 2D flow areas (meshes) in the HDF file
        for a specified variable. It handles both 1D and 2D datasets.
        Group attributes are added as metadata to the DataFrame.

        Args:
            hdf_file (h5py.File): Open HDF file object.
            var (str): The summary output variable to retrieve.
            round_to (str): The time unit to round the datetimes to. Default is "100ms".

        Returns:
            pd.DataFrame: A DataFrame containing the summary output data with attributes as metadata.

        Raises:
            ValueError: If the HDF file cannot be opened or read, or if the requested data is not found.
        """
        try:
            dfs = []
            start_time = HdfBase._get_simulation_start_time(hdf_file)
            
            logger.info(f"Processing summary output for variable: {var}")
            for mesh_name, cell_count in HdfBase._get_2d_flow_area_names_and_counts(hdf_file):
                logger.debug(f"Processing mesh: {mesh_name} with {cell_count} cells")
                group = HdfResultsMesh._get_mesh_summary_output_group(hdf_file, mesh_name, var)
                
                data = group[:]
                logger.debug(f"Data shape for {var} in {mesh_name}: {data.shape}")
                logger.debug(f"Data type: {data.dtype}")
                logger.debug(f"Attributes: {dict(group.attrs)}")
                
                if data.ndim == 2 and data.shape[0] == 2:
                    # This is the case for "Maximum Water Surface"
                    row_variables = group.attrs.get('Row Variables', [b'Value', b'Time'])
                    row_variables = [v.decode('utf-8').strip() for v in row_variables]
                    
                    df = pd.DataFrame({
                        "mesh_name": [mesh_name] * data.shape[1],
                        "cell_id": range(data.shape[1]),
                        f"{var.lower().replace(' ', '_')}": data[0, :],
                        f"{var.lower().replace(' ', '_')}_time": HdfUtils._ras_timesteps_to_datetimes(
                            data[1, :], start_time, time_unit="days", round_to=round_to
                        )
                    })
                elif data.ndim == 1:
                    # Handle 1D datasets (like Cell Last Iteration)
                    df = pd.DataFrame({
                        "mesh_name": [mesh_name] * len(data),
                        "cell_id": range(len(data)),
                        var.lower().replace(' ', '_'): data
                    })
                else:
                    raise ValueError(f"Unexpected data shape for {var} in {mesh_name}. "
                                     f"Got shape {data.shape}")
                
                # Add group attributes as metadata
                df.attrs['mesh_name'] = mesh_name
                for attr_name, attr_value in group.attrs.items():
                    if isinstance(attr_value, bytes):
                        attr_value = attr_value.decode('utf-8')
                    elif isinstance(attr_value, np.ndarray):
                        attr_value = attr_value.tolist()
                    df.attrs[attr_name] = attr_value
                
                dfs.append(df)
            
            result = pd.concat(dfs, ignore_index=True)
            
            # Combine attributes from all meshes
            combined_attrs = {}
            for df in dfs:
                for key, value in df.attrs.items():
                    if key not in combined_attrs:
                        combined_attrs[key] = value
                    elif combined_attrs[key] != value:
                        combined_attrs[key] = f"Multiple values: {combined_attrs[key]}, {value}"
            
            result.attrs.update(combined_attrs)
            
            logger.info(f"Processed {len(result)} rows of summary output data")
            return result
        
        except (KeyError, ValueError, AttributeError) as e:
            logger.error(f"Error processing summary output data: {e}")
            raise ValueError(f"Error processing summary output data: {e}")
        

    @staticmethod
    def _get_mesh_summary_output_group(hdf_file: h5py.File, mesh_name: str, var: str) -> Union[h5py.Group, h5py.Dataset]:
        """
        Return the HDF group for a given mesh and summary output variable.

        Args:
            hdf_file (h5py.File): Open HDF file object.
            mesh_name (str): Name of the mesh.
            var (str): Name of the summary output variable.

        Returns:
            Union[h5py.Group, h5py.Dataset]: The HDF group or dataset for the specified mesh and variable.

        Raises:
            ValueError: If the specified group or dataset is not found in the HDF file.
        """
        output_path = f"Results/Unsteady/Output/Output Blocks/Base Output/Summary Output/2D Flow Areas/{mesh_name}/{var}"
        output_item = hdf_file.get(output_path)
        if output_item is None:
            raise ValueError(f"Could not find HDF group or dataset at path '{output_path}'")
        return output_item

==================================================

File: c:\GH\ras-commander\ras_commander\HdfResultsPlan.py
==================================================
"""
Class: HdfResultsPlan

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""

from typing import Dict, List, Union, Optional
from pathlib import Path
import h5py
import pandas as pd
import xarray as xr
from .Decorators import standardize_input, log_call
from .HdfBase import HdfBase
from .HdfResultsXsec import HdfResultsXsec
from .LoggingConfig import get_logger
import numpy as np
from datetime import datetime

logger = get_logger(__name__)


class HdfResultsPlan:
    """
    A class for handling HEC-RAS plan HDF file results related to unsteady flow and reference line/point outputs.

    This class provides methods for extracting and analyzing data from HEC-RAS plan HDF files,
    focusing on unsteady flow results, volume accounting, and reference line/point time series outputs.

    Methods in this class use the @standardize_input decorator to handle different input types
    (e.g., plan number, file path) and the @log_call decorator for logging method calls.

    Attributes:
        None

    Note:
        This class is designed to work with HEC-RAS plan HDF files and requires the HdfBase class
        for some of its operations.
    """

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_results_unsteady_attrs(hdf_path: Path) -> Dict:
        """
        Get unsteady attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the unsteady attributes.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
            KeyError: If the "Results/Unsteady" group is not found in the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if "Results/Unsteady" not in hdf_file:
                    raise KeyError("Results/Unsteady group not found in the HDF file.")
                return dict(hdf_file["Results/Unsteady"].attrs)
        except FileNotFoundError:
            raise FileNotFoundError(f"HDF file not found: {hdf_path}")
        except Exception as e:
            raise RuntimeError(f"Error reading unsteady attributes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_results_unsteady_summary_attrs(hdf_path: Path) -> Dict:
        """
        Get results unsteady summary attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the results unsteady summary attributes.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
            KeyError: If the "Results/Unsteady/Summary" group is not found in the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if "Results/Unsteady/Summary" not in hdf_file:
                    raise KeyError("Results/Unsteady/Summary group not found in the HDF file.")
                return dict(hdf_file["Results/Unsteady/Summary"].attrs)
        except FileNotFoundError:
            raise FileNotFoundError(f"HDF file not found: {hdf_path}")
        except Exception as e:
            raise RuntimeError(f"Error reading unsteady summary attributes: {str(e)}")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def get_results_volume_accounting_attrs(hdf_path: Path) -> Dict:
        """
        Get volume accounting attributes from a HEC-RAS HDF plan file.

        Args:
            hdf_path (Path): Path to the HEC-RAS plan HDF file.

        Returns:
            Dict: A dictionary containing the volume accounting attributes.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
            KeyError: If the "Results/Unsteady/Summary/Volume Accounting" group is not found in the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if "Results/Unsteady/Summary/Volume Accounting" not in hdf_file:
                    raise KeyError("Results/Unsteady/Summary/Volume Accounting group not found in the HDF file.")
                return dict(hdf_file["Results/Unsteady/Summary/Volume Accounting"].attrs)
        except FileNotFoundError:
            raise FileNotFoundError(f"HDF file not found: {hdf_path}")
        except Exception as e:
            raise RuntimeError(f"Error reading volume accounting attributes: {str(e)}")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_runtime_data(hdf_path: Path) -> Optional[pd.DataFrame]:
        """
        Extract runtime and compute time data from a single HDF file.

        Args:
            hdf_path (Path): The full path to the HDF file.

        Returns:
            Optional[pd.DataFrame]: DataFrame containing runtime and compute time data, or None if data extraction fails.
        """
        if hdf_path is None:
            logger.error(f"Could not find HDF file for input")
            return None

        with h5py.File(hdf_path, 'r') as hdf_file:
            logger.info(f"Extracting Plan Information from: {Path(hdf_file.filename).name}")
            plan_info = hdf_file.get('/Plan Data/Plan Information')
            if plan_info is None:
                logger.warning("Group '/Plan Data/Plan Information' not found.")
                return None

            plan_name = plan_info.attrs.get('Plan Name', 'Unknown')
            plan_name = plan_name.decode('utf-8') if isinstance(plan_name, bytes) else plan_name
            logger.info(f"Plan Name: {plan_name}")

            start_time_str = plan_info.attrs.get('Simulation Start Time', 'Unknown')
            end_time_str = plan_info.attrs.get('Simulation End Time', 'Unknown')
            start_time_str = start_time_str.decode('utf-8') if isinstance(start_time_str, bytes) else start_time_str
            end_time_str = end_time_str.decode('utf-8') if isinstance(end_time_str, bytes) else end_time_str

            start_time = datetime.strptime(start_time_str, "%d%b%Y %H:%M:%S")
            end_time = datetime.strptime(end_time_str, "%d%b%Y %H:%M:%S")
            simulation_duration = end_time - start_time
            simulation_hours = simulation_duration.total_seconds() / 3600

            logger.info(f"Simulation Start Time: {start_time_str}")
            logger.info(f"Simulation End Time: {end_time_str}")
            logger.info(f"Simulation Duration (hours): {simulation_hours}")

            compute_processes = hdf_file.get('/Results/Summary/Compute Processes')
            if compute_processes is None:
                logger.warning("Dataset '/Results/Summary/Compute Processes' not found.")
                return None

            process_names = [name.decode('utf-8') for name in compute_processes['Process'][:]]
            filenames = [filename.decode('utf-8') for filename in compute_processes['Filename'][:]]
            completion_times = compute_processes['Compute Time (ms)'][:]

            compute_processes_df = pd.DataFrame({
                'Process': process_names,
                'Filename': filenames,
                'Compute Time (ms)': completion_times,
                'Compute Time (s)': completion_times / 1000,
                'Compute Time (hours)': completion_times / (1000 * 3600)
            })

            logger.debug("Compute processes DataFrame:")
            logger.debug(compute_processes_df)

            compute_processes_summary = {
                'Plan Name': [plan_name],
                'File Name': [Path(hdf_file.filename).name],
                'Simulation Start Time': [start_time_str],
                'Simulation End Time': [end_time_str],
                'Simulation Duration (s)': [simulation_duration.total_seconds()],
                'Simulation Time (hr)': [simulation_hours],
                'Completing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Geometry']['Compute Time (hours)'].values[0] if 'Completing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Preprocessing Geometry (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Preprocessing Geometry']['Compute Time (hours)'].values[0] if 'Preprocessing Geometry' in compute_processes_df['Process'].values else 'N/A'],
                'Completing Event Conditions (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Completing Event Conditions']['Compute Time (hours)'].values[0] if 'Completing Event Conditions' in compute_processes_df['Process'].values else 'N/A'],
                'Unsteady Flow Computations (hr)': [compute_processes_df[compute_processes_df['Process'] == 'Unsteady Flow Computations']['Compute Time (hours)'].values[0] if 'Unsteady Flow Computations' in compute_processes_df['Process'].values else 'N/A'],
                'Complete Process (hr)': [compute_processes_df['Compute Time (hours)'].sum()]
            }

            compute_processes_summary['Unsteady Flow Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Unsteady Flow Computations (hr)'][0] if compute_processes_summary['Unsteady Flow Computations (hr)'][0] != 'N/A' else 'N/A']
            compute_processes_summary['Complete Process Speed (hr/hr)'] = [simulation_hours / compute_processes_summary['Complete Process (hr)'][0] if compute_processes_summary['Complete Process (hr)'][0] != 'N/A' else 'N/A']

            compute_summary_df = pd.DataFrame(compute_processes_summary)
            logger.debug("Compute summary DataFrame:")
            logger.debug(compute_summary_df)

            return compute_summary_df



    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def reference_timeseries_output(hdf_path: Path, reftype: str = "lines") -> xr.Dataset:
        """
        Get timeseries output for reference lines or points.

        Args:
            hdf_path (Path): Path to the HDF file.
            reftype (str): Type of reference, either "lines" or "points" (default "lines").

        Returns:
            xr.Dataset: Dataset containing the timeseries output for reference lines or points.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
            ValueError: If an invalid reftype is provided.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                return HdfResultsPlan._reference_timeseries_output(hdf_file, reftype)
        except FileNotFoundError:
            raise FileNotFoundError(f"HDF file not found: {hdf_path}")
        except ValueError as ve:
            raise ValueError(f"Invalid reftype: {str(ve)}")
        except Exception as e:
            raise RuntimeError(f"Error getting reference timeseries output: {str(e)}")


    @staticmethod
    def _reference_timeseries_output(hdf_file: h5py.File, reftype: str = "lines") -> xr.Dataset:
        """
        Private method to return timeseries output data for reference lines or points from a HEC-RAS HDF plan file.

        Parameters
        ----------
        hdf_file : h5py.File
            Open HDF file object.
        reftype : str, optional
            The type of reference data to retrieve. Must be either "lines" or "points".
            (default: "lines")

        Returns
        -------
        xr.Dataset
            An xarray Dataset with reference line or point timeseries data.
            Returns an empty Dataset if the reference output data is not found.

        Raises
        ------
        ValueError
            If reftype is not "lines" or "points".
        """
        if reftype == "lines":
            output_path = "Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Lines"
            abbrev = "refln"
        elif reftype == "points":
            output_path = "Results/Unsteady/Output/Output Blocks/Base Output/Unsteady Time Series/Reference Points"
            abbrev = "refpt"
        else:
            raise ValueError('reftype must be either "lines" or "points".')

        try:
            reference_group = hdf_file[output_path]
        except KeyError:
            logger.error(f"Could not find HDF group at path '{output_path}'. "
                         f"The Plan HDF file may not contain reference {reftype[:-1]} output data.")
            return xr.Dataset()

        reference_names = reference_group["Name"][:]
        names = []
        mesh_areas = []
        for s in reference_names:
            name, mesh_area = s.decode("utf-8").split("|")
            names.append(name)
            mesh_areas.append(mesh_area)

        times = HdfBase._get_unsteady_datetimes(hdf_file)

        das = {}
        for var in ["Flow", "Velocity", "Water Surface"]:
            group = reference_group.get(var)
            if group is None:
                continue
            values = group[:]
            units = group.attrs["Units"].decode("utf-8")
            da = xr.DataArray(
                values,
                name=var,
                dims=["time", f"{abbrev}_id"],
                coords={
                    "time": times,
                    f"{abbrev}_id": range(values.shape[1]),
                    f"{abbrev}_name": (f"{abbrev}_id", names),
                    "mesh_name": (f"{abbrev}_id", mesh_areas),
                },
                attrs={"units": units, "hdf_path": f"{output_path}/{var}"},
            )
            das[var] = da
        return xr.Dataset(das)

        


    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def reference_lines_timeseries_output(hdf_path: Path) -> xr.Dataset:
        """
        Get timeseries output for reference lines.

        Args:
            hdf_path (Path): Path to the HDF file.

        Returns:
            xr.Dataset: Dataset containing the timeseries output for reference lines.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
        """
        return HdfResultsPlan.reference_timeseries_output(hdf_path, reftype="lines")

    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def reference_points_timeseries_output(hdf_path: Path) -> xr.Dataset:
        """
        Get timeseries output for reference points.

        Args:
            hdf_path (Path): Path to the HDF file.

        Returns:
            xr.Dataset: Dataset containing the timeseries output for reference points.

        Raises:
            FileNotFoundError: If the specified HDF file is not found.
        """
        return HdfResultsPlan.reference_timeseries_output(hdf_path, reftype="points")
    
    @staticmethod
    @log_call
    @standardize_input(file_type='plan_hdf')
    def reference_summary_output(hdf_path: Path, reftype: str = "lines") -> pd.DataFrame:
        """
        Get summary output for reference lines or points.

        Args:
            hdf_path (Path): Path to the HDF file.
            reftype (str): Type of reference, either "lines" or "points" (default "lines").

        Returns:
            pd.DataFrame: DataFrame containing the summary output for reference lines or points.

        Raises:
            ValueError: If an invalid reftype is provided.
        """
        if not hdf_path.exists():
            logger.error(f"HDF file not found: {hdf_path}")
            return pd.DataFrame()  # Return an empty DataFrame if the path doesn't exist

        try:
            # Get the timeseries output
            ds = HdfResultsPlan.reference_timeseries_output(hdf_path, reftype)
            
            if 'station' not in ds.dims:
                logger.error("No 'station' dimension found in the dataset.")
                return pd.DataFrame()  # Return an empty DataFrame if 'station' dimension is missing
            
            # Calculate summary statistics
            summary = ds.groupby('station').agg({
                'WSE': ['min', 'max', 'mean'],
                'Q': ['min', 'max', 'mean']
            })
            
            # Flatten column names
            summary.columns = ['_'.join(col).strip() for col in summary.columns.values]
            
            # Reset index to make 'station' a column
            summary = summary.reset_index()
            
            return summary
        except ValueError as ve:
            logger.error(f"Invalid reftype: {str(ve)}")
            return pd.DataFrame()  # Return an empty DataFrame on ValueError
        except Exception as e:
            logger.error(f"Error in reference_summary_output: {str(e)}")
            return pd.DataFrame()  # Return an empty DataFrame on general error

==================================================

File: c:\GH\ras-commander\ras_commander\HdfResultsXsec.py
==================================================
"""
Class: HdfResultsXsec

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""

import h5py
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Union, Optional, List
from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger
import xarray as xr

logger = get_logger(__name__)


class HdfResultsXsec:
    """
    A class for handling cross-section results from HEC-RAS HDF files.

    This class provides methods to extract and process steady flow simulation results
    for cross-sections, including water surface elevations, flow rates, energy grades,
    and additional parameters such as encroachment stations and velocities.

    The class relies on the HdfBase and HdfUtils classes for core HDF file operations
    and utility functions.

    Attributes:
        None

    Methods:
        steady_profile_xs_output: Extract steady profile cross-section output for a specified variable.
        cross_sections_wsel: Get water surface elevation data for cross-sections.
        cross_sections_flow: Get flow data for cross-sections.
        cross_sections_energy_grade: Get energy grade data for cross-sections.
        cross_sections_additional_enc_station_left: Get left encroachment station data for cross-sections.
        cross_sections_additional_enc_station_right: Get right encroachment station data for cross-sections.
        cross_sections_additional_area_total: Get total ineffective area data for cross-sections.
        cross_sections_additional_velocity_total: Get total velocity data for cross-sections.
    """

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def steady_profile_xs_output(hdf_path: Path, var: str, round_to: int = 2) -> pd.DataFrame:
        """
        Create a DataFrame from steady cross section results based on the specified variable.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.
        var : str
            The variable to extract from the steady cross section results.
        round_to : int, optional
            Number of decimal places to round the results to (default is 2).

        Returns:
        -------
        pd.DataFrame
            DataFrame containing the steady cross section results for the specified variable.
        """
        XS_STEADY_OUTPUT_ADDITIONAL = [
            "Additional Encroachment Station Left",
            "Additional Encroachment Station Right",
            "Additional Area Ineffective Total",
            "Additional Velocity Total",
        ]
                
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                # Determine the correct path based on the variable
                if var in XS_STEADY_OUTPUT_ADDITIONAL:
                    path = f"/Results/Steady/Cross Sections/Additional Output/{var}"
                else:
                    path = f"/Results/Steady/Cross Sections/{var}"
                
                # Check if the path exists in the HDF file
                if path not in hdf_file:
                    return pd.DataFrame()

                # Get the profile names
                profiles = HdfBase.steady_flow_names(hdf_path)
                
                # Extract the steady data
                steady_data = hdf_file[path]
                
                # Create a DataFrame with profiles as index
                df = pd.DataFrame(steady_data, index=profiles)
                
                # Transpose the DataFrame and round values
                df_t = df.T.copy()
                for p in profiles:
                    df_t[p] = df_t[p].apply(lambda x: round(x, round_to))

                return df_t
        except Exception as e:
            HdfUtils.logger.error(f"Failed to get steady profile cross section output: {str(e)}")
            return pd.DataFrame()

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_wsel(hdf_path: Path) -> pd.DataFrame:
        """
        Return the water surface elevation information for each 1D Cross Section.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the water surface elevations for each cross section and event.
        """
        return HdfResultsXsec.steady_profile_xs_output(hdf_path, "Water Surface")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_flow(hdf_path: Path) -> pd.DataFrame:
        """
        Return the Flow information for each 1D Cross Section.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the flow for each cross section and event.
        """
        return HdfResultsXsec.steady_profile_xs_output(hdf_path, "Flow")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_energy_grade(hdf_path: Path) -> pd.DataFrame:
        """
        Return the energy grade information for each 1D Cross Section.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the energy grade for each cross section and event.
        """
        return HdfResultsXsec.steady_profile_xs_output(hdf_path, "Energy Grade")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_additional_enc_station_left(hdf_path: Path) -> pd.DataFrame:
        """
        Return the left side encroachment information for a floodway plan hdf.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the cross sections left side encroachment stations.
        """
        return HdfResultsXsec.steady_profile_xs_output(
            hdf_path, "Encroachment Station Left"
        )

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_additional_enc_station_right(hdf_path: Path) -> pd.DataFrame:
        """
        Return the right side encroachment information for a floodway plan hdf.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the cross sections right side encroachment stations.
        """
        return HdfResultsXsec.steady_profile_xs_output(
            hdf_path, "Encroachment Station Right"
        )

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_additional_area_total(hdf_path: Path) -> pd.DataFrame:
        """
        Return the 1D cross section area for each profile.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the wet area inside the cross sections.
        """
        return HdfResultsXsec.steady_profile_xs_output(hdf_path, "Area Ineffective Total")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def cross_sections_additional_velocity_total(hdf_path: Path) -> pd.DataFrame:
        """
        Return the 1D cross section velocity for each profile.

        Parameters:
        ----------
        hdf_path : Path
            Path to the HEC-RAS plan HDF file.

        Returns:
        -------
        pd.DataFrame
            A DataFrame containing the velocity inside the cross sections.
        """
        return HdfResultsXsec.steady_profile_xs_output(hdf_path, "Velocity Total")


==================================================

File: c:\GH\ras-commander\ras_commander\HdfStruc.py
==================================================
"""
Class: HdfStruc

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""
from typing import Dict, Any, List, Union
from pathlib import Path
import h5py
import numpy as np
import pandas as pd
from geopandas import GeoDataFrame
from shapely.geometry import LineString, MultiLineString, Polygon, MultiPolygon, Point, GeometryCollection
from .HdfUtils import HdfUtils
from .HdfXsec import HdfXsec
from .HdfBase import HdfBase
from .Decorators import standardize_input, log_call
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)

class HdfStruc:
    """
    HEC-RAS HDF Structures class for handling operations related to structures in HDF files.

    This class provides methods for extracting and analyzing data about structures
    from HEC-RAS HDF files. It includes functionality to retrieve structure geometries
    and attributes.

    Methods in this class use the @standardize_input decorator to handle different
    input types (file path, etc.) and the @log_call decorator for logging method calls.

    Attributes:
        GEOM_STRUCTURES_PATH (str): Constant for the HDF path to structures data.

    Note: This class contains static methods and does not require instantiation.
    """

    GEOM_STRUCTURES_PATH = "Geometry/Structures"

    @staticmethod
    @log_call
    @standardize_input(file_type='geom_hdf')
    def structures(hdf_path: Path, datetime_to_str: bool = False) -> GeoDataFrame:
        """
        Return the model structures.

        This method extracts structure data from the HDF file, including geometry
        and attributes, and returns it as a GeoDataFrame.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        datetime_to_str : bool, optional
            If True, convert datetime objects to strings. Default is False.

        Returns
        -------
        GeoDataFrame
            A GeoDataFrame containing the structures, with columns for attributes
            and geometry.

        Raises
        ------
        Exception
            If there's an error reading the structures data from the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                # Check if the structures path exists in the HDF file
                if HdfStruc.GEOM_STRUCTURES_PATH not in hdf_file:
                    logger.info(f"No structures found in the geometry file: {hdf_path}")
                    return GeoDataFrame()
                
                struct_data = hdf_file[HdfStruc.GEOM_STRUCTURES_PATH]
                v_conv_val = np.vectorize(HdfUtils._convert_ras_hdf_value)
                sd_attrs = struct_data["Attributes"][()]
                
                # Create a dictionary to store structure data
                struct_dict = {"struct_id": range(sd_attrs.shape[0])}
                struct_dict.update(
                    {name: v_conv_val(sd_attrs[name]) for name in sd_attrs.dtype.names}
                )
                
                # Get structure geometries
                geoms = HdfXsec._get_polylines(
                    hdf_path,
                    HdfStruc.GEOM_STRUCTURES_PATH,
                    info_name="Centerline Info",
                    parts_name="Centerline Parts",
                    points_name="Centerline Points"
                )
                
                # Create GeoDataFrame
                struct_gdf = GeoDataFrame(
                    struct_dict,
                    geometry=geoms,
                    crs=HdfUtils.projection(hdf_path),
                )
                
                # Convert datetime to string if requested
                if datetime_to_str:
                    struct_gdf["Last Edited"] = struct_gdf["Last Edited"].apply(
                        lambda x: pd.Timestamp.isoformat(x) if pd.notnull(x) else None
                    )
                
                return struct_gdf
        except Exception as e:
            logger.error(f"Error reading structures: {str(e)}")
            raise

    @staticmethod
    @log_call
    @standardize_input(file_type='geom_hdf')
    def get_geom_structures_attrs(hdf_path: Path) -> Dict[str, Any]:
        """
        Return geometry structures attributes from a HEC-RAS HDF file.

        This method extracts attributes related to geometry structures from the HDF file.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.

        Returns
        -------
        Dict[str, Any]
            A dictionary containing the geometry structures attributes.

        Notes
        -----
        If no structures are found in the geometry file, an empty dictionary is returned.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if HdfStruc.GEOM_STRUCTURES_PATH not in hdf_file:
                    logger.info(f"No structures found in the geometry file: {hdf_path}")
                    return {}
                return HdfUtils.get_attrs(hdf_file, HdfStruc.GEOM_STRUCTURES_PATH)
        except Exception as e:
            logger.error(f"Error reading geometry structures attributes: {str(e)}")
            return {}

==================================================

File: c:\GH\ras-commander\ras_commander\HdfUtils.py
==================================================
"""
Class: HdfUtils

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""
import logging
from pathlib import Path
import h5py
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Union, Optional, Dict, List, Tuple, Any
from scipy.spatial import KDTree
import re

from .Decorators import standardize_input, log_call 
from .LoggingConfig import setup_logging, get_logger

logger = get_logger(__name__)

class HdfUtils:
    """
    Utility class for working with HEC-RAS HDF files.

    This class provides general utility functions for HDF file operations,
    including attribute extraction, data conversion, and common HDF queries.
    It also includes spatial operations and helper methods for working with
    HEC-RAS specific data structures.

    Note:
    - Use this class for general HDF utility functions that are not specific to plan or geometry files.
    - All methods in this class are static and can be called without instantiating the class.
    """

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_hdf_filename(hdf_input: Union[str, Path, h5py.File], ras_object=None) -> Optional[Path]:
        """
        Get the HDF filename from various input types.

        Args:
            hdf_input (Union[str, Path, h5py.File]): The plan number, full path to the HDF file, or an open HDF file object.
            ras_object (RasPrj, optional): The RAS project object. If None, uses the global ras instance.

        Returns:
            Optional[Path]: Path to the HDF file, or None if not found.
        """
        if isinstance(hdf_input, h5py.File):
            return Path(hdf_input.filename)

        if isinstance(hdf_input, str):
            hdf_input = Path(hdf_input)

        if isinstance(hdf_input, Path) and hdf_input.is_file():
            return hdf_input

        if ras_object is None:
            logger.critical("RAS object is not provided. It is required when hdf_input is not a direct file path.")
            return None

        plan_info = ras_object.plan_df[ras_object.plan_df['plan_number'] == str(hdf_input)]
        if plan_info.empty:
            logger.critical(f"No HDF file found for plan number {hdf_input}")
            return None

        hdf_filename = plan_info.iloc[0]['HDF_Results_Path']
        if hdf_filename is None:
            logger.critical(f"HDF_Results_Path is None for plan number {hdf_input}")
            return None

        hdf_path = Path(hdf_filename)
        if not hdf_path.is_file():
            logger.critical(f"HDF file not found: {hdf_path}")
            return None

        return hdf_path

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_root_attrs(hdf_path: Path) -> dict:
        """
        Return attributes at root level of HEC-RAS HDF file.

        Args:
            hdf_path (Path): Path to the HDF file.

        Returns:
            dict: Dictionary filled with HEC-RAS HDF root attributes.
        """
        with h5py.File(hdf_path, 'r') as hdf_file:
            return HdfUtils.get_attrs(hdf_file, "/")

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_attrs(hdf_path: Path, attr_path: str) -> dict:
        """
        Get attributes from a HEC-RAS HDF file for a given attribute path.

        Args:
            hdf_path (Path): The path to the HDF file.
            attr_path (str): The path to the attributes within the HDF file.

        Returns:
            dict: A dictionary of attributes.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                attr_object = hdf_file.get(attr_path)
                if attr_object is None:
                    logger.warning(f"Attribute path '{attr_path}' not found in HDF file.")
                    return {}
                return HdfUtils._hdf5_attrs_to_dict(attr_object.attrs)
        except Exception as e:
            logger.error(f"Error getting attributes from '{attr_path}': {str(e)}")
            return {}

    @staticmethod
    @standardize_input(file_type='plan_hdf')
    def get_hdf_paths_with_properties(hdf_path: Path) -> pd.DataFrame:
        """
        Get all paths in the HDF file with their properties.

        Args:
            hdf_path (Path): Path to the HDF file.

        Returns:
            pd.DataFrame: DataFrame containing paths and their properties.
        """
        def get_item_properties:
    """Docs only, see 'get_item_properties.py' for full function code"""

==================================================

File: c:\GH\ras-commander\ras_commander\HdfXsec.py
==================================================
"""
Class: HdfXsec

Attribution: A substantial amount of code in this file is sourced or derived 
from the https://github.com/fema-ffrd/rashdf library, 
released under MIT license and Copyright (c) 2024 fema-ffrd

The file has been forked and modified for use in RAS Commander.
"""

from pathlib import Path
import h5py
import numpy as np
import pandas as pd
from geopandas import GeoDataFrame
from shapely.geometry import LineString, MultiLineString
from typing import List  # Import List to avoid NameError
from .Decorators import standardize_input, log_call
from .HdfBase import HdfBase
from .HdfUtils import HdfUtils
from .LoggingConfig import get_logger

logger = get_logger(__name__)

class HdfXsec:
    """
    HdfXsec class for handling cross-section related operations on HEC-RAS HDF files.

    This class provides methods to extract and process cross-section data, elevation information,
    and river reach data from HEC-RAS HDF geometry files. It includes functionality to retrieve
    cross-section attributes, elevation profiles, and river reach geometries.

    The class uses static methods, allowing for direct calls without instantiation. It relies on
    utility functions from HdfBase and HdfUtils classes for various operations such as projection
    handling and data conversion.

    Note:
        This class is designed to work with HEC-RAS geometry HDF files and requires them to have
        a specific structure and naming convention for the data groups and attributes.
    """

    @staticmethod
    @log_call
    @standardize_input(file_type='geom_hdf')
    def cross_sections(hdf_path: Path, datetime_to_str: bool = False) -> GeoDataFrame:
        """
        Return the model 1D cross sections.

        This method extracts cross-section data from the HEC-RAS geometry HDF file,
        including attributes and geometry information.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        datetime_to_str : bool, optional
            If True, convert datetime objects to strings. Default is False.

        Returns
        -------
        GeoDataFrame
            A GeoDataFrame containing the cross sections with their attributes and geometries.

        Raises
        ------
        KeyError
            If the required datasets are not found in the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                xs_data = hdf_file["Geometry/Cross Sections"]
                
                if "Attributes" not in xs_data:
                    logger.warning(f"No 'Attributes' dataset group in {hdf_path}")
                    return GeoDataFrame()

                # Convert attribute values
                v_conv_val = np.vectorize(HdfUtils._convert_ras_hdf_value)
                xs_attrs = xs_data["Attributes"][()]
                xs_dict = {"xs_id": range(xs_attrs.shape[0])}
                xs_dict.update(
                    {name: v_conv_val(xs_attrs[name]) for name in xs_attrs.dtype.names}
                )

                xs_df = pd.DataFrame(xs_dict)
                
                # Create geometry from coordinate pairs
                xs_df['geometry'] = xs_df.apply(lambda row: LineString([
                    (row['XS_X_Coord_1'], row['XS_Y_Coord_1']),
                    (row['XS_X_Coord_2'], row['XS_Y_Coord_2'])
                ]), axis=1)
                
                # Convert to GeoDataFrame
                gdf = GeoDataFrame(xs_df, geometry='geometry', crs=HdfUtils.projection(hdf_path))
                
                # Convert datetime columns to strings if requested
                if datetime_to_str:
                    gdf = HdfUtils.df_datetimes_to_str(gdf)
                
                return gdf

        except KeyError as e:
            logger.error(f"Error accessing cross-section data in {hdf_path}: {str(e)}")
            return GeoDataFrame()

    @staticmethod
    @log_call
    @standardize_input(file_type='geom_hdf')
    def cross_sections_elevations(hdf_path: Path, round_to: int = 2) -> pd.DataFrame:
        """
        Return the model cross section elevation information.

        This method extracts cross-section elevation data from the HEC-RAS geometry HDF file,
        including station-elevation pairs for each cross-section.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        round_to : int, optional
            Number of decimal places to round to. Default is 2.

        Returns
        -------
        pd.DataFrame
            A DataFrame containing the cross section elevation information.

        Raises
        ------
        KeyError
            If the required datasets are not found in the HDF file.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                path = "/Geometry/Cross Sections"
                if path not in hdf_file:
                    logger.warning(f"No 'Cross Sections' group found in {hdf_path}")
                    return pd.DataFrame()

                xselev_data = hdf_file[path]
                
                if "Station Elevation Info" not in xselev_data or "Station Elevation Values" not in xselev_data:
                    logger.warning(f"Required datasets not found in Cross Sections group in {hdf_path}")
                    return pd.DataFrame()

                # Get cross-section data
                xs_df = HdfXsec.cross_sections(hdf_path)
                if xs_df.empty:
                    return pd.DataFrame()

                # Extract elevation data
                elevations = []
                for part_start, part_cnt in xselev_data["Station Elevation Info"][()]:
                    xzdata = xselev_data["Station Elevation Values"][()][
                        part_start : part_start + part_cnt
                    ]
                    elevations.append(xzdata)

                # Create DataFrame with elevation info
                xs_elev_df = xs_df[
                    ["xs_id", "River", "Reach", "RS", "Left Bank", "Right Bank"]
                ].copy()
                xs_elev_df["Left Bank"] = xs_elev_df["Left Bank"].round(round_to).astype(str)
                xs_elev_df["Right Bank"] = xs_elev_df["Right Bank"].round(round_to).astype(str)
                xs_elev_df["elevation info"] = elevations

                return xs_elev_df

        except KeyError as e:
            logger.error(f"Error accessing cross-section elevation data in {hdf_path}: {str(e)}")
            return pd.DataFrame()
        except Exception as e:
            logger.error(f"Unexpected error in cross_sections_elevations: {str(e)}")
            return pd.DataFrame()

    @staticmethod
    @log_call
    @standardize_input(file_type='geom_hdf')
    def river_reaches(hdf_path: Path, datetime_to_str: bool = False) -> GeoDataFrame:
        """
        Return the model 1D river reach lines.

        This method extracts river reach data from the HEC-RAS geometry HDF file,
        including attributes and geometry information.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        datetime_to_str : bool, optional
            If True, convert datetime objects to strings. Default is False.

        Returns
        -------
        GeoDataFrame
            A GeoDataFrame containing the river reaches with their attributes and geometries.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                if "Geometry/River Centerlines" not in hdf_file:
                    return GeoDataFrame()

                river_data = hdf_file["Geometry/River Centerlines"]
                v_conv_val = np.vectorize(HdfUtils._convert_ras_hdf_value)
                river_attrs = river_data["Attributes"][()]
                river_dict = {"river_id": range(river_attrs.shape[0])}
                river_dict.update(
                    {name: v_conv_val(river_attrs[name]) for name in river_attrs.dtype.names}
                )
                
                # Get polylines for river reaches
                geoms = HdfXsec._get_polylines(hdf_path, "Geometry/River Centerlines")
                
                river_gdf = GeoDataFrame(
                    river_dict,
                    geometry=geoms,
                    crs=HdfUtils.projection(hdf_path),
                )
                if datetime_to_str:
                    river_gdf["Last Edited"] = river_gdf["Last Edited"].apply(
                        lambda x: pd.Timestamp.isoformat(x)
                    )
                return river_gdf
        except Exception as e:
            logger.error(f"Error reading river reaches: {str(e)}")
            return GeoDataFrame()

    @staticmethod
    def _get_polylines(hdf_path: Path, path: str, info_name: str = "Polyline Info", parts_name: str = "Polyline Parts", points_name: str = "Polyline Points") -> List[LineString]:
        """
        Helper method to extract polylines from HDF file.

        This method is used internally to extract polyline geometries for various features
        such as river reaches.

        Parameters
        ----------
        hdf_path : Path
            Path to the HEC-RAS geometry HDF file.
        path : str
            Path within the HDF file to the polyline data.
        info_name : str, optional
            Name of the dataset containing polyline info. Default is "Polyline Info".
        parts_name : str, optional
            Name of the dataset containing polyline parts. Default is "Polyline Parts".
        points_name : str, optional
            Name of the dataset containing polyline points. Default is "Polyline Points".

        Returns
        -------
        List[LineString]
            A list of LineString geometries representing the polylines.
        """
        try:
            with h5py.File(hdf_path, 'r') as hdf_file:
                polyline_info_path = f"{path}/{info_name}"
                polyline_parts_path = f"{path}/{parts_name}"
                polyline_points_path = f"{path}/{points_name}"

                polyline_info = hdf_file[polyline_info_path][()]
                polyline_parts = hdf_file[polyline_parts_path][()]
                polyline_points = hdf_file[polyline_points_path][()]

                geoms = []
                for pnt_start, pnt_cnt, part_start, part_cnt in polyline_info:
                    points = polyline_points[pnt_start : pnt_start + pnt_cnt]
                    if part_cnt == 1:
                        geoms.append(LineString(points))
                    else:
                        parts = polyline_parts[part_start : part_start + part_cnt]
                        geoms.append(
                            MultiLineString(
                                list(
                                    points[part_pnt_start : part_pnt_start + part_pnt_cnt]
                                    for part_pnt_start, part_pnt_cnt in parts
                                )
                            )
                        )
                return geoms
        except Exception as e:
            logger.error(f"Error getting polylines: {str(e)}")
            return []

==================================================

File: c:\GH\ras-commander\ras_commander\LoggingConfig.py
==================================================
# logging_config.py

import logging
import logging.handlers
from pathlib import Path
import functools

# Define log levels
DEBUG = logging.DEBUG
INFO = logging.INFO
WARNING = logging.WARNING
ERROR = logging.ERROR
CRITICAL = logging.CRITICAL


_logging_setup_done = False

def setup_logging:
    """Docs only, see 'setup_logging.py' for full function code"""
setup_logging()
==================================================

File: c:\GH\ras-commander\ras_commander\RasCmdr.py
==================================================
"""
RasCmdr - Execution operations for running HEC-RAS simulations

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).

Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
import subprocess
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from .RasPrj import ras, RasPrj, init_ras_project, get_ras_exe
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUtils import RasUtils
import logging
import time
import queue
from threading import Thread, Lock
from typing import Union, List, Optional, Dict
from pathlib import Path
import shutil
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Thread
from itertools import cycle
from ras_commander.RasPrj import RasPrj  # Ensure RasPrj is imported
from threading import Lock, Thread, current_thread
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import cycle
from typing import Union, List, Optional, Dict
from .LoggingConfig import get_logger
from .Decorators import log_call

logger = get_logger(__name__)

# Module code starts here

# TODO: Future Enhancements
# 1. Alternate Run Mode for compute_plan and compute_parallel:
#    - Use Powershell to execute HEC-RAS command
#    - Hide RAS window and all child windows
#    - Note: This mode may prevent execution if the plan has a popup
#    - Intended for background runs or popup-free scenarios
#    - Limit to non-commercial use
#
# 2. Implement compute_plan_remote:
#    - Execute compute_plan on a remote machine via psexec
#    - Use keyring package for secure credential storage
#    - Implement psexec command for remote HEC-RAS execution
#    - Create remote_worker objects to store machine details:
#      (machine name, username, password, ras_exe_path, local folder path, etc.)
#    - Develop RasRemote class for remote_worker management and abstractions
#    - Implement compute_plan_remote in RasCmdr as a thin wrapper around RasRemote
#      (similar to existing compute_plan functions but for remote execution)


class RasCmdr:
    
    @staticmethod
    @log_call
    def compute_plan(
        plan_number,
        dest_folder=None, 
        ras_object=None,
        clear_geompre=False,
        num_cores=None,
        overwrite_dest=False
    ):
        """
        Execute a HEC-RAS plan.

        Args:
            plan_number (str, Path): The plan number to execute (e.g., "01", "02") or the full path to the plan file.
            dest_folder (str, Path, optional): Name of the folder or full path for computation.
                If a string is provided, it will be created in the same parent directory as the project folder.
                If a full path is provided, it will be used as is.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files. Defaults to False.
            num_cores (int, optional): Number of cores to use for the plan execution. If None, the current setting is not changed.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            bool: True if the execution was successful, False otherwise.

        Raises:
            ValueError: If the specified dest_folder already exists and is not empty, and overwrite_dest is False.
        """
        try:
            ras_obj = ras_object if ras_object is not None else ras
            logger.info(f"Using ras_object with project folder: {ras_obj.project_folder}")
            ras_obj.check_initialized()
            
            if dest_folder is not None:
                dest_folder = Path(ras_obj.project_folder).parent / dest_folder if isinstance(dest_folder, str) else Path(dest_folder)
                
                if dest_folder.exists():
                    if overwrite_dest:
                        shutil.rmtree(dest_folder)
                        logger.info(f"Destination folder '{dest_folder}' exists. Overwriting as per overwrite_dest=True.")
                    elif any(dest_folder.iterdir()):
                        error_msg = f"Destination folder '{dest_folder}' exists and is not empty. Use overwrite_dest=True to overwrite."
                        logger.error(error_msg)
                        raise ValueError(error_msg)
                
                dest_folder.mkdir(parents=True, exist_ok=True)
                shutil.copytree(ras_obj.project_folder, dest_folder, dirs_exist_ok=True)
                logger.info(f"Copied project folder to destination: {dest_folder}")
                
                compute_ras = RasPrj()
                compute_ras.initialize(dest_folder, ras_obj.ras_exe_path)
                compute_prj_path = compute_ras.prj_file
            else:
                compute_ras = ras_obj
                compute_prj_path = ras_obj.prj_file

            # Determine the plan path
            compute_plan_path = Path(plan_number) if isinstance(plan_number, (str, Path)) and Path(plan_number).is_file() else RasPlan.get_plan_path(plan_number, compute_ras)

            if not compute_prj_path or not compute_plan_path:
                logger.error(f"Could not find project file or plan file for plan {plan_number}")
                return False

            # Clear geometry preprocessor files if requested
            if clear_geompre:
                try:
                    RasGeo.clear_geompre_files(compute_plan_path, ras_object=compute_ras)
                    logger.info(f"Cleared geometry preprocessor files for plan: {plan_number}")
                except Exception as e:
                    logger.error(f"Error clearing geometry preprocessor files for plan {plan_number}: {str(e)}")

            # Set the number of cores if specified
            if num_cores is not None:
                try:
                    RasPlan.set_num_cores(compute_plan_path, num_cores=num_cores, ras_object=compute_ras)
                    logger.info(f"Set number of cores to {num_cores} for plan: {plan_number}")
                except Exception as e:
                    logger.error(f"Error setting number of cores for plan {plan_number}: {str(e)}")

            # Prepare the command for HEC-RAS execution
            cmd = f'"{compute_ras.ras_exe_path}" -c "{compute_prj_path}" "{compute_plan_path}"'
            logger.info("Running HEC-RAS from the Command Line:")
            logger.info(f"Running command: {cmd}")

            # Execute the HEC-RAS command
            start_time = time.time()
            try:
                subprocess.run(cmd, check=True, shell=True, capture_output=True, text=True)
                end_time = time.time()
                run_time = end_time - start_time
                logger.info(f"HEC-RAS execution completed for plan: {plan_number}")
                logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
                return True
            except subprocess.CalledProcessError as e:
                end_time = time.time()
                run_time = end_time - start_time
                logger.error(f"Error running plan: {plan_number}")
                logger.error(f"Error message: {e.output}")
                logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")
                return False
        except Exception as e:
            logger.critical(f"Error in compute_plan: {str(e)}")
            return False
        finally:
            # Update the RAS object's dataframes
            if ras_obj:
                ras_obj.plan_df = ras_obj.get_plan_entries()
                ras_obj.geom_df = ras_obj.get_geom_entries()
                ras_obj.flow_df = ras_obj.get_flow_entries()
                ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
    


    @staticmethod
    @log_call
    @staticmethod
    @log_call
    def compute_parallel(
        plan_number: Union[str, List[str], None] = None,
        max_workers: int = 2,
        num_cores: int = 2,
        clear_geompre: bool = False,
        ras_object: Optional['RasPrj'] = None,
        dest_folder: Union[str, Path, None] = None,
        overwrite_dest: bool = False
    ) -> Dict[str, bool]:
        """
        Compute multiple HEC-RAS plans in parallel.

        Args:
            plan_number (Union[str, List[str], None]): Plan number(s) to compute. If None, all plans are computed.
            max_workers (int): Maximum number of parallel workers.
            num_cores (int): Number of cores to use per plan computation.
            clear_geompre (bool): Whether to clear geometry preprocessor files.
            ras_object (Optional[RasPrj]): RAS project object. If None, uses global instance.
            dest_folder (Union[str, Path, None]): Destination folder for computed results.
            overwrite_dest (bool): Whether to overwrite existing destination folder.

        Returns:
            Dict[str, bool]: Dictionary of plan numbers and their execution success status.
        """
        try:
            ras_obj = ras_object or ras
            ras_obj.check_initialized()

            project_folder = Path(ras_obj.project_folder)

            if dest_folder is not None:
                dest_folder_path = Path(dest_folder)
                if dest_folder_path.exists():
                    if overwrite_dest:
                        shutil.rmtree(dest_folder_path)
                        logger.info(f"Destination folder '{dest_folder_path}' exists. Overwriting as per overwrite_dest=True.")
                    elif any(dest_folder_path.iterdir()):
                        error_msg = f"Destination folder '{dest_folder_path}' exists and is not empty. Use overwrite_dest=True to overwrite."
                        logger.error(error_msg)
                        raise ValueError(error_msg)
                dest_folder_path.mkdir(parents=True, exist_ok=True)
                shutil.copytree(project_folder, dest_folder_path, dirs_exist_ok=True)
                logger.info(f"Copied project folder to destination: {dest_folder_path}")
                project_folder = dest_folder_path

            if plan_number:
                if isinstance(plan_number, str):
                    plan_number = [plan_number]
                ras_obj.plan_df = ras_obj.plan_df[ras_obj.plan_df['plan_number'].isin(plan_number)]
                logger.info(f"Filtered plans to execute: {plan_number}")

            num_plans = len(ras_obj.plan_df)
            max_workers = min(max_workers, num_plans) if num_plans > 0 else 1
            logger.info(f"Adjusted max_workers to {max_workers} based on the number of plans: {num_plans}")

            worker_ras_objects = {}
            for worker_id in range(1, max_workers + 1):
                worker_folder = project_folder.parent / f"{project_folder.name} [Worker {worker_id}]"
                if worker_folder.exists():
                    shutil.rmtree(worker_folder)
                    logger.info(f"Removed existing worker folder: {worker_folder}")
                shutil.copytree(project_folder, worker_folder)
                logger.info(f"Created worker folder: {worker_folder}")

                try:
                    ras_instance = RasPrj()
                    worker_ras_instance = init_ras_project(
                        ras_project_folder=worker_folder,
                        ras_version=ras_obj.ras_exe_path,
                        ras_instance=ras_instance
                    )
                    worker_ras_objects[worker_id] = worker_ras_instance
                except Exception as e:
                    logger.critical(f"Failed to initialize RAS project for worker {worker_id}: {str(e)}")
                    worker_ras_objects[worker_id] = None

            worker_cycle = cycle(range(1, max_workers + 1))
            plan_assignments = [(next(worker_cycle), plan_num) for plan_num in ras_obj.plan_df['plan_number']]

            execution_results: Dict[str, bool] = {}

            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(
                        RasCmdr.compute_plan,
                        plan_num, 
                        ras_object=worker_ras_objects[worker_id], 
                        clear_geompre=clear_geompre,
                        num_cores=num_cores
                    )
                    for worker_id, plan_num in plan_assignments
                ]

                for future, (worker_id, plan_num) in zip(as_completed(futures), plan_assignments):
                    try:
                        success = future.result()
                        execution_results[plan_num] = success
                        logger.info(f"Plan {plan_num} executed in worker {worker_id}: {'Successful' if success else 'Failed'}")
                    except Exception as e:
                        execution_results[plan_num] = False
                        logger.error(f"Plan {plan_num} failed in worker {worker_id}: {str(e)}")

            final_dest_folder = dest_folder_path if dest_folder is not None else project_folder.parent / f"{project_folder.name} [Computed]"
            final_dest_folder.mkdir(parents=True, exist_ok=True)
            logger.info(f"Final destination for computed results: {final_dest_folder}")

            for worker_ras in worker_ras_objects.values():
                if worker_ras is None:
                    continue
                worker_folder = Path(worker_ras.project_folder)
                try:
                    for item in worker_folder.iterdir():
                        dest_path = final_dest_folder / item.name
                        if dest_path.exists():
                            if dest_path.is_dir():
                                shutil.rmtree(dest_path)
                                logger.debug(f"Removed existing directory at {dest_path}")
                            else:
                                dest_path.unlink()
                                logger.debug(f"Removed existing file at {dest_path}")
                        shutil.move(str(item), final_dest_folder)
                        logger.debug(f"Moved {item} to {final_dest_folder}")
                    shutil.rmtree(worker_folder)
                    logger.info(f"Removed worker folder: {worker_folder}")
                except Exception as e:
                    logger.error(f"Error moving results from {worker_folder} to {final_dest_folder}: {str(e)}")

            try:
                final_dest_folder_ras_obj = RasPrj()
                final_dest_folder_ras_obj = init_ras_project(
                    ras_project_folder=final_dest_folder, 
                    ras_version=ras_obj.ras_exe_path,
                    ras_instance=final_dest_folder_ras_obj
                )
                final_dest_folder_ras_obj.check_initialized()
            except Exception as e:
                logger.critical(f"Failed to initialize RasPrj for final destination: {str(e)}")

            logger.info("\nExecution Results:")
            for plan_num, success in execution_results.items():
                status = 'Successful' if success else 'Failed'
                logger.info(f"Plan {plan_num}: {status}")

            ras_obj = ras_object or ras
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

            return execution_results

        except Exception as e:
            logger.critical(f"Error in compute_parallel: {str(e)}")
            return {}

    @staticmethod
    @log_call
    def compute_test_mode(
        plan_number=None, 
        dest_folder_suffix="[Test]", 
        clear_geompre=False, 
        num_cores=None, 
        ras_object=None,
        overwrite_dest=False
    ):
        """
        Execute HEC-RAS plans in test mode. This is a re-creation of the HEC-RAS command line -test flag, 
        which does not work in recent versions of HEC-RAS.
        
        As a special-purpose function that emulates the original -test flag, it operates differently than the 
        other two compute_ functions. Per the original HEC-RAS test flag, it creates a separate test folder,
        copies the project there, and executes the specified plans in sequential order.
        
        For most purposes, just copying a the project folder, initing that new folder, then running each plan 
        with compute_plan is a simpler and more flexible approach.  This is shown in the examples provided
        in the ras-commander library.

        Args:
            plan_number (str, list[str], optional): Plan number or list of plan numbers to execute. 
                If None, all plans will be executed. Default is None.
            dest_folder_suffix (str, optional): Suffix to append to the test folder name to create dest_folder. 
                Defaults to "[Test]".
                dest_folder is always created in the project folder's parent directory.
            clear_geompre (bool, optional): Whether to clear geometry preprocessor files.
                Defaults to False.
            num_cores (int, optional): Maximum number of cores to use for each plan.
                If None, the current setting is not changed. Default is None.
            ras_object (RasPrj, optional): Specific RAS object to use. If None, uses the global ras instance.
            overwrite_dest (bool, optional): If True, overwrite the destination folder if it exists. Defaults to False.

        Returns:
            Dict[str, bool]: Dictionary of plan numbers and their execution success status.

        Example:
            Run all plans: RasCommander.compute_test_mode()
            Run a specific plan: RasCommander.compute_test_mode(plan_number="01")
            Run multiple plans: RasCommander.compute_test_mode(plan_number=["01", "03", "05"])
            Run plans with a custom folder suffix: RasCommander.compute_test_mode(dest_folder_suffix="[TestRun]")
            Run plans and clear geometry preprocessor files: RasCommander.compute_test_mode(clear_geompre=True)
            Run plans with a specific number of cores: RasCommander.compute_test_mode(num_cores=4)
            
        Notes:
            - This function executes plans in a separate folder for isolated testing.
            - If plan_number is not provided, all plans in the project will be executed.
            - The function does not change the geometry preprocessor and IB tables settings.  
                - To force recomputing of geometry preprocessor and IB tables, use the clear_geompre=True option.
            - Plans are executed sequentially.
            - Because copying the project is implicit, only a dest_folder_suffix option is provided.
            - For more flexible run management, use the compute_parallel or compute_sequential functions.
        """
        try:
            ras_obj = ras_object or ras
            ras_obj.check_initialized()
            
            logger.info("Starting the compute_test_mode...")
               
            project_folder = Path(ras_obj.project_folder)

            if not project_folder.exists():
                logger.error(f"Project folder '{project_folder}' does not exist.")
                return {}

            compute_folder = project_folder.parent / f"{project_folder.name} {dest_folder_suffix}"
            logger.info(f"Creating the test folder: {compute_folder}...")

            if compute_folder.exists():
                if overwrite_dest:
                    shutil.rmtree(compute_folder)
                    logger.info(f"Compute folder '{compute_folder}' exists. Overwriting as per overwrite_dest=True.")
                elif any(compute_folder.iterdir()):
                    error_msg = (
                        f"Compute folder '{compute_folder}' exists and is not empty. "
                        "Use overwrite_dest=True to overwrite."
                    )
                    logger.error(error_msg)
                    raise ValueError(error_msg)

            try:
                shutil.copytree(project_folder, compute_folder)
                logger.info(f"Copied project folder to compute folder: {compute_folder}")
            except Exception as e:
                logger.critical(f"Error occurred while copying project folder: {str(e)}")
                return {}

            try:
                compute_ras = RasPrj()
                compute_ras.initialize(compute_folder, ras_obj.ras_exe_path)
                compute_prj_path = compute_ras.prj_file
                logger.info(f"Initialized RAS project in compute folder: {compute_prj_path}")
            except Exception as e:
                logger.critical(f"Error initializing RAS project in compute folder: {str(e)}")
                return {}

            if not compute_prj_path:
                logger.error("Project file not found.")
                return {}

            logger.info("Getting plan entries...")
            try:
                ras_compute_plan_entries = compute_ras.plan_df
                logger.info("Retrieved plan entries successfully.")
            except Exception as e:
                logger.critical(f"Error retrieving plan entries: {str(e)}")
                return {}

            if plan_number:
                if isinstance(plan_number, str):
                    plan_number = [plan_number]
                ras_compute_plan_entries = ras_compute_plan_entries[
                    ras_compute_plan_entries['plan_number'].isin(plan_number)
                ]
                logger.info(f"Filtered plans to execute: {plan_number}")

            execution_results = {}
            logger.info("Running selected plans sequentially...")
            for _, plan in ras_compute_plan_entries.iterrows():
                plan_number = plan["plan_number"]
                start_time = time.time()
                try:
                    success = RasCmdr.compute_plan(
                        plan_number,
                        ras_object=compute_ras,
                        clear_geompre=clear_geompre,
                        num_cores=num_cores
                    )
                    execution_results[plan_number] = success
                    if success:
                        logger.info(f"Successfully computed plan {plan_number}")
                    else:
                        logger.error(f"Failed to compute plan {plan_number}")
                except Exception as e:
                    execution_results[plan_number] = False
                    logger.error(f"Error computing plan {plan_number}: {str(e)}")
                finally:
                    end_time = time.time()
                    run_time = end_time - start_time
                    logger.info(f"Total run time for plan {plan_number}: {run_time:.2f} seconds")

            logger.info("All selected plans have been executed.")
            logger.info("compute_test_mode completed.")

            logger.info("\nExecution Results:")
            for plan_num, success in execution_results.items():
                status = 'Successful' if success else 'Failed'
                logger.info(f"Plan {plan_num}: {status}")

            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()

            return execution_results

        except Exception as e:
            logger.critical(f"Error in compute_test_mode: {str(e)}")
            return {}
==================================================

File: c:\GH\ras-commander\ras_commander\RasExamples.py
==================================================
"""
RasExamples - Manage and load HEC-RAS example projects for testing and development

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
import requests
import zipfile
import pandas as pd
from pathlib import Path
import shutil
from typing import Union, List
import csv
from datetime import datetime
import logging
import re
from tqdm import tqdm
from ras_commander import get_logger
from ras_commander.LoggingConfig import log_call

logger = get_logger(__name__)

class RasExamples:
    """
    A class for quickly loading HEC-RAS example projects for testing and development of ras-commander.

    This class provides functionality to download, extract, and manage HEC-RAS example projects.
    It supports both default HEC-RAS example projects and custom projects from user-provided URLs.
    Additionally, it includes functionality to download FEMA's Base Level Engineering (BLE) models
    from CSV files provided by the FEMA Estimated Base Flood Elevation (BFE) Viewer.
    """
    @log_call
    def __init__:
    """Docs only, see '__init__.py' for full function code"""
        return int(number * units[unit])
==================================================

File: c:\GH\ras-commander\ras_commander\RasGeo.py
==================================================
"""
RasGeo - Operations for handling geometry files in HEC-RAS projects

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
from pathlib import Path
from typing import List, Union
from .RasPlan import RasPlan
from .RasPrj import ras
from .LoggingConfig import get_logger
from .Decorators import log_call

logger = get_logger(__name__)

class RasGeo:
    """
    A class for operations on HEC-RAS geometry files.
    """
    
    @staticmethod
    @log_call
    def clear_geompre_files(
        plan_files: Union[str, Path, List[Union[str, Path]]] = None,
        ras_object = None
    ) -> None:
        """
        Clear HEC-RAS geometry preprocessor files for specified plan files or all plan files in the project directory.
        
        Limitations/Future Work:
        - This function only deletes the geometry preprocessor file.
        - It does not clear the IB tables.
        - It also does not clear geometry preprocessor tables from the geometry HDF.
        - All of these features will need to be added to reliably remove geometry preprocessor files for 1D and 2D projects.
        
        Parameters:
            plan_files (Union[str, Path, List[Union[str, Path]]], optional): 
                Full path(s) to the HEC-RAS plan file(s) (.p*).
                If None, clears all plan files in the project directory.
            ras_object: An optional RAS object instance.
        
        Returns:
            None
        
        Examples:
            # Clear all geometry preprocessor files in the project directory
            RasGeo.clear_geompre_files()
            
            # Clear a single plan file
            RasGeo.clear_geompre_files(r'path/to/plan.p01')
            
            # Clear multiple plan files
            RasGeo.clear_geompre_files([r'path/to/plan1.p01', r'path/to/plan2.p02'])

        Note:
            This function updates the ras object's geometry dataframe after clearing the preprocessor files.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        def clear_single_file(plan_file: Union[str, Path], ras_obj) -> None:
            plan_path = Path(plan_file)
            geom_preprocessor_suffix = '.c' + ''.join(plan_path.suffixes[1:]) if plan_path.suffixes else '.c'
            geom_preprocessor_file = plan_path.with_suffix(geom_preprocessor_suffix)
            if geom_preprocessor_file.exists():
                try:
                    geom_preprocessor_file.unlink()
                    logger.info(f"Deleted geometry preprocessor file: {geom_preprocessor_file}")
                except PermissionError:
                    logger.error(f"Permission denied: Unable to delete geometry preprocessor file: {geom_preprocessor_file}")
                    raise PermissionError(f"Unable to delete geometry preprocessor file: {geom_preprocessor_file}. Permission denied.")
                except OSError as e:
                    logger.error(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
                    raise OSError(f"Error deleting geometry preprocessor file: {geom_preprocessor_file}. {str(e)}")
            else:
                logger.warning(f"No geometry preprocessor file found for: {plan_file}")
        
        if plan_files is None:
            logger.info("Clearing all geometry preprocessor files in the project directory.")
            plan_files_to_clear = list(ras_obj.project_folder.glob(r'*.p*'))
        elif isinstance(plan_files, (str, Path)):
            plan_files_to_clear = [plan_files]
            logger.info(f"Clearing geometry preprocessor file for single plan: {plan_files}")
        elif isinstance(plan_files, list):
            plan_files_to_clear = plan_files
            logger.info(f"Clearing geometry preprocessor files for multiple plans: {plan_files}")
        else:
            logger.error("Invalid input type for plan_files.")
            raise ValueError("Invalid input. Please provide a string, Path, list of paths, or None.")
        
        for plan_file in plan_files_to_clear:
            clear_single_file(plan_file, ras_obj)
        
        try:
            ras_obj.geom_df = ras_obj.get_geom_entries()
            logger.info("Geometry dataframe updated successfully.")
        except Exception as e:
            logger.error(f"Failed to update geometry dataframe: {str(e)}")
            raise









==================================================

File: c:\GH\ras-commander\ras_commander\RasGpt.py
==================================================
import os
from pathlib import Path
from typing import Optional
from ras_commander import get_logger, log_call

logger = get_logger(__name__)

class RasGpt:
    """
    A class containing helper functions for the RAS Commander GPT.
    """
    
# to be implemented later
# 
# This class will contain  methods to help LLM's extract useful information from HEC-RAS models in a structured format with token budget etc. 
# Templates will be used to help with this, based on the example projects (1D Steady, 1D Usteady, 1D Sediment Transport, 1D Water Quality, 2D Unsteady, 2D Steady, 2D Sediment Transport, 2D Water Quality, 2D Geospatial, 3D Unsteady, 3D Steady, 3D Sediment Transport, 3D Water Quality, 3D Geospatial).
# These will simply filter the data to only include the relevant information for the area of focus. 

#

==================================================

File: c:\GH\ras-commander\ras_commander\RasPlan.py
==================================================
"""
RasPlan - Operations for handling plan files in HEC-RAS projects

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).
3. Obtain the logger using: logger = logging.getLogger(__name__)

Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
import re
import logging
from pathlib import Path
import shutil
from typing import Union, Optional
import pandas as pd
from .RasPrj import RasPrj, ras
from .RasUtils import RasUtils
from pathlib import Path
from typing import Union, Any
import logging
import re
from .LoggingConfig import get_logger
from .Decorators import log_call

logger = get_logger(__name__)

class RasPlan:
    """
    A class for operations on HEC-RAS plan files.
    """
    
    @staticmethod
    @log_call
    def set_geom(plan_number: Union[str, int], new_geom: Union[str, int], ras_object=None) -> pd.DataFrame:
        """
        Set the geometry for the specified plan.

        Parameters:
            plan_number (Union[str, int]): The plan number to update.
            new_geom (Union[str, int]): The new geometry number to set.
            ras_object: An optional RAS object instance.

        Returns:
            pd.DataFrame: The updated geometry DataFrame.

        Example:
            updated_geom_df = RasPlan.set_geom('02', '03')

        Note:
            This function updates the ras object's dataframes after modifying the project structure.
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        # Ensure plan_number and new_geom are strings
        plan_number = str(plan_number).zfill(2)
        new_geom = str(new_geom).zfill(2)

        # Before doing anything, make sure the plan, geom, flow, and unsteady dataframes are current
        ras_obj.plan_df = ras_obj.get_plan_entries()
        ras_obj.geom_df = ras_obj.get_geom_entries()
        ras_obj.flow_df = ras_obj.get_flow_entries()
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
        
        if new_geom not in ras_obj.geom_df['geom_number'].values:
            logger.error(f"Geometry {new_geom} not found in project.")
            raise ValueError(f"Geometry {new_geom} not found in project.")

        # Update the geometry for the specified plan
        ras_obj.plan_df.loc[ras_obj.plan_df['plan_number'] == plan_number, 'geom_number'] = new_geom

        logger.info(f"Geometry for plan {plan_number} set to {new_geom}")
        logger.debug("Updated plan DataFrame:")
        logger.debug(ras_obj.plan_df)

        # Update the project file
        prj_file_path = ras_obj.prj_file
        RasUtils.update_file(prj_file_path, RasPlan._update_geom_in_file, plan_number, new_geom)

        # Re-initialize the ras object to reflect changes
        ras_obj.initialize(ras_obj.project_folder, ras_obj.ras_exe_path)

        return ras_obj.plan_df

    @staticmethod
    def _update_geom_in_file:
    """Docs only, see '_update_geom_in_file.py' for full function code"""
        ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
==================================================

File: c:\GH\ras-commander\ras_commander\RasPrj.py
==================================================
"""
RasPrj.py - Manages HEC-RAS projects within the ras-commander library

This module provides a class for managing HEC-RAS projects.

Classes:
    RasPrj: A class for managing HEC-RAS projects.

Functions:
    init_ras_project: Initialize a RAS project.
    get_ras_exe: Determine the HEC-RAS executable path based on the input.

DEVELOPER NOTE:
This class is used to initialize a RAS project and is used in conjunction with the RasCmdr class to manage the execution of RAS plans.
By default, the RasPrj class is initialized with the global 'ras' object.
However, you can create multiple RasPrj instances to manage multiple projects.
Do not mix and match global 'ras' object instances and custom instances of RasPrj - it will cause errors.

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).


Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
import re
from pathlib import Path
import pandas as pd
from typing import Union, Any, List, Dict, Tuple
import logging
from ras_commander.LoggingConfig import get_logger
from ras_commander.Decorators import log_call

logger = get_logger(__name__)

class RasPrj:
    
    def __init__:
    """Docs only, see '__init__.py' for full function code"""
# Defining the global instance allows the init_ras_project function to initialize the project.
# This only happens on the library initialization, not when the user calls init_ras_project.
ras = RasPrj()

# END OF CLASS DEFINITION


# START OF FUNCTION DEFINITIONS


@log_call
def init_ras_project:
    """Docs only, see 'init_ras_project.py' for full function code"""
def get_ras_exe:
    """Docs only, see 'get_ras_exe.py' for full function code"""

==================================================

File: c:\GH\ras-commander\ras_commander\RasUnsteady.py
==================================================
"""
RasUnsteady - Operations for handling unsteady flow files in HEC-RAS projects.

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).


Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
from pathlib import Path
from .RasPrj import ras
from .LoggingConfig import get_logger
from .Decorators import log_call

logger = get_logger(__name__)

# Module code starts here

class RasUnsteady:
    """
    Class for all operations related to HEC-RAS unsteady flow files.
    """
    
    @staticmethod
    @log_call
    def update_unsteady_parameters:
    """Docs only, see 'update_unsteady_parameters.py' for full function code"""

==================================================

File: c:\GH\ras-commander\ras_commander\RasUtils.py
==================================================
"""
RasUtils - Utility functions for the ras-commander library

This module is part of the ras-commander library and uses a centralized logging configuration.

Logging Configuration:
- The logging is set up in the logging_config.py file.
- A @log_call decorator is available to automatically log function calls.
- Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
- Logs are written to both console and a rotating file handler.
- The default log file is 'ras_commander.log' in the 'logs' directory.
- The default log level is INFO.

To use logging in this module:
1. Use the @log_call decorator for automatic function call logging.
2. For additional logging, use logger.[level]() calls (e.g., logger.info(), logger.debug()).

Example:
    @log_call
    def my_function:
    """Docs only, see 'my_function.py' for full function code"""
"""
import os
from pathlib import Path
from .RasPrj import ras
from typing import Union, Optional, Dict, Callable, List, Tuple, Any
import pandas as pd
import numpy as np
import shutil
import re
from scipy.spatial import KDTree
import datetime
import time
import h5py
from datetime import timedelta
from .LoggingConfig import get_logger
from .Decorators import log_call


logger = get_logger(__name__)
# Module code starts here

class RasUtils:
    """
    A class containing utility functions for the ras-commander library.
    When integrating new functions that do not clearly fit into other classes, add them here.
    """

    @staticmethod
    @log_call
    def create_directory(directory_path: Path, ras_object=None) -> Path:
        """
        Ensure that a directory exists, creating it if necessary.

        Parameters:
        directory_path (Path): Path to the directory
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Path to the ensured directory

        Example:
        >>> ensured_dir = RasUtils.create_directory(Path("output"))
        >>> print(f"Directory ensured: {ensured_dir}")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(directory_path)
        try:
            path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Directory ensured: {path}")
        except Exception as e:
            logger.error(f"Failed to create directory {path}: {e}")
            raise
        return path

    @staticmethod
    @log_call
    def find_files_by_extension(extension: str, ras_object=None) -> list:
        """
        List all files in the project directory with a specific extension.

        Parameters:
        extension (str): File extension to filter (e.g., '.prj')
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        list: List of file paths matching the extension

        Example:
        >>> prj_files = RasUtils.find_files_by_extension('.prj')
        >>> print(f"Found {len(prj_files)} .prj files")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        try:
            files = list(ras_obj.project_folder.glob(f"*{extension}"))
            file_list = [str(file) for file in files]
            logger.info(f"Found {len(file_list)} files with extension '{extension}' in {ras_obj.project_folder}")
            return file_list
        except Exception as e:
            logger.error(f"Failed to find files with extension '{extension}': {e}")
            raise

    @staticmethod
    @log_call
    def get_file_size(file_path: Path, ras_object=None) -> Optional[int]:
        """
        Get the size of a file in bytes.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[int]: Size of the file in bytes, or None if the file does not exist

        Example:
        >>> size = RasUtils.get_file_size(Path("project.prj"))
        >>> print(f"File size: {size} bytes")
        """
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                size = path.stat().st_size
                logger.info(f"Size of {path}: {size} bytes")
                return size
            except Exception as e:
                logger.error(f"Failed to get size for {path}: {e}")
                raise
        else:
            logger.warning(f"File not found: {path}")
            return None

    @staticmethod
    @log_call
    def get_file_modification_time(file_path: Path, ras_object=None) -> Optional[float]:
        """
        Get the last modification time of a file.

        Parameters:
        file_path (Path): Path to the file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Optional[float]: Last modification time as a timestamp, or None if the file does not exist

        Example:
        >>> mtime = RasUtils.get_file_modification_time(Path("project.prj"))
        >>> print(f"Last modified: {mtime}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        path = Path(file_path)
        if path.exists():
            try:
                mtime = path.stat().st_mtime
                logger.info(f"Last modification time of {path}: {mtime}")
                return mtime
            except Exception as e:
                logger.exception(f"Failed to get modification time for {path}")
                raise
        else:
            logger.warning(f"File not found: {path}")
            return None

    @staticmethod
    @log_call
    def get_plan_path(current_plan_number_or_path: Union[str, Path], ras_object=None) -> Path:
        """
        Get the path for a plan file with a given plan number or path.

        Parameters:
        current_plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        Path: Full path to the plan file

        Example:
        >>> plan_path = RasUtils.get_plan_path(1)
        >>> print(f"Plan file path: {plan_path}")
        >>> plan_path = RasUtils.get_plan_path("path/to/plan.p01")
        >>> print(f"Plan file path: {plan_path}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        plan_path = Path(current_plan_number_or_path)
        if plan_path.is_file():
            logger.info(f"Using provided plan file path: {plan_path}")
            return plan_path
        
        try:
            current_plan_number = f"{int(current_plan_number_or_path):02d}"  # Ensure two-digit format
            logger.debug(f"Converted plan number to two-digit format: {current_plan_number}")
        except ValueError:
            logger.error(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
            raise ValueError(f"Invalid plan number: {current_plan_number_or_path}. Expected a number from 1 to 99.")
        
        plan_name = f"{ras_obj.project_name}.p{current_plan_number}"
        full_plan_path = ras_obj.project_folder / plan_name
        logger.info(f"Constructed plan file path: {full_plan_path}")
        return full_plan_path

    @staticmethod
    @log_call
    def remove_with_retry(
        path: Path,
        max_attempts: int = 5,
        initial_delay: float = 1.0,
        is_folder: bool = True,
        ras_object=None
    ) -> bool:
        """
        Attempts to remove a file or folder with retry logic and exponential backoff.

        Parameters:
        path (Path): Path to the file or folder to be removed.
        max_attempts (int): Maximum number of removal attempts.
        initial_delay (float): Initial delay between attempts in seconds.
        is_folder (bool): If True, the path is treated as a folder; if False, it's treated as a file.
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Returns:
        bool: True if the file or folder was successfully removed, False otherwise.

        Example:
        >>> success = RasUtils.remove_with_retry(Path("temp_folder"), is_folder=True)
        >>> print(f"Removal successful: {success}")
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()

        path = Path(path)
        for attempt in range(1, max_attempts + 1):
            try:
                if path.exists():
                    if is_folder:
                        shutil.rmtree(path)
                        logger.info(f"Folder removed: {path}")
                    else:
                        path.unlink()
                        logger.info(f"File removed: {path}")
                else:
                    logger.info(f"Path does not exist, nothing to remove: {path}")
                return True
            except PermissionError as pe:
                if attempt < max_attempts:
                    delay = initial_delay * (2 ** (attempt - 1))  # Exponential backoff
                    logger.warning(
                        f"PermissionError on attempt {attempt} to remove {path}: {pe}. "
                        f"Retrying in {delay} seconds..."
                    )
                    time.sleep(delay)
                else:
                    logger.error(
                        f"Failed to remove {path} after {max_attempts} attempts due to PermissionError: {pe}. Skipping."
                    )
                    return False
            except Exception as e:
                logger.exception(f"Failed to remove {path} on attempt {attempt}")
                return False
        return False

    @staticmethod
    @log_call
    def update_plan_file(
        plan_number_or_path: Union[str, Path],
        file_type: str,
        entry_number: int,
        ras_object=None
    ) -> None:
        """
        Update a plan file with a new file reference.

        Parameters:
        plan_number_or_path (Union[str, Path]): The plan number (1 to 99) or full path to the plan file
        file_type (str): Type of file to update ('Geom', 'Flow', or 'Unsteady')
        entry_number (int): Number (from 1 to 99) to set
        ras_object (RasPrj, optional): RAS object to use. If None, uses the default ras object.

        Raises:
        ValueError: If an invalid file_type is provided
        FileNotFoundError: If the plan file doesn't exist

        Example:
        >>> RasUtils.update_plan_file(1, "Geom", 2)
        >>> RasUtils.update_plan_file("path/to/plan.p01", "Geom", 2)
        """
        
        ras_obj = ras_object or ras
        ras_obj.check_initialized()
        
        valid_file_types = {'Geom': 'g', 'Flow': 'f', 'Unsteady': 'u'}
        if file_type not in valid_file_types:
            logger.error(
                f"Invalid file_type '{file_type}'. Expected one of: {', '.join(valid_file_types.keys())}"
            )
            raise ValueError(
                f"Invalid file_type. Expected one of: {', '.join(valid_file_types.keys())}"
            )

        plan_file_path = Path(plan_number_or_path)
        if not plan_file_path.is_file():
            plan_file_path = RasUtils.get_plan_path(plan_number_or_path, ras_object)
            if not plan_file_path.exists():
                logger.error(f"Plan file not found: {plan_file_path}")
                raise FileNotFoundError(f"Plan file not found: {plan_file_path}")
        
        file_prefix = valid_file_types[file_type]
        search_pattern = f"{file_type} File="
        formatted_entry_number = f"{int(entry_number):02d}"  # Ensure two-digit format

        try:
            RasUtils.check_file_access(plan_file_path, 'r')
            with plan_file_path.open('r') as file:
                lines = file.readlines()
        except Exception as e:
            logger.exception(f"Failed to read plan file {plan_file_path}")
            raise

        updated = False
        for i, line in enumerate(lines):
            if line.startswith(search_pattern):
                lines[i] = f"{search_pattern}{file_prefix}{formatted_entry_number}\n"
                logger.info(
                    f"Updated {file_type} File in {plan_file_path} to {file_prefix}{formatted_entry_number}"
                )
                updated = True
                break

        if not updated:
            logger.warning(
                f"Search pattern '{search_pattern}' not found in {plan_file_path}. No update performed."
            )

        try:
            with plan_file_path.open('w') as file:
                file.writelines(lines)
            logger.info(f"Successfully updated plan file: {plan_file_path}")
        except Exception as e:
            logger.exception(f"Failed to write updates to plan file {plan_file_path}")
            raise

        # Refresh RasPrj dataframes
        try:
            ras_obj.plan_df = ras_obj.get_plan_entries()
            ras_obj.geom_df = ras_obj.get_geom_entries()
            ras_obj.flow_df = ras_obj.get_flow_entries()
            ras_obj.unsteady_df = ras_obj.get_unsteady_entries()
            logger.info("RAS object dataframes have been refreshed.")
        except Exception as e:
            logger.exception("Failed to refresh RasPrj dataframes")
            raise

    @staticmethod
    @log_call
    def check_file_access(file_path: Path, mode: str = 'r') -> None:
        """
        Check if the file can be accessed with the specified mode.

        Parameters:
        file_path (Path): Path to the file
        mode (str): Mode to check ('r' for read, 'w' for write, etc.)

        Raises:
        FileNotFoundError: If the file does not exist
        PermissionError: If the required permissions are not met
        """
        
        path = Path(file_path)
        if not path.exists():
            logger.error(f"File not found: {file_path}")
            raise FileNotFoundError(f"File not found: {file_path}")
        
        if mode in ('r', 'rb'):
            if not os.access(path, os.R_OK):
                logger.error(f"Read permission denied for file: {file_path}")
                raise PermissionError(f"Read permission denied for file: {file_path}")
            else:
                logger.debug(f"Read access granted for file: {file_path}")
        
        if mode in ('w', 'wb', 'a', 'ab'):
            parent_dir = path.parent
            if not os.access(parent_dir, os.W_OK):
                logger.error(f"Write permission denied for directory: {parent_dir}")
                raise PermissionError(f"Write permission denied for directory: {parent_dir}")
            else:
                logger.debug(f"Write access granted for directory: {parent_dir}")


    @staticmethod
    @log_call
    def convert_to_dataframe(data_source: Union[pd.DataFrame, Path], **kwargs) -> pd.DataFrame:
        """
        Converts input to a pandas DataFrame. Supports existing DataFrames or file paths (CSV, Excel, TSV, Parquet).

        Args:
            data_source (Union[pd.DataFrame, Path]): The input to convert to a DataFrame. Can be a file path or an existing DataFrame.
            **kwargs: Additional keyword arguments to pass to pandas read functions.

        Returns:
            pd.DataFrame: The resulting DataFrame.

        Raises:
            NotImplementedError: If the file type is unsupported or input type is invalid.

        Example:
            >>> df = RasUtils.convert_to_dataframe(Path("data.csv"))
            >>> print(type(df))
            <class 'pandas.core.frame.DataFrame'>
        """
        if isinstance(data_source, pd.DataFrame):
            logger.debug("Input is already a DataFrame, returning a copy.")
            return data_source.copy()
        elif isinstance(data_source, Path):
            ext = data_source.suffix.replace('.', '', 1)
            logger.info(f"Converting file with extension '{ext}' to DataFrame.")
            if ext == 'csv':
                return pd.read_csv(data_source, **kwargs)
            elif ext.startswith('x'):
                return pd.read_excel(data_source, **kwargs)
            elif ext == "tsv":
                return pd.read_csv(data_source, sep="\t", **kwargs)
            elif ext in ["parquet", "pq", "parq"]:
                return pd.read_parquet(data_source, **kwargs)
            else:
                logger.error(f"Unsupported file type: {ext}")
                raise NotImplementedError(f"Unsupported file type {ext}. Should be one of csv, tsv, parquet, or xlsx.")
        else:
            logger.error(f"Unsupported input type: {type(data_source)}")
            raise NotImplementedError(f"Unsupported type {type(data_source)}. Only file path / existing DataFrame supported at this time")

    @staticmethod
    @log_call
    def save_to_excel(dataframe: pd.DataFrame, excel_path: Path, **kwargs) -> None:
        """
        Saves a pandas DataFrame to an Excel file with retry functionality.

        Args:
            dataframe (pd.DataFrame): The DataFrame to save.
            excel_path (Path): The path to the Excel file where the DataFrame will be saved.
            **kwargs: Additional keyword arguments passed to `DataFrame.to_excel()`.

        Raises:
            IOError: If the file cannot be saved after multiple attempts.

        Example:
            >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
            >>> RasUtils.save_to_excel(df, Path('output.xlsx'))
        """
        saved = False
        max_attempts = 3
        attempt = 0

        while not saved and attempt < max_attempts:
            try:
                dataframe.to_excel(excel_path, **kwargs)
                logger.info(f'DataFrame successfully saved to {excel_path}')
                saved = True
            except IOError as e:
                attempt += 1
                if attempt < max_attempts:
                    logger.warning(f"Error saving file. Attempt {attempt} of {max_attempts}. Please close the Excel document if it's open.")
                else:
                    logger.error(f"Failed to save {excel_path} after {max_attempts} attempts.")
                    raise IOError(f"Failed to save {excel_path} after {max_attempts} attempts. Last error: {str(e)}")

    @staticmethod
    @log_call
    def calculate_rmse(observed_values: np.ndarray, predicted_values: np.ndarray, normalized: bool = True) -> float:
        """
        Calculate the Root Mean Squared Error (RMSE) between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            normalized (bool, optional): Whether to normalize RMSE to a percentage of observed_values. Defaults to True.

        Returns:
            float: The calculated RMSE value.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_rmse(observed, predicted)
            0.06396394
        """
        rmse = np.sqrt(np.mean((predicted_values - observed_values) ** 2))
        
        if normalized:
            rmse = rmse / np.abs(np.mean(observed_values))
        
        logger.debug(f"Calculated RMSE: {rmse}")
        return rmse

    @staticmethod
    @log_call
    def calculate_percent_bias(observed_values: np.ndarray, predicted_values: np.ndarray, as_percentage: bool = False) -> float:
        """
        Calculate the Percent Bias between observed and predicted values.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.
            as_percentage (bool, optional): If True, return bias as a percentage. Defaults to False.

        Returns:
            float: The calculated Percent Bias.

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_percent_bias(observed, predicted, as_percentage=True)
            3.33333333
        """
        multiplier = 100 if as_percentage else 1
        
        percent_bias = multiplier * (np.mean(predicted_values) - np.mean(observed_values)) / np.mean(observed_values)
        
        logger.debug(f"Calculated Percent Bias: {percent_bias}")
        return percent_bias

    @staticmethod
    @log_call
    def calculate_error_metrics(observed_values: np.ndarray, predicted_values: np.ndarray) -> Dict[str, float]:
        """
        Compute a trio of error metrics: correlation, RMSE, and Percent Bias.

        Args:
            observed_values (np.ndarray): Actual observations time series.
            predicted_values (np.ndarray): Estimated/predicted time series.

        Returns:
            Dict[str, float]: A dictionary containing correlation ('cor'), RMSE ('rmse'), and Percent Bias ('pb').

        Example:
            >>> observed = np.array([1, 2, 3])
            >>> predicted = np.array([1.1, 2.2, 2.9])
            >>> RasUtils.calculate_error_metrics(observed, predicted)
            {'cor': 0.9993, 'rmse': 0.06396, 'pb': 0.03333}
        """
        correlation = np.corrcoef(observed_values, predicted_values)[0, 1]
        rmse = RasUtils.calculate_rmse(observed_values, predicted_values)
        percent_bias = RasUtils.calculate_percent_bias(observed_values, predicted_values)
        
        metrics = {'cor': correlation, 'rmse': rmse, 'pb': percent_bias}
        logger.info(f"Calculated error metrics: {metrics}")
        return metrics

    
    @staticmethod
    @log_call
    def update_file(file_path: Path, update_function: Callable, *args) -> None:
        """
        Generic method to update a file.

        Parameters:
        file_path (Path): Path to the file to be updated
        update_function (Callable): Function to update the file contents
        *args: Additional arguments to pass to the update_function

        Raises:
        Exception: If there's an error updating the file

        Example:
        >>> def update_content:
    """Docs only, see 'update_content.py' for full function code"""
    
==================================================

File: c:\GH\ras-commander\ras_commander\__init__.py
==================================================
from importlib.metadata import version, PackageNotFoundError
from .LoggingConfig import setup_logging, get_logger
from .Decorators import log_call, standardize_input

try:
    __version__ = version("ras-commander")
except PackageNotFoundError:
    # package is not installed
    __version__ = "unknown"

# Set up logging
setup_logging()

# Import all necessary functions and classes directly
from .RasPrj import RasPrj, init_ras_project, get_ras_exe, ras
from .RasPlan import RasPlan
from .RasGeo import RasGeo
from .RasUnsteady import RasUnsteady
from .RasUtils import RasUtils
from .RasExamples import RasExamples
from .RasCmdr import RasCmdr
from .RasGpt import RasGpt

# Import the Hdf* classes
from .HdfBase import HdfBase
from .HdfBndry import HdfBndry
from .HdfMesh import HdfMesh
from .HdfPlan import HdfPlan
from .HdfResultsMesh import HdfResultsMesh
from .HdfResultsPlan import HdfResultsPlan
from .HdfResultsXsec import HdfResultsXsec
from .HdfStruc import HdfStruc
from .HdfUtils import HdfUtils
from .HdfXsec import HdfXsec

# Define __all__ to specify what should be imported when using "from ras_commander import *"
__all__ = [
    "HdfBase",
    "HdfBndry",
    "HdfMesh",
    "HdfPlan",
    "HdfResultsMesh",
    "HdfResultsPlan",
    "HdfResultsXsec",
    "HdfStruc",
    "HdfUtils",
    "HdfXsec",
    "standardize_input",
    "ras",
    "init_ras_project",
    "get_ras_exe",
    "RasPrj",
    "RasPlan",
    "RasGeo",
    "RasUnsteady",
    "RasCmdr",
    "RasUtils",
    "RasExamples",
    "get_logger",
    "log_call",
]

__version__ = "0.1.0"

==================================================

